INFO:root:Output: small_val_1310
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24457.48514441288
INFO:root:current train perplexity15516.41015625
INFO:root:current mean train loss 20541.316641802765
INFO:root:current train perplexity3279.9140625
INFO:root:current mean train loss 17747.223776520696
INFO:root:current train perplexity1093.2978515625
INFO:root:current mean train loss 15854.346368851817
INFO:root:current train perplexity514.0171508789062
INFO:root:current mean train loss 14480.691656751002
INFO:root:current train perplexity299.1008605957031
INFO:root:current mean train loss 13437.949959731062
INFO:root:current train perplexity198.9258270263672
INFO:root:current mean train loss 12626.725453912955
INFO:root:current train perplexity144.46685791015625
INFO:root:current mean train loss 11976.334993937735
INFO:root:current train perplexity112.06232452392578
INFO:root:current mean train loss 11443.891840000173
INFO:root:current train perplexity90.89015197753906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.75s/it]
INFO:root:final mean train loss: 11014.523985339749
INFO:root:final train perplexity: 77.13430786132812
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
INFO:root:eval mean loss: 7350.967809985498
INFO:root:eval perplexity: 20.595233917236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/1
  0%|          | 1/200 [02:50<9:25:19, 170.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6822.144391741072
INFO:root:current train perplexity14.502228736877441
INFO:root:current mean train loss 6730.9206611419395
INFO:root:current train perplexity14.39748764038086
INFO:root:current mean train loss 6702.280233337107
INFO:root:current train perplexity14.159095764160156
INFO:root:current mean train loss 6629.950926939128
INFO:root:current train perplexity13.735876083374023
INFO:root:current mean train loss 6576.220441588605
INFO:root:current train perplexity13.43503475189209
INFO:root:current mean train loss 6526.259313940766
INFO:root:current train perplexity13.165239334106445
INFO:root:current mean train loss 6483.578514337933
INFO:root:current train perplexity12.894881248474121
INFO:root:current mean train loss 6435.856498491646
INFO:root:current train perplexity12.653107643127441
INFO:root:current mean train loss 6391.685560186261
INFO:root:current train perplexity12.42737865447998
INFO:root:current mean train loss 6347.077029462686
INFO:root:current train perplexity12.222855567932129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.52s/it]
INFO:root:final mean train loss: 6309.964243242817
INFO:root:final train perplexity: 12.054807662963867
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 6679.4860050407
INFO:root:eval perplexity: 15.622817993164062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/2
  1%|          | 2/200 [05:13<8:29:18, 154.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5986.069986979167
INFO:root:current train perplexity10.633188247680664
INFO:root:current mean train loss 5881.351834239131
INFO:root:current train perplexity10.239001274108887
INFO:root:current mean train loss 5860.10380859375
INFO:root:current train perplexity10.10244083404541
INFO:root:current mean train loss 5839.716590711805
INFO:root:current train perplexity9.988810539245605
INFO:root:current mean train loss 5815.567935805723
INFO:root:current train perplexity9.899845123291016
INFO:root:current mean train loss 5790.868061665656
INFO:root:current train perplexity9.816143035888672
INFO:root:current mean train loss 5766.347487931911
INFO:root:current train perplexity9.736978530883789
INFO:root:current mean train loss 5747.497333233173
INFO:root:current train perplexity9.658931732177734
INFO:root:current mean train loss 5734.457986843367
INFO:root:current train perplexity9.588507652282715
INFO:root:current mean train loss 5715.807463498975
INFO:root:current train perplexity9.505514144897461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.12s/it]
INFO:root:final mean train loss: 5692.208346213064
INFO:root:final train perplexity: 9.447412490844727
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 6401.347514443769
INFO:root:eval perplexity: 13.933183670043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/3
  2%|â–         | 3/200 [07:31<8:01:43, 146.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5565.262780230978
INFO:root:current train perplexity8.82274341583252
INFO:root:current mean train loss 5485.8152073805895
INFO:root:current train perplexity8.718855857849121
INFO:root:current mean train loss 5484.368575707679
INFO:root:current train perplexity8.657110214233398
INFO:root:current mean train loss 5457.572152247001
INFO:root:current train perplexity8.576807022094727
INFO:root:current mean train loss 5444.927106419917
INFO:root:current train perplexity8.551606178283691
INFO:root:current mean train loss 5428.228247677163
INFO:root:current train perplexity8.496688842773438
INFO:root:current mean train loss 5418.575482951695
INFO:root:current train perplexity8.464625358581543
INFO:root:current mean train loss 5409.017093895876
INFO:root:current train perplexity8.430635452270508
INFO:root:current mean train loss 5398.07756433684
INFO:root:current train perplexity8.393914222717285
INFO:root:current mean train loss 5387.289991980126
INFO:root:current train perplexity8.358628273010254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.66s/it]
INFO:root:final mean train loss: 5375.993930570541
INFO:root:final train perplexity: 8.339349746704102
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 6236.344830358814
INFO:root:eval perplexity: 13.018500328063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/4
  2%|â–         | 4/200 [09:56<7:57:22, 146.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5319.846553679436
INFO:root:current train perplexity7.966878890991211
INFO:root:current mean train loss 5240.371168296756
INFO:root:current train perplexity7.883976936340332
INFO:root:current mean train loss 5242.056676559118
INFO:root:current train perplexity7.903822898864746
INFO:root:current mean train loss 5231.113548255759
INFO:root:current train perplexity7.8567795753479
INFO:root:current mean train loss 5225.034022213965
INFO:root:current train perplexity7.826132297515869
INFO:root:current mean train loss 5215.266526159369
INFO:root:current train perplexity7.79844856262207
INFO:root:current mean train loss 5207.893230456369
INFO:root:current train perplexity7.774800777435303
INFO:root:current mean train loss 5199.788339095631
INFO:root:current train perplexity7.758246421813965
INFO:root:current mean train loss 5186.712338884815
INFO:root:current train perplexity7.734213829040527
INFO:root:current mean train loss 5178.163153594086
INFO:root:current train perplexity7.703140735626221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.30s/it]
INFO:root:final mean train loss: 5168.586476848972
INFO:root:final train perplexity: 7.684128284454346
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 6130.646370345247
INFO:root:eval perplexity: 12.464381217956543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/5
  2%|â–Ž         | 5/200 [12:12<7:43:38, 142.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5078.21008613782
INFO:root:current train perplexity7.33279275894165
INFO:root:current mean train loss 5069.163925500225
INFO:root:current train perplexity7.390856742858887
INFO:root:current mean train loss 5077.982820263467
INFO:root:current train perplexity7.40452766418457
INFO:root:current mean train loss 5060.943386741796
INFO:root:current train perplexity7.342576503753662
INFO:root:current mean train loss 5058.175442011318
INFO:root:current train perplexity7.331141471862793
INFO:root:current mean train loss 5046.3053243491995
INFO:root:current train perplexity7.308568477630615
INFO:root:current mean train loss 5038.270888350939
INFO:root:current train perplexity7.287785530090332
INFO:root:current mean train loss 5038.416784717524
INFO:root:current train perplexity7.283473491668701
INFO:root:current mean train loss 5034.381213800842
INFO:root:current train perplexity7.2666754722595215
INFO:root:current mean train loss 5026.356783313366
INFO:root:current train perplexity7.251136779785156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.49s/it]
INFO:root:final mean train loss: 5017.694234786495
INFO:root:final train perplexity: 7.240030765533447
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it]
INFO:root:eval mean loss: 6052.401921255146
INFO:root:eval perplexity: 12.06943130493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/6
  3%|â–Ž         | 6/200 [14:44<7:51:31, 145.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4892.14562209109
INFO:root:current train perplexity6.934016227722168
INFO:root:current mean train loss 4941.345091943027
INFO:root:current train perplexity6.998005390167236
INFO:root:current mean train loss 4923.793739720395
INFO:root:current train perplexity6.982702732086182
INFO:root:current mean train loss 4923.993916888058
INFO:root:current train perplexity6.974914073944092
INFO:root:current mean train loss 4921.197403261325
INFO:root:current train perplexity6.964539051055908
INFO:root:current mean train loss 4912.753623278964
INFO:root:current train perplexity6.944015979766846
INFO:root:current mean train loss 4911.908366891664
INFO:root:current train perplexity6.9396748542785645
INFO:root:current mean train loss 4908.662419861738
INFO:root:current train perplexity6.927169322967529
INFO:root:current mean train loss 4905.173087344119
INFO:root:current train perplexity6.9187517166137695
INFO:root:current mean train loss 4902.750289771977
INFO:root:current train perplexity6.9073262214660645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.12s/it]
INFO:root:final mean train loss: 4897.89404789094
INFO:root:final train perplexity: 6.905794143676758
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 5991.549167290419
INFO:root:eval perplexity: 11.7709379196167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/7
  4%|â–Ž         | 7/200 [17:02<7:40:52, 143.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4790.742316228693
INFO:root:current train perplexity6.707987308502197
INFO:root:current mean train loss 4843.137696887601
INFO:root:current train perplexity6.7701826095581055
INFO:root:current mean train loss 4834.317086971508
INFO:root:current train perplexity6.721529483795166
INFO:root:current mean train loss 4833.464236493178
INFO:root:current train perplexity6.714003562927246
INFO:root:current mean train loss 4827.379414384443
INFO:root:current train perplexity6.696320056915283
INFO:root:current mean train loss 4821.331825819961
INFO:root:current train perplexity6.678447246551514
INFO:root:current mean train loss 4819.718337383707
INFO:root:current train perplexity6.675875186920166
INFO:root:current mean train loss 4821.5285049539525
INFO:root:current train perplexity6.671262741088867
INFO:root:current mean train loss 4812.718371653417
INFO:root:current train perplexity6.655200004577637
INFO:root:current mean train loss 4805.702824617556
INFO:root:current train perplexity6.647739410400391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.71s/it]
INFO:root:final mean train loss: 4801.096777946718
INFO:root:final train perplexity: 6.647039890289307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it]
INFO:root:eval mean loss: 5929.00130257064
INFO:root:eval perplexity: 11.471826553344727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/8
  4%|â–         | 8/200 [19:19<7:31:39, 141.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4748.027940538194
INFO:root:current train perplexity6.451895236968994
INFO:root:current mean train loss 4735.2348093606215
INFO:root:current train perplexity6.469581604003906
INFO:root:current mean train loss 4728.0304256772815
INFO:root:current train perplexity6.465195655822754
INFO:root:current mean train loss 4737.71005711411
INFO:root:current train perplexity6.462625026702881
INFO:root:current mean train loss 4741.734529499358
INFO:root:current train perplexity6.471413612365723
INFO:root:current mean train loss 4733.583317866757
INFO:root:current train perplexity6.45792818069458
INFO:root:current mean train loss 4730.684382143783
INFO:root:current train perplexity6.454950332641602
INFO:root:current mean train loss 4728.623469561456
INFO:root:current train perplexity6.447296619415283
INFO:root:current mean train loss 4723.50484518712
INFO:root:current train perplexity6.438265323638916
INFO:root:current mean train loss 4720.152637073679
INFO:root:current train perplexity6.429442882537842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.77s/it]
INFO:root:final mean train loss: 4718.003709854618
INFO:root:final train perplexity: 6.43266487121582
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it]
INFO:root:eval mean loss: 5890.806279530782
INFO:root:eval perplexity: 11.292922973632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/9
  4%|â–         | 9/200 [21:52<7:40:59, 144.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4641.000130666814
INFO:root:current train perplexity6.211522102355957
INFO:root:current mean train loss 4652.921603732639
INFO:root:current train perplexity6.263927459716797
INFO:root:current mean train loss 4674.72866697417
INFO:root:current train perplexity6.298730850219727
INFO:root:current mean train loss 4668.693025080021
INFO:root:current train perplexity6.286176681518555
INFO:root:current mean train loss 4662.240357741176
INFO:root:current train perplexity6.282495498657227
INFO:root:current mean train loss 4662.379747701401
INFO:root:current train perplexity6.277350902557373
INFO:root:current mean train loss 4663.971796482047
INFO:root:current train perplexity6.282741069793701
INFO:root:current mean train loss 4654.306851200247
INFO:root:current train perplexity6.269068717956543
INFO:root:current mean train loss 4656.9463980988985
INFO:root:current train perplexity6.266900062561035
INFO:root:current mean train loss 4653.083735708597
INFO:root:current train perplexity6.260840892791748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.13s/it]
INFO:root:final mean train loss: 4648.85164900749
INFO:root:final train perplexity: 6.2595391273498535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it]
INFO:root:eval mean loss: 5856.257745251684
INFO:root:eval perplexity: 11.133505821228027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/10
  5%|â–Œ         | 10/200 [24:09<7:31:28, 142.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4638.03741223299
INFO:root:current train perplexity6.144834041595459
INFO:root:current mean train loss 4599.016778871333
INFO:root:current train perplexity6.108523845672607
INFO:root:current mean train loss 4608.359862406194
INFO:root:current train perplexity6.1206865310668945
INFO:root:current mean train loss 4601.7706115239525
INFO:root:current train perplexity6.121408939361572
INFO:root:current mean train loss 4606.8099265845185
INFO:root:current train perplexity6.123260498046875
INFO:root:current mean train loss 4599.676602641947
INFO:root:current train perplexity6.121331214904785
INFO:root:current mean train loss 4598.808129918769
INFO:root:current train perplexity6.11776065826416
INFO:root:current mean train loss 4596.89929590972
INFO:root:current train perplexity6.114567756652832
INFO:root:current mean train loss 4591.378112723532
INFO:root:current train perplexity6.110435485839844
INFO:root:current mean train loss 4590.7367169046065
INFO:root:current train perplexity6.110713481903076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.38s/it]
INFO:root:final mean train loss: 4587.938149482973
INFO:root:final train perplexity: 6.110901832580566
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.63s/it]
INFO:root:eval mean loss: 5816.8966568815495
INFO:root:eval perplexity: 10.954618453979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/11
  6%|â–Œ         | 11/200 [26:27<7:24:33, 141.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4534.854812095905
INFO:root:current train perplexity5.96635103225708
INFO:root:current mean train loss 4556.380240537266
INFO:root:current train perplexity6.000097274780273
INFO:root:current mean train loss 4546.093237900152
INFO:root:current train perplexity5.980079650878906
INFO:root:current mean train loss 4546.220727097464
INFO:root:current train perplexity5.9929118156433105
INFO:root:current mean train loss 4542.908309905191
INFO:root:current train perplexity5.990177631378174
INFO:root:current mean train loss 4539.540115174484
INFO:root:current train perplexity5.984155178070068
INFO:root:current mean train loss 4538.588631575805
INFO:root:current train perplexity5.984541416168213
INFO:root:current mean train loss 4535.399633695997
INFO:root:current train perplexity5.977545261383057
INFO:root:current mean train loss 4536.502518474316
INFO:root:current train perplexity5.979371070861816
INFO:root:current mean train loss 4536.338159748607
INFO:root:current train perplexity5.979733943939209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.49s/it]
INFO:root:final mean train loss: 4532.951831571518
INFO:root:final train perplexity: 5.979761123657227
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5795.6509022969685
INFO:root:eval perplexity: 10.859259605407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/12
  6%|â–Œ         | 12/200 [28:44<7:17:48, 139.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4500.86877055921
INFO:root:current train perplexity5.890324592590332
INFO:root:current mean train loss 4484.425170272436
INFO:root:current train perplexity5.881619453430176
INFO:root:current mean train loss 4489.088672702595
INFO:root:current train perplexity5.8916192054748535
INFO:root:current mean train loss 4482.67519778481
INFO:root:current train perplexity5.87691593170166
INFO:root:current mean train loss 4488.6335518268625
INFO:root:current train perplexity5.878095626831055
INFO:root:current mean train loss 4483.022458885898
INFO:root:current train perplexity5.873936176300049
INFO:root:current mean train loss 4480.525864854991
INFO:root:current train perplexity5.869964599609375
INFO:root:current mean train loss 4484.587807402221
INFO:root:current train perplexity5.864582538604736
INFO:root:current mean train loss 4486.337372610423
INFO:root:current train perplexity5.867159843444824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.21s/it]
INFO:root:final mean train loss: 4485.574676759781
INFO:root:final train perplexity: 5.869027614593506
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5772.219008759824
INFO:root:eval perplexity: 10.755050659179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/13
  6%|â–‹         | 13/200 [30:59<7:11:16, 138.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4713.08642578125
INFO:root:current train perplexity6.054008960723877
INFO:root:current mean train loss 4460.232898304764
INFO:root:current train perplexity5.766119003295898
INFO:root:current mean train loss 4457.920801021783
INFO:root:current train perplexity5.765312194824219
INFO:root:current mean train loss 4456.309965127372
INFO:root:current train perplexity5.771731376647949
INFO:root:current mean train loss 4457.832083349488
INFO:root:current train perplexity5.775806903839111
INFO:root:current mean train loss 4454.202330450888
INFO:root:current train perplexity5.778494358062744
INFO:root:current mean train loss 4450.31136594048
INFO:root:current train perplexity5.7793779373168945
INFO:root:current mean train loss 4446.312857355197
INFO:root:current train perplexity5.771573066711426
INFO:root:current mean train loss 4444.879877643894
INFO:root:current train perplexity5.769033432006836
INFO:root:current mean train loss 4445.313256214095
INFO:root:current train perplexity5.768810749053955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.15s/it]
INFO:root:final mean train loss: 4441.588026969664
INFO:root:final train perplexity: 5.7680559158325195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it]
INFO:root:eval mean loss: 5759.626356661676
INFO:root:eval perplexity: 10.69946002960205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/14
  7%|â–‹         | 14/200 [33:15<7:06:34, 137.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4369.22099165483
INFO:root:current train perplexity5.547903060913086
INFO:root:current mean train loss 4393.949128571931
INFO:root:current train perplexity5.681147575378418
INFO:root:current mean train loss 4385.578226821683
INFO:root:current train perplexity5.678294658660889
INFO:root:current mean train loss 4389.965335171322
INFO:root:current train perplexity5.675992965698242
INFO:root:current mean train loss 4387.801498821472
INFO:root:current train perplexity5.671596527099609
INFO:root:current mean train loss 4391.2798912212575
INFO:root:current train perplexity5.676007270812988
INFO:root:current mean train loss 4398.629398527005
INFO:root:current train perplexity5.680875778198242
INFO:root:current mean train loss 4399.8341378642535
INFO:root:current train perplexity5.677678108215332
INFO:root:current mean train loss 4401.703272507899
INFO:root:current train perplexity5.6807475090026855
INFO:root:current mean train loss 4403.593953673848
INFO:root:current train perplexity5.676225185394287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.74s/it]
INFO:root:final mean train loss: 4400.0025624921245
INFO:root:final train perplexity: 5.674193859100342
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5743.886208539951
INFO:root:eval perplexity: 10.630379676818848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/15
  8%|â–Š         | 15/200 [35:31<7:02:39, 137.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4422.484837582237
INFO:root:current train perplexity5.66622257232666
INFO:root:current mean train loss 4363.908096441702
INFO:root:current train perplexity5.574258804321289
INFO:root:current mean train loss 4360.61487763984
INFO:root:current train perplexity5.586221694946289
INFO:root:current mean train loss 4357.9247457570045
INFO:root:current train perplexity5.584338665008545
INFO:root:current mean train loss 4363.922244998322
INFO:root:current train perplexity5.59230899810791
INFO:root:current mean train loss 4361.832637603113
INFO:root:current train perplexity5.588498592376709
INFO:root:current mean train loss 4360.567086215166
INFO:root:current train perplexity5.5878424644470215
INFO:root:current mean train loss 4363.658398369589
INFO:root:current train perplexity5.591265678405762
INFO:root:current mean train loss 4363.265164143582
INFO:root:current train perplexity5.591790676116943
INFO:root:current mean train loss 4363.441670846369
INFO:root:current train perplexity5.589513778686523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it]
INFO:root:final mean train loss: 4363.903111488588
INFO:root:final train perplexity: 5.593952655792236
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.55s/it]
INFO:root:eval mean loss: 5723.260677863024
INFO:root:eval perplexity: 10.540531158447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/16
  8%|â–Š         | 16/200 [37:54<7:05:42, 138.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.538131148727
INFO:root:current train perplexity5.590938091278076
INFO:root:current mean train loss 4311.46340581939
INFO:root:current train perplexity5.52657413482666
INFO:root:current mean train loss 4324.6208033624725
INFO:root:current train perplexity5.5240607261657715
INFO:root:current mean train loss 4322.697509765625
INFO:root:current train perplexity5.516388893127441
INFO:root:current mean train loss 4328.690915109961
INFO:root:current train perplexity5.518434047698975
INFO:root:current mean train loss 4328.368669021288
INFO:root:current train perplexity5.5126800537109375
INFO:root:current mean train loss 4329.03662498754
INFO:root:current train perplexity5.5114593505859375
INFO:root:current mean train loss 4327.904800939757
INFO:root:current train perplexity5.516266822814941
INFO:root:current mean train loss 4327.7821191052
INFO:root:current train perplexity5.512427806854248
INFO:root:current mean train loss 4329.707389954996
INFO:root:current train perplexity5.516927242279053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.64s/it]
INFO:root:final mean train loss: 4330.458197932089
INFO:root:final train perplexity: 5.520625591278076
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it]
INFO:root:eval mean loss: 5710.815242561752
INFO:root:eval perplexity: 10.486688613891602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/17
  8%|â–Š         | 17/200 [40:10<7:01:36, 138.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4259.837625558036
INFO:root:current train perplexity5.416833400726318
INFO:root:current mean train loss 4296.329994936343
INFO:root:current train perplexity5.440975666046143
INFO:root:current mean train loss 4292.439950756317
INFO:root:current train perplexity5.447251319885254
INFO:root:current mean train loss 4294.757770230877
INFO:root:current train perplexity5.444759845733643
INFO:root:current mean train loss 4295.119920752514
INFO:root:current train perplexity5.449615478515625
INFO:root:current mean train loss 4305.7242817245915
INFO:root:current train perplexity5.45147180557251
INFO:root:current mean train loss 4301.04684808686
INFO:root:current train perplexity5.444782257080078
INFO:root:current mean train loss 4299.678816565689
INFO:root:current train perplexity5.4413065910339355
INFO:root:current mean train loss 4300.661341867047
INFO:root:current train perplexity5.448794364929199
INFO:root:current mean train loss 4300.25430914731
INFO:root:current train perplexity5.45242977142334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.39s/it]
INFO:root:final mean train loss: 4299.115743821667
INFO:root:final train perplexity: 5.4527788162231445
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it]
INFO:root:eval mean loss: 5705.761669044723
INFO:root:eval perplexity: 10.4649019241333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/18
  9%|â–‰         | 18/200 [42:27<6:57:52, 137.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4261.652366460756
INFO:root:current train perplexity5.390641212463379
INFO:root:current mean train loss 4281.9396648273605
INFO:root:current train perplexity5.405691146850586
INFO:root:current mean train loss 4275.548777890303
INFO:root:current train perplexity5.396765232086182
INFO:root:current mean train loss 4281.95935663607
INFO:root:current train perplexity5.41065788269043
INFO:root:current mean train loss 4282.764225186936
INFO:root:current train perplexity5.406726837158203
INFO:root:current mean train loss 4283.067347292961
INFO:root:current train perplexity5.404374122619629
INFO:root:current mean train loss 4278.897193256099
INFO:root:current train perplexity5.398139953613281
INFO:root:current mean train loss 4275.371308646324
INFO:root:current train perplexity5.393246650695801
INFO:root:current mean train loss 4271.755780890884
INFO:root:current train perplexity5.390629291534424
INFO:root:current mean train loss 4270.752067816725
INFO:root:current train perplexity5.38770866394043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.90s/it]
INFO:root:final mean train loss: 4269.863369172619
INFO:root:final train perplexity: 5.390211582183838
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it]
INFO:root:eval mean loss: 5687.963009040513
INFO:root:eval perplexity: 10.388532638549805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/19
 10%|â–‰         | 19/200 [44:53<7:02:56, 140.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4216.5339451210175
INFO:root:current train perplexity5.258106231689453
INFO:root:current mean train loss 4212.273233780008
INFO:root:current train perplexity5.26450252532959
INFO:root:current mean train loss 4241.957872611118
INFO:root:current train perplexity5.293618679046631
INFO:root:current mean train loss 4234.045791321671
INFO:root:current train perplexity5.304823875427246
INFO:root:current mean train loss 4239.735530743314
INFO:root:current train perplexity5.308586597442627
INFO:root:current mean train loss 4237.854986228874
INFO:root:current train perplexity5.313305854797363
INFO:root:current mean train loss 4245.337557603687
INFO:root:current train perplexity5.325989723205566
INFO:root:current mean train loss 4246.457163235477
INFO:root:current train perplexity5.327057361602783
INFO:root:current mean train loss 4246.236339313583
INFO:root:current train perplexity5.329859733581543
INFO:root:current mean train loss 4248.474879957775
INFO:root:current train perplexity5.3328633308410645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.02s/it]
INFO:root:final mean train loss: 4242.031831556751
INFO:root:final train perplexity: 5.331348896026611
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 5677.056722492515
INFO:root:eval perplexity: 10.342010498046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/20
 10%|â–ˆ         | 20/200 [47:08<6:56:11, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4246.125753111758
INFO:root:current train perplexity5.277166366577148
INFO:root:current mean train loss 4237.515253414897
INFO:root:current train perplexity5.273040771484375
INFO:root:current mean train loss 4230.0439745339645
INFO:root:current train perplexity5.274517059326172
INFO:root:current mean train loss 4228.199803599408
INFO:root:current train perplexity5.284138202667236
INFO:root:current mean train loss 4223.819405615979
INFO:root:current train perplexity5.278558731079102
INFO:root:current mean train loss 4220.381826329103
INFO:root:current train perplexity5.27495813369751
INFO:root:current mean train loss 4222.821992217137
INFO:root:current train perplexity5.277001857757568
INFO:root:current mean train loss 4226.568951552722
INFO:root:current train perplexity5.28640604019165
INFO:root:current mean train loss 4224.586957547384
INFO:root:current train perplexity5.2853007316589355
INFO:root:current mean train loss 4221.746628873664
INFO:root:current train perplexity5.281158924102783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.47s/it]
INFO:root:final mean train loss: 4217.179983200565
INFO:root:final train perplexity: 5.279332160949707
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 5683.6235103036115
INFO:root:eval perplexity: 10.3699951171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/21
 10%|â–ˆ         | 21/200 [49:28<6:54:46, 139.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4165.762720819729
INFO:root:current train perplexity5.208869934082031
INFO:root:current mean train loss 4180.433780875748
INFO:root:current train perplexity5.23123836517334
INFO:root:current mean train loss 4186.715363120318
INFO:root:current train perplexity5.222982883453369
INFO:root:current mean train loss 4184.377462028483
INFO:root:current train perplexity5.2141547203063965
INFO:root:current mean train loss 4189.660010392967
INFO:root:current train perplexity5.220892906188965
INFO:root:current mean train loss 4189.275802693039
INFO:root:current train perplexity5.215988636016846
INFO:root:current mean train loss 4191.247057501522
INFO:root:current train perplexity5.217449188232422
INFO:root:current mean train loss 4191.968722625693
INFO:root:current train perplexity5.217121601104736
INFO:root:current mean train loss 4193.484881303165
INFO:root:current train perplexity5.218124866485596
INFO:root:current mean train loss 4192.69619413295
INFO:root:current train perplexity5.221883773803711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.30s/it]
INFO:root:final mean train loss: 4191.023770609209
INFO:root:final train perplexity: 5.225132465362549
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it]
INFO:root:eval mean loss: 5662.033841984001
INFO:root:eval perplexity: 10.278271675109863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/22
 11%|â–ˆ         | 22/200 [51:48<6:53:01, 139.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.806178385416
INFO:root:current train perplexity5.172586917877197
INFO:root:current mean train loss 4170.7557421875
INFO:root:current train perplexity5.178445339202881
INFO:root:current mean train loss 4162.771759588069
INFO:root:current train perplexity5.157844543457031
INFO:root:current mean train loss 4163.240529296875
INFO:root:current train perplexity5.165472030639648
INFO:root:current mean train loss 4165.264274259868
INFO:root:current train perplexity5.17080545425415
INFO:root:current mean train loss 4170.132517408288
INFO:root:current train perplexity5.175865173339844
INFO:root:current mean train loss 4168.205862991898
INFO:root:current train perplexity5.178271293640137
INFO:root:current mean train loss 4172.324436743952
INFO:root:current train perplexity5.180505752563477
INFO:root:current mean train loss 4172.556729073661
INFO:root:current train perplexity5.180360317230225
INFO:root:current mean train loss 4174.577840795272
INFO:root:current train perplexity5.181880950927734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.79s/it]
INFO:root:final mean train loss: 4169.478297202818
INFO:root:final train perplexity: 5.180905818939209
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it]
INFO:root:eval mean loss: 5658.996681441804
INFO:root:eval perplexity: 10.265434265136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/23
 12%|â–ˆâ–        | 23/200 [54:05<6:49:03, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4152.52637601186
INFO:root:current train perplexity5.0951433181762695
INFO:root:current mean train loss 4148.731051752476
INFO:root:current train perplexity5.114828586578369
INFO:root:current mean train loss 4148.751825447217
INFO:root:current train perplexity5.1168904304504395
INFO:root:current mean train loss 4153.894523600686
INFO:root:current train perplexity5.12528133392334
INFO:root:current mean train loss 4156.439552702025
INFO:root:current train perplexity5.132209777832031
INFO:root:current mean train loss 4149.546213349593
INFO:root:current train perplexity5.125211238861084
INFO:root:current mean train loss 4144.1972152240805
INFO:root:current train perplexity5.118799209594727
INFO:root:current mean train loss 4149.717379632124
INFO:root:current train perplexity5.1302971839904785
INFO:root:current mean train loss 4148.974272057262
INFO:root:current train perplexity5.13326358795166
INFO:root:current mean train loss 4149.684989300531
INFO:root:current train perplexity5.134320259094238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.61s/it]
INFO:root:final mean train loss: 4146.490253940706
INFO:root:final train perplexity: 5.134130001068115
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it]
INFO:root:eval mean loss: 5654.807193230726
INFO:root:eval perplexity: 10.247751235961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/24
 12%|â–ˆâ–        | 24/200 [56:20<6:43:53, 137.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.505175244677
INFO:root:current train perplexity5.054027557373047
INFO:root:current mean train loss 4111.372475509244
INFO:root:current train perplexity5.07644510269165
INFO:root:current mean train loss 4108.9720941392825
INFO:root:current train perplexity5.06596040725708
INFO:root:current mean train loss 4120.055686540921
INFO:root:current train perplexity5.086064338684082
INFO:root:current mean train loss 4120.698760302635
INFO:root:current train perplexity5.089900970458984
INFO:root:current mean train loss 4126.383753536114
INFO:root:current train perplexity5.093298435211182
INFO:root:current mean train loss 4128.61822341941
INFO:root:current train perplexity5.0959792137146
INFO:root:current mean train loss 4132.482898736272
INFO:root:current train perplexity5.096663951873779
INFO:root:current mean train loss 4131.011938503963
INFO:root:current train perplexity5.098725318908691
INFO:root:current mean train loss 4129.965717581278
INFO:root:current train perplexity5.094180107116699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.83s/it]
INFO:root:final mean train loss: 4126.631965698734
INFO:root:final train perplexity: 5.094062328338623
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 5652.367232819517
INFO:root:eval perplexity: 10.237462997436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/25
 12%|â–ˆâ–Ž        | 25/200 [58:39<6:42:39, 138.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4081.7833905460857
INFO:root:current train perplexity5.065309047698975
INFO:root:current mean train loss 4092.2404772887876
INFO:root:current train perplexity5.036861419677734
INFO:root:current mean train loss 4105.7951096754805
INFO:root:current train perplexity5.047501564025879
INFO:root:current mean train loss 4112.001646572486
INFO:root:current train perplexity5.057100772857666
INFO:root:current mean train loss 4110.931453727768
INFO:root:current train perplexity5.0529704093933105
INFO:root:current mean train loss 4108.853291455812
INFO:root:current train perplexity5.046741485595703
INFO:root:current mean train loss 4109.354243506348
INFO:root:current train perplexity5.048506736755371
INFO:root:current mean train loss 4112.32344263337
INFO:root:current train perplexity5.051152229309082
INFO:root:current mean train loss 4111.975980798978
INFO:root:current train perplexity5.055067539215088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.36s/it]
INFO:root:final mean train loss: 4106.248602713308
INFO:root:final train perplexity: 5.0532612800598145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5650.869064605165
INFO:root:eval perplexity: 10.231158256530762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/26
 13%|â–ˆâ–Ž        | 26/200 [1:01:08<6:49:36, 141.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.16619001116
INFO:root:current train perplexity5.1312031745910645
INFO:root:current mean train loss 4080.3289806330317
INFO:root:current train perplexity5.0210981369018555
INFO:root:current mean train loss 4089.5986599392363
INFO:root:current train perplexity5.0290141105651855
INFO:root:current mean train loss 4092.554751119707
INFO:root:current train perplexity5.027204513549805
INFO:root:current mean train loss 4099.487813963644
INFO:root:current train perplexity5.038173675537109
INFO:root:current mean train loss 4090.3806648329637
INFO:root:current train perplexity5.025738716125488
INFO:root:current mean train loss 4093.0828163612027
INFO:root:current train perplexity5.0192790031433105
INFO:root:current mean train loss 4093.82723580324
INFO:root:current train perplexity5.021880626678467
INFO:root:current mean train loss 4091.616270838174
INFO:root:current train perplexity5.018662452697754
INFO:root:current mean train loss 4089.036980440756
INFO:root:current train perplexity5.014718532562256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.92s/it]
INFO:root:final mean train loss: 4087.1855635489187
INFO:root:final train perplexity: 5.015398979187012
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 5639.143620473896
INFO:root:eval perplexity: 10.181910514831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/27
 14%|â–ˆâ–Ž        | 27/200 [1:03:24<6:42:50, 139.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4100.303238932292
INFO:root:current train perplexity4.949395179748535
INFO:root:current mean train loss 4051.372125509511
INFO:root:current train perplexity4.96220588684082
INFO:root:current mean train loss 4049.327007630814
INFO:root:current train perplexity4.959352493286133
INFO:root:current mean train loss 4062.929919239831
INFO:root:current train perplexity4.973840236663818
INFO:root:current mean train loss 4072.145111892884
INFO:root:current train perplexity4.9849982261657715
INFO:root:current mean train loss 4067.0001787204187
INFO:root:current train perplexity4.974981307983398
INFO:root:current mean train loss 4069.6608446074697
INFO:root:current train perplexity4.9757890701293945
INFO:root:current mean train loss 4070.7473335746286
INFO:root:current train perplexity4.974989414215088
INFO:root:current mean train loss 4073.6505913295628
INFO:root:current train perplexity4.977695465087891
INFO:root:current mean train loss 4070.818385790215
INFO:root:current train perplexity4.976868152618408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.59s/it]
INFO:root:final mean train loss: 4069.7388763427734
INFO:root:final train perplexity: 4.9809956550598145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it]
INFO:root:eval mean loss: 5636.710140753649
INFO:root:eval perplexity: 10.171714782714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/28
 14%|â–ˆâ–        | 28/200 [1:05:40<6:37:15, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4088.1806322180705
INFO:root:current train perplexity4.966097354888916
INFO:root:current mean train loss 4054.6515894944105
INFO:root:current train perplexity4.930151462554932
INFO:root:current mean train loss 4062.4182424502524
INFO:root:current train perplexity4.95298433303833
INFO:root:current mean train loss 4052.6521117030284
INFO:root:current train perplexity4.943388938903809
INFO:root:current mean train loss 4064.62672341349
INFO:root:current train perplexity4.9530229568481445
INFO:root:current mean train loss 4065.287997243965
INFO:root:current train perplexity4.952030658721924
INFO:root:current mean train loss 4058.065761609024
INFO:root:current train perplexity4.947579383850098
INFO:root:current mean train loss 4055.4072238610825
INFO:root:current train perplexity4.9470295906066895
INFO:root:current mean train loss 4058.10483244181
INFO:root:current train perplexity4.948093414306641
INFO:root:current mean train loss 4056.123179657875
INFO:root:current train perplexity4.947434902191162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.46s/it]
INFO:root:final mean train loss: 4051.832756411645
INFO:root:final train perplexity: 4.945932388305664
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it]
INFO:root:eval mean loss: 5638.724795038828
INFO:root:eval perplexity: 10.180150985717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/29
 14%|â–ˆâ–        | 29/200 [1:08:03<6:38:18, 139.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4060.435987903226
INFO:root:current train perplexity4.907369613647461
INFO:root:current mean train loss 4041.453624463263
INFO:root:current train perplexity4.902651309967041
INFO:root:current mean train loss 4056.365591602408
INFO:root:current train perplexity4.916008949279785
INFO:root:current mean train loss 4058.0881723824587
INFO:root:current train perplexity4.91526985168457
INFO:root:current mean train loss 4055.1152808240286
INFO:root:current train perplexity4.910880088806152
INFO:root:current mean train loss 4050.9226350083864
INFO:root:current train perplexity4.9120774269104
INFO:root:current mean train loss 4045.3683281126187
INFO:root:current train perplexity4.908133506774902
INFO:root:current mean train loss 4045.375869688355
INFO:root:current train perplexity4.911578178405762
INFO:root:current mean train loss 4042.2418126222174
INFO:root:current train perplexity4.908308982849121
INFO:root:current mean train loss 4037.125405677279
INFO:root:current train perplexity4.910337448120117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.35s/it]
INFO:root:final mean train loss: 4034.0814826103947
INFO:root:final train perplexity: 4.91141414642334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 5626.248926950786
INFO:root:eval perplexity: 10.128021240234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/30
 15%|â–ˆâ–Œ        | 30/200 [1:10:19<6:33:16, 138.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4018.900209084535
INFO:root:current train perplexity4.901440620422363
INFO:root:current mean train loss 4014.1140048898383
INFO:root:current train perplexity4.886892318725586
INFO:root:current mean train loss 4017.776187401935
INFO:root:current train perplexity4.8707427978515625
INFO:root:current mean train loss 4013.7870892099927
INFO:root:current train perplexity4.867381572723389
INFO:root:current mean train loss 4020.551800634432
INFO:root:current train perplexity4.871144771575928
INFO:root:current mean train loss 4018.7363697964984
INFO:root:current train perplexity4.873520851135254
INFO:root:current mean train loss 4017.979055867322
INFO:root:current train perplexity4.874810695648193
INFO:root:current mean train loss 4022.6909932922445
INFO:root:current train perplexity4.878833293914795
INFO:root:current mean train loss 4022.624802999758
INFO:root:current train perplexity4.88225793838501
INFO:root:current mean train loss 4021.727619142705
INFO:root:current train perplexity4.881932258605957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.68s/it]
INFO:root:final mean train loss: 4018.1734376722766
INFO:root:final train perplexity: 4.880685329437256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5628.770124789484
INFO:root:eval perplexity: 10.138535499572754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/31
 16%|â–ˆâ–Œ        | 31/200 [1:12:38<6:30:50, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3992.395029920213
INFO:root:current train perplexity4.82252836227417
INFO:root:current mean train loss 3991.221492014775
INFO:root:current train perplexity4.819232940673828
INFO:root:current mean train loss 3984.0960658764548
INFO:root:current train perplexity4.807349681854248
INFO:root:current mean train loss 3995.8905046886257
INFO:root:current train perplexity4.822585105895996
INFO:root:current mean train loss 4000.474579335326
INFO:root:current train perplexity4.83124303817749
INFO:root:current mean train loss 4001.769780746544
INFO:root:current train perplexity4.840139865875244
INFO:root:current mean train loss 4005.904410832448
INFO:root:current train perplexity4.846105098724365
INFO:root:current mean train loss 4001.3119322995103
INFO:root:current train perplexity4.846152305603027
INFO:root:current mean train loss 4003.7692827857513
INFO:root:current train perplexity4.84997034072876
INFO:root:current mean train loss 4003.720170759223
INFO:root:current train perplexity4.848926067352295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.40s/it]
INFO:root:final mean train loss: 4002.419915968372
INFO:root:final train perplexity: 4.850444793701172
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 5627.442833083833
INFO:root:eval perplexity: 10.132999420166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/32
 16%|â–ˆâ–Œ        | 32/200 [1:14:53<6:25:36, 137.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3978.750577059659
INFO:root:current train perplexity4.744394302368164
INFO:root:current mean train loss 4000.4003606980846
INFO:root:current train perplexity4.8063225746154785
INFO:root:current mean train loss 3980.722549977022
INFO:root:current train perplexity4.797127723693848
INFO:root:current mean train loss 3974.2180595290492
INFO:root:current train perplexity4.803542613983154
INFO:root:current mean train loss 3983.91765861092
INFO:root:current train perplexity4.815213680267334
INFO:root:current mean train loss 3984.7963264534064
INFO:root:current train perplexity4.81530237197876
INFO:root:current mean train loss 3988.9619166716366
INFO:root:current train perplexity4.817215442657471
INFO:root:current mean train loss 3990.7484206850168
INFO:root:current train perplexity4.817841053009033
INFO:root:current mean train loss 3991.279417374817
INFO:root:current train perplexity4.818163871765137
INFO:root:current mean train loss 3990.6429403734455
INFO:root:current train perplexity4.821837902069092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.59s/it]
INFO:root:final mean train loss: 3986.5339526514854
INFO:root:final train perplexity: 4.8201398849487305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 5628.480669033028
INFO:root:eval perplexity: 10.1373291015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/33
 16%|â–ˆâ–‹        | 33/200 [1:17:10<6:22:31, 137.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3919.4804958767363
INFO:root:current train perplexity4.73715877532959
INFO:root:current mean train loss 3950.315953915836
INFO:root:current train perplexity4.7815046310424805
INFO:root:current mean train loss 3949.4610535364186
INFO:root:current train perplexity4.780909061431885
INFO:root:current mean train loss 3959.186514694172
INFO:root:current train perplexity4.781973838806152
INFO:root:current mean train loss 3968.7257467644777
INFO:root:current train perplexity4.784646511077881
INFO:root:current mean train loss 3965.3905269968363
INFO:root:current train perplexity4.778660297393799
INFO:root:current mean train loss 3968.640334461609
INFO:root:current train perplexity4.7860541343688965
INFO:root:current mean train loss 3966.688109231651
INFO:root:current train perplexity4.7820048332214355
INFO:root:current mean train loss 3968.4333849715745
INFO:root:current train perplexity4.78310489654541
INFO:root:current mean train loss 3975.7404174170883
INFO:root:current train perplexity4.793758392333984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 123.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 123.00s/it]
INFO:root:final mean train loss: 3972.5444729712704
INFO:root:final train perplexity: 4.793609619140625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it]
INFO:root:eval mean loss: 5621.688871280876
INFO:root:eval perplexity: 10.10903263092041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/34
 17%|â–ˆâ–‹        | 34/200 [1:19:26<6:19:20, 137.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.3861582581426
INFO:root:current train perplexity4.768953800201416
INFO:root:current mean train loss 3955.17419076663
INFO:root:current train perplexity4.748810291290283
INFO:root:current mean train loss 3950.7592205878113
INFO:root:current train perplexity4.7509589195251465
INFO:root:current mean train loss 3952.4685190205946
INFO:root:current train perplexity4.7453837394714355
INFO:root:current mean train loss 3952.370973493896
INFO:root:current train perplexity4.746119976043701
INFO:root:current mean train loss 3956.717442500821
INFO:root:current train perplexity4.756341457366943
INFO:root:current mean train loss 3959.534941944742
INFO:root:current train perplexity4.761070251464844
INFO:root:current mean train loss 3958.11394305792
INFO:root:current train perplexity4.75999641418457
INFO:root:current mean train loss 3961.8507510337436
INFO:root:current train perplexity4.764179229736328
INFO:root:current mean train loss 3960.69735186623
INFO:root:current train perplexity4.765904903411865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.47s/it]
INFO:root:final mean train loss: 3957.9546256526824
INFO:root:final train perplexity: 4.766096591949463
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5621.741572031718
INFO:root:eval perplexity: 10.10925006866455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/35
 18%|â–ˆâ–Š        | 35/200 [1:21:58<6:29:16, 141.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3968.4031070757514
INFO:root:current train perplexity4.757049083709717
INFO:root:current mean train loss 3948.4317879277237
INFO:root:current train perplexity4.726792335510254
INFO:root:current mean train loss 3952.269468245968
INFO:root:current train perplexity4.739120006561279
INFO:root:current mean train loss 3949.9075041999918
INFO:root:current train perplexity4.735596179962158
INFO:root:current mean train loss 3947.947248805291
INFO:root:current train perplexity4.737940311431885
INFO:root:current mean train loss 3951.136884040371
INFO:root:current train perplexity4.736979961395264
INFO:root:current mean train loss 3951.317302990381
INFO:root:current train perplexity4.739962577819824
INFO:root:current mean train loss 3948.911170420812
INFO:root:current train perplexity4.739546298980713
INFO:root:current mean train loss 3946.779732106353
INFO:root:current train perplexity4.7375569343566895
INFO:root:current mean train loss 3946.5901569682073
INFO:root:current train perplexity4.739539623260498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.89s/it]
INFO:root:final mean train loss: 3943.5598940080213
INFO:root:final train perplexity: 4.739105701446533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it]
INFO:root:eval mean loss: 5628.427003415045
INFO:root:eval perplexity: 10.137102127075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/36
 18%|â–ˆâ–Š        | 36/200 [1:24:24<6:30:00, 142.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.023819145115
INFO:root:current train perplexity4.689182281494141
INFO:root:current mean train loss 3908.33674956133
INFO:root:current train perplexity4.685017108917236
INFO:root:current mean train loss 3918.9748934968425
INFO:root:current train perplexity4.692262172698975
INFO:root:current mean train loss 3923.835868736878
INFO:root:current train perplexity4.700536251068115
INFO:root:current mean train loss 3919.935207484439
INFO:root:current train perplexity4.7032999992370605
INFO:root:current mean train loss 3921.8296846717953
INFO:root:current train perplexity4.707240581512451
INFO:root:current mean train loss 3927.0611048091796
INFO:root:current train perplexity4.710081100463867
INFO:root:current mean train loss 3930.129230116344
INFO:root:current train perplexity4.712657451629639
INFO:root:current mean train loss 3931.391217598383
INFO:root:current train perplexity4.710981369018555
INFO:root:current mean train loss 3933.711477726064
INFO:root:current train perplexity4.715686321258545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.87s/it]
INFO:root:final mean train loss: 3930.869332467356
INFO:root:final train perplexity: 4.715437412261963
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it]
INFO:root:eval mean loss: 5620.316666471744
INFO:root:eval perplexity: 10.103324890136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/37
 18%|â–ˆâ–Š        | 37/200 [1:26:37<6:20:14, 139.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.679566714638
INFO:root:current train perplexity4.64780330657959
INFO:root:current mean train loss 3895.618444511218
INFO:root:current train perplexity4.655529022216797
INFO:root:current mean train loss 3903.9515202926377
INFO:root:current train perplexity4.670168399810791
INFO:root:current mean train loss 3896.445839102057
INFO:root:current train perplexity4.6700029373168945
INFO:root:current mean train loss 3902.5376819957387
INFO:root:current train perplexity4.674389839172363
INFO:root:current mean train loss 3907.2716833803834
INFO:root:current train perplexity4.6785888671875
INFO:root:current mean train loss 3908.3481961696266
INFO:root:current train perplexity4.679311275482178
INFO:root:current mean train loss 3914.616706896128
INFO:root:current train perplexity4.685540676116943
INFO:root:current mean train loss 3920.093035854574
INFO:root:current train perplexity4.689505577087402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.20s/it]
INFO:root:final mean train loss: 3916.9089654491795
INFO:root:final train perplexity: 4.689537525177002
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5626.454929009169
INFO:root:eval perplexity: 10.128878593444824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/38
 19%|â–ˆâ–‰        | 38/200 [1:28:58<6:18:50, 140.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.3282877604165
INFO:root:current train perplexity4.496346950531006
INFO:root:current mean train loss 3908.043606359982
INFO:root:current train perplexity4.6525373458862305
INFO:root:current mean train loss 3900.584003617611
INFO:root:current train perplexity4.64923620223999
INFO:root:current mean train loss 3903.0787276969886
INFO:root:current train perplexity4.649292469024658
INFO:root:current mean train loss 3898.9361278448746
INFO:root:current train perplexity4.646506309509277
INFO:root:current mean train loss 3900.8741816678057
INFO:root:current train perplexity4.645576477050781
INFO:root:current mean train loss 3905.4308187253837
INFO:root:current train perplexity4.653227806091309
INFO:root:current mean train loss 3903.806378772893
INFO:root:current train perplexity4.658476829528809
INFO:root:current mean train loss 3906.2753918411427
INFO:root:current train perplexity4.660438537597656
INFO:root:current mean train loss 3908.4182753452037
INFO:root:current train perplexity4.663754940032959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.76s/it]
INFO:root:final mean train loss: 3905.377994598881
INFO:root:final train perplexity: 4.6682515144348145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it]
INFO:root:eval mean loss: 5625.447008327096
INFO:root:eval perplexity: 10.124679565429688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/39
 20%|â–ˆâ–‰        | 39/200 [1:31:14<6:13:04, 139.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.192205255682
INFO:root:current train perplexity4.570061683654785
INFO:root:current mean train loss 3871.6792366096565
INFO:root:current train perplexity4.60487699508667
INFO:root:current mean train loss 3882.839662090862
INFO:root:current train perplexity4.614624977111816
INFO:root:current mean train loss 3884.1477388339026
INFO:root:current train perplexity4.631032466888428
INFO:root:current mean train loss 3886.5151729537333
INFO:root:current train perplexity4.63724946975708
INFO:root:current mean train loss 3891.3240758966795
INFO:root:current train perplexity4.63987398147583
INFO:root:current mean train loss 3890.282517853033
INFO:root:current train perplexity4.636912822723389
INFO:root:current mean train loss 3893.215973115001
INFO:root:current train perplexity4.643152236938477
INFO:root:current mean train loss 3893.7495255664303
INFO:root:current train perplexity4.642111778259277
INFO:root:current mean train loss 3895.4404058362206
INFO:root:current train perplexity4.644803524017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.31s/it]
INFO:root:final mean train loss: 3893.031567296674
INFO:root:final train perplexity: 4.645567893981934
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it]
INFO:root:eval mean loss: 5622.209548676085
INFO:root:eval perplexity: 10.111199378967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/40
 20%|â–ˆâ–ˆ        | 40/200 [1:33:37<6:13:45, 140.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.2030350534537
INFO:root:current train perplexity4.631372451782227
INFO:root:current mean train loss 3877.8799730829833
INFO:root:current train perplexity4.621150970458984
INFO:root:current mean train loss 3874.256939613656
INFO:root:current train perplexity4.615344047546387
INFO:root:current mean train loss 3883.6017507714537
INFO:root:current train perplexity4.6179704666137695
INFO:root:current mean train loss 3883.3893157303473
INFO:root:current train perplexity4.619022369384766
INFO:root:current mean train loss 3886.919217207069
INFO:root:current train perplexity4.622570514678955
INFO:root:current mean train loss 3885.5402634825577
INFO:root:current train perplexity4.62106466293335
INFO:root:current mean train loss 3890.265733657858
INFO:root:current train perplexity4.628381729125977
INFO:root:current mean train loss 3887.029988457723
INFO:root:current train perplexity4.624995231628418
INFO:root:current mean train loss 3883.781309241958
INFO:root:current train perplexity4.6240081787109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.14s/it]
INFO:root:final mean train loss: 3880.5169590980777
INFO:root:final train perplexity: 4.622686862945557
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]
INFO:root:eval mean loss: 5624.164256935348
INFO:root:eval perplexity: 10.11933708190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/41
 20%|â–ˆâ–ˆ        | 41/200 [1:35:57<6:11:25, 140.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3827.0947627314813
INFO:root:current train perplexity4.5800395011901855
INFO:root:current mean train loss 3850.9062730684054
INFO:root:current train perplexity4.572535991668701
INFO:root:current mean train loss 3856.0417104040475
INFO:root:current train perplexity4.584116458892822
INFO:root:current mean train loss 3857.9441216611717
INFO:root:current train perplexity4.5796709060668945
INFO:root:current mean train loss 3859.6851226306353
INFO:root:current train perplexity4.5869245529174805
INFO:root:current mean train loss 3860.5457793784094
INFO:root:current train perplexity4.583446025848389
INFO:root:current mean train loss 3864.0426790520337
INFO:root:current train perplexity4.585014820098877
INFO:root:current mean train loss 3869.073765058137
INFO:root:current train perplexity4.593332290649414
INFO:root:current mean train loss 3873.9289848945737
INFO:root:current train perplexity4.600680351257324
INFO:root:current mean train loss 3873.5179370933624
INFO:root:current train perplexity4.601335048675537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.69s/it]
INFO:root:final mean train loss: 3869.791014148343
INFO:root:final train perplexity: 4.6031670570373535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it]
INFO:root:eval mean loss: 5624.8014420377995
INFO:root:eval perplexity: 10.121988296508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/42
 21%|â–ˆâ–ˆ        | 42/200 [1:38:17<6:08:42, 140.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3798.475899832589
INFO:root:current train perplexity4.544132232666016
INFO:root:current mean train loss 3821.4528971354166
INFO:root:current train perplexity4.554396629333496
INFO:root:current mean train loss 3839.348861369681
INFO:root:current train perplexity4.558010578155518
INFO:root:current mean train loss 3851.5614840834887
INFO:root:current train perplexity4.571577072143555
INFO:root:current mean train loss 3854.6724800197558
INFO:root:current train perplexity4.57191276550293
INFO:root:current mean train loss 3857.4162337543808
INFO:root:current train perplexity4.5747761726379395
INFO:root:current mean train loss 3857.150733190822
INFO:root:current train perplexity4.577258110046387
INFO:root:current mean train loss 3861.260230654762
INFO:root:current train perplexity4.578797340393066
INFO:root:current mean train loss 3858.492044524233
INFO:root:current train perplexity4.5765581130981445
INFO:root:current mean train loss 3858.5968300885697
INFO:root:current train perplexity4.577281951904297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.01s/it]
INFO:root:final mean train loss: 3857.420972577987
INFO:root:final train perplexity: 4.580756664276123
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it]
INFO:root:eval mean loss: 5624.02684962107
INFO:root:eval perplexity: 10.118764877319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/43
 22%|â–ˆâ–ˆâ–       | 43/200 [1:40:36<6:05:57, 139.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.5594056595205
INFO:root:current train perplexity4.568330764770508
INFO:root:current mean train loss 3863.9781246585444
INFO:root:current train perplexity4.568367004394531
INFO:root:current mean train loss 3853.9042637201005
INFO:root:current train perplexity4.5483174324035645
INFO:root:current mean train loss 3851.397968436817
INFO:root:current train perplexity4.549924373626709
INFO:root:current mean train loss 3851.456864815533
INFO:root:current train perplexity4.548182487487793
INFO:root:current mean train loss 3852.4602873575623
INFO:root:current train perplexity4.553842544555664
INFO:root:current mean train loss 3851.2730232582862
INFO:root:current train perplexity4.5541534423828125
INFO:root:current mean train loss 3848.251369553331
INFO:root:current train perplexity4.5548858642578125
INFO:root:current mean train loss 3849.262050063019
INFO:root:current train perplexity4.559120178222656
INFO:root:current mean train loss 3849.0789721136002
INFO:root:current train perplexity4.560225963592529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.65s/it]
INFO:root:final mean train loss: 3846.019394659227
INFO:root:final train perplexity: 4.560197353363037
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.61s/it]
INFO:root:eval mean loss: 5631.946658928237
INFO:root:eval perplexity: 10.1517972946167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/44
 22%|â–ˆâ–ˆâ–       | 44/200 [1:42:56<6:03:02, 139.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3789.4139715456495
INFO:root:current train perplexity4.496411323547363
INFO:root:current mean train loss 3824.5443834721646
INFO:root:current train perplexity4.511624336242676
INFO:root:current mean train loss 3827.7998688838397
INFO:root:current train perplexity4.522820472717285
INFO:root:current mean train loss 3827.3720341435187
INFO:root:current train perplexity4.5230841636657715
INFO:root:current mean train loss 3833.8524627347215
INFO:root:current train perplexity4.523539066314697
INFO:root:current mean train loss 3837.321610743251
INFO:root:current train perplexity4.53289270401001
INFO:root:current mean train loss 3832.998588409658
INFO:root:current train perplexity4.531280517578125
INFO:root:current mean train loss 3835.68880457567
INFO:root:current train perplexity4.535124778747559
INFO:root:current mean train loss 3834.407591769334
INFO:root:current train perplexity4.536398410797119
INFO:root:current mean train loss 3836.8395949884166
INFO:root:current train perplexity4.53780460357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.02s/it]
INFO:root:final mean train loss: 3834.7211131434287
INFO:root:final train perplexity: 4.539915084838867
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it]
INFO:root:eval mean loss: 5626.714241438997
INFO:root:eval perplexity: 10.129962921142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [1:45:16<6:01:06, 139.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.795844643803
INFO:root:current train perplexity4.48806619644165
INFO:root:current mean train loss 3828.18275077388
INFO:root:current train perplexity4.518575191497803
INFO:root:current mean train loss 3824.564115664213
INFO:root:current train perplexity4.519807815551758
INFO:root:current mean train loss 3822.022069224408
INFO:root:current train perplexity4.516568183898926
INFO:root:current mean train loss 3822.185821333742
INFO:root:current train perplexity4.518342971801758
INFO:root:current mean train loss 3823.1501940896133
INFO:root:current train perplexity4.518139362335205
INFO:root:current mean train loss 3828.058409625735
INFO:root:current train perplexity4.520595550537109
INFO:root:current mean train loss 3831.0543124433875
INFO:root:current train perplexity4.519272327423096
INFO:root:current mean train loss 3828.6378564623656
INFO:root:current train perplexity4.521084785461426
INFO:root:current mean train loss 3827.761181844288
INFO:root:current train perplexity4.5210700035095215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.18s/it]
INFO:root:final mean train loss: 3823.9831542353477
INFO:root:final train perplexity: 4.520723342895508
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it]
INFO:root:eval mean loss: 5626.868637724551
INFO:root:eval perplexity: 10.13060474395752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [1:47:40<6:02:36, 141.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3831.5932398554105
INFO:root:current train perplexity4.503236770629883
INFO:root:current mean train loss 3820.1421804827846
INFO:root:current train perplexity4.481849670410156
INFO:root:current mean train loss 3813.6673186227176
INFO:root:current train perplexity4.487101078033447
INFO:root:current mean train loss 3819.0333647766943
INFO:root:current train perplexity4.4952850341796875
INFO:root:current mean train loss 3824.169785950883
INFO:root:current train perplexity4.499526500701904
INFO:root:current mean train loss 3821.7459658668154
INFO:root:current train perplexity4.499017715454102
INFO:root:current mean train loss 3822.9354443871816
INFO:root:current train perplexity4.505499839782715
INFO:root:current mean train loss 3818.985401854832
INFO:root:current train perplexity4.502346992492676
INFO:root:current mean train loss 3818.437742732663
INFO:root:current train perplexity4.502741813659668
INFO:root:current mean train loss 3817.096509521232
INFO:root:current train perplexity4.501976490020752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.85s/it]
INFO:root:final mean train loss: 3813.266030157766
INFO:root:final train perplexity: 4.501648902893066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.48s/it]
INFO:root:eval mean loss: 5630.228208621819
INFO:root:eval perplexity: 10.14461898803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [1:50:01<5:59:24, 140.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.5672330729167
INFO:root:current train perplexity4.427964210510254
INFO:root:current mean train loss 3794.4697279575894
INFO:root:current train perplexity4.465179443359375
INFO:root:current mean train loss 3795.4949937855113
INFO:root:current train perplexity4.465285301208496
INFO:root:current mean train loss 3803.2514309895832
INFO:root:current train perplexity4.4764628410339355
INFO:root:current mean train loss 3803.3501218133224
INFO:root:current train perplexity4.4789910316467285
INFO:root:current mean train loss 3805.6388701596466
INFO:root:current train perplexity4.481206893920898
INFO:root:current mean train loss 3804.84947229456
INFO:root:current train perplexity4.48263692855835
INFO:root:current mean train loss 3804.7399776335687
INFO:root:current train perplexity4.48600435256958
INFO:root:current mean train loss 3805.8326791294644
INFO:root:current train perplexity4.487396240234375
INFO:root:current mean train loss 3806.5820918469553
INFO:root:current train perplexity4.485630989074707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.60s/it]
INFO:root:final mean train loss: 3803.9991162823094
INFO:root:final train perplexity: 4.485220432281494
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.54s/it]
INFO:root:eval mean loss: 5630.365218293881
INFO:root:eval perplexity: 10.14519214630127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/48
 24%|â–ˆâ–ˆâ–       | 48/200 [1:52:22<5:57:07, 140.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3800.7255241669804
INFO:root:current train perplexity4.447688102722168
INFO:root:current mean train loss 3802.2662760416665
INFO:root:current train perplexity4.44530725479126
INFO:root:current mean train loss 3788.998894034342
INFO:root:current train perplexity4.439673900604248
INFO:root:current mean train loss 3787.8073877080615
INFO:root:current train perplexity4.451959609985352
INFO:root:current mean train loss 3788.1597816988547
INFO:root:current train perplexity4.455984115600586
INFO:root:current mean train loss 3792.8913067511794
INFO:root:current train perplexity4.451930522918701
INFO:root:current mean train loss 3794.197778927983
INFO:root:current train perplexity4.45579719543457
INFO:root:current mean train loss 3793.195916771432
INFO:root:current train perplexity4.45915412902832
INFO:root:current mean train loss 3793.6531663075984
INFO:root:current train perplexity4.460714817047119
INFO:root:current mean train loss 3796.9063222735726
INFO:root:current train perplexity4.468555450439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.83s/it]
INFO:root:final mean train loss: 3794.351475438764
INFO:root:final train perplexity: 4.46818208694458
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it]
INFO:root:eval mean loss: 5632.460265016842
INFO:root:eval perplexity: 10.153944969177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/49
 24%|â–ˆâ–ˆâ–       | 49/200 [1:54:42<5:54:30, 140.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.7864735362296
INFO:root:current train perplexity4.401767730712891
INFO:root:current mean train loss 3781.849991563727
INFO:root:current train perplexity4.4184160232543945
INFO:root:current mean train loss 3772.2531033545424
INFO:root:current train perplexity4.424587726593018
INFO:root:current mean train loss 3776.4591866807864
INFO:root:current train perplexity4.430793285369873
INFO:root:current mean train loss 3777.396711609757
INFO:root:current train perplexity4.434236526489258
INFO:root:current mean train loss 3780.3848560933534
INFO:root:current train perplexity4.437951564788818
INFO:root:current mean train loss 3778.2126849957035
INFO:root:current train perplexity4.43574857711792
INFO:root:current mean train loss 3781.1533894496683
INFO:root:current train perplexity4.439087390899658
INFO:root:current mean train loss 3780.430030831317
INFO:root:current train perplexity4.440281867980957
INFO:root:current mean train loss 3785.333309600861
INFO:root:current train perplexity4.447157859802246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.27s/it]
INFO:root:final mean train loss: 3782.456475411692
INFO:root:final train perplexity: 4.447261810302734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it]
INFO:root:eval mean loss: 5636.4242930155315
INFO:root:eval perplexity: 10.170519828796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [1:57:22<6:06:32, 146.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3760.2896839488635
INFO:root:current train perplexity4.382221221923828
INFO:root:current mean train loss 3767.299403511699
INFO:root:current train perplexity4.401617527008057
INFO:root:current mean train loss 3770.4929411514945
INFO:root:current train perplexity4.410900115966797
INFO:root:current mean train loss 3772.5852154801064
INFO:root:current train perplexity4.413621425628662
INFO:root:current mean train loss 3776.6826313760334
INFO:root:current train perplexity4.425336837768555
INFO:root:current mean train loss 3775.3770110014084
INFO:root:current train perplexity4.429858207702637
INFO:root:current mean train loss 3770.7051609022933
INFO:root:current train perplexity4.429201602935791
INFO:root:current mean train loss 3770.7080897019714
INFO:root:current train perplexity4.429207801818848
INFO:root:current mean train loss 3772.3137424286533
INFO:root:current train perplexity4.430357933044434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.57s/it]
INFO:root:final mean train loss: 3774.4831664177677
INFO:root:final train perplexity: 4.433294296264648
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.37s/it]
INFO:root:eval mean loss: 5634.803732866299
INFO:root:eval perplexity: 10.163739204406738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [2:00:08<6:18:24, 152.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.4140625
INFO:root:current train perplexity4.396478176116943
INFO:root:current mean train loss 3763.714782144422
INFO:root:current train perplexity4.39642333984375
INFO:root:current mean train loss 3761.8278030174365
INFO:root:current train perplexity4.403174877166748
INFO:root:current mean train loss 3770.963723247913
INFO:root:current train perplexity4.403458595275879
INFO:root:current mean train loss 3772.049753100046
INFO:root:current train perplexity4.40973424911499
INFO:root:current mean train loss 3768.6727615145774
INFO:root:current train perplexity4.407841205596924
INFO:root:current mean train loss 3765.054834306142
INFO:root:current train perplexity4.407699108123779
INFO:root:current mean train loss 3761.866949575119
INFO:root:current train perplexity4.409348487854004
INFO:root:current mean train loss 3765.317868673521
INFO:root:current train perplexity4.413449764251709
INFO:root:current mean train loss 3765.7064274931954
INFO:root:current train perplexity4.41243839263916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.39s/it]
INFO:root:final mean train loss: 3763.756083826865
INFO:root:final train perplexity: 4.414571762084961
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 5635.152060137538
INFO:root:eval perplexity: 10.16519832611084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:02:31<6:09:01, 149.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3773.050716145833
INFO:root:current train perplexity4.47218132019043
INFO:root:current mean train loss 3735.7695121433426
INFO:root:current train perplexity4.371774673461914
INFO:root:current mean train loss 3738.831281795058
INFO:root:current train perplexity4.375941276550293
INFO:root:current mean train loss 3739.5764136904763
INFO:root:current train perplexity4.3824238777160645
INFO:root:current mean train loss 3745.6670063064757
INFO:root:current train perplexity4.382706642150879
INFO:root:current mean train loss 3748.709130859375
INFO:root:current train perplexity4.386509895324707
INFO:root:current mean train loss 3746.9036668730946
INFO:root:current train perplexity4.391778469085693
INFO:root:current mean train loss 3750.8586910647946
INFO:root:current train perplexity4.3952555656433105
INFO:root:current mean train loss 3756.4280219516872
INFO:root:current train perplexity4.3971638679504395
INFO:root:current mean train loss 3757.634026532616
INFO:root:current train perplexity4.3985819816589355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.45s/it]
INFO:root:final mean train loss: 3755.562025808519
INFO:root:final train perplexity: 4.400322914123535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it]
INFO:root:eval mean loss: 5636.769015192272
INFO:root:eval perplexity: 10.17196273803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:04:52<5:59:54, 146.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3743.8798509680705
INFO:root:current train perplexity4.429381847381592
INFO:root:current mean train loss 3747.4771817835367
INFO:root:current train perplexity4.388978004455566
INFO:root:current mean train loss 3737.8324823080156
INFO:root:current train perplexity4.3775224685668945
INFO:root:current mean train loss 3748.1443664739745
INFO:root:current train perplexity4.3840742111206055
INFO:root:current mean train loss 3743.2245701278075
INFO:root:current train perplexity4.3823113441467285
INFO:root:current mean train loss 3749.496970415571
INFO:root:current train perplexity4.388833999633789
INFO:root:current mean train loss 3751.7218403578954
INFO:root:current train perplexity4.388279438018799
INFO:root:current mean train loss 3747.5157762793915
INFO:root:current train perplexity4.382721424102783
INFO:root:current mean train loss 3750.234385086004
INFO:root:current train perplexity4.38633394241333
INFO:root:current mean train loss 3752.134923800616
INFO:root:current train perplexity4.387386322021484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.35s/it]
INFO:root:final mean train loss: 3746.888679073703
INFO:root:final train perplexity: 4.38529109954834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it]
INFO:root:eval mean loss: 5635.653187277788
INFO:root:eval perplexity: 10.167295455932617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:07:37<6:10:25, 152.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.630552230343
INFO:root:current train perplexity4.371469020843506
INFO:root:current mean train loss 3725.078825739504
INFO:root:current train perplexity4.347479343414307
INFO:root:current mean train loss 3735.8173806987284
INFO:root:current train perplexity4.360783576965332
INFO:root:current mean train loss 3727.173289687972
INFO:root:current train perplexity4.352550506591797
INFO:root:current mean train loss 3730.9386419663574
INFO:root:current train perplexity4.359962463378906
INFO:root:current mean train loss 3734.131399151071
INFO:root:current train perplexity4.366687774658203
INFO:root:current mean train loss 3732.650177824138
INFO:root:current train perplexity4.368401527404785
INFO:root:current mean train loss 3733.762638869592
INFO:root:current train perplexity4.367525100708008
INFO:root:current mean train loss 3735.3574110047193
INFO:root:current train perplexity4.367847442626953
INFO:root:current mean train loss 3737.0819229470158
INFO:root:current train perplexity4.366380214691162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.66s/it]
INFO:root:final mean train loss: 3735.850095871956
INFO:root:final train perplexity: 4.366234302520752
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 5637.972014467159
INFO:root:eval perplexity: 10.176998138427734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:09:56<5:58:23, 148.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3689.107421875
INFO:root:current train perplexity4.306703090667725
INFO:root:current mean train loss 3725.4523240782373
INFO:root:current train perplexity4.331420421600342
INFO:root:current mean train loss 3726.9739382436583
INFO:root:current train perplexity4.3348388671875
INFO:root:current mean train loss 3722.6319727714786
INFO:root:current train perplexity4.329550266265869
INFO:root:current mean train loss 3719.3974420291142
INFO:root:current train perplexity4.330172061920166
INFO:root:current mean train loss 3717.559563065283
INFO:root:current train perplexity4.3363823890686035
INFO:root:current mean train loss 3719.6536053342625
INFO:root:current train perplexity4.340122699737549
INFO:root:current mean train loss 3723.5006914564656
INFO:root:current train perplexity4.347256183624268
INFO:root:current mean train loss 3726.0318255782554
INFO:root:current train perplexity4.349077224731445
INFO:root:current mean train loss 3729.7842579477006
INFO:root:current train perplexity4.351651668548584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.24s/it]
INFO:root:final mean train loss: 3727.5896329572124
INFO:root:final train perplexity: 4.352028846740723
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it]
INFO:root:eval mean loss: 5638.924104427863
INFO:root:eval perplexity: 10.180988311767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:12:14<5:49:04, 145.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3722.8674108626997
INFO:root:current train perplexity4.335879325866699
INFO:root:current mean train loss 3706.7559955622874
INFO:root:current train perplexity4.31567907333374
INFO:root:current mean train loss 3712.8240487411435
INFO:root:current train perplexity4.318447113037109
INFO:root:current mean train loss 3714.183625410888
INFO:root:current train perplexity4.319581031799316
INFO:root:current mean train loss 3713.129675811836
INFO:root:current train perplexity4.326016426086426
INFO:root:current mean train loss 3715.7059341793306
INFO:root:current train perplexity4.327620983123779
INFO:root:current mean train loss 3721.227442462809
INFO:root:current train perplexity4.332584857940674
INFO:root:current mean train loss 3721.6404230202056
INFO:root:current train perplexity4.334779739379883
INFO:root:current mean train loss 3723.1997009781767
INFO:root:current train perplexity4.336787700653076
INFO:root:current mean train loss 3723.2139581924002
INFO:root:current train perplexity4.337142467498779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.11s/it]
INFO:root:final mean train loss: 3718.7635630330733
INFO:root:final train perplexity: 4.336900234222412
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5649.988189149046
INFO:root:eval perplexity: 10.227448463439941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:14:34<5:42:10, 143.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3671.611603338068
INFO:root:current train perplexity4.25156831741333
INFO:root:current mean train loss 3686.540658077117
INFO:root:current train perplexity4.286727428436279
INFO:root:current mean train loss 3696.021689261642
INFO:root:current train perplexity4.2915358543396
INFO:root:current mean train loss 3694.6063139579664
INFO:root:current train perplexity4.292392730712891
INFO:root:current mean train loss 3705.2984573531935
INFO:root:current train perplexity4.304258346557617
INFO:root:current mean train loss 3706.567722849803
INFO:root:current train perplexity4.3104329109191895
INFO:root:current mean train loss 3707.624058474475
INFO:root:current train perplexity4.3153605461120605
INFO:root:current mean train loss 3708.8517561956746
INFO:root:current train perplexity4.321204662322998
INFO:root:current mean train loss 3710.2490873994884
INFO:root:current train perplexity4.320480823516846
INFO:root:current mean train loss 3712.8728957890216
INFO:root:current train perplexity4.322364330291748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.39s/it]
INFO:root:final mean train loss: 3710.6804329656784
INFO:root:final train perplexity: 4.323091506958008
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 5645.786397420004
INFO:root:eval perplexity: 10.20977783203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:16:54<5:37:12, 142.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.137176029266
INFO:root:current train perplexity4.307981491088867
INFO:root:current mean train loss 3680.842469385065
INFO:root:current train perplexity4.267698287963867
INFO:root:current mean train loss 3689.83974070966
INFO:root:current train perplexity4.275883674621582
INFO:root:current mean train loss 3682.3167102487946
INFO:root:current train perplexity4.277271747589111
INFO:root:current mean train loss 3689.6203866386
INFO:root:current train perplexity4.287482261657715
INFO:root:current mean train loss 3692.834536401671
INFO:root:current train perplexity4.290510654449463
INFO:root:current mean train loss 3695.1987672923738
INFO:root:current train perplexity4.2938737869262695
INFO:root:current mean train loss 3696.8990547310163
INFO:root:current train perplexity4.299954414367676
INFO:root:current mean train loss 3699.3008013357294
INFO:root:current train perplexity4.304862976074219
INFO:root:current mean train loss 3704.1238206207813
INFO:root:current train perplexity4.308847904205322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.95s/it]
INFO:root:final mean train loss: 3703.079199267972
INFO:root:final train perplexity: 4.310146331787109
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.55s/it]
INFO:root:eval mean loss: 5651.258613632111
INFO:root:eval perplexity: 10.232797622680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:19:14<5:33:19, 141.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.378287301937
INFO:root:current train perplexity4.27365779876709
INFO:root:current mean train loss 3676.1690181263707
INFO:root:current train perplexity4.255892276763916
INFO:root:current mean train loss 3690.1225766115085
INFO:root:current train perplexity4.271237373352051
INFO:root:current mean train loss 3693.713817174865
INFO:root:current train perplexity4.28177547454834
INFO:root:current mean train loss 3691.2248053095145
INFO:root:current train perplexity4.287492752075195
INFO:root:current mean train loss 3692.5478981672777
INFO:root:current train perplexity4.29081392288208
INFO:root:current mean train loss 3693.044485987565
INFO:root:current train perplexity4.2918829917907715
INFO:root:current mean train loss 3695.508018958739
INFO:root:current train perplexity4.291872024536133
INFO:root:current mean train loss 3695.532833970921
INFO:root:current train perplexity4.292630672454834
INFO:root:current mean train loss 3695.2787550387006
INFO:root:current train perplexity4.2931599617004395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.54s/it]
INFO:root:final mean train loss: 3693.595985166488
INFO:root:final train perplexity: 4.294050693511963
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it]
INFO:root:eval mean loss: 5651.90966504491
INFO:root:eval perplexity: 10.235540390014648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:21:34<5:29:25, 141.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.3695176522942
INFO:root:current train perplexity4.2751874923706055
INFO:root:current mean train loss 3690.7313348354573
INFO:root:current train perplexity4.280886650085449
INFO:root:current mean train loss 3687.225329546091
INFO:root:current train perplexity4.282825946807861
INFO:root:current mean train loss 3677.607488224563
INFO:root:current train perplexity4.276161193847656
INFO:root:current mean train loss 3678.4837256572937
INFO:root:current train perplexity4.272841930389404
INFO:root:current mean train loss 3682.2587384634066
INFO:root:current train perplexity4.27802848815918
INFO:root:current mean train loss 3680.316276808726
INFO:root:current train perplexity4.273926258087158
INFO:root:current mean train loss 3683.373500681964
INFO:root:current train perplexity4.277194499969482
INFO:root:current mean train loss 3685.2153317535017
INFO:root:current train perplexity4.277307510375977
INFO:root:current mean train loss 3689.623173060042
INFO:root:current train perplexity4.281646251678467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.86s/it]
INFO:root:final mean train loss: 3686.3856591255435
INFO:root:final train perplexity: 4.281852722167969
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it]
INFO:root:eval mean loss: 5646.310437231006
INFO:root:eval perplexity: 10.211981773376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:23:53<5:25:46, 140.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.8206408270476
INFO:root:current train perplexity4.226596355438232
INFO:root:current mean train loss 3673.3229288519383
INFO:root:current train perplexity4.2526936531066895
INFO:root:current mean train loss 3677.31664528664
INFO:root:current train perplexity4.257561206817627
INFO:root:current mean train loss 3679.8877691224566
INFO:root:current train perplexity4.2611985206604
INFO:root:current mean train loss 3681.2038514060896
INFO:root:current train perplexity4.265004634857178
INFO:root:current mean train loss 3681.9138029706132
INFO:root:current train perplexity4.2643351554870605
INFO:root:current mean train loss 3681.155268817663
INFO:root:current train perplexity4.264631748199463
INFO:root:current mean train loss 3680.3422463791494
INFO:root:current train perplexity4.267664432525635
INFO:root:current mean train loss 3679.332993499859
INFO:root:current train perplexity4.266544818878174
INFO:root:current mean train loss 3680.9065079925754
INFO:root:current train perplexity4.26775598526001

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.14s/it]
INFO:root:final mean train loss: 3678.0655208095427
INFO:root:final train perplexity: 4.267820358276367
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it]
INFO:root:eval mean loss: 5661.253610942178
INFO:root:eval perplexity: 10.27497386932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:26:15<5:24:40, 141.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3646.0849506578948
INFO:root:current train perplexity4.22055196762085
INFO:root:current mean train loss 3659.9175605969554
INFO:root:current train perplexity4.238974094390869
INFO:root:current mean train loss 3664.2265492584747
INFO:root:current train perplexity4.241329193115234
INFO:root:current mean train loss 3666.0630704855616
INFO:root:current train perplexity4.2428717613220215
INFO:root:current mean train loss 3669.1658464528095
INFO:root:current train perplexity4.241610050201416
INFO:root:current mean train loss 3671.3245699842437
INFO:root:current train perplexity4.249202251434326
INFO:root:current mean train loss 3671.0409745250677
INFO:root:current train perplexity4.248730182647705
INFO:root:current mean train loss 3673.1823033362816
INFO:root:current train perplexity4.255311489105225
INFO:root:current mean train loss 3673.066105916114
INFO:root:current train perplexity4.254651069641113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.46s/it]
INFO:root:final mean train loss: 3669.8687528794812
INFO:root:final train perplexity: 4.254040718078613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 5660.078298968469
INFO:root:eval perplexity: 10.270004272460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:28:34<5:20:47, 140.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.0453287760415
INFO:root:current train perplexity4.313717842102051
INFO:root:current mean train loss 3669.091057342233
INFO:root:current train perplexity4.236348628997803
INFO:root:current mean train loss 3655.724277439963
INFO:root:current train perplexity4.225592136383057
INFO:root:current mean train loss 3655.056538295431
INFO:root:current train perplexity4.233264923095703
INFO:root:current mean train loss 3662.5469961616004
INFO:root:current train perplexity4.237439155578613
INFO:root:current mean train loss 3667.0010406312126
INFO:root:current train perplexity4.235321521759033
INFO:root:current mean train loss 3667.5181615522647
INFO:root:current train perplexity4.235432147979736
INFO:root:current mean train loss 3664.621113545186
INFO:root:current train perplexity4.233809471130371
INFO:root:current mean train loss 3665.05900450216
INFO:root:current train perplexity4.235403537750244
INFO:root:current mean train loss 3664.869384765625
INFO:root:current train perplexity4.23610258102417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.46s/it]
INFO:root:final mean train loss: 3661.229128314603
INFO:root:final train perplexity: 4.239565849304199
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it]
INFO:root:eval mean loss: 5659.08040413314
INFO:root:eval perplexity: 10.265786170959473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [2:30:53<5:17:27, 140.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.298672762784
INFO:root:current train perplexity4.204713344573975
INFO:root:current mean train loss 3663.7088018193976
INFO:root:current train perplexity4.215986728668213
INFO:root:current mean train loss 3643.7209079254294
INFO:root:current train perplexity4.211865425109863
INFO:root:current mean train loss 3632.899911763967
INFO:root:current train perplexity4.205650806427002
INFO:root:current mean train loss 3639.1587056626367
INFO:root:current train perplexity4.206205368041992
INFO:root:current mean train loss 3645.578185199058
INFO:root:current train perplexity4.211791038513184
INFO:root:current mean train loss 3649.9930278072575
INFO:root:current train perplexity4.217693328857422
INFO:root:current mean train loss 3652.6621646586013
INFO:root:current train perplexity4.222247123718262
INFO:root:current mean train loss 3656.728699558319
INFO:root:current train perplexity4.225657939910889
INFO:root:current mean train loss 3655.1096379000583
INFO:root:current train perplexity4.224949359893799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.84s/it]
INFO:root:final mean train loss: 3653.2322943287513
INFO:root:final train perplexity: 4.226210117340088
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 5666.852274454996
INFO:root:eval perplexity: 10.298672676086426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [2:33:12<5:14:27, 139.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.6747147409537
INFO:root:current train perplexity4.186127662658691
INFO:root:current mean train loss 3643.016552324055
INFO:root:current train perplexity4.200658798217773
INFO:root:current mean train loss 3644.915345631778
INFO:root:current train perplexity4.20243501663208
INFO:root:current mean train loss 3646.2894436348943
INFO:root:current train perplexity4.202129364013672
INFO:root:current mean train loss 3648.5466780560114
INFO:root:current train perplexity4.2080535888671875
INFO:root:current mean train loss 3644.7171901342726
INFO:root:current train perplexity4.2022480964660645
INFO:root:current mean train loss 3650.0715316254796
INFO:root:current train perplexity4.209805011749268
INFO:root:current mean train loss 3648.316892493915
INFO:root:current train perplexity4.212187767028809
INFO:root:current mean train loss 3646.639626974588
INFO:root:current train perplexity4.2084574699401855
INFO:root:current mean train loss 3647.780470025163
INFO:root:current train perplexity4.214197635650635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.01s/it]
INFO:root:final mean train loss: 3647.670498878725
INFO:root:final train perplexity: 4.216947555541992
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it]
INFO:root:eval mean loss: 5659.544644110217
INFO:root:eval perplexity: 10.267749786376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [2:35:35<5:14:19, 140.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.523681640625
INFO:root:current train perplexity4.116174221038818
INFO:root:current mean train loss 3625.3827490618846
INFO:root:current train perplexity4.171855449676514
INFO:root:current mean train loss 3639.1997199373623
INFO:root:current train perplexity4.199155807495117
INFO:root:current mean train loss 3640.2770854238343
INFO:root:current train perplexity4.19582462310791
INFO:root:current mean train loss 3642.3711509257905
INFO:root:current train perplexity4.193747520446777
INFO:root:current mean train loss 3636.5819307215074
INFO:root:current train perplexity4.18930721282959
INFO:root:current mean train loss 3636.675998912854
INFO:root:current train perplexity4.192909240722656
INFO:root:current mean train loss 3637.1377268795136
INFO:root:current train perplexity4.1974077224731445
INFO:root:current mean train loss 3637.782993819434
INFO:root:current train perplexity4.199235916137695
INFO:root:current mean train loss 3641.0008604179307
INFO:root:current train perplexity4.201855182647705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.85s/it]
INFO:root:final mean train loss: 3639.4523856255314
INFO:root:final train perplexity: 4.203297138214111
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 5670.359715627339
INFO:root:eval perplexity: 10.31354808807373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [2:37:59<5:13:43, 141.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.5739815848215
INFO:root:current train perplexity4.1562395095825195
INFO:root:current mean train loss 3605.455224609375
INFO:root:current train perplexity4.158646106719971
INFO:root:current mean train loss 3614.4608575049865
INFO:root:current train perplexity4.166916847229004
INFO:root:current mean train loss 3624.0294593924905
INFO:root:current train perplexity4.173757076263428
INFO:root:current mean train loss 3623.62533281699
INFO:root:current train perplexity4.173825263977051
INFO:root:current mean train loss 3631.4080607476635
INFO:root:current train perplexity4.180361747741699
INFO:root:current mean train loss 3631.529681348425
INFO:root:current train perplexity4.177645206451416
INFO:root:current mean train loss 3633.4324610703657
INFO:root:current train perplexity4.183927536010742
INFO:root:current mean train loss 3635.33528694564
INFO:root:current train perplexity4.1883697509765625
INFO:root:current mean train loss 3637.0372524649065
INFO:root:current train perplexity4.1905083656311035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.34s/it]
INFO:root:final mean train loss: 3632.5979617334183
INFO:root:final train perplexity: 4.191945552825928
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it]
INFO:root:eval mean loss: 5671.403133186752
INFO:root:eval perplexity: 10.317977905273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [2:40:22<5:12:23, 142.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.698003724564
INFO:root:current train perplexity4.1575117111206055
INFO:root:current mean train loss 3631.5476876638986
INFO:root:current train perplexity4.176887035369873
INFO:root:current mean train loss 3630.397614655671
INFO:root:current train perplexity4.176915168762207
INFO:root:current mean train loss 3628.287160623178
INFO:root:current train perplexity4.171842575073242
INFO:root:current mean train loss 3622.60985666796
INFO:root:current train perplexity4.167802333831787
INFO:root:current mean train loss 3625.1253435054095
INFO:root:current train perplexity4.170879364013672
INFO:root:current mean train loss 3628.843907571321
INFO:root:current train perplexity4.174127578735352
INFO:root:current mean train loss 3629.688219935544
INFO:root:current train perplexity4.177220344543457
INFO:root:current mean train loss 3631.5307860459297
INFO:root:current train perplexity4.1807756423950195
INFO:root:current mean train loss 3628.543900264283
INFO:root:current train perplexity4.178554534912109

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.14s/it]
INFO:root:final mean train loss: 3625.138811726724
INFO:root:final train perplexity: 4.179626941680908
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.50s/it]
INFO:root:eval mean loss: 5672.462808757485
INFO:root:eval perplexity: 10.322481155395508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [2:42:43<5:09:43, 141.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3603.812619676777
INFO:root:current train perplexity4.147304058074951
INFO:root:current mean train loss 3600.1182723897973
INFO:root:current train perplexity4.152169704437256
INFO:root:current mean train loss 3604.353868704868
INFO:root:current train perplexity4.148914337158203
INFO:root:current mean train loss 3613.7417687744837
INFO:root:current train perplexity4.16070032119751
INFO:root:current mean train loss 3606.2849315973185
INFO:root:current train perplexity4.15760612487793
INFO:root:current mean train loss 3608.0691844019398
INFO:root:current train perplexity4.161918640136719
INFO:root:current mean train loss 3612.375977312548
INFO:root:current train perplexity4.163814544677734
INFO:root:current mean train loss 3614.4171713106484
INFO:root:current train perplexity4.166049003601074
INFO:root:current mean train loss 3617.9814717060813
INFO:root:current train perplexity4.1666388511657715
INFO:root:current mean train loss 3621.2886240224107
INFO:root:current train perplexity4.168971061706543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.06s/it]
INFO:root:final mean train loss: 3619.289898041756
INFO:root:final train perplexity: 4.1699934005737305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5681.801501976515
INFO:root:eval perplexity: 10.362224578857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [2:45:04<5:06:16, 141.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.4816935911017
INFO:root:current train perplexity4.136289119720459
INFO:root:current mean train loss 3581.730614620185
INFO:root:current train perplexity4.133753776550293
INFO:root:current mean train loss 3597.6366527660475
INFO:root:current train perplexity4.142416477203369
INFO:root:current mean train loss 3598.169900793219
INFO:root:current train perplexity4.145245552062988
INFO:root:current mean train loss 3600.277954367511
INFO:root:current train perplexity4.141324996948242
INFO:root:current mean train loss 3600.9376227254306
INFO:root:current train perplexity4.142484188079834
INFO:root:current mean train loss 3603.0619928247106
INFO:root:current train perplexity4.1445817947387695
INFO:root:current mean train loss 3604.2587839159255
INFO:root:current train perplexity4.148298740386963
INFO:root:current mean train loss 3607.094735657378
INFO:root:current train perplexity4.15084981918335
INFO:root:current mean train loss 3612.721030258163
INFO:root:current train perplexity4.1540093421936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.76s/it]
INFO:root:final mean train loss: 3611.019533034294
INFO:root:final train perplexity: 4.156409740447998
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 5674.048377853667
INFO:root:eval perplexity: 10.329216957092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [2:47:26<5:04:30, 141.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.2174527751868
INFO:root:current train perplexity4.084903240203857
INFO:root:current mean train loss 3581.311380169349
INFO:root:current train perplexity4.1015543937683105
INFO:root:current mean train loss 3582.6076294402505
INFO:root:current train perplexity4.113641262054443
INFO:root:current mean train loss 3597.258101211257
INFO:root:current train perplexity4.128792762756348
INFO:root:current mean train loss 3597.1167682263786
INFO:root:current train perplexity4.127989768981934
INFO:root:current mean train loss 3593.225375812941
INFO:root:current train perplexity4.13020133972168
INFO:root:current mean train loss 3599.428954346069
INFO:root:current train perplexity4.134064674377441
INFO:root:current mean train loss 3601.4022689481135
INFO:root:current train perplexity4.1378254890441895
INFO:root:current mean train loss 3601.0772624824285
INFO:root:current train perplexity4.139108657836914
INFO:root:current mean train loss 3607.4932034481644
INFO:root:current train perplexity4.146618366241455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.99s/it]
INFO:root:final mean train loss: 3604.890053410684
INFO:root:final train perplexity: 4.1463704109191895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it]
INFO:root:eval mean loss: 5686.293597375561
INFO:root:eval perplexity: 10.381396293640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [2:49:44<4:59:52, 140.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.5878190104168
INFO:root:current train perplexity4.117974758148193
INFO:root:current mean train loss 3595.2336788504463
INFO:root:current train perplexity4.1146159172058105
INFO:root:current mean train loss 3596.80890625
INFO:root:current train perplexity4.117065906524658
INFO:root:current mean train loss 3594.1651751302084
INFO:root:current train perplexity4.124591827392578
INFO:root:current mean train loss 3597.749103618421
INFO:root:current train perplexity4.130686283111572
INFO:root:current mean train loss 3598.171812160326
INFO:root:current train perplexity4.1292524337768555
INFO:root:current mean train loss 3597.804969256366
INFO:root:current train perplexity4.129457950592041
INFO:root:current mean train loss 3599.3524269153227
INFO:root:current train perplexity4.133372783660889
INFO:root:current mean train loss 3600.85509375
INFO:root:current train perplexity4.133945941925049
INFO:root:current mean train loss 3601.2159833233172
INFO:root:current train perplexity4.135531425476074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.38s/it]
INFO:root:final mean train loss: 3597.8938383902273
INFO:root:final train perplexity: 4.134942054748535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it]
INFO:root:eval mean loss: 5686.886478995135
INFO:root:eval perplexity: 10.383929252624512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [2:52:03<4:56:25, 140.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3558.4615257906626
INFO:root:current train perplexity4.088109016418457
INFO:root:current mean train loss 3576.517303300034
INFO:root:current train perplexity4.104653358459473
INFO:root:current mean train loss 3587.9635048586574
INFO:root:current train perplexity4.118059158325195
INFO:root:current mean train loss 3586.574207913471
INFO:root:current train perplexity4.112961769104004
INFO:root:current mean train loss 3587.9330695805834
INFO:root:current train perplexity4.118380546569824
INFO:root:current mean train loss 3588.3345936796472
INFO:root:current train perplexity4.121602535247803
INFO:root:current mean train loss 3590.550405566549
INFO:root:current train perplexity4.122451305389404
INFO:root:current mean train loss 3590.463020958054
INFO:root:current train perplexity4.120961666107178
INFO:root:current mean train loss 3591.7794799113462
INFO:root:current train perplexity4.1208271980285645
INFO:root:current mean train loss 3592.8358182858597
INFO:root:current train perplexity4.123030662536621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.69s/it]
INFO:root:final mean train loss: 3590.796422466155
INFO:root:final train perplexity: 4.123379230499268
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.67s/it]
INFO:root:eval mean loss: 5693.298407092066
INFO:root:eval perplexity: 10.41136646270752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [2:54:22<4:53:34, 139.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.8379737937844
INFO:root:current train perplexity4.1067585945129395
INFO:root:current mean train loss 3572.757177223086
INFO:root:current train perplexity4.086319923400879
INFO:root:current mean train loss 3580.391815500161
INFO:root:current train perplexity4.095649719238281
INFO:root:current mean train loss 3577.0808305276933
INFO:root:current train perplexity4.096889019012451
INFO:root:current mean train loss 3576.87319455273
INFO:root:current train perplexity4.096774101257324
INFO:root:current mean train loss 3578.4071546835344
INFO:root:current train perplexity4.094845771789551
INFO:root:current mean train loss 3579.9833281278266
INFO:root:current train perplexity4.101176738739014
INFO:root:current mean train loss 3581.5255424798515
INFO:root:current train perplexity4.105524063110352
INFO:root:current mean train loss 3583.0326364776233
INFO:root:current train perplexity4.108119010925293
INFO:root:current mean train loss 3586.8292979097027
INFO:root:current train perplexity4.112410545349121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.06s/it]
INFO:root:final mean train loss: 3584.052521982501
INFO:root:final train perplexity: 4.112422943115234
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 5691.985465592253
INFO:root:eval perplexity: 10.405740737915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [2:56:41<4:50:59, 139.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3565.6576951152147
INFO:root:current train perplexity4.08482027053833
INFO:root:current mean train loss 3577.3633585407506
INFO:root:current train perplexity4.087765216827393
INFO:root:current mean train loss 3576.5195900397157
INFO:root:current train perplexity4.0940070152282715
INFO:root:current mean train loss 3574.707440598567
INFO:root:current train perplexity4.093918800354004
INFO:root:current mean train loss 3578.918461434588
INFO:root:current train perplexity4.096688747406006
INFO:root:current mean train loss 3578.7341577596776
INFO:root:current train perplexity4.093603610992432
INFO:root:current mean train loss 3581.3325684292295
INFO:root:current train perplexity4.1001129150390625
INFO:root:current mean train loss 3578.9234348722034
INFO:root:current train perplexity4.099329471588135
INFO:root:current mean train loss 3579.5512442753234
INFO:root:current train perplexity4.1017584800720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.25s/it]
INFO:root:final mean train loss: 3577.817070622598
INFO:root:final train perplexity: 4.10231876373291
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it]
INFO:root:eval mean loss: 5693.136857632391
INFO:root:eval perplexity: 10.410676002502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [2:59:01<4:48:42, 139.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3572.133056640625
INFO:root:current train perplexity4.095628261566162
INFO:root:current mean train loss 3569.806451244889
INFO:root:current train perplexity4.091467380523682
INFO:root:current mean train loss 3563.9237432065215
INFO:root:current train perplexity4.080925941467285
INFO:root:current mean train loss 3563.6988131743688
INFO:root:current train perplexity4.075682640075684
INFO:root:current mean train loss 3567.9524723587224
INFO:root:current train perplexity4.080839157104492
INFO:root:current mean train loss 3566.901708599143
INFO:root:current train perplexity4.079732418060303
INFO:root:current mean train loss 3571.819157759087
INFO:root:current train perplexity4.085237503051758
INFO:root:current mean train loss 3572.55920910869
INFO:root:current train perplexity4.087751865386963
INFO:root:current mean train loss 3572.5387999051272
INFO:root:current train perplexity4.0877604484558105
INFO:root:current mean train loss 3571.717364562517
INFO:root:current train perplexity4.087723731994629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.29s/it]
INFO:root:final mean train loss: 3570.40152611271
INFO:root:final train perplexity: 4.090334892272949
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it]
INFO:root:eval mean loss: 5704.91405957616
INFO:root:eval perplexity: 10.461250305175781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [3:01:21<4:46:36, 139.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.7741536458334
INFO:root:current train perplexity4.016274452209473
INFO:root:current mean train loss 3555.012444802989
INFO:root:current train perplexity4.049472332000732
INFO:root:current mean train loss 3560.7032896529795
INFO:root:current train perplexity4.05720853805542
INFO:root:current mean train loss 3556.9599880642363
INFO:root:current train perplexity4.05833101272583
INFO:root:current mean train loss 3561.831270590173
INFO:root:current train perplexity4.068423748016357
INFO:root:current mean train loss 3563.3928350652304
INFO:root:current train perplexity4.072135925292969
INFO:root:current mean train loss 3559.368475292175
INFO:root:current train perplexity4.068142414093018
INFO:root:current mean train loss 3563.0323610959354
INFO:root:current train perplexity4.073606491088867
INFO:root:current mean train loss 3564.131153242427
INFO:root:current train perplexity4.076223850250244
INFO:root:current mean train loss 3565.2500544313525
INFO:root:current train perplexity4.077281951904297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it]
INFO:root:final mean train loss: 3564.2142988020373
INFO:root:final train perplexity: 4.080361843109131
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it]
INFO:root:eval mean loss: 5701.320188236808
INFO:root:eval perplexity: 10.44579029083252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:03:42<4:45:00, 140.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3555.3308423913045
INFO:root:current train perplexity4.066317558288574
INFO:root:current mean train loss 3552.5172803925307
INFO:root:current train perplexity4.0687150955200195
INFO:root:current mean train loss 3549.22779962514
INFO:root:current train perplexity4.067661762237549
INFO:root:current mean train loss 3551.5768566781153
INFO:root:current train perplexity4.061798572540283
INFO:root:current mean train loss 3551.1656785608748
INFO:root:current train perplexity4.061265468597412
INFO:root:current mean train loss 3550.1801258327855
INFO:root:current train perplexity4.062862396240234
INFO:root:current mean train loss 3555.3849568619585
INFO:root:current train perplexity4.065683841705322
INFO:root:current mean train loss 3555.1075572835625
INFO:root:current train perplexity4.063687801361084
INFO:root:current mean train loss 3557.3181739705155
INFO:root:current train perplexity4.064450263977051
INFO:root:current mean train loss 3558.4231348502676
INFO:root:current train perplexity4.068989276885986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.33s/it]
INFO:root:final mean train loss: 3558.174487883045
INFO:root:final train perplexity: 4.070650577545166
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it]
INFO:root:eval mean loss: 5707.945170693769
INFO:root:eval perplexity: 10.474309921264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:06:01<4:41:57, 139.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.468553112399
INFO:root:current train perplexity4.028927326202393
INFO:root:current mean train loss 3549.3389063245468
INFO:root:current train perplexity4.0490007400512695
INFO:root:current mean train loss 3554.428978329613
INFO:root:current train perplexity4.05047082901001
INFO:root:current mean train loss 3557.6760615322887
INFO:root:current train perplexity4.051816940307617
INFO:root:current mean train loss 3555.382312323267
INFO:root:current train perplexity4.056392669677734
INFO:root:current mean train loss 3554.766325237612
INFO:root:current train perplexity4.059318542480469
INFO:root:current mean train loss 3554.8644029039965
INFO:root:current train perplexity4.059408187866211
INFO:root:current mean train loss 3553.6177515950967
INFO:root:current train perplexity4.057999610900879
INFO:root:current mean train loss 3556.7205482969503
INFO:root:current train perplexity4.062203407287598
INFO:root:current mean train loss 3553.743315371996
INFO:root:current train perplexity4.0611162185668945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.09s/it]
INFO:root:final mean train loss: 3551.2715254137593
INFO:root:final train perplexity: 4.059578895568848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it]
INFO:root:eval mean loss: 5707.5826891139595
INFO:root:eval perplexity: 10.472746849060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:08:25<4:41:48, 140.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.221454326923
INFO:root:current train perplexity4.043590545654297
INFO:root:current mean train loss 3527.416150868368
INFO:root:current train perplexity4.026496887207031
INFO:root:current mean train loss 3530.01268611892
INFO:root:current train perplexity4.026577472686768
INFO:root:current mean train loss 3534.671896605365
INFO:root:current train perplexity4.025651454925537
INFO:root:current mean train loss 3536.0691207155824
INFO:root:current train perplexity4.035487651824951
INFO:root:current mean train loss 3536.99629757798
INFO:root:current train perplexity4.038592338562012
INFO:root:current mean train loss 3543.9699454867223
INFO:root:current train perplexity4.045164585113525
INFO:root:current mean train loss 3546.0545949974626
INFO:root:current train perplexity4.049633026123047
INFO:root:current mean train loss 3547.635811734114
INFO:root:current train perplexity4.051267147064209
INFO:root:current mean train loss 3547.723392571885
INFO:root:current train perplexity4.051034450531006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.33s/it]
INFO:root:final mean train loss: 3547.027732787594
INFO:root:final train perplexity: 4.052788257598877
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it]
INFO:root:eval mean loss: 5711.625681254678
INFO:root:eval perplexity: 10.490184783935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:10:44<4:38:45, 140.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.52584254488
INFO:root:current train perplexity4.0790581703186035
INFO:root:current mean train loss 3554.7785561490223
INFO:root:current train perplexity4.051807880401611
INFO:root:current mean train loss 3539.174591188006
INFO:root:current train perplexity4.036426544189453
INFO:root:current mean train loss 3536.470835397154
INFO:root:current train perplexity4.032099723815918
INFO:root:current mean train loss 3542.5065147860737
INFO:root:current train perplexity4.0329413414001465
INFO:root:current mean train loss 3536.924629727491
INFO:root:current train perplexity4.033044815063477
INFO:root:current mean train loss 3539.7340874649826
INFO:root:current train perplexity4.036374568939209
INFO:root:current mean train loss 3543.084476905016
INFO:root:current train perplexity4.036985397338867
INFO:root:current mean train loss 3545.6360416705097
INFO:root:current train perplexity4.040299892425537
INFO:root:current mean train loss 3543.1372980361502
INFO:root:current train perplexity4.0426812171936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it]
INFO:root:final mean train loss: 3540.167523476385
INFO:root:final train perplexity: 4.041833877563477
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 5712.631379818488
INFO:root:eval perplexity: 10.494529724121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:13:07<4:37:43, 141.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.236150568182
INFO:root:current train perplexity4.02746057510376
INFO:root:current mean train loss 3532.437411794355
INFO:root:current train perplexity4.026220798492432
INFO:root:current mean train loss 3526.4414081648283
INFO:root:current train perplexity4.020649433135986
INFO:root:current mean train loss 3531.150429825044
INFO:root:current train perplexity4.029404640197754
INFO:root:current mean train loss 3528.829050051511
INFO:root:current train perplexity4.033600807189941
INFO:root:current mean train loss 3531.4848487647805
INFO:root:current train perplexity4.033682346343994
INFO:root:current mean train loss 3532.2915299976144
INFO:root:current train perplexity4.032594203948975
INFO:root:current mean train loss 3534.7373661268625
INFO:root:current train perplexity4.032639503479004
INFO:root:current mean train loss 3535.831690880848
INFO:root:current train perplexity4.031924724578857
INFO:root:current mean train loss 3538.939778304974
INFO:root:current train perplexity4.0343475341796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.91s/it]
INFO:root:final mean train loss: 3534.5520202882826
INFO:root:final train perplexity: 4.032889366149902
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it]
INFO:root:eval mean loss: 5716.386951195265
INFO:root:eval perplexity: 10.510758399963379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:15:27<4:34:30, 140.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3527.1689336867557
INFO:root:current train perplexity3.9885828495025635
INFO:root:current mean train loss 3527.785075369057
INFO:root:current train perplexity4.008372783660889
INFO:root:current mean train loss 3518.8599069109437
INFO:root:current train perplexity4.01490592956543
INFO:root:current mean train loss 3519.153331746083
INFO:root:current train perplexity4.016780376434326
INFO:root:current mean train loss 3522.219931682809
INFO:root:current train perplexity4.014657974243164
INFO:root:current mean train loss 3523.79270119269
INFO:root:current train perplexity4.017028331756592
INFO:root:current mean train loss 3528.3235680765697
INFO:root:current train perplexity4.021173000335693
INFO:root:current mean train loss 3531.5289081058527
INFO:root:current train perplexity4.024797439575195
INFO:root:current mean train loss 3531.0264843071045
INFO:root:current train perplexity4.023432731628418
INFO:root:current mean train loss 3531.0064754307828
INFO:root:current train perplexity4.023671627044678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.17s/it]
INFO:root:final mean train loss: 3529.002109096896
INFO:root:final train perplexity: 4.024068355560303
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.91s/it]
INFO:root:eval mean loss: 5723.915303670004
INFO:root:eval perplexity: 10.543374061584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:17:46<4:31:06, 140.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3496.1694851727552
INFO:root:current train perplexity3.9907872676849365
INFO:root:current mean train loss 3509.11394371345
INFO:root:current train perplexity3.9935522079467773
INFO:root:current mean train loss 3505.6120668530903
INFO:root:current train perplexity3.9928805828094482
INFO:root:current mean train loss 3508.4070903438765
INFO:root:current train perplexity3.9989707469940186
INFO:root:current mean train loss 3511.889688350086
INFO:root:current train perplexity4.000022888183594
INFO:root:current mean train loss 3517.172193537243
INFO:root:current train perplexity4.003521919250488
INFO:root:current mean train loss 3521.3294137423154
INFO:root:current train perplexity4.007750511169434
INFO:root:current mean train loss 3525.0670439921773
INFO:root:current train perplexity4.009427547454834
INFO:root:current mean train loss 3525.6182447886767
INFO:root:current train perplexity4.011794567108154
INFO:root:current mean train loss 3524.2511865083516
INFO:root:current train perplexity4.012256145477295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.70s/it]
INFO:root:final mean train loss: 3521.3076623485936
INFO:root:final train perplexity: 4.011870384216309
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it]
INFO:root:eval mean loss: 5719.599686856755
INFO:root:eval perplexity: 10.524662971496582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [3:20:05<4:28:02, 139.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.205143023141
INFO:root:current train perplexity4.0048651695251465
INFO:root:current mean train loss 3502.9734855097763
INFO:root:current train perplexity4.000357627868652
INFO:root:current mean train loss 3515.5406761032705
INFO:root:current train perplexity4.001791954040527
INFO:root:current mean train loss 3518.3013777518963
INFO:root:current train perplexity3.9985764026641846
INFO:root:current mean train loss 3518.150995624837
INFO:root:current train perplexity4.0000762939453125
INFO:root:current mean train loss 3517.3322686440792
INFO:root:current train perplexity4.00270414352417
INFO:root:current mean train loss 3516.072575564939
INFO:root:current train perplexity4.003760814666748
INFO:root:current mean train loss 3518.628764592025
INFO:root:current train perplexity4.004873275756836
INFO:root:current mean train loss 3520.287124651148
INFO:root:current train perplexity4.005163192749023
INFO:root:current mean train loss 3520.951488833871
INFO:root:current train perplexity4.005556106567383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.37s/it]
INFO:root:final mean train loss: 3517.7011727363833
INFO:root:final train perplexity: 4.006167411804199
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 5729.635069704342
INFO:root:eval perplexity: 10.568216323852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [3:22:24<4:25:22, 139.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.301308818247
INFO:root:current train perplexity3.961177110671997
INFO:root:current mean train loss 3485.8593475831385
INFO:root:current train perplexity3.9666099548339844
INFO:root:current mean train loss 3490.789709004791
INFO:root:current train perplexity3.9833264350891113
INFO:root:current mean train loss 3495.7691855418284
INFO:root:current train perplexity3.983588218688965
INFO:root:current mean train loss 3499.293251491915
INFO:root:current train perplexity3.9835398197174072
INFO:root:current mean train loss 3505.6103806763736
INFO:root:current train perplexity3.9876556396484375
INFO:root:current mean train loss 3506.4785056745814
INFO:root:current train perplexity3.9879114627838135
INFO:root:current mean train loss 3510.454902232072
INFO:root:current train perplexity3.9935407638549805
INFO:root:current mean train loss 3511.56439972784
INFO:root:current train perplexity3.9937620162963867
INFO:root:current mean train loss 3513.2810842713084
INFO:root:current train perplexity3.994734048843384

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.98s/it]
INFO:root:final mean train loss: 3510.6969161495085
INFO:root:final train perplexity: 3.9951117038726807
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it]
INFO:root:eval mean loss: 5726.422133759824
INFO:root:eval perplexity: 10.554253578186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [3:24:39<4:20:10, 138.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.910880962171
INFO:root:current train perplexity3.95967173576355
INFO:root:current mean train loss 3514.64986728766
INFO:root:current train perplexity3.9775915145874023
INFO:root:current mean train loss 3512.7019953323625
INFO:root:current train perplexity3.9834470748901367
INFO:root:current mean train loss 3504.1399562401107
INFO:root:current train perplexity3.9792420864105225
INFO:root:current mean train loss 3503.8224219736426
INFO:root:current train perplexity3.9789958000183105
INFO:root:current mean train loss 3505.6815142463233
INFO:root:current train perplexity3.977372884750366
INFO:root:current mean train loss 3504.605562893435
INFO:root:current train perplexity3.9789958000183105
INFO:root:current mean train loss 3506.182162686714
INFO:root:current train perplexity3.983243465423584
INFO:root:current mean train loss 3508.2080045391062
INFO:root:current train perplexity3.986968755722046

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.56s/it]
INFO:root:final mean train loss: 3506.289579022315
INFO:root:final train perplexity: 3.988171100616455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 5737.168435102451
INFO:root:eval perplexity: 10.601032257080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [3:26:54<4:16:20, 137.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.156982421875
INFO:root:current train perplexity4.084653854370117
INFO:root:current mean train loss 3512.591860873028
INFO:root:current train perplexity3.9774715900421143
INFO:root:current mean train loss 3498.8725886603293
INFO:root:current train perplexity3.965287685394287
INFO:root:current mean train loss 3493.8307646194307
INFO:root:current train perplexity3.9595065116882324
INFO:root:current mean train loss 3499.1236999360267
INFO:root:current train perplexity3.969935894012451
INFO:root:current mean train loss 3499.4315663635375
INFO:root:current train perplexity3.973128318786621
INFO:root:current mean train loss 3500.3618321964395
INFO:root:current train perplexity3.972278356552124
INFO:root:current mean train loss 3496.357367698702
INFO:root:current train perplexity3.970412492752075
INFO:root:current mean train loss 3498.7982501532338
INFO:root:current train perplexity3.9710748195648193
INFO:root:current mean train loss 3499.852130809628
INFO:root:current train perplexity3.9759597778320312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.94s/it]
INFO:root:final mean train loss: 3499.2159238630725
INFO:root:final train perplexity: 3.9770562648773193
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it]
INFO:root:eval mean loss: 5731.8555418459955
INFO:root:eval perplexity: 10.577880859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [3:29:10<4:13:32, 137.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.343172940341
INFO:root:current train perplexity3.9135143756866455
INFO:root:current mean train loss 3486.566016944679
INFO:root:current train perplexity3.9570093154907227
INFO:root:current mean train loss 3484.5274675559094
INFO:root:current train perplexity3.956822633743286
INFO:root:current mean train loss 3481.5779703514368
INFO:root:current train perplexity3.9557034969329834
INFO:root:current mean train loss 3481.131965433014
INFO:root:current train perplexity3.951120138168335
INFO:root:current mean train loss 3483.580700659705
INFO:root:current train perplexity3.9530880451202393
INFO:root:current mean train loss 3486.1220359490076
INFO:root:current train perplexity3.9601213932037354
INFO:root:current mean train loss 3492.2501610435347
INFO:root:current train perplexity3.9618728160858154
INFO:root:current mean train loss 3491.8333684542617
INFO:root:current train perplexity3.9629058837890625
INFO:root:current mean train loss 3494.5735356386353
INFO:root:current train perplexity3.9666812419891357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.34s/it]
INFO:root:final mean train loss: 3494.2698799871628
INFO:root:final train perplexity: 3.9693033695220947
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 5738.466378765906
INFO:root:eval perplexity: 10.606693267822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [3:31:29<4:12:08, 137.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3448.1294073807567
INFO:root:current train perplexity3.9909536838531494
INFO:root:current mean train loss 3485.934227694984
INFO:root:current train perplexity3.9398226737976074
INFO:root:current mean train loss 3500.731493248787
INFO:root:current train perplexity3.949362277984619
INFO:root:current mean train loss 3496.2229531984717
INFO:root:current train perplexity3.9540226459503174
INFO:root:current mean train loss 3496.4956305237547
INFO:root:current train perplexity3.9525649547576904
INFO:root:current mean train loss 3494.7029457753792
INFO:root:current train perplexity3.9536197185516357
INFO:root:current mean train loss 3491.266665062727
INFO:root:current train perplexity3.9542975425720215
INFO:root:current mean train loss 3488.4700440471793
INFO:root:current train perplexity3.95818829536438
INFO:root:current mean train loss 3489.9996741810705
INFO:root:current train perplexity3.9599387645721436
INFO:root:current mean train loss 3493.568064227846
INFO:root:current train perplexity3.962881326675415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.94s/it]
INFO:root:final mean train loss: 3489.7700129478208
INFO:root:final train perplexity: 3.9622628688812256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5736.132841738398
INFO:root:eval perplexity: 10.596516609191895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [3:33:45<4:08:57, 137.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.8162977430557
INFO:root:current train perplexity3.9752328395843506
INFO:root:current mean train loss 3477.6478319543553
INFO:root:current train perplexity3.9431211948394775
INFO:root:current mean train loss 3477.281106957255
INFO:root:current train perplexity3.9468700885772705
INFO:root:current mean train loss 3479.065894077313
INFO:root:current train perplexity3.9462151527404785
INFO:root:current mean train loss 3474.0015992068575
INFO:root:current train perplexity3.9445676803588867
INFO:root:current mean train loss 3480.1890927048744
INFO:root:current train perplexity3.9497714042663574
INFO:root:current mean train loss 3482.449342572518
INFO:root:current train perplexity3.9489753246307373
INFO:root:current mean train loss 3485.018092600155
INFO:root:current train perplexity3.951392412185669
INFO:root:current mean train loss 3485.624437915659
INFO:root:current train perplexity3.9531965255737305
INFO:root:current mean train loss 3485.703746281267
INFO:root:current train perplexity3.952991008758545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.07s/it]
INFO:root:final mean train loss: 3484.0431895717497
INFO:root:final train perplexity: 3.9533207416534424
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it]
INFO:root:eval mean loss: 5749.997201885292
INFO:root:eval perplexity: 10.657144546508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [3:36:01<4:06:19, 136.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.639906529018
INFO:root:current train perplexity3.9277970790863037
INFO:root:current mean train loss 3473.316525607639
INFO:root:current train perplexity3.9326610565185547
INFO:root:current mean train loss 3480.5441468583776
INFO:root:current train perplexity3.943559169769287
INFO:root:current mean train loss 3482.8616764808767
INFO:root:current train perplexity3.9441909790039062
INFO:root:current mean train loss 3485.9742513020833
INFO:root:current train perplexity3.947935104370117
INFO:root:current mean train loss 3486.3057932060456
INFO:root:current train perplexity3.9489376544952393
INFO:root:current mean train loss 3481.851934285802
INFO:root:current train perplexity3.9432170391082764
INFO:root:current mean train loss 3478.7564615885417
INFO:root:current train perplexity3.941788673400879
INFO:root:current mean train loss 3480.7344931231287
INFO:root:current train perplexity3.944143533706665
INFO:root:current mean train loss 3480.013198999415
INFO:root:current train perplexity3.9430384635925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.20s/it]
INFO:root:final mean train loss: 3479.7666601980886
INFO:root:final train perplexity: 3.9466559886932373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it]
INFO:root:eval mean loss: 5746.2268782747005
INFO:root:eval perplexity: 10.640625953674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [3:38:17<4:03:19, 136.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.4965422874275
INFO:root:current train perplexity3.914163827896118
INFO:root:current mean train loss 3474.3112349076705
INFO:root:current train perplexity3.913543224334717
INFO:root:current mean train loss 3466.462454587834
INFO:root:current train perplexity3.9262073040008545
INFO:root:current mean train loss 3467.5768074947614
INFO:root:current train perplexity3.926715612411499
INFO:root:current mean train loss 3466.4171757062995
INFO:root:current train perplexity3.9261739253997803
INFO:root:current mean train loss 3467.0378161688536
INFO:root:current train perplexity3.9269168376922607
INFO:root:current mean train loss 3469.109958583422
INFO:root:current train perplexity3.9315454959869385
INFO:root:current mean train loss 3474.759661134127
INFO:root:current train perplexity3.9342362880706787
INFO:root:current mean train loss 3475.14382518257
INFO:root:current train perplexity3.935262441635132
INFO:root:current mean train loss 3475.9445896573434
INFO:root:current train perplexity3.936444044113159

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.89s/it]
INFO:root:final mean train loss: 3473.4087892347766
INFO:root:final train perplexity: 3.9367687702178955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.99s/it]
INFO:root:eval mean loss: 5748.87939306933
INFO:root:eval perplexity: 10.652246475219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [3:40:38<4:03:20, 137.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.710090188419
INFO:root:current train perplexity3.9302549362182617
INFO:root:current mean train loss 3468.991977312707
INFO:root:current train perplexity3.9222874641418457
INFO:root:current mean train loss 3470.3679782821837
INFO:root:current train perplexity3.9256787300109863
INFO:root:current mean train loss 3469.6839199663905
INFO:root:current train perplexity3.915761947631836
INFO:root:current mean train loss 3467.3042187066935
INFO:root:current train perplexity3.917092800140381
INFO:root:current mean train loss 3470.5065377403303
INFO:root:current train perplexity3.9242658615112305
INFO:root:current mean train loss 3470.3312466997886
INFO:root:current train perplexity3.9276552200317383
INFO:root:current mean train loss 3470.3569469223326
INFO:root:current train perplexity3.926436185836792
INFO:root:current mean train loss 3470.1965323424647
INFO:root:current train perplexity3.927813768386841
INFO:root:current mean train loss 3471.53294691854
INFO:root:current train perplexity3.9308810234069824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.01s/it]
INFO:root:final mean train loss: 3467.9037596794865
INFO:root:final train perplexity: 3.9282279014587402
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 5753.673312067272
INFO:root:eval perplexity: 10.673277854919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [3:42:57<4:01:47, 138.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.404094114142
INFO:root:current train perplexity3.8730673789978027
INFO:root:current mean train loss 3444.6511583628144
INFO:root:current train perplexity3.8801991939544678
INFO:root:current mean train loss 3448.024426316663
INFO:root:current train perplexity3.888817310333252
INFO:root:current mean train loss 3455.761119619385
INFO:root:current train perplexity3.898071527481079
INFO:root:current mean train loss 3456.9348176445055
INFO:root:current train perplexity3.9018054008483887
INFO:root:current mean train loss 3461.6157689512524
INFO:root:current train perplexity3.90641188621521
INFO:root:current mean train loss 3460.9994179894966
INFO:root:current train perplexity3.9090378284454346
INFO:root:current mean train loss 3463.87708854424
INFO:root:current train perplexity3.913025140762329
INFO:root:current mean train loss 3466.6097055419636
INFO:root:current train perplexity3.917553424835205
INFO:root:current mean train loss 3467.264930255719
INFO:root:current train perplexity3.9198265075683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.53s/it]
INFO:root:final mean train loss: 3462.8664737209197
INFO:root:final train perplexity: 3.92042875289917
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 5757.852619468095
INFO:root:eval perplexity: 10.691651344299316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [3:45:14<3:58:44, 137.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.8964515799908
INFO:root:current train perplexity3.9448211193084717
INFO:root:current mean train loss 3461.209588147923
INFO:root:current train perplexity3.915714740753174
INFO:root:current mean train loss 3468.231981141737
INFO:root:current train perplexity3.919560194015503
INFO:root:current mean train loss 3465.301547598774
INFO:root:current train perplexity3.9130661487579346
INFO:root:current mean train loss 3462.1649104573744
INFO:root:current train perplexity3.911435604095459
INFO:root:current mean train loss 3459.3732458043983
INFO:root:current train perplexity3.9107260704040527
INFO:root:current mean train loss 3460.1995276775674
INFO:root:current train perplexity3.9104244709014893
INFO:root:current mean train loss 3458.424956519414
INFO:root:current train perplexity3.912860870361328
INFO:root:current mean train loss 3462.363382904862
INFO:root:current train perplexity3.9154107570648193
INFO:root:current mean train loss 3462.0031867042076
INFO:root:current train perplexity3.9157040119171143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.45s/it]
INFO:root:final mean train loss: 3459.5729661756945
INFO:root:final train perplexity: 3.9153380393981934
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5764.305516408589
INFO:root:eval perplexity: 10.720081329345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [3:47:29<3:55:15, 137.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.3413997395833
INFO:root:current train perplexity3.914353847503662
INFO:root:current mean train loss 3444.5756668526788
INFO:root:current train perplexity3.898883104324341
INFO:root:current mean train loss 3455.7063893821023
INFO:root:current train perplexity3.896641969680786
INFO:root:current mean train loss 3459.687244140625
INFO:root:current train perplexity3.8982598781585693
INFO:root:current mean train loss 3457.07943307977
INFO:root:current train perplexity3.9013044834136963
INFO:root:current mean train loss 3453.2516953974186
INFO:root:current train perplexity3.9032771587371826
INFO:root:current mean train loss 3457.8120699508104
INFO:root:current train perplexity3.9052112102508545
INFO:root:current mean train loss 3456.250601373488
INFO:root:current train perplexity3.9048871994018555
INFO:root:current mean train loss 3457.890283203125
INFO:root:current train perplexity3.90641188621521
INFO:root:current mean train loss 3456.570083633814
INFO:root:current train perplexity3.9078147411346436

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.25s/it]
INFO:root:final mean train loss: 3454.9219066250707
INFO:root:final train perplexity: 3.9081599712371826
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it]
INFO:root:eval mean loss: 5762.702679114427
INFO:root:eval perplexity: 10.713011741638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [3:49:54<3:56:59, 139.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.6874676440134
INFO:root:current train perplexity3.874081611633301
INFO:root:current mean train loss 3435.55922478014
INFO:root:current train perplexity3.886910915374756
INFO:root:current mean train loss 3450.0216560498566
INFO:root:current train perplexity3.8889832496643066
INFO:root:current mean train loss 3450.896280393277
INFO:root:current train perplexity3.886817455291748
INFO:root:current mean train loss 3450.783836980784
INFO:root:current train perplexity3.8897504806518555
INFO:root:current mean train loss 3450.4660837163647
INFO:root:current train perplexity3.8917384147644043
INFO:root:current mean train loss 3452.0190036488834
INFO:root:current train perplexity3.8954544067382812
INFO:root:current mean train loss 3449.6404815712804
INFO:root:current train perplexity3.894864797592163
INFO:root:current mean train loss 3450.757493430599
INFO:root:current train perplexity3.8954293727874756
INFO:root:current mean train loss 3451.194809565345
INFO:root:current train perplexity3.897822141647339

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.42s/it]
INFO:root:final mean train loss: 3448.4038899944676
INFO:root:final train perplexity: 3.898122787475586
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.20s/it]
INFO:root:eval mean loss: 5766.102305155315
INFO:root:eval perplexity: 10.728009223937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [3:52:10<3:53:11, 138.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.7860147664837
INFO:root:current train perplexity3.8446030616760254
INFO:root:current mean train loss 3428.0903806037304
INFO:root:current train perplexity3.8540616035461426
INFO:root:current mean train loss 3432.7476836004616
INFO:root:current train perplexity3.8665785789489746
INFO:root:current mean train loss 3438.318316915761
INFO:root:current train perplexity3.8747036457061768
INFO:root:current mean train loss 3439.57877836208
INFO:root:current train perplexity3.877605438232422
INFO:root:current mean train loss 3439.96579552665
INFO:root:current train perplexity3.877533435821533
INFO:root:current mean train loss 3442.019526656906
INFO:root:current train perplexity3.881040096282959
INFO:root:current mean train loss 3443.1722873538242
INFO:root:current train perplexity3.883810520172119
INFO:root:current mean train loss 3442.344987691586
INFO:root:current train perplexity3.885805606842041
INFO:root:current mean train loss 3446.36282154626
INFO:root:current train perplexity3.890871524810791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.73s/it]
INFO:root:final mean train loss: 3443.6319541931152
INFO:root:final train perplexity: 3.8907902240753174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it]
INFO:root:eval mean loss: 5777.167746538174
INFO:root:eval perplexity: 10.77697467803955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [3:54:30<3:51:32, 138.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.51162257339
INFO:root:current train perplexity3.853628635406494
INFO:root:current mean train loss 3425.4024676605686
INFO:root:current train perplexity3.871241331100464
INFO:root:current mean train loss 3428.242192399143
INFO:root:current train perplexity3.872269630432129
INFO:root:current mean train loss 3425.9078953487233
INFO:root:current train perplexity3.8685851097106934
INFO:root:current mean train loss 3431.905539105555
INFO:root:current train perplexity3.871856212615967
INFO:root:current mean train loss 3434.06040422188
INFO:root:current train perplexity3.875338315963745
INFO:root:current mean train loss 3439.0717679134254
INFO:root:current train perplexity3.8794965744018555
INFO:root:current mean train loss 3442.4056853293177
INFO:root:current train perplexity3.8818910121917725
INFO:root:current mean train loss 3442.1575323493116
INFO:root:current train perplexity3.883483648300171

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.01s/it]
INFO:root:final mean train loss: 3439.2851984577796
INFO:root:final train perplexity: 3.884124517440796
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it]
INFO:root:eval mean loss: 5775.511462914015
INFO:root:eval perplexity: 10.769630432128906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [3:56:46<3:47:26, 137.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.0341796875
INFO:root:current train perplexity3.851259469985962
INFO:root:current mean train loss 3454.8194363317757
INFO:root:current train perplexity3.873145580291748
INFO:root:current mean train loss 3441.849040892965
INFO:root:current train perplexity3.8660356998443604
INFO:root:current mean train loss 3433.844233509772
INFO:root:current train perplexity3.872150182723999
INFO:root:current mean train loss 3440.0037568863254
INFO:root:current train perplexity3.875899314880371
INFO:root:current mean train loss 3439.0812333387266
INFO:root:current train perplexity3.877708911895752
INFO:root:current mean train loss 3437.525574434334
INFO:root:current train perplexity3.874582529067993
INFO:root:current mean train loss 3436.429105982585
INFO:root:current train perplexity3.875088930130005
INFO:root:current mean train loss 3437.4102603198576
INFO:root:current train perplexity3.8768539428710938
INFO:root:current mean train loss 3436.7504484435294
INFO:root:current train perplexity3.8779280185699463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.60s/it]
INFO:root:final mean train loss: 3435.169730032644
INFO:root:final train perplexity: 3.8778226375579834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 5778.9113535624065
INFO:root:eval perplexity: 10.784708023071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [3:59:02<3:44:39, 137.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3418.1592610677085
INFO:root:current train perplexity3.8276240825653076
INFO:root:current mean train loss 3409.2142195991846
INFO:root:current train perplexity3.820544958114624
INFO:root:current mean train loss 3410.807080078125
INFO:root:current train perplexity3.8351218700408936
INFO:root:current mean train loss 3427.398103453621
INFO:root:current train perplexity3.852369785308838
INFO:root:current mean train loss 3432.84765625
INFO:root:current train perplexity3.8574836254119873
INFO:root:current mean train loss 3428.6037370107706
INFO:root:current train perplexity3.8552322387695312
INFO:root:current mean train loss 3430.827498570884
INFO:root:current train perplexity3.859370708465576
INFO:root:current mean train loss 3429.261722164554
INFO:root:current train perplexity3.8621392250061035
INFO:root:current mean train loss 3429.1969130439993
INFO:root:current train perplexity3.8644893169403076
INFO:root:current mean train loss 3430.039822938012
INFO:root:current train perplexity3.866581678390503

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.76s/it]
INFO:root:final mean train loss: 3429.863104051159
INFO:root:final train perplexity: 3.869713306427002
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 5777.49153694564
INFO:root:eval perplexity: 10.778410911560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [4:01:50<3:56:44, 146.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.450333305027
INFO:root:current train perplexity3.8197524547576904
INFO:root:current mean train loss 3413.8763854484246
INFO:root:current train perplexity3.829289436340332
INFO:root:current mean train loss 3418.293961734515
INFO:root:current train perplexity3.8413097858428955
INFO:root:current mean train loss 3416.605788475958
INFO:root:current train perplexity3.8441591262817383
INFO:root:current mean train loss 3415.674162303302
INFO:root:current train perplexity3.8464794158935547
INFO:root:current mean train loss 3419.9482748640653
INFO:root:current train perplexity3.8545289039611816
INFO:root:current mean train loss 3423.3552994582665
INFO:root:current train perplexity3.858854055404663
INFO:root:current mean train loss 3425.5594217345265
INFO:root:current train perplexity3.8628551959991455
INFO:root:current mean train loss 3426.2044566491686
INFO:root:current train perplexity3.862694501876831
INFO:root:current mean train loss 3426.8202564243634
INFO:root:current train perplexity3.8612594604492188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.36s/it]
INFO:root:final mean train loss: 3425.7962701243737
INFO:root:final train perplexity: 3.863508701324463
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it]
INFO:root:eval mean loss: 5782.603628192833
INFO:root:eval perplexity: 10.801107406616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [4:04:10<3:51:12, 144.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.1800891507055
INFO:root:current train perplexity3.8106887340545654
INFO:root:current mean train loss 3393.8955637225667
INFO:root:current train perplexity3.823465347290039
INFO:root:current mean train loss 3390.8295021222266
INFO:root:current train perplexity3.830860137939453
INFO:root:current mean train loss 3401.1879322247923
INFO:root:current train perplexity3.8411004543304443
INFO:root:current mean train loss 3403.1173189167635
INFO:root:current train perplexity3.8416354656219482
INFO:root:current mean train loss 3408.4520495858346
INFO:root:current train perplexity3.844867706298828
INFO:root:current mean train loss 3413.7754885133963
INFO:root:current train perplexity3.8478245735168457
INFO:root:current mean train loss 3416.244855345845
INFO:root:current train perplexity3.8501384258270264
INFO:root:current mean train loss 3422.426186682085
INFO:root:current train perplexity3.8562064170837402
INFO:root:current mean train loss 3422.1160192438406
INFO:root:current train perplexity3.854213237762451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.75s/it]
INFO:root:final mean train loss: 3420.8864839000084
INFO:root:final train perplexity: 3.856032133102417
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5783.877648998877
INFO:root:eval perplexity: 10.806774139404297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [4:06:26<3:45:09, 142.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3402.2406037159453
INFO:root:current train perplexity3.8452320098876953
INFO:root:current mean train loss 3417.498737143098
INFO:root:current train perplexity3.8413302898406982
INFO:root:current mean train loss 3413.7376744737185
INFO:root:current train perplexity3.844708204269409
INFO:root:current mean train loss 3424.217214578724
INFO:root:current train perplexity3.8481810092926025
INFO:root:current mean train loss 3420.0414393952874
INFO:root:current train perplexity3.8444111347198486
INFO:root:current mean train loss 3418.8715842960055
INFO:root:current train perplexity3.8441948890686035
INFO:root:current mean train loss 3421.30790717613
INFO:root:current train perplexity3.8452165126800537
INFO:root:current mean train loss 3422.195708939445
INFO:root:current train perplexity3.846876621246338
INFO:root:current mean train loss 3419.685891698171
INFO:root:current train perplexity3.8461451530456543
INFO:root:current mean train loss 3419.135337106463
INFO:root:current train perplexity3.847695827484131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.70s/it]
INFO:root:final mean train loss: 3415.875528766263
INFO:root:final train perplexity: 3.848416805267334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it]
INFO:root:eval mean loss: 5785.7949291846
INFO:root:eval perplexity: 10.815303802490234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [4:08:43<3:39:58, 140.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.659880942487
INFO:root:current train perplexity3.797168254852295
INFO:root:current mean train loss 3392.5824614025296
INFO:root:current train perplexity3.8277909755706787
INFO:root:current mean train loss 3393.245942521192
INFO:root:current train perplexity3.8225207328796387
INFO:root:current mean train loss 3396.8486785448936
INFO:root:current train perplexity3.8280625343322754
INFO:root:current mean train loss 3402.66380306645
INFO:root:current train perplexity3.826875925064087
INFO:root:current mean train loss 3409.7675272437727
INFO:root:current train perplexity3.832984209060669
INFO:root:current mean train loss 3411.927734375
INFO:root:current train perplexity3.8351945877075195
INFO:root:current mean train loss 3410.7738486498074
INFO:root:current train perplexity3.8358712196350098
INFO:root:current mean train loss 3413.5311413329214
INFO:root:current train perplexity3.840693950653076
INFO:root:current mean train loss 3412.858091650442
INFO:root:current train perplexity3.840733766555786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.12s/it]
INFO:root:final mean train loss: 3411.509779591714
INFO:root:final train perplexity: 3.8417932987213135
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5793.058874438623
INFO:root:eval perplexity: 10.847679138183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [4:10:59<3:35:40, 139.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.9141468394887
INFO:root:current train perplexity3.8136229515075684
INFO:root:current mean train loss 3398.7735540574595
INFO:root:current train perplexity3.815425157546997
INFO:root:current mean train loss 3392.9773226868874
INFO:root:current train perplexity3.8186357021331787
INFO:root:current mean train loss 3402.8298374229753
INFO:root:current train perplexity3.8249757289886475
INFO:root:current mean train loss 3406.4454820570054
INFO:root:current train perplexity3.8239901065826416
INFO:root:current mean train loss 3404.8084622219876
INFO:root:current train perplexity3.8273234367370605
INFO:root:current mean train loss 3405.1585788406487
INFO:root:current train perplexity3.830176591873169
INFO:root:current mean train loss 3408.0872125284563
INFO:root:current train perplexity3.829674243927002
INFO:root:current mean train loss 3407.291236636513
INFO:root:current train perplexity3.829512119293213
INFO:root:current mean train loss 3410.1453219588516
INFO:root:current train perplexity3.8344790935516357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.96s/it]
INFO:root:final mean train loss: 3406.300101126394
INFO:root:final train perplexity: 3.8339054584503174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it]
INFO:root:eval mean loss: 5794.504920822417
INFO:root:eval perplexity: 10.85413932800293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [4:13:17<3:32:56, 138.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.5279870411705
INFO:root:current train perplexity3.811753988265991
INFO:root:current mean train loss 3377.1497915069017
INFO:root:current train perplexity3.823091745376587
INFO:root:current mean train loss 3384.1547443114305
INFO:root:current train perplexity3.817307233810425
INFO:root:current mean train loss 3392.6724628206784
INFO:root:current train perplexity3.8244805335998535
INFO:root:current mean train loss 3396.8835612682237
INFO:root:current train perplexity3.8191146850585938
INFO:root:current mean train loss 3401.101239002831
INFO:root:current train perplexity3.823462724685669
INFO:root:current mean train loss 3403.7797903115575
INFO:root:current train perplexity3.824406862258911
INFO:root:current mean train loss 3404.257020562848
INFO:root:current train perplexity3.8247172832489014
INFO:root:current mean train loss 3404.1334040388724
INFO:root:current train perplexity3.8268630504608154
INFO:root:current mean train loss 3406.156249492958
INFO:root:current train perplexity3.8302102088928223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.87s/it]
INFO:root:final mean train loss: 3403.69351713119
INFO:root:final train perplexity: 3.8299646377563477
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.31s/it]
INFO:root:eval mean loss: 5798.133163360779
INFO:root:eval perplexity: 10.870356559753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [4:16:05<3:43:49, 147.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.523698833627
INFO:root:current train perplexity3.78983998298645
INFO:root:current mean train loss 3379.3400107935854
INFO:root:current train perplexity3.80511736869812
INFO:root:current mean train loss 3381.5507452144834
INFO:root:current train perplexity3.8068854808807373
INFO:root:current mean train loss 3386.580001789926
INFO:root:current train perplexity3.803295850753784
INFO:root:current mean train loss 3390.833674404525
INFO:root:current train perplexity3.812256097793579
INFO:root:current mean train loss 3394.8179091471925
INFO:root:current train perplexity3.8187668323516846
INFO:root:current mean train loss 3396.188166929606
INFO:root:current train perplexity3.8199996948242188
INFO:root:current mean train loss 3398.0121813822348
INFO:root:current train perplexity3.820751190185547
INFO:root:current mean train loss 3399.4160733666404
INFO:root:current train perplexity3.8218536376953125
INFO:root:current mean train loss 3401.5335309925335
INFO:root:current train perplexity3.8243813514709473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.78s/it]
INFO:root:final mean train loss: 3399.72979810161
INFO:root:final train perplexity: 3.8239800930023193
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it]
INFO:root:eval mean loss: 5802.476654600954
INFO:root:eval perplexity: 10.889803886413574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [4:18:22<3:36:36, 144.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.9841432209255
INFO:root:current train perplexity3.7938711643218994
INFO:root:current mean train loss 3392.549036803858
INFO:root:current train perplexity3.79715633392334
INFO:root:current mean train loss 3399.238089612735
INFO:root:current train perplexity3.8101096153259277
INFO:root:current mean train loss 3401.0231379607108
INFO:root:current train perplexity3.8146724700927734
INFO:root:current mean train loss 3402.4729391269248
INFO:root:current train perplexity3.8119325637817383
INFO:root:current mean train loss 3398.5471735346505
INFO:root:current train perplexity3.808187246322632
INFO:root:current mean train loss 3399.331619195278
INFO:root:current train perplexity3.8097996711730957
INFO:root:current mean train loss 3396.1487869438984
INFO:root:current train perplexity3.8111610412597656
INFO:root:current mean train loss 3396.010375282192
INFO:root:current train perplexity3.814880609512329
INFO:root:current mean train loss 3397.8474273214056
INFO:root:current train perplexity3.817704439163208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.63s/it]
INFO:root:final mean train loss: 3395.2898109189928
INFO:root:final train perplexity: 3.8172872066497803
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 5798.596955990363
INFO:root:eval perplexity: 10.872432708740234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [4:20:38<3:30:22, 141.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.9619280935704
INFO:root:current train perplexity3.7970755100250244
INFO:root:current mean train loss 3393.574951171875
INFO:root:current train perplexity3.79836106300354
INFO:root:current mean train loss 3393.3095669098434
INFO:root:current train perplexity3.805541515350342
INFO:root:current mean train loss 3390.1742192546835
INFO:root:current train perplexity3.80108380317688
INFO:root:current mean train loss 3388.9923815090797
INFO:root:current train perplexity3.8040194511413574
INFO:root:current mean train loss 3389.687197631628
INFO:root:current train perplexity3.8078091144561768
INFO:root:current mean train loss 3393.4128073257825
INFO:root:current train perplexity3.811110734939575
INFO:root:current mean train loss 3391.105121617396
INFO:root:current train perplexity3.810941219329834
INFO:root:current mean train loss 3393.0035817383914
INFO:root:current train perplexity3.8116190433502197
INFO:root:current mean train loss 3393.674586519282
INFO:root:current train perplexity3.810594081878662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.26s/it]
INFO:root:final mean train loss: 3390.762935699955
INFO:root:final train perplexity: 3.8104755878448486
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5806.45018361714
INFO:root:eval perplexity: 10.907626152038574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [4:22:57<3:26:50, 141.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.200066817434
INFO:root:current train perplexity3.784613609313965
INFO:root:current mean train loss 3361.646202674279
INFO:root:current train perplexity3.7895147800445557
INFO:root:current mean train loss 3369.19533732786
INFO:root:current train perplexity3.7894632816314697
INFO:root:current mean train loss 3379.181426770174
INFO:root:current train perplexity3.798255205154419
INFO:root:current mean train loss 3380.7294902146464
INFO:root:current train perplexity3.799595594406128
INFO:root:current mean train loss 3379.359932625394
INFO:root:current train perplexity3.7979722023010254
INFO:root:current mean train loss 3383.5720116484936
INFO:root:current train perplexity3.8019182682037354
INFO:root:current mean train loss 3386.948069292944
INFO:root:current train perplexity3.8045971393585205
INFO:root:current mean train loss 3387.957137908083
INFO:root:current train perplexity3.80592679977417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.67s/it]
INFO:root:final mean train loss: 3387.7986978715467
INFO:root:final train perplexity: 3.8060221672058105
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.90s/it]
INFO:root:eval mean loss: 5814.344273367328
INFO:root:eval perplexity: 10.943117141723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [4:25:12<3:22:03, 139.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3326.5940755208335
INFO:root:current train perplexity3.8437013626098633
INFO:root:current mean train loss 3361.226920414897
INFO:root:current train perplexity3.7711377143859863
INFO:root:current mean train loss 3377.6737210879774
INFO:root:current train perplexity3.7893736362457275
INFO:root:current mean train loss 3375.8950968827353
INFO:root:current train perplexity3.7889816761016846
INFO:root:current mean train loss 3375.979005723674
INFO:root:current train perplexity3.7908287048339844
INFO:root:current mean train loss 3380.2905613195826
INFO:root:current train perplexity3.794280767440796
INFO:root:current mean train loss 3381.177172811075
INFO:root:current train perplexity3.794311285018921
INFO:root:current mean train loss 3382.0746837632246
INFO:root:current train perplexity3.7953875064849854
INFO:root:current mean train loss 3386.039175297225
INFO:root:current train perplexity3.7994489669799805
INFO:root:current mean train loss 3384.8480704509275
INFO:root:current train perplexity3.796858549118042

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.18s/it]
INFO:root:final mean train loss: 3382.3533579918644
INFO:root:final train perplexity: 3.797854423522949
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 5808.809229685161
INFO:root:eval perplexity: 10.918221473693848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [4:27:32<3:19:46, 139.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.2602095170455
INFO:root:current train perplexity3.7827959060668945
INFO:root:current mean train loss 3374.2301322318413
INFO:root:current train perplexity3.8039968013763428
INFO:root:current mean train loss 3369.8379889754888
INFO:root:current train perplexity3.796571731567383
INFO:root:current mean train loss 3376.973539395348
INFO:root:current train perplexity3.793315887451172
INFO:root:current mean train loss 3377.4621766176247
INFO:root:current train perplexity3.791501045227051
INFO:root:current mean train loss 3375.003479601119
INFO:root:current train perplexity3.7891387939453125
INFO:root:current mean train loss 3380.5975367769283
INFO:root:current train perplexity3.788452386856079
INFO:root:current mean train loss 3379.3849586025403
INFO:root:current train perplexity3.7888619899749756
INFO:root:current mean train loss 3376.798960280036
INFO:root:current train perplexity3.7866039276123047
INFO:root:current mean train loss 3378.448769327576
INFO:root:current train perplexity3.788099527359009

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.59s/it]
INFO:root:final mean train loss: 3378.1917314837056
INFO:root:final train perplexity: 3.791624069213867
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 5811.725834463885
INFO:root:eval perplexity: 10.931333541870117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [4:29:47<3:15:46, 138.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.5644788240133
INFO:root:current train perplexity3.7465109825134277
INFO:root:current mean train loss 3345.1929367450107
INFO:root:current train perplexity3.7698233127593994
INFO:root:current mean train loss 3361.088763511344
INFO:root:current train perplexity3.7732629776000977
INFO:root:current mean train loss 3368.2876190855213
INFO:root:current train perplexity3.777844190597534
INFO:root:current mean train loss 3368.5488287076746
INFO:root:current train perplexity3.7750396728515625
INFO:root:current mean train loss 3370.719582147911
INFO:root:current train perplexity3.7744815349578857
INFO:root:current mean train loss 3373.2073724158167
INFO:root:current train perplexity3.7793960571289062
INFO:root:current mean train loss 3376.9391173043073
INFO:root:current train perplexity3.78181791305542
INFO:root:current mean train loss 3377.3995249542127
INFO:root:current train perplexity3.7828195095062256
INFO:root:current mean train loss 3375.6054432467354
INFO:root:current train perplexity3.784804582595825

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.57s/it]
INFO:root:final mean train loss: 3374.813121241908
INFO:root:final train perplexity: 3.786573648452759
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.07s/it]
INFO:root:eval mean loss: 5818.558013367796
INFO:root:eval perplexity: 10.962111473083496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [4:32:05<3:13:10, 137.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.1415563512733
INFO:root:current train perplexity3.7929201126098633
INFO:root:current mean train loss 3379.928634042815
INFO:root:current train perplexity3.7784130573272705
INFO:root:current mean train loss 3376.8066223413407
INFO:root:current train perplexity3.7729175090789795
INFO:root:current mean train loss 3370.2295384771596
INFO:root:current train perplexity3.771209239959717
INFO:root:current mean train loss 3373.3144674189475
INFO:root:current train perplexity3.775576114654541
INFO:root:current mean train loss 3372.555962868388
INFO:root:current train perplexity3.7740697860717773
INFO:root:current mean train loss 3372.8065245900616
INFO:root:current train perplexity3.7741494178771973
INFO:root:current mean train loss 3372.8487805729883
INFO:root:current train perplexity3.776003122329712
INFO:root:current mean train loss 3372.095828885467
INFO:root:current train perplexity3.7758965492248535
INFO:root:current mean train loss 3372.6373774292915
INFO:root:current train perplexity3.7792468070983887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.49s/it]
INFO:root:final mean train loss: 3369.8657734163344
INFO:root:final train perplexity: 3.779189348220825
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.48s/it]
INFO:root:eval mean loss: 5817.380185429922
INFO:root:eval perplexity: 10.956796646118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [4:34:24<3:11:25, 138.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.1413225446427
INFO:root:current train perplexity3.7515413761138916
INFO:root:current mean train loss 3365.147184244792
INFO:root:current train perplexity3.755107879638672
INFO:root:current mean train loss 3361.510512591423
INFO:root:current train perplexity3.7613532543182373
INFO:root:current mean train loss 3367.39083124417
INFO:root:current train perplexity3.766289710998535
INFO:root:current mean train loss 3371.012261471803
INFO:root:current train perplexity3.769479990005493
INFO:root:current mean train loss 3370.8318637740945
INFO:root:current train perplexity3.7706286907196045
INFO:root:current mean train loss 3370.1049673966536
INFO:root:current train perplexity3.7735795974731445
INFO:root:current mean train loss 3371.534555697279
INFO:root:current train perplexity3.7737109661102295
INFO:root:current mean train loss 3370.9197005403257
INFO:root:current train perplexity3.774620294570923
INFO:root:current mean train loss 3370.760848199365
INFO:root:current train perplexity3.7764856815338135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.47s/it]
INFO:root:final mean train loss: 3367.717410856678
INFO:root:final train perplexity: 3.7759878635406494
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it]
INFO:root:eval mean loss: 5822.052272408308
INFO:root:eval perplexity: 10.977883338928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [4:36:42<3:09:07, 138.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.101579533067
INFO:root:current train perplexity3.75492525100708
INFO:root:current mean train loss 3348.637278736888
INFO:root:current train perplexity3.7417471408843994
INFO:root:current mean train loss 3348.7123802404835
INFO:root:current train perplexity3.7477924823760986
INFO:root:current mean train loss 3353.0499947328262
INFO:root:current train perplexity3.750504970550537
INFO:root:current mean train loss 3360.4264017970513
INFO:root:current train perplexity3.754183530807495
INFO:root:current mean train loss 3361.6404028904813
INFO:root:current train perplexity3.7564690113067627
INFO:root:current mean train loss 3363.9207165660237
INFO:root:current train perplexity3.761357307434082
INFO:root:current mean train loss 3365.1428623533184
INFO:root:current train perplexity3.764312982559204
INFO:root:current mean train loss 3364.090809017738
INFO:root:current train perplexity3.7685604095458984
INFO:root:current mean train loss 3364.928802846219
INFO:root:current train perplexity3.7683205604553223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.09s/it]
INFO:root:final mean train loss: 3362.6791202176
INFO:root:final train perplexity: 3.768488883972168
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it]
INFO:root:eval mean loss: 5827.898348322886
INFO:root:eval perplexity: 11.004325866699219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [4:39:04<3:08:04, 139.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.0971440333947
INFO:root:current train perplexity3.7586669921875
INFO:root:current mean train loss 3350.5372080013453
INFO:root:current train perplexity3.74780011177063
INFO:root:current mean train loss 3349.2178220710907
INFO:root:current train perplexity3.753384828567505
INFO:root:current mean train loss 3343.9055231425837
INFO:root:current train perplexity3.751807451248169
INFO:root:current mean train loss 3345.2582753386573
INFO:root:current train perplexity3.751011848449707
INFO:root:current mean train loss 3351.2294921875
INFO:root:current train perplexity3.7545058727264404
INFO:root:current mean train loss 3356.0366319694463
INFO:root:current train perplexity3.758333683013916
INFO:root:current mean train loss 3360.0357696898927
INFO:root:current train perplexity3.7617926597595215
INFO:root:current mean train loss 3359.537306179311
INFO:root:current train perplexity3.762326717376709
INFO:root:current mean train loss 3361.2583534088294
INFO:root:current train perplexity3.7630960941314697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.16s/it]
INFO:root:final mean train loss: 3359.3334968320787
INFO:root:final train perplexity: 3.7635183334350586
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it]
INFO:root:eval mean loss: 5827.015415945453
INFO:root:eval perplexity: 11.00032901763916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [4:41:20<3:04:34, 138.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.0181905455506
INFO:root:current train perplexity3.73071026802063
INFO:root:current mean train loss 3337.76732170057
INFO:root:current train perplexity3.7312333583831787
INFO:root:current mean train loss 3338.73140949264
INFO:root:current train perplexity3.7282896041870117
INFO:root:current mean train loss 3345.834531141191
INFO:root:current train perplexity3.7401702404022217
INFO:root:current mean train loss 3348.650078933483
INFO:root:current train perplexity3.7456932067871094
INFO:root:current mean train loss 3347.110209183531
INFO:root:current train perplexity3.7490739822387695
INFO:root:current mean train loss 3352.741558439634
INFO:root:current train perplexity3.75317645072937
INFO:root:current mean train loss 3354.9085717483945
INFO:root:current train perplexity3.755342960357666
INFO:root:current mean train loss 3356.561497858156
INFO:root:current train perplexity3.7557239532470703
INFO:root:current mean train loss 3356.486696499853
INFO:root:current train perplexity3.755779504776001

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.25s/it]
INFO:root:final mean train loss: 3354.2934102089175
INFO:root:final train perplexity: 3.756042718887329
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it]
INFO:root:eval mean loss: 5833.168856135386
INFO:root:eval perplexity: 11.028219223022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [4:43:37<3:01:42, 138.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.0871691347947
INFO:root:current train perplexity3.747871160507202
INFO:root:current mean train loss 3348.6579399794164
INFO:root:current train perplexity3.746387243270874
INFO:root:current mean train loss 3343.7763653587313
INFO:root:current train perplexity3.7383873462677
INFO:root:current mean train loss 3344.0437437468067
INFO:root:current train perplexity3.7422714233398438
INFO:root:current mean train loss 3347.7487594310423
INFO:root:current train perplexity3.7411115169525146
INFO:root:current mean train loss 3347.574676890432
INFO:root:current train perplexity3.742286443710327
INFO:root:current mean train loss 3350.55501363088
INFO:root:current train perplexity3.7443249225616455
INFO:root:current mean train loss 3350.3150034759005
INFO:root:current train perplexity3.745265007019043
INFO:root:current mean train loss 3352.0645029668576
INFO:root:current train perplexity3.746782064437866
INFO:root:current mean train loss 3354.887738990192
INFO:root:current train perplexity3.751997709274292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.52s/it]
INFO:root:final mean train loss: 3352.6695196090204
INFO:root:final train perplexity: 3.7536368370056152
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it]
INFO:root:eval mean loss: 5832.07374216411
INFO:root:eval perplexity: 11.023250579833984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [4:45:53<2:58:23, 137.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.4859114583332
INFO:root:current train perplexity3.739476203918457
INFO:root:current mean train loss 3336.838431919643
INFO:root:current train perplexity3.74725604057312
INFO:root:current mean train loss 3344.2687357954546
INFO:root:current train perplexity3.7475597858428955
INFO:root:current mean train loss 3345.6924264322915
INFO:root:current train perplexity3.744939088821411
INFO:root:current mean train loss 3350.301520867599
INFO:root:current train perplexity3.7488741874694824
INFO:root:current mean train loss 3350.526580757473
INFO:root:current train perplexity3.745511054992676
INFO:root:current mean train loss 3351.5543623408566
INFO:root:current train perplexity3.7464022636413574
INFO:root:current mean train loss 3351.735400705645
INFO:root:current train perplexity3.7466413974761963
INFO:root:current mean train loss 3350.2944958147323
INFO:root:current train perplexity3.745819568634033
INFO:root:current mean train loss 3349.8181455328527
INFO:root:current train perplexity3.7457664012908936

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.75s/it]
INFO:root:final mean train loss: 3347.652783793788
INFO:root:final train perplexity: 3.7462148666381836
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.83s/it]
INFO:root:eval mean loss: 5835.254444236527
INFO:root:eval perplexity: 11.037689208984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [4:48:11<2:56:34, 137.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.488722467997
INFO:root:current train perplexity3.732631206512451
INFO:root:current mean train loss 3321.707175332992
INFO:root:current train perplexity3.728818416595459
INFO:root:current mean train loss 3327.4633806316256
INFO:root:current train perplexity3.7269515991210938
INFO:root:current mean train loss 3338.389621027456
INFO:root:current train perplexity3.737844944000244
INFO:root:current mean train loss 3340.2100423177085
INFO:root:current train perplexity3.7416560649871826
INFO:root:current mean train loss 3349.4536635331797
INFO:root:current train perplexity3.743939161300659
INFO:root:current mean train loss 3351.3155505067257
INFO:root:current train perplexity3.744812250137329
INFO:root:current mean train loss 3349.1433975395116
INFO:root:current train perplexity3.741281509399414
INFO:root:current mean train loss 3348.730437230146
INFO:root:current train perplexity3.742604970932007
INFO:root:current mean train loss 3348.725426985313
INFO:root:current train perplexity3.7437736988067627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.38s/it]
INFO:root:final mean train loss: 3345.950227491317
INFO:root:final train perplexity: 3.743699550628662
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 5842.63118099738
INFO:root:eval perplexity: 11.071245193481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [4:50:32<2:55:23, 138.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.611746651786
INFO:root:current train perplexity3.6770784854888916
INFO:root:current mean train loss 3335.3370329372547
INFO:root:current train perplexity3.718658924102783
INFO:root:current mean train loss 3336.804411478469
INFO:root:current train perplexity3.720027208328247
INFO:root:current mean train loss 3338.1649766224423
INFO:root:current train perplexity3.719571590423584
INFO:root:current mean train loss 3337.4755123472505
INFO:root:current train perplexity3.7213079929351807
INFO:root:current mean train loss 3340.7385456324027
INFO:root:current train perplexity3.7282259464263916
INFO:root:current mean train loss 3342.41122432107
INFO:root:current train perplexity3.730027198791504
INFO:root:current mean train loss 3345.532042916897
INFO:root:current train perplexity3.73185658454895
INFO:root:current mean train loss 3343.717628487567
INFO:root:current train perplexity3.7345104217529297
INFO:root:current mean train loss 3343.355342368425
INFO:root:current train perplexity3.7359423637390137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.22s/it]
INFO:root:final mean train loss: 3340.651932377969
INFO:root:final train perplexity: 3.735881805419922
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 5840.984746327657
INFO:root:eval perplexity: 11.063746452331543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [4:52:47<2:51:46, 137.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.1387458570075
INFO:root:current train perplexity3.726844549179077
INFO:root:current mean train loss 3330.0673030680746
INFO:root:current train perplexity3.724252700805664
INFO:root:current mean train loss 3333.931071507891
INFO:root:current train perplexity3.7262656688690186
INFO:root:current mean train loss 3334.705157057683
INFO:root:current train perplexity3.726693868637085
INFO:root:current mean train loss 3334.0369992915516
INFO:root:current train perplexity3.723792314529419
INFO:root:current mean train loss 3336.640397977749
INFO:root:current train perplexity3.724555015563965
INFO:root:current mean train loss 3336.2903757600143
INFO:root:current train perplexity3.726334571838379
INFO:root:current mean train loss 3339.2719891563675
INFO:root:current train perplexity3.72856068611145
INFO:root:current mean train loss 3340.7617328715933
INFO:root:current train perplexity3.7321324348449707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.61s/it]
INFO:root:final mean train loss: 3338.419825646185
INFO:root:final train perplexity: 3.7325937747955322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.61s/it]
INFO:root:eval mean loss: 5839.836631911958
INFO:root:eval perplexity: 11.05851936340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [4:55:05<2:49:43, 137.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.00830078125
INFO:root:current train perplexity3.7837042808532715
INFO:root:current mean train loss 3325.2933087215247
INFO:root:current train perplexity3.713196039199829
INFO:root:current mean train loss 3332.20948327106
INFO:root:current train perplexity3.717512607574463
INFO:root:current mean train loss 3330.3932930514557
INFO:root:current train perplexity3.7167022228240967
INFO:root:current mean train loss 3324.131248680321
INFO:root:current train perplexity3.7176008224487305
INFO:root:current mean train loss 3329.1203935912845
INFO:root:current train perplexity3.7214837074279785
INFO:root:current mean train loss 3331.0063074353893
INFO:root:current train perplexity3.720581531524658
INFO:root:current mean train loss 3335.239353465899
INFO:root:current train perplexity3.7251486778259277
INFO:root:current mean train loss 3336.2859830608154
INFO:root:current train perplexity3.7259461879730225
INFO:root:current mean train loss 3336.0726069373623
INFO:root:current train perplexity3.7241148948669434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.33s/it]
INFO:root:final mean train loss: 3333.8670398342992
INFO:root:final train perplexity: 3.7258942127227783
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it]
INFO:root:eval mean loss: 5851.527767706774
INFO:root:eval perplexity: 11.11185359954834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [4:57:19<2:46:20, 136.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.794140625
INFO:root:current train perplexity3.739165782928467
INFO:root:current mean train loss 3314.2407035495926
INFO:root:current train perplexity3.7305173873901367
INFO:root:current mean train loss 3319.236583621003
INFO:root:current train perplexity3.726402521133423
INFO:root:current mean train loss 3325.313285125248
INFO:root:current train perplexity3.719888687133789
INFO:root:current mean train loss 3327.794304169804
INFO:root:current train perplexity3.7183077335357666
INFO:root:current mean train loss 3326.640104482706
INFO:root:current train perplexity3.718491792678833
INFO:root:current mean train loss 3328.3968317295476
INFO:root:current train perplexity3.7169573307037354
INFO:root:current mean train loss 3329.9809751283874
INFO:root:current train perplexity3.7187633514404297
INFO:root:current mean train loss 3329.2692304927145
INFO:root:current train perplexity3.7170331478118896
INFO:root:current mean train loss 3331.8573058081456
INFO:root:current train perplexity3.720579147338867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.76s/it]
INFO:root:final mean train loss: 3331.2511102614862
INFO:root:final train perplexity: 3.7220520973205566
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.40s/it]
INFO:root:eval mean loss: 5850.104920530033
INFO:root:eval perplexity: 11.105345726013184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [4:59:37<2:44:31, 137.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3287.6888799252715
INFO:root:current train perplexity3.703886032104492
INFO:root:current mean train loss 3331.162897373603
INFO:root:current train perplexity3.7112317085266113
INFO:root:current mean train loss 3328.4127739192127
INFO:root:current train perplexity3.709866762161255
INFO:root:current mean train loss 3328.8456025965074
INFO:root:current train perplexity3.7171249389648438
INFO:root:current mean train loss 3326.5186274102393
INFO:root:current train perplexity3.7107114791870117
INFO:root:current mean train loss 3325.59197426207
INFO:root:current train perplexity3.713252305984497
INFO:root:current mean train loss 3326.7710223496438
INFO:root:current train perplexity3.714235544204712
INFO:root:current mean train loss 3327.9338311370807
INFO:root:current train perplexity3.7151167392730713
INFO:root:current mean train loss 3326.2469320749165
INFO:root:current train perplexity3.713131904602051
INFO:root:current mean train loss 3327.215209828684
INFO:root:current train perplexity3.713088035583496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.07s/it]
INFO:root:final mean train loss: 3326.130705741144
INFO:root:final train perplexity: 3.7145397663116455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it]
INFO:root:eval mean loss: 5850.179436049775
INFO:root:eval perplexity: 11.105687141418457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [5:01:59<2:43:57, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.0172158518144
INFO:root:current train perplexity3.6823761463165283
INFO:root:current mean train loss 3318.608502802958
INFO:root:current train perplexity3.7026355266571045
INFO:root:current mean train loss 3329.534898369859
INFO:root:current train perplexity3.7124838829040527
INFO:root:current mean train loss 3329.6700834061085
INFO:root:current train perplexity3.7132925987243652
INFO:root:current mean train loss 3326.6626129504425
INFO:root:current train perplexity3.7142934799194336
INFO:root:current mean train loss 3328.931132573417
INFO:root:current train perplexity3.717895030975342
INFO:root:current mean train loss 3327.72684494478
INFO:root:current train perplexity3.7135629653930664
INFO:root:current mean train loss 3328.4760892479267
INFO:root:current train perplexity3.7127716541290283
INFO:root:current mean train loss 3325.265404950267
INFO:root:current train perplexity3.710312843322754
INFO:root:current mean train loss 3325.259667549174
INFO:root:current train perplexity3.709965229034424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.37s/it]
INFO:root:final mean train loss: 3324.158095452093
INFO:root:final train perplexity: 3.7116501331329346
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5859.655059997193
INFO:root:eval perplexity: 11.149079322814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [5:04:16<2:40:54, 137.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.186748798077
INFO:root:current train perplexity3.7044363021850586
INFO:root:current mean train loss 3324.999098963017
INFO:root:current train perplexity3.709676504135132
INFO:root:current mean train loss 3321.364559157623
INFO:root:current train perplexity3.7007904052734375
INFO:root:current mean train loss 3324.7116115873896
INFO:root:current train perplexity3.7056283950805664
INFO:root:current mean train loss 3324.790660814707
INFO:root:current train perplexity3.708369493484497
INFO:root:current mean train loss 3318.226588318211
INFO:root:current train perplexity3.7050840854644775
INFO:root:current mean train loss 3317.943782322843
INFO:root:current train perplexity3.705113410949707
INFO:root:current mean train loss 3318.513616373478
INFO:root:current train perplexity3.7034194469451904
INFO:root:current mean train loss 3322.5321034737226
INFO:root:current train perplexity3.706144332885742
INFO:root:current mean train loss 3323.2001877724806
INFO:root:current train perplexity3.7077391147613525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.79s/it]
INFO:root:final mean train loss: 3321.1593509181853
INFO:root:final train perplexity: 3.707261800765991
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it]
INFO:root:eval mean loss: 5860.68961686003
INFO:root:eval perplexity: 11.153824806213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [5:06:36<2:39:23, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.997937790891
INFO:root:current train perplexity3.6906332969665527
INFO:root:current mean train loss 3313.3108092846514
INFO:root:current train perplexity3.6887404918670654
INFO:root:current mean train loss 3314.9147277090715
INFO:root:current train perplexity3.7004973888397217
INFO:root:current mean train loss 3313.5755266964607
INFO:root:current train perplexity3.6933038234710693
INFO:root:current mean train loss 3315.9492684520064
INFO:root:current train perplexity3.6945135593414307
INFO:root:current mean train loss 3317.2340902436586
INFO:root:current train perplexity3.696270227432251
INFO:root:current mean train loss 3317.79286045269
INFO:root:current train perplexity3.6992716789245605
INFO:root:current mean train loss 3318.754824963918
INFO:root:current train perplexity3.7008914947509766
INFO:root:current mean train loss 3318.0063661037116
INFO:root:current train perplexity3.7002010345458984
INFO:root:current mean train loss 3319.5748604247788
INFO:root:current train perplexity3.70129656791687

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.53s/it]
INFO:root:final mean train loss: 3317.9917065405075
INFO:root:final train perplexity: 3.7026314735412598
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 5856.620485591317
INFO:root:eval perplexity: 11.135164260864258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [5:08:56<2:37:35, 139.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.897283380682
INFO:root:current train perplexity3.673082113265991
INFO:root:current mean train loss 3287.3841355846776
INFO:root:current train perplexity3.6792168617248535
INFO:root:current mean train loss 3292.261613434436
INFO:root:current train perplexity3.6862943172454834
INFO:root:current mean train loss 3294.42324356294
INFO:root:current train perplexity3.6813292503356934
INFO:root:current mean train loss 3299.715858409169
INFO:root:current train perplexity3.6822097301483154
INFO:root:current mean train loss 3303.995794622748
INFO:root:current train perplexity3.6854467391967773
INFO:root:current mean train loss 3306.3969804836593
INFO:root:current train perplexity3.6894173622131348
INFO:root:current mean train loss 3308.84240706488
INFO:root:current train perplexity3.691119909286499
INFO:root:current mean train loss 3312.0206288834065
INFO:root:current train perplexity3.6925418376922607
INFO:root:current mean train loss 3314.073811508099
INFO:root:current train perplexity3.695071220397949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.99s/it]
INFO:root:final mean train loss: 3314.1453555322464
INFO:root:final train perplexity: 3.697016716003418
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.53s/it]
INFO:root:eval mean loss: 5861.622367082242
INFO:root:eval perplexity: 11.158109664916992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [5:11:34<2:41:43, 144.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.4783606150795
INFO:root:current train perplexity3.687715768814087
INFO:root:current mean train loss 3300.6082127108893
INFO:root:current train perplexity3.686789035797119
INFO:root:current mean train loss 3307.341386570223
INFO:root:current train perplexity3.6940202713012695
INFO:root:current mean train loss 3311.3575900159262
INFO:root:current train perplexity3.697340726852417
INFO:root:current mean train loss 3313.170512452754
INFO:root:current train perplexity3.6957287788391113
INFO:root:current mean train loss 3319.3036380855906
INFO:root:current train perplexity3.6971330642700195
INFO:root:current mean train loss 3316.813672095942
INFO:root:current train perplexity3.6945323944091797
INFO:root:current mean train loss 3314.63111151499
INFO:root:current train perplexity3.6929023265838623
INFO:root:current mean train loss 3314.410576635827
INFO:root:current train perplexity3.6935386657714844
INFO:root:current mean train loss 3315.9897369669975
INFO:root:current train perplexity3.6954517364501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.76s/it]
INFO:root:final mean train loss: 3313.4086348010646
INFO:root:final train perplexity: 3.6959424018859863
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it]
INFO:root:eval mean loss: 5864.490137888286
INFO:root:eval perplexity: 11.171280860900879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [5:14:30<2:49:27, 154.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.2024991747357
INFO:root:current train perplexity3.6889805793762207
INFO:root:current mean train loss 3296.551703559028
INFO:root:current train perplexity3.671722650527954
INFO:root:current mean train loss 3297.1969295938075
INFO:root:current train perplexity3.6738269329071045
INFO:root:current mean train loss 3300.16646376453
INFO:root:current train perplexity3.677044630050659
INFO:root:current mean train loss 3304.374589988887
INFO:root:current train perplexity3.681417465209961
INFO:root:current mean train loss 3310.3146523711143
INFO:root:current train perplexity3.6841228008270264
INFO:root:current mean train loss 3314.3451267930327
INFO:root:current train perplexity3.6907436847686768
INFO:root:current mean train loss 3312.658918764186
INFO:root:current train perplexity3.6899681091308594
INFO:root:current mean train loss 3313.443814020343
INFO:root:current train perplexity3.6915040016174316
INFO:root:current mean train loss 3311.617042172213
INFO:root:current train perplexity3.6895673274993896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.37s/it]
INFO:root:final mean train loss: 3309.546785785306
INFO:root:final train perplexity: 3.6903157234191895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5866.160904752994
INFO:root:eval perplexity: 11.178967475891113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [5:16:48<2:41:38, 149.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.551016119462
INFO:root:current train perplexity3.682192087173462
INFO:root:current mean train loss 3305.739371017371
INFO:root:current train perplexity3.6940484046936035
INFO:root:current mean train loss 3304.4716525607637
INFO:root:current train perplexity3.687159538269043
INFO:root:current mean train loss 3307.284369717802
INFO:root:current train perplexity3.686239004135132
INFO:root:current mean train loss 3309.901531816773
INFO:root:current train perplexity3.6874303817749023
INFO:root:current mean train loss 3311.4321048716806
INFO:root:current train perplexity3.6874537467956543
INFO:root:current mean train loss 3314.277648296553
INFO:root:current train perplexity3.6879241466522217
INFO:root:current mean train loss 3313.3661755230064
INFO:root:current train perplexity3.68554425239563
INFO:root:current mean train loss 3311.9365734321673
INFO:root:current train perplexity3.6855547428131104
INFO:root:current mean train loss 3308.672389964648
INFO:root:current train perplexity3.684735059738159

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.12s/it]
INFO:root:final mean train loss: 3306.154231902092
INFO:root:final train perplexity: 3.6853795051574707
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.99s/it]
INFO:root:eval mean loss: 5872.561115561845
INFO:root:eval perplexity: 11.208449363708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [5:19:06<2:35:33, 145.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.4513907596984
INFO:root:current train perplexity3.6663193702697754
INFO:root:current mean train loss 3298.1850703438336
INFO:root:current train perplexity3.6743850708007812
INFO:root:current mean train loss 3296.903775417846
INFO:root:current train perplexity3.671532392501831
INFO:root:current mean train loss 3305.0901799953567
INFO:root:current train perplexity3.677776336669922
INFO:root:current mean train loss 3308.5690612166322
INFO:root:current train perplexity3.6799187660217285
INFO:root:current mean train loss 3307.8219815567772
INFO:root:current train perplexity3.6781184673309326
INFO:root:current mean train loss 3307.2772133284434
INFO:root:current train perplexity3.6783690452575684
INFO:root:current mean train loss 3304.49859533831
INFO:root:current train perplexity3.676900863647461
INFO:root:current mean train loss 3304.806986880813
INFO:root:current train perplexity3.6782565116882324
INFO:root:current mean train loss 3306.0467040768267
INFO:root:current train perplexity3.6817009449005127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.74s/it]
INFO:root:final mean train loss: 3303.7466026429206
INFO:root:final train perplexity: 3.681880235671997
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it]
INFO:root:eval mean loss: 5868.873298325225
INFO:root:eval perplexity: 11.191455841064453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [5:21:23<2:30:31, 143.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.2552991365133
INFO:root:current train perplexity3.6557347774505615
INFO:root:current mean train loss 3293.8572891626604
INFO:root:current train perplexity3.6612918376922607
INFO:root:current mean train loss 3297.073530190678
INFO:root:current train perplexity3.668200969696045
INFO:root:current mean train loss 3297.079848818236
INFO:root:current train perplexity3.6714694499969482
INFO:root:current mean train loss 3296.4167371961807
INFO:root:current train perplexity3.672927141189575
INFO:root:current mean train loss 3299.422167148109
INFO:root:current train perplexity3.6759774684906006
INFO:root:current mean train loss 3297.6457895402427
INFO:root:current train perplexity3.674328088760376
INFO:root:current mean train loss 3301.633198518573
INFO:root:current train perplexity3.6779990196228027
INFO:root:current mean train loss 3302.2852105337815
INFO:root:current train perplexity3.677586078643799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.33s/it]
INFO:root:final mean train loss: 3300.9145383527202
INFO:root:final train perplexity: 3.6777684688568115
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it]
INFO:root:eval mean loss: 5869.599894449382
INFO:root:eval perplexity: 11.19480037689209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [5:23:47<2:28:07, 143.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.4009602864585
INFO:root:current train perplexity3.539137363433838
INFO:root:current mean train loss 3275.1202759974212
INFO:root:current train perplexity3.64007830619812
INFO:root:current mean train loss 3279.367378723445
INFO:root:current train perplexity3.647789478302002
INFO:root:current mean train loss 3285.077793838954
INFO:root:current train perplexity3.656932830810547
INFO:root:current mean train loss 3290.401922713438
INFO:root:current train perplexity3.6558659076690674
INFO:root:current mean train loss 3291.9752490913893
INFO:root:current train perplexity3.6570510864257812
INFO:root:current mean train loss 3293.9707638564987
INFO:root:current train perplexity3.6596503257751465
INFO:root:current mean train loss 3294.938171299898
INFO:root:current train perplexity3.663179636001587
INFO:root:current mean train loss 3297.478308576724
INFO:root:current train perplexity3.6662967205047607
INFO:root:current mean train loss 3297.785442297377
INFO:root:current train perplexity3.668565273284912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.83s/it]
INFO:root:final mean train loss: 3296.8466807949926
INFO:root:final train perplexity: 3.6718716621398926
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5873.789588791167
INFO:root:eval perplexity: 11.214118957519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [5:26:10<2:25:38, 143.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.8939098011365
INFO:root:current train perplexity3.6137187480926514
INFO:root:current mean train loss 3295.5090398015204
INFO:root:current train perplexity3.669309616088867
INFO:root:current mean train loss 3288.889802327088
INFO:root:current train perplexity3.655327320098877
INFO:root:current mean train loss 3279.9034600457194
INFO:root:current train perplexity3.646186113357544
INFO:root:current mean train loss 3284.443173447955
INFO:root:current train perplexity3.6510210037231445
INFO:root:current mean train loss 3286.015915962115
INFO:root:current train perplexity3.6583149433135986
INFO:root:current mean train loss 3288.9624634788
INFO:root:current train perplexity3.659579038619995
INFO:root:current mean train loss 3291.6007899030856
INFO:root:current train perplexity3.6601481437683105
INFO:root:current mean train loss 3293.7959441950525
INFO:root:current train perplexity3.6648507118225098
INFO:root:current mean train loss 3296.1358694836545
INFO:root:current train perplexity3.66611909866333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.24s/it]
INFO:root:final mean train loss: 3293.9104907743395
INFO:root:final train perplexity: 3.6676199436187744
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 5876.296578230258
INFO:root:eval perplexity: 11.225691795349121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [5:29:02<2:32:00, 152.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.5427503083883
INFO:root:current train perplexity3.6609244346618652
INFO:root:current mean train loss 3271.5155244715074
INFO:root:current train perplexity3.646077871322632
INFO:root:current mean train loss 3272.2713996503994
INFO:root:current train perplexity3.657111167907715
INFO:root:current mean train loss 3279.80868329374
INFO:root:current train perplexity3.657406806945801
INFO:root:current mean train loss 3284.2430778266707
INFO:root:current train perplexity3.6595990657806396
INFO:root:current mean train loss 3287.391691880419
INFO:root:current train perplexity3.6612935066223145
INFO:root:current mean train loss 3286.1429674090014
INFO:root:current train perplexity3.660308599472046
INFO:root:current mean train loss 3288.945510800591
INFO:root:current train perplexity3.661346435546875
INFO:root:current mean train loss 3290.3103921631755
INFO:root:current train perplexity3.6616899967193604
INFO:root:current mean train loss 3292.14836550641
INFO:root:current train perplexity3.6620609760284424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.14s/it]
INFO:root:final mean train loss: 3292.2780787560246
INFO:root:final train perplexity: 3.6652591228485107
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]
INFO:root:eval mean loss: 5878.273178740176
INFO:root:eval perplexity: 11.234829902648926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [5:31:19<2:25:01, 147.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.9460720486113
INFO:root:current train perplexity3.658025026321411
INFO:root:current mean train loss 3285.2071139117866
INFO:root:current train perplexity3.662423610687256
INFO:root:current mean train loss 3285.7635869097603
INFO:root:current train perplexity3.661782741546631
INFO:root:current mean train loss 3285.200184113389
INFO:root:current train perplexity3.6626691818237305
INFO:root:current mean train loss 3290.4302432486825
INFO:root:current train perplexity3.6634459495544434
INFO:root:current mean train loss 3290.299398404145
INFO:root:current train perplexity3.6609623432159424
INFO:root:current mean train loss 3291.8333586429676
INFO:root:current train perplexity3.6637325286865234
INFO:root:current mean train loss 3291.7571405255976
INFO:root:current train perplexity3.663689613342285
INFO:root:current mean train loss 3292.4071043445815
INFO:root:current train perplexity3.664809226989746
INFO:root:current mean train loss 3291.6519552846044
INFO:root:current train perplexity3.6618781089782715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.97s/it]
INFO:root:final mean train loss: 3289.7327405252763
INFO:root:final train perplexity: 3.6615803241729736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it]
INFO:root:eval mean loss: 5882.536928096931
INFO:root:eval perplexity: 11.254561424255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [5:33:38<2:20:02, 144.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.8346540178572
INFO:root:current train perplexity3.6541335582733154
INFO:root:current mean train loss 3308.181564670139
INFO:root:current train perplexity3.6392452716827393
INFO:root:current mean train loss 3296.945460023271
INFO:root:current train perplexity3.6409974098205566
INFO:root:current mean train loss 3294.9773233442165
INFO:root:current train perplexity3.6431665420532227
INFO:root:current mean train loss 3288.800677420079
INFO:root:current train perplexity3.6461474895477295
INFO:root:current mean train loss 3293.4980286214955
INFO:root:current train perplexity3.651059865951538
INFO:root:current mean train loss 3289.632353054257
INFO:root:current train perplexity3.6475417613983154
INFO:root:current mean train loss 3287.294778047938
INFO:root:current train perplexity3.6489930152893066
INFO:root:current mean train loss 3285.874529554173
INFO:root:current train perplexity3.6515190601348877
INFO:root:current mean train loss 3286.5297016001005
INFO:root:current train perplexity3.6540558338165283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.10s/it]
INFO:root:final mean train loss: 3285.349263221987
INFO:root:final train perplexity: 3.6552531719207764
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.38s/it]
INFO:root:eval mean loss: 5884.925822183757
INFO:root:eval perplexity: 11.26562786102295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [5:36:12<2:20:11, 147.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.370963163154
INFO:root:current train perplexity3.6310882568359375
INFO:root:current mean train loss 3272.4176990002184
INFO:root:current train perplexity3.6302616596221924
INFO:root:current mean train loss 3270.9536745675796
INFO:root:current train perplexity3.633375883102417
INFO:root:current mean train loss 3276.1098383689414
INFO:root:current train perplexity3.6349220275878906
INFO:root:current mean train loss 3277.846701180693
INFO:root:current train perplexity3.639179229736328
INFO:root:current mean train loss 3280.44311883129
INFO:root:current train perplexity3.6432321071624756
INFO:root:current mean train loss 3282.7401766621306
INFO:root:current train perplexity3.6455211639404297
INFO:root:current mean train loss 3280.2816216326337
INFO:root:current train perplexity3.646467924118042
INFO:root:current mean train loss 3282.70978340701
INFO:root:current train perplexity3.6493754386901855
INFO:root:current mean train loss 3284.266356904079
INFO:root:current train perplexity3.652860403060913

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.43s/it]
INFO:root:final mean train loss: 3283.861706518358
INFO:root:final train perplexity: 3.653108596801758
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it]
INFO:root:eval mean loss: 5886.758505450038
INFO:root:eval perplexity: 11.274126052856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [5:38:40<2:18:00, 147.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.5256826363357
INFO:root:current train perplexity3.6239407062530518
INFO:root:current mean train loss 3276.7428115945777
INFO:root:current train perplexity3.6372249126434326
INFO:root:current mean train loss 3276.9245644375624
INFO:root:current train perplexity3.6355607509613037
INFO:root:current mean train loss 3271.9424217637106
INFO:root:current train perplexity3.6350607872009277
INFO:root:current mean train loss 3275.5921942125137
INFO:root:current train perplexity3.636813163757324
INFO:root:current mean train loss 3277.4280290274783
INFO:root:current train perplexity3.641684055328369
INFO:root:current mean train loss 3281.8082067252303
INFO:root:current train perplexity3.644953727722168
INFO:root:current mean train loss 3283.8620439674182
INFO:root:current train perplexity3.647777795791626
INFO:root:current mean train loss 3283.408241280938
INFO:root:current train perplexity3.6480462551116943
INFO:root:current mean train loss 3281.885315262306
INFO:root:current train perplexity3.648013114929199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.25s/it]
INFO:root:final mean train loss: 3280.6648370065996
INFO:root:final train perplexity: 3.6485040187835693
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 5887.906653489895
INFO:root:eval perplexity: 11.279455184936523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [5:41:01<2:13:29, 145.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.2802361957097
INFO:root:current train perplexity3.628174304962158
INFO:root:current mean train loss 3272.817084930228
INFO:root:current train perplexity3.627426862716675
INFO:root:current mean train loss 3268.3870053088804
INFO:root:current train perplexity3.6305956840515137
INFO:root:current mean train loss 3272.038994494255
INFO:root:current train perplexity3.637197256088257
INFO:root:current mean train loss 3274.7384567759395
INFO:root:current train perplexity3.6383299827575684
INFO:root:current mean train loss 3276.500996652784
INFO:root:current train perplexity3.6406471729278564
INFO:root:current mean train loss 3281.0198676379932
INFO:root:current train perplexity3.642650604248047
INFO:root:current mean train loss 3280.8964261543765
INFO:root:current train perplexity3.644594430923462
INFO:root:current mean train loss 3281.519054053132
INFO:root:current train perplexity3.645413398742676
INFO:root:current mean train loss 3280.809215684877
INFO:root:current train perplexity3.645565986633301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.16s/it]
INFO:root:final mean train loss: 3278.9271007660896
INFO:root:final train perplexity: 3.646003246307373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 5890.264584113024
INFO:root:eval perplexity: 11.29040813446045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [5:43:16<2:08:12, 142.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.307190852379
INFO:root:current train perplexity3.6316311359405518
INFO:root:current mean train loss 3283.4954300383606
INFO:root:current train perplexity3.6256020069122314
INFO:root:current mean train loss 3280.0838947653324
INFO:root:current train perplexity3.6317524909973145
INFO:root:current mean train loss 3281.469957398459
INFO:root:current train perplexity3.630066156387329
INFO:root:current mean train loss 3278.062801124197
INFO:root:current train perplexity3.631348133087158
INFO:root:current mean train loss 3275.2626513930227
INFO:root:current train perplexity3.6330506801605225
INFO:root:current mean train loss 3276.4104201561327
INFO:root:current train perplexity3.634256601333618
INFO:root:current mean train loss 3276.6284036449847
INFO:root:current train perplexity3.634718894958496
INFO:root:current mean train loss 3277.885389915387
INFO:root:current train perplexity3.6385819911956787
INFO:root:current mean train loss 3278.663464898284
INFO:root:current train perplexity3.640575647354126

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.82s/it]
INFO:root:final mean train loss: 3275.464611853323
INFO:root:final train perplexity: 3.641026496887207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5887.686280758795
INFO:root:eval perplexity: 11.278432846069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [5:45:42<2:06:49, 143.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.3514192708335
INFO:root:current train perplexity3.610199451446533
INFO:root:current mean train loss 3270.8887039620536
INFO:root:current train perplexity3.6342785358428955
INFO:root:current mean train loss 3275.8285484730113
INFO:root:current train perplexity3.6390583515167236
INFO:root:current mean train loss 3270.583404296875
INFO:root:current train perplexity3.6339008808135986
INFO:root:current mean train loss 3269.489967105263
INFO:root:current train perplexity3.6302387714385986
INFO:root:current mean train loss 3270.9129330842393
INFO:root:current train perplexity3.630388021469116
INFO:root:current mean train loss 3273.957026909722
INFO:root:current train perplexity3.6325759887695312
INFO:root:current mean train loss 3274.6677778477824
INFO:root:current train perplexity3.632258176803589
INFO:root:current mean train loss 3278.5510851004465
INFO:root:current train perplexity3.6374075412750244
INFO:root:current mean train loss 3277.0055779246795
INFO:root:current train perplexity3.63851261138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.82s/it]
INFO:root:final mean train loss: 3274.3700228660337
INFO:root:final train perplexity: 3.639453887939453
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it]
INFO:root:eval mean loss: 5889.655502958926
INFO:root:eval perplexity: 11.287576675415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [5:48:02<2:03:35, 142.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.565485575113
INFO:root:current train perplexity3.636960506439209
INFO:root:current mean train loss 3268.9472576203893
INFO:root:current train perplexity3.6351370811462402
INFO:root:current mean train loss 3269.781735693187
INFO:root:current train perplexity3.6314034461975098
INFO:root:current mean train loss 3272.232576773621
INFO:root:current train perplexity3.6310477256774902
INFO:root:current mean train loss 3272.4627516215387
INFO:root:current train perplexity3.630176544189453
INFO:root:current mean train loss 3270.9550136350235
INFO:root:current train perplexity3.632234811782837
INFO:root:current mean train loss 3270.9265765836612
INFO:root:current train perplexity3.6314775943756104
INFO:root:current mean train loss 3270.8610777483436
INFO:root:current train perplexity3.631584405899048
INFO:root:current mean train loss 3271.8156002817987
INFO:root:current train perplexity3.6331303119659424
INFO:root:current mean train loss 3273.8346129812276
INFO:root:current train perplexity3.634925603866577

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.93s/it]
INFO:root:final mean train loss: 3271.561412257533
INFO:root:final train perplexity: 3.6354238986968994
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 5892.562093586265
INFO:root:eval perplexity: 11.30108642578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [5:50:20<1:59:52, 141.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.3779028588597
INFO:root:current train perplexity3.609959840774536
INFO:root:current mean train loss 3256.363212225949
INFO:root:current train perplexity3.6095118522644043
INFO:root:current mean train loss 3260.477289888048
INFO:root:current train perplexity3.6169402599334717
INFO:root:current mean train loss 3262.3196250349665
INFO:root:current train perplexity3.617872953414917
INFO:root:current mean train loss 3263.722687575579
INFO:root:current train perplexity3.6209959983825684
INFO:root:current mean train loss 3262.7604311250793
INFO:root:current train perplexity3.6213603019714355
INFO:root:current mean train loss 3266.818247727478
INFO:root:current train perplexity3.6245999336242676
INFO:root:current mean train loss 3267.0339435717246
INFO:root:current train perplexity3.628021001815796
INFO:root:current mean train loss 3268.757683716505
INFO:root:current train perplexity3.6288363933563232
INFO:root:current mean train loss 3270.0847352737132
INFO:root:current train perplexity3.6296913623809814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.57s/it]
INFO:root:final mean train loss: 3267.5467263498613
INFO:root:final train perplexity: 3.629669666290283
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 5897.6797605959955
INFO:root:eval perplexity: 11.324911117553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [5:52:41<1:57:40, 141.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.218118686869
INFO:root:current train perplexity3.640390157699585
INFO:root:current mean train loss 3266.302727013976
INFO:root:current train perplexity3.624713659286499
INFO:root:current mean train loss 3265.6718692843333
INFO:root:current train perplexity3.623462438583374
INFO:root:current mean train loss 3263.3046489514804
INFO:root:current train perplexity3.621220350265503
INFO:root:current mean train loss 3264.706722037826
INFO:root:current train perplexity3.6215667724609375
INFO:root:current mean train loss 3266.401709962568
INFO:root:current train perplexity3.626307964324951
INFO:root:current mean train loss 3265.361010288135
INFO:root:current train perplexity3.6276888847351074
INFO:root:current mean train loss 3262.580889686327
INFO:root:current train perplexity3.625795364379883
INFO:root:current mean train loss 3266.6272999187463
INFO:root:current train perplexity3.6270244121551514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.67s/it]
INFO:root:final mean train loss: 3266.738084362399
INFO:root:final train perplexity: 3.628512382507324
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it]
INFO:root:eval mean loss: 5898.781767519648
INFO:root:eval perplexity: 11.330044746398926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [5:54:58<1:54:13, 139.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.0357840401784
INFO:root:current train perplexity3.6186740398406982
INFO:root:current mean train loss 3267.8061660338785
INFO:root:current train perplexity3.6263277530670166
INFO:root:current mean train loss 3263.4319779400666
INFO:root:current train perplexity3.6248350143432617
INFO:root:current mean train loss 3261.33598521478
INFO:root:current train perplexity3.6275575160980225
INFO:root:current mean train loss 3262.1259165770884
INFO:root:current train perplexity3.6270627975463867
INFO:root:current mean train loss 3263.299928924741
INFO:root:current train perplexity3.623248338699341
INFO:root:current mean train loss 3262.9736834907844
INFO:root:current train perplexity3.623626708984375
INFO:root:current mean train loss 3267.6937330102987
INFO:root:current train perplexity3.6241252422332764
INFO:root:current mean train loss 3268.4794564891185
INFO:root:current train perplexity3.625229597091675
INFO:root:current mean train loss 3271.2775456303402
INFO:root:current train perplexity3.6276185512542725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.69s/it]
INFO:root:final mean train loss: 3265.4508379659346
INFO:root:final train perplexity: 3.6266703605651855
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it]
INFO:root:eval mean loss: 5899.723619655221
INFO:root:eval perplexity: 11.334441184997559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [5:57:20<1:52:29, 140.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3284.5738118489585
INFO:root:current train perplexity3.625408887863159
INFO:root:current mean train loss 3260.3576893682066
INFO:root:current train perplexity3.6135058403015137
INFO:root:current mean train loss 3259.961115779433
INFO:root:current train perplexity3.616661787033081
INFO:root:current mean train loss 3254.5115815662202
INFO:root:current train perplexity3.613698959350586
INFO:root:current mean train loss 3259.448941665098
INFO:root:current train perplexity3.6149656772613525
INFO:root:current mean train loss 3262.1672894227854
INFO:root:current train perplexity3.6186649799346924
INFO:root:current mean train loss 3263.3158143578507
INFO:root:current train perplexity3.6162047386169434
INFO:root:current mean train loss 3265.980040223448
INFO:root:current train perplexity3.6203057765960693
INFO:root:current mean train loss 3264.6690687308283
INFO:root:current train perplexity3.621692657470703
INFO:root:current mean train loss 3265.0458589480872
INFO:root:current train perplexity3.6228392124176025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.52s/it]
INFO:root:final mean train loss: 3262.650873122677
INFO:root:final train perplexity: 3.6226656436920166
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it]
INFO:root:eval mean loss: 5900.274168459955
INFO:root:eval perplexity: 11.337008476257324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [5:59:42<1:50:17, 140.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.7185270889945
INFO:root:current train perplexity3.5754878520965576
INFO:root:current mean train loss 3248.036238011306
INFO:root:current train perplexity3.602433204650879
INFO:root:current mean train loss 3248.903306080087
INFO:root:current train perplexity3.598926544189453
INFO:root:current mean train loss 3250.927312608843
INFO:root:current train perplexity3.6010079383850098
INFO:root:current mean train loss 3252.477790706265
INFO:root:current train perplexity3.6052162647247314
INFO:root:current mean train loss 3255.0559184729027
INFO:root:current train perplexity3.6065866947174072
INFO:root:current mean train loss 3255.2720408431983
INFO:root:current train perplexity3.6100313663482666
INFO:root:current mean train loss 3258.8172176883427
INFO:root:current train perplexity3.613797187805176
INFO:root:current mean train loss 3261.500158706239
INFO:root:current train perplexity3.6146321296691895
INFO:root:current mean train loss 3261.9727509437635
INFO:root:current train perplexity3.6165359020233154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.59s/it]
INFO:root:final mean train loss: 3259.4884366066226
INFO:root:final train perplexity: 3.6181485652923584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it]
INFO:root:eval mean loss: 5902.973602112182
INFO:root:eval perplexity: 11.349611282348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [6:02:00<1:47:21, 140.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.663511214718
INFO:root:current train perplexity3.6451175212860107
INFO:root:current mean train loss 3260.2381675661977
INFO:root:current train perplexity3.623706102371216
INFO:root:current mean train loss 3255.920546494521
INFO:root:current train perplexity3.6106626987457275
INFO:root:current mean train loss 3256.3486778051833
INFO:root:current train perplexity3.6124649047851562
INFO:root:current mean train loss 3252.8580166491442
INFO:root:current train perplexity3.614610433578491
INFO:root:current mean train loss 3252.1857096354165
INFO:root:current train perplexity3.613812208175659
INFO:root:current mean train loss 3256.504492032736
INFO:root:current train perplexity3.6174426078796387
INFO:root:current mean train loss 3259.542365579044
INFO:root:current train perplexity3.6202752590179443
INFO:root:current mean train loss 3262.011709936259
INFO:root:current train perplexity3.6175572872161865
INFO:root:current mean train loss 3260.4052081410277
INFO:root:current train perplexity3.61690354347229

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.45s/it]
INFO:root:final mean train loss: 3258.2904302535517
INFO:root:final train perplexity: 3.6164398193359375
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5904.236181933009
INFO:root:eval perplexity: 11.35550594329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [6:04:16<1:44:13, 138.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.3324005909453
INFO:root:current train perplexity3.6174867153167725
INFO:root:current mean train loss 3254.3837240754274
INFO:root:current train perplexity3.597640037536621
INFO:root:current mean train loss 3257.7198144122644
INFO:root:current train perplexity3.6054115295410156
INFO:root:current mean train loss 3255.6950496347254
INFO:root:current train perplexity3.6097357273101807
INFO:root:current mean train loss 3250.8542280262313
INFO:root:current train perplexity3.6108338832855225
INFO:root:current mean train loss 3253.136432484926
INFO:root:current train perplexity3.609622001647949
INFO:root:current mean train loss 3253.1100092307315
INFO:root:current train perplexity3.6079063415527344
INFO:root:current mean train loss 3255.2462401022285
INFO:root:current train perplexity3.608397960662842
INFO:root:current mean train loss 3256.14323227056
INFO:root:current train perplexity3.6076996326446533
INFO:root:current mean train loss 3257.589546049238
INFO:root:current train perplexity3.611741542816162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.67s/it]
INFO:root:final mean train loss: 3255.287173486525
INFO:root:final train perplexity: 3.612156629562378
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it]
INFO:root:eval mean loss: 5905.4250722188435
INFO:root:eval perplexity: 11.361065864562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [6:06:40<1:42:56, 140.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.229087017952
INFO:root:current train perplexity3.555774211883545
INFO:root:current mean train loss 3255.351873073448
INFO:root:current train perplexity3.5878360271453857
INFO:root:current mean train loss 3246.9198892570216
INFO:root:current train perplexity3.59062123298645
INFO:root:current mean train loss 3249.005827010537
INFO:root:current train perplexity3.594217538833618
INFO:root:current mean train loss 3252.4382646462527
INFO:root:current train perplexity3.600830554962158
INFO:root:current mean train loss 3247.8785063414075
INFO:root:current train perplexity3.5999317169189453
INFO:root:current mean train loss 3248.5140756315204
INFO:root:current train perplexity3.602177381515503
INFO:root:current mean train loss 3251.5316251987115
INFO:root:current train perplexity3.6042447090148926
INFO:root:current mean train loss 3254.927385026195
INFO:root:current train perplexity3.606597423553467
INFO:root:current mean train loss 3256.4351431535442
INFO:root:current train perplexity3.6089091300964355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.78s/it]
INFO:root:final mean train loss: 3253.5897776080715
INFO:root:final train perplexity: 3.609738349914551
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 5909.415612135105
INFO:root:eval perplexity: 11.379735946655273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [6:09:04<1:41:24, 141.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.201260653409
INFO:root:current train perplexity3.6224958896636963
INFO:root:current mean train loss 3223.8766475554435
INFO:root:current train perplexity3.595252513885498
INFO:root:current mean train loss 3238.4787444469976
INFO:root:current train perplexity3.6000168323516846
INFO:root:current mean train loss 3243.798153471611
INFO:root:current train perplexity3.603478193283081
INFO:root:current mean train loss 3245.262261225103
INFO:root:current train perplexity3.60318922996521
INFO:root:current mean train loss 3248.800002199465
INFO:root:current train perplexity3.602949857711792
INFO:root:current mean train loss 3252.5311683713026
INFO:root:current train perplexity3.6058871746063232
INFO:root:current mean train loss 3252.4790197511384
INFO:root:current train perplexity3.6052653789520264
INFO:root:current mean train loss 3254.312535407529
INFO:root:current train perplexity3.607215642929077
INFO:root:current mean train loss 3253.2357158561026
INFO:root:current train perplexity3.6052842140197754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.61s/it]
INFO:root:final mean train loss: 3250.7062761245234
INFO:root:final train perplexity: 3.6056344509124756
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it]
INFO:root:eval mean loss: 5908.709672939278
INFO:root:eval perplexity: 11.376431465148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [6:11:57<1:45:41, 150.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.397972470238
INFO:root:current train perplexity3.600621461868286
INFO:root:current mean train loss 3258.669354210602
INFO:root:current train perplexity3.5949344635009766
INFO:root:current mean train loss 3253.294340764615
INFO:root:current train perplexity3.5930652618408203
INFO:root:current mean train loss 3245.8160423930353
INFO:root:current train perplexity3.595775842666626
INFO:root:current mean train loss 3248.956279317967
INFO:root:current train perplexity3.602482318878174
INFO:root:current mean train loss 3250.76882224481
INFO:root:current train perplexity3.602635622024536
INFO:root:current mean train loss 3249.7355607206823
INFO:root:current train perplexity3.6057558059692383
INFO:root:current mean train loss 3253.6078791187133
INFO:root:current train perplexity3.6053073406219482
INFO:root:current mean train loss 3251.847457655888
INFO:root:current train perplexity3.6043004989624023
INFO:root:current mean train loss 3251.890727929485
INFO:root:current train perplexity3.603550434112549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.62s/it]
INFO:root:final mean train loss: 3249.527760721022
INFO:root:final train perplexity: 3.6039581298828125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it]
INFO:root:eval mean loss: 5912.15022835189
INFO:root:eval perplexity: 11.39255142211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [6:15:06<1:50:53, 162.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.851871974032
INFO:root:current train perplexity3.606924533843994
INFO:root:current mean train loss 3240.980338827211
INFO:root:current train perplexity3.5886847972869873
INFO:root:current mean train loss 3241.9759949406134
INFO:root:current train perplexity3.5892953872680664
INFO:root:current mean train loss 3238.541841491535
INFO:root:current train perplexity3.5943517684936523
INFO:root:current mean train loss 3242.916183568869
INFO:root:current train perplexity3.5958640575408936
INFO:root:current mean train loss 3242.474648711143
INFO:root:current train perplexity3.596902847290039
INFO:root:current mean train loss 3244.705078488846
INFO:root:current train perplexity3.5950205326080322
INFO:root:current mean train loss 3246.796864233747
INFO:root:current train perplexity3.596194267272949
INFO:root:current mean train loss 3248.0295530684916
INFO:root:current train perplexity3.5996291637420654
INFO:root:current mean train loss 3248.159790416211
INFO:root:current train perplexity3.5994186401367188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.53s/it]
INFO:root:final mean train loss: 3246.444840461977
INFO:root:final train perplexity: 3.5995774269104004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it]
INFO:root:eval mean loss: 5914.487098556792
INFO:root:eval perplexity: 11.403512001037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [6:17:23<1:43:12, 154.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.6993670886077
INFO:root:current train perplexity3.583209753036499
INFO:root:current mean train loss 3237.9918178792773
INFO:root:current train perplexity3.5962421894073486
INFO:root:current mean train loss 3244.3620876736113
INFO:root:current train perplexity3.599093437194824
INFO:root:current mean train loss 3250.018201682058
INFO:root:current train perplexity3.597496747970581
INFO:root:current mean train loss 3247.607549806726
INFO:root:current train perplexity3.5957252979278564
INFO:root:current mean train loss 3249.0867820831986
INFO:root:current train perplexity3.59582257270813
INFO:root:current mean train loss 3245.591609544712
INFO:root:current train perplexity3.5971288681030273
INFO:root:current mean train loss 3246.9115947679315
INFO:root:current train perplexity3.5977115631103516
INFO:root:current mean train loss 3245.490719045524
INFO:root:current train perplexity3.5981531143188477
INFO:root:current mean train loss 3247.2974869725167
INFO:root:current train perplexity3.598357677459717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.28s/it]
INFO:root:final mean train loss: 3245.288811652891
INFO:root:final train perplexity: 3.597935914993286
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.33s/it]
INFO:root:eval mean loss: 5915.220906331868
INFO:root:eval perplexity: 11.406953811645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [6:19:45<1:38:02, 150.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.5947013065734
INFO:root:current train perplexity3.5676753520965576
INFO:root:current mean train loss 3231.08512543867
INFO:root:current train perplexity3.5713982582092285
INFO:root:current mean train loss 3237.1850653990637
INFO:root:current train perplexity3.5751681327819824
INFO:root:current mean train loss 3243.6689219708896
INFO:root:current train perplexity3.585474729537964
INFO:root:current mean train loss 3241.312535092082
INFO:root:current train perplexity3.586014986038208
INFO:root:current mean train loss 3242.150416827486
INFO:root:current train perplexity3.5851399898529053
INFO:root:current mean train loss 3241.1030117073783
INFO:root:current train perplexity3.585667371749878
INFO:root:current mean train loss 3242.4133117753336
INFO:root:current train perplexity3.5881547927856445
INFO:root:current mean train loss 3242.78196508156
INFO:root:current train perplexity3.590327024459839
INFO:root:current mean train loss 3245.3106787158845
INFO:root:current train perplexity3.5944809913635254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.53s/it]
INFO:root:final mean train loss: 3242.4904210490563
INFO:root:final train perplexity: 3.593966007232666
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.72s/it]
INFO:root:eval mean loss: 5915.6546623549775
INFO:root:eval perplexity: 11.408990859985352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [6:22:04<1:33:17, 147.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.5507452713814
INFO:root:current train perplexity3.5917675495147705
INFO:root:current mean train loss 3246.9922663762018
INFO:root:current train perplexity3.5992014408111572
INFO:root:current mean train loss 3243.8284063824153
INFO:root:current train perplexity3.590330123901367
INFO:root:current mean train loss 3247.581300682358
INFO:root:current train perplexity3.5884649753570557
INFO:root:current mean train loss 3249.9509104719064
INFO:root:current train perplexity3.5927071571350098
INFO:root:current mean train loss 3248.2215229451153
INFO:root:current train perplexity3.5911757946014404
INFO:root:current mean train loss 3246.900301399505
INFO:root:current train perplexity3.5894935131073
INFO:root:current mean train loss 3244.7805234129323
INFO:root:current train perplexity3.5906853675842285
INFO:root:current mean train loss 3245.164127967877
INFO:root:current train perplexity3.5921199321746826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.89s/it]
INFO:root:final mean train loss: 3241.4200593886835
INFO:root:final train perplexity: 3.5924479961395264
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 5917.527913898765
INFO:root:eval perplexity: 11.4177885055542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [6:24:20<1:28:47, 143.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.6304524739585
INFO:root:current train perplexity3.579587459564209
INFO:root:current mean train loss 3212.6911905529428
INFO:root:current train perplexity3.584728479385376
INFO:root:current mean train loss 3237.0213328394398
INFO:root:current train perplexity3.59770131111145
INFO:root:current mean train loss 3234.08792366053
INFO:root:current train perplexity3.5927140712738037
INFO:root:current mean train loss 3234.0993731098793
INFO:root:current train perplexity3.5947964191436768
INFO:root:current mean train loss 3236.630342942346
INFO:root:current train perplexity3.5942695140838623
INFO:root:current mean train loss 3239.121193349658
INFO:root:current train perplexity3.5919225215911865
INFO:root:current mean train loss 3238.4174280288717
INFO:root:current train perplexity3.588735342025757
INFO:root:current mean train loss 3238.7175657811526
INFO:root:current train perplexity3.589329481124878
INFO:root:current mean train loss 3243.06165023922
INFO:root:current train perplexity3.5911903381347656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.31s/it]
INFO:root:final mean train loss: 3240.592378431751
INFO:root:final train perplexity: 3.591275691986084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it]
INFO:root:eval mean loss: 5919.231514022736
INFO:root:eval perplexity: 11.425797462463379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [6:27:26<1:33:57, 156.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.773859197443
INFO:root:current train perplexity3.575299024581909
INFO:root:current mean train loss 3239.5640990111206
INFO:root:current train perplexity3.572110176086426
INFO:root:current mean train loss 3241.742306677651
INFO:root:current train perplexity3.578697919845581
INFO:root:current mean train loss 3242.026039834958
INFO:root:current train perplexity3.5866870880126953
INFO:root:current mean train loss 3246.409268789918
INFO:root:current train perplexity3.592555046081543
INFO:root:current mean train loss 3242.947251291891
INFO:root:current train perplexity3.5926992893218994
INFO:root:current mean train loss 3240.174769524857
INFO:root:current train perplexity3.589144706726074
INFO:root:current mean train loss 3238.6555031563157
INFO:root:current train perplexity3.5874722003936768
INFO:root:current mean train loss 3239.972188439234
INFO:root:current train perplexity3.5872552394866943
INFO:root:current mean train loss 3239.893054614606
INFO:root:current train perplexity3.586913585662842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.34s/it]
INFO:root:final mean train loss: 3236.8618782412623
INFO:root:final train perplexity: 3.585994005203247
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it]
INFO:root:eval mean loss: 5921.487490351328
INFO:root:eval perplexity: 11.436407089233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [6:30:43<1:38:20, 168.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.7807745682567
INFO:root:current train perplexity3.590836763381958
INFO:root:current mean train loss 3233.537423270089
INFO:root:current train perplexity3.5788347721099854
INFO:root:current mean train loss 3241.1429638448917
INFO:root:current train perplexity3.5909998416900635
INFO:root:current mean train loss 3240.899047468897
INFO:root:current train perplexity3.586308717727661
INFO:root:current mean train loss 3238.2788651131787
INFO:root:current train perplexity3.5864851474761963
INFO:root:current mean train loss 3236.525676631744
INFO:root:current train perplexity3.5863394737243652
INFO:root:current mean train loss 3238.604756837515
INFO:root:current train perplexity3.5863072872161865
INFO:root:current mean train loss 3241.309183897992
INFO:root:current train perplexity3.5870089530944824
INFO:root:current mean train loss 3241.559798355941
INFO:root:current train perplexity3.5887770652770996
INFO:root:current mean train loss 3240.182613999592
INFO:root:current train perplexity3.5864064693450928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.20s/it]
INFO:root:final mean train loss: 3236.832325596963
INFO:root:final train perplexity: 3.585951805114746
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.82s/it]
INFO:root:eval mean loss: 5923.4683348147455
INFO:root:eval perplexity: 11.4457368850708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [6:33:56<1:39:39, 175.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.1999421296296
INFO:root:current train perplexity3.591127872467041
INFO:root:current mean train loss 3232.320675827387
INFO:root:current train perplexity3.5717389583587646
INFO:root:current mean train loss 3237.3612496128167
INFO:root:current train perplexity3.5808815956115723
INFO:root:current mean train loss 3232.762215990539
INFO:root:current train perplexity3.5781590938568115
INFO:root:current mean train loss 3233.67487558548
INFO:root:current train perplexity3.5750949382781982
INFO:root:current mean train loss 3237.3958566510023
INFO:root:current train perplexity3.5757644176483154
INFO:root:current mean train loss 3238.409970516223
INFO:root:current train perplexity3.579179048538208
INFO:root:current mean train loss 3239.1546199331583
INFO:root:current train perplexity3.580618143081665
INFO:root:current mean train loss 3236.433781209851
INFO:root:current train perplexity3.5812833309173584
INFO:root:current mean train loss 3237.02415938722
INFO:root:current train perplexity3.58247709274292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.20s/it]
INFO:root:final mean train loss: 3234.6234700602868
INFO:root:final train perplexity: 3.5828282833099365
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it]
INFO:root:eval mean loss: 5923.758232071014
INFO:root:eval perplexity: 11.447100639343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [6:37:09<1:39:42, 181.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.0336983816965
INFO:root:current train perplexity3.575695753097534
INFO:root:current mean train loss 3234.9945674189817
INFO:root:current train perplexity3.57979154586792
INFO:root:current mean train loss 3223.574657164229
INFO:root:current train perplexity3.57157039642334
INFO:root:current mean train loss 3229.662338940065
INFO:root:current train perplexity3.5726535320281982
INFO:root:current mean train loss 3232.015887100395
INFO:root:current train perplexity3.5748660564422607
INFO:root:current mean train loss 3236.0891902745325
INFO:root:current train perplexity3.576845645904541
INFO:root:current mean train loss 3235.2968788447342
INFO:root:current train perplexity3.5786185264587402
INFO:root:current mean train loss 3236.124393800489
INFO:root:current train perplexity3.5774877071380615
INFO:root:current mean train loss 3236.5873318792105
INFO:root:current train perplexity3.5784010887145996
INFO:root:current mean train loss 3236.1286514037433
INFO:root:current train perplexity3.580151319503784

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.79s/it]
INFO:root:final mean train loss: 3233.412696038523
INFO:root:final train perplexity: 3.5811171531677246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it]
INFO:root:eval mean loss: 5922.149886262631
INFO:root:eval perplexity: 11.439530372619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [6:40:17<1:37:36, 183.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.204845339753
INFO:root:current train perplexity3.5503416061401367
INFO:root:current mean train loss 3246.447205870302
INFO:root:current train perplexity3.581326723098755
INFO:root:current mean train loss 3231.259225099666
INFO:root:current train perplexity3.5771241188049316
INFO:root:current mean train loss 3226.7333592895866
INFO:root:current train perplexity3.5714383125305176
INFO:root:current mean train loss 3228.3611760193285
INFO:root:current train perplexity3.5728652477264404
INFO:root:current mean train loss 3226.995628848699
INFO:root:current train perplexity3.569368600845337
INFO:root:current mean train loss 3231.3980038941
INFO:root:current train perplexity3.570213794708252
INFO:root:current mean train loss 3232.9597079250084
INFO:root:current train perplexity3.574967861175537
INFO:root:current mean train loss 3234.775722227628
INFO:root:current train perplexity3.5766968727111816
INFO:root:current mean train loss 3233.257511401859
INFO:root:current train perplexity3.5765461921691895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.72s/it]
INFO:root:final mean train loss: 3229.8480579007055
INFO:root:final train perplexity: 3.576085090637207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it]
INFO:root:eval mean loss: 5924.672831095621
INFO:root:eval perplexity: 11.451408386230469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [6:42:35<1:27:40, 169.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.1494092754288
INFO:root:current train perplexity3.55637788772583
INFO:root:current mean train loss 3222.8465584256
INFO:root:current train perplexity3.5594587326049805
INFO:root:current mean train loss 3226.4000813153634
INFO:root:current train perplexity3.572000741958618
INFO:root:current mean train loss 3226.3087293836807
INFO:root:current train perplexity3.570892572402954
INFO:root:current mean train loss 3221.2346445832177
INFO:root:current train perplexity3.566551923751831
INFO:root:current mean train loss 3221.9382705273083
INFO:root:current train perplexity3.568197727203369
INFO:root:current mean train loss 3225.4105496501775
INFO:root:current train perplexity3.569730281829834
INFO:root:current mean train loss 3228.400074314976
INFO:root:current train perplexity3.572908639907837
INFO:root:current mean train loss 3229.70244335708
INFO:root:current train perplexity3.5721089839935303
INFO:root:current mean train loss 3230.8391534301886
INFO:root:current train perplexity3.5738110542297363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.12s/it]
INFO:root:final mean train loss: 3229.479169660999
INFO:root:final train perplexity: 3.57556414604187
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it]
INFO:root:eval mean loss: 5927.254303892216
INFO:root:eval perplexity: 11.463583946228027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [6:45:40<1:27:08, 174.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.5594172073625
INFO:root:current train perplexity3.566344976425171
INFO:root:current mean train loss 3211.620866499607
INFO:root:current train perplexity3.552150249481201
INFO:root:current mean train loss 3211.284374811474
INFO:root:current train perplexity3.5604782104492188
INFO:root:current mean train loss 3220.7332454245734
INFO:root:current train perplexity3.5700106620788574
INFO:root:current mean train loss 3220.9541286892363
INFO:root:current train perplexity3.5690174102783203
INFO:root:current mean train loss 3223.3808331702817
INFO:root:current train perplexity3.571880340576172
INFO:root:current mean train loss 3227.2537165686645
INFO:root:current train perplexity3.5739529132843018
INFO:root:current mean train loss 3229.61025184762
INFO:root:current train perplexity3.574878454208374
INFO:root:current mean train loss 3230.078019840476
INFO:root:current train perplexity3.5750010013580322
INFO:root:current mean train loss 3230.154222028969
INFO:root:current train perplexity3.5742647647857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.68s/it]
INFO:root:final mean train loss: 3228.546583175659
INFO:root:final train perplexity: 3.574249029159546
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it]
INFO:root:eval mean loss: 5927.46581592674
INFO:root:eval perplexity: 11.464578628540039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [6:48:01<1:19:26, 164.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.386128439832
INFO:root:current train perplexity3.562699556350708
INFO:root:current mean train loss 3242.749073142777
INFO:root:current train perplexity3.577955722808838
INFO:root:current mean train loss 3234.7329823926148
INFO:root:current train perplexity3.582040786743164
INFO:root:current mean train loss 3235.0444735077485
INFO:root:current train perplexity3.5836362838745117
INFO:root:current mean train loss 3225.44083641428
INFO:root:current train perplexity3.575648546218872
INFO:root:current mean train loss 3223.5087253361994
INFO:root:current train perplexity3.571052312850952
INFO:root:current mean train loss 3223.391109620971
INFO:root:current train perplexity3.5706984996795654
INFO:root:current mean train loss 3226.112473071321
INFO:root:current train perplexity3.5716967582702637
INFO:root:current mean train loss 3229.112300745206
INFO:root:current train perplexity3.5723516941070557
INFO:root:current mean train loss 3229.399576654602
INFO:root:current train perplexity3.5725061893463135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.25s/it]
INFO:root:final mean train loss: 3227.0995532005063
INFO:root:final train perplexity: 3.5722086429595947
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 5926.979344533589
INFO:root:eval perplexity: 11.462285041809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [6:50:56<1:18:05, 167.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.1898828125
INFO:root:current train perplexity3.578005075454712
INFO:root:current mean train loss 3220.148080357143
INFO:root:current train perplexity3.567413568496704
INFO:root:current mean train loss 3229.7033513849433
INFO:root:current train perplexity3.5706915855407715
INFO:root:current mean train loss 3225.3783893229165
INFO:root:current train perplexity3.5669796466827393
INFO:root:current mean train loss 3225.2634498355264
INFO:root:current train perplexity3.5669100284576416
INFO:root:current mean train loss 3226.239982591712
INFO:root:current train perplexity3.56642484664917
INFO:root:current mean train loss 3223.9371223958333
INFO:root:current train perplexity3.5666892528533936
INFO:root:current mean train loss 3225.6920797631046
INFO:root:current train perplexity3.56772518157959
INFO:root:current mean train loss 3227.750240234375
INFO:root:current train perplexity3.568474769592285
INFO:root:current mean train loss 3226.98640249399
INFO:root:current train perplexity3.567816972732544

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.85s/it]
INFO:root:final mean train loss: 3224.043505022603
INFO:root:final train perplexity: 3.5679047107696533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.26s/it]
INFO:root:eval mean loss: 5930.521642262351
INFO:root:eval perplexity: 11.479005813598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [6:54:13<1:19:20, 176.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.5288997788025
INFO:root:current train perplexity3.5858824253082275
INFO:root:current mean train loss 3229.603873164276
INFO:root:current train perplexity3.566911220550537
INFO:root:current mean train loss 3226.5516801706053
INFO:root:current train perplexity3.5683164596557617
INFO:root:current mean train loss 3227.0260440039574
INFO:root:current train perplexity3.563507318496704
INFO:root:current mean train loss 3234.1596507828676
INFO:root:current train perplexity3.5680863857269287
INFO:root:current mean train loss 3228.311882320031
INFO:root:current train perplexity3.5668559074401855
INFO:root:current mean train loss 3226.7817786734763
INFO:root:current train perplexity3.566267490386963
INFO:root:current mean train loss 3227.8211147654256
INFO:root:current train perplexity3.567563533782959
INFO:root:current mean train loss 3229.245617081328
INFO:root:current train perplexity3.5694222450256348
INFO:root:current mean train loss 3227.08863149121
INFO:root:current train perplexity3.5685617923736572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.24s/it]
INFO:root:final mean train loss: 3224.673401617235
INFO:root:final train perplexity: 3.568791151046753
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it]
INFO:root:eval mean loss: 5930.022880508514
INFO:root:eval perplexity: 11.47664737701416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [6:56:55<1:14:32, 172.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.7242391397663
INFO:root:current train perplexity3.558823585510254
INFO:root:current mean train loss 3207.084174830252
INFO:root:current train perplexity3.5507652759552
INFO:root:current mean train loss 3216.6993471125966
INFO:root:current train perplexity3.557884931564331
INFO:root:current mean train loss 3221.801044747043
INFO:root:current train perplexity3.561567783355713
INFO:root:current mean train loss 3218.1348009284306
INFO:root:current train perplexity3.556818723678589
INFO:root:current mean train loss 3219.2804989887372
INFO:root:current train perplexity3.5565130710601807
INFO:root:current mean train loss 3222.130396885741
INFO:root:current train perplexity3.5598397254943848
INFO:root:current mean train loss 3222.3292395281883
INFO:root:current train perplexity3.5606327056884766
INFO:root:current mean train loss 3225.0587608945357
INFO:root:current train perplexity3.564082145690918
INFO:root:current mean train loss 3225.6790659391554
INFO:root:current train perplexity3.566671133041382

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.60s/it]
INFO:root:final mean train loss: 3223.1500408418715
INFO:root:final train perplexity: 3.5666472911834717
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 5932.702380882765
INFO:root:eval perplexity: 11.489312171936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [6:59:13<1:07:26, 161.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.325641670612
INFO:root:current train perplexity3.564563274383545
INFO:root:current mean train loss 3217.318218288709
INFO:root:current train perplexity3.557063341140747
INFO:root:current mean train loss 3219.237649260556
INFO:root:current train perplexity3.559314012527466
INFO:root:current mean train loss 3220.0871569793626
INFO:root:current train perplexity3.559816360473633
INFO:root:current mean train loss 3221.355986876096
INFO:root:current train perplexity3.5612850189208984
INFO:root:current mean train loss 3222.831306979732
INFO:root:current train perplexity3.5648117065429688
INFO:root:current mean train loss 3223.4364294835254
INFO:root:current train perplexity3.5627453327178955
INFO:root:current mean train loss 3221.6152368194616
INFO:root:current train perplexity3.561553716659546
INFO:root:current mean train loss 3222.0163487316636
INFO:root:current train perplexity3.562345266342163

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.71s/it]
INFO:root:final mean train loss: 3221.4877441775416
INFO:root:final train perplexity: 3.5643081665039062
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it]
INFO:root:eval mean loss: 5931.7614497567365
INFO:root:eval perplexity: 11.484864234924316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [7:01:34<1:02:16, 155.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3180.1890694754466
INFO:root:current train perplexity3.4389352798461914
INFO:root:current mean train loss 3228.3810578818634
INFO:root:current train perplexity3.551365613937378
INFO:root:current mean train loss 3221.770488941727
INFO:root:current train perplexity3.5494308471679688
INFO:root:current mean train loss 3219.0410712922435
INFO:root:current train perplexity3.5519211292266846
INFO:root:current mean train loss 3220.684376559621
INFO:root:current train perplexity3.5509490966796875
INFO:root:current mean train loss 3218.5355949326613
INFO:root:current train perplexity3.552253007888794
INFO:root:current mean train loss 3217.3808412756125
INFO:root:current train perplexity3.554060935974121
INFO:root:current mean train loss 3219.455619585396
INFO:root:current train perplexity3.5588507652282715
INFO:root:current mean train loss 3220.747640881544
INFO:root:current train perplexity3.560318946838379
INFO:root:current mean train loss 3223.929948060226
INFO:root:current train perplexity3.5647990703582764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.36s/it]
INFO:root:final mean train loss: 3220.6084573807257
INFO:root:final train perplexity: 3.563072919845581
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5933.848575797623
INFO:root:eval perplexity: 11.494734764099121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [7:04:32<1:02:10, 162.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.8180013020833
INFO:root:current train perplexity3.52250599861145
INFO:root:current mean train loss 3212.6181959069295
INFO:root:current train perplexity3.534162759780884
INFO:root:current mean train loss 3215.4276321765988
INFO:root:current train perplexity3.5575172901153564
INFO:root:current mean train loss 3213.089963107639
INFO:root:current train perplexity3.558366298675537
INFO:root:current mean train loss 3216.328543862952
INFO:root:current train perplexity3.555938720703125
INFO:root:current mean train loss 3216.2458268545206
INFO:root:current train perplexity3.5547103881835938
INFO:root:current mean train loss 3220.114121252541
INFO:root:current train perplexity3.557199001312256
INFO:root:current mean train loss 3222.2323809003497
INFO:root:current train perplexity3.5591843128204346
INFO:root:current mean train loss 3222.238877372508
INFO:root:current train perplexity3.559168577194214
INFO:root:current mean train loss 3220.4771809895833
INFO:root:current train perplexity3.55976939201355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it]
INFO:root:final mean train loss: 3218.737911655057
INFO:root:final train perplexity: 3.5604441165924072
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 5934.719211966692
INFO:root:eval perplexity: 11.498851776123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [7:06:45<56:18, 153.58s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.3243036684785
INFO:root:current train perplexity3.5541141033172607
INFO:root:current mean train loss 3227.7749896786077
INFO:root:current train perplexity3.5462076663970947
INFO:root:current mean train loss 3221.9756384879483
INFO:root:current train perplexity3.54240345954895
INFO:root:current mean train loss 3224.8824149211496
INFO:root:current train perplexity3.5492379665374756
INFO:root:current mean train loss 3228.7361936456487
INFO:root:current train perplexity3.555086612701416
INFO:root:current mean train loss 3224.116894811335
INFO:root:current train perplexity3.5566422939300537
INFO:root:current mean train loss 3223.1227537494983
INFO:root:current train perplexity3.556607723236084
INFO:root:current mean train loss 3220.273435473937
INFO:root:current train perplexity3.557720422744751
INFO:root:current mean train loss 3218.938288191544
INFO:root:current train perplexity3.556595802307129
INFO:root:current mean train loss 3219.3496712698065
INFO:root:current train perplexity3.5594537258148193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.63s/it]
INFO:root:final mean train loss: 3218.167959090202
INFO:root:final train perplexity: 3.559643268585205
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 5936.317787764315
INFO:root:eval perplexity: 11.506418228149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [7:09:48<56:49, 162.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.1992108744957
INFO:root:current train perplexity3.5524630546569824
INFO:root:current mean train loss 3210.2384359345183
INFO:root:current train perplexity3.551933765411377
INFO:root:current mean train loss 3210.111374627976
INFO:root:current train perplexity3.560058355331421
INFO:root:current mean train loss 3210.289161336386
INFO:root:current train perplexity3.5588133335113525
INFO:root:current mean train loss 3212.9227462025087
INFO:root:current train perplexity3.5575919151306152
INFO:root:current mean train loss 3214.648088530632
INFO:root:current train perplexity3.55458927154541
INFO:root:current mean train loss 3216.4027341428537
INFO:root:current train perplexity3.5572152137756348
INFO:root:current mean train loss 3218.4580365349266
INFO:root:current train perplexity3.5585596561431885
INFO:root:current mean train loss 3219.0872924657792
INFO:root:current train perplexity3.5574252605438232
INFO:root:current mean train loss 3217.427113140692
INFO:root:current train perplexity3.5556392669677734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.32s/it]
INFO:root:final mean train loss: 3216.742726479807
INFO:root:final train perplexity: 3.5576422214508057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 5936.105294781531
INFO:root:eval perplexity: 11.505414009094238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [7:12:52<56:16, 168.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.338078425481
INFO:root:current train perplexity3.5765297412872314
INFO:root:current mean train loss 3210.6549590405803
INFO:root:current train perplexity3.555540084838867
INFO:root:current mean train loss 3210.6411735502747
INFO:root:current train perplexity3.5545222759246826
INFO:root:current mean train loss 3215.1564487693586
INFO:root:current train perplexity3.5521225929260254
INFO:root:current mean train loss 3215.189328552107
INFO:root:current train perplexity3.5548319816589355
INFO:root:current mean train loss 3214.908603533743
INFO:root:current train perplexity3.553548574447632
INFO:root:current mean train loss 3213.8772522832305
INFO:root:current train perplexity3.552001953125
INFO:root:current mean train loss 3216.6445913766493
INFO:root:current train perplexity3.5539324283599854
INFO:root:current mean train loss 3218.51415608239
INFO:root:current train perplexity3.5570435523986816
INFO:root:current mean train loss 3218.5899649103103
INFO:root:current train perplexity3.5561611652374268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.05s/it]
INFO:root:final mean train loss: 3216.150771971672
INFO:root:final train perplexity: 3.556811571121216
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 5938.534320031811
INFO:root:eval perplexity: 11.516918182373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [7:15:18<51:15, 161.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.0738966921544
INFO:root:current train perplexity3.532841920852661
INFO:root:current mean train loss 3214.0604887462796
INFO:root:current train perplexity3.557443380355835
INFO:root:current mean train loss 3216.6824363059845
INFO:root:current train perplexity3.5539793968200684
INFO:root:current mean train loss 3224.242739103026
INFO:root:current train perplexity3.5604755878448486
INFO:root:current mean train loss 3219.318562552433
INFO:root:current train perplexity3.5547587871551514
INFO:root:current mean train loss 3216.559385533307
INFO:root:current train perplexity3.55428409576416
INFO:root:current mean train loss 3218.9763138312646
INFO:root:current train perplexity3.5546939373016357
INFO:root:current mean train loss 3217.314128584651
INFO:root:current train perplexity3.5543456077575684
INFO:root:current mean train loss 3217.212978538684
INFO:root:current train perplexity3.5542798042297363
INFO:root:current mean train loss 3217.1946081787883
INFO:root:current train perplexity3.554497241973877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it]
INFO:root:final mean train loss: 3213.94894636831
INFO:root:final train perplexity: 3.553723096847534
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 5940.440365363024
INFO:root:eval perplexity: 11.525956153869629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [7:18:22<50:37, 168.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.947203480114
INFO:root:current train perplexity3.571159839630127
INFO:root:current mean train loss 3205.0034967237902
INFO:root:current train perplexity3.5606653690338135
INFO:root:current mean train loss 3204.059578929228
INFO:root:current train perplexity3.5464043617248535
INFO:root:current mean train loss 3210.4034461652727
INFO:root:current train perplexity3.5481178760528564
INFO:root:current mean train loss 3212.589029232486
INFO:root:current train perplexity3.546592950820923
INFO:root:current mean train loss 3210.949261419623
INFO:root:current train perplexity3.550124168395996
INFO:root:current mean train loss 3212.435518174499
INFO:root:current train perplexity3.5486550331115723
INFO:root:current mean train loss 3213.8154261304844
INFO:root:current train perplexity3.5516717433929443
INFO:root:current mean train loss 3215.4666455363667
INFO:root:current train perplexity3.552086114883423
INFO:root:current mean train loss 3216.3613035831154
INFO:root:current train perplexity3.5524985790252686

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.01s/it]
INFO:root:final mean train loss: 3212.7857506044447
INFO:root:final train perplexity: 3.552093029022217
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it]
INFO:root:eval mean loss: 5939.799247696014
INFO:root:eval perplexity: 11.522913932800293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [7:20:44<45:28, 160.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.0176905071926
INFO:root:current train perplexity3.5561599731445312
INFO:root:current mean train loss 3221.8490746620973
INFO:root:current train perplexity3.553151845932007
INFO:root:current mean train loss 3215.134423085492
INFO:root:current train perplexity3.5526201725006104
INFO:root:current mean train loss 3215.864686908144
INFO:root:current train perplexity3.5556135177612305
INFO:root:current mean train loss 3215.3470266519303
INFO:root:current train perplexity3.554421901702881
INFO:root:current mean train loss 3213.822550961645
INFO:root:current train perplexity3.5533640384674072
INFO:root:current mean train loss 3215.5990271935098
INFO:root:current train perplexity3.553337335586548
INFO:root:current mean train loss 3216.6632238465554
INFO:root:current train perplexity3.551825761795044
INFO:root:current mean train loss 3213.8409959919068
INFO:root:current train perplexity3.550931215286255
INFO:root:current mean train loss 3214.0475587458627
INFO:root:current train perplexity3.55190372467041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it]
INFO:root:final mean train loss: 3212.8322784669936
INFO:root:final train perplexity: 3.5521576404571533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 5938.518094182728
INFO:root:eval perplexity: 11.516841888427734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [7:23:43<44:19, 166.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.3472745653607
INFO:root:current train perplexity3.546475887298584
INFO:root:current mean train loss 3218.0697356999267
INFO:root:current train perplexity3.542853593826294
INFO:root:current mean train loss 3215.052088438365
INFO:root:current train perplexity3.541299819946289
INFO:root:current mean train loss 3212.4264787946427
INFO:root:current train perplexity3.5411460399627686
INFO:root:current mean train loss 3211.9978846329286
INFO:root:current train perplexity3.541750192642212
INFO:root:current mean train loss 3212.3353295000547
INFO:root:current train perplexity3.5433521270751953
INFO:root:current mean train loss 3212.4724903362517
INFO:root:current train perplexity3.5458078384399414
INFO:root:current mean train loss 3210.750450916018
INFO:root:current train perplexity3.5458784103393555
INFO:root:current mean train loss 3214.3665941065406
INFO:root:current train perplexity3.5473663806915283
INFO:root:current mean train loss 3213.0864526844907
INFO:root:current train perplexity3.548168182373047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.53s/it]
INFO:root:final mean train loss: 3209.704674751528
INFO:root:final train perplexity: 3.5477774143218994
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5939.705703826721
INFO:root:eval perplexity: 11.522472381591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [7:26:51<43:08, 172.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.395921924446
INFO:root:current train perplexity3.531975746154785
INFO:root:current mean train loss 3197.884023655726
INFO:root:current train perplexity3.5421018600463867
INFO:root:current mean train loss 3201.8378652483757
INFO:root:current train perplexity3.550743341445923
INFO:root:current mean train loss 3206.2463784733673
INFO:root:current train perplexity3.547222137451172
INFO:root:current mean train loss 3209.2457104645096
INFO:root:current train perplexity3.5479047298431396
INFO:root:current mean train loss 3211.547852405818
INFO:root:current train perplexity3.547048807144165
INFO:root:current mean train loss 3213.4239741059923
INFO:root:current train perplexity3.5491549968719482
INFO:root:current mean train loss 3213.6093963113767
INFO:root:current train perplexity3.5502240657806396
INFO:root:current mean train loss 3214.74199668702
INFO:root:current train perplexity3.5502099990844727
INFO:root:current mean train loss 3214.029528796125
INFO:root:current train perplexity3.5497186183929443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.23s/it]
INFO:root:final mean train loss: 3211.08149750002
INFO:root:final train perplexity: 3.5497055053710938
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.44s/it]
INFO:root:eval mean loss: 5939.290707159899
INFO:root:eval perplexity: 11.520502090454102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [7:29:58<41:19, 177.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.09130859375
INFO:root:current train perplexity3.5595571994781494
INFO:root:current mean train loss 3212.071226395388
INFO:root:current train perplexity3.5542850494384766
INFO:root:current mean train loss 3214.4829986253267
INFO:root:current train perplexity3.5470428466796875
INFO:root:current mean train loss 3215.0637528766956
INFO:root:current train perplexity3.5455503463745117
INFO:root:current mean train loss 3215.0660884160034
INFO:root:current train perplexity3.544222593307495
INFO:root:current mean train loss 3213.4843866455494
INFO:root:current train perplexity3.545837879180908
INFO:root:current mean train loss 3215.19447204501
INFO:root:current train perplexity3.5474026203155518
INFO:root:current mean train loss 3213.5792209959695
INFO:root:current train perplexity3.5475637912750244
INFO:root:current mean train loss 3212.080081152674
INFO:root:current train perplexity3.5468883514404297
INFO:root:current mean train loss 3211.8100348475496
INFO:root:current train perplexity3.5472190380096436

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.90s/it]
INFO:root:final mean train loss: 3208.8933389725225
INFO:root:final train perplexity: 3.546642303466797
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it]
INFO:root:eval mean loss: 5943.038366626123
INFO:root:eval perplexity: 11.538284301757812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [7:33:11<39:22, 181.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.13828125
INFO:root:current train perplexity3.537635564804077
INFO:root:current mean train loss 3214.1960173778043
INFO:root:current train perplexity3.5473780632019043
INFO:root:current mean train loss 3212.221578720869
INFO:root:current train perplexity3.5469582080841064
INFO:root:current mean train loss 3210.427387015427
INFO:root:current train perplexity3.546488046646118
INFO:root:current mean train loss 3207.7864884193496
INFO:root:current train perplexity3.5434281826019287
INFO:root:current mean train loss 3211.0399135044645
INFO:root:current train perplexity3.5476999282836914
INFO:root:current mean train loss 3214.3505423785973
INFO:root:current train perplexity3.5499908924102783
INFO:root:current mean train loss 3212.8489537269065
INFO:root:current train perplexity3.5478897094726562
INFO:root:current mean train loss 3211.9960056411487
INFO:root:current train perplexity3.5480716228485107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.02s/it]
INFO:root:final mean train loss: 3208.934312082106
INFO:root:final train perplexity: 3.5466997623443604
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 5942.470730901478
INFO:root:eval perplexity: 11.535592079162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [7:36:21<36:52, 184.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3169.5127766927085
INFO:root:current train perplexity3.4765517711639404
INFO:root:current mean train loss 3207.7428938486046
INFO:root:current train perplexity3.5271377563476562
INFO:root:current mean train loss 3207.2265576893474
INFO:root:current train perplexity3.537994623184204
INFO:root:current mean train loss 3211.2613062087457
INFO:root:current train perplexity3.545154571533203
INFO:root:current mean train loss 3208.3031014946496
INFO:root:current train perplexity3.5448687076568604
INFO:root:current mean train loss 3208.2912510289825
INFO:root:current train perplexity3.5462546348571777
INFO:root:current mean train loss 3204.5777023087685
INFO:root:current train perplexity3.5447499752044678
INFO:root:current mean train loss 3206.17319433177
INFO:root:current train perplexity3.541624069213867
INFO:root:current mean train loss 3206.206271464917
INFO:root:current train perplexity3.5416154861450195
INFO:root:current mean train loss 3210.600710846657
INFO:root:current train perplexity3.5437042713165283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.71s/it]
INFO:root:final mean train loss: 3207.6335263406077
INFO:root:final train perplexity: 3.544879674911499
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 5942.436346545191
INFO:root:eval perplexity: 11.53542709350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [7:39:32<34:09, 186.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3194.6584694602275
INFO:root:current train perplexity3.5573055744171143
INFO:root:current mean train loss 3192.274616413288
INFO:root:current train perplexity3.5318522453308105
INFO:root:current mean train loss 3207.851128600785
INFO:root:current train perplexity3.5400171279907227
INFO:root:current mean train loss 3209.7411646214327
INFO:root:current train perplexity3.542571544647217
INFO:root:current mean train loss 3205.158984850213
INFO:root:current train perplexity3.5429203510284424
INFO:root:current mean train loss 3204.4373523689765
INFO:root:current train perplexity3.542548179626465
INFO:root:current mean train loss 3202.558870655815
INFO:root:current train perplexity3.5399715900421143
INFO:root:current mean train loss 3204.3903815461276
INFO:root:current train perplexity3.541567325592041
INFO:root:current mean train loss 3204.4137861484664
INFO:root:current train perplexity3.5401554107666016
INFO:root:current mean train loss 3207.8002106952354
INFO:root:current train perplexity3.542357921600342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.75s/it]
INFO:root:final mean train loss: 3206.7462015459614
INFO:root:final train perplexity: 3.5436389446258545
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it]
INFO:root:eval mean loss: 5943.051022466785
INFO:root:eval perplexity: 11.538348197937012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [7:42:42<31:14, 187.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.555484169408
INFO:root:current train perplexity3.5471551418304443
INFO:root:current mean train loss 3226.2751731551994
INFO:root:current train perplexity3.5516762733459473
INFO:root:current mean train loss 3221.405022608091
INFO:root:current train perplexity3.5469062328338623
INFO:root:current mean train loss 3220.8493598770574
INFO:root:current train perplexity3.5477705001831055
INFO:root:current mean train loss 3213.7221062052504
INFO:root:current train perplexity3.54668927192688
INFO:root:current mean train loss 3213.914048858231
INFO:root:current train perplexity3.5461692810058594
INFO:root:current mean train loss 3210.3450357809975
INFO:root:current train perplexity3.5444741249084473
INFO:root:current mean train loss 3210.0966766314978
INFO:root:current train perplexity3.5445501804351807
INFO:root:current mean train loss 3207.777115408463
INFO:root:current train perplexity3.543804883956909
INFO:root:current mean train loss 3208.467931504608
INFO:root:current train perplexity3.543461799621582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.93s/it]
INFO:root:final mean train loss: 3207.149236925187
INFO:root:final train perplexity: 3.5442023277282715
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 5943.338769238866
INFO:root:eval perplexity: 11.539712905883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [7:45:40<27:41, 184.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3258.9317491319443
INFO:root:current train perplexity3.5556652545928955
INFO:root:current mean train loss 3222.4990272822342
INFO:root:current train perplexity3.5371017456054688
INFO:root:current mean train loss 3216.400590669741
INFO:root:current train perplexity3.5422720909118652
INFO:root:current mean train loss 3215.6348791093274
INFO:root:current train perplexity3.5424633026123047
INFO:root:current mean train loss 3211.9841863198917
INFO:root:current train perplexity3.541916608810425
INFO:root:current mean train loss 3215.4616578769865
INFO:root:current train perplexity3.543574333190918
INFO:root:current mean train loss 3210.278382613138
INFO:root:current train perplexity3.5412418842315674
INFO:root:current mean train loss 3208.2795369857936
INFO:root:current train perplexity3.540379524230957
INFO:root:current mean train loss 3206.617571866498
INFO:root:current train perplexity3.54032039642334
INFO:root:current mean train loss 3207.02593842705
INFO:root:current train perplexity3.5409562587738037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.55s/it]
INFO:root:final mean train loss: 3205.7052993774414
INFO:root:final train perplexity: 3.5421838760375977
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 5944.404003029098
INFO:root:eval perplexity: 11.54477310180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [7:48:57<25:06, 188.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.3709542410716
INFO:root:current train perplexity3.5436747074127197
INFO:root:current mean train loss 3204.7062608506944
INFO:root:current train perplexity3.537158727645874
INFO:root:current mean train loss 3201.5360486619015
INFO:root:current train perplexity3.5390052795410156
INFO:root:current mean train loss 3204.861770493237
INFO:root:current train perplexity3.541658639907837
INFO:root:current mean train loss 3209.4288894127153
INFO:root:current train perplexity3.542149305343628
INFO:root:current mean train loss 3204.162012631425
INFO:root:current train perplexity3.5376062393188477
INFO:root:current mean train loss 3206.9141643854578
INFO:root:current train perplexity3.541548013687134
INFO:root:current mean train loss 3204.8293566645407
INFO:root:current train perplexity3.540681838989258
INFO:root:current mean train loss 3204.8924974270208
INFO:root:current train perplexity3.5396060943603516
INFO:root:current mean train loss 3206.1888899043283
INFO:root:current train perplexity3.5405921936035156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.56s/it]
INFO:root:final mean train loss: 3205.1440830230713
INFO:root:final train perplexity: 3.5413997173309326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5945.005131338885
INFO:root:eval perplexity: 11.547627449035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [7:52:07<22:01, 188.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.7320074037066
INFO:root:current train perplexity3.557508707046509
INFO:root:current mean train loss 3205.951142851289
INFO:root:current train perplexity3.55192494392395
INFO:root:current mean train loss 3206.4042466403034
INFO:root:current train perplexity3.5431129932403564
INFO:root:current mean train loss 3201.2568943034803
INFO:root:current train perplexity3.542069911956787
INFO:root:current mean train loss 3206.6193362681647
INFO:root:current train perplexity3.5409488677978516
INFO:root:current mean train loss 3206.4918858087303
INFO:root:current train perplexity3.5388803482055664
INFO:root:current mean train loss 3205.9312643522794
INFO:root:current train perplexity3.539673089981079
INFO:root:current mean train loss 3204.961571016992
INFO:root:current train perplexity3.537970542907715
INFO:root:current mean train loss 3207.9839602795078
INFO:root:current train perplexity3.539865255355835
INFO:root:current mean train loss 3207.8658974122645
INFO:root:current train perplexity3.5397496223449707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.93s/it]
INFO:root:final mean train loss: 3204.34246518535
INFO:root:final train perplexity: 3.5402798652648926
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it]
INFO:root:eval mean loss: 5943.782460469685
INFO:root:eval perplexity: 11.541817665100098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [7:55:21<19:02, 190.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3173.589910768995
INFO:root:current train perplexity3.504347562789917
INFO:root:current mean train loss 3190.7587631932947
INFO:root:current train perplexity3.5226316452026367
INFO:root:current mean train loss 3196.7330560570217
INFO:root:current train perplexity3.534186363220215
INFO:root:current mean train loss 3197.8131406083066
INFO:root:current train perplexity3.534870147705078
INFO:root:current mean train loss 3201.1992122540187
INFO:root:current train perplexity3.5364761352539062
INFO:root:current mean train loss 3203.7198639192943
INFO:root:current train perplexity3.5395233631134033
INFO:root:current mean train loss 3207.6621690038164
INFO:root:current train perplexity3.5427358150482178
INFO:root:current mean train loss 3205.3276871072944
INFO:root:current train perplexity3.540884494781494
INFO:root:current mean train loss 3206.3590683180632
INFO:root:current train perplexity3.5415332317352295
INFO:root:current mean train loss 3207.1160527980414
INFO:root:current train perplexity3.5418710708618164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.28s/it]
INFO:root:final mean train loss: 3204.7440082180883
INFO:root:final train perplexity: 3.5408408641815186
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.94s/it]
INFO:root:eval mean loss: 5943.43538752573
INFO:root:eval perplexity: 11.54017162322998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [7:58:17<15:29, 185.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.5914120431676
INFO:root:current train perplexity3.5563719272613525
INFO:root:current mean train loss 3213.770351193986
INFO:root:current train perplexity3.5440948009490967
INFO:root:current mean train loss 3215.2896950033182
INFO:root:current train perplexity3.541944980621338
INFO:root:current mean train loss 3211.5407449621343
INFO:root:current train perplexity3.538925886154175
INFO:root:current mean train loss 3208.8320823120916
INFO:root:current train perplexity3.538774013519287
INFO:root:current mean train loss 3203.868245733872
INFO:root:current train perplexity3.5374176502227783
INFO:root:current mean train loss 3202.7402877228756
INFO:root:current train perplexity3.5377018451690674
INFO:root:current mean train loss 3203.5494833482585
INFO:root:current train perplexity3.538238763809204
INFO:root:current mean train loss 3205.5384912279906
INFO:root:current train perplexity3.538187265396118
INFO:root:current mean train loss 3205.2677446192324
INFO:root:current train perplexity3.5381624698638916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.35s/it]
INFO:root:final mean train loss: 3202.9453011174355
INFO:root:final train perplexity: 3.5383293628692627
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 5944.635933699008
INFO:root:eval perplexity: 11.54587459564209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [8:01:29<12:31, 187.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.577239534748
INFO:root:current train perplexity3.5455989837646484
INFO:root:current mean train loss 3207.517221416542
INFO:root:current train perplexity3.5439395904541016
INFO:root:current mean train loss 3211.5143549201193
INFO:root:current train perplexity3.5432472229003906
INFO:root:current mean train loss 3211.1572205754
INFO:root:current train perplexity3.541627883911133
INFO:root:current mean train loss 3211.876311144941
INFO:root:current train perplexity3.5425610542297363
INFO:root:current mean train loss 3211.062209356399
INFO:root:current train perplexity3.542708396911621
INFO:root:current mean train loss 3207.5763475684034
INFO:root:current train perplexity3.540163993835449
INFO:root:current mean train loss 3207.7294431683913
INFO:root:current train perplexity3.5412380695343018
INFO:root:current mean train loss 3206.3127311873736
INFO:root:current train perplexity3.5400266647338867
INFO:root:current mean train loss 3205.3383561837513
INFO:root:current train perplexity3.5390267372131348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.41s/it]
INFO:root:final mean train loss: 3202.6922027218725
INFO:root:final train perplexity: 3.537975549697876
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 5944.199446809506
INFO:root:eval perplexity: 11.543801307678223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [8:04:40<09:25, 188.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.6217350260417
INFO:root:current train perplexity3.5300629138946533
INFO:root:current mean train loss 3203.6634835379464
INFO:root:current train perplexity3.5327415466308594
INFO:root:current mean train loss 3202.6496937144884
INFO:root:current train perplexity3.5361270904541016
INFO:root:current mean train loss 3199.6521516927082
INFO:root:current train perplexity3.5347986221313477
INFO:root:current mean train loss 3202.5108218544406
INFO:root:current train perplexity3.5330283641815186
INFO:root:current mean train loss 3203.4785975713316
INFO:root:current train perplexity3.5323574542999268
INFO:root:current mean train loss 3205.265916160301
INFO:root:current train perplexity3.535130262374878
INFO:root:current mean train loss 3203.0534129284274
INFO:root:current train perplexity3.53426194190979
INFO:root:current mean train loss 3204.861092075893
INFO:root:current train perplexity3.534917116165161
INFO:root:current mean train loss 3204.366453575721
INFO:root:current train perplexity3.5370984077453613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.98s/it]
INFO:root:final mean train loss: 3202.1067487655146
INFO:root:final train perplexity: 3.537158727645874
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5945.118367269368
INFO:root:eval perplexity: 11.548164367675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [8:07:46<06:15, 187.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.129506306476
INFO:root:current train perplexity3.544642686843872
INFO:root:current mean train loss 3211.9235479636272
INFO:root:current train perplexity3.5435636043548584
INFO:root:current mean train loss 3213.6617781029154
INFO:root:current train perplexity3.548963785171509
INFO:root:current mean train loss 3208.5846460407147
INFO:root:current train perplexity3.543862819671631
INFO:root:current mean train loss 3201.803351044902
INFO:root:current train perplexity3.5420398712158203
INFO:root:current mean train loss 3206.0597667137918
INFO:root:current train perplexity3.5457229614257812
INFO:root:current mean train loss 3206.816957085583
INFO:root:current train perplexity3.5420491695404053
INFO:root:current mean train loss 3206.188413578584
INFO:root:current train perplexity3.539175271987915
INFO:root:current mean train loss 3205.9409923445464
INFO:root:current train perplexity3.536961317062378
INFO:root:current mean train loss 3205.6830724364986
INFO:root:current train perplexity3.538055658340454

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.97s/it]
INFO:root:final mean train loss: 3202.5123376538677
INFO:root:final train perplexity: 3.537724733352661
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it]
INFO:root:eval mean loss: 5944.93603223241
INFO:root:eval perplexity: 11.547300338745117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [8:10:53<03:07, 187.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.2865057305976
INFO:root:current train perplexity3.5424752235412598
INFO:root:current mean train loss 3199.714999693226
INFO:root:current train perplexity3.5307271480560303
INFO:root:current mean train loss 3197.567317372745
INFO:root:current train perplexity3.533565044403076
INFO:root:current mean train loss 3201.2902632223067
INFO:root:current train perplexity3.534308910369873
INFO:root:current mean train loss 3204.0820581004964
INFO:root:current train perplexity3.537247657775879
INFO:root:current mean train loss 3203.5864063656672
INFO:root:current train perplexity3.5394060611724854
INFO:root:current mean train loss 3202.5925999598635
INFO:root:current train perplexity3.537787437438965
INFO:root:current mean train loss 3204.0354186008612
INFO:root:current train perplexity3.5372793674468994
INFO:root:current mean train loss 3205.3352206965487
INFO:root:current train perplexity3.538484573364258
INFO:root:current mean train loss 3205.250170233271
INFO:root:current train perplexity3.5380001068115234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.74s/it]
INFO:root:final mean train loss: 3202.687383282569
INFO:root:final train perplexity: 3.5379693508148193
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it]
INFO:root:eval mean loss: 5945.033637315213
INFO:root:eval perplexity: 11.547762870788574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1310/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [8:13:35<00:00, 179.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [8:13:35<00:00, 148.08s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.18s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.18s/it]
INFO:root:eval mean loss: 5945.033637315213
INFO:root:eval perplexity: 11.547762870788574
INFO:root:evalaution complete
INFO:root:save model final: small_val_1310/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x154d0265ef06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x154d026568e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x154d0257be09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154d0265fa3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x154d02579948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154d0265fa3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x154d02534b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x154d01f9946a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x154dfe7b5a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x154dfe7b5be0]
python(+0x24a989) [0x5642e631f989]
python(+0x24a9bd) [0x5642e631f9bd]
python(+0x24aa14) [0x5642e631fa14]
python(+0x108f75) [0x5642e61ddf75]
python(Py_RunMain+0x313) [0x5642e6322983]
python(Py_BytesMain+0x39) [0x5642e6322bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x154dfe7930b3]
python(+0x1d6e13) [0x5642e62abe13]
/opt/slurm/data/slurmd/job26146354/slurm_script: line 141: 572564 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_window_10  --output small_val_1310 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
