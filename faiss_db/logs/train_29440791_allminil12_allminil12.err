INFO:root:Output: allminil12_allminilml12
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v2 and are newly initialized: ['encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11599.962890625
INFO:root:current train perplexity9841.65234375
INFO:root:current mean train loss 9667.689938952575
INFO:root:current train perplexity2115.040771484375
INFO:root:current mean train loss 8531.01526899561
INFO:root:current train perplexity859.6255493164062
INFO:root:current mean train loss 7729.941851699561
INFO:root:current train perplexity448.9502868652344
INFO:root:current mean train loss 7116.504191977705
INFO:root:current train perplexity276.5029602050781
INFO:root:current mean train loss 6639.992134106975
INFO:root:current train perplexity189.8398895263672
INFO:root:current mean train loss 6264.26825745764
INFO:root:current train perplexity140.7608642578125
INFO:root:current mean train loss 5965.457726088274
INFO:root:current train perplexity110.57949829101562
INFO:root:current mean train loss 5712.708729100042
INFO:root:current train perplexity90.65434265136719
INFO:root:current mean train loss 5497.723782131741
INFO:root:current train perplexity76.60184478759766
INFO:root:current mean train loss 5315.1306836559515
INFO:root:current train perplexity66.19914245605469
INFO:root:current mean train loss 5156.6029634070055
INFO:root:current train perplexity58.41950607299805
INFO:root:current mean train loss 5016.418151996428
INFO:root:current train perplexity52.28245162963867
INFO:root:current mean train loss 4892.411641162494
INFO:root:current train perplexity47.419334411621094
INFO:root:current mean train loss 4780.639491594657
INFO:root:current train perplexity43.44717788696289
INFO:root:current mean train loss 4680.9470237746245
INFO:root:current train perplexity40.122947692871094
INFO:root:current mean train loss 4589.654030748786
INFO:root:current train perplexity37.32887649536133
INFO:root:current mean train loss 4507.896049291708
INFO:root:current train perplexity34.986454010009766
INFO:root:current mean train loss 4432.6826080595465
INFO:root:current train perplexity32.96113586425781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.67s/it]
INFO:root:final mean train loss: 4372.239117274667
INFO:root:final train perplexity: 31.444080352783203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2825.8532420489805
INFO:root:eval perplexity: 9.829459190368652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 3127.5345874542886
INFO:root:eval perplexity: 12.907177925109863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/1
  0%|          | 1/200 [10:39<35:21:40, 639.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2975.532684326172
INFO:root:current train perplexity10.451549530029297
INFO:root:current mean train loss 3015.924358499461
INFO:root:current train perplexity10.647432327270508
INFO:root:current mean train loss 2997.345895272714
INFO:root:current train perplexity10.527740478515625
INFO:root:current mean train loss 2981.0119613454312
INFO:root:current train perplexity10.397311210632324
INFO:root:current mean train loss 2960.382666367751
INFO:root:current train perplexity10.238168716430664
INFO:root:current mean train loss 2945.5854724026467
INFO:root:current train perplexity10.150287628173828
INFO:root:current mean train loss 2934.274978043197
INFO:root:current train perplexity10.073631286621094
INFO:root:current mean train loss 2919.8421228504712
INFO:root:current train perplexity9.972453117370605
INFO:root:current mean train loss 2906.304532219382
INFO:root:current train perplexity9.879110336303711
INFO:root:current mean train loss 2900.137882682434
INFO:root:current train perplexity9.817631721496582
INFO:root:current mean train loss 2887.9464250699743
INFO:root:current train perplexity9.727829933166504
INFO:root:current mean train loss 2877.2980001032565
INFO:root:current train perplexity9.652425765991211
INFO:root:current mean train loss 2867.839042663574
INFO:root:current train perplexity9.589374542236328
INFO:root:current mean train loss 2859.8075229447663
INFO:root:current train perplexity9.524429321289062
INFO:root:current mean train loss 2853.776771502306
INFO:root:current train perplexity9.468631744384766
INFO:root:current mean train loss 2844.2852232437335
INFO:root:current train perplexity9.40886402130127
INFO:root:current mean train loss 2835.7162146237815
INFO:root:current train perplexity9.351458549499512
INFO:root:current mean train loss 2828.1888737889713
INFO:root:current train perplexity9.288704872131348
INFO:root:current mean train loss 2818.8287728599516
INFO:root:current train perplexity9.223409652709961
INFO:root:current mean train loss 2812.0429365122245
INFO:root:current train perplexity9.178498268127441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.31s/it]
INFO:root:final mean train loss: 2806.4976594264135
INFO:root:final train perplexity: 9.146514892578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it]
INFO:root:eval mean loss: 2517.2070520279253
INFO:root:eval perplexity: 7.658138751983643
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2862.893382836741
INFO:root:eval perplexity: 10.395291328430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/2
  1%|          | 2/200 [21:31<35:33:47, 646.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2633.680427320076
INFO:root:current train perplexity8.033400535583496
INFO:root:current mean train loss 2641.6737143150845
INFO:root:current train perplexity8.032825469970703
INFO:root:current mean train loss 2630.4939719269714
INFO:root:current train perplexity7.99661922454834
INFO:root:current mean train loss 2633.452850066864
INFO:root:current train perplexity7.967973232269287
INFO:root:current mean train loss 2631.260049234086
INFO:root:current train perplexity7.96257209777832
INFO:root:current mean train loss 2627.6656588040864
INFO:root:current train perplexity7.930893898010254
INFO:root:current mean train loss 2622.4308769623817
INFO:root:current train perplexity7.908731460571289
INFO:root:current mean train loss 2621.104535819726
INFO:root:current train perplexity7.889552116394043
INFO:root:current mean train loss 2617.464469772284
INFO:root:current train perplexity7.866520881652832
INFO:root:current mean train loss 2611.589804237423
INFO:root:current train perplexity7.835420608520508
INFO:root:current mean train loss 2605.429229470444
INFO:root:current train perplexity7.805133819580078
INFO:root:current mean train loss 2599.468019732941
INFO:root:current train perplexity7.770556926727295
INFO:root:current mean train loss 2596.016948566916
INFO:root:current train perplexity7.752045154571533
INFO:root:current mean train loss 2592.2882479347863
INFO:root:current train perplexity7.7256879806518555
INFO:root:current mean train loss 2589.017417636187
INFO:root:current train perplexity7.70278263092041
INFO:root:current mean train loss 2584.127999601221
INFO:root:current train perplexity7.674334526062012
INFO:root:current mean train loss 2580.970800302836
INFO:root:current train perplexity7.6502461433410645
INFO:root:current mean train loss 2578.132954504472
INFO:root:current train perplexity7.632439613342285
INFO:root:current mean train loss 2575.950349948215
INFO:root:current train perplexity7.620177268981934
INFO:root:current mean train loss 2573.0578353100345
INFO:root:current train perplexity7.601626873016357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.78s/it]
INFO:root:final mean train loss: 2570.8518401899546
INFO:root:final train perplexity: 7.595291614532471
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 2379.228654577377
INFO:root:eval perplexity: 6.849531650543213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2745.5569903867463
INFO:root:eval perplexity: 9.444117546081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/3
  2%|â–         | 3/200 [32:16<35:21:00, 645.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2453.6052001953126
INFO:root:current train perplexity7.009559154510498
INFO:root:current mean train loss 2468.8711946614585
INFO:root:current train perplexity7.082813262939453
INFO:root:current mean train loss 2479.12069140625
INFO:root:current train perplexity7.069284439086914
INFO:root:current mean train loss 2482.438035714286
INFO:root:current train perplexity7.046352386474609
INFO:root:current mean train loss 2482.1434865993924
INFO:root:current train perplexity7.047432899475098
INFO:root:current mean train loss 2476.2250526012076
INFO:root:current train perplexity7.031229019165039
INFO:root:current mean train loss 2471.5322729492186
INFO:root:current train perplexity7.020131587982178
INFO:root:current mean train loss 2466.781233235677
INFO:root:current train perplexity7.010589599609375
INFO:root:current mean train loss 2465.5832561178768
INFO:root:current train perplexity6.990530490875244
INFO:root:current mean train loss 2462.377907457854
INFO:root:current train perplexity6.9724440574646
INFO:root:current mean train loss 2456.814317452567
INFO:root:current train perplexity6.959299564361572
INFO:root:current mean train loss 2456.544751295007
INFO:root:current train perplexity6.954862117767334
INFO:root:current mean train loss 2456.6597985351564
INFO:root:current train perplexity6.949512958526611
INFO:root:current mean train loss 2454.8613164605035
INFO:root:current train perplexity6.936983108520508
INFO:root:current mean train loss 2453.576913473195
INFO:root:current train perplexity6.921390533447266
INFO:root:current mean train loss 2451.764594017767
INFO:root:current train perplexity6.915961742401123
INFO:root:current mean train loss 2450.2239779385654
INFO:root:current train perplexity6.903358459472656
INFO:root:current mean train loss 2448.345340750558
INFO:root:current train perplexity6.89098596572876
INFO:root:current mean train loss 2445.6042445497255
INFO:root:current train perplexity6.880973815917969
INFO:root:current mean train loss 2443.474774201222
INFO:root:current train perplexity6.86641263961792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.21s/it]
INFO:root:final mean train loss: 2442.1619562484734
INFO:root:final train perplexity: 6.862252712249756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2290.4855299063606
INFO:root:eval perplexity: 6.375167369842529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2666.5532434341753
INFO:root:eval perplexity: 8.853212356567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/4
  2%|â–         | 4/200 [42:49<34:54:08, 641.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2396.889010756763
INFO:root:current train perplexity6.552934646606445
INFO:root:current mean train loss 2375.093296073868
INFO:root:current train perplexity6.465172290802002
INFO:root:current mean train loss 2374.3040195422227
INFO:root:current train perplexity6.490762710571289
INFO:root:current mean train loss 2369.0064570871295
INFO:root:current train perplexity6.471569538116455
INFO:root:current mean train loss 2372.081331763584
INFO:root:current train perplexity6.4974470138549805
INFO:root:current mean train loss 2373.8576636474177
INFO:root:current train perplexity6.492175102233887
INFO:root:current mean train loss 2370.6237392168173
INFO:root:current train perplexity6.4859819412231445
INFO:root:current mean train loss 2373.5812819579123
INFO:root:current train perplexity6.489120006561279
INFO:root:current mean train loss 2371.2014851465633
INFO:root:current train perplexity6.485166072845459
INFO:root:current mean train loss 2369.8934066125503
INFO:root:current train perplexity6.47499942779541
INFO:root:current mean train loss 2369.4663206062924
INFO:root:current train perplexity6.471466064453125
INFO:root:current mean train loss 2366.7882136563103
INFO:root:current train perplexity6.45646858215332
INFO:root:current mean train loss 2367.2821007346956
INFO:root:current train perplexity6.4531474113464355
INFO:root:current mean train loss 2364.623492382527
INFO:root:current train perplexity6.447049140930176
INFO:root:current mean train loss 2362.4266503872964
INFO:root:current train perplexity6.434391498565674
INFO:root:current mean train loss 2361.9847846794983
INFO:root:current train perplexity6.429437637329102
INFO:root:current mean train loss 2358.8929261022795
INFO:root:current train perplexity6.421913146972656
INFO:root:current mean train loss 2359.1832808023396
INFO:root:current train perplexity6.417011737823486
INFO:root:current mean train loss 2357.6623519464297
INFO:root:current train perplexity6.413872718811035
INFO:root:current mean train loss 2356.0878479283174
INFO:root:current train perplexity6.407594680786133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.60s/it]
INFO:root:final mean train loss: 2354.8824571849
INFO:root:final train perplexity: 6.405788421630859
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.92s/it]
INFO:root:eval mean loss: 2232.371049596908
INFO:root:eval perplexity: 6.082468509674072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2618.4176938753603
INFO:root:eval perplexity: 8.51146411895752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/5
  2%|â–Ž         | 5/200 [53:22<34:33:09, 637.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2302.8773498535156
INFO:root:current train perplexity6.20369815826416
INFO:root:current mean train loss 2321.5400702435036
INFO:root:current train perplexity6.206575870513916
INFO:root:current mean train loss 2311.4807872503575
INFO:root:current train perplexity6.179080486297607
INFO:root:current mean train loss 2310.6174437204995
INFO:root:current train perplexity6.186221599578857
INFO:root:current mean train loss 2305.095840580207
INFO:root:current train perplexity6.174874782562256
INFO:root:current mean train loss 2308.3277629695526
INFO:root:current train perplexity6.170587539672852
INFO:root:current mean train loss 2303.8398119831645
INFO:root:current train perplexity6.161636829376221
INFO:root:current mean train loss 2300.9739463961855
INFO:root:current train perplexity6.148433685302734
INFO:root:current mean train loss 2300.3808099392854
INFO:root:current train perplexity6.140150547027588
INFO:root:current mean train loss 2297.6248254543398
INFO:root:current train perplexity6.132948398590088
INFO:root:current mean train loss 2296.895199708833
INFO:root:current train perplexity6.125975608825684
INFO:root:current mean train loss 2296.565599389978
INFO:root:current train perplexity6.11971378326416
INFO:root:current mean train loss 2296.294112446152
INFO:root:current train perplexity6.112813472747803
INFO:root:current mean train loss 2295.217344691988
INFO:root:current train perplexity6.107966423034668
INFO:root:current mean train loss 2292.75424227239
INFO:root:current train perplexity6.105052471160889
INFO:root:current mean train loss 2290.985467852968
INFO:root:current train perplexity6.09818696975708
INFO:root:current mean train loss 2290.8516776839233
INFO:root:current train perplexity6.09412145614624
INFO:root:current mean train loss 2290.578569420785
INFO:root:current train perplexity6.089021682739258
INFO:root:current mean train loss 2289.759568977761
INFO:root:current train perplexity6.086177825927734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.14s/it]
INFO:root:final mean train loss: 2289.8485755016272
INFO:root:final train perplexity: 6.085521697998047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 2190.1893881939827
INFO:root:eval perplexity: 5.878469944000244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 2581.733719629599
INFO:root:eval perplexity: 8.259902000427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/6
  3%|â–Ž         | 6/200 [1:04:03<34:26:41, 639.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2297.63818359375
INFO:root:current train perplexity6.087998390197754
INFO:root:current mean train loss 2231.5324610341895
INFO:root:current train perplexity5.844864845275879
INFO:root:current mean train loss 2235.679481012904
INFO:root:current train perplexity5.864485263824463
INFO:root:current mean train loss 2236.920683090869
INFO:root:current train perplexity5.847728729248047
INFO:root:current mean train loss 2239.6179518854233
INFO:root:current train perplexity5.859748363494873
INFO:root:current mean train loss 2245.029141424183
INFO:root:current train perplexity5.8620100021362305
INFO:root:current mean train loss 2246.8355855069026
INFO:root:current train perplexity5.866628170013428
INFO:root:current mean train loss 2248.7660121074246
INFO:root:current train perplexity5.874332427978516
INFO:root:current mean train loss 2247.2636418527136
INFO:root:current train perplexity5.867444038391113
INFO:root:current mean train loss 2247.378832953619
INFO:root:current train perplexity5.868100166320801
INFO:root:current mean train loss 2244.7338480611184
INFO:root:current train perplexity5.866048812866211
INFO:root:current mean train loss 2245.232101676033
INFO:root:current train perplexity5.864814281463623
INFO:root:current mean train loss 2244.027031205278
INFO:root:current train perplexity5.862797737121582
INFO:root:current mean train loss 2242.266448528926
INFO:root:current train perplexity5.855714321136475
INFO:root:current mean train loss 2242.799191896274
INFO:root:current train perplexity5.856942653656006
INFO:root:current mean train loss 2242.144456755392
INFO:root:current train perplexity5.857296466827393
INFO:root:current mean train loss 2241.1976331321243
INFO:root:current train perplexity5.854002475738525
INFO:root:current mean train loss 2238.711742690421
INFO:root:current train perplexity5.8474507331848145
INFO:root:current mean train loss 2238.178245362277
INFO:root:current train perplexity5.843991279602051
INFO:root:current mean train loss 2238.8423953470215
INFO:root:current train perplexity5.841339588165283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.67s/it]
INFO:root:final mean train loss: 2237.424170112706
INFO:root:final train perplexity: 5.83904504776001
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 2155.223887342088
INFO:root:eval perplexity: 5.714566707611084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2549.4786831470246
INFO:root:eval perplexity: 8.044861793518066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/7
  4%|â–Ž         | 7/200 [1:14:35<34:08:18, 636.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2298.320651584201
INFO:root:current train perplexity5.748165607452393
INFO:root:current mean train loss 2211.39475676973
INFO:root:current train perplexity5.692927360534668
INFO:root:current mean train loss 2206.441892291428
INFO:root:current train perplexity5.652445316314697
INFO:root:current mean train loss 2195.8848136086135
INFO:root:current train perplexity5.636465549468994
INFO:root:current mean train loss 2206.4364001990507
INFO:root:current train perplexity5.672602653503418
INFO:root:current mean train loss 2205.1602698366614
INFO:root:current train perplexity5.663907051086426
INFO:root:current mean train loss 2205.315515808303
INFO:root:current train perplexity5.662717342376709
INFO:root:current mean train loss 2206.84123650766
INFO:root:current train perplexity5.669642925262451
INFO:root:current mean train loss 2201.4014813486115
INFO:root:current train perplexity5.6638078689575195
INFO:root:current mean train loss 2202.8225750559554
INFO:root:current train perplexity5.664450645446777
INFO:root:current mean train loss 2201.1849530712793
INFO:root:current train perplexity5.661013126373291
INFO:root:current mean train loss 2200.003617015422
INFO:root:current train perplexity5.66200065612793
INFO:root:current mean train loss 2198.045650087554
INFO:root:current train perplexity5.658667087554932
INFO:root:current mean train loss 2199.273427589891
INFO:root:current train perplexity5.659761428833008
INFO:root:current mean train loss 2199.438304045641
INFO:root:current train perplexity5.661312580108643
INFO:root:current mean train loss 2198.9869938022375
INFO:root:current train perplexity5.660945892333984
INFO:root:current mean train loss 2197.54453250239
INFO:root:current train perplexity5.654648780822754
INFO:root:current mean train loss 2197.9410784791316
INFO:root:current train perplexity5.654470443725586
INFO:root:current mean train loss 2196.8725283111808
INFO:root:current train perplexity5.65241813659668
INFO:root:current mean train loss 2195.8932618587683
INFO:root:current train perplexity5.6500701904296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.74s/it]
INFO:root:final mean train loss: 2194.9134483318167
INFO:root:final train perplexity: 5.64652681350708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 2129.5566713590147
INFO:root:eval perplexity: 5.597165107727051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 2529.8814571732323
INFO:root:eval perplexity: 7.91695499420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/8
  4%|â–         | 8/200 [1:25:13<33:58:53, 637.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2113.2871616908483
INFO:root:current train perplexity5.32551383972168
INFO:root:current mean train loss 2148.1928132233797
INFO:root:current train perplexity5.461366176605225
INFO:root:current mean train loss 2143.710472593916
INFO:root:current train perplexity5.467375755310059
INFO:root:current mean train loss 2155.8405954844916
INFO:root:current train perplexity5.479790210723877
INFO:root:current mean train loss 2161.9698477909483
INFO:root:current train perplexity5.5015668869018555
INFO:root:current mean train loss 2160.157401339807
INFO:root:current train perplexity5.489921569824219
INFO:root:current mean train loss 2159.778803403359
INFO:root:current train perplexity5.482253551483154
INFO:root:current mean train loss 2158.917428651148
INFO:root:current train perplexity5.48460054397583
INFO:root:current mean train loss 2157.2944873924025
INFO:root:current train perplexity5.483875274658203
INFO:root:current mean train loss 2160.26617751504
INFO:root:current train perplexity5.484569072723389
INFO:root:current mean train loss 2161.0442174054574
INFO:root:current train perplexity5.486401081085205
INFO:root:current mean train loss 2161.7523089034967
INFO:root:current train perplexity5.491926670074463
INFO:root:current mean train loss 2159.4379325341597
INFO:root:current train perplexity5.49064826965332
INFO:root:current mean train loss 2157.8170873749123
INFO:root:current train perplexity5.487559795379639
INFO:root:current mean train loss 2158.1213963312553
INFO:root:current train perplexity5.485775947570801
INFO:root:current mean train loss 2159.0137427314485
INFO:root:current train perplexity5.488617420196533
INFO:root:current mean train loss 2159.699257648246
INFO:root:current train perplexity5.489349365234375
INFO:root:current mean train loss 2159.6108420248333
INFO:root:current train perplexity5.4900007247924805
INFO:root:current mean train loss 2158.764427180901
INFO:root:current train perplexity5.4873881340026855
INFO:root:current mean train loss 2159.3616064579296
INFO:root:current train perplexity5.487334728240967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.67s/it]
INFO:root:final mean train loss: 2158.3977011999455
INFO:root:final train perplexity: 5.486235618591309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 2105.2566195007757
INFO:root:eval perplexity: 5.488242149353027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 2511.0945802512742
INFO:root:eval perplexity: 7.796245574951172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/9
  4%|â–         | 9/200 [1:35:48<33:45:49, 636.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2092.5713571401743
INFO:root:current train perplexity5.335000038146973
INFO:root:current mean train loss 2129.0506953189247
INFO:root:current train perplexity5.399499893188477
INFO:root:current mean train loss 2139.5648043193514
INFO:root:current train perplexity5.393001556396484
INFO:root:current mean train loss 2133.872390053489
INFO:root:current train perplexity5.385680675506592
INFO:root:current mean train loss 2130.976977863143
INFO:root:current train perplexity5.378390789031982
INFO:root:current mean train loss 2128.057202546493
INFO:root:current train perplexity5.3672566413879395
INFO:root:current mean train loss 2128.180285120303
INFO:root:current train perplexity5.3672003746032715
INFO:root:current mean train loss 2127.7194174908577
INFO:root:current train perplexity5.363330364227295
INFO:root:current mean train loss 2131.2129333209546
INFO:root:current train perplexity5.367495536804199
INFO:root:current mean train loss 2129.4283638321053
INFO:root:current train perplexity5.363809108734131
INFO:root:current mean train loss 2129.411481966084
INFO:root:current train perplexity5.361059665679932
INFO:root:current mean train loss 2130.789193789164
INFO:root:current train perplexity5.364165782928467
INFO:root:current mean train loss 2128.4387467356914
INFO:root:current train perplexity5.361192226409912
INFO:root:current mean train loss 2129.350069666755
INFO:root:current train perplexity5.358044147491455
INFO:root:current mean train loss 2129.7696808954242
INFO:root:current train perplexity5.358204364776611
INFO:root:current mean train loss 2129.0503681615455
INFO:root:current train perplexity5.356794834136963
INFO:root:current mean train loss 2130.0979960074437
INFO:root:current train perplexity5.3587117195129395
INFO:root:current mean train loss 2130.2712032370373
INFO:root:current train perplexity5.358941555023193
INFO:root:current mean train loss 2128.9570497714676
INFO:root:current train perplexity5.355482578277588
INFO:root:current mean train loss 2129.1712699014633
INFO:root:current train perplexity5.355451583862305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.27s/it]
INFO:root:final mean train loss: 2127.257500675911
INFO:root:final train perplexity: 5.353139400482178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2088.9813388256316
INFO:root:eval perplexity: 5.416476249694824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2495.7366211803246
INFO:root:eval perplexity: 7.698934078216553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/10
  5%|â–Œ         | 10/200 [1:46:18<33:29:30, 634.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2111.4575849892435
INFO:root:current train perplexity5.270518779754639
INFO:root:current mean train loss 2119.3420388486966
INFO:root:current train perplexity5.273528575897217
INFO:root:current mean train loss 2114.88599313502
INFO:root:current train perplexity5.256825923919678
INFO:root:current mean train loss 2109.5860817348407
INFO:root:current train perplexity5.244631290435791
INFO:root:current mean train loss 2108.420592871302
INFO:root:current train perplexity5.247152805328369
INFO:root:current mean train loss 2103.858698357178
INFO:root:current train perplexity5.244357109069824
INFO:root:current mean train loss 2101.6707376842187
INFO:root:current train perplexity5.236533164978027
INFO:root:current mean train loss 2103.385322164032
INFO:root:current train perplexity5.244979381561279
INFO:root:current mean train loss 2102.124040575104
INFO:root:current train perplexity5.244397163391113
INFO:root:current mean train loss 2101.67693833547
INFO:root:current train perplexity5.243496417999268
INFO:root:current mean train loss 2100.6775219795077
INFO:root:current train perplexity5.240819931030273
INFO:root:current mean train loss 2102.081761421354
INFO:root:current train perplexity5.239861011505127
INFO:root:current mean train loss 2101.7776357952866
INFO:root:current train perplexity5.242420673370361
INFO:root:current mean train loss 2101.631785290358
INFO:root:current train perplexity5.23859977722168
INFO:root:current mean train loss 2102.3673600105303
INFO:root:current train perplexity5.243221282958984
INFO:root:current mean train loss 2101.297520595572
INFO:root:current train perplexity5.239960670471191
INFO:root:current mean train loss 2100.1183789472084
INFO:root:current train perplexity5.2364959716796875
INFO:root:current mean train loss 2100.181213482414
INFO:root:current train perplexity5.234879970550537
INFO:root:current mean train loss 2099.632562154624
INFO:root:current train perplexity5.232527256011963
INFO:root:current mean train loss 2100.2039155122166
INFO:root:current train perplexity5.238245964050293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it]
INFO:root:final mean train loss: 2099.5391875866744
INFO:root:final train perplexity: 5.237387657165527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2076.100550441877
INFO:root:eval perplexity: 5.360343933105469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2486.8164958548036
INFO:root:eval perplexity: 7.642973899841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/11
  6%|â–Œ         | 11/200 [1:56:51<33:16:59, 633.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2082.723886889081
INFO:root:current train perplexity5.105923175811768
INFO:root:current mean train loss 2066.182459021127
INFO:root:current train perplexity5.09907865524292
INFO:root:current mean train loss 2065.672049142264
INFO:root:current train perplexity5.098993301391602
INFO:root:current mean train loss 2069.8042539290195
INFO:root:current train perplexity5.1160078048706055
INFO:root:current mean train loss 2065.3160405414096
INFO:root:current train perplexity5.123201847076416
INFO:root:current mean train loss 2069.3498226855804
INFO:root:current train perplexity5.125382423400879
INFO:root:current mean train loss 2070.960897462361
INFO:root:current train perplexity5.117578029632568
INFO:root:current mean train loss 2071.2006887188395
INFO:root:current train perplexity5.114978313446045
INFO:root:current mean train loss 2071.8879580530033
INFO:root:current train perplexity5.117877960205078
INFO:root:current mean train loss 2073.991666658413
INFO:root:current train perplexity5.122772216796875
INFO:root:current mean train loss 2075.2270494324066
INFO:root:current train perplexity5.129091262817383
INFO:root:current mean train loss 2075.97131563801
INFO:root:current train perplexity5.1310224533081055
INFO:root:current mean train loss 2075.9748552242295
INFO:root:current train perplexity5.131056785583496
INFO:root:current mean train loss 2075.5211452027247
INFO:root:current train perplexity5.132327079772949
INFO:root:current mean train loss 2074.349084866961
INFO:root:current train perplexity5.134403705596924
INFO:root:current mean train loss 2076.224036121729
INFO:root:current train perplexity5.137888431549072
INFO:root:current mean train loss 2075.297407953482
INFO:root:current train perplexity5.138259410858154
INFO:root:current mean train loss 2075.6276514410038
INFO:root:current train perplexity5.139094829559326
INFO:root:current mean train loss 2075.6007182342755
INFO:root:current train perplexity5.141015529632568

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.93s/it]
INFO:root:final mean train loss: 2075.904768658598
INFO:root:final train perplexity: 5.140669345855713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2063.313545822252
INFO:root:eval perplexity: 5.305196762084961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2476.1223594719636
INFO:root:eval perplexity: 7.576420783996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/12
  6%|â–Œ         | 12/200 [2:07:30<33:11:37, 635.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2127.2654622395835
INFO:root:current train perplexity4.972235202789307
INFO:root:current mean train loss 2055.2960133969204
INFO:root:current train perplexity5.060256481170654
INFO:root:current mean train loss 2046.6176781865763
INFO:root:current train perplexity5.0247297286987305
INFO:root:current mean train loss 2051.353648572865
INFO:root:current train perplexity5.030652046203613
INFO:root:current mean train loss 2049.5997699141208
INFO:root:current train perplexity5.027303218841553
INFO:root:current mean train loss 2050.6913601399415
INFO:root:current train perplexity5.034346580505371
INFO:root:current mean train loss 2054.3590187085406
INFO:root:current train perplexity5.051175594329834
INFO:root:current mean train loss 2051.6193248591417
INFO:root:current train perplexity5.0391526222229
INFO:root:current mean train loss 2051.630224244532
INFO:root:current train perplexity5.039375305175781
INFO:root:current mean train loss 2052.502762736408
INFO:root:current train perplexity5.04482889175415
INFO:root:current mean train loss 2051.2323319348593
INFO:root:current train perplexity5.039167404174805
INFO:root:current mean train loss 2051.192769608277
INFO:root:current train perplexity5.044488430023193
INFO:root:current mean train loss 2050.270440942728
INFO:root:current train perplexity5.0445876121521
INFO:root:current mean train loss 2050.7500841282736
INFO:root:current train perplexity5.0457940101623535
INFO:root:current mean train loss 2051.7322647410124
INFO:root:current train perplexity5.043838024139404
INFO:root:current mean train loss 2051.5800153436617
INFO:root:current train perplexity5.042515754699707
INFO:root:current mean train loss 2052.8040094500548
INFO:root:current train perplexity5.047958850860596
INFO:root:current mean train loss 2053.455737362031
INFO:root:current train perplexity5.049749851226807
INFO:root:current mean train loss 2053.721890246941
INFO:root:current train perplexity5.0496602058410645
INFO:root:current mean train loss 2054.768763355249
INFO:root:current train perplexity5.051978588104248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.27s/it]
INFO:root:final mean train loss: 2053.7476537938196
INFO:root:final train perplexity: 5.051619529724121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.00s/it]
INFO:root:eval mean loss: 2053.2262646830673
INFO:root:eval perplexity: 5.2620930671691895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it]
INFO:root:eval mean loss: 2468.268164668523
INFO:root:eval perplexity: 7.527909755706787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/13
  6%|â–‹         | 13/200 [2:18:09<33:04:17, 636.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1996.267724609375
INFO:root:current train perplexity4.896087646484375
INFO:root:current mean train loss 2020.512749226888
INFO:root:current train perplexity4.90925407409668
INFO:root:current mean train loss 2021.1646756258879
INFO:root:current train perplexity4.942994594573975
INFO:root:current mean train loss 2023.513247680664
INFO:root:current train perplexity4.935433864593506
INFO:root:current mean train loss 2024.8259719122025
INFO:root:current train perplexity4.938066482543945
INFO:root:current mean train loss 2030.2141657902644
INFO:root:current train perplexity4.9473652839660645
INFO:root:current mean train loss 2027.0171762774069
INFO:root:current train perplexity4.939294338226318
INFO:root:current mean train loss 2025.6258053249783
INFO:root:current train perplexity4.94012975692749
INFO:root:current mean train loss 2025.3284590558308
INFO:root:current train perplexity4.947381019592285
INFO:root:current mean train loss 2024.9465702222742
INFO:root:current train perplexity4.950163841247559
INFO:root:current mean train loss 2026.715229587929
INFO:root:current train perplexity4.953424453735352
INFO:root:current mean train loss 2027.5472744532995
INFO:root:current train perplexity4.957113265991211
INFO:root:current mean train loss 2028.0896558417649
INFO:root:current train perplexity4.9548749923706055
INFO:root:current mean train loss 2030.2889154607599
INFO:root:current train perplexity4.956769943237305
INFO:root:current mean train loss 2030.540713887819
INFO:root:current train perplexity4.961517810821533
INFO:root:current mean train loss 2029.613064896433
INFO:root:current train perplexity4.962825775146484
INFO:root:current mean train loss 2030.23332436644
INFO:root:current train perplexity4.964168071746826
INFO:root:current mean train loss 2032.1946646047193
INFO:root:current train perplexity4.965816974639893
INFO:root:current mean train loss 2031.603558886182
INFO:root:current train perplexity4.96589994430542
INFO:root:current mean train loss 2032.2889366149902
INFO:root:current train perplexity4.969257354736328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.66s/it]
INFO:root:final mean train loss: 2033.096345056023
INFO:root:final train perplexity: 4.970010757446289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it]
INFO:root:eval mean loss: 2041.0339719082447
INFO:root:eval perplexity: 5.21046257019043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it]
INFO:root:eval mean loss: 2460.9388475350456
INFO:root:eval perplexity: 7.482921600341797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/14
  7%|â–‹         | 14/200 [2:28:43<32:50:26, 635.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2039.232230521537
INFO:root:current train perplexity4.806544780731201
INFO:root:current mean train loss 2026.9908108676436
INFO:root:current train perplexity4.881792068481445
INFO:root:current mean train loss 2016.2316333110825
INFO:root:current train perplexity4.875387191772461
INFO:root:current mean train loss 2014.3263700128664
INFO:root:current train perplexity4.868351936340332
INFO:root:current mean train loss 2015.0876819601867
INFO:root:current train perplexity4.873430252075195
INFO:root:current mean train loss 2017.2315969342849
INFO:root:current train perplexity4.882899284362793
INFO:root:current mean train loss 2013.8181535610038
INFO:root:current train perplexity4.879166603088379
INFO:root:current mean train loss 2012.672887007611
INFO:root:current train perplexity4.879821300506592
INFO:root:current mean train loss 2013.1334123508905
INFO:root:current train perplexity4.879056930541992
INFO:root:current mean train loss 2010.579841670766
INFO:root:current train perplexity4.875448703765869
INFO:root:current mean train loss 2010.3378576648386
INFO:root:current train perplexity4.879303932189941
INFO:root:current mean train loss 2010.923492834247
INFO:root:current train perplexity4.882517337799072
INFO:root:current mean train loss 2011.1621658214178
INFO:root:current train perplexity4.8833489418029785
INFO:root:current mean train loss 2012.5781634379966
INFO:root:current train perplexity4.887746334075928
INFO:root:current mean train loss 2011.3904348013712
INFO:root:current train perplexity4.883854866027832
INFO:root:current mean train loss 2013.2324734987496
INFO:root:current train perplexity4.888314247131348
INFO:root:current mean train loss 2013.5551067298697
INFO:root:current train perplexity4.889792442321777
INFO:root:current mean train loss 2014.0730536356011
INFO:root:current train perplexity4.892469882965088
INFO:root:current mean train loss 2014.1664380534032
INFO:root:current train perplexity4.893977165222168
INFO:root:current mean train loss 2014.7155570767254
INFO:root:current train perplexity4.897363662719727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.16s/it]
INFO:root:final mean train loss: 2015.1634945313976
INFO:root:final train perplexity: 4.900214672088623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2033.347690879876
INFO:root:eval perplexity: 5.178172588348389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2453.795398468667
INFO:root:eval perplexity: 7.439332485198975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/15
  8%|â–Š         | 15/200 [2:39:15<32:36:34, 634.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1969.5518143265335
INFO:root:current train perplexity4.783884048461914
INFO:root:current mean train loss 1986.9906307071835
INFO:root:current train perplexity4.828609943389893
INFO:root:current mean train loss 1994.2835972102607
INFO:root:current train perplexity4.834169387817383
INFO:root:current mean train loss 1991.0753170379812
INFO:root:current train perplexity4.824203968048096
INFO:root:current mean train loss 1992.4637262957738
INFO:root:current train perplexity4.816279411315918
INFO:root:current mean train loss 1997.2108299723602
INFO:root:current train perplexity4.831381320953369
INFO:root:current mean train loss 2000.4357645110617
INFO:root:current train perplexity4.836346626281738
INFO:root:current mean train loss 1997.5943261913026
INFO:root:current train perplexity4.825796127319336
INFO:root:current mean train loss 1997.8385394272816
INFO:root:current train perplexity4.829600811004639
INFO:root:current mean train loss 1997.4800860326995
INFO:root:current train perplexity4.830799579620361
INFO:root:current mean train loss 2000.539482565487
INFO:root:current train perplexity4.834027290344238
INFO:root:current mean train loss 1997.9126994167705
INFO:root:current train perplexity4.830010890960693
INFO:root:current mean train loss 1998.8946439752167
INFO:root:current train perplexity4.833065509796143
INFO:root:current mean train loss 2000.276076436571
INFO:root:current train perplexity4.832075595855713
INFO:root:current mean train loss 2000.532184333224
INFO:root:current train perplexity4.833171367645264
INFO:root:current mean train loss 1999.628182311776
INFO:root:current train perplexity4.833174228668213
INFO:root:current mean train loss 1998.422236782752
INFO:root:current train perplexity4.8311967849731445
INFO:root:current mean train loss 1998.4725280552932
INFO:root:current train perplexity4.832693099975586
INFO:root:current mean train loss 1998.925664117807
INFO:root:current train perplexity4.83369255065918
INFO:root:current mean train loss 1997.8755216413047
INFO:root:current train perplexity4.832037925720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.94s/it]
INFO:root:final mean train loss: 1997.557593826086
INFO:root:final train perplexity: 4.832645416259766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2028.806614652593
INFO:root:eval perplexity: 5.1591901779174805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.95s/it]
INFO:root:eval mean loss: 2452.585638384447
INFO:root:eval perplexity: 7.431976795196533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/16
  8%|â–Š         | 16/200 [2:49:45<32:22:00, 633.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2006.618643747249
INFO:root:current train perplexity4.784162998199463
INFO:root:current mean train loss 1985.8727227818897
INFO:root:current train perplexity4.764188766479492
INFO:root:current mean train loss 1983.0241856874136
INFO:root:current train perplexity4.768604278564453
INFO:root:current mean train loss 1983.4296891451525
INFO:root:current train perplexity4.767309665679932
INFO:root:current mean train loss 1981.6949913851015
INFO:root:current train perplexity4.772507190704346
INFO:root:current mean train loss 1980.9254250868817
INFO:root:current train perplexity4.76915168762207
INFO:root:current mean train loss 1980.3100689633593
INFO:root:current train perplexity4.7609944343566895
INFO:root:current mean train loss 1980.6430534234153
INFO:root:current train perplexity4.7634735107421875
INFO:root:current mean train loss 1980.3045651493883
INFO:root:current train perplexity4.763869285583496
INFO:root:current mean train loss 1979.712923939761
INFO:root:current train perplexity4.764688014984131
INFO:root:current mean train loss 1979.2534145494135
INFO:root:current train perplexity4.766295909881592
INFO:root:current mean train loss 1978.5713894499559
INFO:root:current train perplexity4.763118267059326
INFO:root:current mean train loss 1978.2578521656483
INFO:root:current train perplexity4.759618759155273
INFO:root:current mean train loss 1979.5743109037371
INFO:root:current train perplexity4.763012409210205
INFO:root:current mean train loss 1980.5397861255099
INFO:root:current train perplexity4.766305923461914
INFO:root:current mean train loss 1980.2720456964116
INFO:root:current train perplexity4.768274307250977
INFO:root:current mean train loss 1980.0986979751085
INFO:root:current train perplexity4.768227577209473
INFO:root:current mean train loss 1979.3212053847137
INFO:root:current train perplexity4.7648539543151855
INFO:root:current mean train loss 1979.6216690658823
INFO:root:current train perplexity4.76613187789917
INFO:root:current mean train loss 1980.8070009522846
INFO:root:current train perplexity4.76695442199707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.98s/it]
INFO:root:final mean train loss: 1980.5433450872947
INFO:root:final train perplexity: 4.7682318687438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2020.1890683005042
INFO:root:eval perplexity: 5.1233601570129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2446.040304413924
INFO:root:eval perplexity: 7.392300128936768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/17
  8%|â–Š         | 17/200 [3:00:24<32:16:31, 634.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.816793268377
INFO:root:current train perplexity4.711019039154053
INFO:root:current mean train loss 1951.500732421875
INFO:root:current train perplexity4.678816795349121
INFO:root:current mean train loss 1955.589597913954
INFO:root:current train perplexity4.692150115966797
INFO:root:current mean train loss 1964.5141214587024
INFO:root:current train perplexity4.702375411987305
INFO:root:current mean train loss 1959.8441767458055
INFO:root:current train perplexity4.689770698547363
INFO:root:current mean train loss 1964.7632425528805
INFO:root:current train perplexity4.7028117179870605
INFO:root:current mean train loss 1961.5965276318927
INFO:root:current train perplexity4.69917631149292
INFO:root:current mean train loss 1961.3720786777244
INFO:root:current train perplexity4.7015790939331055
INFO:root:current mean train loss 1962.5802074810406
INFO:root:current train perplexity4.705954074859619
INFO:root:current mean train loss 1962.1735523548202
INFO:root:current train perplexity4.704762935638428
INFO:root:current mean train loss 1962.4226472518023
INFO:root:current train perplexity4.705340385437012
INFO:root:current mean train loss 1963.1494240295206
INFO:root:current train perplexity4.7067341804504395
INFO:root:current mean train loss 1964.4662826253762
INFO:root:current train perplexity4.71058988571167
INFO:root:current mean train loss 1964.167958899946
INFO:root:current train perplexity4.711772918701172
INFO:root:current mean train loss 1963.971553269253
INFO:root:current train perplexity4.711755275726318
INFO:root:current mean train loss 1963.408226801106
INFO:root:current train perplexity4.710052490234375
INFO:root:current mean train loss 1963.5639501634932
INFO:root:current train perplexity4.711051940917969
INFO:root:current mean train loss 1964.4965275502045
INFO:root:current train perplexity4.71037483215332
INFO:root:current mean train loss 1966.5112839391677
INFO:root:current train perplexity4.713039398193359

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.45s/it]
INFO:root:final mean train loss: 1965.6298916461308
INFO:root:final train perplexity: 4.712478160858154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.64s/it]
INFO:root:eval mean loss: 2015.747310557264
INFO:root:eval perplexity: 5.104988098144531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2445.4423572729665
INFO:root:eval perplexity: 7.388686180114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/18
  9%|â–‰         | 18/200 [3:11:06<32:12:13, 637.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.6016845703125
INFO:root:current train perplexity4.3874430656433105
INFO:root:current mean train loss 1919.2836925688243
INFO:root:current train perplexity4.616597652435303
INFO:root:current mean train loss 1930.0622576457697
INFO:root:current train perplexity4.612123012542725
INFO:root:current mean train loss 1940.7257676421618
INFO:root:current train perplexity4.628002643585205
INFO:root:current mean train loss 1937.0608383367091
INFO:root:current train perplexity4.628586769104004
INFO:root:current mean train loss 1939.0319647760675
INFO:root:current train perplexity4.625513553619385
INFO:root:current mean train loss 1937.6677974480242
INFO:root:current train perplexity4.621988296508789
INFO:root:current mean train loss 1939.7270274060838
INFO:root:current train perplexity4.625945091247559
INFO:root:current mean train loss 1942.4621418259899
INFO:root:current train perplexity4.63550329208374
INFO:root:current mean train loss 1946.8003668853592
INFO:root:current train perplexity4.643820285797119
INFO:root:current mean train loss 1946.9092168551772
INFO:root:current train perplexity4.6442365646362305
INFO:root:current mean train loss 1947.6846760331237
INFO:root:current train perplexity4.646313190460205
INFO:root:current mean train loss 1947.5841456496369
INFO:root:current train perplexity4.647421836853027
INFO:root:current mean train loss 1947.4957725320282
INFO:root:current train perplexity4.647451877593994
INFO:root:current mean train loss 1948.5016720591916
INFO:root:current train perplexity4.647579193115234
INFO:root:current mean train loss 1949.8002304330616
INFO:root:current train perplexity4.64982271194458
INFO:root:current mean train loss 1950.5100268782855
INFO:root:current train perplexity4.6514058113098145
INFO:root:current mean train loss 1951.1498011077254
INFO:root:current train perplexity4.654147148132324
INFO:root:current mean train loss 1951.259739384955
INFO:root:current train perplexity4.656369209289551
INFO:root:current mean train loss 1952.0498203227526
INFO:root:current train perplexity4.659453392028809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.11s/it]
INFO:root:final mean train loss: 1951.2593604475935
INFO:root:final train perplexity: 4.6593708992004395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2013.845421324385
INFO:root:eval perplexity: 5.097141265869141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2444.4773840938055
INFO:root:eval perplexity: 7.382856845855713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/19
 10%|â–‰         | 19/200 [3:21:54<32:11:53, 640.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.2846235795455
INFO:root:current train perplexity4.601290225982666
INFO:root:current mean train loss 1921.4138003490011
INFO:root:current train perplexity4.590503692626953
INFO:root:current mean train loss 1939.3256137607334
INFO:root:current train perplexity4.6229119300842285
INFO:root:current mean train loss 1931.2639493764557
INFO:root:current train perplexity4.603455543518066
INFO:root:current mean train loss 1928.0632353145365
INFO:root:current train perplexity4.592140197753906
INFO:root:current mean train loss 1933.861147358043
INFO:root:current train perplexity4.604100704193115
INFO:root:current mean train loss 1932.8705416860305
INFO:root:current train perplexity4.599581718444824
INFO:root:current mean train loss 1935.8935223946612
INFO:root:current train perplexity4.610351085662842
INFO:root:current mean train loss 1934.208819387023
INFO:root:current train perplexity4.610049247741699
INFO:root:current mean train loss 1935.2905866577414
INFO:root:current train perplexity4.608494281768799
INFO:root:current mean train loss 1936.4878071824164
INFO:root:current train perplexity4.608233451843262
INFO:root:current mean train loss 1938.101679239256
INFO:root:current train perplexity4.609518051147461
INFO:root:current mean train loss 1938.0206171962907
INFO:root:current train perplexity4.6068525314331055
INFO:root:current mean train loss 1937.3237772839152
INFO:root:current train perplexity4.604912281036377
INFO:root:current mean train loss 1936.489369323988
INFO:root:current train perplexity4.601961612701416
INFO:root:current mean train loss 1936.274587302891
INFO:root:current train perplexity4.6016764640808105
INFO:root:current mean train loss 1937.430680017436
INFO:root:current train perplexity4.6043572425842285
INFO:root:current mean train loss 1937.1168000933462
INFO:root:current train perplexity4.6044602394104
INFO:root:current mean train loss 1937.656684816865
INFO:root:current train perplexity4.605810165405273
INFO:root:current mean train loss 1937.7570951304997
INFO:root:current train perplexity4.607904434204102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.07s/it]
INFO:root:final mean train loss: 1937.2595637749976
INFO:root:final train perplexity: 4.608209609985352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2008.3456507473127
INFO:root:eval perplexity: 5.074520111083984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 2441.732227081948
INFO:root:eval perplexity: 7.3663010597229
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/20
 10%|â–ˆ         | 20/200 [3:32:24<31:51:33, 637.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.48631247496
INFO:root:current train perplexity4.4715142250061035
INFO:root:current mean train loss 1908.7913458295864
INFO:root:current train perplexity4.513546466827393
INFO:root:current mean train loss 1919.8276811543867
INFO:root:current train perplexity4.524141311645508
INFO:root:current mean train loss 1918.8533150551946
INFO:root:current train perplexity4.517090320587158
INFO:root:current mean train loss 1921.2625101215476
INFO:root:current train perplexity4.539766788482666
INFO:root:current mean train loss 1916.4456787109375
INFO:root:current train perplexity4.5341620445251465
INFO:root:current mean train loss 1919.6200184232566
INFO:root:current train perplexity4.539126396179199
INFO:root:current mean train loss 1919.2647014612758
INFO:root:current train perplexity4.534144878387451
INFO:root:current mean train loss 1921.128663564325
INFO:root:current train perplexity4.540354251861572
INFO:root:current mean train loss 1922.5160785711612
INFO:root:current train perplexity4.544304847717285
INFO:root:current mean train loss 1923.7145102008014
INFO:root:current train perplexity4.547525405883789
INFO:root:current mean train loss 1923.8099429538315
INFO:root:current train perplexity4.551087379455566
INFO:root:current mean train loss 1922.2592097567974
INFO:root:current train perplexity4.5498785972595215
INFO:root:current mean train loss 1923.5132710212554
INFO:root:current train perplexity4.549314022064209
INFO:root:current mean train loss 1924.6842339617085
INFO:root:current train perplexity4.550652503967285
INFO:root:current mean train loss 1924.3103719789383
INFO:root:current train perplexity4.553149700164795
INFO:root:current mean train loss 1925.1029578552805
INFO:root:current train perplexity4.553974151611328
INFO:root:current mean train loss 1926.1734052661373
INFO:root:current train perplexity4.5572404861450195
INFO:root:current mean train loss 1924.9107174813714
INFO:root:current train perplexity4.555328845977783
INFO:root:current mean train loss 1923.6202956657548
INFO:root:current train perplexity4.557160377502441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.99s/it]
INFO:root:final mean train loss: 1923.657249031317
INFO:root:final train perplexity: 4.559039115905762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2003.869118548454
INFO:root:eval perplexity: 5.056182861328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2439.3982751724566
INFO:root:eval perplexity: 7.3522539138793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/21
 10%|â–ˆ         | 21/200 [3:43:01<31:40:39, 637.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1911.1305302211217
INFO:root:current train perplexity4.506712913513184
INFO:root:current mean train loss 1916.0630618364382
INFO:root:current train perplexity4.493518352508545
INFO:root:current mean train loss 1911.4476628303528
INFO:root:current train perplexity4.49667501449585
INFO:root:current mean train loss 1910.4212745923674
INFO:root:current train perplexity4.495851039886475
INFO:root:current mean train loss 1905.305166679516
INFO:root:current train perplexity4.500990867614746
INFO:root:current mean train loss 1904.5928641120306
INFO:root:current train perplexity4.496275901794434
INFO:root:current mean train loss 1905.430840655071
INFO:root:current train perplexity4.497560977935791
INFO:root:current mean train loss 1909.3302909407034
INFO:root:current train perplexity4.501824855804443
INFO:root:current mean train loss 1905.0835769510716
INFO:root:current train perplexity4.4925384521484375
INFO:root:current mean train loss 1907.3154725908735
INFO:root:current train perplexity4.497084140777588
INFO:root:current mean train loss 1906.9560470581055
INFO:root:current train perplexity4.4977803230285645
INFO:root:current mean train loss 1907.2857626944676
INFO:root:current train perplexity4.500890254974365
INFO:root:current mean train loss 1908.0749909224783
INFO:root:current train perplexity4.502076148986816
INFO:root:current mean train loss 1908.0620031666263
INFO:root:current train perplexity4.500377655029297
INFO:root:current mean train loss 1908.4076239617316
INFO:root:current train perplexity4.500271320343018
INFO:root:current mean train loss 1909.8223308180782
INFO:root:current train perplexity4.504001140594482
INFO:root:current mean train loss 1911.6775004069011
INFO:root:current train perplexity4.507596015930176
INFO:root:current mean train loss 1911.0667399273918
INFO:root:current train perplexity4.508461952209473
INFO:root:current mean train loss 1911.6916363814782
INFO:root:current train perplexity4.51133918762207
INFO:root:current mean train loss 1911.9713421843046
INFO:root:current train perplexity4.514672756195068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.81s/it]
INFO:root:final mean train loss: 1911.1688328760774
INFO:root:final train perplexity: 4.514357089996338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2001.1579724034518
INFO:root:eval perplexity: 5.045108795166016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2438.0690112824136
INFO:root:eval perplexity: 7.344264984130859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/22
 11%|â–ˆ         | 22/200 [3:53:30<31:23:29, 634.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1903.908935546875
INFO:root:current train perplexity4.447312831878662
INFO:root:current mean train loss 1899.8048512012283
INFO:root:current train perplexity4.442869663238525
INFO:root:current mean train loss 1904.6808777973329
INFO:root:current train perplexity4.442567825317383
INFO:root:current mean train loss 1900.4726889766252
INFO:root:current train perplexity4.438401699066162
INFO:root:current mean train loss 1897.5300233611092
INFO:root:current train perplexity4.4358696937561035
INFO:root:current mean train loss 1894.9961525482656
INFO:root:current train perplexity4.436931133270264
INFO:root:current mean train loss 1892.8197558376091
INFO:root:current train perplexity4.431155681610107
INFO:root:current mean train loss 1894.723167587221
INFO:root:current train perplexity4.438805103302002
INFO:root:current mean train loss 1893.0784684188861
INFO:root:current train perplexity4.442953109741211
INFO:root:current mean train loss 1894.970676527974
INFO:root:current train perplexity4.451167106628418
INFO:root:current mean train loss 1896.9173100481273
INFO:root:current train perplexity4.454530715942383
INFO:root:current mean train loss 1896.7413394599519
INFO:root:current train perplexity4.455141544342041
INFO:root:current mean train loss 1897.7901384064464
INFO:root:current train perplexity4.458634376525879
INFO:root:current mean train loss 1898.1048155449118
INFO:root:current train perplexity4.457884311676025
INFO:root:current mean train loss 1898.1969471482785
INFO:root:current train perplexity4.4589362144470215
INFO:root:current mean train loss 1898.8433518940221
INFO:root:current train perplexity4.4595818519592285
INFO:root:current mean train loss 1899.1931924312612
INFO:root:current train perplexity4.4623494148254395
INFO:root:current mean train loss 1899.7300544820528
INFO:root:current train perplexity4.468019962310791
INFO:root:current mean train loss 1900.213657002365
INFO:root:current train perplexity4.47266149520874
INFO:root:current mean train loss 1900.0122082067878
INFO:root:current train perplexity4.472740650177002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it]
INFO:root:final mean train loss: 1899.299239642922
INFO:root:final train perplexity: 4.472294807434082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 1999.5343255658522
INFO:root:eval perplexity: 5.038487434387207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2437.451327276568
INFO:root:eval perplexity: 7.340557098388672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/23
 12%|â–ˆâ–        | 23/200 [4:04:04<31:11:49, 634.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.036488172743
INFO:root:current train perplexity4.354762077331543
INFO:root:current mean train loss 1874.3774105674343
INFO:root:current train perplexity4.387887001037598
INFO:root:current mean train loss 1873.7873480435076
INFO:root:current train perplexity4.392963409423828
INFO:root:current mean train loss 1878.6406422150442
INFO:root:current train perplexity4.3987884521484375
INFO:root:current mean train loss 1878.8788051060267
INFO:root:current train perplexity4.4011077880859375
INFO:root:current mean train loss 1881.9448653916181
INFO:root:current train perplexity4.403093338012695
INFO:root:current mean train loss 1882.131683791893
INFO:root:current train perplexity4.4069976806640625
INFO:root:current mean train loss 1882.3194043895867
INFO:root:current train perplexity4.413431644439697
INFO:root:current mean train loss 1883.2936203860165
INFO:root:current train perplexity4.41569185256958
INFO:root:current mean train loss 1881.3527107007576
INFO:root:current train perplexity4.412845611572266
INFO:root:current mean train loss 1881.4900876666427
INFO:root:current train perplexity4.408701419830322
INFO:root:current mean train loss 1882.3322852383142
INFO:root:current train perplexity4.413488388061523
INFO:root:current mean train loss 1882.924880200763
INFO:root:current train perplexity4.417942047119141
INFO:root:current mean train loss 1883.4739339485443
INFO:root:current train perplexity4.42067289352417
INFO:root:current mean train loss 1884.6239528169567
INFO:root:current train perplexity4.424431800842285
INFO:root:current mean train loss 1884.4633379090508
INFO:root:current train perplexity4.425334453582764
INFO:root:current mean train loss 1884.5609038403754
INFO:root:current train perplexity4.426565647125244
INFO:root:current mean train loss 1886.161995760955
INFO:root:current train perplexity4.427233695983887
INFO:root:current mean train loss 1886.8232667307375
INFO:root:current train perplexity4.428721904754639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.77s/it]
INFO:root:final mean train loss: 1887.677286322166
INFO:root:final train perplexity: 4.43148946762085
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 1995.8781803212266
INFO:root:eval perplexity: 5.023612022399902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2438.284386168135
INFO:root:eval perplexity: 7.345559120178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/24
 12%|â–ˆâ–        | 24/200 [4:14:34<30:57:35, 633.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.7154541015625
INFO:root:current train perplexity4.331909656524658
INFO:root:current mean train loss 1862.7404830790013
INFO:root:current train perplexity4.3377766609191895
INFO:root:current mean train loss 1865.729565311745
INFO:root:current train perplexity4.338804244995117
INFO:root:current mean train loss 1862.8841214754682
INFO:root:current train perplexity4.341614723205566
INFO:root:current mean train loss 1857.315674128052
INFO:root:current train perplexity4.331029415130615
INFO:root:current mean train loss 1858.8525513417621
INFO:root:current train perplexity4.339106559753418
INFO:root:current mean train loss 1864.0669007654835
INFO:root:current train perplexity4.351397514343262
INFO:root:current mean train loss 1865.255623176715
INFO:root:current train perplexity4.358287811279297
INFO:root:current mean train loss 1867.6782146392407
INFO:root:current train perplexity4.3648600578308105
INFO:root:current mean train loss 1869.1723642233583
INFO:root:current train perplexity4.370085716247559
INFO:root:current mean train loss 1870.7641542163838
INFO:root:current train perplexity4.375209331512451
INFO:root:current mean train loss 1871.065533011694
INFO:root:current train perplexity4.374875068664551
INFO:root:current mean train loss 1871.917216707876
INFO:root:current train perplexity4.3761115074157715
INFO:root:current mean train loss 1871.0363366054778
INFO:root:current train perplexity4.375241279602051
INFO:root:current mean train loss 1872.264976908149
INFO:root:current train perplexity4.380043983459473
INFO:root:current mean train loss 1873.9493251868882
INFO:root:current train perplexity4.38362979888916
INFO:root:current mean train loss 1874.8501448284119
INFO:root:current train perplexity4.387085914611816
INFO:root:current mean train loss 1874.8946038342808
INFO:root:current train perplexity4.387852668762207
INFO:root:current mean train loss 1875.4092296775561
INFO:root:current train perplexity4.38991117477417
INFO:root:current mean train loss 1875.7994097993208
INFO:root:current train perplexity4.3899617195129395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.83s/it]
INFO:root:final mean train loss: 1876.3905102551373
INFO:root:final train perplexity: 4.392218589782715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 1995.406822258699
INFO:root:eval perplexity: 5.021697521209717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2437.1309866397937
INFO:root:eval perplexity: 7.338634014129639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/25
 12%|â–ˆâ–Ž        | 25/200 [4:25:23<31:00:39, 637.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1846.3273061116536
INFO:root:current train perplexity4.317301273345947
INFO:root:current mean train loss 1869.67869617093
INFO:root:current train perplexity4.343261241912842
INFO:root:current mean train loss 1862.7177276611328
INFO:root:current train perplexity4.318537712097168
INFO:root:current mean train loss 1861.31098467038
INFO:root:current train perplexity4.319971084594727
INFO:root:current mean train loss 1867.2530710472251
INFO:root:current train perplexity4.344089031219482
INFO:root:current mean train loss 1863.0253158452856
INFO:root:current train perplexity4.337554454803467
INFO:root:current mean train loss 1863.3844365829077
INFO:root:current train perplexity4.338321685791016
INFO:root:current mean train loss 1859.3851434697103
INFO:root:current train perplexity4.340090274810791
INFO:root:current mean train loss 1861.094642713232
INFO:root:current train perplexity4.341577529907227
INFO:root:current mean train loss 1861.159957291244
INFO:root:current train perplexity4.343886852264404
INFO:root:current mean train loss 1863.9928011894226
INFO:root:current train perplexity4.3478312492370605
INFO:root:current mean train loss 1863.6966557078515
INFO:root:current train perplexity4.344282627105713
INFO:root:current mean train loss 1865.782297869913
INFO:root:current train perplexity4.349137783050537
INFO:root:current mean train loss 1866.763164600937
INFO:root:current train perplexity4.350264549255371
INFO:root:current mean train loss 1866.512639592203
INFO:root:current train perplexity4.353723526000977
INFO:root:current mean train loss 1866.0178555866553
INFO:root:current train perplexity4.350850582122803
INFO:root:current mean train loss 1866.8457077853197
INFO:root:current train perplexity4.352986812591553
INFO:root:current mean train loss 1867.398989011406
INFO:root:current train perplexity4.354258060455322
INFO:root:current mean train loss 1866.2204483433773
INFO:root:current train perplexity4.3539533615112305
INFO:root:current mean train loss 1866.2537971226936
INFO:root:current train perplexity4.3540873527526855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.88s/it]
INFO:root:final mean train loss: 1865.5395959958967
INFO:root:final train perplexity: 4.35479211807251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.72s/it]
INFO:root:eval mean loss: 1993.0182698567708
INFO:root:eval perplexity: 5.01200532913208
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2436.8126307277817
INFO:root:eval perplexity: 7.336723804473877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/26
 13%|â–ˆâ–Ž        | 26/200 [4:35:54<30:44:10, 635.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.9703964605565
INFO:root:current train perplexity4.277639865875244
INFO:root:current mean train loss 1834.9477547719969
INFO:root:current train perplexity4.26616096496582
INFO:root:current mean train loss 1838.918235177321
INFO:root:current train perplexity4.27606201171875
INFO:root:current mean train loss 1838.4703494432736
INFO:root:current train perplexity4.284841060638428
INFO:root:current mean train loss 1842.1898971177013
INFO:root:current train perplexity4.292590141296387
INFO:root:current mean train loss 1844.2746586544015
INFO:root:current train perplexity4.29126501083374
INFO:root:current mean train loss 1849.1257204243248
INFO:root:current train perplexity4.307571887969971
INFO:root:current mean train loss 1850.0035561833145
INFO:root:current train perplexity4.3049702644348145
INFO:root:current mean train loss 1851.931534811376
INFO:root:current train perplexity4.307110786437988
INFO:root:current mean train loss 1852.78945582326
INFO:root:current train perplexity4.3085408210754395
INFO:root:current mean train loss 1852.7131875337716
INFO:root:current train perplexity4.310032844543457
INFO:root:current mean train loss 1852.6725765031017
INFO:root:current train perplexity4.311784744262695
INFO:root:current mean train loss 1851.173156689099
INFO:root:current train perplexity4.308147430419922
INFO:root:current mean train loss 1853.3799814882784
INFO:root:current train perplexity4.312904357910156
INFO:root:current mean train loss 1852.9790925999469
INFO:root:current train perplexity4.312554836273193
INFO:root:current mean train loss 1854.1988223581482
INFO:root:current train perplexity4.3151140213012695
INFO:root:current mean train loss 1854.371522446655
INFO:root:current train perplexity4.314130783081055
INFO:root:current mean train loss 1855.164730065448
INFO:root:current train perplexity4.316174507141113
INFO:root:current mean train loss 1855.0850954734392
INFO:root:current train perplexity4.31666374206543
INFO:root:current mean train loss 1855.861243222928
INFO:root:current train perplexity4.319272518157959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.71s/it]
INFO:root:final mean train loss: 1855.2897972610942
INFO:root:final train perplexity: 4.319731712341309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.67s/it]
INFO:root:eval mean loss: 1992.9841408154643
INFO:root:eval perplexity: 5.011867046356201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2441.219627001607
INFO:root:eval perplexity: 7.36321496963501
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/27
 14%|â–ˆâ–Ž        | 27/200 [4:46:30<30:33:25, 635.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1836.1926416857489
INFO:root:current train perplexity4.216490268707275
INFO:root:current mean train loss 1833.4902629610858
INFO:root:current train perplexity4.2424187660217285
INFO:root:current mean train loss 1834.6118641934654
INFO:root:current train perplexity4.258583068847656
INFO:root:current mean train loss 1831.1468758183485
INFO:root:current train perplexity4.253050327301025
INFO:root:current mean train loss 1832.8910341221172
INFO:root:current train perplexity4.2564191818237305
INFO:root:current mean train loss 1834.7555172281027
INFO:root:current train perplexity4.259297847747803
INFO:root:current mean train loss 1834.8377954546804
INFO:root:current train perplexity4.2594709396362305
INFO:root:current mean train loss 1837.2456289809738
INFO:root:current train perplexity4.26050329208374
INFO:root:current mean train loss 1837.8894659011237
INFO:root:current train perplexity4.264658451080322
INFO:root:current mean train loss 1840.5690896307003
INFO:root:current train perplexity4.266798973083496
INFO:root:current mean train loss 1839.6563649168538
INFO:root:current train perplexity4.265098571777344
INFO:root:current mean train loss 1838.6654710522587
INFO:root:current train perplexity4.262968063354492
INFO:root:current mean train loss 1839.0853390837701
INFO:root:current train perplexity4.266375541687012
INFO:root:current mean train loss 1839.6293450019848
INFO:root:current train perplexity4.27003812789917
INFO:root:current mean train loss 1840.7414459521551
INFO:root:current train perplexity4.275007247924805
INFO:root:current mean train loss 1842.278767851412
INFO:root:current train perplexity4.2773661613464355
INFO:root:current mean train loss 1842.8494597689235
INFO:root:current train perplexity4.280506610870361
INFO:root:current mean train loss 1844.2320267782547
INFO:root:current train perplexity4.284356594085693
INFO:root:current mean train loss 1844.8691008108938
INFO:root:current train perplexity4.286597728729248
INFO:root:current mean train loss 1846.516910042534
INFO:root:current train perplexity4.287521839141846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it]
INFO:root:final mean train loss: 1845.6900913932982
INFO:root:final train perplexity: 4.2871503829956055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 1993.5067203602891
INFO:root:eval perplexity: 5.013987064361572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2443.1964293134974
INFO:root:eval perplexity: 7.375125408172607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/28
 14%|â–ˆâ–        | 28/200 [4:57:00<30:17:54, 634.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1825.8425895182293
INFO:root:current train perplexity4.225301742553711
INFO:root:current mean train loss 1825.1064153180803
INFO:root:current train perplexity4.208874225616455
INFO:root:current mean train loss 1824.4558158735795
INFO:root:current train perplexity4.206905841827393
INFO:root:current mean train loss 1826.9979130859374
INFO:root:current train perplexity4.212687969207764
INFO:root:current mean train loss 1830.3786880653784
INFO:root:current train perplexity4.227531433105469
INFO:root:current mean train loss 1831.485222486413
INFO:root:current train perplexity4.228343486785889
INFO:root:current mean train loss 1829.4120062934028
INFO:root:current train perplexity4.228991985321045
INFO:root:current mean train loss 1832.408968781502
INFO:root:current train perplexity4.236862659454346
INFO:root:current mean train loss 1834.2593955078125
INFO:root:current train perplexity4.2382402420043945
INFO:root:current mean train loss 1835.4834938401443
INFO:root:current train perplexity4.245305061340332
INFO:root:current mean train loss 1836.0668815861193
INFO:root:current train perplexity4.242198467254639
INFO:root:current mean train loss 1833.2263328000333
INFO:root:current train perplexity4.2392425537109375
INFO:root:current mean train loss 1833.1796090877758
INFO:root:current train perplexity4.241255283355713
INFO:root:current mean train loss 1833.1746285511363
INFO:root:current train perplexity4.243069171905518
INFO:root:current mean train loss 1834.4500512281516
INFO:root:current train perplexity4.246510982513428
INFO:root:current mean train loss 1834.9101217602927
INFO:root:current train perplexity4.2466721534729
INFO:root:current mean train loss 1835.633300416861
INFO:root:current train perplexity4.247923851013184
INFO:root:current mean train loss 1835.6913064618177
INFO:root:current train perplexity4.24902868270874
INFO:root:current mean train loss 1835.3688182291667
INFO:root:current train perplexity4.249153137207031
INFO:root:current mean train loss 1835.7467389611352
INFO:root:current train perplexity4.2516770362854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.94s/it]
INFO:root:final mean train loss: 1835.1533439509267
INFO:root:final train perplexity: 4.25167179107666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 1992.5160375283965
INFO:root:eval perplexity: 5.009970664978027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2443.2908926889404
INFO:root:eval perplexity: 7.375696182250977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/29
 14%|â–ˆâ–        | 29/200 [5:07:33<30:06:27, 633.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.3872667395551
INFO:root:current train perplexity4.173382759094238
INFO:root:current mean train loss 1819.4270273844402
INFO:root:current train perplexity4.183689117431641
INFO:root:current mean train loss 1816.163793694483
INFO:root:current train perplexity4.186450958251953
INFO:root:current mean train loss 1816.2727876001475
INFO:root:current train perplexity4.1950907707214355
INFO:root:current mean train loss 1817.6236646698742
INFO:root:current train perplexity4.198777675628662
INFO:root:current mean train loss 1820.1701917906066
INFO:root:current train perplexity4.194999694824219
INFO:root:current mean train loss 1817.6974748379923
INFO:root:current train perplexity4.193907737731934
INFO:root:current mean train loss 1819.1045687897038
INFO:root:current train perplexity4.197818756103516
INFO:root:current mean train loss 1820.6478995421542
INFO:root:current train perplexity4.200772762298584
INFO:root:current mean train loss 1822.6709064360589
INFO:root:current train perplexity4.20950984954834
INFO:root:current mean train loss 1823.3870531019274
INFO:root:current train perplexity4.209427356719971
INFO:root:current mean train loss 1824.4537469236643
INFO:root:current train perplexity4.211000919342041
INFO:root:current mean train loss 1824.8268173737422
INFO:root:current train perplexity4.213376522064209
INFO:root:current mean train loss 1825.218079490223
INFO:root:current train perplexity4.2141642570495605
INFO:root:current mean train loss 1824.3072521219945
INFO:root:current train perplexity4.2137227058410645
INFO:root:current mean train loss 1824.5734095741157
INFO:root:current train perplexity4.217487812042236
INFO:root:current mean train loss 1825.2998440789838
INFO:root:current train perplexity4.218639850616455
INFO:root:current mean train loss 1826.0425784247261
INFO:root:current train perplexity4.21851921081543
INFO:root:current mean train loss 1826.022631397207
INFO:root:current train perplexity4.218618869781494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.63s/it]
INFO:root:final mean train loss: 1825.6374373520136
INFO:root:final train perplexity: 4.219883441925049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 1990.7464699170268
INFO:root:eval perplexity: 5.002806663513184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it]
INFO:root:eval mean loss: 2440.5966173537236
INFO:root:eval perplexity: 7.359462738037109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/30
 15%|â–ˆâ–Œ        | 30/200 [5:18:06<29:55:15, 633.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.0202772352432
INFO:root:current train perplexity4.157440662384033
INFO:root:current mean train loss 1796.8484446674313
INFO:root:current train perplexity4.126339912414551
INFO:root:current mean train loss 1793.101883153596
INFO:root:current train perplexity4.119521141052246
INFO:root:current mean train loss 1802.6228303878438
INFO:root:current train perplexity4.1402363777160645
INFO:root:current mean train loss 1803.4561125888217
INFO:root:current train perplexity4.140687942504883
INFO:root:current mean train loss 1804.847214014919
INFO:root:current train perplexity4.141427993774414
INFO:root:current mean train loss 1805.3304834224907
INFO:root:current train perplexity4.151711463928223
INFO:root:current mean train loss 1806.9023602785614
INFO:root:current train perplexity4.152003288269043
INFO:root:current mean train loss 1806.9187164118027
INFO:root:current train perplexity4.157520771026611
INFO:root:current mean train loss 1810.328657597205
INFO:root:current train perplexity4.165134429931641
INFO:root:current mean train loss 1810.901541642793
INFO:root:current train perplexity4.167459487915039
INFO:root:current mean train loss 1810.4333736051624
INFO:root:current train perplexity4.173193454742432
INFO:root:current mean train loss 1811.2820345213631
INFO:root:current train perplexity4.175867080688477
INFO:root:current mean train loss 1811.9644983348453
INFO:root:current train perplexity4.179951190948486
INFO:root:current mean train loss 1812.9159635566837
INFO:root:current train perplexity4.181275844573975
INFO:root:current mean train loss 1812.8771473535091
INFO:root:current train perplexity4.181368827819824
INFO:root:current mean train loss 1814.0530496790514
INFO:root:current train perplexity4.18380880355835
INFO:root:current mean train loss 1814.509360414419
INFO:root:current train perplexity4.181914806365967
INFO:root:current mean train loss 1815.0122158035776
INFO:root:current train perplexity4.183108329772949
INFO:root:current mean train loss 1815.7748605239572
INFO:root:current train perplexity4.184805870056152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.51s/it]
INFO:root:final mean train loss: 1815.6619480304266
INFO:root:final train perplexity: 4.18681526184082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 1990.3324623919548
INFO:root:eval perplexity: 5.001131057739258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2442.145088791002
INFO:root:eval perplexity: 7.368791103363037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/31
 16%|â–ˆâ–Œ        | 31/200 [5:28:54<29:56:09, 637.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1795.441650390625
INFO:root:current train perplexity4.115153789520264
INFO:root:current mean train loss 1812.9256591796875
INFO:root:current train perplexity4.13541316986084
INFO:root:current mean train loss 1805.2008510353292
INFO:root:current train perplexity4.127223968505859
INFO:root:current mean train loss 1801.0233753414973
INFO:root:current train perplexity4.130191802978516
INFO:root:current mean train loss 1804.9719883018815
INFO:root:current train perplexity4.13098669052124
INFO:root:current mean train loss 1804.7257381772813
INFO:root:current train perplexity4.131751537322998
INFO:root:current mean train loss 1801.8201192545052
INFO:root:current train perplexity4.13105583190918
INFO:root:current mean train loss 1800.8118674538352
INFO:root:current train perplexity4.13179349899292
INFO:root:current mean train loss 1802.856734379729
INFO:root:current train perplexity4.133270263671875
INFO:root:current mean train loss 1802.9463875360675
INFO:root:current train perplexity4.140232563018799
INFO:root:current mean train loss 1802.953307629561
INFO:root:current train perplexity4.140932083129883
INFO:root:current mean train loss 1802.7056918372905
INFO:root:current train perplexity4.144906997680664
INFO:root:current mean train loss 1803.135407937876
INFO:root:current train perplexity4.147132873535156
INFO:root:current mean train loss 1803.7716998852575
INFO:root:current train perplexity4.1480512619018555
INFO:root:current mean train loss 1803.3485512325506
INFO:root:current train perplexity4.148349285125732
INFO:root:current mean train loss 1804.2272386063441
INFO:root:current train perplexity4.151573181152344
INFO:root:current mean train loss 1805.4197755557877
INFO:root:current train perplexity4.153417110443115
INFO:root:current mean train loss 1805.4602877549473
INFO:root:current train perplexity4.151237964630127
INFO:root:current mean train loss 1806.3259838225415
INFO:root:current train perplexity4.155559539794922
INFO:root:current mean train loss 1806.0390964718003
INFO:root:current train perplexity4.155338764190674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.19s/it]
INFO:root:final mean train loss: 1806.4352280640326
INFO:root:final train perplexity: 4.156458854675293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 1990.0054200084496
INFO:root:eval perplexity: 4.999807834625244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2445.9379822210217
INFO:root:eval perplexity: 7.391681671142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/32
 16%|â–ˆâ–Œ        | 32/200 [5:39:33<29:46:36, 638.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.9643043695494
INFO:root:current train perplexity4.070218086242676
INFO:root:current mean train loss 1795.3502385066106
INFO:root:current train perplexity4.10749626159668
INFO:root:current mean train loss 1799.0616841885287
INFO:root:current train perplexity4.093295574188232
INFO:root:current mean train loss 1791.269287109375
INFO:root:current train perplexity4.084944248199463
INFO:root:current mean train loss 1789.5138209495803
INFO:root:current train perplexity4.098878383636475
INFO:root:current mean train loss 1790.5497426407114
INFO:root:current train perplexity4.104781627655029
INFO:root:current mean train loss 1792.4532525758166
INFO:root:current train perplexity4.112565994262695
INFO:root:current mean train loss 1793.3061446219401
INFO:root:current train perplexity4.117706298828125
INFO:root:current mean train loss 1794.8119045633155
INFO:root:current train perplexity4.122536659240723
INFO:root:current mean train loss 1795.146374602333
INFO:root:current train perplexity4.119490146636963
INFO:root:current mean train loss 1794.5775913081256
INFO:root:current train perplexity4.120073318481445
INFO:root:current mean train loss 1793.3860253094583
INFO:root:current train perplexity4.1175537109375
INFO:root:current mean train loss 1794.334363254538
INFO:root:current train perplexity4.118510723114014
INFO:root:current mean train loss 1795.3405304523164
INFO:root:current train perplexity4.119697570800781
INFO:root:current mean train loss 1796.5097622412075
INFO:root:current train perplexity4.12367057800293
INFO:root:current mean train loss 1796.2278453062977
INFO:root:current train perplexity4.124192237854004
INFO:root:current mean train loss 1797.0149141243153
INFO:root:current train perplexity4.125485897064209
INFO:root:current mean train loss 1796.9019994598932
INFO:root:current train perplexity4.123867511749268
INFO:root:current mean train loss 1798.3564418020678
INFO:root:current train perplexity4.127232074737549
INFO:root:current mean train loss 1797.9230740282626
INFO:root:current train perplexity4.12578821182251

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.11s/it]
INFO:root:final mean train loss: 1797.5522348285624
INFO:root:final train perplexity: 4.12744140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.13s/it]
INFO:root:eval mean loss: 1991.1765712440438
INFO:root:eval perplexity: 5.004546642303467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it]
INFO:root:eval mean loss: 2447.454347001745
INFO:root:eval perplexity: 7.4008564949035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/33
 16%|â–ˆâ–‹        | 33/200 [5:50:15<29:39:41, 639.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.9938924153646
INFO:root:current train perplexity4.055853843688965
INFO:root:current mean train loss 1780.4371292114258
INFO:root:current train perplexity4.094338893890381
INFO:root:current mean train loss 1783.6675354003905
INFO:root:current train perplexity4.093801498413086
INFO:root:current mean train loss 1780.1326571994357
INFO:root:current train perplexity4.087677001953125
INFO:root:current mean train loss 1780.9712720788043
INFO:root:current train perplexity4.0908355712890625
INFO:root:current mean train loss 1777.6120261056083
INFO:root:current train perplexity4.0787577629089355
INFO:root:current mean train loss 1776.4449551669034
INFO:root:current train perplexity4.079205513000488
INFO:root:current mean train loss 1779.761356875771
INFO:root:current train perplexity4.0783891677856445
INFO:root:current mean train loss 1778.8455817643987
INFO:root:current train perplexity4.076009750366211
INFO:root:current mean train loss 1780.741003672282
INFO:root:current train perplexity4.080083847045898
INFO:root:current mean train loss 1782.0737336932489
INFO:root:current train perplexity4.081113815307617
INFO:root:current mean train loss 1783.0083319302264
INFO:root:current train perplexity4.081704616546631
INFO:root:current mean train loss 1783.5736064608134
INFO:root:current train perplexity4.084006309509277
INFO:root:current mean train loss 1785.2987887214213
INFO:root:current train perplexity4.086612224578857
INFO:root:current mean train loss 1787.0678711773598
INFO:root:current train perplexity4.0888237953186035
INFO:root:current mean train loss 1788.2667451516177
INFO:root:current train perplexity4.091084003448486
INFO:root:current mean train loss 1789.1970982563064
INFO:root:current train perplexity4.094559192657471
INFO:root:current mean train loss 1789.311586484042
INFO:root:current train perplexity4.095653057098389
INFO:root:current mean train loss 1789.0319694929226
INFO:root:current train perplexity4.097148895263672
INFO:root:current mean train loss 1788.7959247822664
INFO:root:current train perplexity4.097738265991211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.38s/it]
INFO:root:final mean train loss: 1788.491461357082
INFO:root:final train perplexity: 4.098052978515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it]
INFO:root:eval mean loss: 1990.511158178884
INFO:root:eval perplexity: 5.001854419708252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 2449.5829350897607
INFO:root:eval perplexity: 7.413748741149902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/34
 17%|â–ˆâ–‹        | 34/200 [6:01:10<29:42:05, 644.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1774.1806260146104
INFO:root:current train perplexity4.026815414428711
INFO:root:current mean train loss 1770.9217177568855
INFO:root:current train perplexity4.050391674041748
INFO:root:current mean train loss 1771.5677230229016
INFO:root:current train perplexity4.0507893562316895
INFO:root:current mean train loss 1771.6135273333887
INFO:root:current train perplexity4.050543785095215
INFO:root:current mean train loss 1772.8206244574653
INFO:root:current train perplexity4.049601078033447
INFO:root:current mean train loss 1773.1435756319731
INFO:root:current train perplexity4.055133819580078
INFO:root:current mean train loss 1772.4009447196386
INFO:root:current train perplexity4.054044723510742
INFO:root:current mean train loss 1773.326968709781
INFO:root:current train perplexity4.0521650314331055
INFO:root:current mean train loss 1775.6328424260173
INFO:root:current train perplexity4.05704402923584
INFO:root:current mean train loss 1777.1432738133317
INFO:root:current train perplexity4.0596795082092285
INFO:root:current mean train loss 1776.211367749681
INFO:root:current train perplexity4.05863094329834
INFO:root:current mean train loss 1776.3867599240987
INFO:root:current train perplexity4.064213752746582
INFO:root:current mean train loss 1776.879498343591
INFO:root:current train perplexity4.064729690551758
INFO:root:current mean train loss 1776.9786318444478
INFO:root:current train perplexity4.065154552459717
INFO:root:current mean train loss 1777.8891766030965
INFO:root:current train perplexity4.065611839294434
INFO:root:current mean train loss 1778.9286024133542
INFO:root:current train perplexity4.06632661819458
INFO:root:current mean train loss 1778.9373258842054
INFO:root:current train perplexity4.065911769866943
INFO:root:current mean train loss 1779.2523889922666
INFO:root:current train perplexity4.066788196563721
INFO:root:current mean train loss 1780.1902320467543
INFO:root:current train perplexity4.068385601043701
INFO:root:current mean train loss 1780.1782864390689
INFO:root:current train perplexity4.069755554199219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.58s/it]
INFO:root:final mean train loss: 1779.6422903702467
INFO:root:final train perplexity: 4.069552421569824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 1992.2559961630097
INFO:root:eval perplexity: 5.00891637802124
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 2454.3374131655864
INFO:root:eval perplexity: 7.44263219833374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/35
 18%|â–ˆâ–Š        | 35/200 [6:11:52<29:28:57, 643.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1778.122028756649
INFO:root:current train perplexity4.009572505950928
INFO:root:current mean train loss 1770.4287505788902
INFO:root:current train perplexity4.009456157684326
INFO:root:current mean train loss 1768.3559142651202
INFO:root:current train perplexity4.020475387573242
INFO:root:current mean train loss 1764.8023340835184
INFO:root:current train perplexity4.01876974105835
INFO:root:current mean train loss 1766.2003378926017
INFO:root:current train perplexity4.025956153869629
INFO:root:current mean train loss 1766.2800780016967
INFO:root:current train perplexity4.027555465698242
INFO:root:current mean train loss 1770.0273557107798
INFO:root:current train perplexity4.03779411315918
INFO:root:current mean train loss 1773.068498049335
INFO:root:current train perplexity4.039422512054443
INFO:root:current mean train loss 1772.047835723399
INFO:root:current train perplexity4.033151626586914
INFO:root:current mean train loss 1770.1102518430898
INFO:root:current train perplexity4.028311252593994
INFO:root:current mean train loss 1769.1126976780308
INFO:root:current train perplexity4.030725002288818
INFO:root:current mean train loss 1768.7678671474232
INFO:root:current train perplexity4.0321478843688965
INFO:root:current mean train loss 1769.6937269066364
INFO:root:current train perplexity4.035175323486328
INFO:root:current mean train loss 1770.4154776924822
INFO:root:current train perplexity4.035984992980957
INFO:root:current mean train loss 1771.4722814598238
INFO:root:current train perplexity4.038074493408203
INFO:root:current mean train loss 1772.2186188931148
INFO:root:current train perplexity4.0394134521484375
INFO:root:current mean train loss 1773.1110231654
INFO:root:current train perplexity4.040308475494385
INFO:root:current mean train loss 1773.3913121048024
INFO:root:current train perplexity4.041422367095947
INFO:root:current mean train loss 1772.936058938692
INFO:root:current train perplexity4.044189929962158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.31s/it]
INFO:root:final mean train loss: 1771.7835460668614
INFO:root:final train perplexity: 4.044407844543457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.53s/it]
INFO:root:eval mean loss: 1994.9800462655141
INFO:root:eval perplexity: 5.01996374130249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2453.9903157552085
INFO:root:eval perplexity: 7.440520763397217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/36
 18%|â–ˆâ–Š        | 36/200 [6:22:44<29:25:34, 645.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.8422296697443
INFO:root:current train perplexity4.011362075805664
INFO:root:current mean train loss 1747.716270103111
INFO:root:current train perplexity3.96797776222229
INFO:root:current mean train loss 1752.8804688657065
INFO:root:current train perplexity3.986834764480591
INFO:root:current mean train loss 1755.3064844064006
INFO:root:current train perplexity3.9903652667999268
INFO:root:current mean train loss 1759.7647191254182
INFO:root:current train perplexity3.994314432144165
INFO:root:current mean train loss 1760.2501015261894
INFO:root:current train perplexity3.997244358062744
INFO:root:current mean train loss 1760.2449445708878
INFO:root:current train perplexity3.996738910675049
INFO:root:current mean train loss 1758.2944332503737
INFO:root:current train perplexity3.99652099609375
INFO:root:current mean train loss 1758.7055007802867
INFO:root:current train perplexity3.997847080230713
INFO:root:current mean train loss 1761.1967202614744
INFO:root:current train perplexity4.001468181610107
INFO:root:current mean train loss 1762.157855146127
INFO:root:current train perplexity4.005886077880859
INFO:root:current mean train loss 1761.2443966320461
INFO:root:current train perplexity4.007269859313965
INFO:root:current mean train loss 1761.6255168080036
INFO:root:current train perplexity4.008556365966797
INFO:root:current mean train loss 1761.9262864777006
INFO:root:current train perplexity4.0093584060668945
INFO:root:current mean train loss 1762.0853563899439
INFO:root:current train perplexity4.011561870574951
INFO:root:current mean train loss 1762.7025518108094
INFO:root:current train perplexity4.01357889175415
INFO:root:current mean train loss 1762.0324379691865
INFO:root:current train perplexity4.012564182281494
INFO:root:current mean train loss 1762.7344830154607
INFO:root:current train perplexity4.013502597808838
INFO:root:current mean train loss 1763.75269848862
INFO:root:current train perplexity4.015554428100586
INFO:root:current mean train loss 1763.6577929661948
INFO:root:current train perplexity4.016361713409424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.88s/it]
INFO:root:final mean train loss: 1763.0750316902656
INFO:root:final train perplexity: 4.016725540161133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.49s/it]
INFO:root:eval mean loss: 1995.6857117997838
INFO:root:eval perplexity: 5.022829532623291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.04s/it]
INFO:root:eval mean loss: 2458.8887697043992
INFO:root:eval perplexity: 7.470386505126953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/37
 18%|â–ˆâ–Š        | 37/200 [6:33:27<29:12:59, 645.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1715.747567313058
INFO:root:current train perplexity3.970066547393799
INFO:root:current mean train loss 1761.4747867584229
INFO:root:current train perplexity3.984065532684326
INFO:root:current mean train loss 1756.1055758292214
INFO:root:current train perplexity3.988555669784546
INFO:root:current mean train loss 1748.898121159251
INFO:root:current train perplexity3.9816477298736572
INFO:root:current mean train loss 1746.8243622111384
INFO:root:current train perplexity3.9790759086608887
INFO:root:current mean train loss 1747.859077684807
INFO:root:current train perplexity3.9722390174865723
INFO:root:current mean train loss 1749.8271634047198
INFO:root:current train perplexity3.975853681564331
INFO:root:current mean train loss 1749.3847158243368
INFO:root:current train perplexity3.9763095378875732
INFO:root:current mean train loss 1751.3701653964279
INFO:root:current train perplexity3.9784817695617676
INFO:root:current mean train loss 1753.4189266336375
INFO:root:current train perplexity3.979386329650879
INFO:root:current mean train loss 1754.7913259068353
INFO:root:current train perplexity3.9795594215393066
INFO:root:current mean train loss 1755.3583968142245
INFO:root:current train perplexity3.984863042831421
INFO:root:current mean train loss 1754.6145304825873
INFO:root:current train perplexity3.98753023147583
INFO:root:current mean train loss 1754.4590250038239
INFO:root:current train perplexity3.984651565551758
INFO:root:current mean train loss 1755.3338794013698
INFO:root:current train perplexity3.986506938934326
INFO:root:current mean train loss 1755.7232436734344
INFO:root:current train perplexity3.98648738861084
INFO:root:current mean train loss 1755.108873671923
INFO:root:current train perplexity3.986180305480957
INFO:root:current mean train loss 1756.0429895189072
INFO:root:current train perplexity3.9869179725646973
INFO:root:current mean train loss 1755.330427708198
INFO:root:current train perplexity3.9888229370117188
INFO:root:current mean train loss 1755.2943783202113
INFO:root:current train perplexity3.990166425704956

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:36<00:00, 576.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:36<00:00, 576.54s/it]
INFO:root:final mean train loss: 1755.1449798568594
INFO:root:final train perplexity: 3.991682529449463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 1995.1860654573914
INFO:root:eval perplexity: 5.020800590515137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2459.3801689418497
INFO:root:eval perplexity: 7.473390102386475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/38
 19%|â–ˆâ–‰        | 38/200 [6:44:20<29:08:31, 647.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.6609266493056
INFO:root:current train perplexity3.944448232650757
INFO:root:current mean train loss 1741.6949976427802
INFO:root:current train perplexity3.950749397277832
INFO:root:current mean train loss 1744.3803461814414
INFO:root:current train perplexity3.9506189823150635
INFO:root:current mean train loss 1749.584803838315
INFO:root:current train perplexity3.958930492401123
INFO:root:current mean train loss 1746.2373521440484
INFO:root:current train perplexity3.9609756469726562
INFO:root:current mean train loss 1743.4110454594324
INFO:root:current train perplexity3.958414316177368
INFO:root:current mean train loss 1743.9657133826913
INFO:root:current train perplexity3.9541168212890625
INFO:root:current mean train loss 1743.9401843999055
INFO:root:current train perplexity3.95668625831604
INFO:root:current mean train loss 1743.859502559865
INFO:root:current train perplexity3.9557156562805176
INFO:root:current mean train loss 1741.94426760396
INFO:root:current train perplexity3.950901985168457
INFO:root:current mean train loss 1741.7092968516372
INFO:root:current train perplexity3.951805591583252
INFO:root:current mean train loss 1742.181168655329
INFO:root:current train perplexity3.9530937671661377
INFO:root:current mean train loss 1741.5583032324612
INFO:root:current train perplexity3.9540038108825684
INFO:root:current mean train loss 1743.2006295016263
INFO:root:current train perplexity3.9561712741851807
INFO:root:current mean train loss 1744.0540426815257
INFO:root:current train perplexity3.9579343795776367
INFO:root:current mean train loss 1744.8752457208232
INFO:root:current train perplexity3.9602394104003906
INFO:root:current mean train loss 1746.114231246438
INFO:root:current train perplexity3.9617769718170166
INFO:root:current mean train loss 1746.9899521792174
INFO:root:current train perplexity3.9636948108673096
INFO:root:current mean train loss 1747.5566466458122
INFO:root:current train perplexity3.965433120727539
INFO:root:current mean train loss 1747.77124111303
INFO:root:current train perplexity3.966249704360962

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.91s/it]
INFO:root:final mean train loss: 1747.5889201585055
INFO:root:final train perplexity: 3.967965841293335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it]
INFO:root:eval mean loss: 1995.9759746578568
INFO:root:eval perplexity: 5.024008750915527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2463.3806667463155
INFO:root:eval perplexity: 7.497881889343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/39
 20%|â–ˆâ–‰        | 39/200 [6:55:05<28:55:31, 646.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.4119400516634
INFO:root:current train perplexity3.894489049911499
INFO:root:current mean train loss 1733.969398027585
INFO:root:current train perplexity3.8953564167022705
INFO:root:current mean train loss 1727.2465116777494
INFO:root:current train perplexity3.8955399990081787
INFO:root:current mean train loss 1726.8134333995165
INFO:root:current train perplexity3.8965747356414795
INFO:root:current mean train loss 1728.2393809396983
INFO:root:current train perplexity3.8967902660369873
INFO:root:current mean train loss 1728.089015539855
INFO:root:current train perplexity3.904282569885254
INFO:root:current mean train loss 1731.3260131098352
INFO:root:current train perplexity3.9138991832733154
INFO:root:current mean train loss 1734.7976711803847
INFO:root:current train perplexity3.9184763431549072
INFO:root:current mean train loss 1735.551347843179
INFO:root:current train perplexity3.91865611076355
INFO:root:current mean train loss 1737.2943705283183
INFO:root:current train perplexity3.9216136932373047
INFO:root:current mean train loss 1740.3241035763153
INFO:root:current train perplexity3.931051254272461
INFO:root:current mean train loss 1739.4389128430576
INFO:root:current train perplexity3.9292478561401367
INFO:root:current mean train loss 1738.4623941218986
INFO:root:current train perplexity3.9277689456939697
INFO:root:current mean train loss 1739.297605808611
INFO:root:current train perplexity3.9295313358306885
INFO:root:current mean train loss 1740.2338331146866
INFO:root:current train perplexity3.9336631298065186
INFO:root:current mean train loss 1741.0089246527639
INFO:root:current train perplexity3.936267614364624
INFO:root:current mean train loss 1740.2277599936072
INFO:root:current train perplexity3.9362974166870117
INFO:root:current mean train loss 1740.3966993489953
INFO:root:current train perplexity3.9376158714294434
INFO:root:current mean train loss 1739.9818536121275
INFO:root:current train perplexity3.9391262531280518
INFO:root:current mean train loss 1739.3704071200466
INFO:root:current train perplexity3.939682722091675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.73s/it]
INFO:root:final mean train loss: 1738.5915149375157
INFO:root:final train perplexity: 3.9399099349975586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it]
INFO:root:eval mean loss: 1997.06922295753
INFO:root:eval perplexity: 5.028453350067139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.33s/it]
INFO:root:eval mean loss: 2463.9210850059562
INFO:root:eval perplexity: 7.501194953918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/40
 20%|â–ˆâ–ˆ        | 40/200 [7:06:01<28:52:11, 649.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1719.9896889215784
INFO:root:current train perplexity3.8944530487060547
INFO:root:current mean train loss 1716.1151102588162
INFO:root:current train perplexity3.892585277557373
INFO:root:current mean train loss 1718.0076996177756
INFO:root:current train perplexity3.8905389308929443
INFO:root:current mean train loss 1721.228307880009
INFO:root:current train perplexity3.8963897228240967
INFO:root:current mean train loss 1720.3969041031935
INFO:root:current train perplexity3.895764112472534
INFO:root:current mean train loss 1720.7928656543475
INFO:root:current train perplexity3.895052909851074
INFO:root:current mean train loss 1720.4997074986768
INFO:root:current train perplexity3.894404172897339
INFO:root:current mean train loss 1723.1561932741295
INFO:root:current train perplexity3.89669132232666
INFO:root:current mean train loss 1727.1875863796752
INFO:root:current train perplexity3.90303897857666
INFO:root:current mean train loss 1727.3342689147887
INFO:root:current train perplexity3.9059247970581055
INFO:root:current mean train loss 1728.2714512270838
INFO:root:current train perplexity3.9100072383880615
INFO:root:current mean train loss 1730.5223171243838
INFO:root:current train perplexity3.910999298095703
INFO:root:current mean train loss 1729.5693431910918
INFO:root:current train perplexity3.9079127311706543
INFO:root:current mean train loss 1730.4078938329972
INFO:root:current train perplexity3.9105753898620605
INFO:root:current mean train loss 1730.4103379936296
INFO:root:current train perplexity3.910463571548462
INFO:root:current mean train loss 1731.1689347985275
INFO:root:current train perplexity3.91280198097229
INFO:root:current mean train loss 1730.5361598584536
INFO:root:current train perplexity3.9126598834991455
INFO:root:current mean train loss 1731.2648242352182
INFO:root:current train perplexity3.914325714111328
INFO:root:current mean train loss 1731.5038965701297
INFO:root:current train perplexity3.9163994789123535
INFO:root:current mean train loss 1731.5984270385927
INFO:root:current train perplexity3.9169700145721436

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.87s/it]
INFO:root:final mean train loss: 1731.231770494762
INFO:root:final train perplexity: 3.9171078205108643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.94s/it]
INFO:root:eval mean loss: 1998.1217357013243
INFO:root:eval perplexity: 5.032734394073486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2466.650957256344
INFO:root:eval perplexity: 7.517960548400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/41
 20%|â–ˆâ–ˆ        | 41/200 [7:16:51<28:41:08, 649.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1710.4709714253743
INFO:root:current train perplexity3.8421099185943604
INFO:root:current mean train loss 1721.467260866749
INFO:root:current train perplexity3.875734329223633
INFO:root:current mean train loss 1730.1426626669395
INFO:root:current train perplexity3.882748603820801
INFO:root:current mean train loss 1727.4532544685133
INFO:root:current train perplexity3.8768317699432373
INFO:root:current mean train loss 1722.3451060633506
INFO:root:current train perplexity3.8787899017333984
INFO:root:current mean train loss 1724.1008356081559
INFO:root:current train perplexity3.878361225128174
INFO:root:current mean train loss 1725.4456243405398
INFO:root:current train perplexity3.880805492401123
INFO:root:current mean train loss 1724.0531715891468
INFO:root:current train perplexity3.8762357234954834
INFO:root:current mean train loss 1723.4757383891515
INFO:root:current train perplexity3.8788745403289795
INFO:root:current mean train loss 1723.373531847115
INFO:root:current train perplexity3.8809919357299805
INFO:root:current mean train loss 1723.8672054318615
INFO:root:current train perplexity3.8837289810180664
INFO:root:current mean train loss 1724.3122803550898
INFO:root:current train perplexity3.885021448135376
INFO:root:current mean train loss 1725.1297257034867
INFO:root:current train perplexity3.8865084648132324
INFO:root:current mean train loss 1725.8502702685687
INFO:root:current train perplexity3.889014720916748
INFO:root:current mean train loss 1725.0702189073206
INFO:root:current train perplexity3.8901238441467285
INFO:root:current mean train loss 1724.677464611847
INFO:root:current train perplexity3.88932204246521
INFO:root:current mean train loss 1723.8529395337375
INFO:root:current train perplexity3.889599323272705
INFO:root:current mean train loss 1723.2143348065144
INFO:root:current train perplexity3.8909480571746826
INFO:root:current mean train loss 1723.4600946611492
INFO:root:current train perplexity3.890803813934326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.78s/it]
INFO:root:final mean train loss: 1723.4243204075462
INFO:root:final train perplexity: 3.8930623531341553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.82s/it]
INFO:root:eval mean loss: 2000.6700837696699
INFO:root:eval perplexity: 5.043117523193359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2471.2989744362258
INFO:root:eval perplexity: 7.546595096588135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/42
 21%|â–ˆâ–ˆ        | 42/200 [7:27:49<28:37:16, 652.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1689.109403170072
INFO:root:current train perplexity3.837543487548828
INFO:root:current mean train loss 1711.061309544386
INFO:root:current train perplexity3.8162083625793457
INFO:root:current mean train loss 1700.0048226369938
INFO:root:current train perplexity3.8313205242156982
INFO:root:current mean train loss 1700.0621872191994
INFO:root:current train perplexity3.830413818359375
INFO:root:current mean train loss 1703.8540278474009
INFO:root:current train perplexity3.833446741104126
INFO:root:current mean train loss 1704.6505046048824
INFO:root:current train perplexity3.8397696018218994
INFO:root:current mean train loss 1707.731078105883
INFO:root:current train perplexity3.8473076820373535
INFO:root:current mean train loss 1709.3469976181736
INFO:root:current train perplexity3.8508265018463135
INFO:root:current mean train loss 1708.0813579864314
INFO:root:current train perplexity3.8474719524383545
INFO:root:current mean train loss 1707.5814394830743
INFO:root:current train perplexity3.848414897918701
INFO:root:current mean train loss 1708.4471137902578
INFO:root:current train perplexity3.849104642868042
INFO:root:current mean train loss 1710.1947485417368
INFO:root:current train perplexity3.8524868488311768
INFO:root:current mean train loss 1711.6891024118597
INFO:root:current train perplexity3.853264093399048
INFO:root:current mean train loss 1710.942359012043
INFO:root:current train perplexity3.853053092956543
INFO:root:current mean train loss 1711.2736665222212
INFO:root:current train perplexity3.8554153442382812
INFO:root:current mean train loss 1711.1940752572755
INFO:root:current train perplexity3.854609251022339
INFO:root:current mean train loss 1712.9516653024257
INFO:root:current train perplexity3.8598239421844482
INFO:root:current mean train loss 1714.370213318762
INFO:root:current train perplexity3.863292694091797
INFO:root:current mean train loss 1715.5880850756687
INFO:root:current train perplexity3.8672571182250977
INFO:root:current mean train loss 1717.2430353558507
INFO:root:current train perplexity3.8714675903320312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.85s/it]
INFO:root:final mean train loss: 1716.3866767671693
INFO:root:final train perplexity: 3.8715150356292725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2002.74044778161
INFO:root:eval perplexity: 5.051568508148193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2471.024845204455
INFO:root:eval perplexity: 7.544902324676514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:38:30<28:17:26, 648.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1705.3078125
INFO:root:current train perplexity3.8011245727539062
INFO:root:current mean train loss 1693.3286837064302
INFO:root:current train perplexity3.7981953620910645
INFO:root:current mean train loss 1697.167644467561
INFO:root:current train perplexity3.8006539344787598
INFO:root:current mean train loss 1701.367665423769
INFO:root:current train perplexity3.816072463989258
INFO:root:current mean train loss 1700.597661927689
INFO:root:current train perplexity3.812840223312378
INFO:root:current mean train loss 1702.488324780734
INFO:root:current train perplexity3.8181490898132324
INFO:root:current mean train loss 1701.9066539946057
INFO:root:current train perplexity3.81795072555542
INFO:root:current mean train loss 1703.055912049176
INFO:root:current train perplexity3.825688600540161
INFO:root:current mean train loss 1704.6664256635918
INFO:root:current train perplexity3.830834150314331
INFO:root:current mean train loss 1703.7224605437248
INFO:root:current train perplexity3.8300249576568604
INFO:root:current mean train loss 1702.2327496871208
INFO:root:current train perplexity3.8311007022857666
INFO:root:current mean train loss 1701.8652215198078
INFO:root:current train perplexity3.8294336795806885
INFO:root:current mean train loss 1702.2478515625
INFO:root:current train perplexity3.8294217586517334
INFO:root:current mean train loss 1702.9152804496593
INFO:root:current train perplexity3.8345842361450195
INFO:root:current mean train loss 1704.2331458458534
INFO:root:current train perplexity3.8365590572357178
INFO:root:current mean train loss 1706.2214648277932
INFO:root:current train perplexity3.838120698928833
INFO:root:current mean train loss 1706.693178216665
INFO:root:current train perplexity3.8406729698181152
INFO:root:current mean train loss 1708.5155524634213
INFO:root:current train perplexity3.8429136276245117
INFO:root:current mean train loss 1709.3619476818646
INFO:root:current train perplexity3.8449268341064453
INFO:root:current mean train loss 1709.054129581748
INFO:root:current train perplexity3.846520185470581

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.08s/it]
INFO:root:final mean train loss: 1708.608091599642
INFO:root:final train perplexity: 3.847836971282959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2005.2987883006426
INFO:root:eval perplexity: 5.062031269073486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2478.495417601673
INFO:root:eval perplexity: 7.591140270233154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:49:11<28:00:28, 646.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.6690310214428
INFO:root:current train perplexity3.760166645050049
INFO:root:current mean train loss 1690.0297320099914
INFO:root:current train perplexity3.786862850189209
INFO:root:current mean train loss 1692.4345070533907
INFO:root:current train perplexity3.798393726348877
INFO:root:current mean train loss 1690.704342888824
INFO:root:current train perplexity3.799528121948242
INFO:root:current mean train loss 1692.101992886605
INFO:root:current train perplexity3.802621603012085
INFO:root:current mean train loss 1689.7013615637854
INFO:root:current train perplexity3.803234577178955
INFO:root:current mean train loss 1692.7306742130145
INFO:root:current train perplexity3.8048830032348633
INFO:root:current mean train loss 1693.711717148542
INFO:root:current train perplexity3.80816650390625
INFO:root:current mean train loss 1694.7971447941263
INFO:root:current train perplexity3.8106563091278076
INFO:root:current mean train loss 1695.2111089398263
INFO:root:current train perplexity3.8140435218811035
INFO:root:current mean train loss 1696.048725875082
INFO:root:current train perplexity3.815627098083496
INFO:root:current mean train loss 1697.5687130277013
INFO:root:current train perplexity3.8174846172332764
INFO:root:current mean train loss 1697.3247487328965
INFO:root:current train perplexity3.8164968490600586
INFO:root:current mean train loss 1698.3671026760858
INFO:root:current train perplexity3.818016290664673
INFO:root:current mean train loss 1699.2641590595574
INFO:root:current train perplexity3.8180744647979736
INFO:root:current mean train loss 1700.6455272238102
INFO:root:current train perplexity3.8219375610351562
INFO:root:current mean train loss 1701.0553710789266
INFO:root:current train perplexity3.823674201965332
INFO:root:current mean train loss 1701.6680477777752
INFO:root:current train perplexity3.823277235031128
INFO:root:current mean train loss 1701.627172415361
INFO:root:current train perplexity3.82431960105896
INFO:root:current mean train loss 1702.2313086965723
INFO:root:current train perplexity3.8264598846435547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.18s/it]
INFO:root:final mean train loss: 1701.5744880987909
INFO:root:final train perplexity: 3.8265514373779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 2005.1046454247007
INFO:root:eval perplexity: 5.06123685836792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2480.049093476424
INFO:root:eval perplexity: 7.600793361663818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:59:53<27:46:34, 645.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1706.1749477386475
INFO:root:current train perplexity3.807466506958008
INFO:root:current mean train loss 1692.1328020793635
INFO:root:current train perplexity3.768012285232544
INFO:root:current mean train loss 1685.3307282418916
INFO:root:current train perplexity3.7660529613494873
INFO:root:current mean train loss 1681.2847279978323
INFO:root:current train perplexity3.7564923763275146
INFO:root:current mean train loss 1678.9802090875035
INFO:root:current train perplexity3.7607269287109375
INFO:root:current mean train loss 1683.1594288061697
INFO:root:current train perplexity3.7708747386932373
INFO:root:current mean train loss 1686.0170611645801
INFO:root:current train perplexity3.7723872661590576
INFO:root:current mean train loss 1685.2161484962983
INFO:root:current train perplexity3.7787857055664062
INFO:root:current mean train loss 1688.6152099326805
INFO:root:current train perplexity3.783682107925415
INFO:root:current mean train loss 1690.1135866790391
INFO:root:current train perplexity3.7851321697235107
INFO:root:current mean train loss 1690.269397133275
INFO:root:current train perplexity3.788408041000366
INFO:root:current mean train loss 1691.0913019868517
INFO:root:current train perplexity3.7901110649108887
INFO:root:current mean train loss 1690.4181481856333
INFO:root:current train perplexity3.790024757385254
INFO:root:current mean train loss 1690.456595591436
INFO:root:current train perplexity3.793229341506958
INFO:root:current mean train loss 1690.4769503900914
INFO:root:current train perplexity3.7950987815856934
INFO:root:current mean train loss 1690.5514542757703
INFO:root:current train perplexity3.796642303466797
INFO:root:current mean train loss 1692.080129623413
INFO:root:current train perplexity3.799870252609253
INFO:root:current mean train loss 1692.8523689667925
INFO:root:current train perplexity3.8002829551696777
INFO:root:current mean train loss 1693.7577328006596
INFO:root:current train perplexity3.801837921142578
INFO:root:current mean train loss 1694.364605688029
INFO:root:current train perplexity3.8035805225372314

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.47s/it]
INFO:root:final mean train loss: 1694.1062027723935
INFO:root:final train perplexity: 3.80407977104187
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2007.5443240767675
INFO:root:eval perplexity: 5.07123327255249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2484.0331840785684
INFO:root:eval perplexity: 7.62559700012207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [8:10:29<27:28:56, 642.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.4819592134452
INFO:root:current train perplexity3.736034870147705
INFO:root:current mean train loss 1675.060160431414
INFO:root:current train perplexity3.7475640773773193
INFO:root:current mean train loss 1669.3264399083907
INFO:root:current train perplexity3.74371600151062
INFO:root:current mean train loss 1673.5615362532808
INFO:root:current train perplexity3.7465622425079346
INFO:root:current mean train loss 1673.054311137685
INFO:root:current train perplexity3.757934093475342
INFO:root:current mean train loss 1675.3741188246288
INFO:root:current train perplexity3.756190538406372
INFO:root:current mean train loss 1676.4898780228982
INFO:root:current train perplexity3.757094621658325
INFO:root:current mean train loss 1677.4099840073823
INFO:root:current train perplexity3.7604031562805176
INFO:root:current mean train loss 1677.8016326938937
INFO:root:current train perplexity3.766059398651123
INFO:root:current mean train loss 1679.334165800602
INFO:root:current train perplexity3.768505096435547
INFO:root:current mean train loss 1680.593011593179
INFO:root:current train perplexity3.7718117237091064
INFO:root:current mean train loss 1682.108623352826
INFO:root:current train perplexity3.7745721340179443
INFO:root:current mean train loss 1683.1321381115522
INFO:root:current train perplexity3.7751238346099854
INFO:root:current mean train loss 1684.2727241709472
INFO:root:current train perplexity3.7754855155944824
INFO:root:current mean train loss 1685.0782009951574
INFO:root:current train perplexity3.774738073348999
INFO:root:current mean train loss 1686.2188644264409
INFO:root:current train perplexity3.776324510574341
INFO:root:current mean train loss 1687.5278612235556
INFO:root:current train perplexity3.7789721488952637
INFO:root:current mean train loss 1687.7430970986059
INFO:root:current train perplexity3.7793819904327393
INFO:root:current mean train loss 1687.0744414747808
INFO:root:current train perplexity3.7813031673431396
INFO:root:current mean train loss 1687.8078758089546
INFO:root:current train perplexity3.784013271331787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.47s/it]
INFO:root:final mean train loss: 1687.4326594165643
INFO:root:final train perplexity: 3.7841107845306396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2010.282404040614
INFO:root:eval perplexity: 5.082475185394287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2488.76000283965
INFO:root:eval perplexity: 7.655132293701172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [8:21:16<27:21:20, 643.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.965067960778
INFO:root:current train perplexity3.737990617752075
INFO:root:current mean train loss 1669.2145250108506
INFO:root:current train perplexity3.72481369972229
INFO:root:current mean train loss 1665.4200279696677
INFO:root:current train perplexity3.7176401615142822
INFO:root:current mean train loss 1665.798136802175
INFO:root:current train perplexity3.7298030853271484
INFO:root:current mean train loss 1666.3929328152453
INFO:root:current train perplexity3.7341413497924805
INFO:root:current mean train loss 1669.013063973009
INFO:root:current train perplexity3.739182472229004
INFO:root:current mean train loss 1671.2995180496173
INFO:root:current train perplexity3.7431132793426514
INFO:root:current mean train loss 1672.1088449578535
INFO:root:current train perplexity3.7446913719177246
INFO:root:current mean train loss 1675.3097092388468
INFO:root:current train perplexity3.7508370876312256
INFO:root:current mean train loss 1675.7952726742546
INFO:root:current train perplexity3.7476463317871094
INFO:root:current mean train loss 1676.5819927833988
INFO:root:current train perplexity3.7490100860595703
INFO:root:current mean train loss 1679.1162732972923
INFO:root:current train perplexity3.7524731159210205
INFO:root:current mean train loss 1679.4218693573046
INFO:root:current train perplexity3.751586675643921
INFO:root:current mean train loss 1679.3724524152808
INFO:root:current train perplexity3.754124879837036
INFO:root:current mean train loss 1679.8965412542243
INFO:root:current train perplexity3.7574682235717773
INFO:root:current mean train loss 1680.5635583755818
INFO:root:current train perplexity3.7596888542175293
INFO:root:current mean train loss 1680.4730408649423
INFO:root:current train perplexity3.761794090270996
INFO:root:current mean train loss 1681.3302021641884
INFO:root:current train perplexity3.7619478702545166
INFO:root:current mean train loss 1681.0800630752356
INFO:root:current train perplexity3.7632758617401123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.11s/it]
INFO:root:final mean train loss: 1680.7187503693503
INFO:root:final train perplexity: 3.7641265392303467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2009.3422479291335
INFO:root:eval perplexity: 5.078612327575684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2489.481253116689
INFO:root:eval perplexity: 7.659650802612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/48
 24%|â–ˆâ–ˆâ–       | 48/200 [8:31:49<27:02:52, 640.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1648.7032389322917
INFO:root:current train perplexity3.679234743118286
INFO:root:current mean train loss 1668.788814113451
INFO:root:current train perplexity3.711876392364502
INFO:root:current mean train loss 1658.3603793831758
INFO:root:current train perplexity3.706667423248291
INFO:root:current mean train loss 1665.1399879092262
INFO:root:current train perplexity3.718792676925659
INFO:root:current mean train loss 1665.6415927381402
INFO:root:current train perplexity3.7170445919036865
INFO:root:current mean train loss 1665.1607296249242
INFO:root:current train perplexity3.717283010482788
INFO:root:current mean train loss 1665.1081995522104
INFO:root:current train perplexity3.717909812927246
INFO:root:current mean train loss 1666.05555821132
INFO:root:current train perplexity3.719801902770996
INFO:root:current mean train loss 1664.4772565783167
INFO:root:current train perplexity3.7201344966888428
INFO:root:current mean train loss 1664.835938167051
INFO:root:current train perplexity3.7219290733337402
INFO:root:current mean train loss 1665.5699804446967
INFO:root:current train perplexity3.7262606620788574
INFO:root:current mean train loss 1667.1766465807175
INFO:root:current train perplexity3.728583812713623
INFO:root:current mean train loss 1668.0620978210197
INFO:root:current train perplexity3.729092836380005
INFO:root:current mean train loss 1668.6928495573907
INFO:root:current train perplexity3.73140549659729
INFO:root:current mean train loss 1671.1318875262257
INFO:root:current train perplexity3.7360990047454834
INFO:root:current mean train loss 1671.53551005247
INFO:root:current train perplexity3.7382967472076416
INFO:root:current mean train loss 1671.5340500586542
INFO:root:current train perplexity3.7380058765411377
INFO:root:current mean train loss 1672.187933830061
INFO:root:current train perplexity3.739779233932495
INFO:root:current mean train loss 1672.6819545104813
INFO:root:current train perplexity3.7419095039367676
INFO:root:current mean train loss 1673.5134488337344
INFO:root:current train perplexity3.741764545440674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.31s/it]
INFO:root:final mean train loss: 1673.6812199656554
INFO:root:final train perplexity: 3.743293523788452
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2014.9077706844248
INFO:root:eval perplexity: 5.101521968841553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2497.488760008034
INFO:root:eval perplexity: 7.709975719451904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:42:31<26:53:09, 640.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1652.2261085510254
INFO:root:current train perplexity3.7184619903564453
INFO:root:current mean train loss 1657.6811246004972
INFO:root:current train perplexity3.689455270767212
INFO:root:current mean train loss 1661.549909920528
INFO:root:current train perplexity3.6896557807922363
INFO:root:current mean train loss 1658.9729610580996
INFO:root:current train perplexity3.6860578060150146
INFO:root:current mean train loss 1662.4431039315682
INFO:root:current train perplexity3.6948773860931396
INFO:root:current mean train loss 1663.1224975585938
INFO:root:current train perplexity3.690774440765381
INFO:root:current mean train loss 1666.1918099318877
INFO:root:current train perplexity3.7009708881378174
INFO:root:current mean train loss 1666.7338350223063
INFO:root:current train perplexity3.7046897411346436
INFO:root:current mean train loss 1666.8177300966704
INFO:root:current train perplexity3.7067983150482178
INFO:root:current mean train loss 1667.7910686705757
INFO:root:current train perplexity3.7106428146362305
INFO:root:current mean train loss 1666.9017322155855
INFO:root:current train perplexity3.711838722229004
INFO:root:current mean train loss 1666.4020175462056
INFO:root:current train perplexity3.7126646041870117
INFO:root:current mean train loss 1666.164021578702
INFO:root:current train perplexity3.7122511863708496
INFO:root:current mean train loss 1665.8215503406238
INFO:root:current train perplexity3.713522434234619
INFO:root:current mean train loss 1666.072593305364
INFO:root:current train perplexity3.7152674198150635
INFO:root:current mean train loss 1666.0353541760157
INFO:root:current train perplexity3.715791702270508
INFO:root:current mean train loss 1665.3433098886528
INFO:root:current train perplexity3.7183964252471924
INFO:root:current mean train loss 1665.7981530028733
INFO:root:current train perplexity3.7188751697540283
INFO:root:current mean train loss 1666.6556992843161
INFO:root:current train perplexity3.7206919193267822
INFO:root:current mean train loss 1667.1144383274498
INFO:root:current train perplexity3.722095489501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.45s/it]
INFO:root:final mean train loss: 1666.7517751288788
INFO:root:final train perplexity: 3.7228915691375732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 2015.3055948027481
INFO:root:eval perplexity: 5.1031646728515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2499.0718929209606
INFO:root:eval perplexity: 7.719963550567627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:53:10<26:41:01, 640.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.4571483378509
INFO:root:current train perplexity3.658055067062378
INFO:root:current mean train loss 1651.0963741020869
INFO:root:current train perplexity3.6657989025115967
INFO:root:current mean train loss 1648.2970951187563
INFO:root:current train perplexity3.662532329559326
INFO:root:current mean train loss 1649.0239586597868
INFO:root:current train perplexity3.6734235286712646
INFO:root:current mean train loss 1650.8275967536365
INFO:root:current train perplexity3.6783642768859863
INFO:root:current mean train loss 1649.647312852203
INFO:root:current train perplexity3.678065299987793
INFO:root:current mean train loss 1651.6302787416337
INFO:root:current train perplexity3.678504705429077
INFO:root:current mean train loss 1652.367415342853
INFO:root:current train perplexity3.678227186203003
INFO:root:current mean train loss 1652.6764347359485
INFO:root:current train perplexity3.6777663230895996
INFO:root:current mean train loss 1652.5966349240978
INFO:root:current train perplexity3.6794607639312744
INFO:root:current mean train loss 1653.4988334081193
INFO:root:current train perplexity3.6850240230560303
INFO:root:current mean train loss 1653.211192052192
INFO:root:current train perplexity3.6847987174987793
INFO:root:current mean train loss 1655.653926070544
INFO:root:current train perplexity3.690241813659668
INFO:root:current mean train loss 1655.8354059647772
INFO:root:current train perplexity3.692723274230957
INFO:root:current mean train loss 1655.8204285047068
INFO:root:current train perplexity3.6932029724121094
INFO:root:current mean train loss 1656.6417592530715
INFO:root:current train perplexity3.6962244510650635
INFO:root:current mean train loss 1657.502810208128
INFO:root:current train perplexity3.6984384059906006
INFO:root:current mean train loss 1658.4061846724915
INFO:root:current train perplexity3.7001953125
INFO:root:current mean train loss 1658.9602023053
INFO:root:current train perplexity3.7003235816955566
INFO:root:current mean train loss 1660.2443785650294
INFO:root:current train perplexity3.703131675720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.80s/it]
INFO:root:final mean train loss: 1659.9878609600057
INFO:root:final train perplexity: 3.70308518409729
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2017.9263638976618
INFO:root:eval perplexity: 5.113992691040039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2503.3234677145665
INFO:root:eval perplexity: 7.746853351593018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [9:03:47<26:27:51, 639.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1623.1117350260417
INFO:root:current train perplexity3.6168453693389893
INFO:root:current mean train loss 1637.2369421533792
INFO:root:current train perplexity3.626909017562866
INFO:root:current mean train loss 1637.939579325511
INFO:root:current train perplexity3.63754940032959
INFO:root:current mean train loss 1634.8018358574539
INFO:root:current train perplexity3.6344799995422363
INFO:root:current mean train loss 1642.0014981118395
INFO:root:current train perplexity3.641965389251709
INFO:root:current mean train loss 1643.5865981031222
INFO:root:current train perplexity3.6479599475860596
INFO:root:current mean train loss 1643.78659011795
INFO:root:current train perplexity3.652708053588867
INFO:root:current mean train loss 1645.6369699024967
INFO:root:current train perplexity3.655329942703247
INFO:root:current mean train loss 1646.012656266915
INFO:root:current train perplexity3.6563801765441895
INFO:root:current mean train loss 1647.8169122225997
INFO:root:current train perplexity3.6618003845214844
INFO:root:current mean train loss 1650.8395910209383
INFO:root:current train perplexity3.665663003921509
INFO:root:current mean train loss 1651.3707782097583
INFO:root:current train perplexity3.6688826084136963
INFO:root:current mean train loss 1652.1468458612571
INFO:root:current train perplexity3.6725614070892334
INFO:root:current mean train loss 1652.7776553599413
INFO:root:current train perplexity3.6742403507232666
INFO:root:current mean train loss 1653.7518250594198
INFO:root:current train perplexity3.6771936416625977
INFO:root:current mean train loss 1653.9947914328154
INFO:root:current train perplexity3.677704095840454
INFO:root:current mean train loss 1652.5833314526983
INFO:root:current train perplexity3.677462577819824
INFO:root:current mean train loss 1653.7179781091847
INFO:root:current train perplexity3.6792895793914795
INFO:root:current mean train loss 1653.6068738669571
INFO:root:current train perplexity3.6798415184020996
INFO:root:current mean train loss 1653.3801945698951
INFO:root:current train perplexity3.6825902462005615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.68s/it]
INFO:root:final mean train loss: 1652.9959861766913
INFO:root:final train perplexity: 3.6827216148376465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 2022.9438766587712
INFO:root:eval perplexity: 5.134786605834961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 2506.1798628137467
INFO:root:eval perplexity: 7.7649712562561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [9:14:34<26:22:30, 641.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1609.0943824124624
INFO:root:current train perplexity3.603881597518921
INFO:root:current mean train loss 1623.0169557665215
INFO:root:current train perplexity3.6277875900268555
INFO:root:current mean train loss 1626.3097113619424
INFO:root:current train perplexity3.629448652267456
INFO:root:current mean train loss 1630.5047964389892
INFO:root:current train perplexity3.6285197734832764
INFO:root:current mean train loss 1631.210126983453
INFO:root:current train perplexity3.6306889057159424
INFO:root:current mean train loss 1634.436346718214
INFO:root:current train perplexity3.634302854537964
INFO:root:current mean train loss 1635.0903584827965
INFO:root:current train perplexity3.636725425720215
INFO:root:current mean train loss 1637.7240952142201
INFO:root:current train perplexity3.637373685836792
INFO:root:current mean train loss 1639.3771505388236
INFO:root:current train perplexity3.6415934562683105
INFO:root:current mean train loss 1640.9572941420158
INFO:root:current train perplexity3.64628529548645
INFO:root:current mean train loss 1641.8709007819714
INFO:root:current train perplexity3.6470787525177
INFO:root:current mean train loss 1642.206027962047
INFO:root:current train perplexity3.648179769515991
INFO:root:current mean train loss 1643.2709987577941
INFO:root:current train perplexity3.649384021759033
INFO:root:current mean train loss 1643.410101437517
INFO:root:current train perplexity3.6521224975585938
INFO:root:current mean train loss 1644.6792355188227
INFO:root:current train perplexity3.6554479598999023
INFO:root:current mean train loss 1645.2972317260048
INFO:root:current train perplexity3.6568548679351807
INFO:root:current mean train loss 1645.5939896436794
INFO:root:current train perplexity3.658881187438965
INFO:root:current mean train loss 1646.822587677019
INFO:root:current train perplexity3.661830425262451
INFO:root:current mean train loss 1647.155542860877
INFO:root:current train perplexity3.661177396774292
INFO:root:current mean train loss 1646.4811558648905
INFO:root:current train perplexity3.6638481616973877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.41s/it]
INFO:root:final mean train loss: 1646.4811558648905
INFO:root:final train perplexity: 3.6638481616973877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2021.534870553524
INFO:root:eval perplexity: 5.128938674926758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2509.0155825784022
INFO:root:eval perplexity: 7.7829999923706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [9:25:06<26:05:01, 638.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.0040844726564
INFO:root:current train perplexity3.5858371257781982
INFO:root:current mean train loss 1611.518291015625
INFO:root:current train perplexity3.58783221244812
INFO:root:current mean train loss 1619.4943627929688
INFO:root:current train perplexity3.5968942642211914
INFO:root:current mean train loss 1620.0424114990235
INFO:root:current train perplexity3.605957269668579
INFO:root:current mean train loss 1624.8667368164063
INFO:root:current train perplexity3.613793134689331
INFO:root:current mean train loss 1627.3737927246093
INFO:root:current train perplexity3.6121349334716797
INFO:root:current mean train loss 1628.669989362444
INFO:root:current train perplexity3.615025043487549
INFO:root:current mean train loss 1629.1706434631349
INFO:root:current train perplexity3.616966485977173
INFO:root:current mean train loss 1630.8436877441407
INFO:root:current train perplexity3.620720624923706
INFO:root:current mean train loss 1632.1487443847657
INFO:root:current train perplexity3.6227424144744873
INFO:root:current mean train loss 1632.0404372336648
INFO:root:current train perplexity3.624119520187378
INFO:root:current mean train loss 1634.22835357666
INFO:root:current train perplexity3.6291396617889404
INFO:root:current mean train loss 1634.5109291428787
INFO:root:current train perplexity3.6298751831054688
INFO:root:current mean train loss 1635.9105340576173
INFO:root:current train perplexity3.6330630779266357
INFO:root:current mean train loss 1636.3893767903646
INFO:root:current train perplexity3.634988307952881
INFO:root:current mean train loss 1637.8359143829346
INFO:root:current train perplexity3.6389992237091064
INFO:root:current mean train loss 1639.1691396915212
INFO:root:current train perplexity3.6403303146362305
INFO:root:current mean train loss 1639.6301094563803
INFO:root:current train perplexity3.641096830368042
INFO:root:current mean train loss 1640.3254667583265
INFO:root:current train perplexity3.643098831176758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.36s/it]
INFO:root:final mean train loss: 1639.7499374258837
INFO:root:final train perplexity: 3.6444497108459473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it]
INFO:root:eval mean loss: 2024.0070354921597
INFO:root:eval perplexity: 5.1392035484313965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2511.56777066711
INFO:root:eval perplexity: 7.799263000488281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [9:35:55<26:02:14, 642.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.8711942784926
INFO:root:current train perplexity3.573977470397949
INFO:root:current mean train loss 1623.6026162693643
INFO:root:current train perplexity3.5844225883483887
INFO:root:current mean train loss 1623.1561166789675
INFO:root:current train perplexity3.5863497257232666
INFO:root:current mean train loss 1621.2166151173108
INFO:root:current train perplexity3.5875585079193115
INFO:root:current mean train loss 1620.194519189336
INFO:root:current train perplexity3.590860366821289
INFO:root:current mean train loss 1625.6451720601124
INFO:root:current train perplexity3.600088357925415
INFO:root:current mean train loss 1627.9905746682537
INFO:root:current train perplexity3.6024556159973145
INFO:root:current mean train loss 1628.9375580557553
INFO:root:current train perplexity3.6052660942077637
INFO:root:current mean train loss 1630.3865944384945
INFO:root:current train perplexity3.6078779697418213
INFO:root:current mean train loss 1631.6624687968579
INFO:root:current train perplexity3.6108193397521973
INFO:root:current mean train loss 1630.733990544532
INFO:root:current train perplexity3.6118874549865723
INFO:root:current mean train loss 1631.6088325138485
INFO:root:current train perplexity3.6144042015075684
INFO:root:current mean train loss 1631.0649617680194
INFO:root:current train perplexity3.614546775817871
INFO:root:current mean train loss 1631.7774840798809
INFO:root:current train perplexity3.6172873973846436
INFO:root:current mean train loss 1631.9122257596098
INFO:root:current train perplexity3.6184215545654297
INFO:root:current mean train loss 1632.1539152141613
INFO:root:current train perplexity3.6202661991119385
INFO:root:current mean train loss 1631.6759786611733
INFO:root:current train perplexity3.6211259365081787
INFO:root:current mean train loss 1631.8329204366037
INFO:root:current train perplexity3.62252140045166
INFO:root:current mean train loss 1632.6469003680518
INFO:root:current train perplexity3.6249876022338867
INFO:root:current mean train loss 1634.2407299791953
INFO:root:current train perplexity3.6275298595428467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.76s/it]
INFO:root:final mean train loss: 1634.0999545329637
INFO:root:final train perplexity: 3.628246784210205
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2028.9555534200465
INFO:root:eval perplexity: 5.159811496734619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2521.365894507009
INFO:root:eval perplexity: 7.862009525299072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:46:30<25:46:24, 639.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.3951990464154
INFO:root:current train perplexity3.568023681640625
INFO:root:current mean train loss 1612.2021037998484
INFO:root:current train perplexity3.5853216648101807
INFO:root:current mean train loss 1616.8079609667134
INFO:root:current train perplexity3.5799288749694824
INFO:root:current mean train loss 1617.4599945616578
INFO:root:current train perplexity3.5741331577301025
INFO:root:current mean train loss 1616.408447265625
INFO:root:current train perplexity3.577878952026367
INFO:root:current mean train loss 1617.987241366383
INFO:root:current train perplexity3.57778000831604
INFO:root:current mean train loss 1618.1087979578444
INFO:root:current train perplexity3.5823614597320557
INFO:root:current mean train loss 1618.7207390475987
INFO:root:current train perplexity3.586711883544922
INFO:root:current mean train loss 1620.7039541706479
INFO:root:current train perplexity3.591721296310425
INFO:root:current mean train loss 1622.9092767948257
INFO:root:current train perplexity3.596330404281616
INFO:root:current mean train loss 1624.101475256324
INFO:root:current train perplexity3.5999231338500977
INFO:root:current mean train loss 1624.6548281069156
INFO:root:current train perplexity3.600398302078247
INFO:root:current mean train loss 1624.9583819372342
INFO:root:current train perplexity3.602053165435791
INFO:root:current mean train loss 1625.764724845829
INFO:root:current train perplexity3.6043522357940674
INFO:root:current mean train loss 1625.9849826275388
INFO:root:current train perplexity3.604857921600342
INFO:root:current mean train loss 1627.128789590888
INFO:root:current train perplexity3.6071043014526367
INFO:root:current mean train loss 1627.3141096248182
INFO:root:current train perplexity3.608332633972168
INFO:root:current mean train loss 1627.8236125519256
INFO:root:current train perplexity3.6087822914123535
INFO:root:current mean train loss 1627.2473074643667
INFO:root:current train perplexity3.609340190887451
INFO:root:current mean train loss 1627.4753016537938
INFO:root:current train perplexity3.609866142272949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.09s/it]
INFO:root:final mean train loss: 1627.6425572874807
INFO:root:final train perplexity: 3.609816074371338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.72s/it]
INFO:root:eval mean loss: 2030.3276912608046
INFO:root:eval perplexity: 5.16554069519043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2524.9233394108765
INFO:root:eval perplexity: 7.884918689727783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:57:00<25:28:20, 636.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.7819417317708
INFO:root:current train perplexity3.5413427352905273
INFO:root:current mean train loss 1594.7034451314155
INFO:root:current train perplexity3.539445638656616
INFO:root:current mean train loss 1606.564453125
INFO:root:current train perplexity3.5539743900299072
INFO:root:current mean train loss 1614.1602153723736
INFO:root:current train perplexity3.5640010833740234
INFO:root:current mean train loss 1615.562117007778
INFO:root:current train perplexity3.567579746246338
INFO:root:current mean train loss 1614.038791774189
INFO:root:current train perplexity3.5651283264160156
INFO:root:current mean train loss 1615.7406992172498
INFO:root:current train perplexity3.5690622329711914
INFO:root:current mean train loss 1616.272071320271
INFO:root:current train perplexity3.569362163543701
INFO:root:current mean train loss 1615.9738000674758
INFO:root:current train perplexity3.5719923973083496
INFO:root:current mean train loss 1615.9086264561154
INFO:root:current train perplexity3.572460174560547
INFO:root:current mean train loss 1616.6062957153902
INFO:root:current train perplexity3.575345754623413
INFO:root:current mean train loss 1618.224594845345
INFO:root:current train perplexity3.576829433441162
INFO:root:current mean train loss 1618.350824906481
INFO:root:current train perplexity3.578401803970337
INFO:root:current mean train loss 1619.7856598013334
INFO:root:current train perplexity3.5823819637298584
INFO:root:current mean train loss 1620.8170543752153
INFO:root:current train perplexity3.584212303161621
INFO:root:current mean train loss 1621.5468010179925
INFO:root:current train perplexity3.58542799949646
INFO:root:current mean train loss 1622.1456403079574
INFO:root:current train perplexity3.5878913402557373
INFO:root:current mean train loss 1623.214559384035
INFO:root:current train perplexity3.5914430618286133
INFO:root:current mean train loss 1622.7542526104978
INFO:root:current train perplexity3.5922727584838867
INFO:root:current mean train loss 1622.3694106688076
INFO:root:current train perplexity3.593541145324707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.81s/it]
INFO:root:final mean train loss: 1621.976467115255
INFO:root:final train perplexity: 3.5937209129333496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 2033.292375280502
INFO:root:eval perplexity: 5.17794132232666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2525.6504365095857
INFO:root:eval perplexity: 7.889606475830078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [10:07:40<25:19:54, 637.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.200823615579
INFO:root:current train perplexity3.522751808166504
INFO:root:current mean train loss 1601.20015171596
INFO:root:current train perplexity3.528198719024658
INFO:root:current mean train loss 1602.1091577330633
INFO:root:current train perplexity3.541076421737671
INFO:root:current mean train loss 1606.9051672894022
INFO:root:current train perplexity3.5558488368988037
INFO:root:current mean train loss 1607.1178048940806
INFO:root:current train perplexity3.55298113822937
INFO:root:current mean train loss 1608.5575662532324
INFO:root:current train perplexity3.5512423515319824
INFO:root:current mean train loss 1609.01757666308
INFO:root:current train perplexity3.552201271057129
INFO:root:current mean train loss 1606.7987353007
INFO:root:current train perplexity3.552654981613159
INFO:root:current mean train loss 1606.7911658221126
INFO:root:current train perplexity3.553520679473877
INFO:root:current mean train loss 1608.8865655315808
INFO:root:current train perplexity3.5595364570617676
INFO:root:current mean train loss 1611.1720782219247
INFO:root:current train perplexity3.5629398822784424
INFO:root:current mean train loss 1611.6655122939856
INFO:root:current train perplexity3.5667803287506104
INFO:root:current mean train loss 1612.3652579611407
INFO:root:current train perplexity3.568486452102661
INFO:root:current mean train loss 1611.9659246255083
INFO:root:current train perplexity3.568420648574829
INFO:root:current mean train loss 1612.6696709157336
INFO:root:current train perplexity3.569236993789673
INFO:root:current mean train loss 1613.1605163107113
INFO:root:current train perplexity3.5695459842681885
INFO:root:current mean train loss 1613.5588274253644
INFO:root:current train perplexity3.5700957775115967
INFO:root:current mean train loss 1614.3771584627316
INFO:root:current train perplexity3.5705924034118652
INFO:root:current mean train loss 1614.691136492907
INFO:root:current train perplexity3.5711395740509033
INFO:root:current mean train loss 1615.2821393516974
INFO:root:current train perplexity3.5729658603668213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.74s/it]
INFO:root:final mean train loss: 1614.83758732675
INFO:root:final train perplexity: 3.573545217514038
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2035.1125596499612
INFO:root:eval perplexity: 5.1855692863464355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2528.8704976832614
INFO:root:eval perplexity: 7.91041374206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [10:18:15<25:07:30, 636.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1595.5357981962316
INFO:root:current train perplexity3.516714334487915
INFO:root:current mean train loss 1596.0944263355152
INFO:root:current train perplexity3.5319995880126953
INFO:root:current mean train loss 1599.7363217002467
INFO:root:current train perplexity3.5393903255462646
INFO:root:current mean train loss 1600.5889340883725
INFO:root:current train perplexity3.544830799102783
INFO:root:current mean train loss 1600.853210826756
INFO:root:current train perplexity3.5415446758270264
INFO:root:current mean train loss 1602.070113014156
INFO:root:current train perplexity3.542290210723877
INFO:root:current mean train loss 1602.0621991902372
INFO:root:current train perplexity3.542895793914795
INFO:root:current mean train loss 1602.6198494103305
INFO:root:current train perplexity3.546699047088623
INFO:root:current mean train loss 1604.1614568160753
INFO:root:current train perplexity3.5448789596557617
INFO:root:current mean train loss 1604.3029698405774
INFO:root:current train perplexity3.5445303916931152
INFO:root:current mean train loss 1603.2911211567541
INFO:root:current train perplexity3.5434935092926025
INFO:root:current mean train loss 1604.5206413172468
INFO:root:current train perplexity3.545503854751587
INFO:root:current mean train loss 1606.308469399775
INFO:root:current train perplexity3.5471932888031006
INFO:root:current mean train loss 1606.3574585401625
INFO:root:current train perplexity3.5487570762634277
INFO:root:current mean train loss 1606.854352114899
INFO:root:current train perplexity3.550701856613159
INFO:root:current mean train loss 1608.1505073041947
INFO:root:current train perplexity3.552828550338745
INFO:root:current mean train loss 1608.7943628871476
INFO:root:current train perplexity3.555922031402588
INFO:root:current mean train loss 1609.4771976075585
INFO:root:current train perplexity3.5567309856414795
INFO:root:current mean train loss 1609.4093093993492
INFO:root:current train perplexity3.5579895973205566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.98s/it]
INFO:root:final mean train loss: 1609.5380429389556
INFO:root:final train perplexity: 3.5586400032043457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2038.0534200465424
INFO:root:eval perplexity: 5.1979169845581055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2530.619024614916
INFO:root:eval perplexity: 7.921731948852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [10:28:44<24:51:07, 634.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1599.5669555664062
INFO:root:current train perplexity3.434109687805176
INFO:root:current mean train loss 1570.9697038239124
INFO:root:current train perplexity3.4584991931915283
INFO:root:current mean train loss 1581.4635033937964
INFO:root:current train perplexity3.4872307777404785
INFO:root:current mean train loss 1584.1832699807273
INFO:root:current train perplexity3.4887218475341797
INFO:root:current mean train loss 1587.230568956973
INFO:root:current train perplexity3.4963762760162354
INFO:root:current mean train loss 1589.2279159728275
INFO:root:current train perplexity3.5047056674957275
INFO:root:current mean train loss 1593.7274425417877
INFO:root:current train perplexity3.5167717933654785
INFO:root:current mean train loss 1595.3653788770366
INFO:root:current train perplexity3.5204598903656006
INFO:root:current mean train loss 1596.3414757174446
INFO:root:current train perplexity3.520289897918701
INFO:root:current mean train loss 1597.5619217223446
INFO:root:current train perplexity3.5221104621887207
INFO:root:current mean train loss 1598.2412383484984
INFO:root:current train perplexity3.526566505432129
INFO:root:current mean train loss 1600.6407009893235
INFO:root:current train perplexity3.5297932624816895
INFO:root:current mean train loss 1601.1155392461133
INFO:root:current train perplexity3.5299901962280273
INFO:root:current mean train loss 1601.2163877238143
INFO:root:current train perplexity3.533762216567993
INFO:root:current mean train loss 1601.342186507417
INFO:root:current train perplexity3.5362513065338135
INFO:root:current mean train loss 1601.7541699771398
INFO:root:current train perplexity3.537370443344116
INFO:root:current mean train loss 1601.619191678127
INFO:root:current train perplexity3.538996696472168
INFO:root:current mean train loss 1601.8293554572745
INFO:root:current train perplexity3.5385594367980957
INFO:root:current mean train loss 1602.384536523004
INFO:root:current train perplexity3.5388174057006836
INFO:root:current mean train loss 1602.493282346194
INFO:root:current train perplexity3.5392630100250244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.15s/it]
INFO:root:final mean train loss: 1603.2098432686132
INFO:root:final train perplexity: 3.540924072265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.76s/it]
INFO:root:eval mean loss: 2041.3423232491134
INFO:root:eval perplexity: 5.211760997772217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2537.982033154643
INFO:root:eval perplexity: 7.969576835632324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [10:39:38<24:54:28, 640.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1583.6782098067433
INFO:root:current train perplexity3.509493112564087
INFO:root:current mean train loss 1590.5542833344275
INFO:root:current train perplexity3.5114476680755615
INFO:root:current mean train loss 1594.4970413277683
INFO:root:current train perplexity3.5062878131866455
INFO:root:current mean train loss 1590.8188698508523
INFO:root:current train perplexity3.5025200843811035
INFO:root:current mean train loss 1586.127639806925
INFO:root:current train perplexity3.494765043258667
INFO:root:current mean train loss 1589.7340438342967
INFO:root:current train perplexity3.5005180835723877
INFO:root:current mean train loss 1589.3414547231548
INFO:root:current train perplexity3.5064477920532227
INFO:root:current mean train loss 1591.3198493458797
INFO:root:current train perplexity3.5119078159332275
INFO:root:current mean train loss 1591.2075256422181
INFO:root:current train perplexity3.5113472938537598
INFO:root:current mean train loss 1591.6537243798457
INFO:root:current train perplexity3.5131924152374268
INFO:root:current mean train loss 1592.0831219763938
INFO:root:current train perplexity3.514147996902466
INFO:root:current mean train loss 1592.6265498238872
INFO:root:current train perplexity3.51554012298584
INFO:root:current mean train loss 1593.451047201055
INFO:root:current train perplexity3.516517162322998
INFO:root:current mean train loss 1594.0768324799208
INFO:root:current train perplexity3.518338203430176
INFO:root:current mean train loss 1594.7561810246818
INFO:root:current train perplexity3.5187456607818604
INFO:root:current mean train loss 1595.542068049498
INFO:root:current train perplexity3.519984006881714
INFO:root:current mean train loss 1596.4002968291577
INFO:root:current train perplexity3.521986246109009
INFO:root:current mean train loss 1596.7425632265988
INFO:root:current train perplexity3.522702217102051
INFO:root:current mean train loss 1596.9781724322688
INFO:root:current train perplexity3.524444818496704
INFO:root:current mean train loss 1597.3290011836814
INFO:root:current train perplexity3.5241832733154297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.80s/it]
INFO:root:final mean train loss: 1597.3983989952192
INFO:root:final train perplexity: 3.5247323513031006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2044.4723844054743
INFO:root:eval perplexity: 5.224970817565918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 2540.436013079704
INFO:root:eval perplexity: 7.985585689544678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:50:10<24:37:37, 637.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1562.156741672092
INFO:root:current train perplexity3.4376842975616455
INFO:root:current mean train loss 1563.7840046602137
INFO:root:current train perplexity3.4432249069213867
INFO:root:current mean train loss 1573.0110318458687
INFO:root:current train perplexity3.4704604148864746
INFO:root:current mean train loss 1579.854358854748
INFO:root:current train perplexity3.4793009757995605
INFO:root:current mean train loss 1579.004675628942
INFO:root:current train perplexity3.480994939804077
INFO:root:current mean train loss 1579.7308957683506
INFO:root:current train perplexity3.4810850620269775
INFO:root:current mean train loss 1580.2380278965213
INFO:root:current train perplexity3.4815492630004883
INFO:root:current mean train loss 1583.586168869682
INFO:root:current train perplexity3.4864394664764404
INFO:root:current mean train loss 1584.619346947191
INFO:root:current train perplexity3.4914731979370117
INFO:root:current mean train loss 1584.8406163403113
INFO:root:current train perplexity3.490565538406372
INFO:root:current mean train loss 1584.4788223325515
INFO:root:current train perplexity3.489117383956909
INFO:root:current mean train loss 1584.3809555483535
INFO:root:current train perplexity3.489438533782959
INFO:root:current mean train loss 1585.3077687877667
INFO:root:current train perplexity3.494527816772461
INFO:root:current mean train loss 1587.3652533799589
INFO:root:current train perplexity3.4987475872039795
INFO:root:current mean train loss 1587.1176479839016
INFO:root:current train perplexity3.5003411769866943
INFO:root:current mean train loss 1588.8564585844676
INFO:root:current train perplexity3.5048024654388428
INFO:root:current mean train loss 1589.7785072233391
INFO:root:current train perplexity3.506049871444702
INFO:root:current mean train loss 1590.8177301784815
INFO:root:current train perplexity3.50827956199646
INFO:root:current mean train loss 1591.6380078018622
INFO:root:current train perplexity3.5082695484161377
INFO:root:current mean train loss 1592.2495008736603
INFO:root:current train perplexity3.50881028175354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.34s/it]
INFO:root:final mean train loss: 1591.447618600881
INFO:root:final train perplexity: 3.5082290172576904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2045.9273703284298
INFO:root:eval perplexity: 5.2311224937438965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2545.4603583153257
INFO:root:eval perplexity: 8.018468856811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [11:00:41<24:22:15, 635.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1573.1858140477593
INFO:root:current train perplexity3.4412267208099365
INFO:root:current mean train loss 1578.1808898526858
INFO:root:current train perplexity3.4690191745758057
INFO:root:current mean train loss 1584.2714660403285
INFO:root:current train perplexity3.479091167449951
INFO:root:current mean train loss 1584.1274151248228
INFO:root:current train perplexity3.482123374938965
INFO:root:current mean train loss 1584.9846727653319
INFO:root:current train perplexity3.4848885536193848
INFO:root:current mean train loss 1584.8740662614432
INFO:root:current train perplexity3.4856183528900146
INFO:root:current mean train loss 1584.9983962615452
INFO:root:current train perplexity3.4828720092773438
INFO:root:current mean train loss 1584.6625756090223
INFO:root:current train perplexity3.4777817726135254
INFO:root:current mean train loss 1583.7822018049806
INFO:root:current train perplexity3.476783037185669
INFO:root:current mean train loss 1582.5783130369557
INFO:root:current train perplexity3.4763455390930176
INFO:root:current mean train loss 1583.2415947692234
INFO:root:current train perplexity3.479668617248535
INFO:root:current mean train loss 1583.162781555758
INFO:root:current train perplexity3.4813249111175537
INFO:root:current mean train loss 1583.6591123685967
INFO:root:current train perplexity3.482980728149414
INFO:root:current mean train loss 1584.3730729491465
INFO:root:current train perplexity3.4865307807922363
INFO:root:current mean train loss 1584.4188602917454
INFO:root:current train perplexity3.487452507019043
INFO:root:current mean train loss 1584.0030791116237
INFO:root:current train perplexity3.489187717437744
INFO:root:current mean train loss 1584.6009787336236
INFO:root:current train perplexity3.488844871520996
INFO:root:current mean train loss 1584.6597816132166
INFO:root:current train perplexity3.4893107414245605
INFO:root:current mean train loss 1585.1878789252225
INFO:root:current train perplexity3.4910762310028076
INFO:root:current mean train loss 1585.7500931309603
INFO:root:current train perplexity3.492166757583618

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.51s/it]
INFO:root:final mean train loss: 1585.7468956713117
INFO:root:final train perplexity: 3.492492198944092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.01s/it]
INFO:root:eval mean loss: 2049.948258636691
INFO:root:eval perplexity: 5.248161792755127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2552.035915942902
INFO:root:eval perplexity: 8.061704635620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [11:11:21<24:14:30, 637.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1577.4428344726562
INFO:root:current train perplexity3.445603847503662
INFO:root:current mean train loss 1576.5206751206342
INFO:root:current train perplexity3.4412965774536133
INFO:root:current mean train loss 1572.037924081308
INFO:root:current train perplexity3.4415009021759033
INFO:root:current mean train loss 1567.1835587785051
INFO:root:current train perplexity3.4418795108795166
INFO:root:current mean train loss 1570.8756893076795
INFO:root:current train perplexity3.4495792388916016
INFO:root:current mean train loss 1571.855020088062
INFO:root:current train perplexity3.4546186923980713
INFO:root:current mean train loss 1571.9220402504081
INFO:root:current train perplexity3.4541661739349365
INFO:root:current mean train loss 1572.7613446124187
INFO:root:current train perplexity3.4558112621307373
INFO:root:current mean train loss 1573.5344398235452
INFO:root:current train perplexity3.461066961288452
INFO:root:current mean train loss 1573.339798068017
INFO:root:current train perplexity3.459925889968872
INFO:root:current mean train loss 1573.1718113409024
INFO:root:current train perplexity3.462528705596924
INFO:root:current mean train loss 1574.010960453392
INFO:root:current train perplexity3.4659204483032227
INFO:root:current mean train loss 1574.0347504382996
INFO:root:current train perplexity3.466996431350708
INFO:root:current mean train loss 1575.6570271512887
INFO:root:current train perplexity3.4691731929779053
INFO:root:current mean train loss 1576.6715171762064
INFO:root:current train perplexity3.470515012741089
INFO:root:current mean train loss 1577.125356025453
INFO:root:current train perplexity3.472266674041748
INFO:root:current mean train loss 1577.7961387771331
INFO:root:current train perplexity3.472567558288574
INFO:root:current mean train loss 1578.5076838089249
INFO:root:current train perplexity3.4726736545562744
INFO:root:current mean train loss 1579.514248869381
INFO:root:current train perplexity3.4741203784942627
INFO:root:current mean train loss 1580.7805241463752
INFO:root:current train perplexity3.4772307872772217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.40s/it]
INFO:root:final mean train loss: 1580.20311459663
INFO:root:final train perplexity: 3.47725510597229
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it]
INFO:root:eval mean loss: 2050.1118471402647
INFO:root:eval perplexity: 5.248855113983154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2553.750924184813
INFO:root:eval perplexity: 8.073019981384277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [11:21:51<23:59:34, 635.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1560.214633283944
INFO:root:current train perplexity3.3955047130584717
INFO:root:current mean train loss 1561.4834108403659
INFO:root:current train perplexity3.4227774143218994
INFO:root:current mean train loss 1565.0450605332644
INFO:root:current train perplexity3.4373483657836914
INFO:root:current mean train loss 1563.6190349569001
INFO:root:current train perplexity3.4325344562530518
INFO:root:current mean train loss 1563.5541390608957
INFO:root:current train perplexity3.4365506172180176
INFO:root:current mean train loss 1566.1628494912559
INFO:root:current train perplexity3.4351534843444824
INFO:root:current mean train loss 1564.671898632244
INFO:root:current train perplexity3.4364547729492188
INFO:root:current mean train loss 1565.279450432318
INFO:root:current train perplexity3.4393177032470703
INFO:root:current mean train loss 1566.235783281294
INFO:root:current train perplexity3.441333055496216
INFO:root:current mean train loss 1566.8307231064384
INFO:root:current train perplexity3.445270299911499
INFO:root:current mean train loss 1567.69010222013
INFO:root:current train perplexity3.4489896297454834
INFO:root:current mean train loss 1568.9284578498512
INFO:root:current train perplexity3.451327323913574
INFO:root:current mean train loss 1570.112146574671
INFO:root:current train perplexity3.4543139934539795
INFO:root:current mean train loss 1569.9808343448653
INFO:root:current train perplexity3.4551899433135986
INFO:root:current mean train loss 1571.151035865522
INFO:root:current train perplexity3.4561095237731934
INFO:root:current mean train loss 1571.7118843718001
INFO:root:current train perplexity3.456725597381592
INFO:root:current mean train loss 1572.5796745766106
INFO:root:current train perplexity3.457428216934204
INFO:root:current mean train loss 1572.3057864743635
INFO:root:current train perplexity3.4583213329315186
INFO:root:current mean train loss 1573.5322478455591
INFO:root:current train perplexity3.4595558643341064

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.65s/it]
INFO:root:final mean train loss: 1574.1126528926047
INFO:root:final train perplexity: 3.46059250831604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2056.107249158494
INFO:root:eval perplexity: 5.274367809295654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.63s/it]
INFO:root:eval mean loss: 2558.4829720571533
INFO:root:eval perplexity: 8.104323387145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [11:32:30<23:51:16, 636.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1511.6223754882812
INFO:root:current train perplexity3.3814799785614014
INFO:root:current mean train loss 1543.9345315786509
INFO:root:current train perplexity3.394021987915039
INFO:root:current mean train loss 1547.900224872664
INFO:root:current train perplexity3.4057159423828125
INFO:root:current mean train loss 1549.4294521934107
INFO:root:current train perplexity3.4139578342437744
INFO:root:current mean train loss 1553.0950208607287
INFO:root:current train perplexity3.4175658226013184
INFO:root:current mean train loss 1556.4202725849455
INFO:root:current train perplexity3.422468423843384
INFO:root:current mean train loss 1559.200896206281
INFO:root:current train perplexity3.424053907394409
INFO:root:current mean train loss 1561.5598966425116
INFO:root:current train perplexity3.42978835105896
INFO:root:current mean train loss 1563.3727290974327
INFO:root:current train perplexity3.4334216117858887
INFO:root:current mean train loss 1564.5876778121544
INFO:root:current train perplexity3.4370737075805664
INFO:root:current mean train loss 1565.21176852648
INFO:root:current train perplexity3.438530206680298
INFO:root:current mean train loss 1566.9942273126132
INFO:root:current train perplexity3.4409873485565186
INFO:root:current mean train loss 1566.9097635769765
INFO:root:current train perplexity3.4393889904022217
INFO:root:current mean train loss 1567.3757547951914
INFO:root:current train perplexity3.4405529499053955
INFO:root:current mean train loss 1567.6183605574474
INFO:root:current train perplexity3.441333055496216
INFO:root:current mean train loss 1568.7346160564016
INFO:root:current train perplexity3.4432482719421387
INFO:root:current mean train loss 1568.702697068973
INFO:root:current train perplexity3.4433610439300537
INFO:root:current mean train loss 1568.4381656557182
INFO:root:current train perplexity3.4434800148010254
INFO:root:current mean train loss 1568.3253828162892
INFO:root:current train perplexity3.443674325942993
INFO:root:current mean train loss 1568.7648984764805
INFO:root:current train perplexity3.4450502395629883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.06s/it]
INFO:root:final mean train loss: 1568.6608628173458
INFO:root:final train perplexity: 3.4457454681396484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 2057.713156842171
INFO:root:eval perplexity: 5.281222820281982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 2562.856789879765
INFO:root:eval perplexity: 8.1333646774292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [11:43:15<23:46:58, 638.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.4936058407739
INFO:root:current train perplexity3.4270663261413574
INFO:root:current mean train loss 1559.0840560030347
INFO:root:current train perplexity3.4168012142181396
INFO:root:current mean train loss 1566.5262296512656
INFO:root:current train perplexity3.424422025680542
INFO:root:current mean train loss 1559.2549105730384
INFO:root:current train perplexity3.4157965183258057
INFO:root:current mean train loss 1556.1320693498553
INFO:root:current train perplexity3.411072254180908
INFO:root:current mean train loss 1556.7818528539617
INFO:root:current train perplexity3.41422438621521
INFO:root:current mean train loss 1556.722322276633
INFO:root:current train perplexity3.415496826171875
INFO:root:current mean train loss 1557.114155381794
INFO:root:current train perplexity3.4136643409729004
INFO:root:current mean train loss 1557.3912995834444
INFO:root:current train perplexity3.4146599769592285
INFO:root:current mean train loss 1557.2924111497778
INFO:root:current train perplexity3.4175796508789062
INFO:root:current mean train loss 1556.6772462133097
INFO:root:current train perplexity3.418336868286133
INFO:root:current mean train loss 1558.0220129470756
INFO:root:current train perplexity3.418613910675049
INFO:root:current mean train loss 1557.8976573897228
INFO:root:current train perplexity3.4204444885253906
INFO:root:current mean train loss 1557.7393015212492
INFO:root:current train perplexity3.421238899230957
INFO:root:current mean train loss 1559.0810253081568
INFO:root:current train perplexity3.42301344871521
INFO:root:current mean train loss 1561.322114421536
INFO:root:current train perplexity3.424964189529419
INFO:root:current mean train loss 1562.3360975996202
INFO:root:current train perplexity3.426314353942871
INFO:root:current mean train loss 1562.807382551478
INFO:root:current train perplexity3.428891658782959
INFO:root:current mean train loss 1563.2113759073827
INFO:root:current train perplexity3.430300235748291
INFO:root:current mean train loss 1563.2288130164952
INFO:root:current train perplexity3.430018424987793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.16s/it]
INFO:root:final mean train loss: 1563.1854694653086
INFO:root:final train perplexity: 3.430898427963257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it]
INFO:root:eval mean loss: 2060.802577674812
INFO:root:eval perplexity: 5.294435024261475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.52s/it]
INFO:root:eval mean loss: 2567.5563804680573
INFO:root:eval perplexity: 8.16468334197998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:54:01<23:40:32, 640.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1520.5506045692846
INFO:root:current train perplexity3.358408212661743
INFO:root:current mean train loss 1531.587349269701
INFO:root:current train perplexity3.3505821228027344
INFO:root:current mean train loss 1538.6719714252888
INFO:root:current train perplexity3.3647546768188477
INFO:root:current mean train loss 1543.2492859970182
INFO:root:current train perplexity3.3754210472106934
INFO:root:current mean train loss 1543.2097744876392
INFO:root:current train perplexity3.378309726715088
INFO:root:current mean train loss 1545.7294651868176
INFO:root:current train perplexity3.3829355239868164
INFO:root:current mean train loss 1548.2663645011878
INFO:root:current train perplexity3.3900809288024902
INFO:root:current mean train loss 1548.5317711972286
INFO:root:current train perplexity3.3956050872802734
INFO:root:current mean train loss 1550.7022380237079
INFO:root:current train perplexity3.400848388671875
INFO:root:current mean train loss 1551.574956507571
INFO:root:current train perplexity3.4022834300994873
INFO:root:current mean train loss 1549.9640386504245
INFO:root:current train perplexity3.3988213539123535
INFO:root:current mean train loss 1550.5308650172658
INFO:root:current train perplexity3.399099826812744
INFO:root:current mean train loss 1552.4366787369686
INFO:root:current train perplexity3.4019734859466553
INFO:root:current mean train loss 1554.1928908001682
INFO:root:current train perplexity3.4062957763671875
INFO:root:current mean train loss 1555.3839756484158
INFO:root:current train perplexity3.4079291820526123
INFO:root:current mean train loss 1556.204746122323
INFO:root:current train perplexity3.409832239151001
INFO:root:current mean train loss 1557.0813773764214
INFO:root:current train perplexity3.4121081829071045
INFO:root:current mean train loss 1557.0168815235274
INFO:root:current train perplexity3.4137275218963623
INFO:root:current mean train loss 1556.7546368122619
INFO:root:current train perplexity3.4140737056732178
INFO:root:current mean train loss 1557.7597454059235
INFO:root:current train perplexity3.415083169937134

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.04s/it]
INFO:root:final mean train loss: 1557.7550511131728
INFO:root:final train perplexity: 3.41623592376709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2063.390358782829
INFO:root:eval perplexity: 5.305526256561279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2570.770503050892
INFO:root:eval perplexity: 8.186175346374512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [12:04:33<23:23:54, 638.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1550.073211115057
INFO:root:current train perplexity3.376842975616455
INFO:root:current mean train loss 1547.4822816910282
INFO:root:current train perplexity3.375936985015869
INFO:root:current mean train loss 1544.43429553462
INFO:root:current train perplexity3.370401382446289
INFO:root:current mean train loss 1542.5990657322843
INFO:root:current train perplexity3.36936092376709
INFO:root:current mean train loss 1545.2632817865729
INFO:root:current train perplexity3.370384693145752
INFO:root:current mean train loss 1544.6419022293778
INFO:root:current train perplexity3.366661787033081
INFO:root:current mean train loss 1544.765202319895
INFO:root:current train perplexity3.372507095336914
INFO:root:current mean train loss 1546.7070787846646
INFO:root:current train perplexity3.3783318996429443
INFO:root:current mean train loss 1547.401454706917
INFO:root:current train perplexity3.3814215660095215
INFO:root:current mean train loss 1547.8055750981675
INFO:root:current train perplexity3.382683038711548
INFO:root:current mean train loss 1549.1440023557834
INFO:root:current train perplexity3.3848845958709717
INFO:root:current mean train loss 1548.0997615665585
INFO:root:current train perplexity3.3838539123535156
INFO:root:current mean train loss 1549.6085990996949
INFO:root:current train perplexity3.3897948265075684
INFO:root:current mean train loss 1549.5259880037765
INFO:root:current train perplexity3.391367197036743
INFO:root:current mean train loss 1550.0528289270565
INFO:root:current train perplexity3.3918046951293945
INFO:root:current mean train loss 1551.0183300153235
INFO:root:current train perplexity3.393777847290039
INFO:root:current mean train loss 1551.0347136252597
INFO:root:current train perplexity3.394958257675171
INFO:root:current mean train loss 1552.2822941706731
INFO:root:current train perplexity3.3972578048706055
INFO:root:current mean train loss 1551.7205537451566
INFO:root:current train perplexity3.3986289501190186
INFO:root:current mean train loss 1552.9056708060261
INFO:root:current train perplexity3.402369737625122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.76s/it]
INFO:root:final mean train loss: 1552.7750612259872
INFO:root:final train perplexity: 3.4028451442718506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2065.4053106646165
INFO:root:eval perplexity: 5.314179420471191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.20s/it]
INFO:root:eval mean loss: 2574.6864814487753
INFO:root:eval perplexity: 8.212432861328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [12:15:08<23:11:13, 637.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1558.2184007432725
INFO:root:current train perplexity3.391392707824707
INFO:root:current mean train loss 1548.4558368061864
INFO:root:current train perplexity3.3724679946899414
INFO:root:current mean train loss 1547.7750037698186
INFO:root:current train perplexity3.3790791034698486
INFO:root:current mean train loss 1545.9151066605764
INFO:root:current train perplexity3.3758704662323
INFO:root:current mean train loss 1540.9790910623842
INFO:root:current train perplexity3.3695313930511475
INFO:root:current mean train loss 1538.8794880046712
INFO:root:current train perplexity3.36606502532959
INFO:root:current mean train loss 1540.1108511061896
INFO:root:current train perplexity3.368605136871338
INFO:root:current mean train loss 1541.2423955887712
INFO:root:current train perplexity3.370358467102051
INFO:root:current mean train loss 1541.393619782334
INFO:root:current train perplexity3.372309684753418
INFO:root:current mean train loss 1543.3375030643165
INFO:root:current train perplexity3.375215530395508
INFO:root:current mean train loss 1542.3635553388453
INFO:root:current train perplexity3.3774588108062744
INFO:root:current mean train loss 1542.4796362346349
INFO:root:current train perplexity3.3767635822296143
INFO:root:current mean train loss 1541.8224059290856
INFO:root:current train perplexity3.3774447441101074
INFO:root:current mean train loss 1543.2251394733396
INFO:root:current train perplexity3.3801841735839844
INFO:root:current mean train loss 1544.1963826055112
INFO:root:current train perplexity3.382190227508545
INFO:root:current mean train loss 1544.3278800828464
INFO:root:current train perplexity3.382197856903076
INFO:root:current mean train loss 1544.811177230908
INFO:root:current train perplexity3.382071018218994
INFO:root:current mean train loss 1546.01639028166
INFO:root:current train perplexity3.383610486984253
INFO:root:current mean train loss 1546.9667265802368
INFO:root:current train perplexity3.385657548904419
INFO:root:current mean train loss 1547.481243017479
INFO:root:current train perplexity3.387575149536133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.70s/it]
INFO:root:final mean train loss: 1547.061294286346
INFO:root:final train perplexity: 3.387545108795166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2069.1104342413287
INFO:root:eval perplexity: 5.330126762390137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2580.2731695513353
INFO:root:eval perplexity: 8.250041961669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [12:25:35<22:54:30, 634.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1515.20274781645
INFO:root:current train perplexity3.3386011123657227
INFO:root:current mean train loss 1517.7036733475943
INFO:root:current train perplexity3.331407070159912
INFO:root:current mean train loss 1528.149585129893
INFO:root:current train perplexity3.3342084884643555
INFO:root:current mean train loss 1528.455412641589
INFO:root:current train perplexity3.341710090637207
INFO:root:current mean train loss 1529.9225397714565
INFO:root:current train perplexity3.3456602096557617
INFO:root:current mean train loss 1531.56826196745
INFO:root:current train perplexity3.350543737411499
INFO:root:current mean train loss 1532.570333937602
INFO:root:current train perplexity3.352079153060913
INFO:root:current mean train loss 1534.3972616642902
INFO:root:current train perplexity3.3529551029205322
INFO:root:current mean train loss 1535.6043521293236
INFO:root:current train perplexity3.3566715717315674
INFO:root:current mean train loss 1537.3844759394353
INFO:root:current train perplexity3.361233949661255
INFO:root:current mean train loss 1535.7556113110868
INFO:root:current train perplexity3.3585593700408936
INFO:root:current mean train loss 1535.9787888202075
INFO:root:current train perplexity3.358887195587158
INFO:root:current mean train loss 1535.7102810287772
INFO:root:current train perplexity3.358424425125122
INFO:root:current mean train loss 1536.7938810695925
INFO:root:current train perplexity3.3620951175689697
INFO:root:current mean train loss 1538.0286076573257
INFO:root:current train perplexity3.364377737045288
INFO:root:current mean train loss 1538.9661710053738
INFO:root:current train perplexity3.367016553878784
INFO:root:current mean train loss 1539.4074328316958
INFO:root:current train perplexity3.3679888248443604
INFO:root:current mean train loss 1540.5030495060962
INFO:root:current train perplexity3.3688857555389404
INFO:root:current mean train loss 1541.649139872804
INFO:root:current train perplexity3.372147560119629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.02s/it]
INFO:root:final mean train loss: 1541.3708909458423
INFO:root:final train perplexity: 3.3723766803741455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 2071.8108040018283
INFO:root:eval perplexity: 5.341780185699463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it]
INFO:root:eval mean loss: 2584.573378109763
INFO:root:eval perplexity: 8.279108047485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [12:36:21<22:51:11, 637.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.5679524739583
INFO:root:current train perplexity3.330782890319824
INFO:root:current mean train loss 1515.3636486125442
INFO:root:current train perplexity3.315308094024658
INFO:root:current mean train loss 1525.6007542286104
INFO:root:current train perplexity3.3170902729034424
INFO:root:current mean train loss 1526.3374805325775
INFO:root:current train perplexity3.320199489593506
INFO:root:current mean train loss 1529.4723673101716
INFO:root:current train perplexity3.326047658920288
INFO:root:current mean train loss 1527.2666129010468
INFO:root:current train perplexity3.328935146331787
INFO:root:current mean train loss 1527.2416468453487
INFO:root:current train perplexity3.3278844356536865
INFO:root:current mean train loss 1526.2209106099504
INFO:root:current train perplexity3.328409194946289
INFO:root:current mean train loss 1525.9962868513007
INFO:root:current train perplexity3.333827257156372
INFO:root:current mean train loss 1526.699812529103
INFO:root:current train perplexity3.3380119800567627
INFO:root:current mean train loss 1528.469044740347
INFO:root:current train perplexity3.3395371437072754
INFO:root:current mean train loss 1530.2972330434843
INFO:root:current train perplexity3.3428211212158203
INFO:root:current mean train loss 1531.2754052005596
INFO:root:current train perplexity3.3447556495666504
INFO:root:current mean train loss 1532.0100383670917
INFO:root:current train perplexity3.347625732421875
INFO:root:current mean train loss 1532.6431863060377
INFO:root:current train perplexity3.3488426208496094
INFO:root:current mean train loss 1533.355130908657
INFO:root:current train perplexity3.350083351135254
INFO:root:current mean train loss 1534.1563317095802
INFO:root:current train perplexity3.352109909057617
INFO:root:current mean train loss 1535.1047945011403
INFO:root:current train perplexity3.352771759033203
INFO:root:current mean train loss 1535.2466605726138
INFO:root:current train perplexity3.353487968444824
INFO:root:current mean train loss 1535.9075869453166
INFO:root:current train perplexity3.3553218841552734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.45s/it]
INFO:root:final mean train loss: 1535.9376009557805
INFO:root:final train perplexity: 3.357956647872925
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 2078.7171851624835
INFO:root:eval perplexity: 5.371700286865234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2591.3139276166335
INFO:root:eval perplexity: 8.324872016906738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [12:46:57<22:39:27, 637.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1544.9698167883832
INFO:root:current train perplexity3.3214523792266846
INFO:root:current mean train loss 1529.5810308689024
INFO:root:current train perplexity3.3202195167541504
INFO:root:current mean train loss 1524.4187526275225
INFO:root:current train perplexity3.314767599105835
INFO:root:current mean train loss 1524.240541629378
INFO:root:current train perplexity3.316197633743286
INFO:root:current mean train loss 1525.4261390920508
INFO:root:current train perplexity3.317376136779785
INFO:root:current mean train loss 1525.1070334906788
INFO:root:current train perplexity3.3202576637268066
INFO:root:current mean train loss 1524.9362216906602
INFO:root:current train perplexity3.3215975761413574
INFO:root:current mean train loss 1524.7198251642462
INFO:root:current train perplexity3.3252005577087402
INFO:root:current mean train loss 1524.2465879641934
INFO:root:current train perplexity3.325697660446167
INFO:root:current mean train loss 1525.425673727612
INFO:root:current train perplexity3.3291501998901367
INFO:root:current mean train loss 1524.460044584899
INFO:root:current train perplexity3.330000877380371
INFO:root:current mean train loss 1525.3218791958273
INFO:root:current train perplexity3.331328868865967
INFO:root:current mean train loss 1525.7589633345897
INFO:root:current train perplexity3.332245111465454
INFO:root:current mean train loss 1526.2017250205204
INFO:root:current train perplexity3.333139419555664
INFO:root:current mean train loss 1526.8213598341147
INFO:root:current train perplexity3.3348588943481445
INFO:root:current mean train loss 1528.918118312182
INFO:root:current train perplexity3.3381922245025635
INFO:root:current mean train loss 1528.6888175019494
INFO:root:current train perplexity3.3392250537872314
INFO:root:current mean train loss 1528.978704221153
INFO:root:current train perplexity3.339768171310425
INFO:root:current mean train loss 1529.6351235327456
INFO:root:current train perplexity3.3421318531036377
INFO:root:current mean train loss 1530.793166043048
INFO:root:current train perplexity3.3442277908325195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.02s/it]
INFO:root:final mean train loss: 1530.9077122582971
INFO:root:final train perplexity: 3.344662666320801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2077.7496272959606
INFO:root:eval perplexity: 5.36749792098999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2591.0038365573746
INFO:root:eval perplexity: 8.322762489318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:57:27<22:24:00, 634.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1518.8935302734376
INFO:root:current train perplexity3.3107707500457764
INFO:root:current mean train loss 1513.9489327566964
INFO:root:current train perplexity3.2924439907073975
INFO:root:current mean train loss 1523.4361363728842
INFO:root:current train perplexity3.30438494682312
INFO:root:current mean train loss 1520.5577216653262
INFO:root:current train perplexity3.3097078800201416
INFO:root:current mean train loss 1519.9270183216443
INFO:root:current train perplexity3.3080339431762695
INFO:root:current mean train loss 1521.9118238661024
INFO:root:current train perplexity3.3097143173217773
INFO:root:current mean train loss 1521.303726387024
INFO:root:current train perplexity3.3113632202148438
INFO:root:current mean train loss 1520.6181942501585
INFO:root:current train perplexity3.3111822605133057
INFO:root:current mean train loss 1521.5599327450707
INFO:root:current train perplexity3.3133089542388916
INFO:root:current mean train loss 1522.4327095194067
INFO:root:current train perplexity3.3156254291534424
INFO:root:current mean train loss 1521.7252171443058
INFO:root:current train perplexity3.3162243366241455
INFO:root:current mean train loss 1522.0514497455797
INFO:root:current train perplexity3.3174326419830322
INFO:root:current mean train loss 1523.7060833346459
INFO:root:current train perplexity3.3218977451324463
INFO:root:current mean train loss 1524.5265647774313
INFO:root:current train perplexity3.3246443271636963
INFO:root:current mean train loss 1524.8312914530436
INFO:root:current train perplexity3.325608491897583
INFO:root:current mean train loss 1524.8318169928216
INFO:root:current train perplexity3.3260440826416016
INFO:root:current mean train loss 1524.3930197366853
INFO:root:current train perplexity3.3265724182128906
INFO:root:current mean train loss 1525.255650522517
INFO:root:current train perplexity3.3268990516662598
INFO:root:current mean train loss 1526.334143265434
INFO:root:current train perplexity3.329669237136841
INFO:root:current mean train loss 1526.6414288393
INFO:root:current train perplexity3.3311750888824463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.98s/it]
INFO:root:final mean train loss: 1526.292102561716
INFO:root:final train perplexity: 3.332509756088257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2083.262684923537
INFO:root:eval perplexity: 5.391483306884766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2598.561971028646
INFO:root:eval perplexity: 8.374364852905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [13:08:09<22:17:58, 637.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.5882782517817
INFO:root:current train perplexity3.267775774002075
INFO:root:current mean train loss 1504.0444732471635
INFO:root:current train perplexity3.278316020965576
INFO:root:current mean train loss 1510.6856219221181
INFO:root:current train perplexity3.2867133617401123
INFO:root:current mean train loss 1507.979582799917
INFO:root:current train perplexity3.289027214050293
INFO:root:current mean train loss 1511.4188435427209
INFO:root:current train perplexity3.2915151119232178
INFO:root:current mean train loss 1508.4660274156333
INFO:root:current train perplexity3.2928874492645264
INFO:root:current mean train loss 1510.6053741780227
INFO:root:current train perplexity3.2951912879943848
INFO:root:current mean train loss 1512.3565872172226
INFO:root:current train perplexity3.2992749214172363
INFO:root:current mean train loss 1513.4018412248395
INFO:root:current train perplexity3.3039560317993164
INFO:root:current mean train loss 1515.263958619057
INFO:root:current train perplexity3.305762767791748
INFO:root:current mean train loss 1515.2252536798944
INFO:root:current train perplexity3.3045098781585693
INFO:root:current mean train loss 1515.91806317777
INFO:root:current train perplexity3.307157039642334
INFO:root:current mean train loss 1516.7233207902932
INFO:root:current train perplexity3.3082985877990723
INFO:root:current mean train loss 1516.949956119456
INFO:root:current train perplexity3.308220863342285
INFO:root:current mean train loss 1517.7035878115348
INFO:root:current train perplexity3.309566020965576
INFO:root:current mean train loss 1518.2740008893807
INFO:root:current train perplexity3.3118996620178223
INFO:root:current mean train loss 1518.730923364302
INFO:root:current train perplexity3.3132004737854004
INFO:root:current mean train loss 1519.2768472010396
INFO:root:current train perplexity3.3136813640594482
INFO:root:current mean train loss 1520.66413119331
INFO:root:current train perplexity3.3163418769836426
INFO:root:current mean train loss 1520.902572421316
INFO:root:current train perplexity3.3173341751098633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.30s/it]
INFO:root:final mean train loss: 1520.5378678360794
INFO:root:final train perplexity: 3.3174209594726562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 2082.2917255374555
INFO:root:eval perplexity: 5.387253284454346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2599.7518444737643
INFO:root:eval perplexity: 8.382516860961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [13:18:37<22:01:24, 634.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1509.1246799778294
INFO:root:current train perplexity3.280791997909546
INFO:root:current mean train loss 1502.2287850215516
INFO:root:current train perplexity3.272047996520996
INFO:root:current mean train loss 1502.1299483027772
INFO:root:current train perplexity3.2801740169525146
INFO:root:current mean train loss 1502.6076947380516
INFO:root:current train perplexity3.2790496349334717
INFO:root:current mean train loss 1503.2034948163898
INFO:root:current train perplexity3.277243137359619
INFO:root:current mean train loss 1506.533690980918
INFO:root:current train perplexity3.279905080795288
INFO:root:current mean train loss 1507.7726275616653
INFO:root:current train perplexity3.2832493782043457
INFO:root:current mean train loss 1508.252277226411
INFO:root:current train perplexity3.2818753719329834
INFO:root:current mean train loss 1507.8059170022436
INFO:root:current train perplexity3.2839972972869873
INFO:root:current mean train loss 1509.4303365781811
INFO:root:current train perplexity3.285210371017456
INFO:root:current mean train loss 1510.7153915888327
INFO:root:current train perplexity3.286362409591675
INFO:root:current mean train loss 1510.353176032461
INFO:root:current train perplexity3.288102626800537
INFO:root:current mean train loss 1510.6697041797488
INFO:root:current train perplexity3.2910959720611572
INFO:root:current mean train loss 1512.4373511879378
INFO:root:current train perplexity3.2935426235198975
INFO:root:current mean train loss 1512.8482960839447
INFO:root:current train perplexity3.2952089309692383
INFO:root:current mean train loss 1513.3974361201556
INFO:root:current train perplexity3.29768705368042
INFO:root:current mean train loss 1514.401334591664
INFO:root:current train perplexity3.2991151809692383
INFO:root:current mean train loss 1515.2255355680136
INFO:root:current train perplexity3.300551414489746
INFO:root:current mean train loss 1515.2753032085861
INFO:root:current train perplexity3.301532745361328
INFO:root:current mean train loss 1515.08342275262
INFO:root:current train perplexity3.3022282123565674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.51s/it]
INFO:root:final mean train loss: 1514.7816397262472
INFO:root:final train perplexity: 3.3023948669433594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2088.5747239133143
INFO:root:eval perplexity: 5.4146952629089355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 2606.7092016774714
INFO:root:eval perplexity: 8.430350303649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [13:29:05<21:47:22, 632.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.2883595896292
INFO:root:current train perplexity3.2784314155578613
INFO:root:current mean train loss 1498.8185562213678
INFO:root:current train perplexity3.2805898189544678
INFO:root:current mean train loss 1495.2101174056324
INFO:root:current train perplexity3.280151844024658
INFO:root:current mean train loss 1494.7607065966672
INFO:root:current train perplexity3.2677271366119385
INFO:root:current mean train loss 1495.6348026687403
INFO:root:current train perplexity3.2713518142700195
INFO:root:current mean train loss 1495.5241197305281
INFO:root:current train perplexity3.2685112953186035
INFO:root:current mean train loss 1498.291702645905
INFO:root:current train perplexity3.2684326171875
INFO:root:current mean train loss 1498.918898089345
INFO:root:current train perplexity3.271601915359497
INFO:root:current mean train loss 1501.1611748726414
INFO:root:current train perplexity3.275735378265381
INFO:root:current mean train loss 1502.3589542207997
INFO:root:current train perplexity3.276249647140503
INFO:root:current mean train loss 1502.8919546824875
INFO:root:current train perplexity3.278268337249756
INFO:root:current mean train loss 1504.8026866128123
INFO:root:current train perplexity3.28082013130188
INFO:root:current mean train loss 1505.522001211815
INFO:root:current train perplexity3.282607078552246
INFO:root:current mean train loss 1506.8582292415529
INFO:root:current train perplexity3.2832212448120117
INFO:root:current mean train loss 1507.7690930740694
INFO:root:current train perplexity3.2848122119903564
INFO:root:current mean train loss 1508.8733286878585
INFO:root:current train perplexity3.28780198097229
INFO:root:current mean train loss 1509.6157726826998
INFO:root:current train perplexity3.290283679962158
INFO:root:current mean train loss 1510.9772595480658
INFO:root:current train perplexity3.291579008102417
INFO:root:current mean train loss 1511.0449272974781
INFO:root:current train perplexity3.2927823066711426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.26s/it]
INFO:root:final mean train loss: 1511.1239856714199
INFO:root:final train perplexity: 3.2928824424743652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2091.976544319315
INFO:root:eval perplexity: 5.429612636566162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2610.7303687562335
INFO:root:eval perplexity: 8.458121299743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [13:39:48<21:42:53, 635.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.238784790039
INFO:root:current train perplexity3.193671464920044
INFO:root:current mean train loss 1494.782601815683
INFO:root:current train perplexity3.239078998565674
INFO:root:current mean train loss 1494.0794049776518
INFO:root:current train perplexity3.2517688274383545
INFO:root:current mean train loss 1492.9656986385196
INFO:root:current train perplexity3.2569425106048584
INFO:root:current mean train loss 1493.910321703144
INFO:root:current train perplexity3.2546825408935547
INFO:root:current mean train loss 1495.0013841043308
INFO:root:current train perplexity3.256953477859497
INFO:root:current mean train loss 1494.7408495451275
INFO:root:current train perplexity3.2586827278137207
INFO:root:current mean train loss 1494.4040551481946
INFO:root:current train perplexity3.2583744525909424
INFO:root:current mean train loss 1497.6444103883045
INFO:root:current train perplexity3.2605412006378174
INFO:root:current mean train loss 1499.2783800032696
INFO:root:current train perplexity3.2631099224090576
INFO:root:current mean train loss 1501.0488415672667
INFO:root:current train perplexity3.2677295207977295
INFO:root:current mean train loss 1501.9006381809497
INFO:root:current train perplexity3.268948554992676
INFO:root:current mean train loss 1502.5473800558127
INFO:root:current train perplexity3.270326852798462
INFO:root:current mean train loss 1503.8760819274717
INFO:root:current train perplexity3.2724077701568604
INFO:root:current mean train loss 1504.3272591504183
INFO:root:current train perplexity3.274226427078247
INFO:root:current mean train loss 1504.8577352265781
INFO:root:current train perplexity3.2752883434295654
INFO:root:current mean train loss 1506.0068028388332
INFO:root:current train perplexity3.27640700340271
INFO:root:current mean train loss 1505.9258862390452
INFO:root:current train perplexity3.2768940925598145
INFO:root:current mean train loss 1505.9385637941614
INFO:root:current train perplexity3.2782375812530518
INFO:root:current mean train loss 1506.0874435456794
INFO:root:current train perplexity3.2792553901672363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.70s/it]
INFO:root:final mean train loss: 1506.0723327852172
INFO:root:final train perplexity: 3.279789686203003
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 2095.6195592136246
INFO:root:eval perplexity: 5.4456329345703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2614.4947392889794
INFO:root:eval perplexity: 8.484199523925781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [13:50:17<21:28:47, 633.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1491.154833984375
INFO:root:current train perplexity3.246772050857544
INFO:root:current mean train loss 1484.5665087890625
INFO:root:current train perplexity3.2594006061553955
INFO:root:current mean train loss 1485.8990125868056
INFO:root:current train perplexity3.24428129196167
INFO:root:current mean train loss 1488.435576923077
INFO:root:current train perplexity3.246061086654663
INFO:root:current mean train loss 1490.0158760340073
INFO:root:current train perplexity3.2500829696655273
INFO:root:current mean train loss 1492.0688016183035
INFO:root:current train perplexity3.251094102859497
INFO:root:current mean train loss 1490.04462109375
INFO:root:current train perplexity3.254206418991089
INFO:root:current mean train loss 1490.364617962015
INFO:root:current train perplexity3.252041816711426
INFO:root:current mean train loss 1492.9839274088542
INFO:root:current train perplexity3.252615213394165
INFO:root:current mean train loss 1494.293430637669
INFO:root:current train perplexity3.2557361125946045
INFO:root:current mean train loss 1493.9326245712653
INFO:root:current train perplexity3.257953643798828
INFO:root:current mean train loss 1495.33454296875
INFO:root:current train perplexity3.2578237056732178
INFO:root:current mean train loss 1497.3410699338328
INFO:root:current train perplexity3.260298490524292
INFO:root:current mean train loss 1497.940167029039
INFO:root:current train perplexity3.2609171867370605
INFO:root:current mean train loss 1498.986145319353
INFO:root:current train perplexity3.262413501739502
INFO:root:current mean train loss 1499.477255219006
INFO:root:current train perplexity3.262667655944824
INFO:root:current mean train loss 1499.4185018028845
INFO:root:current train perplexity3.2636547088623047
INFO:root:current mean train loss 1500.1030996659874
INFO:root:current train perplexity3.2634639739990234
INFO:root:current mean train loss 1501.2383761638484
INFO:root:current train perplexity3.2650835514068604
INFO:root:current mean train loss 1501.7560693993507
INFO:root:current train perplexity3.2671058177948

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.71s/it]
INFO:root:final mean train loss: 1501.4311110072827
INFO:root:final train perplexity: 3.2678062915802
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2099.146595190603
INFO:root:eval perplexity: 5.4611897468566895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2622.23298547623
INFO:root:eval perplexity: 8.53806209564209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [14:00:58<21:22:33, 635.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1501.8341384161085
INFO:root:current train perplexity3.2555322647094727
INFO:root:current mean train loss 1499.819441674461
INFO:root:current train perplexity3.2409541606903076
INFO:root:current mean train loss 1497.6542484504132
INFO:root:current train perplexity3.2424306869506836
INFO:root:current mean train loss 1493.3796872144553
INFO:root:current train perplexity3.238438844680786
INFO:root:current mean train loss 1491.9832841001485
INFO:root:current train perplexity3.242861747741699
INFO:root:current mean train loss 1490.1891513275484
INFO:root:current train perplexity3.2379953861236572
INFO:root:current mean train loss 1491.4558668285144
INFO:root:current train perplexity3.2382972240448
INFO:root:current mean train loss 1492.269451624621
INFO:root:current train perplexity3.2406744956970215
INFO:root:current mean train loss 1491.3085095185847
INFO:root:current train perplexity3.2410669326782227
INFO:root:current mean train loss 1492.2052618784003
INFO:root:current train perplexity3.2451159954071045
INFO:root:current mean train loss 1494.0589611324376
INFO:root:current train perplexity3.246971845626831
INFO:root:current mean train loss 1492.6728551968176
INFO:root:current train perplexity3.2469184398651123
INFO:root:current mean train loss 1493.2379541566022
INFO:root:current train perplexity3.248690366744995
INFO:root:current mean train loss 1493.2277421794954
INFO:root:current train perplexity3.2491986751556396
INFO:root:current mean train loss 1494.1215662857035
INFO:root:current train perplexity3.251467227935791
INFO:root:current mean train loss 1495.1113343789266
INFO:root:current train perplexity3.2521891593933105
INFO:root:current mean train loss 1495.684971018337
INFO:root:current train perplexity3.252718210220337
INFO:root:current mean train loss 1495.709177150792
INFO:root:current train perplexity3.253476142883301
INFO:root:current mean train loss 1496.5068771577685
INFO:root:current train perplexity3.2539937496185303
INFO:root:current mean train loss 1496.5529929729742
INFO:root:current train perplexity3.2547495365142822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.27s/it]
INFO:root:final mean train loss: 1496.651746910507
INFO:root:final train perplexity: 3.255511999130249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2099.9808795469025
INFO:root:eval perplexity: 5.464875221252441
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2623.3697786804632
INFO:root:eval perplexity: 8.546005249023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [14:11:27<21:07:32, 633.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1477.4219432766154
INFO:root:current train perplexity3.1952507495880127
INFO:root:current mean train loss 1475.7066926776238
INFO:root:current train perplexity3.1984446048736572
INFO:root:current mean train loss 1476.8549587883083
INFO:root:current train perplexity3.2100234031677246
INFO:root:current mean train loss 1482.8258784302097
INFO:root:current train perplexity3.218292713165283
INFO:root:current mean train loss 1482.5728198614515
INFO:root:current train perplexity3.2199182510375977
INFO:root:current mean train loss 1483.5692861485354
INFO:root:current train perplexity3.2164928913116455
INFO:root:current mean train loss 1485.0759027275583
INFO:root:current train perplexity3.2196054458618164
INFO:root:current mean train loss 1484.8614313781497
INFO:root:current train perplexity3.2215983867645264
INFO:root:current mean train loss 1484.465817612458
INFO:root:current train perplexity3.224011182785034
INFO:root:current mean train loss 1485.9867169934096
INFO:root:current train perplexity3.227412462234497
INFO:root:current mean train loss 1486.4071210909835
INFO:root:current train perplexity3.2280690670013428
INFO:root:current mean train loss 1486.8329540973496
INFO:root:current train perplexity3.229356288909912
INFO:root:current mean train loss 1488.5102243340139
INFO:root:current train perplexity3.2319254875183105
INFO:root:current mean train loss 1489.3703108472453
INFO:root:current train perplexity3.2339518070220947
INFO:root:current mean train loss 1490.0840407666317
INFO:root:current train perplexity3.2351861000061035
INFO:root:current mean train loss 1490.3075096810605
INFO:root:current train perplexity3.2373456954956055
INFO:root:current mean train loss 1491.366530719042
INFO:root:current train perplexity3.2386481761932373
INFO:root:current mean train loss 1491.6412200147013
INFO:root:current train perplexity3.241044282913208
INFO:root:current mean train loss 1491.3560617661335
INFO:root:current train perplexity3.241284132003784
INFO:root:current mean train loss 1492.0733521691752
INFO:root:current train perplexity3.2435688972473145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.11s/it]
INFO:root:final mean train loss: 1492.0879584623597
INFO:root:final train perplexity: 3.2438156604766846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2102.486427685893
INFO:root:eval perplexity: 5.475959300994873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it]
INFO:root:eval mean loss: 2625.281189830591
INFO:root:eval perplexity: 8.559375762939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [14:22:01<20:57:06, 633.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1475.7377897563733
INFO:root:current train perplexity3.215282440185547
INFO:root:current mean train loss 1480.6690930453215
INFO:root:current train perplexity3.211883068084717
INFO:root:current mean train loss 1476.2697413347769
INFO:root:current train perplexity3.203883409500122
INFO:root:current mean train loss 1476.806772434965
INFO:root:current train perplexity3.206547260284424
INFO:root:current mean train loss 1478.2263488769531
INFO:root:current train perplexity3.204132080078125
INFO:root:current mean train loss 1481.912251578437
INFO:root:current train perplexity3.208652973175049
INFO:root:current mean train loss 1482.2561145308455
INFO:root:current train perplexity3.2115085124969482
INFO:root:current mean train loss 1482.8195613585797
INFO:root:current train perplexity3.212813138961792
INFO:root:current mean train loss 1483.8756511810163
INFO:root:current train perplexity3.215858221054077
INFO:root:current mean train loss 1484.7585548025663
INFO:root:current train perplexity3.217256784439087
INFO:root:current mean train loss 1484.7654420079796
INFO:root:current train perplexity3.219567060470581
INFO:root:current mean train loss 1485.307524285349
INFO:root:current train perplexity3.2215113639831543
INFO:root:current mean train loss 1486.988393371008
INFO:root:current train perplexity3.225503444671631
INFO:root:current mean train loss 1486.6512748363407
INFO:root:current train perplexity3.225344657897949
INFO:root:current mean train loss 1485.6844795040968
INFO:root:current train perplexity3.225738048553467
INFO:root:current mean train loss 1486.341367615056
INFO:root:current train perplexity3.2274527549743652
INFO:root:current mean train loss 1486.4531860351562
INFO:root:current train perplexity3.2286810874938965
INFO:root:current mean train loss 1486.426079827386
INFO:root:current train perplexity3.229534149169922
INFO:root:current mean train loss 1487.4518494433178
INFO:root:current train perplexity3.2315289974212646
INFO:root:current mean train loss 1488.093104930059
INFO:root:current train perplexity3.232771873474121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.17s/it]
INFO:root:final mean train loss: 1487.7710920017414
INFO:root:final train perplexity: 3.232790946960449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 2109.1662563026375
INFO:root:eval perplexity: 5.505621910095215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2633.23381139877
INFO:root:eval perplexity: 8.61522388458252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [14:32:38<20:48:20, 634.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1466.3516412550402
INFO:root:current train perplexity3.1784682273864746
INFO:root:current mean train loss 1469.9412607776069
INFO:root:current train perplexity3.1915957927703857
INFO:root:current mean train loss 1471.465776150544
INFO:root:current train perplexity3.194361448287964
INFO:root:current mean train loss 1474.0647659107626
INFO:root:current train perplexity3.1953916549682617
INFO:root:current mean train loss 1475.3140680959211
INFO:root:current train perplexity3.1972830295562744
INFO:root:current mean train loss 1479.8686863093512
INFO:root:current train perplexity3.2066781520843506
INFO:root:current mean train loss 1477.8490088877052
INFO:root:current train perplexity3.2079176902770996
INFO:root:current mean train loss 1478.76569781117
INFO:root:current train perplexity3.211036443710327
INFO:root:current mean train loss 1478.7814740461838
INFO:root:current train perplexity3.209664821624756
INFO:root:current mean train loss 1480.1806285354905
INFO:root:current train perplexity3.2110836505889893
INFO:root:current mean train loss 1481.1621400880247
INFO:root:current train perplexity3.212448835372925
INFO:root:current mean train loss 1481.1053518981166
INFO:root:current train perplexity3.214019775390625
INFO:root:current mean train loss 1480.214707612807
INFO:root:current train perplexity3.2133548259735107
INFO:root:current mean train loss 1480.3429629838647
INFO:root:current train perplexity3.214111089706421
INFO:root:current mean train loss 1480.4269203548854
INFO:root:current train perplexity3.213752031326294
INFO:root:current mean train loss 1481.4266991145344
INFO:root:current train perplexity3.213479518890381
INFO:root:current mean train loss 1481.3860527349518
INFO:root:current train perplexity3.2153818607330322
INFO:root:current mean train loss 1481.5150988653793
INFO:root:current train perplexity3.2162139415740967
INFO:root:current mean train loss 1482.1422027571768
INFO:root:current train perplexity3.2170495986938477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.01s/it]
INFO:root:final mean train loss: 1482.0400634088483
INFO:root:final train perplexity: 3.218212127685547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.52s/it]
INFO:root:eval mean loss: 2109.4265305539393
INFO:root:eval perplexity: 5.506780624389648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2636.5099050102503
INFO:root:eval perplexity: 8.638338088989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [14:43:25<20:44:58, 638.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.5976318359376
INFO:root:current train perplexity3.1576473712921143
INFO:root:current mean train loss 1461.3114002574573
INFO:root:current train perplexity3.1693310737609863
INFO:root:current mean train loss 1465.6361752464659
INFO:root:current train perplexity3.1734492778778076
INFO:root:current mean train loss 1465.8737915039062
INFO:root:current train perplexity3.1716220378875732
INFO:root:current mean train loss 1463.8888451552973
INFO:root:current train perplexity3.1707043647766113
INFO:root:current mean train loss 1465.6622781192555
INFO:root:current train perplexity3.1747238636016846
INFO:root:current mean train loss 1465.5447733894723
INFO:root:current train perplexity3.1791532039642334
INFO:root:current mean train loss 1465.755037721446
INFO:root:current train perplexity3.181976079940796
INFO:root:current mean train loss 1466.5456809714988
INFO:root:current train perplexity3.1848256587982178
INFO:root:current mean train loss 1467.221233527215
INFO:root:current train perplexity3.187234878540039
INFO:root:current mean train loss 1469.7081109075264
INFO:root:current train perplexity3.1888480186462402
INFO:root:current mean train loss 1470.5462561804968
INFO:root:current train perplexity3.1911163330078125
INFO:root:current mean train loss 1471.6758336090845
INFO:root:current train perplexity3.1928999423980713
INFO:root:current mean train loss 1472.0540788257395
INFO:root:current train perplexity3.19525146484375
INFO:root:current mean train loss 1472.946703668689
INFO:root:current train perplexity3.1981923580169678
INFO:root:current mean train loss 1473.6661745589302
INFO:root:current train perplexity3.1987366676330566
INFO:root:current mean train loss 1474.5011318420031
INFO:root:current train perplexity3.2006003856658936
INFO:root:current mean train loss 1474.3367563704999
INFO:root:current train perplexity3.201470136642456
INFO:root:current mean train loss 1476.1507908942292
INFO:root:current train perplexity3.2044174671173096
INFO:root:current mean train loss 1477.2699568344037
INFO:root:current train perplexity3.2054507732391357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.40s/it]
INFO:root:final mean train loss: 1477.967928626233
INFO:root:final train perplexity: 3.207893133163452
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 2112.2868388290944
INFO:root:eval perplexity: 5.519535541534424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2638.1069435498393
INFO:root:eval perplexity: 8.649627685546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [14:54:02<20:33:22, 637.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1453.4525191695602
INFO:root:current train perplexity3.1754066944122314
INFO:root:current mean train loss 1462.7518810362328
INFO:root:current train perplexity3.1702773571014404
INFO:root:current mean train loss 1468.9843034786275
INFO:root:current train perplexity3.176788091659546
INFO:root:current mean train loss 1464.9619163023222
INFO:root:current train perplexity3.1775944232940674
INFO:root:current mean train loss 1466.0018250512296
INFO:root:current train perplexity3.1773998737335205
INFO:root:current mean train loss 1466.432247270443
INFO:root:current train perplexity3.1758952140808105
INFO:root:current mean train loss 1467.2907485110147
INFO:root:current train perplexity3.1772139072418213
INFO:root:current mean train loss 1469.5769155468213
INFO:root:current train perplexity3.1809418201446533
INFO:root:current mean train loss 1469.9985541974474
INFO:root:current train perplexity3.182319402694702
INFO:root:current mean train loss 1468.5647793042492
INFO:root:current train perplexity3.1798086166381836
INFO:root:current mean train loss 1469.0152551043695
INFO:root:current train perplexity3.1809520721435547
INFO:root:current mean train loss 1471.1536110283107
INFO:root:current train perplexity3.1832363605499268
INFO:root:current mean train loss 1471.4744546730146
INFO:root:current train perplexity3.1855523586273193
INFO:root:current mean train loss 1472.169641766408
INFO:root:current train perplexity3.1879096031188965
INFO:root:current mean train loss 1472.7866605292188
INFO:root:current train perplexity3.1888909339904785
INFO:root:current mean train loss 1472.8421207170668
INFO:root:current train perplexity3.1908934116363525
INFO:root:current mean train loss 1472.1970489445682
INFO:root:current train perplexity3.1900198459625244
INFO:root:current mean train loss 1472.6308229023414
INFO:root:current train perplexity3.192314863204956
INFO:root:current mean train loss 1473.3542876679453
INFO:root:current train perplexity3.194725513458252
INFO:root:current mean train loss 1474.0861986177106
INFO:root:current train perplexity3.196350574493408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.84s/it]
INFO:root:final mean train loss: 1473.714488311783
INFO:root:final train perplexity: 3.197150468826294
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 2117.855891667359
INFO:root:eval perplexity: 5.544450759887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2645.827599924507
INFO:root:eval perplexity: 8.704416275024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [15:04:47<20:26:41, 640.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.3692876642401
INFO:root:current train perplexity3.15372633934021
INFO:root:current mean train loss 1459.8477333916558
INFO:root:current train perplexity3.172272205352783
INFO:root:current mean train loss 1463.9178231661438
INFO:root:current train perplexity3.1815342903137207
INFO:root:current mean train loss 1463.6759068688682
INFO:root:current train perplexity3.1739866733551025
INFO:root:current mean train loss 1465.6682953705658
INFO:root:current train perplexity3.1770505905151367
INFO:root:current mean train loss 1465.2157016080969
INFO:root:current train perplexity3.1748857498168945
INFO:root:current mean train loss 1466.7207008503979
INFO:root:current train perplexity3.1760237216949463
INFO:root:current mean train loss 1469.1983220910513
INFO:root:current train perplexity3.1791272163391113
INFO:root:current mean train loss 1469.6627999979173
INFO:root:current train perplexity3.179112434387207
INFO:root:current mean train loss 1468.4604750811043
INFO:root:current train perplexity3.1757514476776123
INFO:root:current mean train loss 1467.6444111674225
INFO:root:current train perplexity3.175837755203247
INFO:root:current mean train loss 1467.4645006940082
INFO:root:current train perplexity3.1768407821655273
INFO:root:current mean train loss 1468.5684479839165
INFO:root:current train perplexity3.178311586380005
INFO:root:current mean train loss 1468.8220545450847
INFO:root:current train perplexity3.1789705753326416
INFO:root:current mean train loss 1469.6779507877425
INFO:root:current train perplexity3.1807658672332764
INFO:root:current mean train loss 1469.529834569427
INFO:root:current train perplexity3.180945634841919
INFO:root:current mean train loss 1469.377317034125
INFO:root:current train perplexity3.1819703578948975
INFO:root:current mean train loss 1469.2755405531018
INFO:root:current train perplexity3.1834914684295654
INFO:root:current mean train loss 1469.2100982997008
INFO:root:current train perplexity3.184682607650757
INFO:root:current mean train loss 1469.4831112206227
INFO:root:current train perplexity3.186121702194214

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.43s/it]
INFO:root:final mean train loss: 1469.33180194495
INFO:root:final train perplexity: 3.1861190795898438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 2120.3739100246567
INFO:root:eval perplexity: 5.555752277374268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2654.033936412622
INFO:root:eval perplexity: 8.763031959533691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [15:15:23<20:14:12, 639.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1443.2313152375768
INFO:root:current train perplexity3.117232084274292
INFO:root:current mean train loss 1448.3284206982726
INFO:root:current train perplexity3.142925977706909
INFO:root:current mean train loss 1451.4592406758861
INFO:root:current train perplexity3.150031328201294
INFO:root:current mean train loss 1453.073933693841
INFO:root:current train perplexity3.152235269546509
INFO:root:current mean train loss 1453.386876567584
INFO:root:current train perplexity3.1527609825134277
INFO:root:current mean train loss 1453.7646952202401
INFO:root:current train perplexity3.1574065685272217
INFO:root:current mean train loss 1454.8265238659465
INFO:root:current train perplexity3.1559410095214844
INFO:root:current mean train loss 1457.5666356331103
INFO:root:current train perplexity3.1619527339935303
INFO:root:current mean train loss 1458.3801774258675
INFO:root:current train perplexity3.163486957550049
INFO:root:current mean train loss 1458.2513437896316
INFO:root:current train perplexity3.1640255451202393
INFO:root:current mean train loss 1458.852200924283
INFO:root:current train perplexity3.1645045280456543
INFO:root:current mean train loss 1460.150295786566
INFO:root:current train perplexity3.165724754333496
INFO:root:current mean train loss 1460.5989509116648
INFO:root:current train perplexity3.1671040058135986
INFO:root:current mean train loss 1461.8708841406537
INFO:root:current train perplexity3.167692184448242
INFO:root:current mean train loss 1462.8549102010343
INFO:root:current train perplexity3.169283628463745
INFO:root:current mean train loss 1462.6681242117434
INFO:root:current train perplexity3.1679680347442627
INFO:root:current mean train loss 1462.5713409478947
INFO:root:current train perplexity3.1688146591186523
INFO:root:current mean train loss 1463.3505984148744
INFO:root:current train perplexity3.170818328857422
INFO:root:current mean train loss 1464.5823469536078
INFO:root:current train perplexity3.175086736679077
INFO:root:current mean train loss 1465.835017708599
INFO:root:current train perplexity3.1759839057922363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.54s/it]
INFO:root:final mean train loss: 1465.2447262300846
INFO:root:final train perplexity: 3.175865411758423
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 2121.0384993316434
INFO:root:eval perplexity: 5.558740139007568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2652.014502559148
INFO:root:eval perplexity: 8.74857234954834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [15:26:01<20:02:34, 638.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1441.8284145257412
INFO:root:current train perplexity3.1111738681793213
INFO:root:current mean train loss 1457.7438999133165
INFO:root:current train perplexity3.1410558223724365
INFO:root:current mean train loss 1453.0334744899394
INFO:root:current train perplexity3.1368343830108643
INFO:root:current mean train loss 1454.4526615849247
INFO:root:current train perplexity3.138319253921509
INFO:root:current mean train loss 1455.3542278720745
INFO:root:current train perplexity3.143352508544922
INFO:root:current mean train loss 1455.298324215371
INFO:root:current train perplexity3.142831325531006
INFO:root:current mean train loss 1456.2238033148392
INFO:root:current train perplexity3.145449638366699
INFO:root:current mean train loss 1456.5026751912958
INFO:root:current train perplexity3.14699387550354
INFO:root:current mean train loss 1456.3680006996103
INFO:root:current train perplexity3.1512861251831055
INFO:root:current mean train loss 1457.9474592150355
INFO:root:current train perplexity3.155876398086548
INFO:root:current mean train loss 1457.098810482556
INFO:root:current train perplexity3.156512975692749
INFO:root:current mean train loss 1458.6146016404261
INFO:root:current train perplexity3.157409906387329
INFO:root:current mean train loss 1458.8040124836475
INFO:root:current train perplexity3.1587514877319336
INFO:root:current mean train loss 1459.1456699232924
INFO:root:current train perplexity3.1589183807373047
INFO:root:current mean train loss 1459.9535377925722
INFO:root:current train perplexity3.159445285797119
INFO:root:current mean train loss 1459.431384493945
INFO:root:current train perplexity3.1590068340301514
INFO:root:current mean train loss 1460.5433183745065
INFO:root:current train perplexity3.161497116088867
INFO:root:current mean train loss 1460.7324863429546
INFO:root:current train perplexity3.1622369289398193
INFO:root:current mean train loss 1461.0816552240374
INFO:root:current train perplexity3.1640491485595703
INFO:root:current mean train loss 1461.50100056925
INFO:root:current train perplexity3.1655831336975098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.72s/it]
INFO:root:final mean train loss: 1461.179709384012
INFO:root:final train perplexity: 3.1657001972198486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2125.253315810616
INFO:root:eval perplexity: 5.5777201652526855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2654.7180232054798
INFO:root:eval perplexity: 8.767934799194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [15:36:47<19:56:10, 640.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1447.7335706208883
INFO:root:current train perplexity3.1314897537231445
INFO:root:current mean train loss 1442.6156919821715
INFO:root:current train perplexity3.1210508346557617
INFO:root:current mean train loss 1445.5762802899894
INFO:root:current train perplexity3.123386859893799
INFO:root:current mean train loss 1442.2045929341377
INFO:root:current train perplexity3.1241698265075684
INFO:root:current mean train loss 1445.6726175327494
INFO:root:current train perplexity3.128014326095581
INFO:root:current mean train loss 1446.9054995240283
INFO:root:current train perplexity3.129448652267456
INFO:root:current mean train loss 1448.0093944961218
INFO:root:current train perplexity3.1334939002990723
INFO:root:current mean train loss 1449.0128422575176
INFO:root:current train perplexity3.134664297103882
INFO:root:current mean train loss 1451.4975224500263
INFO:root:current train perplexity3.135226011276245
INFO:root:current mean train loss 1451.199404002434
INFO:root:current train perplexity3.1388261318206787
INFO:root:current mean train loss 1452.7693668173872
INFO:root:current train perplexity3.140349864959717
INFO:root:current mean train loss 1452.9858346340548
INFO:root:current train perplexity3.1432883739471436
INFO:root:current mean train loss 1453.202601841518
INFO:root:current train perplexity3.1433229446411133
INFO:root:current mean train loss 1454.351324484767
INFO:root:current train perplexity3.1447548866271973
INFO:root:current mean train loss 1454.324057323239
INFO:root:current train perplexity3.145846366882324
INFO:root:current mean train loss 1454.1567848133816
INFO:root:current train perplexity3.147787094116211
INFO:root:current mean train loss 1454.5172273979074
INFO:root:current train perplexity3.147763252258301
INFO:root:current mean train loss 1454.7321586247606
INFO:root:current train perplexity3.1487038135528564
INFO:root:current mean train loss 1455.121900058233
INFO:root:current train perplexity3.1500437259674072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.82s/it]
INFO:root:final mean train loss: 1455.4616134420405
INFO:root:final train perplexity: 3.151456117630005
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2131.2391405037956
INFO:root:eval perplexity: 5.604787349700928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2664.874985715176
INFO:root:eval perplexity: 8.841071128845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [15:47:24<19:43:13, 639.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1473.3405456542969
INFO:root:current train perplexity3.1033053398132324
INFO:root:current mean train loss 1436.7190257481166
INFO:root:current train perplexity3.0928468704223633
INFO:root:current mean train loss 1438.8362052485627
INFO:root:current train perplexity3.0981335639953613
INFO:root:current mean train loss 1438.932856241862
INFO:root:current train perplexity3.1066129207611084
INFO:root:current mean train loss 1440.0152593816367
INFO:root:current train perplexity3.111661672592163
INFO:root:current mean train loss 1442.9056050777435
INFO:root:current train perplexity3.119152784347534
INFO:root:current mean train loss 1445.5083662045547
INFO:root:current train perplexity3.1216659545898438
INFO:root:current mean train loss 1444.6759357238084
INFO:root:current train perplexity3.122422695159912
INFO:root:current mean train loss 1444.7825348952722
INFO:root:current train perplexity3.1271309852600098
INFO:root:current mean train loss 1446.4298983122173
INFO:root:current train perplexity3.131385564804077
INFO:root:current mean train loss 1447.5822155616972
INFO:root:current train perplexity3.132270336151123
INFO:root:current mean train loss 1448.1128776056303
INFO:root:current train perplexity3.131761074066162
INFO:root:current mean train loss 1448.8889605330162
INFO:root:current train perplexity3.132697582244873
INFO:root:current mean train loss 1449.1203691436024
INFO:root:current train perplexity3.1334619522094727
INFO:root:current mean train loss 1449.683266874751
INFO:root:current train perplexity3.1348540782928467
INFO:root:current mean train loss 1450.3962994933759
INFO:root:current train perplexity3.13686466217041
INFO:root:current mean train loss 1450.8832235407297
INFO:root:current train perplexity3.1394641399383545
INFO:root:current mean train loss 1451.3114073566187
INFO:root:current train perplexity3.1407341957092285
INFO:root:current mean train loss 1451.3603188217871
INFO:root:current train perplexity3.1401772499084473
INFO:root:current mean train loss 1451.5116223450984
INFO:root:current train perplexity3.1410202980041504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.89s/it]
INFO:root:final mean train loss: 1451.2262046610053
INFO:root:final train perplexity: 3.140946626663208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 2131.150217908494
INFO:root:eval perplexity: 5.604384422302246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2665.0944153264904
INFO:root:eval perplexity: 8.842657089233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [15:57:58<19:29:44, 638.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.3567483836207
INFO:root:current train perplexity3.1125783920288086
INFO:root:current mean train loss 1435.175110336422
INFO:root:current train perplexity3.10909366607666
INFO:root:current mean train loss 1437.7337769087746
INFO:root:current train perplexity3.1202573776245117
INFO:root:current mean train loss 1436.0596775414372
INFO:root:current train perplexity3.116603136062622
INFO:root:current mean train loss 1440.433713543943
INFO:root:current train perplexity3.1174614429473877
INFO:root:current mean train loss 1440.330118968942
INFO:root:current train perplexity3.110474109649658
INFO:root:current mean train loss 1441.0691645732934
INFO:root:current train perplexity3.1119472980499268
INFO:root:current mean train loss 1441.3731969092935
INFO:root:current train perplexity3.1141700744628906
INFO:root:current mean train loss 1441.2816765834684
INFO:root:current train perplexity3.113833427429199
INFO:root:current mean train loss 1442.132429075703
INFO:root:current train perplexity3.1149837970733643
INFO:root:current mean train loss 1443.1458491111289
INFO:root:current train perplexity3.1184446811676025
INFO:root:current mean train loss 1443.2856881046212
INFO:root:current train perplexity3.120382785797119
INFO:root:current mean train loss 1444.5400605166801
INFO:root:current train perplexity3.123444080352783
INFO:root:current mean train loss 1444.7075687635206
INFO:root:current train perplexity3.124915599822998
INFO:root:current mean train loss 1445.7716162690256
INFO:root:current train perplexity3.127288341522217
INFO:root:current mean train loss 1446.7382685559649
INFO:root:current train perplexity3.1285994052886963
INFO:root:current mean train loss 1447.577010930426
INFO:root:current train perplexity3.1293156147003174
INFO:root:current mean train loss 1447.6936872492229
INFO:root:current train perplexity3.1296157836914062
INFO:root:current mean train loss 1447.4874902290358
INFO:root:current train perplexity3.130384922027588
INFO:root:current mean train loss 1448.0423083426483
INFO:root:current train perplexity3.1320512294769287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.20s/it]
INFO:root:final mean train loss: 1447.7363750325028
INFO:root:final train perplexity: 3.132314443588257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 2134.1641308940048
INFO:root:eval perplexity: 5.618061542510986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2667.5283921694927
INFO:root:eval perplexity: 8.860276222229004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [16:08:46<19:24:32, 641.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.5674385402513
INFO:root:current train perplexity3.06069278717041
INFO:root:current mean train loss 1422.9134170323202
INFO:root:current train perplexity3.084947347640991
INFO:root:current mean train loss 1424.6869854190486
INFO:root:current train perplexity3.0817365646362305
INFO:root:current mean train loss 1425.716223920701
INFO:root:current train perplexity3.087877035140991
INFO:root:current mean train loss 1429.1714020459642
INFO:root:current train perplexity3.0910093784332275
INFO:root:current mean train loss 1432.2908633724674
INFO:root:current train perplexity3.100766181945801
INFO:root:current mean train loss 1433.7705233074932
INFO:root:current train perplexity3.101548433303833
INFO:root:current mean train loss 1436.0999656043168
INFO:root:current train perplexity3.104707717895508
INFO:root:current mean train loss 1435.372950344221
INFO:root:current train perplexity3.1052920818328857
INFO:root:current mean train loss 1435.7503565330585
INFO:root:current train perplexity3.1067686080932617
INFO:root:current mean train loss 1438.0892526542707
INFO:root:current train perplexity3.1086232662200928
INFO:root:current mean train loss 1437.8432824898764
INFO:root:current train perplexity3.109560251235962
INFO:root:current mean train loss 1438.6696025915742
INFO:root:current train perplexity3.1103098392486572
INFO:root:current mean train loss 1439.6111773055873
INFO:root:current train perplexity3.11177396774292
INFO:root:current mean train loss 1440.8314939211348
INFO:root:current train perplexity3.1134419441223145
INFO:root:current mean train loss 1441.139222849541
INFO:root:current train perplexity3.114690065383911
INFO:root:current mean train loss 1441.9242531462398
INFO:root:current train perplexity3.1167221069335938
INFO:root:current mean train loss 1441.9554139931452
INFO:root:current train perplexity3.1175453662872314
INFO:root:current mean train loss 1442.1312902580748
INFO:root:current train perplexity3.1183688640594482
INFO:root:current mean train loss 1443.1374140364048
INFO:root:current train perplexity3.1205344200134277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.51s/it]
INFO:root:final mean train loss: 1443.211843732025
INFO:root:final train perplexity: 3.121156930923462
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.47s/it]
INFO:root:eval mean loss: 2137.3364954738754
INFO:root:eval perplexity: 5.632493495941162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 2672.1420474221522
INFO:root:eval perplexity: 8.893773078918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [16:19:31<19:15:53, 642.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1420.9954330202133
INFO:root:current train perplexity3.089827299118042
INFO:root:current mean train loss 1425.0045795089627
INFO:root:current train perplexity3.0989418029785156
INFO:root:current mean train loss 1430.0048080850463
INFO:root:current train perplexity3.100661277770996
INFO:root:current mean train loss 1431.9191037012527
INFO:root:current train perplexity3.102485179901123
INFO:root:current mean train loss 1430.7060301679771
INFO:root:current train perplexity3.096788167953491
INFO:root:current mean train loss 1430.0283935980517
INFO:root:current train perplexity3.096158027648926
INFO:root:current mean train loss 1431.8878435275853
INFO:root:current train perplexity3.09969162940979
INFO:root:current mean train loss 1433.001013999529
INFO:root:current train perplexity3.0998170375823975
INFO:root:current mean train loss 1434.1978458479687
INFO:root:current train perplexity3.1009130477905273
INFO:root:current mean train loss 1434.9237240546713
INFO:root:current train perplexity3.101069688796997
INFO:root:current mean train loss 1436.8038199165467
INFO:root:current train perplexity3.1029603481292725
INFO:root:current mean train loss 1437.6134669270273
INFO:root:current train perplexity3.1046669483184814
INFO:root:current mean train loss 1438.5146434116439
INFO:root:current train perplexity3.1069209575653076
INFO:root:current mean train loss 1439.1340225454821
INFO:root:current train perplexity3.107698917388916
INFO:root:current mean train loss 1438.8932530578488
INFO:root:current train perplexity3.108704090118408
INFO:root:current mean train loss 1439.2011928839022
INFO:root:current train perplexity3.1088545322418213
INFO:root:current mean train loss 1439.1047332451706
INFO:root:current train perplexity3.110426664352417
INFO:root:current mean train loss 1439.359924212546
INFO:root:current train perplexity3.1109750270843506
INFO:root:current mean train loss 1439.8805689092483
INFO:root:current train perplexity3.111844539642334
INFO:root:current mean train loss 1440.0523641841849
INFO:root:current train perplexity3.1120963096618652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.03s/it]
INFO:root:final mean train loss: 1439.648319492542
INFO:root:final train perplexity: 3.1123971939086914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 2142.8755527793937
INFO:root:eval perplexity: 5.657781600952148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2679.81723217254
INFO:root:eval perplexity: 8.949773788452148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [16:30:09<19:03:04, 640.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1414.9898406982422
INFO:root:current train perplexity3.0555436611175537
INFO:root:current mean train loss 1425.9937438964844
INFO:root:current train perplexity3.0683882236480713
INFO:root:current mean train loss 1427.469472830636
INFO:root:current train perplexity3.0746641159057617
INFO:root:current mean train loss 1428.5116721705388
INFO:root:current train perplexity3.075676679611206
INFO:root:current mean train loss 1427.4106269836425
INFO:root:current train perplexity3.079395294189453
INFO:root:current mean train loss 1428.0862875050511
INFO:root:current train perplexity3.082048177719116
INFO:root:current mean train loss 1429.5599928911995
INFO:root:current train perplexity3.084538698196411
INFO:root:current mean train loss 1429.6949135804787
INFO:root:current train perplexity3.0843288898468018
INFO:root:current mean train loss 1429.3579374833541
INFO:root:current train perplexity3.086225986480713
INFO:root:current mean train loss 1430.9408578055245
INFO:root:current train perplexity3.0888051986694336
INFO:root:current mean train loss 1431.27432985659
INFO:root:current train perplexity3.0903618335723877
INFO:root:current mean train loss 1432.2845548985367
INFO:root:current train perplexity3.0922563076019287
INFO:root:current mean train loss 1432.5511147499085
INFO:root:current train perplexity3.093851089477539
INFO:root:current mean train loss 1433.0021710824276
INFO:root:current train perplexity3.0936853885650635
INFO:root:current mean train loss 1433.374701587574
INFO:root:current train perplexity3.096013069152832
INFO:root:current mean train loss 1434.4791708644432
INFO:root:current train perplexity3.0980539321899414
INFO:root:current mean train loss 1434.9986361549013
INFO:root:current train perplexity3.099371910095215
INFO:root:current mean train loss 1435.3169864268784
INFO:root:current train perplexity3.100231885910034
INFO:root:current mean train loss 1435.3936902634641
INFO:root:current train perplexity3.100660562515259
INFO:root:current mean train loss 1435.5843084778448
INFO:root:current train perplexity3.1015148162841797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.36s/it]
INFO:root:final mean train loss: 1435.2553720786843
INFO:root:final train perplexity: 3.101633071899414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 2142.8261021823746
INFO:root:eval perplexity: 5.65755558013916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2680.2747049534573
INFO:root:eval perplexity: 8.95312213897705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [16:40:44<18:49:18, 639.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1418.1440631040593
INFO:root:current train perplexity3.0727474689483643
INFO:root:current mean train loss 1421.522102781964
INFO:root:current train perplexity3.074902296066284
INFO:root:current mean train loss 1419.6069274285826
INFO:root:current train perplexity3.0726077556610107
INFO:root:current mean train loss 1419.2822456263775
INFO:root:current train perplexity3.0692906379699707
INFO:root:current mean train loss 1418.9321797484124
INFO:root:current train perplexity3.0727663040161133
INFO:root:current mean train loss 1420.3874466734715
INFO:root:current train perplexity3.076477527618408
INFO:root:current mean train loss 1421.5965504365809
INFO:root:current train perplexity3.0780394077301025
INFO:root:current mean train loss 1425.4027565222611
INFO:root:current train perplexity3.083181142807007
INFO:root:current mean train loss 1427.3197912856222
INFO:root:current train perplexity3.0852787494659424
INFO:root:current mean train loss 1427.6368081294665
INFO:root:current train perplexity3.0860180854797363
INFO:root:current mean train loss 1428.4007138832112
INFO:root:current train perplexity3.0861976146698
INFO:root:current mean train loss 1429.1857527730458
INFO:root:current train perplexity3.086777448654175
INFO:root:current mean train loss 1429.6637693241917
INFO:root:current train perplexity3.087852954864502
INFO:root:current mean train loss 1429.8147356255872
INFO:root:current train perplexity3.086684226989746
INFO:root:current mean train loss 1430.059093039595
INFO:root:current train perplexity3.086548089981079
INFO:root:current mean train loss 1430.7986132598476
INFO:root:current train perplexity3.087754487991333
INFO:root:current mean train loss 1430.4787858773066
INFO:root:current train perplexity3.0892069339752197
INFO:root:current mean train loss 1431.3861741547328
INFO:root:current train perplexity3.091453790664673
INFO:root:current mean train loss 1431.6213757279174
INFO:root:current train perplexity3.0916333198547363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.95s/it]
INFO:root:final mean train loss: 1431.3846589750674
INFO:root:final train perplexity: 3.092179298400879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2147.556700361536
INFO:root:eval perplexity: 5.679242134094238
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2686.43603645487
INFO:root:eval perplexity: 8.998350143432617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [16:51:19<18:36:04, 637.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1444.6782052176338
INFO:root:current train perplexity3.07008957862854
INFO:root:current mean train loss 1416.0695747241639
INFO:root:current train perplexity3.073573112487793
INFO:root:current mean train loss 1420.506646557389
INFO:root:current train perplexity3.0593695640563965
INFO:root:current mean train loss 1420.669189453125
INFO:root:current train perplexity3.0652401447296143
INFO:root:current mean train loss 1420.1887655212108
INFO:root:current train perplexity3.0589888095855713
INFO:root:current mean train loss 1420.3733040776235
INFO:root:current train perplexity3.0597729682922363
INFO:root:current mean train loss 1419.4719520593699
INFO:root:current train perplexity3.0615458488464355
INFO:root:current mean train loss 1419.9949804140406
INFO:root:current train perplexity3.0623984336853027
INFO:root:current mean train loss 1421.7581835097703
INFO:root:current train perplexity3.065913200378418
INFO:root:current mean train loss 1422.1953394783404
INFO:root:current train perplexity3.067169189453125
INFO:root:current mean train loss 1422.534705769616
INFO:root:current train perplexity3.069737195968628
INFO:root:current mean train loss 1423.3653698138746
INFO:root:current train perplexity3.0694053173065186
INFO:root:current mean train loss 1423.372170864652
INFO:root:current train perplexity3.0707497596740723
INFO:root:current mean train loss 1424.1888355272545
INFO:root:current train perplexity3.0730667114257812
INFO:root:current mean train loss 1425.7189557238719
INFO:root:current train perplexity3.0743870735168457
INFO:root:current mean train loss 1425.8400116168366
INFO:root:current train perplexity3.076122760772705
INFO:root:current mean train loss 1426.271870704093
INFO:root:current train perplexity3.0779576301574707
INFO:root:current mean train loss 1426.4570835251513
INFO:root:current train perplexity3.0795562267303467
INFO:root:current mean train loss 1427.0154220429645
INFO:root:current train perplexity3.0807321071624756
INFO:root:current mean train loss 1427.6743759745216
INFO:root:current train perplexity3.0822503566741943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.85s/it]
INFO:root:final mean train loss: 1427.4641393987565
INFO:root:final train perplexity: 3.0826327800750732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 2151.265334541916
INFO:root:eval perplexity: 5.696300983428955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2693.9410872222684
INFO:root:eval perplexity: 9.053750991821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [17:02:06<18:30:28, 640.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1405.0393617691532
INFO:root:current train perplexity2.994162082672119
INFO:root:current mean train loss 1410.509477688156
INFO:root:current train perplexity3.0299875736236572
INFO:root:current mean train loss 1415.3874009697984
INFO:root:current train perplexity3.042675256729126
INFO:root:current mean train loss 1415.0775489461387
INFO:root:current train perplexity3.0447089672088623
INFO:root:current mean train loss 1414.1532194841213
INFO:root:current train perplexity3.0376765727996826
INFO:root:current mean train loss 1413.5991456917225
INFO:root:current train perplexity3.043091297149658
INFO:root:current mean train loss 1416.3746943405804
INFO:root:current train perplexity3.049367904663086
INFO:root:current mean train loss 1418.396151228251
INFO:root:current train perplexity3.0511605739593506
INFO:root:current mean train loss 1418.420423523757
INFO:root:current train perplexity3.0518274307250977
INFO:root:current mean train loss 1418.8109538634533
INFO:root:current train perplexity3.0562281608581543
INFO:root:current mean train loss 1419.715180005759
INFO:root:current train perplexity3.057896137237549
INFO:root:current mean train loss 1420.089515638815
INFO:root:current train perplexity3.060458183288574
INFO:root:current mean train loss 1420.3694229435862
INFO:root:current train perplexity3.0631890296936035
INFO:root:current mean train loss 1420.2794792009063
INFO:root:current train perplexity3.0645554065704346
INFO:root:current mean train loss 1420.7806875040947
INFO:root:current train perplexity3.06544828414917
INFO:root:current mean train loss 1420.8792225484517
INFO:root:current train perplexity3.0660886764526367
INFO:root:current mean train loss 1421.9305323373314
INFO:root:current train perplexity3.0676467418670654
INFO:root:current mean train loss 1422.6585368261663
INFO:root:current train perplexity3.068471908569336
INFO:root:current mean train loss 1422.9526951871628
INFO:root:current train perplexity3.0701236724853516
INFO:root:current mean train loss 1423.3926792707794
INFO:root:current train perplexity3.0722663402557373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.48s/it]
INFO:root:final mean train loss: 1423.266218299885
INFO:root:final train perplexity: 3.072443723678589
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 2154.3793594685008
INFO:root:eval perplexity: 5.710664749145508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2695.8064722372287
INFO:root:eval perplexity: 9.067574501037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [17:12:47<18:20:07, 640.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1419.0409088134766
INFO:root:current train perplexity3.035123109817505
INFO:root:current mean train loss 1415.4874688225823
INFO:root:current train perplexity3.0312340259552
INFO:root:current mean train loss 1416.3445193383002
INFO:root:current train perplexity3.0454792976379395
INFO:root:current mean train loss 1414.5097768498563
INFO:root:current train perplexity3.0521535873413086
INFO:root:current mean train loss 1413.3436649867467
INFO:root:current train perplexity3.051513671875
INFO:root:current mean train loss 1413.661018093137
INFO:root:current train perplexity3.0484280586242676
INFO:root:current mean train loss 1412.2734280809943
INFO:root:current train perplexity3.0491342544555664
INFO:root:current mean train loss 1413.1892528839928
INFO:root:current train perplexity3.051481008529663
INFO:root:current mean train loss 1415.3021025747623
INFO:root:current train perplexity3.0528018474578857
INFO:root:current mean train loss 1415.0526027759922
INFO:root:current train perplexity3.0510528087615967
INFO:root:current mean train loss 1415.1227326138328
INFO:root:current train perplexity3.0519521236419678
INFO:root:current mean train loss 1416.5883506216653
INFO:root:current train perplexity3.055459976196289
INFO:root:current mean train loss 1417.4347692636343
INFO:root:current train perplexity3.056318521499634
INFO:root:current mean train loss 1418.027258626785
INFO:root:current train perplexity3.056523323059082
INFO:root:current mean train loss 1417.6218910849555
INFO:root:current train perplexity3.057997465133667
INFO:root:current mean train loss 1417.3450425416615
INFO:root:current train perplexity3.0589475631713867
INFO:root:current mean train loss 1417.5661843309124
INFO:root:current train perplexity3.060091018676758
INFO:root:current mean train loss 1418.2006287738443
INFO:root:current train perplexity3.06013560295105
INFO:root:current mean train loss 1419.0118726589978
INFO:root:current train perplexity3.061432361602783
INFO:root:current mean train loss 1419.8085608511735
INFO:root:current train perplexity3.0622754096984863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.77s/it]
INFO:root:final mean train loss: 1419.132380606247
INFO:root:final train perplexity: 3.062443494796753
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2157.1720875408632
INFO:root:eval perplexity: 5.723578453063965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2697.73053021803
INFO:root:eval perplexity: 9.081853866577148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [17:23:25<18:08:00, 640.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.1482008713942
INFO:root:current train perplexity3.0041966438293457
INFO:root:current mean train loss 1400.0855897845645
INFO:root:current train perplexity3.010223150253296
INFO:root:current mean train loss 1402.9793093123526
INFO:root:current train perplexity3.0181052684783936
INFO:root:current mean train loss 1403.7674028788526
INFO:root:current train perplexity3.0175414085388184
INFO:root:current mean train loss 1406.3726890646
INFO:root:current train perplexity3.0260672569274902
INFO:root:current mean train loss 1405.2048478118086
INFO:root:current train perplexity3.030897617340088
INFO:root:current mean train loss 1405.7953523334704
INFO:root:current train perplexity3.033693552017212
INFO:root:current mean train loss 1406.8555161420036
INFO:root:current train perplexity3.036182403564453
INFO:root:current mean train loss 1408.4080970014452
INFO:root:current train perplexity3.039262056350708
INFO:root:current mean train loss 1409.7929836767325
INFO:root:current train perplexity3.042210102081299
INFO:root:current mean train loss 1410.6197478818221
INFO:root:current train perplexity3.0422897338867188
INFO:root:current mean train loss 1410.988211675161
INFO:root:current train perplexity3.043480634689331
INFO:root:current mean train loss 1411.6591766960537
INFO:root:current train perplexity3.0453991889953613
INFO:root:current mean train loss 1411.6662217583848
INFO:root:current train perplexity3.0470218658447266
INFO:root:current mean train loss 1412.9767807267224
INFO:root:current train perplexity3.0484023094177246
INFO:root:current mean train loss 1413.3742419160594
INFO:root:current train perplexity3.050373077392578
INFO:root:current mean train loss 1414.5307087116414
INFO:root:current train perplexity3.051548957824707
INFO:root:current mean train loss 1415.1522745883499
INFO:root:current train perplexity3.053283929824829
INFO:root:current mean train loss 1415.1282574119261
INFO:root:current train perplexity3.05277419090271
INFO:root:current mean train loss 1415.6037852357665
INFO:root:current train perplexity3.0531296730041504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.94s/it]
INFO:root:final mean train loss: 1415.3125812263124
INFO:root:final train perplexity: 3.0532314777374268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 2161.2711220599235
INFO:root:eval perplexity: 5.742584228515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2704.0301011538677
INFO:root:eval perplexity: 9.128762245178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [17:34:10<17:59:43, 641.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1396.0680065620236
INFO:root:current train perplexity3.023794651031494
INFO:root:current mean train loss 1397.6516327910372
INFO:root:current train perplexity3.026326894760132
INFO:root:current mean train loss 1402.65310690589
INFO:root:current train perplexity3.024102210998535
INFO:root:current mean train loss 1405.1959675893734
INFO:root:current train perplexity3.0236093997955322
INFO:root:current mean train loss 1405.4774818262124
INFO:root:current train perplexity3.027895927429199
INFO:root:current mean train loss 1404.515997293479
INFO:root:current train perplexity3.0269827842712402
INFO:root:current mean train loss 1403.8780762792683
INFO:root:current train perplexity3.0285518169403076
INFO:root:current mean train loss 1403.469002882233
INFO:root:current train perplexity3.0281670093536377
INFO:root:current mean train loss 1406.1961326685623
INFO:root:current train perplexity3.032400369644165
INFO:root:current mean train loss 1407.0960771673324
INFO:root:current train perplexity3.0311927795410156
INFO:root:current mean train loss 1407.020336440222
INFO:root:current train perplexity3.0318732261657715
INFO:root:current mean train loss 1407.7753133757667
INFO:root:current train perplexity3.0320322513580322
INFO:root:current mean train loss 1409.1274355979122
INFO:root:current train perplexity3.0345711708068848
INFO:root:current mean train loss 1409.7757375802732
INFO:root:current train perplexity3.036257028579712
INFO:root:current mean train loss 1410.405703072284
INFO:root:current train perplexity3.0384387969970703
INFO:root:current mean train loss 1410.7919088525205
INFO:root:current train perplexity3.0403759479522705
INFO:root:current mean train loss 1411.6548832769768
INFO:root:current train perplexity3.041811466217041
INFO:root:current mean train loss 1411.6682017933238
INFO:root:current train perplexity3.0419564247131348
INFO:root:current mean train loss 1411.9244764208413
INFO:root:current train perplexity3.0443308353424072
INFO:root:current mean train loss 1412.648662671071
INFO:root:current train perplexity3.045766830444336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.48s/it]
INFO:root:final mean train loss: 1412.1941277623719
INFO:root:final train perplexity: 3.045731782913208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it]
INFO:root:eval mean loss: 2161.812463205757
INFO:root:eval perplexity: 5.7450971603393555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 2706.085179105718
INFO:root:eval perplexity: 9.144116401672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [17:44:54<17:50:17, 642.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1389.409939236111
INFO:root:current train perplexity3.0039515495300293
INFO:root:current mean train loss 1403.2173471115343
INFO:root:current train perplexity3.0184733867645264
INFO:root:current mean train loss 1402.1025272229044
INFO:root:current train perplexity3.0165932178497314
INFO:root:current mean train loss 1402.6983379469182
INFO:root:current train perplexity3.021860361099243
INFO:root:current mean train loss 1403.4575552472131
INFO:root:current train perplexity3.0177600383758545
INFO:root:current mean train loss 1402.3654895202942
INFO:root:current train perplexity3.0200467109680176
INFO:root:current mean train loss 1401.9103799582551
INFO:root:current train perplexity3.0222811698913574
INFO:root:current mean train loss 1401.833383648506
INFO:root:current train perplexity3.0211665630340576
INFO:root:current mean train loss 1402.5707444306609
INFO:root:current train perplexity3.0246410369873047
INFO:root:current mean train loss 1403.1837369596158
INFO:root:current train perplexity3.025892496109009
INFO:root:current mean train loss 1404.5277759388862
INFO:root:current train perplexity3.029944658279419
INFO:root:current mean train loss 1406.2126033168918
INFO:root:current train perplexity3.031747579574585
INFO:root:current mean train loss 1405.4628327379235
INFO:root:current train perplexity3.031106472015381
INFO:root:current mean train loss 1405.6359432239547
INFO:root:current train perplexity3.032172203063965
INFO:root:current mean train loss 1406.3891931372216
INFO:root:current train perplexity3.0324530601501465
INFO:root:current mean train loss 1407.4935718032998
INFO:root:current train perplexity3.0332748889923096
INFO:root:current mean train loss 1407.9188104531847
INFO:root:current train perplexity3.0344207286834717
INFO:root:current mean train loss 1407.8908497342275
INFO:root:current train perplexity3.033936023712158
INFO:root:current mean train loss 1408.370482948468
INFO:root:current train perplexity3.0345938205718994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.77s/it]
INFO:root:final mean train loss: 1408.325481066605
INFO:root:final train perplexity: 3.0364534854888916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 2165.163314494681
INFO:root:eval perplexity: 5.760688781738281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2707.86800216783
INFO:root:eval perplexity: 9.15746021270752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [17:55:31<17:36:59, 640.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1378.0514526367188
INFO:root:current train perplexity3.0039000511169434
INFO:root:current mean train loss 1395.8577659870016
INFO:root:current train perplexity2.9960598945617676
INFO:root:current mean train loss 1398.6668848108363
INFO:root:current train perplexity2.9958040714263916
INFO:root:current mean train loss 1396.348823643938
INFO:root:current train perplexity2.9987170696258545
INFO:root:current mean train loss 1394.0439761235164
INFO:root:current train perplexity3.0022685527801514
INFO:root:current mean train loss 1394.3491244057352
INFO:root:current train perplexity3.004410982131958
INFO:root:current mean train loss 1394.5332677271458
INFO:root:current train perplexity3.002469062805176
INFO:root:current mean train loss 1393.520029760606
INFO:root:current train perplexity3.004227638244629
INFO:root:current mean train loss 1395.5672504200654
INFO:root:current train perplexity3.0085196495056152
INFO:root:current mean train loss 1396.4814012019394
INFO:root:current train perplexity3.0103421211242676
INFO:root:current mean train loss 1397.091792309378
INFO:root:current train perplexity3.0127170085906982
INFO:root:current mean train loss 1398.6724485992104
INFO:root:current train perplexity3.0147392749786377
INFO:root:current mean train loss 1399.0470205608167
INFO:root:current train perplexity3.0160000324249268
INFO:root:current mean train loss 1400.1270281667043
INFO:root:current train perplexity3.0176682472229004
INFO:root:current mean train loss 1401.2900422521905
INFO:root:current train perplexity3.0202138423919678
INFO:root:current mean train loss 1401.943968035615
INFO:root:current train perplexity3.022599935531616
INFO:root:current mean train loss 1402.459277766766
INFO:root:current train perplexity3.0237205028533936
INFO:root:current mean train loss 1403.31453550112
INFO:root:current train perplexity3.025407075881958
INFO:root:current mean train loss 1404.1606472200233
INFO:root:current train perplexity3.026904582977295
INFO:root:current mean train loss 1404.5344351686863
INFO:root:current train perplexity3.0273773670196533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.36s/it]
INFO:root:final mean train loss: 1404.7516697101141
INFO:root:final train perplexity: 3.027907133102417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 2167.8003263000055
INFO:root:eval perplexity: 5.77298641204834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2712.8164447757367
INFO:root:eval perplexity: 9.194594383239746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [18:06:09<17:24:55, 639.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1401.191465435606
INFO:root:current train perplexity3.0084784030914307
INFO:root:current mean train loss 1398.8658070958647
INFO:root:current train perplexity3.025270700454712
INFO:root:current mean train loss 1394.1539977241484
INFO:root:current train perplexity3.0090465545654297
INFO:root:current mean train loss 1395.786105685764
INFO:root:current train perplexity3.0083231925964355
INFO:root:current mean train loss 1398.5042710513496
INFO:root:current train perplexity3.0098912715911865
INFO:root:current mean train loss 1396.8986864501494
INFO:root:current train perplexity3.0079216957092285
INFO:root:current mean train loss 1395.8411261632357
INFO:root:current train perplexity3.00888729095459
INFO:root:current mean train loss 1397.626667017501
INFO:root:current train perplexity3.0101208686828613
INFO:root:current mean train loss 1397.6917601513262
INFO:root:current train perplexity3.011383533477783
INFO:root:current mean train loss 1398.8465462344252
INFO:root:current train perplexity3.0103538036346436
INFO:root:current mean train loss 1399.0579241949267
INFO:root:current train perplexity3.010773181915283
INFO:root:current mean train loss 1399.2942947158747
INFO:root:current train perplexity3.0127668380737305
INFO:root:current mean train loss 1399.2966448187537
INFO:root:current train perplexity3.012563705444336
INFO:root:current mean train loss 1399.9031974180068
INFO:root:current train perplexity3.0136046409606934
INFO:root:current mean train loss 1400.1896150619602
INFO:root:current train perplexity3.014618158340454
INFO:root:current mean train loss 1400.8610778529894
INFO:root:current train perplexity3.017106533050537
INFO:root:current mean train loss 1400.9974830192944
INFO:root:current train perplexity3.0176358222961426
INFO:root:current mean train loss 1400.746928026273
INFO:root:current train perplexity3.0172858238220215
INFO:root:current mean train loss 1401.9331743289263
INFO:root:current train perplexity3.0195999145507812
INFO:root:current mean train loss 1401.8495068814061
INFO:root:current train perplexity3.0199296474456787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it]
INFO:root:final mean train loss: 1401.5301642021145
INFO:root:final train perplexity: 3.02022385597229
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2171.0054256358044
INFO:root:eval perplexity: 5.787970066070557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2717.5453478224736
INFO:root:eval perplexity: 9.230222702026367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [18:16:43<17:11:30, 638.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.392607421875
INFO:root:current train perplexity2.977900743484497
INFO:root:current mean train loss 1386.1906599934896
INFO:root:current train perplexity2.9846785068511963
INFO:root:current mean train loss 1391.1386665039063
INFO:root:current train perplexity2.9884469509124756
INFO:root:current mean train loss 1389.104392438616
INFO:root:current train perplexity2.9845707416534424
INFO:root:current mean train loss 1388.6827026367187
INFO:root:current train perplexity2.9880566596984863
INFO:root:current mean train loss 1391.2389690607245
INFO:root:current train perplexity2.9937403202056885
INFO:root:current mean train loss 1392.158617600661
INFO:root:current train perplexity2.9981184005737305
INFO:root:current mean train loss 1393.8645971679687
INFO:root:current train perplexity2.9985830783843994
INFO:root:current mean train loss 1394.003173828125
INFO:root:current train perplexity2.997384548187256
INFO:root:current mean train loss 1395.5471475380346
INFO:root:current train perplexity3.0006492137908936
INFO:root:current mean train loss 1395.7249579148065
INFO:root:current train perplexity3.003040075302124
INFO:root:current mean train loss 1395.451730638587
INFO:root:current train perplexity3.00266170501709
INFO:root:current mean train loss 1395.7537083007812
INFO:root:current train perplexity3.00277042388916
INFO:root:current mean train loss 1395.6850074146412
INFO:root:current train perplexity3.003859281539917
INFO:root:current mean train loss 1395.9044356984105
INFO:root:current train perplexity3.0046865940093994
INFO:root:current mean train loss 1396.3084749086443
INFO:root:current train perplexity3.0067903995513916
INFO:root:current mean train loss 1397.346765654593
INFO:root:current train perplexity3.008230686187744
INFO:root:current mean train loss 1397.6803283342633
INFO:root:current train perplexity3.008671760559082
INFO:root:current mean train loss 1397.6651768369932
INFO:root:current train perplexity3.009552001953125
INFO:root:current mean train loss 1397.6413743239182
INFO:root:current train perplexity3.0097529888153076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.57s/it]
INFO:root:final mean train loss: 1397.35404976726
INFO:root:final train perplexity: 3.0102930068969727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2172.345814373476
INFO:root:eval perplexity: 5.794248104095459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2720.0689870415003
INFO:root:eval perplexity: 9.249295234680176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [18:27:27<17:03:54, 639.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1399.3848257491838
INFO:root:current train perplexity2.9587574005126953
INFO:root:current mean train loss 1387.0945920658683
INFO:root:current train perplexity2.9695732593536377
INFO:root:current mean train loss 1387.680223786429
INFO:root:current train perplexity2.9736640453338623
INFO:root:current mean train loss 1385.698903096794
INFO:root:current train perplexity2.9739890098571777
INFO:root:current mean train loss 1385.155935544784
INFO:root:current train perplexity2.973071336746216
INFO:root:current mean train loss 1386.3722162801753
INFO:root:current train perplexity2.977510929107666
INFO:root:current mean train loss 1387.0605911643788
INFO:root:current train perplexity2.979808807373047
INFO:root:current mean train loss 1388.544500597142
INFO:root:current train perplexity2.9827048778533936
INFO:root:current mean train loss 1388.671805305877
INFO:root:current train perplexity2.986093521118164
INFO:root:current mean train loss 1388.2431341445433
INFO:root:current train perplexity2.986445665359497
INFO:root:current mean train loss 1388.5438424622555
INFO:root:current train perplexity2.990694999694824
INFO:root:current mean train loss 1390.1123054197126
INFO:root:current train perplexity2.9935996532440186
INFO:root:current mean train loss 1390.3090850179742
INFO:root:current train perplexity2.9947350025177
INFO:root:current mean train loss 1390.9821945223916
INFO:root:current train perplexity2.9954416751861572
INFO:root:current mean train loss 1390.2560402753813
INFO:root:current train perplexity2.996086835861206
INFO:root:current mean train loss 1390.4578447664476
INFO:root:current train perplexity2.9967033863067627
INFO:root:current mean train loss 1391.4109727370933
INFO:root:current train perplexity2.9982011318206787
INFO:root:current mean train loss 1392.5429157630563
INFO:root:current train perplexity3.0001986026763916
INFO:root:current mean train loss 1393.315326316764
INFO:root:current train perplexity3.0012495517730713
INFO:root:current mean train loss 1394.3233355864936
INFO:root:current train perplexity3.0020604133605957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.26s/it]
INFO:root:final mean train loss: 1394.050197891797
INFO:root:final train perplexity: 3.002459764480591
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 2177.7665734257257
INFO:root:eval perplexity: 5.819705486297607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2725.845146882619
INFO:root:eval perplexity: 9.29308795928955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [18:38:08<16:53:39, 640.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1373.313246954055
INFO:root:current train perplexity2.947549343109131
INFO:root:current mean train loss 1377.9556957742443
INFO:root:current train perplexity2.962797164916992
INFO:root:current mean train loss 1378.5267437142386
INFO:root:current train perplexity2.9677574634552
INFO:root:current mean train loss 1377.5430345535278
INFO:root:current train perplexity2.965026617050171
INFO:root:current mean train loss 1380.0542794219718
INFO:root:current train perplexity2.9699909687042236
INFO:root:current mean train loss 1384.4857196546582
INFO:root:current train perplexity2.976069927215576
INFO:root:current mean train loss 1386.067896257367
INFO:root:current train perplexity2.977799892425537
INFO:root:current mean train loss 1386.1550112354512
INFO:root:current train perplexity2.978618621826172
INFO:root:current mean train loss 1385.2303176810838
INFO:root:current train perplexity2.9802050590515137
INFO:root:current mean train loss 1384.8923743023136
INFO:root:current train perplexity2.9809303283691406
INFO:root:current mean train loss 1385.81329447053
INFO:root:current train perplexity2.98225998878479
INFO:root:current mean train loss 1386.9877893602527
INFO:root:current train perplexity2.983017683029175
INFO:root:current mean train loss 1387.2707241925866
INFO:root:current train perplexity2.985269069671631
INFO:root:current mean train loss 1388.0923670950654
INFO:root:current train perplexity2.987494468688965
INFO:root:current mean train loss 1389.119024806267
INFO:root:current train perplexity2.9896035194396973
INFO:root:current mean train loss 1389.2918247261432
INFO:root:current train perplexity2.9898476600646973
INFO:root:current mean train loss 1389.302075601247
INFO:root:current train perplexity2.9907631874084473
INFO:root:current mean train loss 1390.0069322799889
INFO:root:current train perplexity2.9933016300201416
INFO:root:current mean train loss 1390.9200501006626
INFO:root:current train perplexity2.994920015335083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.58s/it]
INFO:root:final mean train loss: 1390.859582605713
INFO:root:final train perplexity: 2.9949138164520264
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2179.717202044548
INFO:root:eval perplexity: 5.828894138336182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2728.7991263748063
INFO:root:eval perplexity: 9.315567016601562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [18:48:36<16:37:25, 636.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1376.07373046875
INFO:root:current train perplexity3.0582728385925293
INFO:root:current mean train loss 1375.0041479733911
INFO:root:current train perplexity2.9643125534057617
INFO:root:current mean train loss 1380.6373594673119
INFO:root:current train perplexity2.972602128982544
INFO:root:current mean train loss 1382.1944369192536
INFO:root:current train perplexity2.972564697265625
INFO:root:current mean train loss 1380.6946226961893
INFO:root:current train perplexity2.9728682041168213
INFO:root:current mean train loss 1380.3204774532965
INFO:root:current train perplexity2.971665382385254
INFO:root:current mean train loss 1381.6035808239524
INFO:root:current train perplexity2.971593141555786
INFO:root:current mean train loss 1382.3850914360623
INFO:root:current train perplexity2.975403308868408
INFO:root:current mean train loss 1383.323588434379
INFO:root:current train perplexity2.9762611389160156
INFO:root:current mean train loss 1382.5853551934483
INFO:root:current train perplexity2.975888252258301
INFO:root:current mean train loss 1382.2273947975852
INFO:root:current train perplexity2.975886106491089
INFO:root:current mean train loss 1382.3208762852307
INFO:root:current train perplexity2.9783146381378174
INFO:root:current mean train loss 1382.7729464744548
INFO:root:current train perplexity2.979959011077881
INFO:root:current mean train loss 1383.5550868322443
INFO:root:current train perplexity2.980578899383545
INFO:root:current mean train loss 1383.486647720936
INFO:root:current train perplexity2.981459617614746
INFO:root:current mean train loss 1383.9164587703249
INFO:root:current train perplexity2.9821012020111084
INFO:root:current mean train loss 1384.5843833718427
INFO:root:current train perplexity2.982158660888672
INFO:root:current mean train loss 1385.123731717441
INFO:root:current train perplexity2.982346296310425
INFO:root:current mean train loss 1386.5576042416756
INFO:root:current train perplexity2.9845383167266846
INFO:root:current mean train loss 1386.9648154317424
INFO:root:current train perplexity2.9854633808135986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.75s/it]
INFO:root:final mean train loss: 1387.2535714030687
INFO:root:final train perplexity: 2.9864089488983154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2181.5511002777316
INFO:root:eval perplexity: 5.837545394897461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.10s/it]
INFO:root:eval mean loss: 2731.136042601673
INFO:root:eval perplexity: 9.333389282226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [18:59:16<16:27:59, 637.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.0099758572048
INFO:root:current train perplexity2.9613566398620605
INFO:root:current mean train loss 1376.812363446769
INFO:root:current train perplexity2.959981918334961
INFO:root:current mean train loss 1378.2139422215453
INFO:root:current train perplexity2.961866617202759
INFO:root:current mean train loss 1376.6707468092816
INFO:root:current train perplexity2.957523822784424
INFO:root:current mean train loss 1378.4936383261065
INFO:root:current train perplexity2.959618091583252
INFO:root:current mean train loss 1376.8499072454151
INFO:root:current train perplexity2.9630208015441895
INFO:root:current mean train loss 1376.4965917099642
INFO:root:current train perplexity2.9624838829040527
INFO:root:current mean train loss 1376.0854194662365
INFO:root:current train perplexity2.962735176086426
INFO:root:current mean train loss 1376.6843690009455
INFO:root:current train perplexity2.963916301727295
INFO:root:current mean train loss 1378.871672586678
INFO:root:current train perplexity2.9658772945404053
INFO:root:current mean train loss 1379.8085679689418
INFO:root:current train perplexity2.9679689407348633
INFO:root:current mean train loss 1379.1834747369046
INFO:root:current train perplexity2.967869997024536
INFO:root:current mean train loss 1378.9517295098265
INFO:root:current train perplexity2.9676144123077393
INFO:root:current mean train loss 1380.1374776605771
INFO:root:current train perplexity2.9702560901641846
INFO:root:current mean train loss 1381.1437327999658
INFO:root:current train perplexity2.9722442626953125
INFO:root:current mean train loss 1381.7485340304368
INFO:root:current train perplexity2.973195791244507
INFO:root:current mean train loss 1382.7097037448577
INFO:root:current train perplexity2.973693370819092
INFO:root:current mean train loss 1383.0269047800405
INFO:root:current train perplexity2.9751226902008057
INFO:root:current mean train loss 1383.5215951648877
INFO:root:current train perplexity2.9751479625701904
INFO:root:current mean train loss 1383.5277506934715
INFO:root:current train perplexity2.9758358001708984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.95s/it]
INFO:root:final mean train loss: 1383.3378996125268
INFO:root:final train perplexity: 2.977200746536255
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 2185.4602518284573
INFO:root:eval perplexity: 5.856029510498047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2737.2091393436945
INFO:root:eval perplexity: 9.37985897064209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [19:09:48<16:15:01, 635.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1373.8142333984374
INFO:root:current train perplexity2.9754724502563477
INFO:root:current mean train loss 1362.6564914279513
INFO:root:current train perplexity2.9688591957092285
INFO:root:current mean train loss 1367.7443967129323
INFO:root:current train perplexity2.9544503688812256
INFO:root:current mean train loss 1368.5644651498367
INFO:root:current train perplexity2.9495487213134766
INFO:root:current mean train loss 1368.6700248630568
INFO:root:current train perplexity2.9512531757354736
INFO:root:current mean train loss 1370.8692159207067
INFO:root:current train perplexity2.9519357681274414
INFO:root:current mean train loss 1371.6585949034202
INFO:root:current train perplexity2.9511096477508545
INFO:root:current mean train loss 1373.5599740579826
INFO:root:current train perplexity2.955094337463379
INFO:root:current mean train loss 1373.0120326242047
INFO:root:current train perplexity2.9592232704162598
INFO:root:current mean train loss 1374.4335630692262
INFO:root:current train perplexity2.9589672088623047
INFO:root:current mean train loss 1375.2937416260945
INFO:root:current train perplexity2.961608648300171
INFO:root:current mean train loss 1376.585496110958
INFO:root:current train perplexity2.963682174682617
INFO:root:current mean train loss 1376.9812777747027
INFO:root:current train perplexity2.9653141498565674
INFO:root:current mean train loss 1377.9350307964653
INFO:root:current train perplexity2.9658772945404053
INFO:root:current mean train loss 1377.9233509023845
INFO:root:current train perplexity2.9662928581237793
INFO:root:current mean train loss 1378.1050899741704
INFO:root:current train perplexity2.9659550189971924
INFO:root:current mean train loss 1378.3335510440559
INFO:root:current train perplexity2.9665367603302
INFO:root:current mean train loss 1378.8909674300928
INFO:root:current train perplexity2.96771502494812
INFO:root:current mean train loss 1379.3356970846814
INFO:root:current train perplexity2.9680333137512207
INFO:root:current mean train loss 1380.6094899416587
INFO:root:current train perplexity2.969787120819092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.54s/it]
INFO:root:final mean train loss: 1380.3660199525557
INFO:root:final train perplexity: 2.970231056213379
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2190.2573285474846
INFO:root:eval perplexity: 5.878793716430664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2741.6360144648993
INFO:root:eval perplexity: 9.413881301879883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [19:20:20<16:02:32, 634.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1365.922602726863
INFO:root:current train perplexity2.953354597091675
INFO:root:current mean train loss 1375.542903699373
INFO:root:current train perplexity2.955212354660034
INFO:root:current mean train loss 1374.6983894469247
INFO:root:current train perplexity2.9454925060272217
INFO:root:current mean train loss 1371.2247480912642
INFO:root:current train perplexity2.9480490684509277
INFO:root:current mean train loss 1372.4153307349281
INFO:root:current train perplexity2.9541921615600586
INFO:root:current mean train loss 1374.5876885013304
INFO:root:current train perplexity2.9521028995513916
INFO:root:current mean train loss 1374.6759549942485
INFO:root:current train perplexity2.9512534141540527
INFO:root:current mean train loss 1376.4414739405854
INFO:root:current train perplexity2.9510908126831055
INFO:root:current mean train loss 1376.3908379066718
INFO:root:current train perplexity2.9523417949676514
INFO:root:current mean train loss 1376.0729965081737
INFO:root:current train perplexity2.953923225402832
INFO:root:current mean train loss 1375.3089896662607
INFO:root:current train perplexity2.9542734622955322
INFO:root:current mean train loss 1375.3943838543362
INFO:root:current train perplexity2.953453540802002
INFO:root:current mean train loss 1375.9059678342776
INFO:root:current train perplexity2.9544429779052734
INFO:root:current mean train loss 1375.7846037734896
INFO:root:current train perplexity2.9559316635131836
INFO:root:current mean train loss 1376.5482512334818
INFO:root:current train perplexity2.9572389125823975
INFO:root:current mean train loss 1376.8129815956981
INFO:root:current train perplexity2.9587626457214355
INFO:root:current mean train loss 1376.762816939458
INFO:root:current train perplexity2.9599554538726807
INFO:root:current mean train loss 1376.943123734705
INFO:root:current train perplexity2.9617362022399902
INFO:root:current mean train loss 1376.9544209095109
INFO:root:current train perplexity2.9621329307556152
INFO:root:current mean train loss 1377.4083966739843
INFO:root:current train perplexity2.9625980854034424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.20s/it]
INFO:root:final mean train loss: 1376.953989218415
INFO:root:final train perplexity: 2.9622490406036377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2192.3996599346187
INFO:root:eval perplexity: 5.888987064361572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2743.4890470031305
INFO:root:eval perplexity: 9.428157806396484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [19:31:03<15:55:43, 637.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1359.0211977751358
INFO:root:current train perplexity2.9158356189727783
INFO:root:current mean train loss 1357.5451241216715
INFO:root:current train perplexity2.9207332134246826
INFO:root:current mean train loss 1358.585416545655
INFO:root:current train perplexity2.924635648727417
INFO:root:current mean train loss 1362.8590478250974
INFO:root:current train perplexity2.9244821071624756
INFO:root:current mean train loss 1363.641411559668
INFO:root:current train perplexity2.925234794616699
INFO:root:current mean train loss 1365.784327501991
INFO:root:current train perplexity2.9292819499969482
INFO:root:current mean train loss 1367.9233548060304
INFO:root:current train perplexity2.9330224990844727
INFO:root:current mean train loss 1369.031493981886
INFO:root:current train perplexity2.9377219676971436
INFO:root:current mean train loss 1368.8314303100726
INFO:root:current train perplexity2.940988063812256
INFO:root:current mean train loss 1370.23745459841
INFO:root:current train perplexity2.9421284198760986
INFO:root:current mean train loss 1369.6984914667257
INFO:root:current train perplexity2.9437789916992188
INFO:root:current mean train loss 1369.164657919095
INFO:root:current train perplexity2.944870710372925
INFO:root:current mean train loss 1370.1130696229807
INFO:root:current train perplexity2.9447920322418213
INFO:root:current mean train loss 1369.6737490334242
INFO:root:current train perplexity2.946104049682617
INFO:root:current mean train loss 1371.2808237926258
INFO:root:current train perplexity2.947749614715576
INFO:root:current mean train loss 1371.8824988827728
INFO:root:current train perplexity2.948864459991455
INFO:root:current mean train loss 1372.5041926654246
INFO:root:current train perplexity2.9503042697906494
INFO:root:current mean train loss 1373.3514291128242
INFO:root:current train perplexity2.9518444538116455
INFO:root:current mean train loss 1373.4499599238395
INFO:root:current train perplexity2.9531090259552
INFO:root:current mean train loss 1373.6456299448087
INFO:root:current train perplexity2.9536664485931396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.77s/it]
INFO:root:final mean train loss: 1373.5144817373455
INFO:root:final train perplexity: 2.9542243480682373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2194.9893344311004
INFO:root:eval perplexity: 5.901334762573242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2747.474348785184
INFO:root:eval perplexity: 9.45893383026123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [19:41:43<15:46:36, 638.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1359.933640590934
INFO:root:current train perplexity2.92790150642395
INFO:root:current mean train loss 1359.8107299804688
INFO:root:current train perplexity2.9243037700653076
INFO:root:current mean train loss 1361.3187413782507
INFO:root:current train perplexity2.928698778152466
INFO:root:current mean train loss 1360.8932387594114
INFO:root:current train perplexity2.926753044128418
INFO:root:current mean train loss 1363.1706035598315
INFO:root:current train perplexity2.9246044158935547
INFO:root:current mean train loss 1363.8093936646758
INFO:root:current train perplexity2.9271481037139893
INFO:root:current mean train loss 1365.2535145929187
INFO:root:current train perplexity2.928931474685669
INFO:root:current mean train loss 1364.2991517821645
INFO:root:current train perplexity2.9319233894348145
INFO:root:current mean train loss 1364.9580943363783
INFO:root:current train perplexity2.932040214538574
INFO:root:current mean train loss 1365.7587519214312
INFO:root:current train perplexity2.9338715076446533
INFO:root:current mean train loss 1366.431212030063
INFO:root:current train perplexity2.935140371322632
INFO:root:current mean train loss 1366.7645979008023
INFO:root:current train perplexity2.936858892440796
INFO:root:current mean train loss 1367.6875349314735
INFO:root:current train perplexity2.939085006713867
INFO:root:current mean train loss 1367.2441310249537
INFO:root:current train perplexity2.939988374710083
INFO:root:current mean train loss 1368.5366429448288
INFO:root:current train perplexity2.941324234008789
INFO:root:current mean train loss 1368.672854564229
INFO:root:current train perplexity2.94353985786438
INFO:root:current mean train loss 1369.337931749518
INFO:root:current train perplexity2.945521593093872
INFO:root:current mean train loss 1370.0027183541258
INFO:root:current train perplexity2.9460608959198
INFO:root:current mean train loss 1370.2329097031788
INFO:root:current train perplexity2.9466917514801025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.33s/it]
INFO:root:final mean train loss: 1370.511459619904
INFO:root:final train perplexity: 2.9472360610961914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2198.8028040676254
INFO:root:eval perplexity: 5.919562816619873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2753.3249204378603
INFO:root:eval perplexity: 9.504303932189941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [19:52:16<15:33:40, 636.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1352.3908284505208
INFO:root:current train perplexity2.8924012184143066
INFO:root:current mean train loss 1360.7834804497877
INFO:root:current train perplexity2.9202802181243896
INFO:root:current mean train loss 1361.307718211207
INFO:root:current train perplexity2.9342973232269287
INFO:root:current mean train loss 1356.801130137428
INFO:root:current train perplexity2.9316294193267822
INFO:root:current mean train loss 1358.0538442152606
INFO:root:current train perplexity2.9342284202575684
INFO:root:current mean train loss 1358.6474026932158
INFO:root:current train perplexity2.932485818862915
INFO:root:current mean train loss 1360.5616922710665
INFO:root:current train perplexity2.9331023693084717
INFO:root:current mean train loss 1359.978751257168
INFO:root:current train perplexity2.933351516723633
INFO:root:current mean train loss 1360.2470584551097
INFO:root:current train perplexity2.9327645301818848
INFO:root:current mean train loss 1361.0733249195391
INFO:root:current train perplexity2.934804916381836
INFO:root:current mean train loss 1362.0280455021655
INFO:root:current train perplexity2.9361202716827393
INFO:root:current mean train loss 1362.6882750302796
INFO:root:current train perplexity2.9347968101501465
INFO:root:current mean train loss 1363.788734239434
INFO:root:current train perplexity2.9350175857543945
INFO:root:current mean train loss 1363.6087457242602
INFO:root:current train perplexity2.9340670108795166
INFO:root:current mean train loss 1364.4490000153132
INFO:root:current train perplexity2.9341962337493896
INFO:root:current mean train loss 1364.6999383394668
INFO:root:current train perplexity2.934746742248535
INFO:root:current mean train loss 1365.8953358631766
INFO:root:current train perplexity2.93642520904541
INFO:root:current mean train loss 1366.997163782663
INFO:root:current train perplexity2.9359865188598633
INFO:root:current mean train loss 1367.332502672954
INFO:root:current train perplexity2.9372661113739014
INFO:root:current mean train loss 1367.8658832143121
INFO:root:current train perplexity2.9385013580322266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.76s/it]
INFO:root:final mean train loss: 1367.5056212978777
INFO:root:final train perplexity: 2.9402575492858887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2200.2790756766676
INFO:root:eval perplexity: 5.926634311676025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2755.462198893229
INFO:root:eval perplexity: 9.520930290222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [20:03:00<15:26:23, 638.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1326.056622314453
INFO:root:current train perplexity2.8966879844665527
INFO:root:current mean train loss 1356.7408020019532
INFO:root:current train perplexity2.9189085960388184
INFO:root:current mean train loss 1354.2495888449928
INFO:root:current train perplexity2.9132962226867676
INFO:root:current mean train loss 1356.977185821533
INFO:root:current train perplexity2.914564371109009
INFO:root:current mean train loss 1355.2566970098587
INFO:root:current train perplexity2.917738914489746
INFO:root:current mean train loss 1355.7791356013372
INFO:root:current train perplexity2.9185631275177
INFO:root:current mean train loss 1357.0064618510585
INFO:root:current train perplexity2.917436122894287
INFO:root:current mean train loss 1356.5218575371637
INFO:root:current train perplexity2.919426202774048
INFO:root:current mean train loss 1356.094661954554
INFO:root:current train perplexity2.9198081493377686
INFO:root:current mean train loss 1356.8150235383407
INFO:root:current train perplexity2.920247793197632
INFO:root:current mean train loss 1359.0232865875842
INFO:root:current train perplexity2.9213602542877197
INFO:root:current mean train loss 1359.7058231898716
INFO:root:current train perplexity2.9225330352783203
INFO:root:current mean train loss 1360.8986228067367
INFO:root:current train perplexity2.9240808486938477
INFO:root:current mean train loss 1361.394936209014
INFO:root:current train perplexity2.925811529159546
INFO:root:current mean train loss 1362.114269331811
INFO:root:current train perplexity2.926053047180176
INFO:root:current mean train loss 1362.4455504568
INFO:root:current train perplexity2.9281418323516846
INFO:root:current mean train loss 1363.0452482247058
INFO:root:current train perplexity2.930001735687256
INFO:root:current mean train loss 1363.431944381359
INFO:root:current train perplexity2.929840087890625
INFO:root:current mean train loss 1363.6560344318766
INFO:root:current train perplexity2.9311304092407227
INFO:root:current mean train loss 1364.4653774261474
INFO:root:current train perplexity2.9315896034240723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.14s/it]
INFO:root:final mean train loss: 1363.924150998822
INFO:root:final train perplexity: 2.931964635848999
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2206.4597947140956
INFO:root:eval perplexity: 5.956333160400391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2763.638879221382
INFO:root:eval perplexity: 9.584814071655273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [20:13:33<15:13:07, 637.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1346.1864937447212
INFO:root:current train perplexity2.876685619354248
INFO:root:current mean train loss 1344.13214512289
INFO:root:current train perplexity2.907294273376465
INFO:root:current mean train loss 1344.7090245500397
INFO:root:current train perplexity2.8968427181243896
INFO:root:current mean train loss 1351.8466293380238
INFO:root:current train perplexity2.9083008766174316
INFO:root:current mean train loss 1352.7883141559103
INFO:root:current train perplexity2.916226387023926
INFO:root:current mean train loss 1354.9838014741183
INFO:root:current train perplexity2.9199106693267822
INFO:root:current mean train loss 1355.8163332377724
INFO:root:current train perplexity2.921621561050415
INFO:root:current mean train loss 1355.6757822437883
INFO:root:current train perplexity2.918760061264038
INFO:root:current mean train loss 1355.7026966600863
INFO:root:current train perplexity2.916900873184204
INFO:root:current mean train loss 1355.5402085539372
INFO:root:current train perplexity2.9167673587799072
INFO:root:current mean train loss 1356.651438404992
INFO:root:current train perplexity2.9173665046691895
INFO:root:current mean train loss 1356.5614457075912
INFO:root:current train perplexity2.917489528656006
INFO:root:current mean train loss 1357.1768663633034
INFO:root:current train perplexity2.9186272621154785
INFO:root:current mean train loss 1357.713355350423
INFO:root:current train perplexity2.9191970825195312
INFO:root:current mean train loss 1358.8685038546016
INFO:root:current train perplexity2.9207262992858887
INFO:root:current mean train loss 1358.6726671465822
INFO:root:current train perplexity2.921096086502075
INFO:root:current mean train loss 1359.2650649082973
INFO:root:current train perplexity2.9223177433013916
INFO:root:current mean train loss 1359.400747840543
INFO:root:current train perplexity2.9236340522766113
INFO:root:current mean train loss 1360.1712091619318
INFO:root:current train perplexity2.9236397743225098
INFO:root:current mean train loss 1360.6989787687146
INFO:root:current train perplexity2.9238831996917725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.50s/it]
INFO:root:final mean train loss: 1360.6107297157675
INFO:root:final train perplexity: 2.9243128299713135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2208.7422264586103
INFO:root:eval perplexity: 5.967339992523193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2764.11214279283
INFO:root:eval perplexity: 9.588523864746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [20:24:02<14:59:13, 634.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1358.425828721788
INFO:root:current train perplexity2.894664764404297
INFO:root:current mean train loss 1357.682712307224
INFO:root:current train perplexity2.889512538909912
INFO:root:current mean train loss 1354.671679399145
INFO:root:current train perplexity2.897535800933838
INFO:root:current mean train loss 1350.1284365896452
INFO:root:current train perplexity2.8978564739227295
INFO:root:current mean train loss 1349.980975314909
INFO:root:current train perplexity2.9009993076324463
INFO:root:current mean train loss 1351.4156115149763
INFO:root:current train perplexity2.9027915000915527
INFO:root:current mean train loss 1352.0345460850895
INFO:root:current train perplexity2.9045052528381348
INFO:root:current mean train loss 1352.7433818139195
INFO:root:current train perplexity2.9058704376220703
INFO:root:current mean train loss 1352.598531325472
INFO:root:current train perplexity2.9066002368927
INFO:root:current mean train loss 1352.764113196287
INFO:root:current train perplexity2.909479856491089
INFO:root:current mean train loss 1353.845686910727
INFO:root:current train perplexity2.910426139831543
INFO:root:current mean train loss 1354.869536877505
INFO:root:current train perplexity2.9109129905700684
INFO:root:current mean train loss 1354.9512565649297
INFO:root:current train perplexity2.9128785133361816
INFO:root:current mean train loss 1355.2282856387612
INFO:root:current train perplexity2.9125399589538574
INFO:root:current mean train loss 1355.2712707939306
INFO:root:current train perplexity2.9128472805023193
INFO:root:current mean train loss 1355.8792705756816
INFO:root:current train perplexity2.914008617401123
INFO:root:current mean train loss 1356.4349929828022
INFO:root:current train perplexity2.913792848587036
INFO:root:current mean train loss 1357.3080335767131
INFO:root:current train perplexity2.9151628017425537
INFO:root:current mean train loss 1357.4260373079533
INFO:root:current train perplexity2.9164161682128906
INFO:root:current mean train loss 1357.7223909938348
INFO:root:current train perplexity2.9176535606384277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.85s/it]
INFO:root:final mean train loss: 1357.6296591092646
INFO:root:final train perplexity: 2.917445421218872
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2209.445205147385
INFO:root:eval perplexity: 5.970732688903809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.38s/it]
INFO:root:eval mean loss: 2767.247211429244
INFO:root:eval perplexity: 9.613140106201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [20:34:48<14:53:12, 638.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1362.4537731761664
INFO:root:current train perplexity2.896334409713745
INFO:root:current mean train loss 1348.6858424136512
INFO:root:current train perplexity2.8901188373565674
INFO:root:current mean train loss 1351.6358894826742
INFO:root:current train perplexity2.896986961364746
INFO:root:current mean train loss 1350.0366763708726
INFO:root:current train perplexity2.8966400623321533
INFO:root:current mean train loss 1349.948908779525
INFO:root:current train perplexity2.8939733505249023
INFO:root:current mean train loss 1350.0697389191796
INFO:root:current train perplexity2.89604115486145
INFO:root:current mean train loss 1349.9088003781087
INFO:root:current train perplexity2.898705244064331
INFO:root:current mean train loss 1351.5649841546085
INFO:root:current train perplexity2.9007439613342285
INFO:root:current mean train loss 1353.628258478491
INFO:root:current train perplexity2.904111623764038
INFO:root:current mean train loss 1352.716524322541
INFO:root:current train perplexity2.903700828552246
INFO:root:current mean train loss 1352.8895097264167
INFO:root:current train perplexity2.9035801887512207
INFO:root:current mean train loss 1352.425922292812
INFO:root:current train perplexity2.905082941055298
INFO:root:current mean train loss 1351.9254621000011
INFO:root:current train perplexity2.9047982692718506
INFO:root:current mean train loss 1352.76044008351
INFO:root:current train perplexity2.906050205230713
INFO:root:current mean train loss 1353.138994850973
INFO:root:current train perplexity2.9075984954833984
INFO:root:current mean train loss 1353.0352835263666
INFO:root:current train perplexity2.9086391925811768
INFO:root:current mean train loss 1353.217493574324
INFO:root:current train perplexity2.909025192260742
INFO:root:current mean train loss 1353.8507484681588
INFO:root:current train perplexity2.909749984741211
INFO:root:current mean train loss 1354.5228091412723
INFO:root:current train perplexity2.910088062286377
INFO:root:current mean train loss 1355.2888191645065
INFO:root:current train perplexity2.911318063735962

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.77s/it]
INFO:root:final mean train loss: 1354.9996154754376
INFO:root:final train perplexity: 2.911400318145752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2213.3983656430073
INFO:root:eval perplexity: 5.989851951599121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2772.241558102006
INFO:root:eval perplexity: 9.652483940124512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [20:45:17<14:38:40, 635.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1351.0527787642045
INFO:root:current train perplexity2.885822057723999
INFO:root:current mean train loss 1353.268407943401
INFO:root:current train perplexity2.8859331607818604
INFO:root:current mean train loss 1350.4786012437607
INFO:root:current train perplexity2.8858911991119385
INFO:root:current mean train loss 1350.61903145387
INFO:root:current train perplexity2.880056858062744
INFO:root:current mean train loss 1347.798463164783
INFO:root:current train perplexity2.8823695182800293
INFO:root:current mean train loss 1348.0418344095451
INFO:root:current train perplexity2.8822619915008545
INFO:root:current mean train loss 1349.2913543346317
INFO:root:current train perplexity2.8849587440490723
INFO:root:current mean train loss 1348.2196065060377
INFO:root:current train perplexity2.8864269256591797
INFO:root:current mean train loss 1348.7099080128712
INFO:root:current train perplexity2.889056921005249
INFO:root:current mean train loss 1348.045991102211
INFO:root:current train perplexity2.890070676803589
INFO:root:current mean train loss 1349.7465430988984
INFO:root:current train perplexity2.8919565677642822
INFO:root:current mean train loss 1349.239032064624
INFO:root:current train perplexity2.8921561241149902
INFO:root:current mean train loss 1349.9441260106814
INFO:root:current train perplexity2.8948891162872314
INFO:root:current mean train loss 1350.5880736425217
INFO:root:current train perplexity2.8955209255218506
INFO:root:current mean train loss 1350.9340863791845
INFO:root:current train perplexity2.8957390785217285
INFO:root:current mean train loss 1350.88716644364
INFO:root:current train perplexity2.898420810699463
INFO:root:current mean train loss 1352.069204610671
INFO:root:current train perplexity2.900629997253418
INFO:root:current mean train loss 1352.4209622035357
INFO:root:current train perplexity2.9018020629882812
INFO:root:current mean train loss 1352.2592601452843
INFO:root:current train perplexity2.9025213718414307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.29s/it]
INFO:root:final mean train loss: 1351.8527106257682
INFO:root:final train perplexity: 2.904184103012085
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 2215.9344240012742
INFO:root:eval perplexity: 6.002150535583496
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2775.391721468445
INFO:root:eval perplexity: 9.677383422851562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [20:56:05<14:33:28, 639.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1300.139990234375
INFO:root:current train perplexity2.807192087173462
INFO:root:current mean train loss 1338.1229875837053
INFO:root:current train perplexity2.869523763656616
INFO:root:current mean train loss 1333.9655916539634
INFO:root:current train perplexity2.866852283477783
INFO:root:current mean train loss 1338.865651415215
INFO:root:current train perplexity2.868220329284668
INFO:root:current mean train loss 1340.3684648678627
INFO:root:current train perplexity2.871121644973755
INFO:root:current mean train loss 1342.7678490969215
INFO:root:current train perplexity2.873167037963867
INFO:root:current mean train loss 1343.3943264543518
INFO:root:current train perplexity2.8795578479766846
INFO:root:current mean train loss 1343.5519318276263
INFO:root:current train perplexity2.8848750591278076
INFO:root:current mean train loss 1343.9596541694973
INFO:root:current train perplexity2.8870773315429688
INFO:root:current mean train loss 1345.3402960171356
INFO:root:current train perplexity2.8893535137176514
INFO:root:current mean train loss 1344.37827816484
INFO:root:current train perplexity2.8888049125671387
INFO:root:current mean train loss 1346.0452836671027
INFO:root:current train perplexity2.8916566371917725
INFO:root:current mean train loss 1346.3012666947614
INFO:root:current train perplexity2.8923423290252686
INFO:root:current mean train loss 1347.2032723262391
INFO:root:current train perplexity2.893599033355713
INFO:root:current mean train loss 1347.6305788304883
INFO:root:current train perplexity2.8944334983825684
INFO:root:current mean train loss 1348.6230774534106
INFO:root:current train perplexity2.8960580825805664
INFO:root:current mean train loss 1348.640483611395
INFO:root:current train perplexity2.8966710567474365
INFO:root:current mean train loss 1348.2770963875778
INFO:root:current train perplexity2.895663261413574
INFO:root:current mean train loss 1348.8459955527183
INFO:root:current train perplexity2.895641803741455
INFO:root:current mean train loss 1348.9331118766404
INFO:root:current train perplexity2.89640474319458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it]
INFO:root:final mean train loss: 1348.7206933679931
INFO:root:final train perplexity: 2.8970186710357666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2217.6299884336213
INFO:root:eval perplexity: 6.010385513305664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2779.5060844691934
INFO:root:eval perplexity: 9.710003852844238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [21:06:44<14:22:43, 639.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1340.7910711115057
INFO:root:current train perplexity2.862980842590332
INFO:root:current mean train loss 1333.3923279809171
INFO:root:current train perplexity2.8708410263061523
INFO:root:current mean train loss 1334.902539502393
INFO:root:current train perplexity2.8633289337158203
INFO:root:current mean train loss 1335.6190280321962
INFO:root:current train perplexity2.8659775257110596
INFO:root:current mean train loss 1336.3200536068016
INFO:root:current train perplexity2.8660130500793457
INFO:root:current mean train loss 1337.2694218076508
INFO:root:current train perplexity2.8697896003723145
INFO:root:current mean train loss 1337.3196126563755
INFO:root:current train perplexity2.8715145587921143
INFO:root:current mean train loss 1338.5161665390733
INFO:root:current train perplexity2.874290704727173
INFO:root:current mean train loss 1339.972556900804
INFO:root:current train perplexity2.8738386631011963
INFO:root:current mean train loss 1341.5465531421587
INFO:root:current train perplexity2.8777153491973877
INFO:root:current mean train loss 1341.5177369836258
INFO:root:current train perplexity2.8776066303253174
INFO:root:current mean train loss 1342.206228654015
INFO:root:current train perplexity2.879046678543091
INFO:root:current mean train loss 1342.367769182021
INFO:root:current train perplexity2.881340265274048
INFO:root:current mean train loss 1341.9363402396937
INFO:root:current train perplexity2.8822455406188965
INFO:root:current mean train loss 1342.600165301402
INFO:root:current train perplexity2.884976863861084
INFO:root:current mean train loss 1344.0488022191453
INFO:root:current train perplexity2.8869104385375977
INFO:root:current mean train loss 1344.6501631166432
INFO:root:current train perplexity2.8878777027130127
INFO:root:current mean train loss 1344.8608426792973
INFO:root:current train perplexity2.889172315597534
INFO:root:current mean train loss 1345.820242353119
INFO:root:current train perplexity2.8900084495544434
INFO:root:current mean train loss 1345.9439498472661
INFO:root:current train perplexity2.8903942108154297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.22s/it]
INFO:root:final mean train loss: 1346.0462375627403
INFO:root:final train perplexity: 2.8909149169921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it]
INFO:root:eval mean loss: 2222.6076603882702
INFO:root:eval perplexity: 6.03463077545166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 2783.194980486065
INFO:root:eval perplexity: 9.739337921142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [21:17:25<14:12:43, 639.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1333.3250043820112
INFO:root:current train perplexity2.8443219661712646
INFO:root:current mean train loss 1333.7966203209307
INFO:root:current train perplexity2.851590633392334
INFO:root:current mean train loss 1332.9061141393174
INFO:root:current train perplexity2.8598077297210693
INFO:root:current mean train loss 1329.9578428915468
INFO:root:current train perplexity2.8666534423828125
INFO:root:current mean train loss 1331.0753393499074
INFO:root:current train perplexity2.863346576690674
INFO:root:current mean train loss 1334.5967829603433
INFO:root:current train perplexity2.8680596351623535
INFO:root:current mean train loss 1334.8037816198405
INFO:root:current train perplexity2.8658387660980225
INFO:root:current mean train loss 1335.6461310483444
INFO:root:current train perplexity2.870875597000122
INFO:root:current mean train loss 1337.2634331176903
INFO:root:current train perplexity2.869957208633423
INFO:root:current mean train loss 1337.3900778285993
INFO:root:current train perplexity2.8699827194213867
INFO:root:current mean train loss 1338.2221512854157
INFO:root:current train perplexity2.8720486164093018
INFO:root:current mean train loss 1338.924990418713
INFO:root:current train perplexity2.872950792312622
INFO:root:current mean train loss 1338.937317731979
INFO:root:current train perplexity2.8733890056610107
INFO:root:current mean train loss 1339.7818473149273
INFO:root:current train perplexity2.8749401569366455
INFO:root:current mean train loss 1339.9916074327332
INFO:root:current train perplexity2.8765482902526855
INFO:root:current mean train loss 1341.6080645089648
INFO:root:current train perplexity2.8790457248687744
INFO:root:current mean train loss 1342.178406618222
INFO:root:current train perplexity2.8806142807006836
INFO:root:current mean train loss 1342.6487044542257
INFO:root:current train perplexity2.881406307220459
INFO:root:current mean train loss 1342.9911124979822
INFO:root:current train perplexity2.883155107498169
INFO:root:current mean train loss 1343.3912330222167
INFO:root:current train perplexity2.884005546569824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.15s/it]
INFO:root:final mean train loss: 1343.1265693699177
INFO:root:final train perplexity: 2.884265899658203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2224.5543580833055
INFO:root:eval perplexity: 6.044138431549072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2785.7774982858214
INFO:root:eval perplexity: 9.759930610656738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [21:27:57<13:59:24, 637.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1337.7252088274274
INFO:root:current train perplexity2.8695976734161377
INFO:root:current mean train loss 1335.7979572002705
INFO:root:current train perplexity2.866969108581543
INFO:root:current mean train loss 1336.3523921966553
INFO:root:current train perplexity2.8663129806518555
INFO:root:current mean train loss 1335.2331587544988
INFO:root:current train perplexity2.8676679134368896
INFO:root:current mean train loss 1338.1356217233758
INFO:root:current train perplexity2.8659169673919678
INFO:root:current mean train loss 1339.8139646241991
INFO:root:current train perplexity2.866083860397339
INFO:root:current mean train loss 1340.4029827583126
INFO:root:current train perplexity2.8659942150115967
INFO:root:current mean train loss 1338.3668077256943
INFO:root:current train perplexity2.8669240474700928
INFO:root:current mean train loss 1338.889801738418
INFO:root:current train perplexity2.8707876205444336
INFO:root:current mean train loss 1339.1159222335496
INFO:root:current train perplexity2.8741295337677
INFO:root:current mean train loss 1338.8077518578732
INFO:root:current train perplexity2.8737802505493164
INFO:root:current mean train loss 1338.2453164493336
INFO:root:current train perplexity2.874502420425415
INFO:root:current mean train loss 1337.7763491102085
INFO:root:current train perplexity2.8743510246276855
INFO:root:current mean train loss 1338.2907253029073
INFO:root:current train perplexity2.8740642070770264
INFO:root:current mean train loss 1338.2192177405725
INFO:root:current train perplexity2.8746337890625
INFO:root:current mean train loss 1339.2019402275969
INFO:root:current train perplexity2.8754589557647705
INFO:root:current mean train loss 1339.563365770423
INFO:root:current train perplexity2.8761134147644043
INFO:root:current mean train loss 1339.9885887893295
INFO:root:current train perplexity2.8774046897888184
INFO:root:current mean train loss 1340.6974542552027
INFO:root:current train perplexity2.877790927886963
INFO:root:current mean train loss 1340.997786071403
INFO:root:current train perplexity2.8787152767181396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.19s/it]
INFO:root:final mean train loss: 1340.7871767506717
INFO:root:final train perplexity: 2.8789491653442383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 2225.860212610123
INFO:root:eval perplexity: 6.050525665283203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2788.8126510728334
INFO:root:eval perplexity: 9.784186363220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [21:38:35<13:48:38, 637.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1325.4157263350814
INFO:root:current train perplexity2.8615975379943848
INFO:root:current mean train loss 1325.4690040191474
INFO:root:current train perplexity2.8518810272216797
INFO:root:current mean train loss 1329.630110855941
INFO:root:current train perplexity2.852654218673706
INFO:root:current mean train loss 1331.697105591802
INFO:root:current train perplexity2.855323076248169
INFO:root:current mean train loss 1330.2713772731402
INFO:root:current train perplexity2.8584957122802734
INFO:root:current mean train loss 1330.747692168071
INFO:root:current train perplexity2.8603408336639404
INFO:root:current mean train loss 1331.4213660411635
INFO:root:current train perplexity2.8622491359710693
INFO:root:current mean train loss 1332.8368292607433
INFO:root:current train perplexity2.8628013134002686
INFO:root:current mean train loss 1334.497220907834
INFO:root:current train perplexity2.8633005619049072
INFO:root:current mean train loss 1335.8942823419836
INFO:root:current train perplexity2.8639726638793945
INFO:root:current mean train loss 1336.5860724258068
INFO:root:current train perplexity2.8650174140930176
INFO:root:current mean train loss 1337.3957354065099
INFO:root:current train perplexity2.8672635555267334
INFO:root:current mean train loss 1337.7167211204462
INFO:root:current train perplexity2.8664326667785645
INFO:root:current mean train loss 1337.3532401888542
INFO:root:current train perplexity2.8674464225769043
INFO:root:current mean train loss 1336.9569055333238
INFO:root:current train perplexity2.8665401935577393
INFO:root:current mean train loss 1337.2281102242928
INFO:root:current train perplexity2.867377519607544
INFO:root:current mean train loss 1337.8591591697643
INFO:root:current train perplexity2.867950201034546
INFO:root:current mean train loss 1338.1061000318361
INFO:root:current train perplexity2.8686532974243164
INFO:root:current mean train loss 1337.5910684287198
INFO:root:current train perplexity2.869513750076294
INFO:root:current mean train loss 1337.6583555118118
INFO:root:current train perplexity2.8707337379455566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.11s/it]
INFO:root:final mean train loss: 1337.2054290694537
INFO:root:final train perplexity: 2.87082839012146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2228.2508596866687
INFO:root:eval perplexity: 6.062234878540039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2791.6425478238584
INFO:root:eval perplexity: 9.806859016418457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [21:49:05<13:35:16, 635.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1324.1362847222222
INFO:root:current train perplexity2.856525421142578
INFO:root:current mean train loss 1322.095894582648
INFO:root:current train perplexity2.845465898513794
INFO:root:current mean train loss 1328.304052734375
INFO:root:current train perplexity2.852820873260498
INFO:root:current mean train loss 1331.2572537935698
INFO:root:current train perplexity2.85662579536438
INFO:root:current mean train loss 1331.2757543447067
INFO:root:current train perplexity2.857482433319092
INFO:root:current mean train loss 1330.7811631024895
INFO:root:current train perplexity2.8558924198150635
INFO:root:current mean train loss 1330.2247176460598
INFO:root:current train perplexity2.856994152069092
INFO:root:current mean train loss 1330.9653633986848
INFO:root:current train perplexity2.857710838317871
INFO:root:current mean train loss 1331.1180263562148
INFO:root:current train perplexity2.857781410217285
INFO:root:current mean train loss 1331.1285071170691
INFO:root:current train perplexity2.859558582305908
INFO:root:current mean train loss 1331.9254545719252
INFO:root:current train perplexity2.860283136367798
INFO:root:current mean train loss 1332.2336667870272
INFO:root:current train perplexity2.8625338077545166
INFO:root:current mean train loss 1332.000586505269
INFO:root:current train perplexity2.8627872467041016
INFO:root:current mean train loss 1332.6176627838354
INFO:root:current train perplexity2.8630456924438477
INFO:root:current mean train loss 1333.6593269092125
INFO:root:current train perplexity2.863416910171509
INFO:root:current mean train loss 1333.2330539535426
INFO:root:current train perplexity2.8622584342956543
INFO:root:current mean train loss 1333.2380010661288
INFO:root:current train perplexity2.862549304962158
INFO:root:current mean train loss 1333.8093578146822
INFO:root:current train perplexity2.8625662326812744
INFO:root:current mean train loss 1334.3267455408813
INFO:root:current train perplexity2.864131450653076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.87s/it]
INFO:root:final mean train loss: 1334.6385517437773
INFO:root:final train perplexity: 2.865022897720337
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.43s/it]
INFO:root:eval mean loss: 2233.105788210605
INFO:root:eval perplexity: 6.086084842681885
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2797.143448633505
INFO:root:eval perplexity: 9.851076126098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [21:59:53<13:29:32, 639.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1328.1555873325892
INFO:root:current train perplexity2.7703418731689453
INFO:root:current mean train loss 1325.783174603899
INFO:root:current train perplexity2.8265175819396973
INFO:root:current mean train loss 1331.7325280230978
INFO:root:current train perplexity2.843677043914795
INFO:root:current mean train loss 1329.0037988917447
INFO:root:current train perplexity2.8447206020355225
INFO:root:current mean train loss 1324.9824293731765
INFO:root:current train perplexity2.8460323810577393
INFO:root:current mean train loss 1327.135130872858
INFO:root:current train perplexity2.849252462387085
INFO:root:current mean train loss 1327.2578967627035
INFO:root:current train perplexity2.847731590270996
INFO:root:current mean train loss 1328.6598730883134
INFO:root:current train perplexity2.8480985164642334
INFO:root:current mean train loss 1328.4690215194682
INFO:root:current train perplexity2.847538709640503
INFO:root:current mean train loss 1329.0152571740198
INFO:root:current train perplexity2.849519729614258
INFO:root:current mean train loss 1328.1719592491233
INFO:root:current train perplexity2.8499882221221924
INFO:root:current mean train loss 1328.8208775300643
INFO:root:current train perplexity2.852285146713257
INFO:root:current mean train loss 1328.7615161759852
INFO:root:current train perplexity2.8512582778930664
INFO:root:current mean train loss 1328.843500815919
INFO:root:current train perplexity2.85144305229187
INFO:root:current mean train loss 1329.1546786158494
INFO:root:current train perplexity2.8525772094726562
INFO:root:current mean train loss 1330.4948461541453
INFO:root:current train perplexity2.8541548252105713
INFO:root:current mean train loss 1330.5141545350907
INFO:root:current train perplexity2.8554279804229736
INFO:root:current mean train loss 1330.7197704706264
INFO:root:current train perplexity2.8557987213134766
INFO:root:current mean train loss 1331.0685105611424
INFO:root:current train perplexity2.8569223880767822
INFO:root:current mean train loss 1331.6797083678143
INFO:root:current train perplexity2.858306407928467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.26s/it]
INFO:root:final mean train loss: 1331.8342316858827
INFO:root:final train perplexity: 2.8586935997009277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2233.480521993434
INFO:root:eval perplexity: 6.087928771972656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2798.7189365684562
INFO:root:eval perplexity: 9.863779067993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [22:10:20<13:14:20, 635.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1309.8892059326172
INFO:root:current train perplexity2.82157826423645
INFO:root:current mean train loss 1319.2933704007057
INFO:root:current train perplexity2.8352279663085938
INFO:root:current mean train loss 1320.9947793143135
INFO:root:current train perplexity2.826810121536255
INFO:root:current mean train loss 1323.654214364511
INFO:root:current train perplexity2.836437940597534
INFO:root:current mean train loss 1326.1264677227668
INFO:root:current train perplexity2.838148355484009
INFO:root:current mean train loss 1324.6053713733004
INFO:root:current train perplexity2.83670711517334
INFO:root:current mean train loss 1324.9542899498572
INFO:root:current train perplexity2.8399975299835205
INFO:root:current mean train loss 1325.2369523022057
INFO:root:current train perplexity2.840972900390625
INFO:root:current mean train loss 1324.4800075790258
INFO:root:current train perplexity2.843693256378174
INFO:root:current mean train loss 1323.9150769782789
INFO:root:current train perplexity2.8445022106170654
INFO:root:current mean train loss 1324.7174080610275
INFO:root:current train perplexity2.846078872680664
INFO:root:current mean train loss 1325.1368624324052
INFO:root:current train perplexity2.8467137813568115
INFO:root:current mean train loss 1326.7846525104997
INFO:root:current train perplexity2.848125457763672
INFO:root:current mean train loss 1326.9404895240807
INFO:root:current train perplexity2.84775710105896
INFO:root:current mean train loss 1327.4495153534278
INFO:root:current train perplexity2.849454164505005
INFO:root:current mean train loss 1328.049640485308
INFO:root:current train perplexity2.8503901958465576
INFO:root:current mean train loss 1328.3361993047404
INFO:root:current train perplexity2.850051164627075
INFO:root:current mean train loss 1328.605406157102
INFO:root:current train perplexity2.850754737854004
INFO:root:current mean train loss 1328.9892120361328
INFO:root:current train perplexity2.8515565395355225
INFO:root:current mean train loss 1329.7301769613475
INFO:root:current train perplexity2.8528029918670654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.36s/it]
INFO:root:final mean train loss: 1329.587488433176
INFO:root:final train perplexity: 2.8536324501037598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2235.678845994016
INFO:root:eval perplexity: 6.098761081695557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2801.579487685616
INFO:root:eval perplexity: 9.886883735656738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [22:20:59<13:05:05, 636.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1315.5945598323171
INFO:root:current train perplexity2.8277876377105713
INFO:root:current mean train loss 1321.0114183358266
INFO:root:current train perplexity2.828488826751709
INFO:root:current mean train loss 1321.2330236157936
INFO:root:current train perplexity2.830085515975952
INFO:root:current mean train loss 1322.4339270270116
INFO:root:current train perplexity2.831960678100586
INFO:root:current mean train loss 1325.4006967695932
INFO:root:current train perplexity2.8341867923736572
INFO:root:current mean train loss 1324.7737705421096
INFO:root:current train perplexity2.830850124359131
INFO:root:current mean train loss 1324.4351439096627
INFO:root:current train perplexity2.8298823833465576
INFO:root:current mean train loss 1322.5862271081098
INFO:root:current train perplexity2.827880620956421
INFO:root:current mean train loss 1322.3093409770734
INFO:root:current train perplexity2.8280138969421387
INFO:root:current mean train loss 1322.5890537306555
INFO:root:current train perplexity2.8298556804656982
INFO:root:current mean train loss 1322.8622376133226
INFO:root:current train perplexity2.831928253173828
INFO:root:current mean train loss 1323.431787087978
INFO:root:current train perplexity2.833993911743164
INFO:root:current mean train loss 1323.768531670213
INFO:root:current train perplexity2.836456775665283
INFO:root:current mean train loss 1324.4892470710408
INFO:root:current train perplexity2.838179588317871
INFO:root:current mean train loss 1324.935521376621
INFO:root:current train perplexity2.8389806747436523
INFO:root:current mean train loss 1325.5536489121562
INFO:root:current train perplexity2.8407373428344727
INFO:root:current mean train loss 1325.832709963913
INFO:root:current train perplexity2.843165159225464
INFO:root:current mean train loss 1326.3981693099108
INFO:root:current train perplexity2.844149589538574
INFO:root:current mean train loss 1326.666769264963
INFO:root:current train perplexity2.845271348953247
INFO:root:current mean train loss 1326.8639961883373
INFO:root:current train perplexity2.8460371494293213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.54s/it]
INFO:root:final mean train loss: 1326.2430279260925
INFO:root:final train perplexity: 2.8461153507232666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2239.26077854887
INFO:root:eval perplexity: 6.116455078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2805.398089036874
INFO:root:eval perplexity: 9.917804718017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [22:31:28<12:51:43, 634.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1301.5137118635507
INFO:root:current train perplexity2.8091354370117188
INFO:root:current mean train loss 1306.3927056034909
INFO:root:current train perplexity2.822380304336548
INFO:root:current mean train loss 1311.2895422647166
INFO:root:current train perplexity2.8284366130828857
INFO:root:current mean train loss 1313.615259607411
INFO:root:current train perplexity2.8298275470733643
INFO:root:current mean train loss 1315.345187391256
INFO:root:current train perplexity2.8287484645843506
INFO:root:current mean train loss 1317.2337893687695
INFO:root:current train perplexity2.82827091217041
INFO:root:current mean train loss 1317.681470876769
INFO:root:current train perplexity2.828641891479492
INFO:root:current mean train loss 1318.3385362448983
INFO:root:current train perplexity2.8297929763793945
INFO:root:current mean train loss 1318.7022888610413
INFO:root:current train perplexity2.8279452323913574
INFO:root:current mean train loss 1319.1668024560852
INFO:root:current train perplexity2.829145669937134
INFO:root:current mean train loss 1320.4893427309783
INFO:root:current train perplexity2.830518960952759
INFO:root:current mean train loss 1320.3955368015638
INFO:root:current train perplexity2.8313822746276855
INFO:root:current mean train loss 1320.513983843247
INFO:root:current train perplexity2.8320727348327637
INFO:root:current mean train loss 1321.0614396602311
INFO:root:current train perplexity2.8333470821380615
INFO:root:current mean train loss 1321.5016743224344
INFO:root:current train perplexity2.8342180252075195
INFO:root:current mean train loss 1322.423781819766
INFO:root:current train perplexity2.8348751068115234
INFO:root:current mean train loss 1322.960308815803
INFO:root:current train perplexity2.8364381790161133
INFO:root:current mean train loss 1323.7368634151246
INFO:root:current train perplexity2.8378639221191406
INFO:root:current mean train loss 1324.0735293615237
INFO:root:current train perplexity2.8387269973754883
INFO:root:current mean train loss 1324.0674712168427
INFO:root:current train perplexity2.8398828506469727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.42s/it]
INFO:root:final mean train loss: 1323.8331724196687
INFO:root:final train perplexity: 2.8407111167907715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 2242.3570530668217
INFO:root:eval perplexity: 6.131789684295654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2810.4664904005986
INFO:root:eval perplexity: 9.959000587463379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [22:42:02<12:41:14, 634.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1311.202023111979
INFO:root:current train perplexity2.8224828243255615
INFO:root:current mean train loss 1313.2289662388393
INFO:root:current train perplexity2.8097615242004395
INFO:root:current mean train loss 1315.303730024858
INFO:root:current train perplexity2.8211007118225098
INFO:root:current mean train loss 1315.1240875651042
INFO:root:current train perplexity2.8205714225769043
INFO:root:current mean train loss 1313.1015141858552
INFO:root:current train perplexity2.8194925785064697
INFO:root:current mean train loss 1314.3860147758153
INFO:root:current train perplexity2.8217945098876953
INFO:root:current mean train loss 1314.566103515625
INFO:root:current train perplexity2.8212146759033203
INFO:root:current mean train loss 1315.9135321635586
INFO:root:current train perplexity2.8228366374969482
INFO:root:current mean train loss 1317.7101731305804
INFO:root:current train perplexity2.8254170417785645
INFO:root:current mean train loss 1317.8465443459536
INFO:root:current train perplexity2.8273324966430664
INFO:root:current mean train loss 1318.7806952897893
INFO:root:current train perplexity2.828310489654541
INFO:root:current mean train loss 1319.0172658327792
INFO:root:current train perplexity2.828291177749634
INFO:root:current mean train loss 1318.9966388059129
INFO:root:current train perplexity2.8291738033294678
INFO:root:current mean train loss 1319.3914860617897
INFO:root:current train perplexity2.8311400413513184
INFO:root:current mean train loss 1320.4306119239936
INFO:root:current train perplexity2.832191228866577
INFO:root:current mean train loss 1320.5086645120289
INFO:root:current train perplexity2.8339688777923584
INFO:root:current mean train loss 1320.6851279734142
INFO:root:current train perplexity2.8344616889953613
INFO:root:current mean train loss 1321.3133427321743
INFO:root:current train perplexity2.834832191467285
INFO:root:current mean train loss 1321.8466518229166
INFO:root:current train perplexity2.835315465927124
INFO:root:current mean train loss 1321.5279956981803
INFO:root:current train perplexity2.8351686000823975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.74s/it]
INFO:root:final mean train loss: 1321.3453804666324
INFO:root:final train perplexity: 2.8351430892944336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it]
INFO:root:eval mean loss: 2246.0207277122117
INFO:root:eval perplexity: 6.149984836578369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2815.793128913176
INFO:root:eval perplexity: 10.00247573852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [22:52:45<12:33:41, 636.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1309.5712134319804
INFO:root:current train perplexity2.790992498397827
INFO:root:current mean train loss 1309.3516947428386
INFO:root:current train perplexity2.810919761657715
INFO:root:current mean train loss 1307.671359127515
INFO:root:current train perplexity2.8171112537384033
INFO:root:current mean train loss 1310.680787067024
INFO:root:current train perplexity2.821119785308838
INFO:root:current mean train loss 1310.47108372634
INFO:root:current train perplexity2.8175113201141357
INFO:root:current mean train loss 1311.721124597498
INFO:root:current train perplexity2.818654775619507
INFO:root:current mean train loss 1312.7547718555252
INFO:root:current train perplexity2.821596384048462
INFO:root:current mean train loss 1312.2397699837734
INFO:root:current train perplexity2.821898937225342
INFO:root:current mean train loss 1312.446142632865
INFO:root:current train perplexity2.822808265686035
INFO:root:current mean train loss 1313.4967747349892
INFO:root:current train perplexity2.8238532543182373
INFO:root:current mean train loss 1314.7509459331359
INFO:root:current train perplexity2.8266704082489014
INFO:root:current mean train loss 1314.724744451126
INFO:root:current train perplexity2.8263368606567383
INFO:root:current mean train loss 1315.517471171754
INFO:root:current train perplexity2.826486587524414
INFO:root:current mean train loss 1316.309936260355
INFO:root:current train perplexity2.8264241218566895
INFO:root:current mean train loss 1317.0162617783124
INFO:root:current train perplexity2.826585292816162
INFO:root:current mean train loss 1318.0005210224708
INFO:root:current train perplexity2.827901840209961
INFO:root:current mean train loss 1318.9003963966459
INFO:root:current train perplexity2.8277554512023926
INFO:root:current mean train loss 1318.9574965749468
INFO:root:current train perplexity2.8283708095550537
INFO:root:current mean train loss 1319.2333551451218
INFO:root:current train perplexity2.8296449184417725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.81s/it]
INFO:root:final mean train loss: 1319.0078202255795
INFO:root:final train perplexity: 2.829921245574951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2247.699260305851
INFO:root:eval perplexity: 6.158339500427246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.98s/it]
INFO:root:eval mean loss: 2816.6972080528312
INFO:root:eval perplexity: 10.009878158569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [23:03:25<12:23:55, 637.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1300.6783718532986
INFO:root:current train perplexity2.7632834911346436
INFO:root:current mean train loss 1318.6440944846618
INFO:root:current train perplexity2.8273675441741943
INFO:root:current mean train loss 1312.717983702153
INFO:root:current train perplexity2.824897527694702
INFO:root:current mean train loss 1312.4622775080907
INFO:root:current train perplexity2.8242478370666504
INFO:root:current mean train loss 1312.8563733835383
INFO:root:current train perplexity2.8201019763946533
INFO:root:current mean train loss 1313.8626982383503
INFO:root:current train perplexity2.821772336959839
INFO:root:current mean train loss 1313.351626642036
INFO:root:current train perplexity2.820167064666748
INFO:root:current mean train loss 1313.9504163820081
INFO:root:current train perplexity2.8229780197143555
INFO:root:current mean train loss 1314.0177548176277
INFO:root:current train perplexity2.8240041732788086
INFO:root:current mean train loss 1313.2933565817518
INFO:root:current train perplexity2.8233134746551514
INFO:root:current mean train loss 1313.71828543112
INFO:root:current train perplexity2.82432222366333
INFO:root:current mean train loss 1314.753335964798
INFO:root:current train perplexity2.8244545459747314
INFO:root:current mean train loss 1314.4501095906676
INFO:root:current train perplexity2.8242204189300537
INFO:root:current mean train loss 1315.3201886578495
INFO:root:current train perplexity2.82448673248291
INFO:root:current mean train loss 1315.3461967776902
INFO:root:current train perplexity2.825122833251953
INFO:root:current mean train loss 1316.404116155929
INFO:root:current train perplexity2.825491189956665
INFO:root:current mean train loss 1316.1461251438443
INFO:root:current train perplexity2.8256959915161133
INFO:root:current mean train loss 1316.720271628945
INFO:root:current train perplexity2.826171636581421
INFO:root:current mean train loss 1316.9317915765141
INFO:root:current train perplexity2.8259694576263428
INFO:root:current mean train loss 1317.3260099032339
INFO:root:current train perplexity2.825503349304199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.90s/it]
INFO:root:final mean train loss: 1317.2506370679093
INFO:root:final train perplexity: 2.8260021209716797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it]
INFO:root:eval mean loss: 2248.0392291562775
INFO:root:eval perplexity: 6.160032749176025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2817.7017320132427
INFO:root:eval perplexity: 10.01810359954834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [23:14:04<12:13:47, 638.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1278.2117262620193
INFO:root:current train perplexity2.824467420578003
INFO:root:current mean train loss 1300.1224433051216
INFO:root:current train perplexity2.7924540042877197
INFO:root:current mean train loss 1302.888539002005
INFO:root:current train perplexity2.796309471130371
INFO:root:current mean train loss 1304.8410884178488
INFO:root:current train perplexity2.799896717071533
INFO:root:current mean train loss 1306.6284165359998
INFO:root:current train perplexity2.801516532897949
INFO:root:current mean train loss 1308.4548335202294
INFO:root:current train perplexity2.8032193183898926
INFO:root:current mean train loss 1308.7051742602462
INFO:root:current train perplexity2.805009126663208
INFO:root:current mean train loss 1308.940934110279
INFO:root:current train perplexity2.8062796592712402
INFO:root:current mean train loss 1309.8456975091744
INFO:root:current train perplexity2.806950569152832
INFO:root:current mean train loss 1310.903136152428
INFO:root:current train perplexity2.8094482421875
INFO:root:current mean train loss 1311.6130156935308
INFO:root:current train perplexity2.8101301193237305
INFO:root:current mean train loss 1312.0721799806422
INFO:root:current train perplexity2.811762571334839
INFO:root:current mean train loss 1312.2306239764414
INFO:root:current train perplexity2.8118410110473633
INFO:root:current mean train loss 1312.2683017092054
INFO:root:current train perplexity2.812027931213379
INFO:root:current mean train loss 1311.8283749616496
INFO:root:current train perplexity2.81219482421875
INFO:root:current mean train loss 1312.086766874181
INFO:root:current train perplexity2.812960147857666
INFO:root:current mean train loss 1312.8831266846605
INFO:root:current train perplexity2.814875364303589
INFO:root:current mean train loss 1313.3091685271897
INFO:root:current train perplexity2.8170018196105957
INFO:root:current mean train loss 1313.7797258592252
INFO:root:current train perplexity2.816929578781128
INFO:root:current mean train loss 1313.98098244672
INFO:root:current train perplexity2.8179001808166504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.30s/it]
INFO:root:final mean train loss: 1313.9240412709692
INFO:root:final train perplexity: 2.8185977935791016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.47s/it]
INFO:root:eval mean loss: 2251.8153063185673
INFO:root:eval perplexity: 6.178874492645264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 2820.9016446593805
INFO:root:eval perplexity: 10.044356346130371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [23:25:06<12:11:19, 645.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1300.1603294195131
INFO:root:current train perplexity2.7972750663757324
INFO:root:current mean train loss 1305.0137282151443
INFO:root:current train perplexity2.798942804336548
INFO:root:current mean train loss 1304.634649080504
INFO:root:current train perplexity2.7925498485565186
INFO:root:current mean train loss 1307.0531920496994
INFO:root:current train perplexity2.795154333114624
INFO:root:current mean train loss 1306.700157286082
INFO:root:current train perplexity2.7978312969207764
INFO:root:current mean train loss 1307.5131143531307
INFO:root:current train perplexity2.798856496810913
INFO:root:current mean train loss 1307.9908650399739
INFO:root:current train perplexity2.7999143600463867
INFO:root:current mean train loss 1307.744511929046
INFO:root:current train perplexity2.800034523010254
INFO:root:current mean train loss 1307.978506791917
INFO:root:current train perplexity2.7996933460235596
INFO:root:current mean train loss 1307.3556344445917
INFO:root:current train perplexity2.801800012588501
INFO:root:current mean train loss 1307.7793091639576
INFO:root:current train perplexity2.803640842437744
INFO:root:current mean train loss 1308.335743127324
INFO:root:current train perplexity2.804961919784546
INFO:root:current mean train loss 1309.609124672384
INFO:root:current train perplexity2.806516170501709
INFO:root:current mean train loss 1309.2118917935302
INFO:root:current train perplexity2.8069326877593994
INFO:root:current mean train loss 1309.5843350204923
INFO:root:current train perplexity2.8081727027893066
INFO:root:current mean train loss 1309.9538558396287
INFO:root:current train perplexity2.8094193935394287
INFO:root:current mean train loss 1310.5791844038868
INFO:root:current train perplexity2.8098480701446533
INFO:root:current mean train loss 1310.4449605761215
INFO:root:current train perplexity2.81065034866333
INFO:root:current mean train loss 1310.8684142967054
INFO:root:current train perplexity2.810551643371582
INFO:root:current mean train loss 1311.1408499159643
INFO:root:current train perplexity2.811825752258301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.54s/it]
INFO:root:final mean train loss: 1310.9230769893707
INFO:root:final train perplexity: 2.8119351863861084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 2252.2904256184897
INFO:root:eval perplexity: 6.181248664855957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2825.6191778521165
INFO:root:eval perplexity: 10.083183288574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [23:35:48<11:59:27, 644.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1299.5023457845052
INFO:root:current train perplexity2.808725595474243
INFO:root:current mean train loss 1310.518482208252
INFO:root:current train perplexity2.7947332859039307
INFO:root:current mean train loss 1307.1704857459436
INFO:root:current train perplexity2.7894845008850098
INFO:root:current mean train loss 1307.6739247639973
INFO:root:current train perplexity2.7935404777526855
INFO:root:current mean train loss 1307.859608260445
INFO:root:current train perplexity2.7947919368743896
INFO:root:current mean train loss 1308.6037961687362
INFO:root:current train perplexity2.793041944503784
INFO:root:current mean train loss 1309.0421902743253
INFO:root:current train perplexity2.795560359954834
INFO:root:current mean train loss 1307.9546087967722
INFO:root:current train perplexity2.7981574535369873
INFO:root:current mean train loss 1308.551085006359
INFO:root:current train perplexity2.7992684841156006
INFO:root:current mean train loss 1307.7994921366374
INFO:root:current train perplexity2.800717830657959
INFO:root:current mean train loss 1307.4893163141214
INFO:root:current train perplexity2.800387382507324
INFO:root:current mean train loss 1307.954706652411
INFO:root:current train perplexity2.801987409591675
INFO:root:current mean train loss 1308.4180017864894
INFO:root:current train perplexity2.8016879558563232
INFO:root:current mean train loss 1308.6114878934973
INFO:root:current train perplexity2.802675724029541
INFO:root:current mean train loss 1309.0528826987907
INFO:root:current train perplexity2.802680730819702
INFO:root:current mean train loss 1308.9340818747496
INFO:root:current train perplexity2.80411696434021
INFO:root:current mean train loss 1308.9864622552711
INFO:root:current train perplexity2.805586338043213
INFO:root:current mean train loss 1309.555222528631
INFO:root:current train perplexity2.806619167327881
INFO:root:current mean train loss 1309.5718559019026
INFO:root:current train perplexity2.8077168464660645
INFO:root:current mean train loss 1310.0584957200654
INFO:root:current train perplexity2.8087964057922363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.85s/it]
INFO:root:final mean train loss: 1309.772621174022
INFO:root:final train perplexity: 2.80938458442688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2254.144313081782
INFO:root:eval perplexity: 6.19052267074585
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2827.1057345342974
INFO:root:eval perplexity: 10.09544849395752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [23:46:18<11:43:53, 639.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1295.099270114651
INFO:root:current train perplexity2.778658390045166
INFO:root:current mean train loss 1299.2661201778778
INFO:root:current train perplexity2.7913973331451416
INFO:root:current mean train loss 1297.6000258242611
INFO:root:current train perplexity2.78279972076416
INFO:root:current mean train loss 1298.449352800688
INFO:root:current train perplexity2.7854878902435303
INFO:root:current mean train loss 1298.138813650583
INFO:root:current train perplexity2.7854061126708984
INFO:root:current mean train loss 1298.433612155749
INFO:root:current train perplexity2.786947250366211
INFO:root:current mean train loss 1299.3226442773725
INFO:root:current train perplexity2.78806734085083
INFO:root:current mean train loss 1300.0762881324404
INFO:root:current train perplexity2.7904181480407715
INFO:root:current mean train loss 1301.544237752325
INFO:root:current train perplexity2.7916367053985596
INFO:root:current mean train loss 1301.9133826795596
INFO:root:current train perplexity2.7905197143554688
INFO:root:current mean train loss 1302.9008784528783
INFO:root:current train perplexity2.795555830001831
INFO:root:current mean train loss 1302.5272842186837
INFO:root:current train perplexity2.7957139015197754
INFO:root:current mean train loss 1302.951974461017
INFO:root:current train perplexity2.7961552143096924
INFO:root:current mean train loss 1303.5634918102078
INFO:root:current train perplexity2.797436237335205
INFO:root:current mean train loss 1304.1598814471638
INFO:root:current train perplexity2.7986388206481934
INFO:root:current mean train loss 1304.5391562394727
INFO:root:current train perplexity2.7985658645629883
INFO:root:current mean train loss 1304.9485350980174
INFO:root:current train perplexity2.7997143268585205
INFO:root:current mean train loss 1305.8794367097373
INFO:root:current train perplexity2.8006591796875
INFO:root:current mean train loss 1306.296988615789
INFO:root:current train perplexity2.8024682998657227
INFO:root:current mean train loss 1306.6957984349315
INFO:root:current train perplexity2.80197811126709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.33s/it]
INFO:root:final mean train loss: 1306.4151037911604
INFO:root:final train perplexity: 2.801955461502075
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2258.5113079530975
INFO:root:eval perplexity: 6.212426662445068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2830.541499144642
INFO:root:eval perplexity: 10.123856544494629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [23:56:58<11:33:15, 639.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1293.1675012466756
INFO:root:current train perplexity2.776506185531616
INFO:root:current mean train loss 1296.0812302422278
INFO:root:current train perplexity2.7817318439483643
INFO:root:current mean train loss 1294.640133397109
INFO:root:current train perplexity2.777174949645996
INFO:root:current mean train loss 1297.2899129644868
INFO:root:current train perplexity2.775212287902832
INFO:root:current mean train loss 1297.7104877672698
INFO:root:current train perplexity2.7793538570404053
INFO:root:current mean train loss 1299.6516464695785
INFO:root:current train perplexity2.7825734615325928
INFO:root:current mean train loss 1301.205374681984
INFO:root:current train perplexity2.786302089691162
INFO:root:current mean train loss 1301.0681668913335
INFO:root:current train perplexity2.7879600524902344
INFO:root:current mean train loss 1302.5801357465568
INFO:root:current train perplexity2.7907841205596924
INFO:root:current mean train loss 1303.0351335306761
INFO:root:current train perplexity2.7918784618377686
INFO:root:current mean train loss 1303.1805957745373
INFO:root:current train perplexity2.792320489883423
INFO:root:current mean train loss 1303.2250268063954
INFO:root:current train perplexity2.793400287628174
INFO:root:current mean train loss 1303.4777494309674
INFO:root:current train perplexity2.7935338020324707
INFO:root:current mean train loss 1304.1757232797368
INFO:root:current train perplexity2.79487943649292
INFO:root:current mean train loss 1304.1569859352776
INFO:root:current train perplexity2.7947163581848145
INFO:root:current mean train loss 1303.9184107762508
INFO:root:current train perplexity2.795314073562622
INFO:root:current mean train loss 1304.8619372515357
INFO:root:current train perplexity2.79673433303833
INFO:root:current mean train loss 1304.9086453406974
INFO:root:current train perplexity2.797497510910034
INFO:root:current mean train loss 1305.1086833756476
INFO:root:current train perplexity2.798124313354492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.41s/it]
INFO:root:final mean train loss: 1304.9953991249843
INFO:root:final train perplexity: 2.7988200187683105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2261.547993544991
INFO:root:eval perplexity: 6.227701187133789
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2834.7109747271165
INFO:root:eval perplexity: 10.15843677520752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [24:07:27<11:19:07, 636.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.4372225674715
INFO:root:current train perplexity2.810319423675537
INFO:root:current mean train loss 1293.195663314682
INFO:root:current train perplexity2.7654106616973877
INFO:root:current mean train loss 1290.1929266328495
INFO:root:current train perplexity2.773298740386963
INFO:root:current mean train loss 1294.020272307074
INFO:root:current train perplexity2.7739217281341553
INFO:root:current mean train loss 1294.6210411795735
INFO:root:current train perplexity2.773265838623047
INFO:root:current mean train loss 1295.2231672253395
INFO:root:current train perplexity2.7759904861450195
INFO:root:current mean train loss 1296.492784066208
INFO:root:current train perplexity2.780256748199463
INFO:root:current mean train loss 1296.680987523075
INFO:root:current train perplexity2.7813923358917236
INFO:root:current mean train loss 1297.8398831857853
INFO:root:current train perplexity2.784726142883301
INFO:root:current mean train loss 1298.3244789701394
INFO:root:current train perplexity2.7849576473236084
INFO:root:current mean train loss 1298.4776823834306
INFO:root:current train perplexity2.7852091789245605
INFO:root:current mean train loss 1299.368331730634
INFO:root:current train perplexity2.786015748977661
INFO:root:current mean train loss 1299.0913815738543
INFO:root:current train perplexity2.7851078510284424
INFO:root:current mean train loss 1299.8784191792108
INFO:root:current train perplexity2.786527395248413
INFO:root:current mean train loss 1300.6636154856096
INFO:root:current train perplexity2.788817882537842
INFO:root:current mean train loss 1300.742414432831
INFO:root:current train perplexity2.7898521423339844
INFO:root:current mean train loss 1300.9821287092402
INFO:root:current train perplexity2.7906737327575684
INFO:root:current mean train loss 1301.222441431934
INFO:root:current train perplexity2.7906391620635986
INFO:root:current mean train loss 1302.2613968915007
INFO:root:current train perplexity2.7918708324432373
INFO:root:current mean train loss 1302.5889458848444
INFO:root:current train perplexity2.792464256286621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.02s/it]
INFO:root:final mean train loss: 1302.0714349866935
INFO:root:final train perplexity: 2.7923731803894043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2264.963434746925
INFO:root:eval perplexity: 6.244926929473877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2839.2615213597073
INFO:root:eval perplexity: 10.196310997009277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [24:18:02<11:08:13, 636.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1287.179207938058
INFO:root:current train perplexity2.7520875930786133
INFO:root:current mean train loss 1287.7018384933472
INFO:root:current train perplexity2.7583460807800293
INFO:root:current mean train loss 1292.4099822462651
INFO:root:current train perplexity2.764274835586548
INFO:root:current mean train loss 1294.8226891494378
INFO:root:current train perplexity2.768723726272583
INFO:root:current mean train loss 1293.1101162634163
INFO:root:current train perplexity2.772585868835449
INFO:root:current mean train loss 1292.7261239254112
INFO:root:current train perplexity2.771454334259033
INFO:root:current mean train loss 1292.2306077313272
INFO:root:current train perplexity2.771609306335449
INFO:root:current mean train loss 1292.318110036326
INFO:root:current train perplexity2.7727880477905273
INFO:root:current mean train loss 1293.9330947065123
INFO:root:current train perplexity2.775970697402954
INFO:root:current mean train loss 1294.4203633275524
INFO:root:current train perplexity2.77551007270813
INFO:root:current mean train loss 1294.9345739936086
INFO:root:current train perplexity2.77681040763855
INFO:root:current mean train loss 1295.6193664767218
INFO:root:current train perplexity2.780449390411377
INFO:root:current mean train loss 1296.429208761706
INFO:root:current train perplexity2.781374931335449
INFO:root:current mean train loss 1296.8272894434183
INFO:root:current train perplexity2.78324556350708
INFO:root:current mean train loss 1296.927686247839
INFO:root:current train perplexity2.784817695617676
INFO:root:current mean train loss 1297.387933301676
INFO:root:current train perplexity2.785419464111328
INFO:root:current mean train loss 1297.4238695899157
INFO:root:current train perplexity2.7853128910064697
INFO:root:current mean train loss 1298.0631897537796
INFO:root:current train perplexity2.7852418422698975
INFO:root:current mean train loss 1299.353142202031
INFO:root:current train perplexity2.7860090732574463
INFO:root:current mean train loss 1299.5788643864676
INFO:root:current train perplexity2.786403179168701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.17s/it]
INFO:root:final mean train loss: 1299.658007153825
INFO:root:final train perplexity: 2.7870635986328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 2264.121796303607
INFO:root:eval perplexity: 6.2406768798828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 2838.45884628837
INFO:root:eval perplexity: 10.189620971679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [24:28:41<10:58:09, 636.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1286.6238796657985
INFO:root:current train perplexity2.7766306400299072
INFO:root:current mean train loss 1290.4705061287716
INFO:root:current train perplexity2.7665913105010986
INFO:root:current mean train loss 1288.4216632453763
INFO:root:current train perplexity2.761340618133545
INFO:root:current mean train loss 1288.096785481771
INFO:root:current train perplexity2.76123309135437
INFO:root:current mean train loss 1287.7187414962254
INFO:root:current train perplexity2.7635512351989746
INFO:root:current mean train loss 1289.4600568018923
INFO:root:current train perplexity2.7652602195739746
INFO:root:current mean train loss 1290.7484954124272
INFO:root:current train perplexity2.766590118408203
INFO:root:current mean train loss 1291.0295718199454
INFO:root:current train perplexity2.768505334854126
INFO:root:current mean train loss 1291.9160781770063
INFO:root:current train perplexity2.7702972888946533
INFO:root:current mean train loss 1292.6717621011078
INFO:root:current train perplexity2.7715861797332764
INFO:root:current mean train loss 1293.8302744888233
INFO:root:current train perplexity2.7739970684051514
INFO:root:current mean train loss 1294.7453292380253
INFO:root:current train perplexity2.7739150524139404
INFO:root:current mean train loss 1295.1776160305283
INFO:root:current train perplexity2.7762246131896973
INFO:root:current mean train loss 1295.9399381389405
INFO:root:current train perplexity2.7775166034698486
INFO:root:current mean train loss 1296.633895335478
INFO:root:current train perplexity2.7784574031829834
INFO:root:current mean train loss 1297.2426761762995
INFO:root:current train perplexity2.7792563438415527
INFO:root:current mean train loss 1297.7462283612747
INFO:root:current train perplexity2.7812256813049316
INFO:root:current mean train loss 1298.1195414633328
INFO:root:current train perplexity2.781424045562744
INFO:root:current mean train loss 1298.568880009845
INFO:root:current train perplexity2.7825047969818115
INFO:root:current mean train loss 1298.474451091541
INFO:root:current train perplexity2.783838987350464

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it]
INFO:root:final mean train loss: 1298.2139847948283
INFO:root:final train perplexity: 2.783891439437866
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2269.9294697646556
INFO:root:eval perplexity: 6.270057201385498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2843.880875824191
INFO:root:eval perplexity: 10.234903335571289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [24:39:11<10:45:31, 634.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1285.2429770192791
INFO:root:current train perplexity2.7672972679138184
INFO:root:current mean train loss 1289.3052609290605
INFO:root:current train perplexity2.7623586654663086
INFO:root:current mean train loss 1289.7932156861284
INFO:root:current train perplexity2.7586305141448975
INFO:root:current mean train loss 1291.8649922576399
INFO:root:current train perplexity2.759120225906372
INFO:root:current mean train loss 1292.7139361493
INFO:root:current train perplexity2.762537717819214
INFO:root:current mean train loss 1292.3505251195506
INFO:root:current train perplexity2.760281562805176
INFO:root:current mean train loss 1291.2291611962448
INFO:root:current train perplexity2.761918544769287
INFO:root:current mean train loss 1291.702945418871
INFO:root:current train perplexity2.7647671699523926
INFO:root:current mean train loss 1293.8658243343061
INFO:root:current train perplexity2.7676374912261963
INFO:root:current mean train loss 1295.0017294140218
INFO:root:current train perplexity2.767308235168457
INFO:root:current mean train loss 1296.0848241543815
INFO:root:current train perplexity2.7690224647521973
INFO:root:current mean train loss 1296.1309934212295
INFO:root:current train perplexity2.7712557315826416
INFO:root:current mean train loss 1295.23164824714
INFO:root:current train perplexity2.770029067993164
INFO:root:current mean train loss 1294.991290435567
INFO:root:current train perplexity2.7708165645599365
INFO:root:current mean train loss 1294.9279593951726
INFO:root:current train perplexity2.771458387374878
INFO:root:current mean train loss 1294.9814100668464
INFO:root:current train perplexity2.772695541381836
INFO:root:current mean train loss 1295.9506417284804
INFO:root:current train perplexity2.7742085456848145
INFO:root:current mean train loss 1296.0919548320446
INFO:root:current train perplexity2.7754554748535156
INFO:root:current mean train loss 1295.7279357582363
INFO:root:current train perplexity2.776736259460449
INFO:root:current mean train loss 1295.7355642833963
INFO:root:current train perplexity2.7772796154022217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.96s/it]
INFO:root:final mean train loss: 1295.411454455154
INFO:root:final train perplexity: 2.777744770050049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2270.7243223799037
INFO:root:eval perplexity: 6.27409029006958
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2846.6699378913177
INFO:root:eval perplexity: 10.258277893066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [24:49:42<10:33:45, 633.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.585439947587
INFO:root:current train perplexity2.776042938232422
INFO:root:current mean train loss 1289.363576537404
INFO:root:current train perplexity2.7673583030700684
INFO:root:current mean train loss 1287.1285037242383
INFO:root:current train perplexity2.7658920288085938
INFO:root:current mean train loss 1287.0304908450487
INFO:root:current train perplexity2.7623050212860107
INFO:root:current mean train loss 1289.4854713392158
INFO:root:current train perplexity2.767612934112549
INFO:root:current mean train loss 1288.1389969741742
INFO:root:current train perplexity2.7646853923797607
INFO:root:current mean train loss 1289.1390850083992
INFO:root:current train perplexity2.764742612838745
INFO:root:current mean train loss 1289.9466280074114
INFO:root:current train perplexity2.7648541927337646
INFO:root:current mean train loss 1289.26982496867
INFO:root:current train perplexity2.765538215637207
INFO:root:current mean train loss 1290.326019380626
INFO:root:current train perplexity2.7677431106567383
INFO:root:current mean train loss 1291.3998801697173
INFO:root:current train perplexity2.768332004547119
INFO:root:current mean train loss 1291.8919873419609
INFO:root:current train perplexity2.7692346572875977
INFO:root:current mean train loss 1291.982977347415
INFO:root:current train perplexity2.76938796043396
INFO:root:current mean train loss 1291.9526019300388
INFO:root:current train perplexity2.7687571048736572
INFO:root:current mean train loss 1293.2921886224856
INFO:root:current train perplexity2.769787073135376
INFO:root:current mean train loss 1293.7300972820763
INFO:root:current train perplexity2.77195405960083
INFO:root:current mean train loss 1293.8345151881933
INFO:root:current train perplexity2.7725670337677
INFO:root:current mean train loss 1293.7288508895008
INFO:root:current train perplexity2.772897958755493
INFO:root:current mean train loss 1293.876470170927
INFO:root:current train perplexity2.773550510406494
INFO:root:current mean train loss 1293.705135551711
INFO:root:current train perplexity2.7731761932373047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.79s/it]
INFO:root:final mean train loss: 1293.4250903184884
INFO:root:final train perplexity: 2.7733964920043945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2271.461903673537
INFO:root:eval perplexity: 6.277834415435791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2845.9425529317655
INFO:root:eval perplexity: 10.252174377441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [25:00:09<10:21:21, 631.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1282.7212346394856
INFO:root:current train perplexity2.749795913696289
INFO:root:current mean train loss 1281.7833974410078
INFO:root:current train perplexity2.7552852630615234
INFO:root:current mean train loss 1282.281901591533
INFO:root:current train perplexity2.7515342235565186
INFO:root:current mean train loss 1284.3265775430082
INFO:root:current train perplexity2.7553820610046387
INFO:root:current mean train loss 1285.2982701947612
INFO:root:current train perplexity2.756232738494873
INFO:root:current mean train loss 1287.3039716682179
INFO:root:current train perplexity2.7577264308929443
INFO:root:current mean train loss 1287.052697368052
INFO:root:current train perplexity2.7573740482330322
INFO:root:current mean train loss 1286.800573147721
INFO:root:current train perplexity2.7585697174072266
INFO:root:current mean train loss 1287.3701212746757
INFO:root:current train perplexity2.759829521179199
INFO:root:current mean train loss 1288.2614798794789
INFO:root:current train perplexity2.7609004974365234
INFO:root:current mean train loss 1289.0700299339574
INFO:root:current train perplexity2.7616653442382812
INFO:root:current mean train loss 1288.643465584337
INFO:root:current train perplexity2.7618789672851562
INFO:root:current mean train loss 1288.7357537540388
INFO:root:current train perplexity2.7622950077056885
INFO:root:current mean train loss 1289.3807403651897
INFO:root:current train perplexity2.762470245361328
INFO:root:current mean train loss 1289.8292792825139
INFO:root:current train perplexity2.7629287242889404
INFO:root:current mean train loss 1290.9620949498992
INFO:root:current train perplexity2.7649176120758057
INFO:root:current mean train loss 1291.2835806360786
INFO:root:current train perplexity2.7669572830200195
INFO:root:current mean train loss 1292.1853247559682
INFO:root:current train perplexity2.7677526473999023
INFO:root:current mean train loss 1292.1276505868645
INFO:root:current train perplexity2.7689461708068848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.09s/it]
INFO:root:final mean train loss: 1291.3937352075159
INFO:root:final train perplexity: 2.7689571380615234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2274.7557160938886
INFO:root:eval perplexity: 6.29457950592041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2851.991378026651
INFO:root:eval perplexity: 10.303019523620605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [25:10:50<10:13:22, 634.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1311.6280141977163
INFO:root:current train perplexity2.7473011016845703
INFO:root:current mean train loss 1296.765694137168
INFO:root:current train perplexity2.7526557445526123
INFO:root:current mean train loss 1288.6155025858275
INFO:root:current train perplexity2.7376205921173096
INFO:root:current mean train loss 1287.3175828830122
INFO:root:current train perplexity2.7419798374176025
INFO:root:current mean train loss 1287.156916214248
INFO:root:current train perplexity2.7438035011291504
INFO:root:current mean train loss 1286.110849599857
INFO:root:current train perplexity2.745068311691284
INFO:root:current mean train loss 1287.1212198030307
INFO:root:current train perplexity2.749237060546875
INFO:root:current mean train loss 1286.6052372786642
INFO:root:current train perplexity2.7530558109283447
INFO:root:current mean train loss 1287.2818897805678
INFO:root:current train perplexity2.754969835281372
INFO:root:current mean train loss 1286.775769938775
INFO:root:current train perplexity2.7546286582946777
INFO:root:current mean train loss 1286.5584134763697
INFO:root:current train perplexity2.755378484725952
INFO:root:current mean train loss 1286.9311468599085
INFO:root:current train perplexity2.7562718391418457
INFO:root:current mean train loss 1287.0034944513861
INFO:root:current train perplexity2.7571287155151367
INFO:root:current mean train loss 1287.3127962970952
INFO:root:current train perplexity2.757192611694336
INFO:root:current mean train loss 1288.0040424020258
INFO:root:current train perplexity2.758024215698242
INFO:root:current mean train loss 1288.7097731121944
INFO:root:current train perplexity2.7584595680236816
INFO:root:current mean train loss 1288.9684011952447
INFO:root:current train perplexity2.760470390319824
INFO:root:current mean train loss 1289.0582785620302
INFO:root:current train perplexity2.761171579360962
INFO:root:current mean train loss 1289.3519795455134
INFO:root:current train perplexity2.7619142532348633
INFO:root:current mean train loss 1289.3976144027909
INFO:root:current train perplexity2.7628300189971924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.78s/it]
INFO:root:final mean train loss: 1289.226103274316
INFO:root:final train perplexity: 2.7642273902893066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2276.0263693518673
INFO:root:eval perplexity: 6.301050662994385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2853.2340728543327
INFO:root:eval perplexity: 10.313494682312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [25:21:22<10:01:57, 633.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1290.6126586914063
INFO:root:current train perplexity2.7432193756103516
INFO:root:current mean train loss 1281.3603299654446
INFO:root:current train perplexity2.7327706813812256
INFO:root:current mean train loss 1285.6585024626359
INFO:root:current train perplexity2.732862710952759
INFO:root:current mean train loss 1284.2311545632103
INFO:root:current train perplexity2.735703706741333
INFO:root:current mean train loss 1285.754740018623
INFO:root:current train perplexity2.7385635375976562
INFO:root:current mean train loss 1284.40373834574
INFO:root:current train perplexity2.742037057876587
INFO:root:current mean train loss 1285.3532953171502
INFO:root:current train perplexity2.746957778930664
INFO:root:current mean train loss 1285.078663447132
INFO:root:current train perplexity2.7492153644561768
INFO:root:current mean train loss 1285.7506575618881
INFO:root:current train perplexity2.7506561279296875
INFO:root:current mean train loss 1285.3542364961359
INFO:root:current train perplexity2.7504944801330566
INFO:root:current mean train loss 1285.9152243012363
INFO:root:current train perplexity2.7530252933502197
INFO:root:current mean train loss 1287.0555356186048
INFO:root:current train perplexity2.754469156265259
INFO:root:current mean train loss 1286.7827203021786
INFO:root:current train perplexity2.754711866378784
INFO:root:current mean train loss 1287.3272926273203
INFO:root:current train perplexity2.755768299102783
INFO:root:current mean train loss 1287.6801018561516
INFO:root:current train perplexity2.7577672004699707
INFO:root:current mean train loss 1287.2954188527624
INFO:root:current train perplexity2.7585153579711914
INFO:root:current mean train loss 1287.6265513414255
INFO:root:current train perplexity2.7597687244415283
INFO:root:current mean train loss 1287.9412331641754
INFO:root:current train perplexity2.760824203491211
INFO:root:current mean train loss 1287.9250463600367
INFO:root:current train perplexity2.760472536087036
INFO:root:current mean train loss 1288.3184468481825
INFO:root:current train perplexity2.76073956489563

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.29s/it]
INFO:root:final mean train loss: 1287.6801642698288
INFO:root:final train perplexity: 2.7608590126037598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2280.1067708333335
INFO:root:eval perplexity: 6.3218793869018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2857.743459282192
INFO:root:eval perplexity: 10.35159969329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [25:31:50<9:49:53, 632.03s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1266.3928820021608
INFO:root:current train perplexity2.737363338470459
INFO:root:current mean train loss 1275.1648098692601
INFO:root:current train perplexity2.7349393367767334
INFO:root:current mean train loss 1275.5434105753416
INFO:root:current train perplexity2.733246088027954
INFO:root:current mean train loss 1277.145561284222
INFO:root:current train perplexity2.7354238033294678
INFO:root:current mean train loss 1279.0016770330851
INFO:root:current train perplexity2.7395036220550537
INFO:root:current mean train loss 1278.772024206967
INFO:root:current train perplexity2.737419843673706
INFO:root:current mean train loss 1279.7053762256087
INFO:root:current train perplexity2.7420144081115723
INFO:root:current mean train loss 1281.5546910951095
INFO:root:current train perplexity2.7437069416046143
INFO:root:current mean train loss 1282.6474383105353
INFO:root:current train perplexity2.745018482208252
INFO:root:current mean train loss 1283.5750153651334
INFO:root:current train perplexity2.7473037242889404
INFO:root:current mean train loss 1283.698991165234
INFO:root:current train perplexity2.7486119270324707
INFO:root:current mean train loss 1283.7804397809161
INFO:root:current train perplexity2.7495696544647217
INFO:root:current mean train loss 1284.2513875097109
INFO:root:current train perplexity2.7500617504119873
INFO:root:current mean train loss 1285.189980465125
INFO:root:current train perplexity2.7508883476257324
INFO:root:current mean train loss 1285.290269958454
INFO:root:current train perplexity2.7516655921936035
INFO:root:current mean train loss 1285.0811877259919
INFO:root:current train perplexity2.751178503036499
INFO:root:current mean train loss 1285.5672188662152
INFO:root:current train perplexity2.7524609565734863
INFO:root:current mean train loss 1285.57936058634
INFO:root:current train perplexity2.7540411949157715
INFO:root:current mean train loss 1285.3917531755465
INFO:root:current train perplexity2.753966808319092
INFO:root:current mean train loss 1285.487795915491
INFO:root:current train perplexity2.7545394897460938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.40s/it]
INFO:root:final mean train loss: 1284.9692385274836
INFO:root:final train perplexity: 2.754962921142578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2278.658498344692
INFO:root:eval perplexity: 6.314478874206543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2857.0873486674423
INFO:root:eval perplexity: 10.346047401428223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [25:42:18<9:38:11, 630.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.0122661590576
INFO:root:current train perplexity2.7326672077178955
INFO:root:current mean train loss 1278.3907009217796
INFO:root:current train perplexity2.7358641624450684
INFO:root:current mean train loss 1270.486714218602
INFO:root:current train perplexity2.731329917907715
INFO:root:current mean train loss 1273.7945382254463
INFO:root:current train perplexity2.7346813678741455
INFO:root:current mean train loss 1273.7676215336242
INFO:root:current train perplexity2.7374038696289062
INFO:root:current mean train loss 1275.160262087558
INFO:root:current train perplexity2.7396414279937744
INFO:root:current mean train loss 1275.706601062453
INFO:root:current train perplexity2.741010904312134
INFO:root:current mean train loss 1277.319094672877
INFO:root:current train perplexity2.7403998374938965
INFO:root:current mean train loss 1276.9307866979527
INFO:root:current train perplexity2.7411205768585205
INFO:root:current mean train loss 1277.5513634899346
INFO:root:current train perplexity2.742950439453125
INFO:root:current mean train loss 1278.5256818039973
INFO:root:current train perplexity2.745441198348999
INFO:root:current mean train loss 1278.4717945216858
INFO:root:current train perplexity2.7454471588134766
INFO:root:current mean train loss 1279.3788287971593
INFO:root:current train perplexity2.746253728866577
INFO:root:current mean train loss 1279.7785483441394
INFO:root:current train perplexity2.7469282150268555
INFO:root:current mean train loss 1280.7324789912323
INFO:root:current train perplexity2.7478132247924805
INFO:root:current mean train loss 1281.582441559228
INFO:root:current train perplexity2.749087333679199
INFO:root:current mean train loss 1281.831071633559
INFO:root:current train perplexity2.749323844909668
INFO:root:current mean train loss 1282.2286457918128
INFO:root:current train perplexity2.7504351139068604
INFO:root:current mean train loss 1283.0778878011417
INFO:root:current train perplexity2.751516342163086
INFO:root:current mean train loss 1283.5243976538634
INFO:root:current train perplexity2.751389265060425

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.21s/it]
INFO:root:final mean train loss: 1283.3210408897996
INFO:root:final train perplexity: 2.7513842582702637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 2279.8695709012077
INFO:root:eval perplexity: 6.320666790008545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2858.963638630319
INFO:root:eval perplexity: 10.36193561553955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [25:52:57<9:30:04, 633.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.9936297381366
INFO:root:current train perplexity2.745084524154663
INFO:root:current mean train loss 1283.421117624525
INFO:root:current train perplexity2.7384698390960693
INFO:root:current mean train loss 1280.6673397186387
INFO:root:current train perplexity2.7358503341674805
INFO:root:current mean train loss 1278.8572648816846
INFO:root:current train perplexity2.738868236541748
INFO:root:current mean train loss 1279.3957605817957
INFO:root:current train perplexity2.7390542030334473
INFO:root:current mean train loss 1280.3345148871153
INFO:root:current train perplexity2.742414951324463
INFO:root:current mean train loss 1280.1797656536803
INFO:root:current train perplexity2.743793249130249
INFO:root:current mean train loss 1279.5854704755523
INFO:root:current train perplexity2.74314022064209
INFO:root:current mean train loss 1280.831561397072
INFO:root:current train perplexity2.7439823150634766
INFO:root:current mean train loss 1279.9782022987545
INFO:root:current train perplexity2.744424819946289
INFO:root:current mean train loss 1280.3120228981772
INFO:root:current train perplexity2.745081663131714
INFO:root:current mean train loss 1280.5178696053397
INFO:root:current train perplexity2.7452759742736816
INFO:root:current mean train loss 1279.9368185598714
INFO:root:current train perplexity2.745974063873291
INFO:root:current mean train loss 1279.9460078853356
INFO:root:current train perplexity2.7458252906799316
INFO:root:current mean train loss 1280.4836227963053
INFO:root:current train perplexity2.745856523513794
INFO:root:current mean train loss 1280.462312856405
INFO:root:current train perplexity2.7457313537597656
INFO:root:current mean train loss 1280.9717588407664
INFO:root:current train perplexity2.746155261993408
INFO:root:current mean train loss 1281.712172253891
INFO:root:current train perplexity2.746962785720825
INFO:root:current mean train loss 1281.6648738360163
INFO:root:current train perplexity2.747110366821289
INFO:root:current mean train loss 1281.6731212756538
INFO:root:current train perplexity2.746926784515381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.03s/it]
INFO:root:final mean train loss: 1281.2982577248408
INFO:root:final train perplexity: 2.7469985485076904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2285.015240175504
INFO:root:eval perplexity: 6.347024917602539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2863.4038860780975
INFO:root:eval perplexity: 10.39963150024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [26:03:28<9:18:52, 632.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1270.969691685268
INFO:root:current train perplexity2.7386746406555176
INFO:root:current mean train loss 1274.0694302645597
INFO:root:current train perplexity2.731215000152588
INFO:root:current mean train loss 1272.915958276531
INFO:root:current train perplexity2.7376041412353516
INFO:root:current mean train loss 1271.2902865769277
INFO:root:current train perplexity2.7326886653900146
INFO:root:current mean train loss 1273.7112559123211
INFO:root:current train perplexity2.731104612350464
INFO:root:current mean train loss 1275.1161564345343
INFO:root:current train perplexity2.732591152191162
INFO:root:current mean train loss 1275.6428439514684
INFO:root:current train perplexity2.7332372665405273
INFO:root:current mean train loss 1276.1017688569568
INFO:root:current train perplexity2.7345852851867676
INFO:root:current mean train loss 1276.2053915928627
INFO:root:current train perplexity2.735595703125
INFO:root:current mean train loss 1276.629751323937
INFO:root:current train perplexity2.7365598678588867
INFO:root:current mean train loss 1277.6930610920779
INFO:root:current train perplexity2.737952470779419
INFO:root:current mean train loss 1277.6748921134833
INFO:root:current train perplexity2.738359212875366
INFO:root:current mean train loss 1277.8706901091823
INFO:root:current train perplexity2.7393970489501953
INFO:root:current mean train loss 1277.7828552508047
INFO:root:current train perplexity2.7396914958953857
INFO:root:current mean train loss 1278.409112785146
INFO:root:current train perplexity2.7396867275238037
INFO:root:current mean train loss 1279.1564279109873
INFO:root:current train perplexity2.7409017086029053
INFO:root:current mean train loss 1279.4251903089112
INFO:root:current train perplexity2.7415339946746826
INFO:root:current mean train loss 1279.5175335876668
INFO:root:current train perplexity2.742337465286255
INFO:root:current mean train loss 1279.7858799893186
INFO:root:current train perplexity2.7426939010620117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.55s/it]
INFO:root:final mean train loss: 1279.7897704216307
INFO:root:final train perplexity: 2.7437326908111572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2287.4638966228945
INFO:root:eval perplexity: 6.359606742858887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 2866.17426619293
INFO:root:eval perplexity: 10.42322063446045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [26:13:56<9:07:05, 631.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1278.1325927734374
INFO:root:current train perplexity2.720978021621704
INFO:root:current mean train loss 1281.9079759680706
INFO:root:current train perplexity2.73642897605896
INFO:root:current mean train loss 1269.0828590570495
INFO:root:current train perplexity2.733905076980591
INFO:root:current mean train loss 1270.1610874720982
INFO:root:current train perplexity2.7338829040527344
INFO:root:current mean train loss 1271.5761421663215
INFO:root:current train perplexity2.7319421768188477
INFO:root:current mean train loss 1272.0498912033524
INFO:root:current train perplexity2.731921911239624
INFO:root:current mean train loss 1273.2905323059579
INFO:root:current train perplexity2.731881856918335
INFO:root:current mean train loss 1274.3155954641063
INFO:root:current train perplexity2.7311768531799316
INFO:root:current mean train loss 1275.3252279644364
INFO:root:current train perplexity2.730506181716919
INFO:root:current mean train loss 1275.8652609236253
INFO:root:current train perplexity2.732116937637329
INFO:root:current mean train loss 1275.7820909020936
INFO:root:current train perplexity2.7319982051849365
INFO:root:current mean train loss 1275.9618407108323
INFO:root:current train perplexity2.734349250793457
INFO:root:current mean train loss 1276.3606264467592
INFO:root:current train perplexity2.7339930534362793
INFO:root:current mean train loss 1276.7743566012655
INFO:root:current train perplexity2.7339611053466797
INFO:root:current mean train loss 1276.2253258371522
INFO:root:current train perplexity2.7346930503845215
INFO:root:current mean train loss 1276.0333956173938
INFO:root:current train perplexity2.7350735664367676
INFO:root:current mean train loss 1276.150633858601
INFO:root:current train perplexity2.73587965965271
INFO:root:current mean train loss 1276.5702394001685
INFO:root:current train perplexity2.73648738861084
INFO:root:current mean train loss 1276.5510652063963
INFO:root:current train perplexity2.7366034984588623
INFO:root:current mean train loss 1276.934655156148
INFO:root:current train perplexity2.73765230178833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.30s/it]
INFO:root:final mean train loss: 1277.2259324497486
INFO:root:final train perplexity: 2.738190174102783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 2288.058905418883
INFO:root:eval perplexity: 6.362668037414551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2869.3733165551585
INFO:root:eval perplexity: 10.450528144836426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [26:24:24<8:55:46, 630.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.2140312194824
INFO:root:current train perplexity2.739224433898926
INFO:root:current mean train loss 1267.1293316465435
INFO:root:current train perplexity2.7122089862823486
INFO:root:current mean train loss 1269.3404509445716
INFO:root:current train perplexity2.7258455753326416
INFO:root:current mean train loss 1268.7784173804594
INFO:root:current train perplexity2.729041337966919
INFO:root:current mean train loss 1271.58906950774
INFO:root:current train perplexity2.727790355682373
INFO:root:current mean train loss 1272.0575244874883
INFO:root:current train perplexity2.7270710468292236
INFO:root:current mean train loss 1272.8434821020198
INFO:root:current train perplexity2.7281415462493896
INFO:root:current mean train loss 1272.2606834870219
INFO:root:current train perplexity2.7282185554504395
INFO:root:current mean train loss 1273.298842063317
INFO:root:current train perplexity2.7291765213012695
INFO:root:current mean train loss 1273.8577738094739
INFO:root:current train perplexity2.730882167816162
INFO:root:current mean train loss 1274.1211434297784
INFO:root:current train perplexity2.7291605472564697
INFO:root:current mean train loss 1274.5562771099617
INFO:root:current train perplexity2.7310938835144043
INFO:root:current mean train loss 1274.6706918493494
INFO:root:current train perplexity2.731607675552368
INFO:root:current mean train loss 1275.1010975880665
INFO:root:current train perplexity2.7323098182678223
INFO:root:current mean train loss 1275.4693458599752
INFO:root:current train perplexity2.7324514389038086
INFO:root:current mean train loss 1275.7810688865402
INFO:root:current train perplexity2.734520673751831
INFO:root:current mean train loss 1276.1578408783557
INFO:root:current train perplexity2.7349820137023926
INFO:root:current mean train loss 1276.6160884443111
INFO:root:current train perplexity2.7356767654418945
INFO:root:current mean train loss 1276.7084507838088
INFO:root:current train perplexity2.7350947856903076
INFO:root:current mean train loss 1276.568527506005
INFO:root:current train perplexity2.7357516288757324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.67s/it]
INFO:root:final mean train loss: 1276.3104781142642
INFO:root:final train perplexity: 2.7362136840820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2289.464736830258
INFO:root:eval perplexity: 6.369905948638916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2871.815502843113
INFO:root:eval perplexity: 10.471418380737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [26:34:54<8:45:04, 630.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1269.551962093431
INFO:root:current train perplexity2.707468271255493
INFO:root:current mean train loss 1267.2632155450399
INFO:root:current train perplexity2.7160706520080566
INFO:root:current mean train loss 1267.511613347923
INFO:root:current train perplexity2.7186989784240723
INFO:root:current mean train loss 1266.5599085417039
INFO:root:current train perplexity2.7161591053009033
INFO:root:current mean train loss 1267.894655767156
INFO:root:current train perplexity2.7141597270965576
INFO:root:current mean train loss 1267.2767496300091
INFO:root:current train perplexity2.715644598007202
INFO:root:current mean train loss 1269.9596991164292
INFO:root:current train perplexity2.7216086387634277
INFO:root:current mean train loss 1270.7168915650554
INFO:root:current train perplexity2.7229461669921875
INFO:root:current mean train loss 1272.1049823379067
INFO:root:current train perplexity2.722421646118164
INFO:root:current mean train loss 1271.5409406334381
INFO:root:current train perplexity2.7239773273468018
INFO:root:current mean train loss 1272.2926188306199
INFO:root:current train perplexity2.7248926162719727
INFO:root:current mean train loss 1272.8123295902687
INFO:root:current train perplexity2.7257158756256104
INFO:root:current mean train loss 1272.8214144557833
INFO:root:current train perplexity2.726550817489624
INFO:root:current mean train loss 1273.2014193637358
INFO:root:current train perplexity2.727541208267212
INFO:root:current mean train loss 1273.0126098043102
INFO:root:current train perplexity2.7274277210235596
INFO:root:current mean train loss 1273.8967917967489
INFO:root:current train perplexity2.729149580001831
INFO:root:current mean train loss 1273.871261420866
INFO:root:current train perplexity2.7293455600738525
INFO:root:current mean train loss 1274.4377436520647
INFO:root:current train perplexity2.7306134700775146
INFO:root:current mean train loss 1274.3771856461685
INFO:root:current train perplexity2.730912923812866
INFO:root:current mean train loss 1274.4875944870566
INFO:root:current train perplexity2.7309858798980713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.44s/it]
INFO:root:final mean train loss: 1274.0234724343936
INFO:root:final train perplexity: 2.73128342628479
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2292.4780295081173
INFO:root:eval perplexity: 6.385448932647705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2874.696937506926
INFO:root:eval perplexity: 10.496126174926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [26:45:35<8:37:10, 633.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1264.8609415690105
INFO:root:current train perplexity2.716876983642578
INFO:root:current mean train loss 1262.0713500976562
INFO:root:current train perplexity2.707625389099121
INFO:root:current mean train loss 1263.1628344542999
INFO:root:current train perplexity2.705639362335205
INFO:root:current mean train loss 1266.0286021415002
INFO:root:current train perplexity2.7120819091796875
INFO:root:current mean train loss 1265.401152647616
INFO:root:current train perplexity2.7144081592559814
INFO:root:current mean train loss 1265.3103072634856
INFO:root:current train perplexity2.71618390083313
INFO:root:current mean train loss 1266.1406691725906
INFO:root:current train perplexity2.717700958251953
INFO:root:current mean train loss 1266.2667677757322
INFO:root:current train perplexity2.7161998748779297
INFO:root:current mean train loss 1266.3023370121698
INFO:root:current train perplexity2.717364549636841
INFO:root:current mean train loss 1266.7148630841177
INFO:root:current train perplexity2.7175145149230957
INFO:root:current mean train loss 1267.6208764052972
INFO:root:current train perplexity2.719188928604126
INFO:root:current mean train loss 1267.7735626063666
INFO:root:current train perplexity2.7200582027435303
INFO:root:current mean train loss 1269.011841495267
INFO:root:current train perplexity2.72279691696167
INFO:root:current mean train loss 1269.15430733051
INFO:root:current train perplexity2.7235476970672607
INFO:root:current mean train loss 1270.5632136033958
INFO:root:current train perplexity2.724715232849121
INFO:root:current mean train loss 1271.1762840300228
INFO:root:current train perplexity2.7255136966705322
INFO:root:current mean train loss 1271.223303896754
INFO:root:current train perplexity2.7260260581970215
INFO:root:current mean train loss 1271.9670801389527
INFO:root:current train perplexity2.727363109588623
INFO:root:current mean train loss 1272.0902951353999
INFO:root:current train perplexity2.7272889614105225
INFO:root:current mean train loss 1272.330442597398
INFO:root:current train perplexity2.7266557216644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.90s/it]
INFO:root:final mean train loss: 1271.9617908533571
INFO:root:final train perplexity: 2.7268455028533936
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2291.9278594754264
INFO:root:eval perplexity: 6.3826069831848145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it]
INFO:root:eval mean loss: 2874.246749986148
INFO:root:eval perplexity: 10.492258071899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [26:56:07<8:26:18, 632.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.0758159591492
INFO:root:current train perplexity2.7063093185424805
INFO:root:current mean train loss 1266.1968473840932
INFO:root:current train perplexity2.716242790222168
INFO:root:current mean train loss 1266.3823350023465
INFO:root:current train perplexity2.7153754234313965
INFO:root:current mean train loss 1268.2726419712794
INFO:root:current train perplexity2.716506242752075
INFO:root:current mean train loss 1267.7592811347536
INFO:root:current train perplexity2.7114126682281494
INFO:root:current mean train loss 1268.7121395680344
INFO:root:current train perplexity2.714709758758545
INFO:root:current mean train loss 1268.4701308422173
INFO:root:current train perplexity2.7153499126434326
INFO:root:current mean train loss 1269.1165394204481
INFO:root:current train perplexity2.718055486679077
INFO:root:current mean train loss 1269.314724223395
INFO:root:current train perplexity2.7176272869110107
INFO:root:current mean train loss 1270.0454629333433
INFO:root:current train perplexity2.719599485397339
INFO:root:current mean train loss 1269.6256141838714
INFO:root:current train perplexity2.720261812210083
INFO:root:current mean train loss 1269.9705925084531
INFO:root:current train perplexity2.7204668521881104
INFO:root:current mean train loss 1269.7517297258623
INFO:root:current train perplexity2.720832347869873
INFO:root:current mean train loss 1270.065180868837
INFO:root:current train perplexity2.721362352371216
INFO:root:current mean train loss 1269.7888281546327
INFO:root:current train perplexity2.7207534313201904
INFO:root:current mean train loss 1269.7538703152145
INFO:root:current train perplexity2.7209315299987793
INFO:root:current mean train loss 1269.6107113181447
INFO:root:current train perplexity2.72057843208313
INFO:root:current mean train loss 1269.6949751121706
INFO:root:current train perplexity2.72182035446167
INFO:root:current mean train loss 1270.283621133165
INFO:root:current train perplexity2.7227566242218018
INFO:root:current mean train loss 1270.5348931801661
INFO:root:current train perplexity2.7237789630889893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.10s/it]
INFO:root:final mean train loss: 1270.5348931801661
INFO:root:final train perplexity: 2.7237789630889893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2294.911979080092
INFO:root:eval perplexity: 6.398029327392578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2876.0059515770445
INFO:root:eval perplexity: 10.507368087768555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [27:06:34<8:14:28, 631.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1265.671055908203
INFO:root:current train perplexity2.7220287322998047
INFO:root:current mean train loss 1263.728486328125
INFO:root:current train perplexity2.716978073120117
INFO:root:current mean train loss 1266.7788350423177
INFO:root:current train perplexity2.7137629985809326
INFO:root:current mean train loss 1265.7081231689453
INFO:root:current train perplexity2.7103185653686523
INFO:root:current mean train loss 1266.4674489746094
INFO:root:current train perplexity2.7120561599731445
INFO:root:current mean train loss 1265.8545147705079
INFO:root:current train perplexity2.7102389335632324
INFO:root:current mean train loss 1265.9129743303572
INFO:root:current train perplexity2.7103443145751953
INFO:root:current mean train loss 1265.360601348877
INFO:root:current train perplexity2.7085824012756348
INFO:root:current mean train loss 1265.9987344021267
INFO:root:current train perplexity2.7114791870117188
INFO:root:current mean train loss 1266.965866821289
INFO:root:current train perplexity2.713430404663086
INFO:root:current mean train loss 1268.0822200150924
INFO:root:current train perplexity2.7139687538146973
INFO:root:current mean train loss 1267.0212647501628
INFO:root:current train perplexity2.713909387588501
INFO:root:current mean train loss 1267.0250834773137
INFO:root:current train perplexity2.7136197090148926
INFO:root:current mean train loss 1267.4865145438057
INFO:root:current train perplexity2.715240478515625
INFO:root:current mean train loss 1267.9457316894532
INFO:root:current train perplexity2.7146880626678467
INFO:root:current mean train loss 1268.5020957183838
INFO:root:current train perplexity2.715420722961426
INFO:root:current mean train loss 1267.844097397748
INFO:root:current train perplexity2.7165026664733887
INFO:root:current mean train loss 1268.1650404188367
INFO:root:current train perplexity2.7171785831451416
INFO:root:current mean train loss 1268.321697419819
INFO:root:current train perplexity2.7179808616638184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.43s/it]
INFO:root:final mean train loss: 1268.006213582049
INFO:root:final train perplexity: 2.7183525562286377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2296.7150233924813
INFO:root:eval perplexity: 6.407365798950195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2879.4239995428857
INFO:root:eval perplexity: 10.53678035736084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [27:17:14<8:05:53, 633.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.1074290556066
INFO:root:current train perplexity2.67509388923645
INFO:root:current mean train loss 1260.5207050030049
INFO:root:current train perplexity2.711102247238159
INFO:root:current mean train loss 1261.1877132011448
INFO:root:current train perplexity2.712082862854004
INFO:root:current mean train loss 1261.850986805624
INFO:root:current train perplexity2.709886074066162
INFO:root:current mean train loss 1264.4157539203013
INFO:root:current train perplexity2.7111356258392334
INFO:root:current mean train loss 1264.2609790086285
INFO:root:current train perplexity2.7074999809265137
INFO:root:current mean train loss 1264.384186730779
INFO:root:current train perplexity2.708098888397217
INFO:root:current mean train loss 1265.2312369246863
INFO:root:current train perplexity2.708977699279785
INFO:root:current mean train loss 1265.118615139946
INFO:root:current train perplexity2.7102930545806885
INFO:root:current mean train loss 1265.5717531160544
INFO:root:current train perplexity2.711059808731079
INFO:root:current mean train loss 1265.9841295390472
INFO:root:current train perplexity2.7112929821014404
INFO:root:current mean train loss 1266.6963191156208
INFO:root:current train perplexity2.7126030921936035
INFO:root:current mean train loss 1266.8439743806812
INFO:root:current train perplexity2.712158203125
INFO:root:current mean train loss 1266.5505048538937
INFO:root:current train perplexity2.7129967212677
INFO:root:current mean train loss 1267.6735521961284
INFO:root:current train perplexity2.7136921882629395
INFO:root:current mean train loss 1267.9461279650934
INFO:root:current train perplexity2.714491367340088
INFO:root:current mean train loss 1268.0122464379929
INFO:root:current train perplexity2.715414524078369
INFO:root:current mean train loss 1267.4544109684407
INFO:root:current train perplexity2.7153000831604004
INFO:root:current mean train loss 1267.7843007500774
INFO:root:current train perplexity2.716456890106201
INFO:root:current mean train loss 1267.9209935721096
INFO:root:current train perplexity2.7164859771728516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.81s/it]
INFO:root:final mean train loss: 1267.3683888737867
INFO:root:final train perplexity: 2.7169852256774902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2299.9001187804743
INFO:root:eval perplexity: 6.423891544342041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2882.608465965758
INFO:root:eval perplexity: 10.564255714416504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [27:27:44<7:54:31, 632.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1261.2931159524358
INFO:root:current train perplexity2.6821250915527344
INFO:root:current mean train loss 1262.5198418916161
INFO:root:current train perplexity2.709975481033325
INFO:root:current mean train loss 1260.7727921966814
INFO:root:current train perplexity2.708711624145508
INFO:root:current mean train loss 1260.7369366491625
INFO:root:current train perplexity2.7043373584747314
INFO:root:current mean train loss 1261.0465509792627
INFO:root:current train perplexity2.7053775787353516
INFO:root:current mean train loss 1261.9576420587546
INFO:root:current train perplexity2.7061667442321777
INFO:root:current mean train loss 1261.9704557111963
INFO:root:current train perplexity2.7045230865478516
INFO:root:current mean train loss 1263.0319242139603
INFO:root:current train perplexity2.704354763031006
INFO:root:current mean train loss 1263.5248468705504
INFO:root:current train perplexity2.7033636569976807
INFO:root:current mean train loss 1263.1772994178266
INFO:root:current train perplexity2.7026824951171875
INFO:root:current mean train loss 1262.3273284735026
INFO:root:current train perplexity2.704021692276001
INFO:root:current mean train loss 1262.2280270208128
INFO:root:current train perplexity2.704674482345581
INFO:root:current mean train loss 1262.2971616772818
INFO:root:current train perplexity2.7047746181488037
INFO:root:current mean train loss 1263.0769741167014
INFO:root:current train perplexity2.7066807746887207
INFO:root:current mean train loss 1263.1350619477041
INFO:root:current train perplexity2.7076334953308105
INFO:root:current mean train loss 1263.5464491862829
INFO:root:current train perplexity2.708024263381958
INFO:root:current mean train loss 1264.1961048364346
INFO:root:current train perplexity2.7088427543640137
INFO:root:current mean train loss 1264.645030372558
INFO:root:current train perplexity2.7100532054901123
INFO:root:current mean train loss 1265.0870982329225
INFO:root:current train perplexity2.7105937004089355
INFO:root:current mean train loss 1265.2457532281096
INFO:root:current train perplexity2.711507797241211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.66s/it]
INFO:root:final mean train loss: 1264.8315996640388
INFO:root:final train perplexity: 2.711555004119873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2301.0823753843915
INFO:root:eval perplexity: 6.430037498474121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2884.323135267758
INFO:root:eval perplexity: 10.579081535339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [27:38:33<7:47:29, 637.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.410436293658
INFO:root:current train perplexity2.7181942462921143
INFO:root:current mean train loss 1259.657197459644
INFO:root:current train perplexity2.708293914794922
INFO:root:current mean train loss 1258.980173057769
INFO:root:current train perplexity2.702667474746704
INFO:root:current mean train loss 1258.400451486267
INFO:root:current train perplexity2.696289539337158
INFO:root:current mean train loss 1261.6818604056957
INFO:root:current train perplexity2.700479745864868
INFO:root:current mean train loss 1261.077259873738
INFO:root:current train perplexity2.701213836669922
INFO:root:current mean train loss 1261.9484355123727
INFO:root:current train perplexity2.7015933990478516
INFO:root:current mean train loss 1261.4604841656437
INFO:root:current train perplexity2.7026193141937256
INFO:root:current mean train loss 1261.0229371695066
INFO:root:current train perplexity2.702815294265747
INFO:root:current mean train loss 1261.6787550933227
INFO:root:current train perplexity2.7022504806518555
INFO:root:current mean train loss 1262.6108743393568
INFO:root:current train perplexity2.703629970550537
INFO:root:current mean train loss 1263.1916686322356
INFO:root:current train perplexity2.705090284347534
INFO:root:current mean train loss 1263.4215724100407
INFO:root:current train perplexity2.705554485321045
INFO:root:current mean train loss 1263.6637488759773
INFO:root:current train perplexity2.706902027130127
INFO:root:current mean train loss 1264.4293033697127
INFO:root:current train perplexity2.7077836990356445
INFO:root:current mean train loss 1264.556098273921
INFO:root:current train perplexity2.707895278930664
INFO:root:current mean train loss 1264.567110501803
INFO:root:current train perplexity2.7081964015960693
INFO:root:current mean train loss 1264.676777820598
INFO:root:current train perplexity2.7090611457824707
INFO:root:current mean train loss 1264.498123440982
INFO:root:current train perplexity2.709773063659668
INFO:root:current mean train loss 1264.5400295521526
INFO:root:current train perplexity2.7093698978424072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.53s/it]
INFO:root:final mean train loss: 1264.043447089568
INFO:root:final train perplexity: 2.7098701000213623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2300.1084564425423
INFO:root:eval perplexity: 6.424975395202637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2882.967578644448
INFO:root:eval perplexity: 10.567361831665039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [27:49:04<7:35:36, 635.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1254.0922564338234
INFO:root:current train perplexity2.683708906173706
INFO:root:current mean train loss 1253.0701744442895
INFO:root:current train perplexity2.6904854774475098
INFO:root:current mean train loss 1253.5384120656483
INFO:root:current train perplexity2.693913459777832
INFO:root:current mean train loss 1256.3660407688308
INFO:root:current train perplexity2.699739933013916
INFO:root:current mean train loss 1257.1456833537827
INFO:root:current train perplexity2.699662446975708
INFO:root:current mean train loss 1256.4240153138066
INFO:root:current train perplexity2.6980481147766113
INFO:root:current mean train loss 1255.9618415147245
INFO:root:current train perplexity2.700382947921753
INFO:root:current mean train loss 1257.2419931093852
INFO:root:current train perplexity2.7022454738616943
INFO:root:current mean train loss 1258.054678218156
INFO:root:current train perplexity2.703136444091797
INFO:root:current mean train loss 1258.4012480176184
INFO:root:current train perplexity2.7042887210845947
INFO:root:current mean train loss 1259.1762135252077
INFO:root:current train perplexity2.703880548477173
INFO:root:current mean train loss 1259.7533855699512
INFO:root:current train perplexity2.704514980316162
INFO:root:current mean train loss 1260.7225439992237
INFO:root:current train perplexity2.7037925720214844
INFO:root:current mean train loss 1260.8184478045905
INFO:root:current train perplexity2.7041051387786865
INFO:root:current mean train loss 1260.2219442008952
INFO:root:current train perplexity2.7030141353607178
INFO:root:current mean train loss 1260.699031907685
INFO:root:current train perplexity2.70339035987854
INFO:root:current mean train loss 1260.930104939486
INFO:root:current train perplexity2.7044997215270996
INFO:root:current mean train loss 1261.0509026298696
INFO:root:current train perplexity2.7041332721710205
INFO:root:current mean train loss 1261.4821972734667
INFO:root:current train perplexity2.704923152923584
INFO:root:current mean train loss 1262.294305568788
INFO:root:current train perplexity2.7054638862609863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.69s/it]
INFO:root:final mean train loss: 1262.0023155500958
INFO:root:final train perplexity: 2.7055113315582275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2304.670167314245
INFO:root:eval perplexity: 6.448720932006836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2888.5499838971077
INFO:root:eval perplexity: 10.615717887878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [27:59:35<7:23:54, 634.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.1987936580883
INFO:root:current train perplexity2.6927030086517334
INFO:root:current mean train loss 1250.716734190245
INFO:root:current train perplexity2.6935606002807617
INFO:root:current mean train loss 1254.369884183114
INFO:root:current train perplexity2.6965222358703613
INFO:root:current mean train loss 1256.68187620485
INFO:root:current train perplexity2.7000365257263184
INFO:root:current mean train loss 1257.7253722515302
INFO:root:current train perplexity2.7010364532470703
INFO:root:current mean train loss 1255.7521012787126
INFO:root:current train perplexity2.700986862182617
INFO:root:current mean train loss 1256.8252535854813
INFO:root:current train perplexity2.7004966735839844
INFO:root:current mean train loss 1257.6918065162222
INFO:root:current train perplexity2.701749324798584
INFO:root:current mean train loss 1258.4345292085982
INFO:root:current train perplexity2.7013864517211914
INFO:root:current mean train loss 1259.6205250386658
INFO:root:current train perplexity2.7013442516326904
INFO:root:current mean train loss 1258.8329004806308
INFO:root:current train perplexity2.700925588607788
INFO:root:current mean train loss 1258.6004587165414
INFO:root:current train perplexity2.7007012367248535
INFO:root:current mean train loss 1258.7650105635944
INFO:root:current train perplexity2.701096534729004
INFO:root:current mean train loss 1259.310611215309
INFO:root:current train perplexity2.700481414794922
INFO:root:current mean train loss 1259.5251220703126
INFO:root:current train perplexity2.700148582458496
INFO:root:current mean train loss 1259.771098756038
INFO:root:current train perplexity2.701263189315796
INFO:root:current mean train loss 1260.5304689673358
INFO:root:current train perplexity2.701603651046753
INFO:root:current mean train loss 1261.3186604133841
INFO:root:current train perplexity2.702484607696533
INFO:root:current mean train loss 1261.7238923009575
INFO:root:current train perplexity2.7033472061157227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.12s/it]
INFO:root:final mean train loss: 1261.3247771770498
INFO:root:final train perplexity: 2.704066038131714
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2305.807485161098
INFO:root:eval perplexity: 6.454657077789307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2891.2612010333555
INFO:root:eval perplexity: 10.639281272888184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [28:10:06<7:12:46, 633.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1176.417236328125
INFO:root:current train perplexity2.669748544692993
INFO:root:current mean train loss 1246.9546496821386
INFO:root:current train perplexity2.693230152130127
INFO:root:current mean train loss 1247.705034010481
INFO:root:current train perplexity2.6854162216186523
INFO:root:current mean train loss 1253.5052146658993
INFO:root:current train perplexity2.688058614730835
INFO:root:current mean train loss 1252.914086488942
INFO:root:current train perplexity2.686429977416992
INFO:root:current mean train loss 1254.2587200028013
INFO:root:current train perplexity2.6880013942718506
INFO:root:current mean train loss 1255.1577519515029
INFO:root:current train perplexity2.688746690750122
INFO:root:current mean train loss 1255.3598924946582
INFO:root:current train perplexity2.688706874847412
INFO:root:current mean train loss 1255.933433780052
INFO:root:current train perplexity2.6899962425231934
INFO:root:current mean train loss 1256.1116698406752
INFO:root:current train perplexity2.6930038928985596
INFO:root:current mean train loss 1256.0660655008342
INFO:root:current train perplexity2.694455146789551
INFO:root:current mean train loss 1257.4578800928355
INFO:root:current train perplexity2.6963865756988525
INFO:root:current mean train loss 1257.5545483682795
INFO:root:current train perplexity2.6961026191711426
INFO:root:current mean train loss 1257.9224771947904
INFO:root:current train perplexity2.6959197521209717
INFO:root:current mean train loss 1259.074102252084
INFO:root:current train perplexity2.6963794231414795
INFO:root:current mean train loss 1259.0465803082868
INFO:root:current train perplexity2.697343349456787
INFO:root:current mean train loss 1259.6607894611716
INFO:root:current train perplexity2.698779821395874
INFO:root:current mean train loss 1259.4793945025613
INFO:root:current train perplexity2.6992671489715576
INFO:root:current mean train loss 1259.6220222837255
INFO:root:current train perplexity2.6999077796936035
INFO:root:current mean train loss 1259.9283663552142
INFO:root:current train perplexity2.7005770206451416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.32s/it]
INFO:root:final mean train loss: 1259.7460843315644
INFO:root:final train perplexity: 2.7007014751434326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2308.0775423523382
INFO:root:eval perplexity: 6.466516017913818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2893.235167591284
INFO:root:eval perplexity: 10.656471252441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [28:20:38<7:01:50, 632.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1256.7798879523027
INFO:root:current train perplexity2.699113607406616
INFO:root:current mean train loss 1256.2219751181722
INFO:root:current train perplexity2.680682897567749
INFO:root:current mean train loss 1255.6785743748217
INFO:root:current train perplexity2.679044246673584
INFO:root:current mean train loss 1252.8768700865742
INFO:root:current train perplexity2.6852867603302
INFO:root:current mean train loss 1253.5978674695145
INFO:root:current train perplexity2.6866772174835205
INFO:root:current mean train loss 1252.9951355333274
INFO:root:current train perplexity2.688598871231079
INFO:root:current mean train loss 1253.4458076834487
INFO:root:current train perplexity2.6892077922821045
INFO:root:current mean train loss 1254.357529004857
INFO:root:current train perplexity2.6893150806427
INFO:root:current mean train loss 1254.5738264556624
INFO:root:current train perplexity2.6906845569610596
INFO:root:current mean train loss 1254.7728814757038
INFO:root:current train perplexity2.6915159225463867
INFO:root:current mean train loss 1255.550191622838
INFO:root:current train perplexity2.692488670349121
INFO:root:current mean train loss 1255.9701331362753
INFO:root:current train perplexity2.6942460536956787
INFO:root:current mean train loss 1256.8724771801617
INFO:root:current train perplexity2.6946489810943604
INFO:root:current mean train loss 1257.9944329829357
INFO:root:current train perplexity2.6954524517059326
INFO:root:current mean train loss 1258.0803972799397
INFO:root:current train perplexity2.6948819160461426
INFO:root:current mean train loss 1257.7740062238984
INFO:root:current train perplexity2.69671893119812
INFO:root:current mean train loss 1257.4127333737067
INFO:root:current train perplexity2.6969997882843018
INFO:root:current mean train loss 1257.7627683132453
INFO:root:current train perplexity2.697300672531128
INFO:root:current mean train loss 1258.2103392279625
INFO:root:current train perplexity2.6968436241149902
INFO:root:current mean train loss 1258.501417898523
INFO:root:current train perplexity2.6971144676208496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.35s/it]
INFO:root:final mean train loss: 1258.0947225304246
INFO:root:final train perplexity: 2.697186231613159
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2309.7335503760805
INFO:root:eval perplexity: 6.475183010101318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2895.024705386331
INFO:root:eval perplexity: 10.672077178955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [28:31:06<6:50:32, 631.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1261.8428107367622
INFO:root:current train perplexity2.6900851726531982
INFO:root:current mean train loss 1256.225207160501
INFO:root:current train perplexity2.675766706466675
INFO:root:current mean train loss 1254.1423484672935
INFO:root:current train perplexity2.684976100921631
INFO:root:current mean train loss 1256.05090150379
INFO:root:current train perplexity2.6890811920166016
INFO:root:current mean train loss 1256.3606752168148
INFO:root:current train perplexity2.688505172729492
INFO:root:current mean train loss 1254.5931180128412
INFO:root:current train perplexity2.6880688667297363
INFO:root:current mean train loss 1255.3100198229904
INFO:root:current train perplexity2.6862943172454834
INFO:root:current mean train loss 1255.241119053053
INFO:root:current train perplexity2.6900055408477783
INFO:root:current mean train loss 1255.446459172445
INFO:root:current train perplexity2.689368724822998
INFO:root:current mean train loss 1255.314948709602
INFO:root:current train perplexity2.6898038387298584
INFO:root:current mean train loss 1255.419297855333
INFO:root:current train perplexity2.6906747817993164
INFO:root:current mean train loss 1256.0995988442864
INFO:root:current train perplexity2.6915905475616455
INFO:root:current mean train loss 1255.9729019708232
INFO:root:current train perplexity2.6914708614349365
INFO:root:current mean train loss 1256.1072295411618
INFO:root:current train perplexity2.6924052238464355
INFO:root:current mean train loss 1256.089717259314
INFO:root:current train perplexity2.6921145915985107
INFO:root:current mean train loss 1256.6653227806091
INFO:root:current train perplexity2.692030429840088
INFO:root:current mean train loss 1256.902835612775
INFO:root:current train perplexity2.6934380531311035
INFO:root:current mean train loss 1256.584256009572
INFO:root:current train perplexity2.693960189819336
INFO:root:current mean train loss 1256.845855247481
INFO:root:current train perplexity2.694356679916382
INFO:root:current mean train loss 1256.8405618588786
INFO:root:current train perplexity2.693830966949463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.57s/it]
INFO:root:final mean train loss: 1256.471110241496
INFO:root:final train perplexity: 2.693735361099243
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2309.7571337544327
INFO:root:eval perplexity: 6.475306510925293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 2895.979632005624
INFO:root:eval perplexity: 10.680416107177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [28:41:35<6:39:24, 630.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.6655503758843
INFO:root:current train perplexity2.675328493118286
INFO:root:current mean train loss 1254.397345249949
INFO:root:current train perplexity2.673483371734619
INFO:root:current mean train loss 1254.9492853338068
INFO:root:current train perplexity2.672738790512085
INFO:root:current mean train loss 1254.6595773669883
INFO:root:current train perplexity2.676764726638794
INFO:root:current mean train loss 1253.8357313547704
INFO:root:current train perplexity2.680772304534912
INFO:root:current mean train loss 1253.2022365135483
INFO:root:current train perplexity2.6820034980773926
INFO:root:current mean train loss 1252.816480090388
INFO:root:current train perplexity2.6817822456359863
INFO:root:current mean train loss 1252.2101480147119
INFO:root:current train perplexity2.681554079055786
INFO:root:current mean train loss 1252.168448158613
INFO:root:current train perplexity2.680999517440796
INFO:root:current mean train loss 1252.5355266879262
INFO:root:current train perplexity2.6819636821746826
INFO:root:current mean train loss 1253.6481357440423
INFO:root:current train perplexity2.683748483657837
INFO:root:current mean train loss 1254.5570359507128
INFO:root:current train perplexity2.684457778930664
INFO:root:current mean train loss 1254.6226793001483
INFO:root:current train perplexity2.685012102127075
INFO:root:current mean train loss 1255.4978483866869
INFO:root:current train perplexity2.6874306201934814
INFO:root:current mean train loss 1254.6722202077867
INFO:root:current train perplexity2.6876392364501953
INFO:root:current mean train loss 1254.94933453208
INFO:root:current train perplexity2.688525915145874
INFO:root:current mean train loss 1254.8157333494025
INFO:root:current train perplexity2.68867564201355
INFO:root:current mean train loss 1254.8600088185879
INFO:root:current train perplexity2.6887729167938232
INFO:root:current mean train loss 1255.0299198749706
INFO:root:current train perplexity2.6894261837005615
INFO:root:current mean train loss 1255.2824383885568
INFO:root:current train perplexity2.6904850006103516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.54s/it]
INFO:root:final mean train loss: 1255.033045658606
INFO:root:final train perplexity: 2.6906819343566895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 2310.357866003158
INFO:root:eval perplexity: 6.478453636169434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2897.7491571953956
INFO:root:eval perplexity: 10.695883750915527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [28:52:16<6:30:47, 633.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.409756905692
INFO:root:current train perplexity2.699204921722412
INFO:root:current mean train loss 1251.173590446921
INFO:root:current train perplexity2.6888442039489746
INFO:root:current mean train loss 1249.161872016059
INFO:root:current train perplexity2.6858041286468506
INFO:root:current mean train loss 1250.4377975876266
INFO:root:current train perplexity2.6810104846954346
INFO:root:current mean train loss 1250.3396964864528
INFO:root:current train perplexity2.677717924118042
INFO:root:current mean train loss 1252.5035443222314
INFO:root:current train perplexity2.678835153579712
INFO:root:current mean train loss 1251.9521573650304
INFO:root:current train perplexity2.6795501708984375
INFO:root:current mean train loss 1252.2823957170758
INFO:root:current train perplexity2.680636405944824
INFO:root:current mean train loss 1252.3653586902838
INFO:root:current train perplexity2.680675983428955
INFO:root:current mean train loss 1253.1785138631603
INFO:root:current train perplexity2.681597948074341
INFO:root:current mean train loss 1252.7969207478461
INFO:root:current train perplexity2.6825406551361084
INFO:root:current mean train loss 1252.3690658178084
INFO:root:current train perplexity2.6839637756347656
INFO:root:current mean train loss 1252.4111018623892
INFO:root:current train perplexity2.6842219829559326
INFO:root:current mean train loss 1252.291259141908
INFO:root:current train perplexity2.6837704181671143
INFO:root:current mean train loss 1252.350338724357
INFO:root:current train perplexity2.6847283840179443
INFO:root:current mean train loss 1252.6256174269756
INFO:root:current train perplexity2.684190273284912
INFO:root:current mean train loss 1252.8351658986714
INFO:root:current train perplexity2.6846344470977783
INFO:root:current mean train loss 1253.3330573992541
INFO:root:current train perplexity2.6854801177978516
INFO:root:current mean train loss 1253.0719852549507
INFO:root:current train perplexity2.686033010482788
INFO:root:current mean train loss 1253.728950306849
INFO:root:current train perplexity2.6871120929718018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.44s/it]
INFO:root:final mean train loss: 1253.3982505779102
INFO:root:final train perplexity: 2.6872148513793945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2312.014984347296
INFO:root:eval perplexity: 6.487141132354736
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2898.627150948166
INFO:root:eval perplexity: 10.703567504882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [29:02:46<6:19:36, 632.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1243.4705249304059
INFO:root:current train perplexity2.6771726608276367
INFO:root:current mean train loss 1249.3379291391627
INFO:root:current train perplexity2.678189516067505
INFO:root:current mean train loss 1247.3605565725718
INFO:root:current train perplexity2.672501802444458
INFO:root:current mean train loss 1249.0928980312299
INFO:root:current train perplexity2.6721136569976807
INFO:root:current mean train loss 1248.0313846031988
INFO:root:current train perplexity2.672548294067383
INFO:root:current mean train loss 1246.9031813977322
INFO:root:current train perplexity2.673638343811035
INFO:root:current mean train loss 1247.4276455319778
INFO:root:current train perplexity2.6754724979400635
INFO:root:current mean train loss 1248.122140886823
INFO:root:current train perplexity2.6768219470977783
INFO:root:current mean train loss 1248.482416094895
INFO:root:current train perplexity2.6771128177642822
INFO:root:current mean train loss 1247.709971450141
INFO:root:current train perplexity2.677510976791382
INFO:root:current mean train loss 1248.5245537639432
INFO:root:current train perplexity2.678199291229248
INFO:root:current mean train loss 1249.1628861206364
INFO:root:current train perplexity2.678708553314209
INFO:root:current mean train loss 1249.8298815984363
INFO:root:current train perplexity2.6796669960021973
INFO:root:current mean train loss 1249.4471335215112
INFO:root:current train perplexity2.6809475421905518
INFO:root:current mean train loss 1249.847726027919
INFO:root:current train perplexity2.680750846862793
INFO:root:current mean train loss 1250.4523245048883
INFO:root:current train perplexity2.6817641258239746
INFO:root:current mean train loss 1251.0756594257095
INFO:root:current train perplexity2.6831557750701904
INFO:root:current mean train loss 1251.446013157636
INFO:root:current train perplexity2.683499336242676
INFO:root:current mean train loss 1251.5947126541178
INFO:root:current train perplexity2.683175802230835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.25s/it]
INFO:root:final mean train loss: 1251.7266800457699
INFO:root:final train perplexity: 2.6836743354797363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2313.156798450659
INFO:root:eval perplexity: 6.493135452270508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2900.851509256566
INFO:root:eval perplexity: 10.723053932189941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [29:13:25<6:10:12, 634.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.1437683105469
INFO:root:current train perplexity2.6908693313598633
INFO:root:current mean train loss 1241.4322709303635
INFO:root:current train perplexity2.6668546199798584
INFO:root:current mean train loss 1244.0440554151348
INFO:root:current train perplexity2.672023296356201
INFO:root:current mean train loss 1244.7525723105982
INFO:root:current train perplexity2.6721673011779785
INFO:root:current mean train loss 1247.3987611071898
INFO:root:current train perplexity2.6723716259002686
INFO:root:current mean train loss 1247.9998435368614
INFO:root:current train perplexity2.6740834712982178
INFO:root:current mean train loss 1247.2950382864237
INFO:root:current train perplexity2.6763570308685303
INFO:root:current mean train loss 1248.3682231903076
INFO:root:current train perplexity2.6774656772613525
INFO:root:current mean train loss 1248.5553307984005
INFO:root:current train perplexity2.6756155490875244
INFO:root:current mean train loss 1248.642905311247
INFO:root:current train perplexity2.6766886711120605
INFO:root:current mean train loss 1249.3180931060913
INFO:root:current train perplexity2.6773576736450195
INFO:root:current mean train loss 1249.1683415951936
INFO:root:current train perplexity2.677288293838501
INFO:root:current mean train loss 1249.7850231284715
INFO:root:current train perplexity2.6777737140655518
INFO:root:current mean train loss 1250.0801139784737
INFO:root:current train perplexity2.6785128116607666
INFO:root:current mean train loss 1249.4566499106904
INFO:root:current train perplexity2.6786673069000244
INFO:root:current mean train loss 1249.5566345377172
INFO:root:current train perplexity2.68011736869812
INFO:root:current mean train loss 1249.590801895408
INFO:root:current train perplexity2.6803622245788574
INFO:root:current mean train loss 1250.1994489929486
INFO:root:current train perplexity2.680126905441284
INFO:root:current mean train loss 1250.4914759870644
INFO:root:current train perplexity2.6809778213500977
INFO:root:current mean train loss 1250.8034088391216
INFO:root:current train perplexity2.682015895843506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.51s/it]
INFO:root:final mean train loss: 1251.1500825867531
INFO:root:final train perplexity: 2.6824543476104736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2315.811572785073
INFO:root:eval perplexity: 6.507091045379639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2902.869546660295
INFO:root:eval perplexity: 10.740767478942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [29:23:53<5:58:30, 632.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.6259242466517
INFO:root:current train perplexity2.650023937225342
INFO:root:current mean train loss 1245.8928585840652
INFO:root:current train perplexity2.6660468578338623
INFO:root:current mean train loss 1246.7629576808188
INFO:root:current train perplexity2.661681652069092
INFO:root:current mean train loss 1245.4751493745132
INFO:root:current train perplexity2.662146806716919
INFO:root:current mean train loss 1247.322605450193
INFO:root:current train perplexity2.6658883094787598
INFO:root:current mean train loss 1246.1261473672175
INFO:root:current train perplexity2.669450044631958
INFO:root:current mean train loss 1247.2465906803543
INFO:root:current train perplexity2.670673131942749
INFO:root:current mean train loss 1247.8566835273816
INFO:root:current train perplexity2.673246145248413
INFO:root:current mean train loss 1248.2067640632138
INFO:root:current train perplexity2.6725354194641113
INFO:root:current mean train loss 1248.881515718309
INFO:root:current train perplexity2.672825336456299
INFO:root:current mean train loss 1248.3608528757422
INFO:root:current train perplexity2.6726438999176025
INFO:root:current mean train loss 1247.948178593332
INFO:root:current train perplexity2.675107955932617
INFO:root:current mean train loss 1248.8754047015766
INFO:root:current train perplexity2.6750705242156982
INFO:root:current mean train loss 1248.6891341342969
INFO:root:current train perplexity2.67519474029541
INFO:root:current mean train loss 1248.6484624123086
INFO:root:current train perplexity2.6744515895843506
INFO:root:current mean train loss 1249.044536964271
INFO:root:current train perplexity2.6756722927093506
INFO:root:current mean train loss 1249.3559696072784
INFO:root:current train perplexity2.6759226322174072
INFO:root:current mean train loss 1249.2603393767477
INFO:root:current train perplexity2.6762890815734863
INFO:root:current mean train loss 1249.2883245142393
INFO:root:current train perplexity2.677178144454956
INFO:root:current mean train loss 1249.35587232551
INFO:root:current train perplexity2.6778972148895264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.87s/it]
INFO:root:final mean train loss: 1249.087673693189
INFO:root:final train perplexity: 2.6780951023101807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it]
INFO:root:eval mean loss: 2317.4390336706283
INFO:root:eval perplexity: 6.515659809112549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.20s/it]
INFO:root:eval mean loss: 2905.6273141414563
INFO:root:eval perplexity: 10.76501750946045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [29:34:40<5:50:12, 636.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.9436163651317
INFO:root:current train perplexity2.6566288471221924
INFO:root:current mean train loss 1244.8535306626472
INFO:root:current train perplexity2.6641685962677
INFO:root:current mean train loss 1245.9109876616662
INFO:root:current train perplexity2.661719560623169
INFO:root:current mean train loss 1246.0661454962556
INFO:root:current train perplexity2.660429000854492
INFO:root:current mean train loss 1247.3776897273651
INFO:root:current train perplexity2.6647207736968994
INFO:root:current mean train loss 1245.5642257747154
INFO:root:current train perplexity2.663961410522461
INFO:root:current mean train loss 1246.5029069188995
INFO:root:current train perplexity2.6641695499420166
INFO:root:current mean train loss 1247.9859849056254
INFO:root:current train perplexity2.6673502922058105
INFO:root:current mean train loss 1248.5202109398308
INFO:root:current train perplexity2.6675195693969727
INFO:root:current mean train loss 1247.6937391203858
INFO:root:current train perplexity2.668752670288086
INFO:root:current mean train loss 1247.7823692130676
INFO:root:current train perplexity2.671107530593872
INFO:root:current mean train loss 1247.4704556590852
INFO:root:current train perplexity2.6723403930664062
INFO:root:current mean train loss 1247.372187748479
INFO:root:current train perplexity2.6746630668640137
INFO:root:current mean train loss 1247.167446347452
INFO:root:current train perplexity2.6739821434020996
INFO:root:current mean train loss 1247.731613817069
INFO:root:current train perplexity2.6745665073394775
INFO:root:current mean train loss 1247.4847932773387
INFO:root:current train perplexity2.6746373176574707
INFO:root:current mean train loss 1247.7344781412164
INFO:root:current train perplexity2.6750571727752686
INFO:root:current mean train loss 1248.081432276683
INFO:root:current train perplexity2.675637722015381
INFO:root:current mean train loss 1248.2726716715051
INFO:root:current train perplexity2.675722122192383
INFO:root:current mean train loss 1248.7183189116517
INFO:root:current train perplexity2.676499128341675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.22s/it]
INFO:root:final mean train loss: 1248.2436555755662
INFO:root:final train perplexity: 2.6763129234313965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2319.3735684875055
INFO:root:eval perplexity: 6.5258636474609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 2908.4125708180964
INFO:root:eval perplexity: 10.789566993713379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [29:45:10<5:38:38, 634.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1243.69453125
INFO:root:current train perplexity2.6708834171295166
INFO:root:current mean train loss 1241.3969923450102
INFO:root:current train perplexity2.6547014713287354
INFO:root:current mean train loss 1244.0810546875
INFO:root:current train perplexity2.660479784011841
INFO:root:current mean train loss 1244.6782862703565
INFO:root:current train perplexity2.661579132080078
INFO:root:current mean train loss 1244.5461911379637
INFO:root:current train perplexity2.6642844676971436
INFO:root:current mean train loss 1245.6844944309544
INFO:root:current train perplexity2.666699171066284
INFO:root:current mean train loss 1246.175777709029
INFO:root:current train perplexity2.6690773963928223
INFO:root:current mean train loss 1246.8931972074192
INFO:root:current train perplexity2.670031785964966
INFO:root:current mean train loss 1245.9661154228345
INFO:root:current train perplexity2.6699328422546387
INFO:root:current mean train loss 1246.2808620592687
INFO:root:current train perplexity2.670025110244751
INFO:root:current mean train loss 1246.3823193590788
INFO:root:current train perplexity2.6696903705596924
INFO:root:current mean train loss 1246.5285545183983
INFO:root:current train perplexity2.669745683670044
INFO:root:current mean train loss 1247.7356550361055
INFO:root:current train perplexity2.6700243949890137
INFO:root:current mean train loss 1247.372678321754
INFO:root:current train perplexity2.670159339904785
INFO:root:current mean train loss 1247.286704319695
INFO:root:current train perplexity2.671463966369629
INFO:root:current mean train loss 1247.4971264412932
INFO:root:current train perplexity2.672621726989746
INFO:root:current mean train loss 1247.6800544485225
INFO:root:current train perplexity2.674818277359009
INFO:root:current mean train loss 1247.414746858863
INFO:root:current train perplexity2.675062894821167
INFO:root:current mean train loss 1247.8094268552056
INFO:root:current train perplexity2.6755905151367188
INFO:root:current mean train loss 1247.6651212960558
INFO:root:current train perplexity2.6747422218322754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.67s/it]
INFO:root:final mean train loss: 1247.4883935633056
INFO:root:final train perplexity: 2.6747190952301025
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2320.6064080853835
INFO:root:eval perplexity: 6.532371997833252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2908.3072972940213
INFO:root:eval perplexity: 10.7886381149292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [29:55:51<5:29:01, 636.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.634726630317
INFO:root:current train perplexity2.641995906829834
INFO:root:current mean train loss 1242.5906861770984
INFO:root:current train perplexity2.6453819274902344
INFO:root:current mean train loss 1244.492292516372
INFO:root:current train perplexity2.651780843734741
INFO:root:current mean train loss 1244.8758646647136
INFO:root:current train perplexity2.6576623916625977
INFO:root:current mean train loss 1244.671288700427
INFO:root:current train perplexity2.6571788787841797
INFO:root:current mean train loss 1243.649885270979
INFO:root:current train perplexity2.662008047103882
INFO:root:current mean train loss 1242.9472894214448
INFO:root:current train perplexity2.6615712642669678
INFO:root:current mean train loss 1243.2143388659226
INFO:root:current train perplexity2.661391258239746
INFO:root:current mean train loss 1243.2571828299706
INFO:root:current train perplexity2.6626126766204834
INFO:root:current mean train loss 1243.7147906268085
INFO:root:current train perplexity2.6638193130493164
INFO:root:current mean train loss 1242.5807415407096
INFO:root:current train perplexity2.662909507751465
INFO:root:current mean train loss 1243.0553046216737
INFO:root:current train perplexity2.664243221282959
INFO:root:current mean train loss 1243.8827131739204
INFO:root:current train perplexity2.664435386657715
INFO:root:current mean train loss 1243.9661675722884
INFO:root:current train perplexity2.6655733585357666
INFO:root:current mean train loss 1244.3726704638937
INFO:root:current train perplexity2.666414976119995
INFO:root:current mean train loss 1243.9344146961473
INFO:root:current train perplexity2.666496515274048
INFO:root:current mean train loss 1243.8885133004073
INFO:root:current train perplexity2.666931629180908
INFO:root:current mean train loss 1244.3526180775386
INFO:root:current train perplexity2.6677396297454834
INFO:root:current mean train loss 1244.8006808941182
INFO:root:current train perplexity2.6691882610321045
INFO:root:current mean train loss 1245.231055764591
INFO:root:current train perplexity2.6693100929260254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.94s/it]
INFO:root:final mean train loss: 1244.8653421022047
INFO:root:final train perplexity: 2.669191837310791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2320.5151120449636
INFO:root:eval perplexity: 6.531889915466309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2909.9307584289118
INFO:root:eval perplexity: 10.802971839904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [30:06:24<5:17:46, 635.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.6550073516503
INFO:root:current train perplexity2.663235664367676
INFO:root:current mean train loss 1238.945683877935
INFO:root:current train perplexity2.666727304458618
INFO:root:current mean train loss 1243.037503041198
INFO:root:current train perplexity2.6634397506713867
INFO:root:current mean train loss 1242.9330659292657
INFO:root:current train perplexity2.660054922103882
INFO:root:current mean train loss 1243.2939959879059
INFO:root:current train perplexity2.664259910583496
INFO:root:current mean train loss 1241.4749055354016
INFO:root:current train perplexity2.662309169769287
INFO:root:current mean train loss 1242.2550130326447
INFO:root:current train perplexity2.663835287094116
INFO:root:current mean train loss 1242.679704054529
INFO:root:current train perplexity2.662641763687134
INFO:root:current mean train loss 1242.8091354455937
INFO:root:current train perplexity2.6629552841186523
INFO:root:current mean train loss 1243.5474859687026
INFO:root:current train perplexity2.6633288860321045
INFO:root:current mean train loss 1242.9433194695534
INFO:root:current train perplexity2.6624033451080322
INFO:root:current mean train loss 1242.5699632290134
INFO:root:current train perplexity2.6624889373779297
INFO:root:current mean train loss 1243.0250706284244
INFO:root:current train perplexity2.6639442443847656
INFO:root:current mean train loss 1242.9970131881637
INFO:root:current train perplexity2.66426944732666
INFO:root:current mean train loss 1243.1650092212685
INFO:root:current train perplexity2.665025472640991
INFO:root:current mean train loss 1243.5101286862316
INFO:root:current train perplexity2.6663591861724854
INFO:root:current mean train loss 1243.792708636883
INFO:root:current train perplexity2.666999101638794
INFO:root:current mean train loss 1243.944712861148
INFO:root:current train perplexity2.66764235496521
INFO:root:current mean train loss 1244.4670667996666
INFO:root:current train perplexity2.667609691619873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.08s/it]
INFO:root:final mean train loss: 1244.7167365477653
INFO:root:final train perplexity: 2.6688787937164307
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2322.6130171971963
INFO:root:eval perplexity: 6.5429816246032715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2912.205394555491
INFO:root:eval perplexity: 10.82308578491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [30:16:51<5:05:53, 632.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1237.8152465820312
INFO:root:current train perplexity2.676760196685791
INFO:root:current mean train loss 1251.3250536648732
INFO:root:current train perplexity2.6559016704559326
INFO:root:current mean train loss 1241.1605135723225
INFO:root:current train perplexity2.6457133293151855
INFO:root:current mean train loss 1238.6896099015778
INFO:root:current train perplexity2.644404888153076
INFO:root:current mean train loss 1240.0955798520242
INFO:root:current train perplexity2.6500442028045654
INFO:root:current mean train loss 1242.699706307513
INFO:root:current train perplexity2.655153512954712
INFO:root:current mean train loss 1241.494448016579
INFO:root:current train perplexity2.654165267944336
INFO:root:current mean train loss 1240.5585444723242
INFO:root:current train perplexity2.6543257236480713
INFO:root:current mean train loss 1239.8081984602784
INFO:root:current train perplexity2.656137704849243
INFO:root:current mean train loss 1240.169863938759
INFO:root:current train perplexity2.657465696334839
INFO:root:current mean train loss 1239.7815717996707
INFO:root:current train perplexity2.6577436923980713
INFO:root:current mean train loss 1240.0688316524568
INFO:root:current train perplexity2.6582396030426025
INFO:root:current mean train loss 1241.0942913200922
INFO:root:current train perplexity2.6595592498779297
INFO:root:current mean train loss 1241.709007929149
INFO:root:current train perplexity2.6600637435913086
INFO:root:current mean train loss 1242.391736221856
INFO:root:current train perplexity2.660634994506836
INFO:root:current mean train loss 1242.139435179205
INFO:root:current train perplexity2.6614937782287598
INFO:root:current mean train loss 1243.1084220762716
INFO:root:current train perplexity2.6625149250030518
INFO:root:current mean train loss 1243.5897936625329
INFO:root:current train perplexity2.6640167236328125
INFO:root:current mean train loss 1243.6118802126591
INFO:root:current train perplexity2.6651620864868164
INFO:root:current mean train loss 1243.5190236911194
INFO:root:current train perplexity2.6650195121765137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it]
INFO:root:final mean train loss: 1243.3100798006196
INFO:root:final train perplexity: 2.665919780731201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2324.111258865248
INFO:root:eval perplexity: 6.550914764404297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 2913.71221534242
INFO:root:eval perplexity: 10.836435317993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [30:27:34<4:56:51, 636.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1220.5328475288723
INFO:root:current train perplexity2.623258352279663
INFO:root:current mean train loss 1231.485472640371
INFO:root:current train perplexity2.649448871612549
INFO:root:current mean train loss 1233.8874878477088
INFO:root:current train perplexity2.6590821743011475
INFO:root:current mean train loss 1234.4464663101055
INFO:root:current train perplexity2.657231092453003
INFO:root:current mean train loss 1234.7751020427008
INFO:root:current train perplexity2.6540887355804443
INFO:root:current mean train loss 1235.362870458891
INFO:root:current train perplexity2.6580018997192383
INFO:root:current mean train loss 1236.5159531986733
INFO:root:current train perplexity2.6576790809631348
INFO:root:current mean train loss 1236.7209138355809
INFO:root:current train perplexity2.6576006412506104
INFO:root:current mean train loss 1237.8328893019536
INFO:root:current train perplexity2.657869815826416
INFO:root:current mean train loss 1239.424817780632
INFO:root:current train perplexity2.6589303016662598
INFO:root:current mean train loss 1239.2899197366814
INFO:root:current train perplexity2.657930850982666
INFO:root:current mean train loss 1239.2848039526866
INFO:root:current train perplexity2.657867670059204
INFO:root:current mean train loss 1239.639076613444
INFO:root:current train perplexity2.6582531929016113
INFO:root:current mean train loss 1240.988763257039
INFO:root:current train perplexity2.6607511043548584
INFO:root:current mean train loss 1242.0720438739404
INFO:root:current train perplexity2.6604480743408203
INFO:root:current mean train loss 1242.2375812092191
INFO:root:current train perplexity2.66127347946167
INFO:root:current mean train loss 1242.156947673579
INFO:root:current train perplexity2.661621332168579
INFO:root:current mean train loss 1241.9513724443875
INFO:root:current train perplexity2.6620571613311768
INFO:root:current mean train loss 1241.835925246096
INFO:root:current train perplexity2.6628429889678955
INFO:root:current mean train loss 1241.9482607233977
INFO:root:current train perplexity2.662686586380005

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.28s/it]
INFO:root:final mean train loss: 1241.8205319864846
INFO:root:final train perplexity: 2.662789821624756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 2325.3345233024434
INFO:root:eval perplexity: 6.557399749755859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2915.481405921016
INFO:root:eval perplexity: 10.852126121520996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [30:38:08<4:45:52, 635.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1230.6474365234376
INFO:root:current train perplexity2.6507115364074707
INFO:root:current mean train loss 1233.0377903529577
INFO:root:current train perplexity2.6482460498809814
INFO:root:current mean train loss 1238.8684987386068
INFO:root:current train perplexity2.648435592651367
INFO:root:current mean train loss 1238.3961411420037
INFO:root:current train perplexity2.6489193439483643
INFO:root:current mean train loss 1237.8178550026635
INFO:root:current train perplexity2.6520237922668457
INFO:root:current mean train loss 1238.277991852937
INFO:root:current train perplexity2.652825355529785
INFO:root:current mean train loss 1238.6907484054566
INFO:root:current train perplexity2.65311598777771
INFO:root:current mean train loss 1239.1822430584882
INFO:root:current train perplexity2.6521172523498535
INFO:root:current mean train loss 1238.962327212379
INFO:root:current train perplexity2.654534101486206
INFO:root:current mean train loss 1239.9179077148438
INFO:root:current train perplexity2.657338857650757
INFO:root:current mean train loss 1239.7749210064228
INFO:root:current train perplexity2.657400131225586
INFO:root:current mean train loss 1239.2122147409539
INFO:root:current train perplexity2.6580538749694824
INFO:root:current mean train loss 1239.3093033329133
INFO:root:current train perplexity2.6574087142944336
INFO:root:current mean train loss 1238.776253042648
INFO:root:current train perplexity2.6582913398742676
INFO:root:current mean train loss 1239.5300148857964
INFO:root:current train perplexity2.659735679626465
INFO:root:current mean train loss 1239.6302954735695
INFO:root:current train perplexity2.6597325801849365
INFO:root:current mean train loss 1239.8936912722704
INFO:root:current train perplexity2.660181760787964
INFO:root:current mean train loss 1240.4828397202766
INFO:root:current train perplexity2.660813093185425
INFO:root:current mean train loss 1240.5152140741764
INFO:root:current train perplexity2.660778522491455
INFO:root:current mean train loss 1241.0527829514335
INFO:root:current train perplexity2.6610827445983887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.89s/it]
INFO:root:final mean train loss: 1240.9525664498333
INFO:root:final train perplexity: 2.6609675884246826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2326.0102889689992
INFO:root:eval perplexity: 6.560983180999756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2915.914511389766
INFO:root:eval perplexity: 10.855969429016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [30:48:43<4:35:19, 635.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.969760827851
INFO:root:current train perplexity2.665464401245117
INFO:root:current mean train loss 1232.6724954592953
INFO:root:current train perplexity2.6513609886169434
INFO:root:current mean train loss 1232.3610806595027
INFO:root:current train perplexity2.6454148292541504
INFO:root:current mean train loss 1235.0684554583552
INFO:root:current train perplexity2.6465954780578613
INFO:root:current mean train loss 1235.8978036425567
INFO:root:current train perplexity2.6459598541259766
INFO:root:current mean train loss 1235.8247118526986
INFO:root:current train perplexity2.649822950363159
INFO:root:current mean train loss 1235.3953240567328
INFO:root:current train perplexity2.650222063064575
INFO:root:current mean train loss 1235.7773194004396
INFO:root:current train perplexity2.6504433155059814
INFO:root:current mean train loss 1236.2439299575644
INFO:root:current train perplexity2.652447462081909
INFO:root:current mean train loss 1237.489346590909
INFO:root:current train perplexity2.6536123752593994
INFO:root:current mean train loss 1237.4805796180226
INFO:root:current train perplexity2.6542532444000244
INFO:root:current mean train loss 1237.813622582649
INFO:root:current train perplexity2.655452251434326
INFO:root:current mean train loss 1239.034707202168
INFO:root:current train perplexity2.656184434890747
INFO:root:current mean train loss 1239.1765805991502
INFO:root:current train perplexity2.6559200286865234
INFO:root:current mean train loss 1239.3588758270955
INFO:root:current train perplexity2.6566741466522217
INFO:root:current mean train loss 1239.7813609373745
INFO:root:current train perplexity2.656942129135132
INFO:root:current mean train loss 1239.841752083962
INFO:root:current train perplexity2.657240152359009
INFO:root:current mean train loss 1240.1320670860086
INFO:root:current train perplexity2.6581006050109863
INFO:root:current mean train loss 1240.2698084554431
INFO:root:current train perplexity2.657780647277832
INFO:root:current mean train loss 1240.5505619351206
INFO:root:current train perplexity2.6591010093688965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.34s/it]
INFO:root:final mean train loss: 1240.2510560036187
INFO:root:final train perplexity: 2.6594958305358887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2326.6002690741357
INFO:root:eval perplexity: 6.564115524291992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2917.322843943927
INFO:root:eval perplexity: 10.868480682373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [30:59:12<4:23:57, 633.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1232.9154927021748
INFO:root:current train perplexity2.6351053714752197
INFO:root:current mean train loss 1234.1374104817708
INFO:root:current train perplexity2.639070510864258
INFO:root:current mean train loss 1230.580815001996
INFO:root:current train perplexity2.647108793258667
INFO:root:current mean train loss 1231.203730129303
INFO:root:current train perplexity2.648250102996826
INFO:root:current mean train loss 1232.2889159641186
INFO:root:current train perplexity2.648805856704712
INFO:root:current mean train loss 1234.2535704503075
INFO:root:current train perplexity2.651132345199585
INFO:root:current mean train loss 1235.7071576670298
INFO:root:current train perplexity2.6532156467437744
INFO:root:current mean train loss 1236.4375376935461
INFO:root:current train perplexity2.6528074741363525
INFO:root:current mean train loss 1236.9445116405357
INFO:root:current train perplexity2.6537089347839355
INFO:root:current mean train loss 1237.4962618160052
INFO:root:current train perplexity2.6547858715057373
INFO:root:current mean train loss 1237.271478805684
INFO:root:current train perplexity2.6549060344696045
INFO:root:current mean train loss 1237.5898399028097
INFO:root:current train perplexity2.654277801513672
INFO:root:current mean train loss 1238.15599426557
INFO:root:current train perplexity2.654761791229248
INFO:root:current mean train loss 1237.7845085843683
INFO:root:current train perplexity2.6538357734680176
INFO:root:current mean train loss 1238.1582552988784
INFO:root:current train perplexity2.6546239852905273
INFO:root:current mean train loss 1238.463674387756
INFO:root:current train perplexity2.655874252319336
INFO:root:current mean train loss 1239.0267239915854
INFO:root:current train perplexity2.657130241394043
INFO:root:current mean train loss 1239.082736353998
INFO:root:current train perplexity2.657069444656372
INFO:root:current mean train loss 1239.349731119618
INFO:root:current train perplexity2.657360076904297
INFO:root:current mean train loss 1239.5463744746153
INFO:root:current train perplexity2.6570286750793457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it]
INFO:root:final mean train loss: 1239.1474005794862
INFO:root:final train perplexity: 2.657181978225708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2327.8954225364305
INFO:root:eval perplexity: 6.570994853973389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2918.7315219311004
INFO:root:eval perplexity: 10.88100814819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [31:09:53<4:14:16, 635.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.7919452373799
INFO:root:current train perplexity2.6534013748168945
INFO:root:current mean train loss 1235.8946609896516
INFO:root:current train perplexity2.656667947769165
INFO:root:current mean train loss 1236.0801666364637
INFO:root:current train perplexity2.6555817127227783
INFO:root:current mean train loss 1236.5160040111493
INFO:root:current train perplexity2.6513893604278564
INFO:root:current mean train loss 1236.2106321999108
INFO:root:current train perplexity2.651973247528076
INFO:root:current mean train loss 1237.1253548507561
INFO:root:current train perplexity2.6528279781341553
INFO:root:current mean train loss 1238.1649251184313
INFO:root:current train perplexity2.654046058654785
INFO:root:current mean train loss 1237.650352198315
INFO:root:current train perplexity2.6550545692443848
INFO:root:current mean train loss 1237.528030960648
INFO:root:current train perplexity2.6542842388153076
INFO:root:current mean train loss 1237.477387675604
INFO:root:current train perplexity2.652189016342163
INFO:root:current mean train loss 1236.9537614215742
INFO:root:current train perplexity2.653211832046509
INFO:root:current mean train loss 1237.5942867608956
INFO:root:current train perplexity2.6532227993011475
INFO:root:current mean train loss 1237.3069597476217
INFO:root:current train perplexity2.653216600418091
INFO:root:current mean train loss 1237.3123738928548
INFO:root:current train perplexity2.653202772140503
INFO:root:current mean train loss 1237.3439711347512
INFO:root:current train perplexity2.6534481048583984
INFO:root:current mean train loss 1237.5069800280385
INFO:root:current train perplexity2.6535491943359375
INFO:root:current mean train loss 1238.0903988053713
INFO:root:current train perplexity2.654677391052246
INFO:root:current mean train loss 1238.043920707596
INFO:root:current train perplexity2.6547086238861084
INFO:root:current mean train loss 1237.8348206631536
INFO:root:current train perplexity2.6545727252960205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.76s/it]
INFO:root:final mean train loss: 1237.9564313325868
INFO:root:final train perplexity: 2.6546874046325684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2327.4324258574356
INFO:root:eval perplexity: 6.5685343742370605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2917.630624757591
INFO:root:eval perplexity: 10.871216773986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [31:20:24<4:03:06, 634.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1206.4175262451172
INFO:root:current train perplexity2.629457473754883
INFO:root:current mean train loss 1243.0832236961082
INFO:root:current train perplexity2.6595492362976074
INFO:root:current mean train loss 1240.328474191519
INFO:root:current train perplexity2.6592187881469727
INFO:root:current mean train loss 1234.3892207950742
INFO:root:current train perplexity2.6535332202911377
INFO:root:current mean train loss 1235.9224554323682
INFO:root:current train perplexity2.652883291244507
INFO:root:current mean train loss 1234.8650022491695
INFO:root:current train perplexity2.6521897315979004
INFO:root:current mean train loss 1235.4512214660645
INFO:root:current train perplexity2.6544196605682373
INFO:root:current mean train loss 1236.4211467161017
INFO:root:current train perplexity2.6529335975646973
INFO:root:current mean train loss 1236.1068985438583
INFO:root:current train perplexity2.651540756225586
INFO:root:current mean train loss 1236.5280834315631
INFO:root:current train perplexity2.6530399322509766
INFO:root:current mean train loss 1236.8386570763967
INFO:root:current train perplexity2.6523261070251465
INFO:root:current mean train loss 1236.4194268732724
INFO:root:current train perplexity2.6525750160217285
INFO:root:current mean train loss 1236.2194685778081
INFO:root:current train perplexity2.652207612991333
INFO:root:current mean train loss 1235.9982357666763
INFO:root:current train perplexity2.652184247970581
INFO:root:current mean train loss 1236.401951789856
INFO:root:current train perplexity2.6518874168395996
INFO:root:current mean train loss 1235.932562385377
INFO:root:current train perplexity2.6516497135162354
INFO:root:current mean train loss 1236.3883455191085
INFO:root:current train perplexity2.6531755924224854
INFO:root:current mean train loss 1236.7783537603375
INFO:root:current train perplexity2.6536738872528076
INFO:root:current mean train loss 1237.1420491311403
INFO:root:current train perplexity2.653442144393921
INFO:root:current mean train loss 1237.6253454820164
INFO:root:current train perplexity2.6531529426574707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.67s/it]
INFO:root:final mean train loss: 1237.0859173396232
INFO:root:final train perplexity: 2.6528656482696533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it]
INFO:root:eval mean loss: 2329.8046840370125
INFO:root:eval perplexity: 6.58114767074585
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 2921.676161312888
INFO:root:eval perplexity: 10.907244682312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [31:31:06<3:53:26, 636.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1226.73021484375
INFO:root:current train perplexity2.6861772537231445
INFO:root:current mean train loss 1225.5196982421876
INFO:root:current train perplexity2.641561985015869
INFO:root:current mean train loss 1233.4288313802083
INFO:root:current train perplexity2.6424152851104736
INFO:root:current mean train loss 1232.2718596003606
INFO:root:current train perplexity2.6456987857818604
INFO:root:current mean train loss 1232.1054262408088
INFO:root:current train perplexity2.6457388401031494
INFO:root:current mean train loss 1232.7279541015625
INFO:root:current train perplexity2.6453516483306885
INFO:root:current mean train loss 1232.9664912109374
INFO:root:current train perplexity2.6472551822662354
INFO:root:current mean train loss 1232.9518430091596
INFO:root:current train perplexity2.647920846939087
INFO:root:current mean train loss 1233.1725935132577
INFO:root:current train perplexity2.6496787071228027
INFO:root:current mean train loss 1233.6082610589106
INFO:root:current train perplexity2.6490323543548584
INFO:root:current mean train loss 1234.3367840129574
INFO:root:current train perplexity2.6484622955322266
INFO:root:current mean train loss 1234.3469918619792
INFO:root:current train perplexity2.6486434936523438
INFO:root:current mean train loss 1234.224913803412
INFO:root:current train perplexity2.6495580673217773
INFO:root:current mean train loss 1234.8951706220519
INFO:root:current train perplexity2.6490135192871094
INFO:root:current mean train loss 1235.3475645901865
INFO:root:current train perplexity2.6487607955932617
INFO:root:current mean train loss 1235.233077692751
INFO:root:current train perplexity2.6496222019195557
INFO:root:current mean train loss 1235.6422644981972
INFO:root:current train perplexity2.6491096019744873
INFO:root:current mean train loss 1235.5159883803215
INFO:root:current train perplexity2.6492676734924316
INFO:root:current mean train loss 1235.4978454757063
INFO:root:current train perplexity2.6502091884613037
INFO:root:current mean train loss 1235.932375202922
INFO:root:current train perplexity2.650181770324707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.19s/it]
INFO:root:final mean train loss: 1235.9298196351112
INFO:root:final train perplexity: 2.650447368621826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2329.190549593445
INFO:root:eval perplexity: 6.577880859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2920.9329691136136
INFO:root:eval perplexity: 10.900614738464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [31:41:34<3:41:56, 634.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.7718738374256
INFO:root:current train perplexity2.628262758255005
INFO:root:current mean train loss 1228.1532076983385
INFO:root:current train perplexity2.6312460899353027
INFO:root:current mean train loss 1230.451541616897
INFO:root:current train perplexity2.6312406063079834
INFO:root:current mean train loss 1230.700061463473
INFO:root:current train perplexity2.637112855911255
INFO:root:current mean train loss 1231.7715849034926
INFO:root:current train perplexity2.64290714263916
INFO:root:current mean train loss 1233.0629193633245
INFO:root:current train perplexity2.6435658931732178
INFO:root:current mean train loss 1232.3373753437743
INFO:root:current train perplexity2.6437315940856934
INFO:root:current mean train loss 1232.416248414073
INFO:root:current train perplexity2.6451454162597656
INFO:root:current mean train loss 1232.2322639954627
INFO:root:current train perplexity2.6455023288726807
INFO:root:current mean train loss 1231.4523623845128
INFO:root:current train perplexity2.6443212032318115
INFO:root:current mean train loss 1231.8248005169596
INFO:root:current train perplexity2.6447863578796387
INFO:root:current mean train loss 1233.200145607863
INFO:root:current train perplexity2.6457676887512207
INFO:root:current mean train loss 1233.7301835261296
INFO:root:current train perplexity2.6474437713623047
INFO:root:current mean train loss 1234.3437927518978
INFO:root:current train perplexity2.6473300457000732
INFO:root:current mean train loss 1235.0518176625076
INFO:root:current train perplexity2.647918701171875
INFO:root:current mean train loss 1235.6684285323443
INFO:root:current train perplexity2.648236036300659
INFO:root:current mean train loss 1235.658621598684
INFO:root:current train perplexity2.6494510173797607
INFO:root:current mean train loss 1235.1620320124139
INFO:root:current train perplexity2.64864182472229
INFO:root:current mean train loss 1235.434123582871
INFO:root:current train perplexity2.6488304138183594
INFO:root:current mean train loss 1235.7107271141422
INFO:root:current train perplexity2.6495015621185303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.41s/it]
INFO:root:final mean train loss: 1235.1634065952196
INFO:root:final train perplexity: 2.64884614944458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.40s/it]
INFO:root:eval mean loss: 2331.3977436038617
INFO:root:eval perplexity: 6.589632987976074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2923.173451957973
INFO:root:eval perplexity: 10.920605659484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [31:52:26<3:33:05, 639.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.52514027741
INFO:root:current train perplexity2.6132431030273438
INFO:root:current mean train loss 1238.199289381879
INFO:root:current train perplexity2.635019063949585
INFO:root:current mean train loss 1236.5858974383145
INFO:root:current train perplexity2.6423823833465576
INFO:root:current mean train loss 1233.6718566384488
INFO:root:current train perplexity2.6390087604522705
INFO:root:current mean train loss 1233.667372227754
INFO:root:current train perplexity2.639376163482666
INFO:root:current mean train loss 1232.5427781106748
INFO:root:current train perplexity2.641845226287842
INFO:root:current mean train loss 1234.302734375
INFO:root:current train perplexity2.642369270324707
INFO:root:current mean train loss 1234.206930730968
INFO:root:current train perplexity2.640848159790039
INFO:root:current mean train loss 1233.0956803878055
INFO:root:current train perplexity2.6399312019348145
INFO:root:current mean train loss 1231.8483091161447
INFO:root:current train perplexity2.6406989097595215
INFO:root:current mean train loss 1231.081714143834
INFO:root:current train perplexity2.641033411026001
INFO:root:current mean train loss 1231.3711755866116
INFO:root:current train perplexity2.642873764038086
INFO:root:current mean train loss 1232.0686120479422
INFO:root:current train perplexity2.64350962638855
INFO:root:current mean train loss 1232.0893504386268
INFO:root:current train perplexity2.643312692642212
INFO:root:current mean train loss 1232.0875174696923
INFO:root:current train perplexity2.6422879695892334
INFO:root:current mean train loss 1232.3923552037816
INFO:root:current train perplexity2.6436424255371094
INFO:root:current mean train loss 1233.0518264632544
INFO:root:current train perplexity2.643831968307495
INFO:root:current mean train loss 1233.5495787290363
INFO:root:current train perplexity2.644321918487549
INFO:root:current mean train loss 1233.8635646579983
INFO:root:current train perplexity2.6450743675231934
INFO:root:current mean train loss 1233.958333395646
INFO:root:current train perplexity2.6454901695251465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.20s/it]
INFO:root:final mean train loss: 1233.7031310942818
INFO:root:final train perplexity: 2.6457972526550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2331.9452791687445
INFO:root:eval perplexity: 6.592549800872803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2923.9391302014074
INFO:root:eval perplexity: 10.927448272705078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [32:03:00<3:21:56, 637.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1221.963438335218
INFO:root:current train perplexity2.6240386962890625
INFO:root:current mean train loss 1227.6914790760386
INFO:root:current train perplexity2.630150079727173
INFO:root:current mean train loss 1229.7449760989866
INFO:root:current train perplexity2.6329121589660645
INFO:root:current mean train loss 1228.0696579953458
INFO:root:current train perplexity2.6352572441101074
INFO:root:current mean train loss 1229.6032266055836
INFO:root:current train perplexity2.6401095390319824
INFO:root:current mean train loss 1230.2516337500679
INFO:root:current train perplexity2.637402296066284
INFO:root:current mean train loss 1229.600770126433
INFO:root:current train perplexity2.63745379447937
INFO:root:current mean train loss 1230.6305689860865
INFO:root:current train perplexity2.639227867126465
INFO:root:current mean train loss 1231.0905062183397
INFO:root:current train perplexity2.6421756744384766
INFO:root:current mean train loss 1230.269075987769
INFO:root:current train perplexity2.641918420791626
INFO:root:current mean train loss 1230.6084080806008
INFO:root:current train perplexity2.6423027515411377
INFO:root:current mean train loss 1231.340631705563
INFO:root:current train perplexity2.642732858657837
INFO:root:current mean train loss 1232.0403929324732
INFO:root:current train perplexity2.6433205604553223
INFO:root:current mean train loss 1232.0820874058923
INFO:root:current train perplexity2.6432108879089355
INFO:root:current mean train loss 1232.796242235799
INFO:root:current train perplexity2.6443722248077393
INFO:root:current mean train loss 1233.5233545448575
INFO:root:current train perplexity2.645004987716675
INFO:root:current mean train loss 1233.7969693204384
INFO:root:current train perplexity2.6457221508026123
INFO:root:current mean train loss 1234.0810063680012
INFO:root:current train perplexity2.6447160243988037
INFO:root:current mean train loss 1233.9022592247677
INFO:root:current train perplexity2.6444530487060547
INFO:root:current mean train loss 1233.7781456086318
INFO:root:current train perplexity2.6453583240509033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.82s/it]
INFO:root:final mean train loss: 1233.4215844751186
INFO:root:final train perplexity: 2.645210027694702
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2332.848531520113
INFO:root:eval perplexity: 6.597368240356445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2925.253912743102
INFO:root:eval perplexity: 10.939204216003418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [32:13:28<3:10:26, 634.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.1024038663475
INFO:root:current train perplexity2.63822340965271
INFO:root:current mean train loss 1234.236479289791
INFO:root:current train perplexity2.636298418045044
INFO:root:current mean train loss 1231.2694479255547
INFO:root:current train perplexity2.6319353580474854
INFO:root:current mean train loss 1230.9090296621541
INFO:root:current train perplexity2.635958671569824
INFO:root:current mean train loss 1232.4592683803721
INFO:root:current train perplexity2.6369123458862305
INFO:root:current mean train loss 1231.5665104111772
INFO:root:current train perplexity2.6387946605682373
INFO:root:current mean train loss 1231.6462226196113
INFO:root:current train perplexity2.642106294631958
INFO:root:current mean train loss 1232.3099576125078
INFO:root:current train perplexity2.6419801712036133
INFO:root:current mean train loss 1232.2091607139732
INFO:root:current train perplexity2.6417462825775146
INFO:root:current mean train loss 1232.0962482002926
INFO:root:current train perplexity2.6432862281799316
INFO:root:current mean train loss 1232.0273139304452
INFO:root:current train perplexity2.643923282623291
INFO:root:current mean train loss 1232.2497328368936
INFO:root:current train perplexity2.6436960697174072
INFO:root:current mean train loss 1231.8958482498913
INFO:root:current train perplexity2.643385171890259
INFO:root:current mean train loss 1232.2666919103049
INFO:root:current train perplexity2.642965793609619
INFO:root:current mean train loss 1232.299686623514
INFO:root:current train perplexity2.643010377883911
INFO:root:current mean train loss 1232.5743037317807
INFO:root:current train perplexity2.6433568000793457
INFO:root:current mean train loss 1232.5643919816894
INFO:root:current train perplexity2.643080949783325
INFO:root:current mean train loss 1232.4939646340586
INFO:root:current train perplexity2.642909526824951
INFO:root:current mean train loss 1232.8555006701292
INFO:root:current train perplexity2.642679214477539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.94s/it]
INFO:root:final mean train loss: 1232.3951908175054
INFO:root:final train perplexity: 2.6430697441101074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 2334.916018222241
INFO:root:eval perplexity: 6.608410835266113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2927.123878857768
INFO:root:eval perplexity: 10.95594596862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [32:24:11<3:00:34, 637.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1249.212451171875
INFO:root:current train perplexity2.619561195373535
INFO:root:current mean train loss 1230.3316739169034
INFO:root:current train perplexity2.623345136642456
INFO:root:current mean train loss 1229.616190592448
INFO:root:current train perplexity2.62990403175354
INFO:root:current mean train loss 1228.242152454007
INFO:root:current train perplexity2.634171962738037
INFO:root:current mean train loss 1228.1220631669207
INFO:root:current train perplexity2.6375460624694824
INFO:root:current mean train loss 1228.5990784888174
INFO:root:current train perplexity2.640409469604492
INFO:root:current mean train loss 1230.075624359631
INFO:root:current train perplexity2.641566514968872
INFO:root:current mean train loss 1230.042071275308
INFO:root:current train perplexity2.640543222427368
INFO:root:current mean train loss 1230.0814576702353
INFO:root:current train perplexity2.64058518409729
INFO:root:current mean train loss 1230.4867919921876
INFO:root:current train perplexity2.6407647132873535
INFO:root:current mean train loss 1230.676640697517
INFO:root:current train perplexity2.641679048538208
INFO:root:current mean train loss 1230.9076417115357
INFO:root:current train perplexity2.6422722339630127
INFO:root:current mean train loss 1231.790117853338
INFO:root:current train perplexity2.6405727863311768
INFO:root:current mean train loss 1231.8941596344227
INFO:root:current train perplexity2.6404707431793213
INFO:root:current mean train loss 1232.1083547172816
INFO:root:current train perplexity2.640244722366333
INFO:root:current mean train loss 1231.9006410712439
INFO:root:current train perplexity2.6394922733306885
INFO:root:current mean train loss 1231.4476287273146
INFO:root:current train perplexity2.6391499042510986
INFO:root:current mean train loss 1231.5017030593247
INFO:root:current train perplexity2.639357566833496
INFO:root:current mean train loss 1231.108123408365
INFO:root:current train perplexity2.639408588409424
INFO:root:current mean train loss 1231.2251709623486
INFO:root:current train perplexity2.640410900115967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.70s/it]
INFO:root:final mean train loss: 1231.3090979748763
INFO:root:final train perplexity: 2.6408069133758545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2334.768036537982
INFO:root:eval perplexity: 6.60761833190918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2927.858179403535
INFO:root:eval perplexity: 10.962530136108398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [32:34:44<2:49:34, 635.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1227.1941234447338
INFO:root:current train perplexity2.6365981101989746
INFO:root:current mean train loss 1227.2117093304012
INFO:root:current train perplexity2.63834547996521
INFO:root:current mean train loss 1227.3858642578125
INFO:root:current train perplexity2.633258819580078
INFO:root:current mean train loss 1226.3822428385417
INFO:root:current train perplexity2.626007318496704
INFO:root:current mean train loss 1226.3132109809535
INFO:root:current train perplexity2.6272027492523193
INFO:root:current mean train loss 1225.183854104898
INFO:root:current train perplexity2.6286122798919678
INFO:root:current mean train loss 1226.487607234973
INFO:root:current train perplexity2.6275579929351807
INFO:root:current mean train loss 1227.3929659962819
INFO:root:current train perplexity2.628640651702881
INFO:root:current mean train loss 1228.3819560889322
INFO:root:current train perplexity2.6318254470825195
INFO:root:current mean train loss 1229.105663114381
INFO:root:current train perplexity2.6339359283447266
INFO:root:current mean train loss 1229.1458586903602
INFO:root:current train perplexity2.637185573577881
INFO:root:current mean train loss 1229.518917973949
INFO:root:current train perplexity2.6367173194885254
INFO:root:current mean train loss 1230.0976100881214
INFO:root:current train perplexity2.6373395919799805
INFO:root:current mean train loss 1230.3272728995444
INFO:root:current train perplexity2.6385409832000732
INFO:root:current mean train loss 1230.1113319744493
INFO:root:current train perplexity2.638366937637329
INFO:root:current mean train loss 1230.585884818706
INFO:root:current train perplexity2.6382079124450684
INFO:root:current mean train loss 1230.9058668327684
INFO:root:current train perplexity2.6386852264404297
INFO:root:current mean train loss 1230.577635305081
INFO:root:current train perplexity2.638939619064331
INFO:root:current mean train loss 1230.7527897776838
INFO:root:current train perplexity2.6391730308532715
INFO:root:current mean train loss 1230.9564914040202
INFO:root:current train perplexity2.638643264770508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.10s/it]
INFO:root:final mean train loss: 1230.3787388573135
INFO:root:final train perplexity: 2.6388700008392334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2335.4563282635195
INFO:root:eval perplexity: 6.6112961769104
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2928.982246994127
INFO:root:eval perplexity: 10.972613334655762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [32:45:11<2:38:20, 633.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.6610911976206
INFO:root:current train perplexity2.629857301712036
INFO:root:current mean train loss 1225.3551720513237
INFO:root:current train perplexity2.6296207904815674
INFO:root:current mean train loss 1226.609510578093
INFO:root:current train perplexity2.631476879119873
INFO:root:current mean train loss 1226.2038794229197
INFO:root:current train perplexity2.629873275756836
INFO:root:current mean train loss 1226.4745541134396
INFO:root:current train perplexity2.6309702396392822
INFO:root:current mean train loss 1226.084893394919
INFO:root:current train perplexity2.634274482727051
INFO:root:current mean train loss 1226.09367417993
INFO:root:current train perplexity2.6340525150299072
INFO:root:current mean train loss 1226.8745619250883
INFO:root:current train perplexity2.633819818496704
INFO:root:current mean train loss 1229.3137729156638
INFO:root:current train perplexity2.6343843936920166
INFO:root:current mean train loss 1228.9171993449584
INFO:root:current train perplexity2.635338306427002
INFO:root:current mean train loss 1229.3339061517825
INFO:root:current train perplexity2.6348230838775635
INFO:root:current mean train loss 1230.0263043383618
INFO:root:current train perplexity2.6342923641204834
INFO:root:current mean train loss 1230.0212807609337
INFO:root:current train perplexity2.634676933288574
INFO:root:current mean train loss 1229.566931497483
INFO:root:current train perplexity2.633824348449707
INFO:root:current mean train loss 1230.0357978799666
INFO:root:current train perplexity2.635148048400879
INFO:root:current mean train loss 1229.7034870207
INFO:root:current train perplexity2.635166645050049
INFO:root:current mean train loss 1229.3241018030765
INFO:root:current train perplexity2.635329246520996
INFO:root:current mean train loss 1229.4024339728398
INFO:root:current train perplexity2.6360623836517334
INFO:root:current mean train loss 1229.6143097122424
INFO:root:current train perplexity2.636678695678711
INFO:root:current mean train loss 1229.563124166104
INFO:root:current train perplexity2.636955976486206

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.77s/it]
INFO:root:final mean train loss: 1229.45699579236
INFO:root:final train perplexity: 2.6369519233703613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 2335.801624920351
INFO:root:eval perplexity: 6.61314582824707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2929.2302722254544
INFO:root:eval perplexity: 10.974836349487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [32:55:52<2:28:18, 635.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1233.3068867667776
INFO:root:current train perplexity2.6244089603424072
INFO:root:current mean train loss 1237.2860281808037
INFO:root:current train perplexity2.6344871520996094
INFO:root:current mean train loss 1237.7547621452945
INFO:root:current train perplexity2.6399083137512207
INFO:root:current mean train loss 1235.0412695718273
INFO:root:current train perplexity2.640571117401123
INFO:root:current mean train loss 1232.6534471491154
INFO:root:current train perplexity2.637551784515381
INFO:root:current mean train loss 1232.342874183587
INFO:root:current train perplexity2.6361124515533447
INFO:root:current mean train loss 1231.0076841507305
INFO:root:current train perplexity2.6360278129577637
INFO:root:current mean train loss 1229.581999970485
INFO:root:current train perplexity2.637073516845703
INFO:root:current mean train loss 1229.9007769683235
INFO:root:current train perplexity2.637465000152588
INFO:root:current mean train loss 1228.9965022600156
INFO:root:current train perplexity2.636608123779297
INFO:root:current mean train loss 1229.176385848956
INFO:root:current train perplexity2.6367971897125244
INFO:root:current mean train loss 1228.748533579114
INFO:root:current train perplexity2.6364200115203857
INFO:root:current mean train loss 1228.6160890607962
INFO:root:current train perplexity2.63683819770813
INFO:root:current mean train loss 1229.636880284631
INFO:root:current train perplexity2.637033700942993
INFO:root:current mean train loss 1230.145882378695
INFO:root:current train perplexity2.635484457015991
INFO:root:current mean train loss 1229.9447075442424
INFO:root:current train perplexity2.635817050933838
INFO:root:current mean train loss 1229.8420682811795
INFO:root:current train perplexity2.636815309524536
INFO:root:current mean train loss 1229.7146982499512
INFO:root:current train perplexity2.636713743209839
INFO:root:current mean train loss 1229.6294815088074
INFO:root:current train perplexity2.6364009380340576
INFO:root:current mean train loss 1229.3735268148823
INFO:root:current train perplexity2.636319637298584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.20s/it]
INFO:root:final mean train loss: 1229.0647505752017
INFO:root:final train perplexity: 2.636136293411255
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2337.2850709739305
INFO:root:eval perplexity: 6.621082782745361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2930.6319956678026
INFO:root:eval perplexity: 10.987421989440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [33:06:26<2:17:35, 635.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1218.5223592122395
INFO:root:current train perplexity2.6423237323760986
INFO:root:current mean train loss 1227.0640519388605
INFO:root:current train perplexity2.640568733215332
INFO:root:current mean train loss 1225.7060643477405
INFO:root:current train perplexity2.627776622772217
INFO:root:current mean train loss 1226.1740729114997
INFO:root:current train perplexity2.6278014183044434
INFO:root:current mean train loss 1225.2028405097738
INFO:root:current train perplexity2.6282002925872803
INFO:root:current mean train loss 1225.4523866646844
INFO:root:current train perplexity2.630589246749878
INFO:root:current mean train loss 1224.9618935374033
INFO:root:current train perplexity2.6301307678222656
INFO:root:current mean train loss 1225.6715804936034
INFO:root:current train perplexity2.6294913291931152
INFO:root:current mean train loss 1225.8234628316752
INFO:root:current train perplexity2.631396532058716
INFO:root:current mean train loss 1226.7483715221194
INFO:root:current train perplexity2.632051944732666
INFO:root:current mean train loss 1226.890554113158
INFO:root:current train perplexity2.6328976154327393
INFO:root:current mean train loss 1226.9444485779327
INFO:root:current train perplexity2.6329426765441895
INFO:root:current mean train loss 1227.9339682708883
INFO:root:current train perplexity2.6330533027648926
INFO:root:current mean train loss 1228.5328059978513
INFO:root:current train perplexity2.632476329803467
INFO:root:current mean train loss 1229.0081995240084
INFO:root:current train perplexity2.633605718612671
INFO:root:current mean train loss 1229.0602472689668
INFO:root:current train perplexity2.632974624633789
INFO:root:current mean train loss 1228.6592077680368
INFO:root:current train perplexity2.632559061050415
INFO:root:current mean train loss 1228.7664954203722
INFO:root:current train perplexity2.6330699920654297
INFO:root:current mean train loss 1229.164821896944
INFO:root:current train perplexity2.634551763534546
INFO:root:current mean train loss 1229.0765374070834
INFO:root:current train perplexity2.635357618331909

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.06s/it]
INFO:root:final mean train loss: 1228.7564786217517
INFO:root:final train perplexity: 2.635495901107788
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2336.694720761996
INFO:root:eval perplexity: 6.617923259735107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2930.3487864825743
INFO:root:eval perplexity: 10.984881401062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [33:17:08<2:07:25, 637.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.141578433388
INFO:root:current train perplexity2.636221170425415
INFO:root:current mean train loss 1227.6283935546876
INFO:root:current train perplexity2.6247262954711914
INFO:root:current mean train loss 1228.0572770458157
INFO:root:current train perplexity2.6216390132904053
INFO:root:current mean train loss 1227.3243859399722
INFO:root:current train perplexity2.6213674545288086
INFO:root:current mean train loss 1228.5161830709437
INFO:root:current train perplexity2.6261489391326904
INFO:root:current mean train loss 1227.158388589811
INFO:root:current train perplexity2.6258955001831055
INFO:root:current mean train loss 1226.938879306711
INFO:root:current train perplexity2.6264984607696533
INFO:root:current mean train loss 1226.1575368821245
INFO:root:current train perplexity2.626176595687866
INFO:root:current mean train loss 1225.972006890494
INFO:root:current train perplexity2.6257472038269043
INFO:root:current mean train loss 1226.974091036236
INFO:root:current train perplexity2.6270077228546143
INFO:root:current mean train loss 1226.9806461142623
INFO:root:current train perplexity2.6289353370666504
INFO:root:current mean train loss 1227.562408779256
INFO:root:current train perplexity2.630171775817871
INFO:root:current mean train loss 1227.240777328668
INFO:root:current train perplexity2.630995988845825
INFO:root:current mean train loss 1227.1254043633792
INFO:root:current train perplexity2.631957530975342
INFO:root:current mean train loss 1227.5768404447115
INFO:root:current train perplexity2.63230562210083
INFO:root:current mean train loss 1227.5984943641017
INFO:root:current train perplexity2.6332225799560547
INFO:root:current mean train loss 1228.1437371087989
INFO:root:current train perplexity2.6334328651428223
INFO:root:current mean train loss 1228.2771907370734
INFO:root:current train perplexity2.6343324184417725
INFO:root:current mean train loss 1228.1399937773128
INFO:root:current train perplexity2.634596109390259

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.41s/it]
INFO:root:final mean train loss: 1228.0231469751186
INFO:root:final train perplexity: 2.633971691131592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2337.360784003075
INFO:root:eval perplexity: 6.621488571166992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2931.3310512245125
INFO:root:eval perplexity: 10.993708610534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [33:27:38<1:56:26, 635.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.6363728841145
INFO:root:current train perplexity2.6237499713897705
INFO:root:current mean train loss 1226.0646830967494
INFO:root:current train perplexity2.6207339763641357
INFO:root:current mean train loss 1224.2369730247642
INFO:root:current train perplexity2.629154920578003
INFO:root:current mean train loss 1224.6027139516978
INFO:root:current train perplexity2.627047061920166
INFO:root:current mean train loss 1224.105041207619
INFO:root:current train perplexity2.626408338546753
INFO:root:current mean train loss 1224.198987007141
INFO:root:current train perplexity2.6295788288116455
INFO:root:current mean train loss 1225.9125707289752
INFO:root:current train perplexity2.6279993057250977
INFO:root:current mean train loss 1225.950809264451
INFO:root:current train perplexity2.627794027328491
INFO:root:current mean train loss 1226.3230248061307
INFO:root:current train perplexity2.63012957572937
INFO:root:current mean train loss 1225.532340200324
INFO:root:current train perplexity2.631460428237915
INFO:root:current mean train loss 1225.7982686762753
INFO:root:current train perplexity2.6305947303771973
INFO:root:current mean train loss 1226.1317761098737
INFO:root:current train perplexity2.6300156116485596
INFO:root:current mean train loss 1227.0522027849759
INFO:root:current train perplexity2.6307756900787354
INFO:root:current mean train loss 1226.643079525087
INFO:root:current train perplexity2.630953550338745
INFO:root:current mean train loss 1227.1160925846261
INFO:root:current train perplexity2.631946325302124
INFO:root:current mean train loss 1227.5323183574374
INFO:root:current train perplexity2.6319780349731445
INFO:root:current mean train loss 1227.449252523796
INFO:root:current train perplexity2.632844924926758
INFO:root:current mean train loss 1227.377652105884
INFO:root:current train perplexity2.6324262619018555
INFO:root:current mean train loss 1227.6222723482986
INFO:root:current train perplexity2.6326661109924316
INFO:root:current mean train loss 1227.5836164402663
INFO:root:current train perplexity2.6327426433563232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it]
INFO:root:final mean train loss: 1227.3175916801604
INFO:root:final train perplexity: 2.6325066089630127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2337.640676944814
INFO:root:eval perplexity: 6.622987747192383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2931.3291145487033
INFO:root:eval perplexity: 10.993692398071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [33:38:10<1:45:40, 634.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1233.3296656115301
INFO:root:current train perplexity2.6267576217651367
INFO:root:current mean train loss 1220.8761374303538
INFO:root:current train perplexity2.6260173320770264
INFO:root:current mean train loss 1221.1092785164778
INFO:root:current train perplexity2.6219184398651123
INFO:root:current mean train loss 1223.5280832215283
INFO:root:current train perplexity2.626426935195923
INFO:root:current mean train loss 1226.5090491377111
INFO:root:current train perplexity2.628929376602173
INFO:root:current mean train loss 1226.4506891319115
INFO:root:current train perplexity2.629349708557129
INFO:root:current mean train loss 1225.2703350898003
INFO:root:current train perplexity2.629321336746216
INFO:root:current mean train loss 1227.0264231154622
INFO:root:current train perplexity2.6301419734954834
INFO:root:current mean train loss 1226.5023174216865
INFO:root:current train perplexity2.6299045085906982
INFO:root:current mean train loss 1226.6322374949543
INFO:root:current train perplexity2.6308252811431885
INFO:root:current mean train loss 1225.9137342506758
INFO:root:current train perplexity2.63063383102417
INFO:root:current mean train loss 1225.0940527430248
INFO:root:current train perplexity2.6302757263183594
INFO:root:current mean train loss 1225.8471985608219
INFO:root:current train perplexity2.6297919750213623
INFO:root:current mean train loss 1226.378218100428
INFO:root:current train perplexity2.6302576065063477
INFO:root:current mean train loss 1226.5838057542699
INFO:root:current train perplexity2.6311194896698
INFO:root:current mean train loss 1226.982020296405
INFO:root:current train perplexity2.6310226917266846
INFO:root:current mean train loss 1227.1066980707346
INFO:root:current train perplexity2.6322529315948486
INFO:root:current mean train loss 1226.9954956125289
INFO:root:current train perplexity2.6325955390930176
INFO:root:current mean train loss 1227.3105044941096
INFO:root:current train perplexity2.6329140663146973
INFO:root:current mean train loss 1227.3598672047126
INFO:root:current train perplexity2.632458448410034

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.26s/it]
INFO:root:final mean train loss: 1227.3905573473155
INFO:root:final train perplexity: 2.632657766342163
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 2338.2697450894834
INFO:root:eval perplexity: 6.626357078552246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 2932.1629820478724
INFO:root:eval perplexity: 11.00118637084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [33:48:45<1:35:08, 634.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1221.419600777004
INFO:root:current train perplexity2.6102135181427
INFO:root:current mean train loss 1218.2272840526007
INFO:root:current train perplexity2.6153180599212646
INFO:root:current mean train loss 1222.3830675574823
INFO:root:current train perplexity2.6261274814605713
INFO:root:current mean train loss 1223.8134278754967
INFO:root:current train perplexity2.6299657821655273
INFO:root:current mean train loss 1223.345788793179
INFO:root:current train perplexity2.6270992755889893
INFO:root:current mean train loss 1223.475373544099
INFO:root:current train perplexity2.6270267963409424
INFO:root:current mean train loss 1223.7153658556865
INFO:root:current train perplexity2.6277482509613037
INFO:root:current mean train loss 1224.0880747122676
INFO:root:current train perplexity2.627349853515625
INFO:root:current mean train loss 1224.5659621218417
INFO:root:current train perplexity2.6254634857177734
INFO:root:current mean train loss 1224.6706393284223
INFO:root:current train perplexity2.625532865524292
INFO:root:current mean train loss 1225.5123918872491
INFO:root:current train perplexity2.6260836124420166
INFO:root:current mean train loss 1226.2297983219487
INFO:root:current train perplexity2.626600980758667
INFO:root:current mean train loss 1226.4394806545006
INFO:root:current train perplexity2.6286728382110596
INFO:root:current mean train loss 1226.3716398015242
INFO:root:current train perplexity2.628858804702759
INFO:root:current mean train loss 1226.260747505916
INFO:root:current train perplexity2.629441499710083
INFO:root:current mean train loss 1226.2260200530097
INFO:root:current train perplexity2.6302528381347656
INFO:root:current mean train loss 1226.318302567066
INFO:root:current train perplexity2.630737781524658
INFO:root:current mean train loss 1226.9546331905963
INFO:root:current train perplexity2.631234884262085
INFO:root:current mean train loss 1227.2978162507195
INFO:root:current train perplexity2.6314990520477295
INFO:root:current mean train loss 1227.1508095281588
INFO:root:current train perplexity2.6312947273254395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.55s/it]
INFO:root:final mean train loss: 1226.9213959217311
INFO:root:final train perplexity: 2.6316840648651123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 2338.605059684591
INFO:root:eval perplexity: 6.628154754638672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2932.564523683372
INFO:root:eval perplexity: 11.004806518554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [33:59:15<1:24:25, 633.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.1563352554563
INFO:root:current train perplexity2.615659475326538
INFO:root:current mean train loss 1226.213525690184
INFO:root:current train perplexity2.6296329498291016
INFO:root:current mean train loss 1224.3220084882962
INFO:root:current train perplexity2.628723621368408
INFO:root:current mean train loss 1226.1882606695506
INFO:root:current train perplexity2.6249420642852783
INFO:root:current mean train loss 1227.630001982654
INFO:root:current train perplexity2.625725507736206
INFO:root:current mean train loss 1227.6525640402974
INFO:root:current train perplexity2.628969669342041
INFO:root:current mean train loss 1228.2351006095046
INFO:root:current train perplexity2.630847692489624
INFO:root:current mean train loss 1228.6938911727966
INFO:root:current train perplexity2.630605459213257
INFO:root:current mean train loss 1227.9046661978111
INFO:root:current train perplexity2.6307637691497803
INFO:root:current mean train loss 1227.7907935406931
INFO:root:current train perplexity2.631087303161621
INFO:root:current mean train loss 1227.9216688699803
INFO:root:current train perplexity2.632631301879883
INFO:root:current mean train loss 1227.57174270643
INFO:root:current train perplexity2.6320583820343018
INFO:root:current mean train loss 1227.798830444626
INFO:root:current train perplexity2.63226056098938
INFO:root:current mean train loss 1227.1393924749518
INFO:root:current train perplexity2.6312949657440186
INFO:root:current mean train loss 1226.8653213177654
INFO:root:current train perplexity2.632136106491089
INFO:root:current mean train loss 1226.9117071599587
INFO:root:current train perplexity2.6317107677459717
INFO:root:current mean train loss 1227.0642808465734
INFO:root:current train perplexity2.6316070556640625
INFO:root:current mean train loss 1227.3790529005512
INFO:root:current train perplexity2.6305735111236572
INFO:root:current mean train loss 1227.3158575560672
INFO:root:current train perplexity2.63122296333313
INFO:root:current mean train loss 1226.7175676031982
INFO:root:current train perplexity2.6310794353485107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.46s/it]
INFO:root:final mean train loss: 1226.6078461970696
INFO:root:final train perplexity: 2.631033420562744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2338.6818371495456
INFO:root:eval perplexity: 6.628567218780518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2932.1596463250776
INFO:root:eval perplexity: 11.00115966796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [34:09:44<1:13:43, 631.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.2570053100585
INFO:root:current train perplexity2.621992588043213
INFO:root:current mean train loss 1225.848873562283
INFO:root:current train perplexity2.6325857639312744
INFO:root:current mean train loss 1224.6978642054967
INFO:root:current train perplexity2.6333248615264893
INFO:root:current mean train loss 1225.2406066894532
INFO:root:current train perplexity2.633643388748169
INFO:root:current mean train loss 1226.015338643392
INFO:root:current train perplexity2.630277395248413
INFO:root:current mean train loss 1225.0601128939925
INFO:root:current train perplexity2.6277875900268555
INFO:root:current mean train loss 1224.288595042509
INFO:root:current train perplexity2.625551700592041
INFO:root:current mean train loss 1224.6197436210437
INFO:root:current train perplexity2.6264681816101074
INFO:root:current mean train loss 1224.5345360495828
INFO:root:current train perplexity2.6254684925079346
INFO:root:current mean train loss 1224.547812574737
INFO:root:current train perplexity2.6250832080841064
INFO:root:current mean train loss 1224.0316076208044
INFO:root:current train perplexity2.6247189044952393
INFO:root:current mean train loss 1224.4025308899961
INFO:root:current train perplexity2.624911308288574
INFO:root:current mean train loss 1224.0539346694945
INFO:root:current train perplexity2.6240696907043457
INFO:root:current mean train loss 1224.48610751387
INFO:root:current train perplexity2.624389410018921
INFO:root:current mean train loss 1224.2720374030037
INFO:root:current train perplexity2.6250884532928467
INFO:root:current mean train loss 1224.0287341154074
INFO:root:current train perplexity2.6259477138519287
INFO:root:current mean train loss 1224.1016708374023
INFO:root:current train perplexity2.6263062953948975
INFO:root:current mean train loss 1224.59934095747
INFO:root:current train perplexity2.6265809535980225
INFO:root:current mean train loss 1224.888769141664
INFO:root:current train perplexity2.627474784851074
INFO:root:current mean train loss 1225.0501999980272
INFO:root:current train perplexity2.6271820068359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.80s/it]
INFO:root:final mean train loss: 1224.6789171273697
INFO:root:final train perplexity: 2.6270341873168945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2339.217970394919
INFO:root:eval perplexity: 6.631441593170166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2933.4110202654033
INFO:root:eval perplexity: 11.012423515319824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [34:20:27<1:03:30, 635.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1215.0119389799452
INFO:root:current train perplexity2.6256535053253174
INFO:root:current mean train loss 1215.9926980885152
INFO:root:current train perplexity2.6181294918060303
INFO:root:current mean train loss 1218.70071565262
INFO:root:current train perplexity2.6228044033050537
INFO:root:current mean train loss 1221.0060663103156
INFO:root:current train perplexity2.619076728820801
INFO:root:current mean train loss 1221.7723280601579
INFO:root:current train perplexity2.6183531284332275
INFO:root:current mean train loss 1221.0365718157846
INFO:root:current train perplexity2.6199886798858643
INFO:root:current mean train loss 1220.6768672729668
INFO:root:current train perplexity2.622441530227661
INFO:root:current mean train loss 1221.496279535808
INFO:root:current train perplexity2.6226611137390137
INFO:root:current mean train loss 1222.8750140169925
INFO:root:current train perplexity2.6230857372283936
INFO:root:current mean train loss 1223.049288000721
INFO:root:current train perplexity2.625187397003174
INFO:root:current mean train loss 1223.58704414472
INFO:root:current train perplexity2.6262776851654053
INFO:root:current mean train loss 1223.7110169425844
INFO:root:current train perplexity2.6264376640319824
INFO:root:current mean train loss 1223.905677013059
INFO:root:current train perplexity2.6250925064086914
INFO:root:current mean train loss 1223.8340926392214
INFO:root:current train perplexity2.624796152114868
INFO:root:current mean train loss 1223.647705893558
INFO:root:current train perplexity2.625324249267578
INFO:root:current mean train loss 1224.2099798175045
INFO:root:current train perplexity2.624943494796753
INFO:root:current mean train loss 1224.391571278704
INFO:root:current train perplexity2.6256136894226074
INFO:root:current mean train loss 1224.543759455864
INFO:root:current train perplexity2.625598907470703
INFO:root:current mean train loss 1224.6784848146333
INFO:root:current train perplexity2.6257872581481934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.35s/it]
INFO:root:final mean train loss: 1224.1623099014967
INFO:root:final train perplexity: 2.6259639263153076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 2339.9881215196974
INFO:root:eval perplexity: 6.63557243347168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2934.020087492381
INFO:root:eval perplexity: 11.017911911010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [34:31:04<52:59, 635.88s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1208.2810668945312
INFO:root:current train perplexity2.64636492729187
INFO:root:current mean train loss 1224.4140175267269
INFO:root:current train perplexity2.630370855331421
INFO:root:current mean train loss 1225.577037205206
INFO:root:current train perplexity2.6275224685668945
INFO:root:current mean train loss 1224.7361049773588
INFO:root:current train perplexity2.6245667934417725
INFO:root:current mean train loss 1224.5909235120396
INFO:root:current train perplexity2.6250360012054443
INFO:root:current mean train loss 1224.459980649243
INFO:root:current train perplexity2.6267991065979004
INFO:root:current mean train loss 1223.465557483586
INFO:root:current train perplexity2.626131534576416
INFO:root:current mean train loss 1223.6693503329066
INFO:root:current train perplexity2.625469207763672
INFO:root:current mean train loss 1224.9417318208211
INFO:root:current train perplexity2.6260950565338135
INFO:root:current mean train loss 1225.2168446880983
INFO:root:current train perplexity2.6269259452819824
INFO:root:current mean train loss 1224.582429724097
INFO:root:current train perplexity2.6269264221191406
INFO:root:current mean train loss 1224.1616534193713
INFO:root:current train perplexity2.626621961593628
INFO:root:current mean train loss 1224.3422676601756
INFO:root:current train perplexity2.6263394355773926
INFO:root:current mean train loss 1224.2739399949164
INFO:root:current train perplexity2.6261978149414062
INFO:root:current mean train loss 1224.0967478880282
INFO:root:current train perplexity2.625654458999634
INFO:root:current mean train loss 1224.9243358375218
INFO:root:current train perplexity2.625256299972534
INFO:root:current mean train loss 1225.1455593180035
INFO:root:current train perplexity2.625582218170166
INFO:root:current mean train loss 1225.1646645188748
INFO:root:current train perplexity2.6262283325195312
INFO:root:current mean train loss 1224.9744886505564
INFO:root:current train perplexity2.6260578632354736
INFO:root:current mean train loss 1224.6142303881352
INFO:root:current train perplexity2.6254186630249023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it]
INFO:root:final mean train loss: 1224.343727531183
INFO:root:final train perplexity: 2.6263391971588135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2340.5394373684067
INFO:root:eval perplexity: 6.638532638549805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2934.632613811087
INFO:root:eval perplexity: 11.023432731628418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [34:41:32<42:14, 633.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.6334582913307
INFO:root:current train perplexity2.6446235179901123
INFO:root:current mean train loss 1223.6567848729724
INFO:root:current train perplexity2.626481771469116
INFO:root:current mean train loss 1225.6974125321294
INFO:root:current train perplexity2.621180534362793
INFO:root:current mean train loss 1224.0220172801407
INFO:root:current train perplexity2.6203343868255615
INFO:root:current mean train loss 1225.0560149792452
INFO:root:current train perplexity2.624340295791626
INFO:root:current mean train loss 1226.430835788533
INFO:root:current train perplexity2.6259844303131104
INFO:root:current mean train loss 1226.7521223984127
INFO:root:current train perplexity2.6254324913024902
INFO:root:current mean train loss 1226.1343396313375
INFO:root:current train perplexity2.6255452632904053
INFO:root:current mean train loss 1225.9968824329217
INFO:root:current train perplexity2.625584125518799
INFO:root:current mean train loss 1225.2074374517488
INFO:root:current train perplexity2.6251187324523926
INFO:root:current mean train loss 1224.7890923367786
INFO:root:current train perplexity2.6255180835723877
INFO:root:current mean train loss 1223.877262887862
INFO:root:current train perplexity2.6254968643188477
INFO:root:current mean train loss 1224.1944101118247
INFO:root:current train perplexity2.6248342990875244
INFO:root:current mean train loss 1224.4927133836754
INFO:root:current train perplexity2.625728130340576
INFO:root:current mean train loss 1224.3505428588783
INFO:root:current train perplexity2.626268148422241
INFO:root:current mean train loss 1223.8151601122377
INFO:root:current train perplexity2.6255428791046143
INFO:root:current mean train loss 1223.4427961002166
INFO:root:current train perplexity2.6248667240142822
INFO:root:current mean train loss 1223.4463212901908
INFO:root:current train perplexity2.6244418621063232
INFO:root:current mean train loss 1223.6641739033273
INFO:root:current train perplexity2.6251869201660156
INFO:root:current mean train loss 1223.8670381203272
INFO:root:current train perplexity2.6249470710754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.18s/it]
INFO:root:final mean train loss: 1223.430760709192
INFO:root:final train perplexity: 2.6244492530822754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2340.361976569426
INFO:root:eval perplexity: 6.637578964233398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2934.363840089622
INFO:root:eval perplexity: 11.02100944519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [34:52:00<31:35, 631.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1226.3186340332031
INFO:root:current train perplexity2.640554904937744
INFO:root:current mean train loss 1221.5754510003167
INFO:root:current train perplexity2.628221035003662
INFO:root:current mean train loss 1217.7157750283518
INFO:root:current train perplexity2.616560935974121
INFO:root:current mean train loss 1219.6529611170977
INFO:root:current train perplexity2.616457462310791
INFO:root:current mean train loss 1219.1034772055489
INFO:root:current train perplexity2.6172852516174316
INFO:root:current mean train loss 1220.8876378414404
INFO:root:current train perplexity2.615295886993408
INFO:root:current mean train loss 1220.5435069519797
INFO:root:current train perplexity2.616410732269287
INFO:root:current mean train loss 1220.7728947114178
INFO:root:current train perplexity2.6181724071502686
INFO:root:current mean train loss 1221.6977091375386
INFO:root:current train perplexity2.6186840534210205
INFO:root:current mean train loss 1222.3173691632878
INFO:root:current train perplexity2.6225805282592773
INFO:root:current mean train loss 1223.158033298172
INFO:root:current train perplexity2.6238925457000732
INFO:root:current mean train loss 1223.1863284227325
INFO:root:current train perplexity2.6248137950897217
INFO:root:current mean train loss 1223.4471455109426
INFO:root:current train perplexity2.6251678466796875
INFO:root:current mean train loss 1223.9336763376298
INFO:root:current train perplexity2.6252264976501465
INFO:root:current mean train loss 1224.0417450962805
INFO:root:current train perplexity2.6239945888519287
INFO:root:current mean train loss 1224.1609842463058
INFO:root:current train perplexity2.6242921352386475
INFO:root:current mean train loss 1224.0338914000872
INFO:root:current train perplexity2.6243209838867188
INFO:root:current mean train loss 1223.8543860394022
INFO:root:current train perplexity2.6244261264801025
INFO:root:current mean train loss 1223.9668826148622
INFO:root:current train perplexity2.6242825984954834
INFO:root:current mean train loss 1223.8893824269885
INFO:root:current train perplexity2.624535322189331

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.37s/it]
INFO:root:final mean train loss: 1223.4318788560183
INFO:root:final train perplexity: 2.6244516372680664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2340.634584251025
INFO:root:eval perplexity: 6.639043807983398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2934.847799098238
INFO:root:eval perplexity: 11.025374412536621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [35:02:34<21:04, 632.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1209.7418719951922
INFO:root:current train perplexity2.6315345764160156
INFO:root:current mean train loss 1217.4888139204545
INFO:root:current train perplexity2.622535467147827
INFO:root:current mean train loss 1220.0500391546286
INFO:root:current train perplexity2.6242787837982178
INFO:root:current mean train loss 1220.4421443573417
INFO:root:current train perplexity2.629481077194214
INFO:root:current mean train loss 1221.0243654968917
INFO:root:current train perplexity2.6266980171203613
INFO:root:current mean train loss 1221.0878586490596
INFO:root:current train perplexity2.626580238342285
INFO:root:current mean train loss 1221.4522136028547
INFO:root:current train perplexity2.627699851989746
INFO:root:current mean train loss 1222.2956467971303
INFO:root:current train perplexity2.6293246746063232
INFO:root:current mean train loss 1222.0510848028812
INFO:root:current train perplexity2.628025770187378
INFO:root:current mean train loss 1221.9146184575372
INFO:root:current train perplexity2.6286659240722656
INFO:root:current mean train loss 1222.9169663979974
INFO:root:current train perplexity2.628321647644043
INFO:root:current mean train loss 1222.9845402402427
INFO:root:current train perplexity2.626987934112549
INFO:root:current mean train loss 1223.0908746410264
INFO:root:current train perplexity2.627194404602051
INFO:root:current mean train loss 1223.3953864576179
INFO:root:current train perplexity2.6264288425445557
INFO:root:current mean train loss 1223.2672334117694
INFO:root:current train perplexity2.6269211769104004
INFO:root:current mean train loss 1223.7037232615316
INFO:root:current train perplexity2.626159191131592
INFO:root:current mean train loss 1223.3835027654607
INFO:root:current train perplexity2.6256906986236572
INFO:root:current mean train loss 1223.5014735581178
INFO:root:current train perplexity2.624568223953247
INFO:root:current mean train loss 1223.5464716770693
INFO:root:current train perplexity2.6244394779205322
INFO:root:current mean train loss 1223.7514080018489
INFO:root:current train perplexity2.6244583129882812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.30s/it]
INFO:root:final mean train loss: 1223.3955132911979
INFO:root:final train perplexity: 2.6243765354156494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 2340.732293744459
INFO:root:eval perplexity: 6.639567852020264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2935.0474814557015
INFO:root:eval perplexity: 11.027173042297363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [35:13:04<10:31, 631.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1210.031610256288
INFO:root:current train perplexity2.635504722595215
INFO:root:current mean train loss 1216.1874671349158
INFO:root:current train perplexity2.6212306022644043
INFO:root:current mean train loss 1218.1684189383866
INFO:root:current train perplexity2.620577812194824
INFO:root:current mean train loss 1217.762237708606
INFO:root:current train perplexity2.6195452213287354
INFO:root:current mean train loss 1221.3598184546
INFO:root:current train perplexity2.622619390487671
INFO:root:current mean train loss 1222.6319754164654
INFO:root:current train perplexity2.623868227005005
INFO:root:current mean train loss 1223.1533009817174
INFO:root:current train perplexity2.624377965927124
INFO:root:current mean train loss 1223.83926867707
INFO:root:current train perplexity2.623263359069824
INFO:root:current mean train loss 1222.8776441647622
INFO:root:current train perplexity2.623136043548584
INFO:root:current mean train loss 1222.6438704294487
INFO:root:current train perplexity2.6246585845947266
INFO:root:current mean train loss 1223.4249084811113
INFO:root:current train perplexity2.6245334148406982
INFO:root:current mean train loss 1223.247316621887
INFO:root:current train perplexity2.6244876384735107
INFO:root:current mean train loss 1223.6638083614164
INFO:root:current train perplexity2.6249406337738037
INFO:root:current mean train loss 1223.9839613565316
INFO:root:current train perplexity2.6255340576171875
INFO:root:current mean train loss 1223.5726665131315
INFO:root:current train perplexity2.624952793121338
INFO:root:current mean train loss 1223.5311334853527
INFO:root:current train perplexity2.6248838901519775
INFO:root:current mean train loss 1224.0174694809705
INFO:root:current train perplexity2.6247401237487793
INFO:root:current mean train loss 1224.1104577403812
INFO:root:current train perplexity2.625103235244751
INFO:root:current mean train loss 1224.089685616407
INFO:root:current train perplexity2.62554669380188
INFO:root:current mean train loss 1224.0422420559448
INFO:root:current train perplexity2.62506103515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.97s/it]
INFO:root:final mean train loss: 1223.73218062762
INFO:root:final train perplexity: 2.6250734329223633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 2340.7369280875996
INFO:root:eval perplexity: 6.639592170715332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2934.9738501149714
INFO:root:eval perplexity: 11.026507377624512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_allminilml12/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:23:46<00:00, 634.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:23:46<00:00, 637.13s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.41s/it]
INFO:root:eval mean loss: 2340.7369280875996
INFO:root:eval perplexity: 6.639592170715332
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.24s/it]
INFO:root:eval mean loss: 2934.9738501149714
INFO:root:eval perplexity: 11.026507377624512
INFO:root:evalaution complete
INFO:root:save model final: allminil12_allminilml12/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x154dbcc1ef06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x154dbcc168e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x154dbcb3be09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154dbcc1fa3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x154dbcb39948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154dbcc1fa3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x154dbcaf4b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x154dbc55946a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x154eb8d75a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x154eb8d75be0]
python(+0x24a989) [0x560c80552989]
python(+0x24a9bd) [0x560c805529bd]
python(+0x24aa14) [0x560c80552a14]
python(+0x108f75) [0x560c80410f75]
python(Py_RunMain+0x313) [0x560c80555983]
python(Py_BytesMain+0x39) [0x560c80555bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x154eb8d530b3]
python(+0x1d6e13) [0x560c804dee13]
/opt/slurm/data/slurmd/job29440791/slurm_script: line 224: 4183425 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L12-v2 --data_config data_config.json --data_folder fast_processed_data_allminil12_final --output allminil12_allminilml12 --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval
"
