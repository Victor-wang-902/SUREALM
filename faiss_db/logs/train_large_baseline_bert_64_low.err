INFO:root:Output: big_baseline_base_64_low
INFO:root:Steps per epochs:496
INFO:root:Total steps:99200
Some weights of the model checkpoint at bert-base-uncased were not used when initializing RetrievalGenerationModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing RetrievalGenerationModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RetrievalGenerationModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 36399.21141098485
INFO:root:current train perplexity1325.822509765625
INFO:root:current mean train loss 31390.965000785174
INFO:root:current train perplexity491.01165771484375
INFO:root:current mean train loss 27413.43829692726
INFO:root:current train perplexity223.1145477294922
INFO:root:current mean train loss 24628.972188772714
INFO:root:current train perplexity128.44891357421875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 14076.799409412202
INFO:root:eval perplexity: 18.426252365112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/1

  0%|          | 1/200 [05:47<19:13:15, 347.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13452.542643229166
INFO:root:current train perplexity14.55611515045166
INFO:root:current mean train loss 13235.04156553398
INFO:root:current train perplexity13.62351131439209
INFO:root:current mean train loss 12880.678494458129
INFO:root:current train perplexity12.682394981384277
INFO:root:current mean train loss 12600.559119095504
INFO:root:current train perplexity11.972651481628418
INFO:root:current mean train loss 12336.395115248913
INFO:root:current train perplexity11.389358520507812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 12327.291785830543
INFO:root:eval perplexity: 12.828165054321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/2

  1%|          | 2/200 [11:26<18:50:33, 342.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10999.211635044643
INFO:root:current train perplexity8.755247116088867
INFO:root:current mean train loss 10974.820422021028
INFO:root:current train perplexity8.689159393310547
INFO:root:current mean train loss 10881.590744829407
INFO:root:current train perplexity8.554404258728027
INFO:root:current mean train loss 10794.546693683835
INFO:root:current train perplexity8.408415794372559
INFO:root:current mean train loss 10728.048329046376
INFO:root:current train perplexity8.287224769592285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 11835.126055036273
INFO:root:eval perplexity: 11.585670471191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/3

  2%|â–         | 3/200 [17:05<18:39:43, 341.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10272.376420454546
INFO:root:current train perplexity7.5005903244018555
INFO:root:current mean train loss 10221.732518651464
INFO:root:current train perplexity7.486956596374512
INFO:root:current mean train loss 10168.388010034065
INFO:root:current train perplexity7.417668342590332
INFO:root:current mean train loss 10130.439509646303
INFO:root:current train perplexity7.36762809753418
INFO:root:current mean train loss 10097.611249714872
INFO:root:current train perplexity7.317959308624268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11617.054626464844
INFO:root:eval perplexity: 11.074334144592285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/4

  2%|â–         | 4/200 [22:45<18:31:46, 340.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9691.446419270833
INFO:root:current train perplexity6.934134006500244
INFO:root:current mean train loss 9803.70613111413
INFO:root:current train perplexity6.8928961753845215
INFO:root:current mean train loss 9789.37788880814
INFO:root:current train perplexity6.867918968200684
INFO:root:current mean train loss 9755.934554811507
INFO:root:current train perplexity6.8359904289245605
INFO:root:current mean train loss 9725.280647590362
INFO:root:current train perplexity6.804568290710449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11456.927528018043
INFO:root:eval perplexity: 10.713292121887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/5

  2%|â–Ž         | 5/200 [28:24<18:24:45, 339.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9628.773231907895
INFO:root:current train perplexity6.565311431884766
INFO:root:current mean train loss 9502.448332457983
INFO:root:current train perplexity6.519982814788818
INFO:root:current mean train loss 9498.472232626998
INFO:root:current train perplexity6.5104498863220215
INFO:root:current mean train loss 9489.758590076412
INFO:root:current train perplexity6.4810872077941895
INFO:root:current mean train loss 9471.115572326224
INFO:root:current train perplexity6.46165132522583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11379.6242414202
INFO:root:eval perplexity: 10.543232917785645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/6

  3%|â–Ž         | 6/200 [34:04<18:18:55, 339.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9407.023692255434
INFO:root:current train perplexity6.278834819793701
INFO:root:current mean train loss 9285.644213668698
INFO:root:current train perplexity6.223305702209473
INFO:root:current mean train loss 9291.755933821469
INFO:root:current train perplexity6.226722717285156
INFO:root:current mean train loss 9280.987809597524
INFO:root:current train perplexity6.220231056213379
INFO:root:current mean train loss 9270.763050845893
INFO:root:current train perplexity6.213198184967041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11280.67247953869
INFO:root:eval perplexity: 10.329480171203613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/7

  4%|â–Ž         | 7/200 [39:43<18:12:47, 339.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9133.441080729166
INFO:root:current train perplexity6.002633571624756
INFO:root:current mean train loss 9144.684485728347
INFO:root:current train perplexity6.048742294311523
INFO:root:current mean train loss 9107.295687637665
INFO:root:current train perplexity6.026561737060547
INFO:root:current mean train loss 9105.425467674886
INFO:root:current train perplexity6.021716594696045
INFO:root:current mean train loss 9102.315800186621
INFO:root:current train perplexity6.019705772399902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11243.408505394345
INFO:root:eval perplexity: 10.250114440917969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/8

  4%|â–         | 8/200 [45:23<18:07:15, 339.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9037.168126260081
INFO:root:current train perplexity5.9086689949035645
INFO:root:current mean train loss 9001.836116412214
INFO:root:current train perplexity5.872251033782959
INFO:root:current mean train loss 8987.090541294643
INFO:root:current train perplexity5.870849132537842
INFO:root:current mean train loss 8984.404330803909
INFO:root:current train perplexity5.86942720413208
INFO:root:current mean train loss 8971.139492096867
INFO:root:current train perplexity5.860757827758789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11185.746643066406
INFO:root:eval perplexity: 10.128499031066895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/9

  4%|â–         | 9/200 [51:02<18:00:40, 339.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8862.832589285714
INFO:root:current train perplexity5.790097713470459
INFO:root:current mean train loss 8837.344994212963
INFO:root:current train perplexity5.714737415313721
INFO:root:current mean train loss 8856.900935006648
INFO:root:current train perplexity5.715893268585205
INFO:root:current mean train loss 8867.624517548973
INFO:root:current train perplexity5.724620342254639
INFO:root:current mean train loss 8856.150587059985
INFO:root:current train perplexity5.723135471343994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11160.240025111607
INFO:root:eval perplexity: 10.075163841247559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/10

  5%|â–Œ         | 10/200 [56:41<17:54:47, 339.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8719.315630008014
INFO:root:current train perplexity5.618142127990723
INFO:root:current mean train loss 8754.249522257194
INFO:root:current train perplexity5.600606918334961
INFO:root:current mean train loss 8754.600357119509
INFO:root:current train perplexity5.606288909912109
INFO:root:current mean train loss 8748.177992199024
INFO:root:current train perplexity5.603262901306152
INFO:root:current mean train loss 8741.950154158954
INFO:root:current train perplexity5.603432655334473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11140.540190197173
INFO:root:eval perplexity: 10.034164428710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/11

  6%|â–Œ         | 11/200 [1:02:21<17:49:41, 339.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8683.458212209302
INFO:root:current train perplexity5.543419361114502
INFO:root:current mean train loss 8674.710964816433
INFO:root:current train perplexity5.518439769744873
INFO:root:current mean train loss 8654.129916972093
INFO:root:current train perplexity5.494018077850342
INFO:root:current mean train loss 8657.007475116163
INFO:root:current train perplexity5.501893997192383
INFO:root:current mean train loss 8650.693736332534
INFO:root:current train perplexity5.501383304595947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 11116.542448497954
INFO:root:eval perplexity: 9.984443664550781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/12

  6%|â–Œ         | 12/200 [1:08:01<17:43:57, 339.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8519.539394946809
INFO:root:current train perplexity5.390960216522217
INFO:root:current mean train loss 8556.210778061224
INFO:root:current train perplexity5.403136253356934
INFO:root:current mean train loss 8563.685147551872
INFO:root:current train perplexity5.411222457885742
INFO:root:current mean train loss 8564.244095596181
INFO:root:current train perplexity5.409807205200195
INFO:root:current mean train loss 8564.864102698546
INFO:root:current train perplexity5.411473751068115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11092.767296200707
INFO:root:eval perplexity: 9.935431480407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/13

  6%|â–‹         | 13/200 [1:13:40<17:38:09, 339.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8485.782992493872
INFO:root:current train perplexity5.318567276000977
INFO:root:current mean train loss 8486.627919986548
INFO:root:current train perplexity5.317397117614746
INFO:root:current mean train loss 8495.057566608566
INFO:root:current train perplexity5.321531772613525
INFO:root:current mean train loss 8489.390140892094
INFO:root:current train perplexity5.3190436363220215
INFO:root:current mean train loss 8493.104062370081
INFO:root:current train perplexity5.330000877380371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11076.802600678944
INFO:root:eval perplexity: 9.9026517868042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/14

  7%|â–‹         | 14/200 [1:19:19<17:32:31, 339.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8400.916956676136
INFO:root:current train perplexity5.266022205352783
INFO:root:current mean train loss 8398.656313004032
INFO:root:current train perplexity5.256194591522217
INFO:root:current mean train loss 8418.314592907476
INFO:root:current train perplexity5.262275218963623
INFO:root:current mean train loss 8414.740942726672
INFO:root:current train perplexity5.255049705505371
INFO:root:current mean train loss 8415.732897278504
INFO:root:current train perplexity5.252737998962402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11069.616213843936
INFO:root:eval perplexity: 9.887932777404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/15

  8%|â–Š         | 15/200 [1:24:59<17:26:37, 339.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8351.076056011652
INFO:root:current train perplexity5.153989791870117
INFO:root:current mean train loss 8357.647209119497
INFO:root:current train perplexity5.1679463386535645
INFO:root:current mean train loss 8356.906849511342
INFO:root:current train perplexity5.174440383911133
INFO:root:current mean train loss 8344.972646729195
INFO:root:current train perplexity5.1713361740112305
INFO:root:current mean train loss 8339.211931083197
INFO:root:current train perplexity5.175771236419678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 11038.54898797898
INFO:root:eval perplexity: 9.82455062866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/16

  8%|â–Š         | 16/200 [1:30:38<17:20:29, 339.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8324.1550796751
INFO:root:current train perplexity5.117338180541992
INFO:root:current mean train loss 8273.328933809433
INFO:root:current train perplexity5.115870952606201
INFO:root:current mean train loss 8269.385365301212
INFO:root:current train perplexity5.113959789276123
INFO:root:current mean train loss 8286.208354855371
INFO:root:current train perplexity5.122986316680908
INFO:root:current mean train loss 8281.992717965375
INFO:root:current train perplexity5.118502616882324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11059.170529320127
INFO:root:eval perplexity: 9.866578102111816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/17

  8%|â–Š         | 17/200 [1:36:17<17:14:27, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8197.288770988805
INFO:root:current train perplexity5.044262409210205
INFO:root:current mean train loss 8216.065251333272
INFO:root:current train perplexity5.053638458251953
INFO:root:current mean train loss 8221.307584269663
INFO:root:current train perplexity5.053290843963623
INFO:root:current mean train loss 8208.82885409571
INFO:root:current train perplexity5.054285526275635
INFO:root:current mean train loss 8219.151275177328
INFO:root:current train perplexity5.054628372192383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11046.58850969587
INFO:root:eval perplexity: 9.840913772583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/18

  9%|â–‰         | 18/200 [1:41:56<17:09:15, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8157.393540933099
INFO:root:current train perplexity4.972015857696533
INFO:root:current mean train loss 8153.734349300987
INFO:root:current train perplexity4.992193698883057
INFO:root:current mean train loss 8155.407468000461
INFO:root:current train perplexity4.999119758605957
INFO:root:current mean train loss 8163.862821923433
INFO:root:current train perplexity4.99884557723999
INFO:root:current mean train loss 8167.946583482617
INFO:root:current train perplexity5.001732349395752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 302.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 302.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 11031.719938732329
INFO:root:eval perplexity: 9.810672760009766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/19

 10%|â–‰         | 19/200 [1:47:35<17:03:35, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8105.62908203125
INFO:root:current train perplexity4.945544242858887
INFO:root:current mean train loss 8089.663116629465
INFO:root:current train perplexity4.9341607093811035
INFO:root:current mean train loss 8089.498620383522
INFO:root:current train perplexity4.938832759857178
INFO:root:current mean train loss 8102.495509114583
INFO:root:current train perplexity4.944309234619141
INFO:root:current mean train loss 8110.2315049342105
INFO:root:current train perplexity4.950286388397217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 11037.05215890067
INFO:root:eval perplexity: 9.821508407592773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/20

 10%|â–ˆ         | 20/200 [1:53:15<16:58:12, 339.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8011.733416979826
INFO:root:current train perplexity4.877683639526367
INFO:root:current mean train loss 8041.818689442213
INFO:root:current train perplexity4.8936686515808105
INFO:root:current mean train loss 8056.452533462141
INFO:root:current train perplexity4.8968610763549805
INFO:root:current mean train loss 8062.870271788423
INFO:root:current train perplexity4.902083396911621
INFO:root:current mean train loss 8063.340190337944
INFO:root:current train perplexity4.901268005371094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11052.852928524926
INFO:root:eval perplexity: 9.853681564331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/21

 10%|â–ˆ         | 21/200 [1:58:54<16:52:07, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8008.742252211973
INFO:root:current train perplexity4.864136219024658
INFO:root:current mean train loss 8006.642012465847
INFO:root:current train perplexity4.8509602546691895
INFO:root:current mean train loss 8027.655514990061
INFO:root:current train perplexity4.849812984466553
INFO:root:current mean train loss 8022.118768358355
INFO:root:current train perplexity4.852721214294434
INFO:root:current mean train loss 8016.2343588250515
INFO:root:current train perplexity4.853002071380615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11041.178016299293
INFO:root:eval perplexity: 9.8298978805542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/22

 11%|â–ˆ         | 22/200 [2:04:33<16:46:08, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7931.649879894037
INFO:root:current train perplexity4.772443771362305
INFO:root:current mean train loss 7939.632426052807
INFO:root:current train perplexity4.7829766273498535
INFO:root:current mean train loss 7949.855312227787
INFO:root:current train perplexity4.794175148010254
INFO:root:current mean train loss 7957.156248738292
INFO:root:current train perplexity4.802170276641846
INFO:root:current mean train loss 7968.920814216504
INFO:root:current train perplexity4.808887481689453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11025.879371279761
INFO:root:eval perplexity: 9.798821449279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/23
##########best######
 12%|â–ˆâ–        | 23/200 [2:10:12<16:40:45, 339.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7925.8498776614015
INFO:root:current train perplexity4.747679233551025
INFO:root:current mean train loss 7915.825793520942
INFO:root:current train perplexity4.7591142654418945
INFO:root:current mean train loss 7920.223896249463
INFO:root:current train perplexity4.762237548828125
INFO:root:current mean train loss 7925.270124430546
INFO:root:current train perplexity4.764906406402588
INFO:root:current mean train loss 7921.781937173816
INFO:root:current train perplexity4.765286922454834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11048.899393717447
INFO:root:eval perplexity: 9.845622062683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/24

 12%|â–ˆâ–        | 24/200 [2:15:52<16:35:33, 339.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7865.311569695724
INFO:root:current train perplexity4.722017288208008
INFO:root:current mean train loss 7893.834753104968
INFO:root:current train perplexity4.729628562927246
INFO:root:current mean train loss 7877.45993776483
INFO:root:current train perplexity4.720601558685303
INFO:root:current mean train loss 7878.437830053402
INFO:root:current train perplexity4.720261096954346
INFO:root:current mean train loss 7878.0445588699495
INFO:root:current train perplexity4.724823951721191


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11056.858052571615
INFO:root:eval perplexity: 9.861855506896973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/25

 12%|â–ˆâ–Ž        | 25/200 [2:21:31<16:29:40, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7813.824268071338
INFO:root:current train perplexity4.667957782745361
INFO:root:current mean train loss 7815.356352072864
INFO:root:current train perplexity4.669443130493164
INFO:root:current mean train loss 7833.614270876881
INFO:root:current train perplexity4.679346084594727
INFO:root:current mean train loss 7832.674809582551
INFO:root:current train perplexity4.682976722717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.25s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 11060.888128371465
INFO:root:eval perplexity: 9.870085716247559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/26

 13%|â–ˆâ–Ž        | 26/200 [2:27:11<16:24:14, 339.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7503.068684895833
INFO:root:current train perplexity4.460366249084473
INFO:root:current mean train loss 7743.088658601335
INFO:root:current train perplexity4.614327430725098
INFO:root:current mean train loss 7759.6516774746
INFO:root:current train perplexity4.62628173828125
INFO:root:current mean train loss 7765.925030295998
INFO:root:current train perplexity4.630414962768555
INFO:root:current mean train loss 7779.920682769851
INFO:root:current train perplexity4.638425827026367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11055.934175037202
INFO:root:eval perplexity: 9.859968185424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/27

 14%|â–ˆâ–Ž        | 27/200 [2:32:51<16:18:49, 339.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7769.543387276785
INFO:root:current train perplexity4.56810998916626
INFO:root:current mean train loss 7754.212370400117
INFO:root:current train perplexity4.612283229827881
INFO:root:current mean train loss 7754.246048931915
INFO:root:current train perplexity4.60548734664917
INFO:root:current mean train loss 7755.346989833571
INFO:root:current train perplexity4.605184555053711
INFO:root:current mean train loss 7754.935042997543
INFO:root:current train perplexity4.610042095184326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11074.848185221354
INFO:root:eval perplexity: 9.898646354675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/28

 14%|â–ˆâ–        | 28/200 [2:38:30<16:12:52, 339.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7702.543013139205
INFO:root:current train perplexity4.544136047363281
INFO:root:current mean train loss 7679.130085163289
INFO:root:current train perplexity4.562084197998047
INFO:root:current mean train loss 7681.445076458827
INFO:root:current train perplexity4.567322731018066
INFO:root:current mean train loss 7692.668342418609
INFO:root:current train perplexity4.569761276245117
INFO:root:current mean train loss 7712.920477874088
INFO:root:current train perplexity4.5802764892578125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11066.714021228609
INFO:root:eval perplexity: 9.881993293762207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/29

 14%|â–ˆâ–        | 29/200 [2:44:09<16:07:20, 339.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7669.4494140625
INFO:root:current train perplexity4.590152740478516
INFO:root:current mean train loss 7657.740637737772
INFO:root:current train perplexity4.526582717895508
INFO:root:current mean train loss 7679.896316315407
INFO:root:current train perplexity4.53396463394165
INFO:root:current mean train loss 7668.963392857143
INFO:root:current train perplexity4.539361476898193
INFO:root:current mean train loss 7676.669512424699
INFO:root:current train perplexity4.544713497161865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11088.40947905041
INFO:root:eval perplexity: 9.926471710205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/30

 15%|â–ˆâ–Œ        | 30/200 [2:49:48<16:01:32, 339.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7650.817511307566
INFO:root:current train perplexity4.447885036468506
INFO:root:current mean train loss 7619.640370601365
INFO:root:current train perplexity4.506012916564941
INFO:root:current mean train loss 7625.619517426512
INFO:root:current train perplexity4.503565311431885
INFO:root:current mean train loss 7639.789662519593
INFO:root:current train perplexity4.508935451507568
INFO:root:current mean train loss 7640.632186707563
INFO:root:current train perplexity4.511495113372803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.10s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11089.970363071987
INFO:root:eval perplexity: 9.929681777954102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/31

 16%|â–ˆâ–Œ        | 31/200 [2:55:28<15:55:43, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7611.903766134511
INFO:root:current train perplexity4.455594539642334
INFO:root:current mean train loss 7600.351864202235
INFO:root:current train perplexity4.460043430328369
INFO:root:current mean train loss 7612.855808138313
INFO:root:current train perplexity4.475526332855225
INFO:root:current mean train loss 7605.069106158088
INFO:root:current train perplexity4.478497505187988
INFO:root:current mean train loss 7612.406912584958
INFO:root:current train perplexity4.483448505401611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 11091.345714750743
INFO:root:eval perplexity: 9.93250846862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/32

 16%|â–ˆâ–Œ        | 32/200 [3:01:07<15:50:08, 339.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7639.711100260417
INFO:root:current train perplexity4.427650451660156
INFO:root:current mean train loss 7595.1225662832185
INFO:root:current train perplexity4.446806907653809
INFO:root:current mean train loss 7587.4524495801215
INFO:root:current train perplexity4.4471635818481445
INFO:root:current mean train loss 7577.157752174121
INFO:root:current train perplexity4.452209949493408
INFO:root:current mean train loss 7578.2090083888315
INFO:root:current train perplexity4.4531569480896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 11122.098876953125
INFO:root:eval perplexity: 9.995933532714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/33

 16%|â–ˆâ–‹        | 33/200 [3:06:46<15:44:36, 339.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7488.762726814516
INFO:root:current train perplexity4.381590366363525
INFO:root:current mean train loss 7516.787649838979
INFO:root:current train perplexity4.401979446411133
INFO:root:current mean train loss 7525.142755681818
INFO:root:current train perplexity4.409717559814453
INFO:root:current mean train loss 7535.749048515389
INFO:root:current train perplexity4.420659065246582
INFO:root:current mean train loss 7538.5859533606435
INFO:root:current train perplexity4.423373699188232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11114.352265857515
INFO:root:eval perplexity: 9.9799222946167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/34

 17%|â–ˆâ–‹        | 34/200 [3:12:26<15:38:54, 339.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7503.8265625
INFO:root:current train perplexity4.396369457244873
INFO:root:current mean train loss 7498.4007631655095
INFO:root:current train perplexity4.394340991973877
INFO:root:current mean train loss 7480.850145445479
INFO:root:current train perplexity4.385716915130615
INFO:root:current mean train loss 7492.45478515625
INFO:root:current train perplexity4.388635158538818
INFO:root:current mean train loss 7499.627371812141
INFO:root:current train perplexity4.389033317565918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11133.108154296875
INFO:root:eval perplexity: 10.0187406539917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/35

 18%|â–ˆâ–Š        | 35/200 [3:18:04<15:32:31, 339.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7450.335662059295
INFO:root:current train perplexity4.368449687957764
INFO:root:current mean train loss 7456.04143013714
INFO:root:current train perplexity4.368699073791504
INFO:root:current mean train loss 7466.044082194691
INFO:root:current train perplexity4.363325119018555
INFO:root:current mean train loss 7465.521007616611
INFO:root:current train perplexity4.36325740814209
INFO:root:current mean train loss 7467.845496245017
INFO:root:current train perplexity4.35998010635376


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 11138.693324497768
INFO:root:eval perplexity: 10.030332565307617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/36

 18%|â–ˆâ–Š        | 36/200 [3:23:44<15:27:16, 339.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7452.5437409156975
INFO:root:current train perplexity4.345706939697266
INFO:root:current mean train loss 7445.312547803759
INFO:root:current train perplexity4.347814083099365
INFO:root:current mean train loss 7438.989356272506
INFO:root:current train perplexity4.339577674865723
INFO:root:current mean train loss 7444.478978282161
INFO:root:current train perplexity4.3376007080078125
INFO:root:current mean train loss 7441.450021162528
INFO:root:current train perplexity4.336953163146973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11158.10487874349
INFO:root:eval perplexity: 10.070713996887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/37

 18%|â–ˆâ–Š        | 37/200 [3:29:23<15:21:48, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7368.159138131649
INFO:root:current train perplexity4.267208099365234
INFO:root:current mean train loss 7395.711047114158
INFO:root:current train perplexity4.28224515914917
INFO:root:current mean train loss 7394.563195850203
INFO:root:current train perplexity4.289610385894775
INFO:root:current mean train loss 7403.506122512158
INFO:root:current train perplexity4.3068976402282715
INFO:root:current mean train loss 7410.205614469729
INFO:root:current train perplexity4.310751438140869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 11169.049560546875
INFO:root:eval perplexity: 10.09355640411377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/38

 19%|â–ˆâ–‰        | 38/200 [3:35:02<15:15:33, 339.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7376.279268152573
INFO:root:current train perplexity4.255875587463379
INFO:root:current mean train loss 7375.366712153353
INFO:root:current train perplexity4.265969276428223
INFO:root:current mean train loss 7366.241304313994
INFO:root:current train perplexity4.265316009521484
INFO:root:current mean train loss 7375.700205050302
INFO:root:current train perplexity4.276089191436768
INFO:root:current mean train loss 7379.16060772069
INFO:root:current train perplexity4.280519962310791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 11175.927083333334
INFO:root:eval perplexity: 10.10793399810791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/39

 20%|â–ˆâ–‰        | 39/200 [3:40:41<15:10:02, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7346.605477627841
INFO:root:current train perplexity4.238776683807373
INFO:root:current mean train loss 7349.075163810484
INFO:root:current train perplexity4.245971202850342
INFO:root:current mean train loss 7352.6741632199755
INFO:root:current train perplexity4.250663757324219
INFO:root:current mean train loss 7353.4581824933975
INFO:root:current train perplexity4.250975131988525
INFO:root:current mean train loss 7348.526576450893
INFO:root:current train perplexity4.256521224975586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 11201.399140857515
INFO:root:eval perplexity: 10.161367416381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/40

 20%|â–ˆâ–ˆ        | 40/200 [3:46:21<15:04:37, 339.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7295.694104210805
INFO:root:current train perplexity4.231766700744629
INFO:root:current mean train loss 7307.1574722386
INFO:root:current train perplexity4.224956035614014
INFO:root:current mean train loss 7300.261501945584
INFO:root:current train perplexity4.2255353927612305
INFO:root:current mean train loss 7311.220560312935
INFO:root:current train perplexity4.2314653396606445
INFO:root:current mean train loss 7319.94889429296
INFO:root:current train perplexity4.233295440673828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.28s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 11196.678510393414
INFO:root:eval perplexity: 10.151444435119629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/41

 20%|â–ˆâ–ˆ        | 41/200 [3:52:00<14:59:00, 339.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7263.4140392485115
INFO:root:current train perplexity4.188409328460693
INFO:root:current mean train loss 7268.783619512078
INFO:root:current train perplexity4.189860820770264
INFO:root:current mean train loss 7271.720211130584
INFO:root:current train perplexity4.193268775939941
INFO:root:current mean train loss 7280.160811327049
INFO:root:current train perplexity4.203381061553955
INFO:root:current mean train loss 7286.735969559935
INFO:root:current train perplexity4.208197116851807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11213.66417875744
INFO:root:eval perplexity: 10.187196731567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/42

 21%|â–ˆâ–ˆ        | 42/200 [3:57:40<14:53:39, 339.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7249.190101737407
INFO:root:current train perplexity4.161601543426514
INFO:root:current mean train loss 7252.568496795471
INFO:root:current train perplexity4.163081169128418
INFO:root:current mean train loss 7252.359737096208
INFO:root:current train perplexity4.168745994567871
INFO:root:current mean train loss 7255.079914477606
INFO:root:current train perplexity4.175630569458008
INFO:root:current mean train loss 7259.006198139722
INFO:root:current train perplexity4.183751583099365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11221.151939755395
INFO:root:eval perplexity: 10.203001022338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/43

 22%|â–ˆâ–ˆâ–       | 43/200 [4:03:19<14:47:50, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7206.517516230194
INFO:root:current train perplexity4.1478471755981445
INFO:root:current mean train loss 7224.76501107913
INFO:root:current train perplexity4.162373065948486
INFO:root:current mean train loss 7223.40935265798
INFO:root:current train perplexity4.157284736633301
INFO:root:current mean train loss 7231.325234796159
INFO:root:current train perplexity4.157712936401367
INFO:root:current mean train loss 7235.258472871882
INFO:root:current train perplexity4.159536361694336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11240.009236653646
INFO:root:eval perplexity: 10.242902755737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:08:58<14:42:12, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7209.2859375
INFO:root:current train perplexity4.133747100830078
INFO:root:current mean train loss 7205.502020089286
INFO:root:current train perplexity4.1360955238342285
INFO:root:current mean train loss 7205.390049715909
INFO:root:current train perplexity4.141010761260986
INFO:root:current mean train loss 7199.417830729167
INFO:root:current train perplexity4.137824058532715
INFO:root:current mean train loss 7205.7144562088815
INFO:root:current train perplexity4.137520790100098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 11241.835393996465
INFO:root:eval perplexity: 10.246774673461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:14:37<14:36:15, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7165.147652541535
INFO:root:current train perplexity4.094798564910889
INFO:root:current mean train loss 7165.201717440643
INFO:root:current train perplexity4.0968499183654785
INFO:root:current mean train loss 7162.812636508736
INFO:root:current train perplexity4.102252006530762
INFO:root:current mean train loss 7172.28556980747
INFO:root:current train perplexity4.110301494598389
INFO:root:current mean train loss 7175.063794607907
INFO:root:current train perplexity4.114360332489014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11269.005522228423
INFO:root:eval perplexity: 10.3045654296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:20:16<14:30:06, 339.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7101.222932746611
INFO:root:current train perplexity4.0464982986450195
INFO:root:current mean train loss 7116.577132428279
INFO:root:current train perplexity4.069008827209473
INFO:root:current mean train loss 7126.704929742712
INFO:root:current train perplexity4.081643581390381
INFO:root:current mean train loss 7145.077467158942
INFO:root:current train perplexity4.086273193359375
INFO:root:current mean train loss 7149.998775758605
INFO:root:current train perplexity4.09382963180542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 11271.872875395275
INFO:root:eval perplexity: 10.310684204101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:25:55<14:24:40, 339.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7141.788411458333
INFO:root:current train perplexity4.057979583740234
INFO:root:current mean train loss 7124.814899628175
INFO:root:current train perplexity4.056236267089844
INFO:root:current mean train loss 7126.305635139917
INFO:root:current train perplexity4.069486141204834
INFO:root:current mean train loss 7125.69185667999
INFO:root:current train perplexity4.0698652267456055
INFO:root:current mean train loss 7125.796226297805
INFO:root:current train perplexity4.073383808135986


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11293.639157249814
INFO:root:eval perplexity: 10.357242584228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:31:34<14:19:12, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7069.925893930288
INFO:root:current train perplexity4.034379959106445
INFO:root:current mean train loss 7093.247512577716
INFO:root:current train perplexity4.038259506225586
INFO:root:current mean train loss 7096.825462105348
INFO:root:current train perplexity4.043999195098877
INFO:root:current mean train loss 7099.190388477062
INFO:root:current train perplexity4.049047470092773
INFO:root:current mean train loss 7098.50879602374
INFO:root:current train perplexity4.051342010498047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11301.9452398391
INFO:root:eval perplexity: 10.375064849853516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:37:13<14:13:05, 338.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7060.183701685855
INFO:root:current train perplexity4.0200347900390625
INFO:root:current mean train loss 7067.109585336539
INFO:root:current train perplexity4.023519039154053
INFO:root:current mean train loss 7060.813258077331
INFO:root:current train perplexity4.026640892028809
INFO:root:current mean train loss 7063.345496687104
INFO:root:current train perplexity4.029314041137695
INFO:root:current mean train loss 7075.244388218119
INFO:root:current train perplexity4.033178329467773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 11313.504801432291
INFO:root:eval perplexity: 10.399916648864746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:42:52<14:07:35, 339.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7009.785008285985
INFO:root:current train perplexity3.987107515335083
INFO:root:current mean train loss 7029.545645709014
INFO:root:current train perplexity3.994844913482666
INFO:root:current mean train loss 7043.811306242162
INFO:root:current train perplexity4.007575511932373
INFO:root:current mean train loss 7043.7720509770525
INFO:root:current train perplexity4.011594295501709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11326.553914388021
INFO:root:eval perplexity: 10.428045272827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:48:31<14:02:18, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7084.291341145833
INFO:root:current train perplexity4.022107124328613
INFO:root:current mean train loss 7020.32171571602
INFO:root:current train perplexity3.9765827655792236
INFO:root:current mean train loss 7017.59423828125
INFO:root:current train perplexity3.9911272525787354
INFO:root:current mean train loss 7020.161380981848
INFO:root:current train perplexity3.9892218112945557
INFO:root:current mean train loss 7020.429155600574
INFO:root:current train perplexity3.992093801498413


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 11344.592322939918
INFO:root:eval perplexity: 10.467055320739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:54:10<13:56:29, 339.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6919.850725446428
INFO:root:current train perplexity3.9081218242645264
INFO:root:current mean train loss 6946.640611309872
INFO:root:current train perplexity3.9543421268463135
INFO:root:current mean train loss 6984.44158080465
INFO:root:current train perplexity3.968475341796875
INFO:root:current mean train loss 6990.832161670399
INFO:root:current train perplexity3.9691832065582275
INFO:root:current mean train loss 6988.212618291232
INFO:root:current train perplexity3.965754508972168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11346.997750418526
INFO:root:eval perplexity: 10.472270011901855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:59:50<13:51:11, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6943.259588068182
INFO:root:current train perplexity3.895223617553711
INFO:root:current mean train loss 6964.463955166104
INFO:root:current train perplexity3.933089256286621
INFO:root:current mean train loss 6968.963203032435
INFO:root:current train perplexity3.9352409839630127
INFO:root:current mean train loss 6970.445248128517
INFO:root:current train perplexity3.942744016647339
INFO:root:current mean train loss 6966.314980611314
INFO:root:current train perplexity3.947460651397705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 11375.843552362352
INFO:root:eval perplexity: 10.53498363494873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:05:30<13:45:56, 339.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6969.90390625
INFO:root:current train perplexity3.9044127464294434
INFO:root:current mean train loss 6909.994951596467
INFO:root:current train perplexity3.915867805480957
INFO:root:current mean train loss 6924.810299327762
INFO:root:current train perplexity3.916747808456421
INFO:root:current mean train loss 6929.015513392857
INFO:root:current train perplexity3.924006700515747
INFO:root:current mean train loss 6941.003960372741
INFO:root:current train perplexity3.929593563079834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 11395.023559570312
INFO:root:eval perplexity: 10.576892852783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:11:08<13:39:37, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6857.4456208881575
INFO:root:current train perplexity3.9116199016571045
INFO:root:current mean train loss 6881.811084394695
INFO:root:current train perplexity3.891066789627075
INFO:root:current mean train loss 6890.591542701199
INFO:root:current train perplexity3.896799087524414
INFO:root:current mean train loss 6908.724251200039
INFO:root:current train perplexity3.9048960208892822
INFO:root:current mean train loss 6909.265841754923
INFO:root:current train perplexity3.907055139541626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11402.724286760602
INFO:root:eval perplexity: 10.59376335144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:16:47<13:33:38, 339.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6880.493376358696
INFO:root:current train perplexity3.850520372390747
INFO:root:current mean train loss 6881.138874333079
INFO:root:current train perplexity3.8700873851776123
INFO:root:current mean train loss 6883.743466227578
INFO:root:current train perplexity3.8766934871673584
INFO:root:current mean train loss 6888.10013393721
INFO:root:current train perplexity3.88496732711792
INFO:root:current mean train loss 6894.685134779477
INFO:root:current train perplexity3.8930628299713135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 11408.42667061942
INFO:root:eval perplexity: 10.60627555847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:22:26<13:28:07, 339.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6863.729654947917
INFO:root:current train perplexity3.8754570484161377
INFO:root:current mean train loss 6851.256562961368
INFO:root:current train perplexity3.859621047973633
INFO:root:current mean train loss 6880.3135109788
INFO:root:current train perplexity3.8710784912109375
INFO:root:current mean train loss 6870.891217806288
INFO:root:current train perplexity3.8693127632141113
INFO:root:current mean train loss 6876.080972354362
INFO:root:current train perplexity3.875439167022705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11422.544169108072
INFO:root:eval perplexity: 10.63731575012207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:28:06<13:23:03, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6819.35546875
INFO:root:current train perplexity3.8273119926452637
INFO:root:current mean train loss 6824.038872405773
INFO:root:current train perplexity3.831754446029663
INFO:root:current mean train loss 6828.75389356737
INFO:root:current train perplexity3.846588134765625
INFO:root:current mean train loss 6836.899067397564
INFO:root:current train perplexity3.8482306003570557
INFO:root:current mean train loss 6844.366551941343
INFO:root:current train perplexity3.852686643600464


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 11448.811256045386
INFO:root:eval perplexity: 10.69530963897705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:33:46<13:17:28, 339.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6810.550530133929
INFO:root:current train perplexity3.8210153579711914
INFO:root:current mean train loss 6805.589767795139
INFO:root:current train perplexity3.8241186141967773
INFO:root:current mean train loss 6809.042299700798
INFO:root:current train perplexity3.831747531890869
INFO:root:current mean train loss 6812.52772708722
INFO:root:current train perplexity3.834465742111206
INFO:root:current mean train loss 6822.270328214799
INFO:root:current train perplexity3.838228225708008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 11465.58303687686
INFO:root:eval perplexity: 10.732504844665527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:39:24<13:11:31, 339.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6788.532677283654
INFO:root:current train perplexity3.7793068885803223
INFO:root:current mean train loss 6791.846925584532
INFO:root:current train perplexity3.8039114475250244
INFO:root:current mean train loss 6783.12720237317
INFO:root:current train perplexity3.8151795864105225
INFO:root:current mean train loss 6790.435580003226
INFO:root:current train perplexity3.8196005821228027
INFO:root:current mean train loss 6801.299525510749
INFO:root:current train perplexity3.8238487243652344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 11478.211678641183
INFO:root:eval perplexity: 10.76059341430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:45:04<13:06:04, 339.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6728.827659429506
INFO:root:current train perplexity3.7832303047180176
INFO:root:current mean train loss 6763.308853256119
INFO:root:current train perplexity3.7889251708984375
INFO:root:current mean train loss 6765.104222929527
INFO:root:current train perplexity3.7970120906829834
INFO:root:current mean train loss 6777.595149359967
INFO:root:current train perplexity3.801126003265381
INFO:root:current mean train loss 6783.970673365195
INFO:root:current train perplexity3.807587146759033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11492.190790085566
INFO:root:eval perplexity: 10.791776657104492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:50:43<13:00:22, 339.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6712.131015209441
INFO:root:current train perplexity3.774413585662842
INFO:root:current mean train loss 6726.162298708546
INFO:root:current train perplexity3.766073703765869
INFO:root:current mean train loss 6742.272611177885
INFO:root:current train perplexity3.7782721519470215
INFO:root:current mean train loss 6743.93742542102
INFO:root:current train perplexity3.7826638221740723
INFO:root:current mean train loss 6758.551116602
INFO:root:current train perplexity3.790588617324829


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 11505.534359886533
INFO:root:eval perplexity: 10.821625709533691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:56:22<12:54:20, 339.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6721.853984757966
INFO:root:current train perplexity3.76139497756958
INFO:root:current mean train loss 6717.285275895075
INFO:root:current train perplexity3.764185905456543
INFO:root:current mean train loss 6733.226685056648
INFO:root:current train perplexity3.7663447856903076
INFO:root:current mean train loss 6737.87676254229
INFO:root:current train perplexity3.769188404083252
INFO:root:current mean train loss 6738.040559823656
INFO:root:current train perplexity3.7743136882781982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11521.336175827753
INFO:root:eval perplexity: 10.857076644897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:02:01<12:48:40, 339.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6638.076695667613
INFO:root:current train perplexity3.7126834392547607
INFO:root:current mean train loss 6685.409872731855
INFO:root:current train perplexity3.7328288555145264
INFO:root:current mean train loss 6694.732012101716
INFO:root:current train perplexity3.7440195083618164
INFO:root:current mean train loss 6707.446890129841
INFO:root:current train perplexity3.748466730117798
INFO:root:current mean train loss 6709.3947855855085
INFO:root:current train perplexity3.7521841526031494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11539.044576009115
INFO:root:eval perplexity: 10.89694881439209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:07:40<12:43:02, 339.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6632.951776019598
INFO:root:current train perplexity3.705231189727783
INFO:root:current mean train loss 6664.93916138463
INFO:root:current train perplexity3.7265312671661377
INFO:root:current mean train loss 6671.910256168557
INFO:root:current train perplexity3.725754737854004
INFO:root:current mean train loss 6684.357257301097
INFO:root:current train perplexity3.732299327850342
INFO:root:current mean train loss 6694.132685908565
INFO:root:current train perplexity3.7397232055664062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 11551.38420468285
INFO:root:eval perplexity: 10.924814224243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:13:19<12:37:26, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6656.454961867559
INFO:root:current train perplexity3.705151319503784
INFO:root:current mean train loss 6639.204272311158
INFO:root:current train perplexity3.7089879512786865
INFO:root:current mean train loss 6654.231664389258
INFO:root:current train perplexity3.7125179767608643
INFO:root:current mean train loss 6659.665244866994
INFO:root:current train perplexity3.717925786972046
INFO:root:current mean train loss 6667.985260866631
INFO:root:current train perplexity3.7246007919311523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11575.274024600074
INFO:root:eval perplexity: 10.978974342346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:19:52<13:07:36, 355.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6637.6897883628735
INFO:root:current train perplexity3.6822566986083984
INFO:root:current mean train loss 6648.918436564371
INFO:root:current train perplexity3.697169780731201
INFO:root:current mean train loss 6633.503039413624
INFO:root:current train perplexity3.699368476867676
INFO:root:current mean train loss 6643.352582967898
INFO:root:current train perplexity3.7074341773986816
INFO:root:current mean train loss 6647.631870441314
INFO:root:current train perplexity3.7066404819488525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 11569.786493210566
INFO:root:eval perplexity: 10.966508865356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:27:03<13:51:37, 378.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6631.801001320423
INFO:root:current train perplexity3.6823720932006836
INFO:root:current mean train loss 6622.93335674799
INFO:root:current train perplexity3.689357042312622
INFO:root:current mean train loss 6624.788853494004
INFO:root:current train perplexity3.692758083343506
INFO:root:current mean train loss 6626.079839906924
INFO:root:current train perplexity3.694492816925049
INFO:root:current mean train loss 6630.395542023288
INFO:root:current train perplexity3.695826530456543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 11592.80698939732
INFO:root:eval perplexity: 11.018889427185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:32:43<13:20:05, 366.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6568.4548958333335
INFO:root:current train perplexity3.656754970550537
INFO:root:current mean train loss 6591.999606584822
INFO:root:current train perplexity3.662360429763794
INFO:root:current mean train loss 6597.052084517046
INFO:root:current train perplexity3.671535015106201
INFO:root:current mean train loss 6601.855111979166
INFO:root:current train perplexity3.674410820007324
INFO:root:current mean train loss 6613.472984169408
INFO:root:current train perplexity3.6803464889526367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11609.949390229725
INFO:root:eval perplexity: 11.05805778503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:38:22<12:56:18, 358.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6555.023122280459
INFO:root:current train perplexity3.6398158073425293
INFO:root:current mean train loss 6568.019962246857
INFO:root:current train perplexity3.6576757431030273
INFO:root:current mean train loss 6582.1407860103045
INFO:root:current train perplexity3.6631293296813965
INFO:root:current mean train loss 6584.6072363538915
INFO:root:current train perplexity3.667189598083496
INFO:root:current mean train loss 6588.8573444024005
INFO:root:current train perplexity3.664229393005371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11618.94766671317
INFO:root:eval perplexity: 11.078675270080566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:44:01<12:38:04, 352.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6530.644219455949
INFO:root:current train perplexity3.62504243850708
INFO:root:current mean train loss 6548.18351103569
INFO:root:current train perplexity3.632789134979248
INFO:root:current mean train loss 6553.820395318021
INFO:root:current train perplexity3.6390717029571533
INFO:root:current mean train loss 6557.403752498776
INFO:root:current train perplexity3.645472526550293
INFO:root:current mean train loss 6568.747987229878
INFO:root:current train perplexity3.650782585144043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 11630.926249186197
INFO:root:eval perplexity: 11.10617733001709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:49:41<12:24:10, 348.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6528.322742681394
INFO:root:current train perplexity3.6109042167663574
INFO:root:current mean train loss 6538.4373381099595
INFO:root:current train perplexity3.625296115875244
INFO:root:current mean train loss 6549.423042111281
INFO:root:current train perplexity3.6363601684570312
INFO:root:current mean train loss 6550.710904695575
INFO:root:current train perplexity3.6386148929595947
INFO:root:current mean train loss 6550.514206277271
INFO:root:current train perplexity3.637035846710205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11648.587498256138
INFO:root:eval perplexity: 11.146854400634766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [6:55:21<12:12:22, 346.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6484.326805030906
INFO:root:current train perplexity3.5961015224456787
INFO:root:current mean train loss 6520.522962000981
INFO:root:current train perplexity3.6083576679229736
INFO:root:current mean train loss 6521.257767195554
INFO:root:current train perplexity3.610276222229004
INFO:root:current mean train loss 6527.647865549073
INFO:root:current train perplexity3.617710828781128
INFO:root:current mean train loss 6528.7116336239815
INFO:root:current train perplexity3.621382236480713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.67s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11659.66694859096
INFO:root:eval perplexity: 11.172445297241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [7:01:01<12:02:39, 344.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6484.1457288240135
INFO:root:current train perplexity3.5908851623535156
INFO:root:current mean train loss 6496.673167067308
INFO:root:current train perplexity3.601114273071289
INFO:root:current mean train loss 6497.3281630693855
INFO:root:current train perplexity3.59958553314209
INFO:root:current mean train loss 6502.151694768591
INFO:root:current train perplexity3.6051509380340576
INFO:root:current mean train loss 6507.495493016098
INFO:root:current train perplexity3.606588840484619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 11669.071841285342
INFO:root:eval perplexity: 11.194215774536133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:08:03<12:45:33, 367.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6460.92204269255
INFO:root:current train perplexity3.590177297592163
INFO:root:current mean train loss 6474.737226169912
INFO:root:current train perplexity3.5885422229766846
INFO:root:current mean train loss 6485.726902173913
INFO:root:current train perplexity3.5950284004211426
INFO:root:current mean train loss 6482.537158325501
INFO:root:current train perplexity3.5937187671661377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11684.671869187128
INFO:root:eval perplexity: 11.230422019958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:13:57<12:31:28, 363.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6295.912434895833
INFO:root:current train perplexity3.4809024333953857
INFO:root:current mean train loss 6451.550193416262
INFO:root:current train perplexity3.5738863945007324
INFO:root:current mean train loss 6454.338143184267
INFO:root:current train perplexity3.568587303161621
INFO:root:current mean train loss 6456.641145511036
INFO:root:current train perplexity3.574187994003296
INFO:root:current mean train loss 6461.032127209987
INFO:root:current train perplexity3.5791103839874268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 11693.51738920666
INFO:root:eval perplexity: 11.251001358032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:19:36<12:10:26, 356.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6357.329310825893
INFO:root:current train perplexity3.4855775833129883
INFO:root:current mean train loss 6421.902841158002
INFO:root:current train perplexity3.534329652786255
INFO:root:current mean train loss 6427.398364375755
INFO:root:current train perplexity3.54591703414917
INFO:root:current mean train loss 6447.973830033591
INFO:root:current train perplexity3.5587692260742188
INFO:root:current mean train loss 6449.3897504127
INFO:root:current train perplexity3.5637385845184326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 11705.16289701916
INFO:root:eval perplexity: 11.278159141540527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:25:15<11:53:53, 351.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6395.556019176136
INFO:root:current train perplexity3.5702383518218994
INFO:root:current mean train loss 6382.905572564752
INFO:root:current train perplexity3.5292234420776367
INFO:root:current mean train loss 6404.567197682169
INFO:root:current train perplexity3.537414312362671
INFO:root:current mean train loss 6418.310810641077
INFO:root:current train perplexity3.5485124588012695
INFO:root:current mean train loss 6429.386610639066
INFO:root:current train perplexity3.5557291507720947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11739.43955485026
INFO:root:eval perplexity: 11.358460426330566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:30:55<11:40:58, 347.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6368.829622395833
INFO:root:current train perplexity3.5075185298919678
INFO:root:current mean train loss 6394.010996942935
INFO:root:current train perplexity3.52386474609375
INFO:root:current mean train loss 6402.004953215843
INFO:root:current train perplexity3.53399395942688
INFO:root:current mean train loss 6406.548575458829
INFO:root:current train perplexity3.536935567855835
INFO:root:current mean train loss 6409.023648108057
INFO:root:current train perplexity3.5398905277252197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11740.401611328125
INFO:root:eval perplexity: 11.360721588134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:36:35<11:30:27, 345.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6328.423853824013
INFO:root:current train perplexity3.519597291946411
INFO:root:current mean train loss 6351.420861508666
INFO:root:current train perplexity3.5160889625549316
INFO:root:current mean train loss 6359.068774079623
INFO:root:current train perplexity3.51690673828125
INFO:root:current mean train loss 6384.319043581015
INFO:root:current train perplexity3.525543689727783
INFO:root:current mean train loss 6394.750626957786
INFO:root:current train perplexity3.5289783477783203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11761.56266857329
INFO:root:eval perplexity: 11.410593032836914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:42:14<11:21:07, 343.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6370.922214673913
INFO:root:current train perplexity3.475904941558838
INFO:root:current mean train loss 6376.712580983231
INFO:root:current train perplexity3.503819465637207
INFO:root:current mean train loss 6372.498239559977
INFO:root:current train perplexity3.5083255767822266
INFO:root:current mean train loss 6366.64797189435
INFO:root:current train perplexity3.5097455978393555
INFO:root:current mean train loss 6373.845999787603
INFO:root:current train perplexity3.5122909545898438


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 11775.9435773577
INFO:root:eval perplexity: 11.444609642028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:47:54<11:13:15, 342.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6329.934932002315
INFO:root:current train perplexity3.5048952102661133
INFO:root:current mean train loss 6355.086571881152
INFO:root:current train perplexity3.503671646118164
INFO:root:current mean train loss 6348.825924507847
INFO:root:current train perplexity3.49993896484375
INFO:root:current mean train loss 6351.973816477925
INFO:root:current train perplexity3.500906229019165
INFO:root:current mean train loss 6354.720841490413
INFO:root:current train perplexity3.501922607421875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11785.63934907459
INFO:root:eval perplexity: 11.467598915100098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [7:53:33<11:05:38, 341.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6334.044402091734
INFO:root:current train perplexity3.477965831756592
INFO:root:current mean train loss 6328.694134661259
INFO:root:current train perplexity3.475663423538208
INFO:root:current mean train loss 6326.173838693859
INFO:root:current train perplexity3.479033946990967
INFO:root:current mean train loss 6331.929504578928
INFO:root:current train perplexity3.4815945625305176
INFO:root:current mean train loss 6338.418931717662
INFO:root:current train perplexity3.4875268936157227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 11803.466456821987
INFO:root:eval perplexity: 11.509998321533203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [7:59:12<10:58:58, 340.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6264.357380022321
INFO:root:current train perplexity3.444862127304077
INFO:root:current mean train loss 6304.821234809027
INFO:root:current train perplexity3.4585630893707275
INFO:root:current mean train loss 6310.859177609707
INFO:root:current train perplexity3.4635071754455566
INFO:root:current mean train loss 6317.757193038713
INFO:root:current train perplexity3.4700963497161865
INFO:root:current mean train loss 6316.466191855245
INFO:root:current train perplexity3.475088357925415


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11816.725949242002
INFO:root:eval perplexity: 11.541629791259766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [8:04:51<10:51:59, 340.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6309.990284455128
INFO:root:current train perplexity3.434438943862915
INFO:root:current mean train loss 6293.871027006519
INFO:root:current train perplexity3.4509241580963135
INFO:root:current mean train loss 6305.836156102902
INFO:root:current train perplexity3.461209774017334
INFO:root:current mean train loss 6309.834638297382
INFO:root:current train perplexity3.464102029800415
INFO:root:current mean train loss 6310.314363032105
INFO:root:current train perplexity3.465332508087158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11830.198901948475
INFO:root:eval perplexity: 11.573862075805664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:10:30<10:45:42, 339.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6252.656897256541
INFO:root:current train perplexity3.447476863861084
INFO:root:current mean train loss 6280.366767509834
INFO:root:current train perplexity3.4490160942077637
INFO:root:current mean train loss 6267.648192354681
INFO:root:current train perplexity3.4459915161132812
INFO:root:current mean train loss 6284.451341278699
INFO:root:current train perplexity3.4488630294799805
INFO:root:current mean train loss 6285.610038533437
INFO:root:current train perplexity3.450676918029785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 11836.643952869234
INFO:root:eval perplexity: 11.589311599731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:16:10<10:39:55, 339.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6238.761292802526
INFO:root:current train perplexity3.422318696975708
INFO:root:current mean train loss 6265.104874176233
INFO:root:current train perplexity3.4311728477478027
INFO:root:current mean train loss 6265.079544376265
INFO:root:current train perplexity3.4326703548431396
INFO:root:current mean train loss 6266.16830928044
INFO:root:current train perplexity3.4382379055023193
INFO:root:current mean train loss 6264.659736786913
INFO:root:current train perplexity3.438972234725952


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 11853.487938290551
INFO:root:eval perplexity: 11.629789352416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:21:48<10:33:43, 339.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6225.559962852329
INFO:root:current train perplexity3.427995443344116
INFO:root:current mean train loss 6255.410479615066
INFO:root:current train perplexity3.4265153408050537
INFO:root:current mean train loss 6249.898408319846
INFO:root:current train perplexity3.4235501289367676
INFO:root:current mean train loss 6257.548331497062
INFO:root:current train perplexity3.427441358566284
INFO:root:current mean train loss 6257.651279491754
INFO:root:current train perplexity3.4320032596588135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 11870.094546363467
INFO:root:eval perplexity: 11.669833183288574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:27:28<10:27:59, 339.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6250.09951171875
INFO:root:current train perplexity3.423384428024292
INFO:root:current mean train loss 6246.617981350806
INFO:root:current train perplexity3.409677505493164
INFO:root:current mean train loss 6237.959635416667
INFO:root:current train perplexity3.4138951301574707
INFO:root:current mean train loss 6241.919197018045
INFO:root:current train perplexity3.415008783340454
INFO:root:current mean train loss 6241.158014251374
INFO:root:current train perplexity3.4191224575042725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.54s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 11889.450049990699
INFO:root:eval perplexity: 11.716683387756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:33:07<10:22:25, 339.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6201.73732951536
INFO:root:current train perplexity3.3890914916992188
INFO:root:current mean train loss 6213.014731353184
INFO:root:current train perplexity3.4021506309509277
INFO:root:current mean train loss 6218.768743213079
INFO:root:current train perplexity3.403083324432373
INFO:root:current mean train loss 6217.6412914563025
INFO:root:current train perplexity3.407036066055298
INFO:root:current mean train loss 6221.772824754902
INFO:root:current train perplexity3.4088687896728516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 11907.323253813243
INFO:root:eval perplexity: 11.76010799407959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:38:46<10:16:32, 339.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6169.884494357639
INFO:root:current train perplexity3.3580901622772217
INFO:root:current mean train loss 6188.047006805981
INFO:root:current train perplexity3.380073308944702
INFO:root:current mean train loss 6188.239361781131
INFO:root:current train perplexity3.3863298892974854
INFO:root:current mean train loss 6192.714259964704
INFO:root:current train perplexity3.3912811279296875
INFO:root:current mean train loss 6206.972423182708
INFO:root:current train perplexity3.397303581237793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 11911.223138718378
INFO:root:eval perplexity: 11.769608497619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:44:26<10:10:44, 339.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6158.0307835820895
INFO:root:current train perplexity3.368602752685547
INFO:root:current mean train loss 6165.076364848428
INFO:root:current train perplexity3.3792405128479004
INFO:root:current mean train loss 6180.8531791315545
INFO:root:current train perplexity3.3777976036071777
INFO:root:current mean train loss 6185.590584819908
INFO:root:current train perplexity3.3838984966278076
INFO:root:current mean train loss 6192.143495090003
INFO:root:current train perplexity3.387322187423706


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11924.157380603609
INFO:root:eval perplexity: 11.801159858703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:50:05<10:05:14, 339.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6177.442795444542
INFO:root:current train perplexity3.3635332584381104
INFO:root:current mean train loss 6152.0156050118785
INFO:root:current train perplexity3.362886905670166
INFO:root:current mean train loss 6157.963414941767
INFO:root:current train perplexity3.3687822818756104
INFO:root:current mean train loss 6167.402689890077
INFO:root:current train perplexity3.373060703277588
INFO:root:current mean train loss 6174.691416616905
INFO:root:current train perplexity3.3764142990112305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11937.1337890625
INFO:root:eval perplexity: 11.832901000976562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [8:55:44<9:59:20, 339.25s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6143.25421875
INFO:root:current train perplexity3.360914707183838
INFO:root:current mean train loss 6135.3523214285715
INFO:root:current train perplexity3.3597664833068848
INFO:root:current mean train loss 6143.414011008523
INFO:root:current train perplexity3.3620002269744873
INFO:root:current mean train loss 6151.974311197917
INFO:root:current train perplexity3.363243341445923
INFO:root:current mean train loss 6156.921549136513
INFO:root:current train perplexity3.366173267364502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11947.63330078125
INFO:root:eval perplexity: 11.858643531799316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [9:01:23<9:53:27, 339.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6116.456406991693
INFO:root:current train perplexity3.3524272441864014
INFO:root:current mean train loss 6131.887166113826
INFO:root:current train perplexity3.3547327518463135
INFO:root:current mean train loss 6140.098207535282
INFO:root:current train perplexity3.360015392303467
INFO:root:current mean train loss 6144.051961370383
INFO:root:current train perplexity3.3596014976501465
INFO:root:current mean train loss 6145.076954756002
INFO:root:current train perplexity3.357457160949707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 11974.29223342169
INFO:root:eval perplexity: 11.924263000488281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [9:07:03<9:48:13, 339.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6122.566729809864
INFO:root:current train perplexity3.3160552978515625
INFO:root:current mean train loss 6121.012351114242
INFO:root:current train perplexity3.3308260440826416
INFO:root:current mean train loss 6123.9096783210025
INFO:root:current train perplexity3.337862014770508
INFO:root:current mean train loss 6124.5583336733025
INFO:root:current train perplexity3.341437578201294
INFO:root:current mean train loss 6124.870441697399
INFO:root:current train perplexity3.3447093963623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.59s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 11973.867268880209
INFO:root:eval perplexity: 11.923213958740234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:12:42<9:42:12, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6074.645844558189
INFO:root:current train perplexity3.3195998668670654
INFO:root:current mean train loss 6100.191025025067
INFO:root:current train perplexity3.3323187828063965
INFO:root:current mean train loss 6105.5020960365855
INFO:root:current train perplexity3.331129550933838
INFO:root:current mean train loss 6111.050906159157
INFO:root:current train perplexity3.332191228866577
INFO:root:current mean train loss 6112.582920583612
INFO:root:current train perplexity3.3352081775665283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 11987.915573846727
INFO:root:eval perplexity: 11.957934379577637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:18:21<9:36:44, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6080.240631438874
INFO:root:current train perplexity3.299685478210449
INFO:root:current mean train loss 6085.829137352749
INFO:root:current train perplexity3.3127403259277344
INFO:root:current mean train loss 6092.0888554419025
INFO:root:current train perplexity3.322288751602173
INFO:root:current mean train loss 6092.540197660246
INFO:root:current train perplexity3.322450637817383
INFO:root:current mean train loss 6099.592421397658
INFO:root:current train perplexity3.327807903289795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 11996.427484421503
INFO:root:eval perplexity: 11.979022026062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:24:00<9:30:59, 339.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6075.21320415296
INFO:root:current train perplexity3.2991249561309814
INFO:root:current mean train loss 6082.638842147436
INFO:root:current train perplexity3.3014419078826904
INFO:root:current mean train loss 6075.404010527012
INFO:root:current train perplexity3.3093228340148926
INFO:root:current mean train loss 6084.168212272548
INFO:root:current train perplexity3.3141796588897705
INFO:root:current mean train loss 6084.342703401199
INFO:root:current train perplexity3.3178906440734863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12011.681329636347
INFO:root:eval perplexity: 12.0169095993042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:29:39<9:25:19, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6071.298191879735
INFO:root:current train perplexity3.2911553382873535
INFO:root:current mean train loss 6061.486379652167
INFO:root:current train perplexity3.293412685394287
INFO:root:current mean train loss 6062.11947539977
INFO:root:current train perplexity3.299862861633301
INFO:root:current mean train loss 6062.941047687578
INFO:root:current train perplexity3.3040430545806885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12029.491359165737
INFO:root:eval perplexity: 12.061290740966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:35:19<9:19:43, 339.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6002.756022135417
INFO:root:current train perplexity3.253932237625122
INFO:root:current mean train loss 6022.024328731796
INFO:root:current train perplexity3.273268699645996
INFO:root:current mean train loss 6038.92909338439
INFO:root:current train perplexity3.280942440032959
INFO:root:current mean train loss 6048.616937719163
INFO:root:current train perplexity3.2883715629577637
INFO:root:current mean train loss 6049.803496481467
INFO:root:current train perplexity3.294048309326172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12035.735831124442
INFO:root:eval perplexity: 12.076889038085938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:40:58<9:14:01, 339.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5897.534040178572
INFO:root:current train perplexity3.2643344402313232
INFO:root:current mean train loss 6021.3703909900705
INFO:root:current train perplexity3.276294231414795
INFO:root:current mean train loss 6025.923280872585
INFO:root:current train perplexity3.282130479812622
INFO:root:current mean train loss 6030.919400193404
INFO:root:current train perplexity3.282912015914917
INFO:root:current mean train loss 6035.150106294149
INFO:root:current train perplexity3.286167621612549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 12054.994326636905
INFO:root:eval perplexity: 12.125128746032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:46:37<9:08:20, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6057.661754261364
INFO:root:current train perplexity3.2580337524414062
INFO:root:current mean train loss 6018.465745530687
INFO:root:current train perplexity3.262984275817871
INFO:root:current mean train loss 6019.909225970083
INFO:root:current train perplexity3.274567127227783
INFO:root:current mean train loss 6023.627990918911
INFO:root:current train perplexity3.276379346847534
INFO:root:current mean train loss 6027.388220422749
INFO:root:current train perplexity3.2777931690216064


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.10s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12064.65462530227
INFO:root:eval perplexity: 12.149397850036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:52:16<9:02:42, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5976.363802083333
INFO:root:current train perplexity3.246701240539551
INFO:root:current mean train loss 5997.419624660326
INFO:root:current train perplexity3.2475626468658447
INFO:root:current mean train loss 6000.627507267442
INFO:root:current train perplexity3.2565174102783203
INFO:root:current mean train loss 6002.275055803571
INFO:root:current train perplexity3.261068105697632
INFO:root:current mean train loss 6007.972642131024
INFO:root:current train perplexity3.2669055461883545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 12068.29774111793
INFO:root:eval perplexity: 12.158560752868652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [9:57:56<8:57:14, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5930.6990388569075
INFO:root:current train perplexity3.2421038150787354
INFO:root:current mean train loss 5972.614549139968
INFO:root:current train perplexity3.251566171646118
INFO:root:current mean train loss 5982.794783640125
INFO:root:current train perplexity3.2541117668151855
INFO:root:current mean train loss 5988.111237815929
INFO:root:current train perplexity3.256209135055542
INFO:root:current mean train loss 5992.43352033301
INFO:root:current train perplexity3.258549451828003


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 12091.48282296317
INFO:root:eval perplexity: 12.21705150604248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [10:03:35<8:51:38, 339.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5919.596106487772
INFO:root:current train perplexity3.2131855487823486
INFO:root:current mean train loss 5968.934689405488
INFO:root:current train perplexity3.248534679412842
INFO:root:current mean train loss 5959.709807665358
INFO:root:current train perplexity3.245877265930176
INFO:root:current mean train loss 5971.107104416602
INFO:root:current train perplexity3.2508738040924072
INFO:root:current mean train loss 5980.332032404329
INFO:root:current train perplexity3.252717971801758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 12095.995454334077
INFO:root:eval perplexity: 12.228468894958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [10:09:13<8:45:31, 339.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5903.638545283565
INFO:root:current train perplexity3.2459957599639893
INFO:root:current mean train loss 5932.407484159695
INFO:root:current train perplexity3.231980800628662
INFO:root:current mean train loss 5949.823513215859
INFO:root:current train perplexity3.23763108253479
INFO:root:current mean train loss 5960.656578507263
INFO:root:current train perplexity3.240997791290283
INFO:root:current mean train loss 5965.728262908006
INFO:root:current train perplexity3.2416670322418213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 12121.996239071801
INFO:root:eval perplexity: 12.294458389282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [10:14:53<8:40:11, 339.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5927.1429088961695
INFO:root:current train perplexity3.213834047317505
INFO:root:current mean train loss 5937.564296576813
INFO:root:current train perplexity3.2234573364257812
INFO:root:current mean train loss 5942.288337476326
INFO:root:current train perplexity3.2272262573242188
INFO:root:current mean train loss 5952.417810906816
INFO:root:current train perplexity3.2284631729125977
INFO:root:current mean train loss 5954.311063478828
INFO:root:current train perplexity3.232029914855957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 12138.703717912946
INFO:root:eval perplexity: 12.33704948425293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:20:34<8:35:12, 339.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5915.739885602678
INFO:root:current train perplexity3.2170522212982178
INFO:root:current mean train loss 5928.61298828125
INFO:root:current train perplexity3.213545560836792
INFO:root:current mean train loss 5938.084304355053
INFO:root:current train perplexity3.2176616191864014
INFO:root:current mean train loss 5938.913514458955
INFO:root:current train perplexity3.2221884727478027
INFO:root:current mean train loss 5941.339930181393
INFO:root:current train perplexity3.2253243923187256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 12143.21031842913
INFO:root:eval perplexity: 12.348567008972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:26:19<8:31:50, 341.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5919.844188201122
INFO:root:current train perplexity3.2071118354797363
INFO:root:current mean train loss 5898.92731986286
INFO:root:current train perplexity3.2030420303344727
INFO:root:current mean train loss 5914.44041130034
INFO:root:current train perplexity3.2101187705993652
INFO:root:current mean train loss 5927.247341099742
INFO:root:current train perplexity3.214458465576172
INFO:root:current mean train loss 5930.892621503061
INFO:root:current train perplexity3.2163548469543457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12156.359151204428
INFO:root:eval perplexity: 12.382220268249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:31:58<8:25:13, 340.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5898.182651253634
INFO:root:current train perplexity3.1885383129119873
INFO:root:current mean train loss 5892.823754370629
INFO:root:current train perplexity3.1979575157165527
INFO:root:current mean train loss 5902.471408420139
INFO:root:current train perplexity3.199763536453247
INFO:root:current mean train loss 5906.77682699754
INFO:root:current train perplexity3.2056283950805664
INFO:root:current mean train loss 5913.332760916337
INFO:root:current train perplexity3.2097249031066895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12164.332077752977
INFO:root:eval perplexity: 12.402671813964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:37:37<8:18:51, 340.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5881.6064453125
INFO:root:current train perplexity3.1918210983276367
INFO:root:current mean train loss 5903.104943930697
INFO:root:current train perplexity3.1944572925567627
INFO:root:current mean train loss 5903.745973162323
INFO:root:current train perplexity3.203057289123535
INFO:root:current mean train loss 5906.543966419758
INFO:root:current train perplexity3.203294038772583
INFO:root:current mean train loss 5907.9759540600535
INFO:root:current train perplexity3.2026426792144775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 12179.883829752604
INFO:root:eval perplexity: 12.442662239074707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:43:16<8:12:44, 339.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5852.0001531862745
INFO:root:current train perplexity3.1872355937957764
INFO:root:current mean train loss 5861.040035828849
INFO:root:current train perplexity3.188812017440796
INFO:root:current mean train loss 5870.496146274278
INFO:root:current train perplexity3.1871488094329834
INFO:root:current mean train loss 5885.153595753205
INFO:root:current train perplexity3.1916704177856445
INFO:root:current mean train loss 5888.4633388477
INFO:root:current train perplexity3.19317626953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 12189.01332310268
INFO:root:eval perplexity: 12.466194152832031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:48:55<8:06:49, 339.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5848.012748579546
INFO:root:current train perplexity3.168111801147461
INFO:root:current mean train loss 5841.8351184475805
INFO:root:current train perplexity3.1670360565185547
INFO:root:current mean train loss 5858.242882582721
INFO:root:current train perplexity3.1741344928741455
INFO:root:current mean train loss 5867.408822073064
INFO:root:current train perplexity3.1793465614318848
INFO:root:current mean train loss 5874.465340616415
INFO:root:current train perplexity3.183213233947754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12206.191920689174
INFO:root:eval perplexity: 12.510602951049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [10:54:35<8:01:02, 339.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5841.87158203125
INFO:root:current train perplexity3.1692047119140625
INFO:root:current mean train loss 5854.467573825668
INFO:root:current train perplexity3.1698718070983887
INFO:root:current mean train loss 5857.592271959459
INFO:root:current train perplexity3.1701300144195557
INFO:root:current mean train loss 5859.462497551794
INFO:root:current train perplexity3.1737875938415527
INFO:root:current mean train loss 5866.459724775327
INFO:root:current train perplexity3.1770312786102295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12203.80639939081
INFO:root:eval perplexity: 12.504426956176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [11:00:14<7:55:12, 339.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5831.506975446428
INFO:root:current train perplexity3.1687705516815186
INFO:root:current mean train loss 5836.929894195744
INFO:root:current train perplexity3.1649885177612305
INFO:root:current mean train loss 5841.121309113593
INFO:root:current train perplexity3.1656911373138428
INFO:root:current mean train loss 5843.155089155045
INFO:root:current train perplexity3.1674067974090576
INFO:root:current mean train loss 5851.654544706736
INFO:root:current train perplexity3.1703736782073975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 12218.050935291109
INFO:root:eval perplexity: 12.541351318359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [11:05:53<7:49:32, 339.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5808.819642024254
INFO:root:current train perplexity3.1457462310791016
INFO:root:current mean train loss 5827.85498339259
INFO:root:current train perplexity3.1515214443206787
INFO:root:current mean train loss 5837.016230322449
INFO:root:current train perplexity3.1572232246398926
INFO:root:current mean train loss 5838.401263411103
INFO:root:current train perplexity3.1612017154693604
INFO:root:current mean train loss 5841.315255077288
INFO:root:current train perplexity3.16202974319458


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12233.968752906436
INFO:root:eval perplexity: 12.58273983001709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [11:11:32<7:43:45, 339.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5801.343811894806
INFO:root:current train perplexity3.143781900405884
INFO:root:current mean train loss 5806.548830980446
INFO:root:current train perplexity3.1488866806030273
INFO:root:current mean train loss 5809.0216195081875
INFO:root:current train perplexity3.1503520011901855
INFO:root:current mean train loss 5821.653408492672
INFO:root:current train perplexity3.152390956878662
INFO:root:current mean train loss 5827.1998542413085
INFO:root:current train perplexity3.154527187347412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12238.765154157367
INFO:root:eval perplexity: 12.595237731933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [11:17:12<7:38:14, 339.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5796.448717447916
INFO:root:current train perplexity3.142517328262329
INFO:root:current mean train loss 5800.910340401786
INFO:root:current train perplexity3.141228437423706
INFO:root:current mean train loss 5805.692919034091
INFO:root:current train perplexity3.1427881717681885
INFO:root:current mean train loss 5812.854709635417
INFO:root:current train perplexity3.145115375518799
INFO:root:current mean train loss 5816.024884868421
INFO:root:current train perplexity3.1471312046051025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12243.84654889788
INFO:root:eval perplexity: 12.60849380493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:22:51<7:32:38, 339.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5804.725530310522
INFO:root:current train perplexity3.1351490020751953
INFO:root:current mean train loss 5810.525963468925
INFO:root:current train perplexity3.1327717304229736
INFO:root:current mean train loss 5811.873137880824
INFO:root:current train perplexity3.1366662979125977
INFO:root:current mean train loss 5810.595642572972
INFO:root:current train perplexity3.137817859649658
INFO:root:current mean train loss 5808.029953353341
INFO:root:current train perplexity3.1400551795959473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12268.853768484933
INFO:root:eval perplexity: 12.673928260803223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:28:30<7:26:46, 339.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5778.605409920934
INFO:root:current train perplexity3.1265313625335693
INFO:root:current mean train loss 5782.355442067965
INFO:root:current train perplexity3.13254451751709
INFO:root:current mean train loss 5785.895438797483
INFO:root:current train perplexity3.132284164428711
INFO:root:current mean train loss 5792.431163817722
INFO:root:current train perplexity3.13191556930542
INFO:root:current mean train loss 5796.747032907932
INFO:root:current train perplexity3.1339597702026367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 12280.339631580171
INFO:root:eval perplexity: 12.704095840454102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:34:11<7:21:37, 339.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5771.862972566451
INFO:root:current train perplexity3.112752676010132
INFO:root:current mean train loss 5766.367490391042
INFO:root:current train perplexity3.115506649017334
INFO:root:current mean train loss 5770.697879804551
INFO:root:current train perplexity3.1173043251037598
INFO:root:current mean train loss 5776.224803678133
INFO:root:current train perplexity3.122591972351074
INFO:root:current mean train loss 5782.240211314489
INFO:root:current train perplexity3.127190351486206


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12280.547988164992
INFO:root:eval perplexity: 12.704644203186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:39:50<7:15:45, 339.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5741.59043934581
INFO:root:current train perplexity3.105961561203003
INFO:root:current mean train loss 5763.638620746074
INFO:root:current train perplexity3.11521577835083
INFO:root:current mean train loss 5769.987831561426
INFO:root:current train perplexity3.1176888942718506
INFO:root:current mean train loss 5772.50131249001
INFO:root:current train perplexity3.1188130378723145
INFO:root:current mean train loss 5774.709568124682
INFO:root:current train perplexity3.121446132659912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 12295.22620500837
INFO:root:eval perplexity: 12.743305206298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:45:30<7:10:07, 339.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5741.864956825658
INFO:root:current train perplexity3.1114280223846436
INFO:root:current mean train loss 5759.765902944711
INFO:root:current train perplexity3.111020803451538
INFO:root:current mean train loss 5760.56687135858
INFO:root:current train perplexity3.1128110885620117
INFO:root:current mean train loss 5757.594595530063
INFO:root:current train perplexity3.1140506267547607
INFO:root:current mean train loss 5763.1346107559975
INFO:root:current train perplexity3.1143245697021484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.32s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 12309.188915434337
INFO:root:eval perplexity: 12.780184745788574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:51:09<7:04:23, 339.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5737.54303286774
INFO:root:current train perplexity3.099285840988159
INFO:root:current mean train loss 5744.08369238772
INFO:root:current train perplexity3.1023738384246826
INFO:root:current mean train loss 5751.441528728575
INFO:root:current train perplexity3.1050477027893066
INFO:root:current mean train loss 5750.535841557017
INFO:root:current train perplexity3.1065871715545654


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 12327.21665736607
INFO:root:eval perplexity: 12.827962875366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [11:56:49<6:58:48, 339.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5770.930989583333
INFO:root:current train perplexity3.152562141418457
INFO:root:current mean train loss 5718.771721404733
INFO:root:current train perplexity3.078017473220825
INFO:root:current mean train loss 5738.281293295874
INFO:root:current train perplexity3.088965892791748
INFO:root:current mean train loss 5737.7779448354995
INFO:root:current train perplexity3.0940659046173096
INFO:root:current mean train loss 5738.88337347821
INFO:root:current train perplexity3.098738670349121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12327.361691429502
INFO:root:eval perplexity: 12.828351020812988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [12:02:28<6:52:56, 339.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5627.6572265625
INFO:root:current train perplexity3.064352512359619
INFO:root:current mean train loss 5727.624215099299
INFO:root:current train perplexity3.086977958679199
INFO:root:current mean train loss 5722.055477713617
INFO:root:current train perplexity3.0944979190826416
INFO:root:current mean train loss 5726.657654405029
INFO:root:current train perplexity3.094120502471924
INFO:root:current mean train loss 5731.80638988598
INFO:root:current train perplexity3.095430612564087


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12347.936645507812
INFO:root:eval perplexity: 12.883099555969238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [12:08:07<6:47:04, 339.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5689.469992897727
INFO:root:current train perplexity3.071305990219116
INFO:root:current mean train loss 5708.2250756615995
INFO:root:current train perplexity3.0826780796051025
INFO:root:current mean train loss 5707.815064055095
INFO:root:current train perplexity3.0885095596313477
INFO:root:current mean train loss 5713.6696267082
INFO:root:current train perplexity3.0862693786621094
INFO:root:current mean train loss 5712.657480801399
INFO:root:current train perplexity3.0883398056030273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12347.731718517485
INFO:root:eval perplexity: 12.882552146911621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [12:13:46<6:41:19, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5666.583984375
INFO:root:current train perplexity3.071739435195923
INFO:root:current mean train loss 5705.743401834239
INFO:root:current train perplexity3.0765316486358643
INFO:root:current mean train loss 5707.650218023256
INFO:root:current train perplexity3.0823421478271484
INFO:root:current mean train loss 5711.303683035714
INFO:root:current train perplexity3.0827507972717285
INFO:root:current mean train loss 5713.950572995105
INFO:root:current train perplexity3.084045648574829


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 12364.017624627977
INFO:root:eval perplexity: 12.926055908203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [12:19:25<6:35:38, 339.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5689.981676603618
INFO:root:current train perplexity3.0630943775177
INFO:root:current mean train loss 5679.410193178834
INFO:root:current train perplexity3.0684165954589844
INFO:root:current mean train loss 5682.240762788955
INFO:root:current train perplexity3.0692687034606934
INFO:root:current mean train loss 5691.159850117555
INFO:root:current train perplexity3.0736374855041504
INFO:root:current mean train loss 5697.449024136709
INFO:root:current train perplexity3.07407808303833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 12369.070271809896
INFO:root:eval perplexity: 12.939579963684082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:25:04<6:30:05, 339.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5658.421471637228
INFO:root:current train perplexity3.0368480682373047
INFO:root:current mean train loss 5676.574083777947
INFO:root:current train perplexity3.0626566410064697
INFO:root:current mean train loss 5674.56268392657
INFO:root:current train perplexity3.0661978721618652
INFO:root:current mean train loss 5687.2167832696405
INFO:root:current train perplexity3.0682218074798584
INFO:root:current mean train loss 5692.070821559176
INFO:root:current train perplexity3.072110176086426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12377.076116652715
INFO:root:eval perplexity: 12.961041450500488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:30:43<6:24:12, 339.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5697.4483326099535
INFO:root:current train perplexity3.067736864089966
INFO:root:current mean train loss 5690.081012395423
INFO:root:current train perplexity3.063272714614868
INFO:root:current mean train loss 5686.900313188326
INFO:root:current train perplexity3.064394950866699
INFO:root:current mean train loss 5681.039670238437
INFO:root:current train perplexity3.064168930053711
INFO:root:current mean train loss 5680.8210546417595
INFO:root:current train perplexity3.067352056503296


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12383.25341796875
INFO:root:eval perplexity: 12.977624893188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:36:22<6:18:40, 339.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5613.673418598791
INFO:root:current train perplexity3.065173864364624
INFO:root:current mean train loss 5669.475462935353
INFO:root:current train perplexity3.056043863296509
INFO:root:current mean train loss 5669.329323508523
INFO:root:current train perplexity3.0603082180023193
INFO:root:current mean train loss 5676.839873253399
INFO:root:current train perplexity3.06024169921875
INFO:root:current mean train loss 5677.076301025957
INFO:root:current train perplexity3.0619287490844727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12399.941330682665
INFO:root:eval perplexity: 13.02253246307373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:42:01<6:13:01, 339.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5626.052915736607
INFO:root:current train perplexity3.0394978523254395
INFO:root:current mean train loss 5661.927520978009
INFO:root:current train perplexity3.0459132194519043
INFO:root:current mean train loss 5655.717742270612
INFO:root:current train perplexity3.045579433441162
INFO:root:current mean train loss 5663.88116691931
INFO:root:current train perplexity3.0520670413970947
INFO:root:current mean train loss 5663.162168866738
INFO:root:current train perplexity3.0521645545959473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12409.492257254464
INFO:root:eval perplexity: 13.048300743103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:47:40<6:07:12, 338.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5662.638897235577
INFO:root:current train perplexity3.034740686416626
INFO:root:current mean train loss 5642.500734178282
INFO:root:current train perplexity3.036688804626465
INFO:root:current mean train loss 5643.0140416612185
INFO:root:current train perplexity3.0439796447753906
INFO:root:current mean train loss 5647.929654371774
INFO:root:current train perplexity3.0479283332824707
INFO:root:current mean train loss 5656.354018365603
INFO:root:current train perplexity3.0485639572143555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12410.762701125372
INFO:root:eval perplexity: 13.051732063293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [12:53:19<6:01:45, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5635.3583984375
INFO:root:current train perplexity3.045409917831421
INFO:root:current mean train loss 5636.8458909254805
INFO:root:current train perplexity3.036360502243042
INFO:root:current mean train loss 5637.982813705633
INFO:root:current train perplexity3.0389833450317383
INFO:root:current mean train loss 5635.91670605184
INFO:root:current train perplexity3.040238618850708
INFO:root:current mean train loss 5643.217080144258
INFO:root:current train perplexity3.04101824760437


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12436.964808872768
INFO:root:eval perplexity: 13.122714042663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [12:58:59<5:56:11, 339.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5649.283919963431
INFO:root:current train perplexity3.0486297607421875
INFO:root:current mean train loss 5642.001800329507
INFO:root:current train perplexity3.036510705947876
INFO:root:current mean train loss 5632.9640470805925
INFO:root:current train perplexity3.037109136581421
INFO:root:current mean train loss 5634.43986682727
INFO:root:current train perplexity3.0372612476348877
INFO:root:current mean train loss 5636.074473267967
INFO:root:current train perplexity3.037410020828247


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 12431.401547386533
INFO:root:eval perplexity: 13.107611656188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [13:04:38<5:50:34, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5554.0053615196075
INFO:root:current train perplexity3.0110137462615967
INFO:root:current mean train loss 5610.014784250828
INFO:root:current train perplexity3.0214693546295166
INFO:root:current mean train loss 5617.488456330926
INFO:root:current train perplexity3.026000738143921
INFO:root:current mean train loss 5619.8328047097575
INFO:root:current train perplexity3.03045392036438
INFO:root:current mean train loss 5627.386341983093
INFO:root:current train perplexity3.033071279525757


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12449.714303152901
INFO:root:eval perplexity: 13.157388687133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [13:10:17<5:44:52, 339.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5600.501029829546
INFO:root:current train perplexity3.018195390701294
INFO:root:current mean train loss 5615.80027406754
INFO:root:current train perplexity3.0243475437164307
INFO:root:current mean train loss 5619.895375689338
INFO:root:current train perplexity3.025721549987793
INFO:root:current mean train loss 5618.215212367958
INFO:root:current train perplexity3.0268499851226807
INFO:root:current mean train loss 5622.704827008929
INFO:root:current train perplexity3.0302646160125732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 12457.235089983258
INFO:root:eval perplexity: 13.177886009216309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [13:15:56<5:39:10, 339.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5580.6262910487285
INFO:root:current train perplexity3.032020330429077
INFO:root:current mean train loss 5595.537047955975
INFO:root:current train perplexity3.0247983932495117
INFO:root:current mean train loss 5603.426671090733
INFO:root:current train perplexity3.0230424404144287
INFO:root:current mean train loss 5605.96630859375
INFO:root:current train perplexity3.0227344036102295
INFO:root:current mean train loss 5610.554463039556
INFO:root:current train perplexity3.0230863094329834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12462.662054152715
INFO:root:eval perplexity: 13.19270133972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [13:21:35<5:33:28, 339.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5585.2294921875
INFO:root:current train perplexity3.0074281692504883
INFO:root:current mean train loss 5586.477392278566
INFO:root:current train perplexity3.0162875652313232
INFO:root:current mean train loss 5593.533010040399
INFO:root:current train perplexity3.0168700218200684
INFO:root:current mean train loss 5601.7126431215565
INFO:root:current train perplexity3.0170199871063232
INFO:root:current mean train loss 5601.342706997502
INFO:root:current train perplexity3.0175230503082275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12473.895685105097
INFO:root:eval perplexity: 13.223410606384277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:27:15<5:27:55, 339.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5576.968735424441
INFO:root:current train perplexity3.0137534141540527
INFO:root:current mean train loss 5579.774457920097
INFO:root:current train perplexity3.0117104053497314
INFO:root:current mean train loss 5583.459355615051
INFO:root:current train perplexity3.008720636367798
INFO:root:current mean train loss 5590.90839604266
INFO:root:current train perplexity3.0084681510925293
INFO:root:current mean train loss 5593.856700431611
INFO:root:current train perplexity3.011183023452759


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 12480.200538271949
INFO:root:eval perplexity: 13.240679740905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:32:54<5:22:11, 339.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5600.72245681118
INFO:root:current train perplexity3.0029985904693604
INFO:root:current mean train loss 5579.47264197277
INFO:root:current train perplexity3.0007779598236084
INFO:root:current mean train loss 5577.309941478321
INFO:root:current train perplexity2.9992434978485107
INFO:root:current mean train loss 5583.558770110344
INFO:root:current train perplexity3.0042731761932373
INFO:root:current mean train loss 5587.929771471935
INFO:root:current train perplexity3.007958173751831


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.39s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 12488.86634172712
INFO:root:eval perplexity: 13.264450073242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:38:33<5:16:37, 339.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5564.678821614583
INFO:root:current train perplexity2.9965720176696777
INFO:root:current mean train loss 5559.021409040179
INFO:root:current train perplexity2.992581605911255
INFO:root:current mean train loss 5576.125630326705
INFO:root:current train perplexity2.9987757205963135
INFO:root:current mean train loss 5576.4513671875
INFO:root:current train perplexity3.0012755393981934
INFO:root:current mean train loss 5580.866278782894
INFO:root:current train perplexity3.0047402381896973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 12477.744652157739
INFO:root:eval perplexity: 13.233951568603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:44:13<5:11:00, 339.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5564.294025662579
INFO:root:current train perplexity2.987905263900757
INFO:root:current mean train loss 5565.705896473463
INFO:root:current train perplexity2.9983737468719482
INFO:root:current mean train loss 5564.757971760193
INFO:root:current train perplexity2.996946334838867
INFO:root:current mean train loss 5567.629884100841
INFO:root:current train perplexity2.997725009918213
INFO:root:current mean train loss 5571.81676201233
INFO:root:current train perplexity2.998817205429077


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 12492.438988095239
INFO:root:eval perplexity: 13.274264335632324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [13:49:52<5:05:22, 339.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5547.767313394202
INFO:root:current train perplexity2.9921658039093018
INFO:root:current mean train loss 5552.076940317623
INFO:root:current train perplexity2.988887310028076
INFO:root:current mean train loss 5560.784483353577
INFO:root:current train perplexity2.991896152496338
INFO:root:current mean train loss 5562.895855856315
INFO:root:current train perplexity2.9925496578216553
INFO:root:current mean train loss 5566.270772677278
INFO:root:current train perplexity2.995187997817993


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12511.56448218936
INFO:root:eval perplexity: 13.326916694641113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [13:55:31<4:59:42, 339.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5537.9506218570405
INFO:root:current train perplexity2.982328176498413
INFO:root:current mean train loss 5540.51619422627
INFO:root:current train perplexity2.991037130355835
INFO:root:current mean train loss 5554.199710433907
INFO:root:current train perplexity2.993687391281128
INFO:root:current mean train loss 5552.56961729853
INFO:root:current train perplexity2.9892313480377197
INFO:root:current mean train loss 5557.671847928966
INFO:root:current train perplexity2.9904284477233887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12514.305669875372
INFO:root:eval perplexity: 13.334484100341797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [14:01:10<4:53:57, 339.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5531.641531808035
INFO:root:current train perplexity2.9797706604003906
INFO:root:current mean train loss 5542.038896330988
INFO:root:current train perplexity2.9836461544036865
INFO:root:current mean train loss 5541.947003865979
INFO:root:current train perplexity2.9824953079223633
INFO:root:current mean train loss 5548.0465378236895
INFO:root:current train perplexity2.984163999557495
INFO:root:current mean train loss 5549.02310733834
INFO:root:current train perplexity2.986126184463501


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 12523.574832007998
INFO:root:eval perplexity: 13.360092163085938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [14:06:49<4:48:06, 338.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5535.9455386513155
INFO:root:current train perplexity2.9850094318389893
INFO:root:current mean train loss 5537.492385316506
INFO:root:current train perplexity2.980870246887207
INFO:root:current mean train loss 5540.018020060911
INFO:root:current train perplexity2.980093002319336
INFO:root:current mean train loss 5537.502603342563
INFO:root:current train perplexity2.9799447059631348
INFO:root:current mean train loss 5544.076451033775
INFO:root:current train perplexity2.9823784828186035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12536.975742885044
INFO:root:eval perplexity: 13.397204399108887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [14:12:28<4:42:32, 339.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5534.90676294192
INFO:root:current train perplexity2.9694979190826416
INFO:root:current mean train loss 5532.15943977701
INFO:root:current train perplexity2.973391056060791
INFO:root:current mean train loss 5533.922413905728
INFO:root:current train perplexity2.9746029376983643
INFO:root:current mean train loss 5532.508835565476
INFO:root:current train perplexity2.9738125801086426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12538.003426688058
INFO:root:eval perplexity: 13.400050163269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [14:18:08<4:37:03, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5560.3359375
INFO:root:current train perplexity3.01194167137146
INFO:root:current mean train loss 5514.9282463592235
INFO:root:current train perplexity2.973095417022705
INFO:root:current mean train loss 5520.963131157636
INFO:root:current train perplexity2.969442129135132
INFO:root:current mean train loss 5529.318618824773
INFO:root:current train perplexity2.971615791320801
INFO:root:current mean train loss 5528.364319604916
INFO:root:current train perplexity2.973721504211426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 12538.553734188989
INFO:root:eval perplexity: 13.401577949523926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [14:23:47<4:31:23, 339.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5523.798967633928
INFO:root:current train perplexity3.0093913078308105
INFO:root:current mean train loss 5505.369774934287
INFO:root:current train perplexity2.962928295135498
INFO:root:current mean train loss 5512.615982129378
INFO:root:current train perplexity2.9672532081604004
INFO:root:current mean train loss 5519.6059554407575
INFO:root:current train perplexity2.966895818710327
INFO:root:current mean train loss 5520.196771345209
INFO:root:current train perplexity2.969310998916626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 12557.51216343471
INFO:root:eval perplexity: 13.454277038574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:29:27<4:25:51, 339.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5457.337180397727
INFO:root:current train perplexity2.9765753746032715
INFO:root:current mean train loss 5495.368128871059
INFO:root:current train perplexity2.974790096282959
INFO:root:current mean train loss 5501.673110744964
INFO:root:current train perplexity2.9664971828460693
INFO:root:current mean train loss 5515.490813718348
INFO:root:current train perplexity2.9663968086242676
INFO:root:current mean train loss 5517.376365049042
INFO:root:current train perplexity2.9653279781341553


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 12563.527282714844
INFO:root:eval perplexity: 13.471037864685059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:35:06<4:20:13, 339.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5511.860319010417
INFO:root:current train perplexity2.9395251274108887
INFO:root:current mean train loss 5507.615879755434
INFO:root:current train perplexity2.9473462104797363
INFO:root:current mean train loss 5511.044524436773
INFO:root:current train perplexity2.95637845993042
INFO:root:current mean train loss 5513.129670448909
INFO:root:current train perplexity2.9581048488616943
INFO:root:current mean train loss 5513.18095703125
INFO:root:current train perplexity2.9614412784576416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 12570.864592052641
INFO:root:eval perplexity: 13.49151611328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:40:45<4:14:30, 339.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5491.069413034539
INFO:root:current train perplexity2.940642833709717
INFO:root:current mean train loss 5494.053772485557
INFO:root:current train perplexity2.953280210494995
INFO:root:current mean train loss 5494.52872386915
INFO:root:current train perplexity2.9565603733062744
INFO:root:current mean train loss 5497.483421397434
INFO:root:current train perplexity2.9569177627563477
INFO:root:current mean train loss 5501.275875410203
INFO:root:current train perplexity2.9590210914611816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12571.079929896763
INFO:root:eval perplexity: 13.492114067077637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [14:46:25<4:08:56, 339.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5465.273819633152
INFO:root:current train perplexity2.942362070083618
INFO:root:current mean train loss 5475.510039538872
INFO:root:current train perplexity2.95447039604187
INFO:root:current mean train loss 5488.771298258828
INFO:root:current train perplexity2.9534366130828857
INFO:root:current mean train loss 5492.720996396091
INFO:root:current train perplexity2.9538917541503906
INFO:root:current mean train loss 5494.401776974365
INFO:root:current train perplexity2.955746650695801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 12580.555879138765
INFO:root:eval perplexity: 13.518597602844238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [14:52:04<4:03:09, 339.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5470.043746383102
INFO:root:current train perplexity2.9333486557006836
INFO:root:current mean train loss 5492.964978315699
INFO:root:current train perplexity2.9361143112182617
INFO:root:current mean train loss 5496.548946431029
INFO:root:current train perplexity2.9446053504943848
INFO:root:current mean train loss 5500.053501887423
INFO:root:current train perplexity2.946897268295288
INFO:root:current mean train loss 5492.0313026017275
INFO:root:current train perplexity2.951491355895996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12582.241426013765
INFO:root:eval perplexity: 13.523317337036133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [14:57:43<3:57:32, 339.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5489.203440020161
INFO:root:current train perplexity2.9511682987213135
INFO:root:current mean train loss 5476.299506500477
INFO:root:current train perplexity2.9408798217773438
INFO:root:current mean train loss 5485.440789028679
INFO:root:current train perplexity2.9424290657043457
INFO:root:current mean train loss 5489.721212058629
INFO:root:current train perplexity2.946024179458618
INFO:root:current mean train loss 5485.658639292706
INFO:root:current train perplexity2.9468655586242676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 12595.554768880209
INFO:root:eval perplexity: 13.560637474060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [15:03:23<3:51:52, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5463.36455078125
INFO:root:current train perplexity2.9249935150146484
INFO:root:current mean train loss 5468.619921875
INFO:root:current train perplexity2.936420202255249
INFO:root:current mean train loss 5457.271752410239
INFO:root:current train perplexity2.937032461166382
INFO:root:current mean train loss 5469.9912109375
INFO:root:current train perplexity2.9416706562042236
INFO:root:current mean train loss 5478.442337913075
INFO:root:current train perplexity2.9448208808898926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.71s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12598.16869826544
INFO:root:eval perplexity: 13.567978858947754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [15:09:01<3:46:06, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5442.033916766827
INFO:root:current train perplexity2.9399631023406982
INFO:root:current mean train loss 5453.405730103417
INFO:root:current train perplexity2.9416096210479736
INFO:root:current mean train loss 5466.184807302563
INFO:root:current train perplexity2.9394359588623047
INFO:root:current mean train loss 5471.848658738938
INFO:root:current train perplexity2.942322015762329
INFO:root:current mean train loss 5475.212754929527
INFO:root:current train perplexity2.94354510307312


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 12604.178774879092
INFO:root:eval perplexity: 13.58486557006836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [15:14:41<3:40:27, 339.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5450.172454124273
INFO:root:current train perplexity2.954022169113159
INFO:root:current mean train loss 5464.517926409528
INFO:root:current train perplexity2.939814805984497
INFO:root:current mean train loss 5463.553413548097
INFO:root:current train perplexity2.935955762863159
INFO:root:current mean train loss 5465.80419779519
INFO:root:current train perplexity2.9373698234558105
INFO:root:current mean train loss 5467.36031188276
INFO:root:current train perplexity2.9384841918945312


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12612.278549920946
INFO:root:eval perplexity: 13.607660293579102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [15:20:19<3:34:44, 339.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5467.317652925532
INFO:root:current train perplexity2.923887014389038
INFO:root:current mean train loss 5447.64461761267
INFO:root:current train perplexity2.92323637008667
INFO:root:current mean train loss 5458.656833169914
INFO:root:current train perplexity2.930820941925049
INFO:root:current mean train loss 5457.1375461545385
INFO:root:current train perplexity2.932772159576416
INFO:root:current mean train loss 5460.504110519784
INFO:root:current train perplexity2.9354546070098877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12614.497108096168
INFO:root:eval perplexity: 13.613910675048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [15:25:58<3:29:04, 339.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5452.461569393382
INFO:root:current train perplexity2.928057909011841
INFO:root:current mean train loss 5445.011906301738
INFO:root:current train perplexity2.9307148456573486
INFO:root:current mean train loss 5446.839904055652
INFO:root:current train perplexity2.9308691024780273
INFO:root:current mean train loss 5453.976019965277
INFO:root:current train perplexity2.932145357131958
INFO:root:current mean train loss 5453.061411923157
INFO:root:current train perplexity2.9310731887817383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 12620.35710216704
INFO:root:eval perplexity: 13.6304349899292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [15:31:37<3:23:24, 339.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5449.223428622159
INFO:root:current train perplexity2.9222660064697266
INFO:root:current mean train loss 5452.637380292339
INFO:root:current train perplexity2.9259395599365234
INFO:root:current mean train loss 5455.227188648897
INFO:root:current train perplexity2.9271628856658936
INFO:root:current mean train loss 5453.457170169454
INFO:root:current train perplexity2.9273571968078613
INFO:root:current mean train loss 5453.90471432864
INFO:root:current train perplexity2.929266929626465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.72s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 12632.091587611607
INFO:root:eval perplexity: 13.663583755493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:37:17<3:17:53, 339.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5416.869662010064
INFO:root:current train perplexity2.924740791320801
INFO:root:current mean train loss 5443.851737544222
INFO:root:current train perplexity2.9262936115264893
INFO:root:current mean train loss 5444.954195825289
INFO:root:current train perplexity2.9266607761383057
INFO:root:current mean train loss 5447.63093146109
INFO:root:current train perplexity2.9286160469055176
INFO:root:current mean train loss 5446.987603613494
INFO:root:current train perplexity2.926607370376587


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 12634.859688895089
INFO:root:eval perplexity: 13.671414375305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:42:57<3:12:23, 339.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5434.779916914683
INFO:root:current train perplexity2.91767954826355
INFO:root:current mean train loss 5434.172123634011
INFO:root:current train perplexity2.920034885406494
INFO:root:current mean train loss 5437.932167894487
INFO:root:current train perplexity2.920783042907715
INFO:root:current mean train loss 5439.067634351326
INFO:root:current train perplexity2.921858787536621
INFO:root:current mean train loss 5444.723856388364
INFO:root:current train perplexity2.9226179122924805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 12638.1877179827
INFO:root:eval perplexity: 13.68083381652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [15:48:36<3:06:37, 339.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5434.898707147854
INFO:root:current train perplexity2.923266649246216
INFO:root:current mean train loss 5425.655796804828
INFO:root:current train perplexity2.919080972671509
INFO:root:current mean train loss 5432.232116470623
INFO:root:current train perplexity2.9185523986816406
INFO:root:current mean train loss 5437.548770914936
INFO:root:current train perplexity2.9186904430389404
INFO:root:current mean train loss 5440.257394271948
INFO:root:current train perplexity2.921415328979492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 12644.499662853423
INFO:root:eval perplexity: 13.69871997833252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [15:54:15<3:00:53, 339.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5417.5047796544895
INFO:root:current train perplexity2.9111645221710205
INFO:root:current mean train loss 5427.034873560855
INFO:root:current train perplexity2.9119656085968018
INFO:root:current mean train loss 5424.371412664322
INFO:root:current train perplexity2.9173731803894043
INFO:root:current mean train loss 5431.934612428403
INFO:root:current train perplexity2.9173574447631836
INFO:root:current mean train loss 5433.675355170183
INFO:root:current train perplexity2.918311595916748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 12649.189031691778
INFO:root:eval perplexity: 13.71202278137207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [15:59:54<2:55:15, 339.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5400.1653515625
INFO:root:current train perplexity2.8986668586730957
INFO:root:current mean train loss 5416.812974330357
INFO:root:current train perplexity2.9067800045013428
INFO:root:current mean train loss 5420.425537997159
INFO:root:current train perplexity2.9104673862457275
INFO:root:current mean train loss 5427.415759114583
INFO:root:current train perplexity2.9169530868530273
INFO:root:current mean train loss 5428.87638569079
INFO:root:current train perplexity2.9162847995758057


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12655.396187918526
INFO:root:eval perplexity: 13.72965145111084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [16:05:33<2:49:36, 339.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5407.964386372627
INFO:root:current train perplexity2.9038405418395996
INFO:root:current mean train loss 5414.404138660963
INFO:root:current train perplexity2.90482759475708
INFO:root:current mean train loss 5418.113606770833
INFO:root:current train perplexity2.9096665382385254
INFO:root:current mean train loss 5418.3895518119225
INFO:root:current train perplexity2.9133999347686768
INFO:root:current mean train loss 5425.039069635634
INFO:root:current train perplexity2.9136035442352295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12660.497334798178
INFO:root:eval perplexity: 13.744157791137695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [16:11:13<2:43:56, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5422.781961831702
INFO:root:current train perplexity2.895040988922119
INFO:root:current mean train loss 5416.1774995730875
INFO:root:current train perplexity2.900189161300659
INFO:root:current mean train loss 5418.030323473387
INFO:root:current train perplexity2.904712438583374
INFO:root:current mean train loss 5419.847414021704
INFO:root:current train perplexity2.908754825592041
INFO:root:current mean train loss 5420.460761597438
INFO:root:current train perplexity2.9117867946624756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12664.251659574962
INFO:root:eval perplexity: 13.754840850830078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [16:16:51<2:38:14, 339.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5402.721730199353
INFO:root:current train perplexity2.91104793548584
INFO:root:current mean train loss 5412.327216326872
INFO:root:current train perplexity2.9097611904144287
INFO:root:current mean train loss 5419.326061288654
INFO:root:current train perplexity2.9102847576141357
INFO:root:current mean train loss 5417.335306645672
INFO:root:current train perplexity2.9116370677948
INFO:root:current mean train loss 5420.289885659971
INFO:root:current train perplexity2.9112250804901123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 12666.300458635602
INFO:root:eval perplexity: 13.760672569274902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [16:22:31<2:32:40, 339.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5408.332970252404
INFO:root:current train perplexity2.904499053955078
INFO:root:current mean train loss 5403.778826488874
INFO:root:current train perplexity2.906430959701538
INFO:root:current mean train loss 5412.679645551439
INFO:root:current train perplexity2.9082515239715576
INFO:root:current mean train loss 5414.239687400096
INFO:root:current train perplexity2.908292293548584
INFO:root:current mean train loss 5415.045725400967
INFO:root:current train perplexity2.9075818061828613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12671.248561314174
INFO:root:eval perplexity: 13.77477741241455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [16:28:10<2:26:56, 339.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5392.966606702303
INFO:root:current train perplexity2.8938167095184326
INFO:root:current mean train loss 5397.31926582532
INFO:root:current train perplexity2.90037202835083
INFO:root:current mean train loss 5405.2662870762715
INFO:root:current train perplexity2.903273582458496
INFO:root:current mean train loss 5406.933650613133
INFO:root:current train perplexity2.9037387371063232
INFO:root:current mean train loss 5411.381013257575
INFO:root:current train perplexity2.9054617881774902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 12674.304704938617
INFO:root:eval perplexity: 13.783490180969238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [16:33:49<2:21:16, 339.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5392.037942905618
INFO:root:current train perplexity2.9086270332336426
INFO:root:current mean train loss 5408.784793106156
INFO:root:current train perplexity2.9033594131469727
INFO:root:current mean train loss 5413.280134628449
INFO:root:current train perplexity2.903498649597168
INFO:root:current mean train loss 5406.002879513237
INFO:root:current train perplexity2.9015934467315674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 12685.073375883556
INFO:root:eval perplexity: 13.814250946044922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [16:39:28<2:15:38, 339.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5320.137858072917
INFO:root:current train perplexity2.8612887859344482
INFO:root:current mean train loss 5385.2232820084955
INFO:root:current train perplexity2.9038593769073486
INFO:root:current mean train loss 5396.496021590209
INFO:root:current train perplexity2.9009647369384766
INFO:root:current mean train loss 5401.720780476485
INFO:root:current train perplexity2.900848388671875
INFO:root:current mean train loss 5404.909529844525
INFO:root:current train perplexity2.90193772315979


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 12681.299755278087
INFO:root:eval perplexity: 13.803468704223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:45:07<2:10:00, 339.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5383.885602678572
INFO:root:current train perplexity2.866769313812256
INFO:root:current mean train loss 5410.49994067611
INFO:root:current train perplexity2.896965503692627
INFO:root:current mean train loss 5405.10917213919
INFO:root:current train perplexity2.8945233821868896
INFO:root:current mean train loss 5402.718438263437
INFO:root:current train perplexity2.8980822563171387
INFO:root:current mean train loss 5400.151890260288
INFO:root:current train perplexity2.898047685623169


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 12681.24069359189
INFO:root:eval perplexity: 13.80329704284668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [16:50:47<2:04:23, 339.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5385.928666548295
INFO:root:current train perplexity2.9038596153259277
INFO:root:current mean train loss 5392.974244263795
INFO:root:current train perplexity2.899134397506714
INFO:root:current mean train loss 5396.089880776066
INFO:root:current train perplexity2.8964200019836426
INFO:root:current mean train loss 5396.127709882436
INFO:root:current train perplexity2.8955469131469727
INFO:root:current mean train loss 5397.614924298586
INFO:root:current train perplexity2.896846055984497


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 12688.436726888021
INFO:root:eval perplexity: 13.823871612548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [16:56:26<1:58:43, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5361.345572916666
INFO:root:current train perplexity2.874269723892212
INFO:root:current mean train loss 5389.629029381794
INFO:root:current train perplexity2.8913536071777344
INFO:root:current mean train loss 5394.0051507994185
INFO:root:current train perplexity2.8907432556152344
INFO:root:current mean train loss 5393.089236111111
INFO:root:current train perplexity2.8923051357269287
INFO:root:current mean train loss 5393.028342667545
INFO:root:current train perplexity2.8951785564422607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 12688.260585239956
INFO:root:eval perplexity: 13.823369979858398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base_64_low/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [17:02:05<1:53:03, 339.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5380.7353515625
INFO:root:current train perplexity2.891113519668579
INFO:root:current mean train loss 5385.539493336397
INFO:root:current train perplexity2.8888182640075684
INFO:root:current mean train loss 5393.754191638128
INFO:root:current train perplexity2.8956024646759033
slurmstepd: error: *** JOB 25935127 ON gv008 CANCELLED AT 2022-10-16T04:12:46 ***
