INFO:root:Output: small_val_138
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24459.4583136048
INFO:root:current train perplexity15528.50390625
INFO:root:current mean train loss 20546.495887641333
INFO:root:current train perplexity3286.620849609375
INFO:root:current mean train loss 17750.975896216554
INFO:root:current train perplexity1094.9151611328125
INFO:root:current mean train loss 15856.80073719455
INFO:root:current train perplexity514.5142211914062
INFO:root:current mean train loss 14483.508563024487
INFO:root:current train perplexity299.43280029296875
INFO:root:current mean train loss 13439.810770229027
INFO:root:current train perplexity199.0715789794922
INFO:root:current mean train loss 12629.657042147264
INFO:root:current train perplexity144.6338653564453
INFO:root:current mean train loss 11978.55601912058
INFO:root:current train perplexity112.1604232788086
INFO:root:current mean train loss 11445.646570733976
INFO:root:current train perplexity90.95306396484375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.53s/it]
INFO:root:final mean train loss: 11015.711554127354
INFO:root:final train perplexity: 77.1704330444336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it]
INFO:root:eval mean loss: 6411.286427166445
INFO:root:eval perplexity: 13.363618850708008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/1

  0%|          | 1/200 [04:43<15:41:17, 283.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6832.081403459822
INFO:root:current train perplexity14.558825492858887
INFO:root:current mean train loss 6731.4475074839365
INFO:root:current train perplexity14.400490760803223
INFO:root:current mean train loss 6702.763096316425
INFO:root:current train perplexity14.161800384521484
INFO:root:current mean train loss 6631.146630700326
INFO:root:current train perplexity13.742368698120117
INFO:root:current mean train loss 6577.697296817414
INFO:root:current train perplexity13.442877769470215
INFO:root:current mean train loss 6527.241297614645
INFO:root:current train perplexity13.170347213745117
INFO:root:current mean train loss 6484.613944089786
INFO:root:current train perplexity12.900148391723633
INFO:root:current mean train loss 6436.8751111927595
INFO:root:current train perplexity12.658191680908203
INFO:root:current mean train loss 6392.645274260378
INFO:root:current train perplexity12.43207836151123
INFO:root:current mean train loss 6348.494385034799
INFO:root:current train perplexity12.229690551757812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.14s/it]
INFO:root:final mean train loss: 6311.3579671306
INFO:root:final train perplexity: 12.061437606811523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 5541.4424312943265
INFO:root:eval perplexity: 9.400816917419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/2

  1%|          | 2/200 [09:55<16:29:58, 299.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5996.895768229167
INFO:root:current train perplexity10.678743362426758
INFO:root:current mean train loss 5885.059629755435
INFO:root:current train perplexity10.254027366638184
INFO:root:current mean train loss 5861.977552688953
INFO:root:current train perplexity10.109912872314453
INFO:root:current mean train loss 5841.609109933036
INFO:root:current train perplexity9.996262550354004
INFO:root:current mean train loss 5817.138578925075
INFO:root:current train perplexity9.905974388122559
INFO:root:current mean train loss 5791.298442240594
INFO:root:current train perplexity9.81781005859375
INFO:root:current mean train loss 5767.001633161839
INFO:root:current train perplexity9.739495277404785
INFO:root:current mean train loss 5748.689961893575
INFO:root:current train perplexity9.66347599029541
INFO:root:current mean train loss 5735.688357337998
INFO:root:current train perplexity9.593161582946777
INFO:root:current mean train loss 5716.853818732923
INFO:root:current train perplexity9.50943374633789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.40s/it]
INFO:root:final mean train loss: 5693.535986623457
INFO:root:final train perplexity: 9.452362060546875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 5180.563812472296
INFO:root:eval perplexity: 8.124367713928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/3

  2%|â–         | 3/200 [15:10<16:47:29, 306.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5555.328761888587
INFO:root:current train perplexity8.788520812988281
INFO:root:current mean train loss 5484.71361312246
INFO:root:current train perplexity8.715066909790039
INFO:root:current mean train loss 5484.749667180493
INFO:root:current train perplexity8.658409118652344
INFO:root:current mean train loss 5458.957185444079
INFO:root:current train perplexity8.581486701965332
INFO:root:current mean train loss 5445.938573526152
INFO:root:current train perplexity8.555017471313477
INFO:root:current mean train loss 5430.317804807003
INFO:root:current train perplexity8.50368881225586
INFO:root:current mean train loss 5420.4465430001
INFO:root:current train perplexity8.470871925354004
INFO:root:current mean train loss 5410.114662349802
INFO:root:current train perplexity8.434284210205078
INFO:root:current mean train loss 5399.346062661376
INFO:root:current train perplexity8.398114204406738
INFO:root:current mean train loss 5388.679271693865
INFO:root:current train perplexity8.36320686340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.43s/it]
INFO:root:final mean train loss: 5377.797079516995
INFO:root:final train perplexity: 8.345282554626465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.02s/it]
INFO:root:eval mean loss: 4959.737328928413
INFO:root:eval perplexity: 7.4303436279296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/4

  2%|â–         | 4/200 [20:29<16:57:58, 311.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5315.3499401461695
INFO:root:current train perplexity7.952919006347656
INFO:root:current mean train loss 5242.157301109256
INFO:root:current train perplexity7.889527797698975
INFO:root:current mean train loss 5244.499843580898
INFO:root:current train perplexity7.911441802978516
INFO:root:current mean train loss 5232.954951260385
INFO:root:current train perplexity7.862482070922852
INFO:root:current mean train loss 5226.072664406903
INFO:root:current train perplexity7.8293328285217285
INFO:root:current mean train loss 5215.325797617997
INFO:root:current train perplexity7.798630714416504
INFO:root:current mean train loss 5207.439496458994
INFO:root:current train perplexity7.773410797119141
INFO:root:current mean train loss 5199.789729127479
INFO:root:current train perplexity7.758252143859863
INFO:root:current mean train loss 5186.505252402038
INFO:root:current train perplexity7.733582973480225
INFO:root:current mean train loss 5178.576193378256
INFO:root:current train perplexity7.704395294189453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.25s/it]
INFO:root:final mean train loss: 5169.100961254489
INFO:root:final train perplexity: 7.68568754196167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 4818.484132590869
INFO:root:eval perplexity: 7.01782751083374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/5

  2%|â–Ž         | 5/200 [25:28<16:38:49, 307.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5075.603778545673
INFO:root:current train perplexity7.3252997398376465
INFO:root:current mean train loss 5068.704758458858
INFO:root:current train perplexity7.3895158767700195
INFO:root:current mean train loss 5076.0554618037395
INFO:root:current train perplexity7.3989033699035645
INFO:root:current mean train loss 5059.7380263066925
INFO:root:current train perplexity7.339090824127197
INFO:root:current mean train loss 5058.02651511781
INFO:root:current train perplexity7.3307108879089355
INFO:root:current mean train loss 5044.926296708314
INFO:root:current train perplexity7.304595470428467
INFO:root:current mean train loss 5036.803328106661
INFO:root:current train perplexity7.283571720123291
INFO:root:current mean train loss 5036.577537608889
INFO:root:current train perplexity7.278195381164551
INFO:root:current mean train loss 5032.747516109207
INFO:root:current train perplexity7.262002944946289
INFO:root:current mean train loss 5024.9070799221245
INFO:root:current train perplexity7.2469940185546875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.54s/it]
INFO:root:final mean train loss: 5016.22139463117
INFO:root:final train perplexity: 7.235825538635254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it]
INFO:root:eval mean loss: 4702.819945423315
INFO:root:eval perplexity: 6.697152137756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/6

  3%|â–Ž         | 6/200 [30:07<16:02:23, 297.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4887.026730801197
INFO:root:current train perplexity6.919979572296143
INFO:root:current mean train loss 4942.694143282313
INFO:root:current train perplexity7.00172233581543
INFO:root:current mean train loss 4924.42951353745
INFO:root:current train perplexity6.984455108642578
INFO:root:current mean train loss 4923.220790368336
INFO:root:current train perplexity6.972787380218506
INFO:root:current mean train loss 4920.742190777055
INFO:root:current train perplexity6.9632887840271
INFO:root:current mean train loss 4911.567300688414
INFO:root:current train perplexity6.940769195556641
INFO:root:current mean train loss 4911.28324765142
INFO:root:current train perplexity6.937963485717773
INFO:root:current mean train loss 4908.013404529576
INFO:root:current train perplexity6.9253973960876465
INFO:root:current mean train loss 4904.381431822793
INFO:root:current train perplexity6.916592597961426
INFO:root:current mean train loss 4902.28840252112
INFO:root:current train perplexity6.906069755554199


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.73s/it]
INFO:root:final mean train loss: 4897.143982548868
INFO:root:final train perplexity: 6.903753280639648
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.92s/it]
INFO:root:eval mean loss: 4614.999226022274
INFO:root:eval perplexity: 6.463494777679443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/7

  4%|â–Ž         | 7/200 [35:28<16:21:51, 305.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4792.577143998579
INFO:root:current train perplexity6.712880611419678
INFO:root:current mean train loss 4842.051037991431
INFO:root:current train perplexity6.767276763916016
INFO:root:current mean train loss 4834.488540709252
INFO:root:current train perplexity6.721985816955566
INFO:root:current mean train loss 4833.431031992738
INFO:root:current train perplexity6.713913917541504
INFO:root:current mean train loss 4826.963698167067
INFO:root:current train perplexity6.695224285125732
INFO:root:current mean train loss 4821.310806851774
INFO:root:current train perplexity6.678391933441162
INFO:root:current mean train loss 4820.202150301169
INFO:root:current train perplexity6.67714786529541
INFO:root:current mean train loss 4820.833314685948
INFO:root:current train perplexity6.669435977935791
INFO:root:current mean train loss 4811.779327428271
INFO:root:current train perplexity6.652740001678467
INFO:root:current mean train loss 4804.218793203943
INFO:root:current train perplexity6.643851280212402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.10s/it]
INFO:root:final mean train loss: 4799.978281451809
INFO:root:final train perplexity: 6.644106864929199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 4543.547967572585
INFO:root:eval perplexity: 6.279419422149658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/8

  4%|â–         | 8/200 [40:21<16:04:05, 301.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4743.660249255952
INFO:root:current train perplexity6.440840244293213
INFO:root:current mean train loss 4732.352215538727
INFO:root:current train perplexity6.462233066558838
INFO:root:current mean train loss 4726.044840185361
INFO:root:current train perplexity6.460130214691162
INFO:root:current mean train loss 4737.0166647834885
INFO:root:current train perplexity6.4608612060546875
INFO:root:current mean train loss 4741.698885495411
INFO:root:current train perplexity6.471323490142822
INFO:root:current mean train loss 4733.928837561057
INFO:root:current train perplexity6.458807945251465
INFO:root:current mean train loss 4731.124301824095
INFO:root:current train perplexity6.456068992614746
INFO:root:current mean train loss 4728.890138958573
INFO:root:current train perplexity6.447974681854248
INFO:root:current mean train loss 4723.904891808644
INFO:root:current train perplexity6.439279079437256
INFO:root:current mean train loss 4720.46793442327
INFO:root:current train perplexity6.430241584777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.85s/it]
INFO:root:final mean train loss: 4718.31155789283
INFO:root:final train perplexity: 6.433446407318115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it]
INFO:root:eval mean loss: 4484.844700590093
INFO:root:eval perplexity: 6.132112979888916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/9

  4%|â–         | 9/200 [45:09<15:45:58, 297.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4642.013534330986
INFO:root:current train perplexity6.213998794555664
INFO:root:current mean train loss 4652.6307994106355
INFO:root:current train perplexity6.263209819793701
INFO:root:current mean train loss 4675.438186476591
INFO:root:current train perplexity6.300491809844971
INFO:root:current mean train loss 4669.795348298518
INFO:root:current train perplexity6.288905143737793
INFO:root:current mean train loss 4663.884981256635
INFO:root:current train perplexity6.286571502685547
INFO:root:current mean train loss 4663.509813512478
INFO:root:current train perplexity6.28014612197876
INFO:root:current mean train loss 4664.978205992106
INFO:root:current train perplexity6.2852325439453125
INFO:root:current mean train loss 4655.522510652258
INFO:root:current train perplexity6.272074222564697
INFO:root:current mean train loss 4657.746220725549
INFO:root:current train perplexity6.268875598907471
INFO:root:current mean train loss 4653.660583433236
INFO:root:current train perplexity6.262265682220459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.75s/it]
INFO:root:final mean train loss: 4649.325735030636
INFO:root:final train perplexity: 6.260709285736084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 4439.73651512633
INFO:root:eval perplexity: 6.021275997161865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/10

  5%|â–Œ         | 10/200 [49:53<15:28:33, 293.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4631.207448452334
INFO:root:current train perplexity6.1284260749816895
INFO:root:current mean train loss 4596.142552210632
INFO:root:current train perplexity6.101619243621826
INFO:root:current mean train loss 4605.558601625504
INFO:root:current train perplexity6.113948822021484
INFO:root:current mean train loss 4600.559533594781
INFO:root:current train perplexity6.118489742279053
INFO:root:current mean train loss 4604.212934967869
INFO:root:current train perplexity6.117008686065674
INFO:root:current mean train loss 4597.984017011415
INFO:root:current train perplexity6.117250919342041
INFO:root:current mean train loss 4597.302687632317
INFO:root:current train perplexity6.114133834838867
INFO:root:current mean train loss 4595.425166980905
INFO:root:current train perplexity6.111018180847168
INFO:root:current mean train loss 4590.342720943099
INFO:root:current train perplexity6.107941627502441
INFO:root:current mean train loss 4589.629034180685
INFO:root:current train perplexity6.108046531677246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.09s/it]
INFO:root:final mean train loss: 4586.736737774265
INFO:root:final train perplexity: 6.108006477355957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 4393.940737893396
INFO:root:eval perplexity: 5.910796642303467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/11

  6%|â–Œ         | 11/200 [54:40<15:17:33, 291.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4537.070315306214
INFO:root:current train perplexity5.971560001373291
INFO:root:current mean train loss 4558.166426877924
INFO:root:current train perplexity6.0043134689331055
INFO:root:current mean train loss 4544.736781529018
INFO:root:current train perplexity5.976890563964844
INFO:root:current mean train loss 4545.873378073522
INFO:root:current train perplexity5.992092609405518
INFO:root:current mean train loss 4543.336524540394
INFO:root:current train perplexity5.991188049316406
INFO:root:current mean train loss 4539.763260953471
INFO:root:current train perplexity5.984681606292725
INFO:root:current mean train loss 4538.425159348844
INFO:root:current train perplexity5.984155178070068
INFO:root:current mean train loss 4535.416002906111
INFO:root:current train perplexity5.977582931518555
INFO:root:current mean train loss 4536.564955994134
INFO:root:current train perplexity5.979517936706543
INFO:root:current mean train loss 4536.330364810901
INFO:root:current train perplexity5.9797163009643555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.13s/it]
INFO:root:final mean train loss: 4532.892786026001
INFO:root:final train perplexity: 5.979620933532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it]
INFO:root:eval mean loss: 4356.364669908023
INFO:root:eval perplexity: 5.821663856506348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/12

  6%|â–Œ         | 12/200 [59:20<15:01:27, 287.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4500.143390213816
INFO:root:current train perplexity5.888641357421875
INFO:root:current mean train loss 4484.2898099459135
INFO:root:current train perplexity5.8813042640686035
INFO:root:current mean train loss 4488.556419657045
INFO:root:current train perplexity5.890378952026367
INFO:root:current mean train loss 4481.972795317444
INFO:root:current train perplexity5.875285625457764
INFO:root:current mean train loss 4487.806423611111
INFO:root:current train perplexity5.876178741455078
INFO:root:current mean train loss 4482.519295315783
INFO:root:current train perplexity5.872768402099609
INFO:root:current mean train loss 4479.612922240332
INFO:root:current train perplexity5.867847919464111
INFO:root:current mean train loss 4483.613104977398
INFO:root:current train perplexity5.862328052520752
INFO:root:current mean train loss 4484.618459486295
INFO:root:current train perplexity5.863184928894043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.20s/it]
INFO:root:final mean train loss: 4483.52200009746
INFO:root:final train perplexity: 5.864276885986328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.42s/it]
INFO:root:eval mean loss: 4322.174529379987
INFO:root:eval perplexity: 5.741729259490967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/13

  6%|â–‹         | 13/200 [1:04:20<15:08:57, 291.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4702.774739583333
INFO:root:current train perplexity6.030204772949219
INFO:root:current mean train loss 4457.410514164897
INFO:root:current train perplexity5.759730815887451
INFO:root:current mean train loss 4454.954130426417
INFO:root:current train perplexity5.758594989776611
INFO:root:current mean train loss 4453.843720993193
INFO:root:current train perplexity5.766134738922119
INFO:root:current mean train loss 4456.060947919897
INFO:root:current train perplexity5.771783828735352
INFO:root:current mean train loss 4452.333099061879
INFO:root:current train perplexity5.774241924285889
INFO:root:current mean train loss 4448.703047668559
INFO:root:current train perplexity5.77571439743042
INFO:root:current mean train loss 4445.283212848951
INFO:root:current train perplexity5.769230842590332
INFO:root:current mean train loss 4443.512477318941
INFO:root:current train perplexity5.765924453735352
INFO:root:current mean train loss 4443.653216221536
INFO:root:current train perplexity5.765037536621094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.15s/it]
INFO:root:final mean train loss: 4439.993846401091
INFO:root:final train perplexity: 5.764427661895752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 4296.114311488807
INFO:root:eval perplexity: 5.681541919708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/14

  7%|â–‹         | 14/200 [1:09:20<15:11:43, 294.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4390.626686789773
INFO:root:current train perplexity5.594669342041016
INFO:root:current mean train loss 4397.796091990428
INFO:root:current train perplexity5.68979549407959
INFO:root:current mean train loss 4387.270315739781
INFO:root:current train perplexity5.682099342346191
INFO:root:current mean train loss 4390.819316312048
INFO:root:current train perplexity5.6779093742370605
INFO:root:current mean train loss 4387.944345441758
INFO:root:current train perplexity5.671916484832764
INFO:root:current mean train loss 4391.580434541646
INFO:root:current train perplexity5.676681041717529
INFO:root:current mean train loss 4399.3114151525415
INFO:root:current train perplexity5.682405471801758
INFO:root:current mean train loss 4400.137231067599
INFO:root:current train perplexity5.678357124328613
INFO:root:current mean train loss 4402.833280551596
INFO:root:current train perplexity5.683279514312744
INFO:root:current mean train loss 4404.971759013104
INFO:root:current train perplexity5.679309844970703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it]
INFO:root:final mean train loss: 4401.456378690658
INFO:root:final train perplexity: 5.6774492263793945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 4272.281073387633
INFO:root:eval perplexity: 5.627048492431641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/15

  8%|â–Š         | 15/200 [1:13:59<14:52:05, 289.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4416.088147615132
INFO:root:current train perplexity5.652023792266846
INFO:root:current mean train loss 4364.480109719669
INFO:root:current train perplexity5.57551383972168
INFO:root:current mean train loss 4361.473535825128
INFO:root:current train perplexity5.588114261627197
INFO:root:current mean train loss 4359.561965798884
INFO:root:current train perplexity5.587946891784668
INFO:root:current mean train loss 4364.3350168742545
INFO:root:current train perplexity5.59321928024292
INFO:root:current mean train loss 4362.211855261771
INFO:root:current train perplexity5.5893354415893555
INFO:root:current mean train loss 4361.304355405644
INFO:root:current train perplexity5.589468479156494
INFO:root:current mean train loss 4364.654119626869
INFO:root:current train perplexity5.5934624671936035
INFO:root:current mean train loss 4364.295660258795
INFO:root:current train perplexity5.594063758850098
INFO:root:current mean train loss 4363.823368109868
INFO:root:current train perplexity5.590355396270752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.33s/it]
INFO:root:final mean train loss: 4364.185711768366
INFO:root:final train perplexity: 5.59457540512085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it]
INFO:root:eval mean loss: 4247.709754889738
INFO:root:eval perplexity: 5.571415424346924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/16

  8%|â–Š         | 16/200 [1:18:56<14:54:42, 291.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4355.3628833912035
INFO:root:current train perplexity5.581729412078857
INFO:root:current mean train loss 4311.286063607284
INFO:root:current train perplexity5.526186466217041
INFO:root:current mean train loss 4324.751051848155
INFO:root:current train perplexity5.524345397949219
INFO:root:current mean train loss 4320.986564799551
INFO:root:current train perplexity5.512662410736084
INFO:root:current mean train loss 4328.058371907933
INFO:root:current train perplexity5.5170578956604
INFO:root:current mean train loss 4328.315039618418
INFO:root:current train perplexity5.512563705444336
INFO:root:current mean train loss 4328.729012861967
INFO:root:current train perplexity5.5107903480529785
INFO:root:current mean train loss 4327.91744252117
INFO:root:current train perplexity5.516294479370117
INFO:root:current mean train loss 4328.34003357155
INFO:root:current train perplexity5.513639450073242
INFO:root:current mean train loss 4330.544644550212
INFO:root:current train perplexity5.518749237060547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.79s/it]
INFO:root:final mean train loss: 4330.848581744778
INFO:root:final train perplexity: 5.521474838256836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.30s/it]
INFO:root:eval mean loss: 4227.091531956449
INFO:root:eval perplexity: 5.525156497955322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/17

  8%|â–Š         | 17/200 [1:23:34<14:37:16, 287.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4261.924790736607
INFO:root:current train perplexity5.421319484710693
INFO:root:current mean train loss 4300.0556297019675
INFO:root:current train perplexity5.448973178863525
INFO:root:current mean train loss 4293.962414810505
INFO:root:current train perplexity5.450527191162109
INFO:root:current mean train loss 4296.730930066465
INFO:root:current train perplexity5.448998928070068
INFO:root:current mean train loss 4296.168860564835
INFO:root:current train perplexity5.451873779296875
INFO:root:current mean train loss 4307.521607129819
INFO:root:current train perplexity5.455333709716797
INFO:root:current mean train loss 4302.959757551058
INFO:root:current train perplexity5.448887348175049
INFO:root:current mean train loss 4301.459186330782
INFO:root:current train perplexity5.445124626159668
INFO:root:current mean train loss 4302.414029168226
INFO:root:current train perplexity5.4525604248046875
INFO:root:current mean train loss 4301.594053935494
INFO:root:current train perplexity5.455312728881836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.41s/it]
INFO:root:final mean train loss: 4300.291322646603
INFO:root:final train perplexity: 5.4553093910217285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it]
INFO:root:eval mean loss: 4208.396619431516
INFO:root:eval perplexity: 5.483546733856201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/18

  9%|â–‰         | 18/200 [1:28:34<14:43:26, 291.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4265.802166606105
INFO:root:current train perplexity5.399490833282471
INFO:root:current mean train loss 4284.03392701049
INFO:root:current train perplexity5.410154819488525
INFO:root:current mean train loss 4274.733266822595
INFO:root:current train perplexity5.395030498504639
INFO:root:current mean train loss 4280.674148426112
INFO:root:current train perplexity5.407917499542236
INFO:root:current mean train loss 4280.83182348247
INFO:root:current train perplexity5.40261173248291
INFO:root:current mean train loss 4281.609484256302
INFO:root:current train perplexity5.401270866394043
INFO:root:current mean train loss 4277.33946481945
INFO:root:current train perplexity5.3948283195495605
INFO:root:current mean train loss 4273.976264471
INFO:root:current train perplexity5.390281677246094
INFO:root:current mean train loss 4270.503735090914
INFO:root:current train perplexity5.387969493865967
INFO:root:current mean train loss 4269.627428202462
INFO:root:current train perplexity5.385319709777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.01s/it]
INFO:root:final mean train loss: 4268.907828853977
INFO:root:final train perplexity: 5.388180255889893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it]
INFO:root:eval mean loss: 4194.402520362367
INFO:root:eval perplexity: 5.452603340148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/19

 10%|â–‰         | 19/200 [1:33:15<14:30:02, 288.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4210.606550628064
INFO:root:current train perplexity5.245851993560791
INFO:root:current mean train loss 4209.693102299772
INFO:root:current train perplexity5.259149074554443
INFO:root:current mean train loss 4240.950068865164
INFO:root:current train perplexity5.291522979736328
INFO:root:current mean train loss 4233.421011117788
INFO:root:current train perplexity5.303517818450928
INFO:root:current mean train loss 4239.345789738082
INFO:root:current train perplexity5.307772159576416
INFO:root:current mean train loss 4238.117378470253
INFO:root:current train perplexity5.313854694366455
INFO:root:current mean train loss 4245.203542401714
INFO:root:current train perplexity5.325707912445068
INFO:root:current mean train loss 4245.926585841275
INFO:root:current train perplexity5.325944900512695
INFO:root:current mean train loss 4246.08763988598
INFO:root:current train perplexity5.329547882080078
INFO:root:current mean train loss 4248.286227028703
INFO:root:current train perplexity5.332467555999756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.38s/it]
INFO:root:final mean train loss: 4241.569371623377
INFO:root:final train perplexity: 5.330376625061035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4176.623503989362
INFO:root:eval perplexity: 5.413544654846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/20

 10%|â–ˆ         | 20/200 [1:38:20<14:40:02, 293.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.44774149232
INFO:root:current train perplexity5.284039497375488
INFO:root:current mean train loss 4236.666786433766
INFO:root:current train perplexity5.271286487579346
INFO:root:current mean train loss 4228.865714172599
INFO:root:current train perplexity5.272073268890381
INFO:root:current mean train loss 4227.548153508008
INFO:root:current train perplexity5.282782077789307
INFO:root:current mean train loss 4223.210304542824
INFO:root:current train perplexity5.2772932052612305
INFO:root:current mean train loss 4220.216384587433
INFO:root:current train perplexity5.274614334106445
INFO:root:current mean train loss 4221.763226568428
INFO:root:current train perplexity5.274801731109619
INFO:root:current mean train loss 4225.658513849432
INFO:root:current train perplexity5.284509181976318
INFO:root:current mean train loss 4223.5778666486285
INFO:root:current train perplexity5.283199310302734
INFO:root:current mean train loss 4220.9781648160515
INFO:root:current train perplexity5.27955961227417


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.26s/it]
INFO:root:final mean train loss: 4216.300059903053
INFO:root:final train perplexity: 5.277500152587891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it]
INFO:root:eval mean loss: 4168.357503255208
INFO:root:eval perplexity: 5.39547872543335
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/21

 10%|â–ˆ         | 21/200 [1:43:05<14:27:03, 290.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4169.396309468284
INFO:root:current train perplexity5.21637487411499
INFO:root:current mean train loss 4184.13053921454
INFO:root:current train perplexity5.238899230957031
INFO:root:current mean train loss 4188.263888584094
INFO:root:current train perplexity5.22617769241333
INFO:root:current mean train loss 4184.958832036572
INFO:root:current train perplexity5.21535062789917
INFO:root:current mean train loss 4190.246552755287
INFO:root:current train perplexity5.22210168838501
INFO:root:current mean train loss 4189.7340908151455
INFO:root:current train perplexity5.216930866241455
INFO:root:current mean train loss 4191.975254682229
INFO:root:current train perplexity5.2189459800720215
INFO:root:current mean train loss 4192.673005304249
INFO:root:current train perplexity5.218570232391357
INFO:root:current mean train loss 4194.23438316618
INFO:root:current train perplexity5.219666004180908
INFO:root:current mean train loss 4192.745571385002
INFO:root:current train perplexity5.221985340118408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.84s/it]
INFO:root:final mean train loss: 4191.028399190595
INFO:root:final train perplexity: 5.225142002105713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it]
INFO:root:eval mean loss: 4147.00068913453
INFO:root:eval perplexity: 5.349083423614502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/22

 11%|â–ˆ         | 22/200 [1:47:47<14:15:13, 288.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4181.090970052083
INFO:root:current train perplexity5.173165798187256
INFO:root:current mean train loss 4172.788790457589
INFO:root:current train perplexity5.182598114013672
INFO:root:current mean train loss 4163.955904651989
INFO:root:current train perplexity5.160252571105957
INFO:root:current mean train loss 4163.846159505209
INFO:root:current train perplexity5.166706085205078
INFO:root:current mean train loss 4165.137508737665
INFO:root:current train perplexity5.1705474853515625
INFO:root:current mean train loss 4169.880529891304
INFO:root:current train perplexity5.175351619720459
INFO:root:current mean train loss 4167.740532769098
INFO:root:current train perplexity5.177320957183838
INFO:root:current mean train loss 4172.184392011089
INFO:root:current train perplexity5.1802191734313965
INFO:root:current mean train loss 4172.444366071429
INFO:root:current train perplexity5.1801323890686035
INFO:root:current mean train loss 4174.022809745593
INFO:root:current train perplexity5.180747985839844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.99s/it]
INFO:root:final mean train loss: 4168.880141412058
INFO:root:final train perplexity: 5.179682731628418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it]
INFO:root:eval mean loss: 4138.491212668994
INFO:root:eval perplexity: 5.330709457397461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/23

 12%|â–ˆâ–        | 23/200 [1:52:38<14:12:19, 288.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.0004500423565
INFO:root:current train perplexity5.100088596343994
INFO:root:current mean train loss 4148.880567206711
INFO:root:current train perplexity5.115128040313721
INFO:root:current mean train loss 4149.657932241055
INFO:root:current train perplexity5.118715286254883
INFO:root:current mean train loss 4155.598095448147
INFO:root:current train perplexity5.128716945648193
INFO:root:current mean train loss 4157.06769670759
INFO:root:current train perplexity5.13347864151001
INFO:root:current mean train loss 4151.027110916059
INFO:root:current train perplexity5.128201484680176
INFO:root:current mean train loss 4145.95259918615
INFO:root:current train perplexity5.122339725494385
INFO:root:current mean train loss 4150.940484564575
INFO:root:current train perplexity5.132771015167236
INFO:root:current mean train loss 4150.597719842688
INFO:root:current train perplexity5.136549949645996
INFO:root:current mean train loss 4151.230479181238
INFO:root:current train perplexity5.137450218200684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.02s/it]
INFO:root:final mean train loss: 4147.974968817926
INFO:root:final train perplexity: 5.137138366699219
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 4124.315441807957
INFO:root:eval perplexity: 5.3002400398254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/24

 12%|â–ˆâ–        | 24/200 [1:57:51<14:28:29, 296.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4097.655230511676
INFO:root:current train perplexity5.056325912475586
INFO:root:current mean train loss 4113.812223903796
INFO:root:current train perplexity5.081342697143555
INFO:root:current mean train loss 4111.63125788633
INFO:root:current train perplexity5.071282863616943
INFO:root:current mean train loss 4120.937180931306
INFO:root:current train perplexity5.087834358215332
INFO:root:current mean train loss 4121.123762888238
INFO:root:current train perplexity5.090755462646484
INFO:root:current mean train loss 4126.438557116513
INFO:root:current train perplexity5.093409061431885
INFO:root:current mean train loss 4128.741750096102
INFO:root:current train perplexity5.096227645874023
INFO:root:current mean train loss 4132.81696335977
INFO:root:current train perplexity5.097334861755371
INFO:root:current mean train loss 4131.284724140274
INFO:root:current train perplexity5.099273204803467
INFO:root:current mean train loss 4130.087361941063
INFO:root:current train perplexity5.094424724578857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.84s/it]
INFO:root:final mean train loss: 4126.768464857532
INFO:root:final train perplexity: 5.094336986541748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4115.452918952238
INFO:root:eval perplexity: 5.28127908706665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/25

 12%|â–ˆâ–Ž        | 25/200 [2:02:36<14:14:40, 293.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4082.090080492424
INFO:root:current train perplexity5.065927028656006
INFO:root:current mean train loss 4090.9158279188914
INFO:root:current train perplexity5.0342254638671875
INFO:root:current mean train loss 4103.833299311507
INFO:root:current train perplexity5.0435991287231445
INFO:root:current mean train loss 4111.608475534539
INFO:root:current train perplexity5.05631685256958
INFO:root:current mean train loss 4110.994252176228
INFO:root:current train perplexity5.053094387054443
INFO:root:current mean train loss 4109.147981010016
INFO:root:current train perplexity5.047327518463135
INFO:root:current mean train loss 4109.620270866863
INFO:root:current train perplexity5.049036026000977
INFO:root:current mean train loss 4112.745759775403
INFO:root:current train perplexity5.051992416381836
INFO:root:current mean train loss 4112.324665209608
INFO:root:current train perplexity5.055761814117432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.07s/it]
INFO:root:final mean train loss: 4106.581886168449
INFO:root:final train perplexity: 5.053925514221191
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it]
INFO:root:eval mean loss: 4111.580419229277
INFO:root:eval perplexity: 5.273016452789307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/26

 13%|â–ˆâ–Ž        | 26/200 [2:07:39<14:18:06, 295.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4145.12077985491
INFO:root:current train perplexity5.110957622528076
INFO:root:current mean train loss 4076.219455041618
INFO:root:current train perplexity5.012943744659424
INFO:root:current mean train loss 4087.72964551253
INFO:root:current train perplexity5.025302886962891
INFO:root:current mean train loss 4090.932738064943
INFO:root:current train perplexity5.023987770080566
INFO:root:current mean train loss 4098.401629923603
INFO:root:current train perplexity5.036016464233398
INFO:root:current mean train loss 4089.5079617773054
INFO:root:current train perplexity5.024007797241211
INFO:root:current mean train loss 4091.770044870392
INFO:root:current train perplexity5.016682147979736
INFO:root:current mean train loss 4093.2245527426626
INFO:root:current train perplexity5.020687580108643
INFO:root:current mean train loss 4091.2533535301463
INFO:root:current train perplexity5.017945289611816
INFO:root:current mean train loss 4089.502157966252
INFO:root:current train perplexity5.015638828277588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.79s/it]
INFO:root:final mean train loss: 4087.9377076548913
INFO:root:final train perplexity: 5.016887664794922
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 4100.003965120789
INFO:root:eval perplexity: 5.248389720916748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/27

 14%|â–ˆâ–Ž        | 27/200 [2:12:51<14:26:41, 300.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4093.205712890625
INFO:root:current train perplexity4.935712814331055
INFO:root:current mean train loss 4046.6686608355976
INFO:root:current train perplexity4.952985763549805
INFO:root:current mean train loss 4047.37754928234
INFO:root:current train perplexity4.955530166625977
INFO:root:current mean train loss 4060.546070498512
INFO:root:current train perplexity4.969161033630371
INFO:root:current mean train loss 4070.838936605798
INFO:root:current train perplexity4.9824299812316895
INFO:root:current mean train loss 4065.6433432569784
INFO:root:current train perplexity4.972319602966309
INFO:root:current mean train loss 4068.944540777439
INFO:root:current train perplexity4.974384784698486
INFO:root:current mean train loss 4069.9146047312065
INFO:root:current train perplexity4.973357200622559
INFO:root:current mean train loss 4073.13578622268
INFO:root:current train perplexity4.976685523986816
INFO:root:current mean train loss 4070.2353030011955
INFO:root:current train perplexity4.975723743438721


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.15s/it]
INFO:root:final mean train loss: 4069.0146965519075
INFO:root:final train perplexity: 4.979572772979736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 4090.082386206228
INFO:root:eval perplexity: 5.227374076843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/28

 14%|â–ˆâ–        | 28/200 [2:17:56<14:25:58, 302.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4090.632080078125
INFO:root:current train perplexity4.970871448516846
INFO:root:current mean train loss 4056.7799419620173
INFO:root:current train perplexity4.934281826019287
INFO:root:current mean train loss 4062.7934778324693
INFO:root:current train perplexity4.953716278076172
INFO:root:current mean train loss 4052.3715351683436
INFO:root:current train perplexity4.942840576171875
INFO:root:current mean train loss 4063.4629154430777
INFO:root:current train perplexity4.950754642486572
INFO:root:current mean train loss 4064.3575255063934
INFO:root:current train perplexity4.950216770172119
INFO:root:current mean train loss 4056.7051443525534
INFO:root:current train perplexity4.94492769241333
INFO:root:current mean train loss 4053.685177118452
INFO:root:current train perplexity4.943673133850098
INFO:root:current mean train loss 4056.621760019555
INFO:root:current train perplexity4.945202350616455
INFO:root:current mean train loss 4055.0546274567478
INFO:root:current train perplexity4.9453511238098145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.69s/it]
INFO:root:final mean train loss: 4050.8381018484793
INFO:root:final train perplexity: 4.943990230560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it]
INFO:root:eval mean loss: 4083.9380540780144
INFO:root:eval perplexity: 5.21440315246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/29

 14%|â–ˆâ–        | 29/200 [2:22:35<14:00:47, 295.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4055.2370526713707
INFO:root:current train perplexity4.897383689880371
INFO:root:current mean train loss 4035.5990241829677
INFO:root:current train perplexity4.891373634338379
INFO:root:current mean train loss 4053.8517030658145
INFO:root:current train perplexity4.911159992218018
INFO:root:current mean train loss 4057.060453939294
INFO:root:current train perplexity4.913288116455078
INFO:root:current mean train loss 4054.038365198122
INFO:root:current train perplexity4.908806324005127
INFO:root:current mean train loss 4049.9447883562852
INFO:root:current train perplexity4.910190582275391
INFO:root:current mean train loss 4044.8083082099347
INFO:root:current train perplexity4.907052993774414
INFO:root:current mean train loss 4044.624074202719
INFO:root:current train perplexity4.910125732421875
INFO:root:current mean train loss 4041.6294609280985
INFO:root:current train perplexity4.9071269035339355
INFO:root:current mean train loss 4036.589349175114
INFO:root:current train perplexity4.909300804138184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.70s/it]
INFO:root:final mean train loss: 4033.4253306235037
INFO:root:final train perplexity: 4.9101433753967285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 4072.424486092642
INFO:root:eval perplexity: 5.190182685852051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/30

 15%|â–ˆâ–Œ        | 30/200 [2:27:15<13:43:20, 290.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4017.615215594952
INFO:root:current train perplexity4.89894962310791
INFO:root:current mean train loss 4011.830476829474
INFO:root:current train perplexity4.882483959197998
INFO:root:current mean train loss 4016.6004940016996
INFO:root:current train perplexity4.8684868812561035
INFO:root:current mean train loss 4013.4849324184183
INFO:root:current train perplexity4.8668012619018555
INFO:root:current mean train loss 4020.1317002420274
INFO:root:current train perplexity4.87033748626709
INFO:root:current mean train loss 4017.8391217459994
INFO:root:current train perplexity4.871797561645508
INFO:root:current mean train loss 4017.97001884353
INFO:root:current train perplexity4.874793529510498
INFO:root:current mean train loss 4022.557216122928
INFO:root:current train perplexity4.878575801849365
INFO:root:current mean train loss 4022.29329494981
INFO:root:current train perplexity4.881619930267334
INFO:root:current mean train loss 4021.2795220355765
INFO:root:current train perplexity4.881070613861084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.90s/it]
INFO:root:final mean train loss: 4017.901146304223
INFO:root:final train perplexity: 4.880161285400391
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it]
INFO:root:eval mean loss: 4066.7803963735596
INFO:root:eval perplexity: 5.178350925445557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/31

 16%|â–ˆâ–Œ        | 31/200 [2:31:53<13:28:10, 286.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.9103120844416
INFO:root:current train perplexity4.817809104919434
INFO:root:current mean train loss 3991.1772045732355
INFO:root:current train perplexity4.819148540496826
INFO:root:current mean train loss 3983.1600583960653
INFO:root:current train perplexity4.805576324462891
INFO:root:current mean train loss 3995.23302061757
INFO:root:current train perplexity4.8213372230529785
INFO:root:current mean train loss 3999.865313570505
INFO:root:current train perplexity4.830083847045898
INFO:root:current mean train loss 4002.0806712929902
INFO:root:current train perplexity4.840733051300049
INFO:root:current mean train loss 4006.074627034631
INFO:root:current train perplexity4.846431255340576
INFO:root:current mean train loss 4001.467977705091
INFO:root:current train perplexity4.846450328826904
INFO:root:current mean train loss 4003.7661444113414
INFO:root:current train perplexity4.849964141845703
INFO:root:current mean train loss 4003.8516063267225
INFO:root:current train perplexity4.849177837371826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.29s/it]
INFO:root:final mean train loss: 4002.6266753289005
INFO:root:final train perplexity: 4.850841045379639
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 4060.566130942487
INFO:root:eval perplexity: 5.165355205535889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/32

 16%|â–ˆâ–Œ        | 32/200 [2:36:32<13:16:25, 284.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.8784224076703
INFO:root:current train perplexity4.748347282409668
INFO:root:current mean train loss 4003.5414598034276
INFO:root:current train perplexity4.812251567840576
INFO:root:current mean train loss 3982.607711014093
INFO:root:current train perplexity4.8006911277771
INFO:root:current mean train loss 3976.2584417638645
INFO:root:current train perplexity4.807414531707764
INFO:root:current mean train loss 3985.1263940161402
INFO:root:current train perplexity4.817511081695557
INFO:root:current mean train loss 3986.373355679899
INFO:root:current train perplexity4.818298816680908
INFO:root:current mean train loss 3990.3866520306537
INFO:root:current train perplexity4.81992244720459
INFO:root:current mean train loss 3992.4721265780217
INFO:root:current train perplexity4.8211140632629395
INFO:root:current mean train loss 3993.3613703855995
INFO:root:current train perplexity4.822116851806641
INFO:root:current mean train loss 3992.6899621134653
INFO:root:current train perplexity4.825729846954346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.86s/it]
INFO:root:final mean train loss: 3988.6083878547915
INFO:root:final train perplexity: 4.824086666107178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it]
INFO:root:eval mean loss: 4054.3380100980717
INFO:root:eval perplexity: 5.152361869812012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/33

 16%|â–ˆâ–‹        | 33/200 [2:41:10<13:06:17, 282.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3923.9913659474205
INFO:root:current train perplexity4.745646953582764
INFO:root:current mean train loss 3949.1844519866754
INFO:root:current train perplexity4.779362201690674
INFO:root:current mean train loss 3948.7365843334123
INFO:root:current train perplexity4.779537200927734
INFO:root:current mean train loss 3959.1800607728565
INFO:root:current train perplexity4.781960964202881
INFO:root:current mean train loss 3968.295888946072
INFO:root:current train perplexity4.783834934234619
INFO:root:current mean train loss 3965.50918194244
INFO:root:current train perplexity4.77888298034668
INFO:root:current mean train loss 3968.1686124269418
INFO:root:current train perplexity4.785163402557373
INFO:root:current mean train loss 3966.697388815224
INFO:root:current train perplexity4.782022476196289
INFO:root:current mean train loss 3968.710818400112
INFO:root:current train perplexity4.783628463745117
INFO:root:current mean train loss 3976.0194671092127
INFO:root:current train perplexity4.794285774230957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.41s/it]
INFO:root:final mean train loss: 3972.5465212175923
INFO:root:final train perplexity: 4.793613433837891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 4051.1778798204787
INFO:root:eval perplexity: 5.145782947540283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/34

 17%|â–ˆâ–‹        | 34/200 [2:46:20<13:24:39, 290.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3992.1272247744278
INFO:root:current train perplexity4.774075031280518
INFO:root:current mean train loss 3953.9049850374636
INFO:root:current train perplexity4.746436595916748
INFO:root:current mean train loss 3950.0347670664205
INFO:root:current train perplexity4.749601364135742
INFO:root:current mean train loss 3952.2758084937245
INFO:root:current train perplexity4.745023250579834
INFO:root:current mean train loss 3952.290231886943
INFO:root:current train perplexity4.745968341827393
INFO:root:current mean train loss 3956.5972393724005
INFO:root:current train perplexity4.756115913391113
INFO:root:current mean train loss 3958.760884451262
INFO:root:current train perplexity4.759618282318115
INFO:root:current mean train loss 3957.731053610875
INFO:root:current train perplexity4.759278297424316
INFO:root:current mean train loss 3961.276502852325
INFO:root:current train perplexity4.7631001472473145
INFO:root:current mean train loss 3960.056769609697
INFO:root:current train perplexity4.764700412750244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.13s/it]
INFO:root:final mean train loss: 3957.3140205260247
INFO:root:final train perplexity: 4.764892101287842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.45s/it]
INFO:root:eval mean loss: 4045.037649601064
INFO:root:eval perplexity: 5.133022308349609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/35

 18%|â–ˆâ–Š        | 35/200 [2:51:33<13:38:16, 297.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3968.991146039359
INFO:root:current train perplexity4.758148670196533
INFO:root:current mean train loss 3947.8547813372907
INFO:root:current train perplexity4.725719451904297
INFO:root:current mean train loss 3951.0563089787747
INFO:root:current train perplexity4.736856937408447
INFO:root:current mean train loss 3948.8985998309695
INFO:root:current train perplexity4.733715057373047
INFO:root:current mean train loss 3947.681379664666
INFO:root:current train perplexity4.7374444007873535
INFO:root:current mean train loss 3949.7285982701856
INFO:root:current train perplexity4.734353542327881
INFO:root:current mean train loss 3950.3139288878406
INFO:root:current train perplexity4.7380900382995605
INFO:root:current mean train loss 3948.2811045811936
INFO:root:current train perplexity4.738368988037109
INFO:root:current mean train loss 3946.4430869040634
INFO:root:current train perplexity4.736928939819336
INFO:root:current mean train loss 3946.2833362926135
INFO:root:current train perplexity4.738966464996338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.22s/it]
INFO:root:final mean train loss: 3943.158200171686
INFO:root:final train perplexity: 4.738354682922363
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it]
INFO:root:eval mean loss: 4042.4919295074246
INFO:root:eval perplexity: 5.127740383148193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/36

 18%|â–ˆâ–Š        | 36/200 [2:56:12<13:17:43, 291.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3897.7919023886493
INFO:root:current train perplexity4.686892986297607
INFO:root:current mean train loss 3906.7958710206385
INFO:root:current train perplexity4.682165145874023
INFO:root:current mean train loss 3919.586742228332
INFO:root:current train perplexity4.693395614624023
INFO:root:current mean train loss 3924.3035595324613
INFO:root:current train perplexity4.7014031410217285
INFO:root:current mean train loss 3920.355140388379
INFO:root:current train perplexity4.704080581665039
INFO:root:current mean train loss 3921.1759430399543
INFO:root:current train perplexity4.706024169921875
INFO:root:current mean train loss 3925.9990571978483
INFO:root:current train perplexity4.7081074714660645
INFO:root:current mean train loss 3928.9227091729867
INFO:root:current train perplexity4.710415840148926
INFO:root:current mean train loss 3930.410778024151
INFO:root:current train perplexity4.709160804748535
INFO:root:current mean train loss 3932.510179699373
INFO:root:current train perplexity4.713454723358154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.93s/it]
INFO:root:final mean train loss: 3929.6537906892836
INFO:root:final train perplexity: 4.71317720413208
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 4037.6005132147607
INFO:root:eval perplexity: 5.117608547210693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/37

 18%|â–ˆâ–Š        | 37/200 [3:00:53<13:04:23, 288.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3892.555617804276
INFO:root:current train perplexity4.6439104080200195
INFO:root:current mean train loss 3894.4630596454326
INFO:root:current train perplexity4.653405666351318
INFO:root:current mean train loss 3904.282875397246
INFO:root:current train perplexity4.670778751373291
INFO:root:current mean train loss 3896.9564286244067
INFO:root:current train perplexity4.670945167541504
INFO:root:current mean train loss 3903.835899029356
INFO:root:current train perplexity4.676788330078125
INFO:root:current mean train loss 3907.7971503249737
INFO:root:current train perplexity4.679560661315918
INFO:root:current mean train loss 3909.2644158891635
INFO:root:current train perplexity4.681003093719482
INFO:root:current mean train loss 3915.7633868907233
INFO:root:current train perplexity4.6876606941223145
INFO:root:current mean train loss 3921.271508925454
INFO:root:current train perplexity4.691685199737549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.05s/it]
INFO:root:final mean train loss: 3917.6322303279753
INFO:root:final train perplexity: 4.690875053405762
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it]
INFO:root:eval mean loss: 4034.06099879488
INFO:root:eval perplexity: 5.110288619995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/38

 19%|â–ˆâ–‰        | 38/200 [3:05:32<12:51:13, 285.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3830.2325032552085
INFO:root:current train perplexity4.489131927490234
INFO:root:current mean train loss 3913.3071265359526
INFO:root:current train perplexity4.662181377410889
INFO:root:current mean train loss 3903.545091450508
INFO:root:current train perplexity4.654664039611816
INFO:root:current mean train loss 3905.76875451217
INFO:root:current train perplexity4.654219150543213
INFO:root:current mean train loss 3899.9632098858174
INFO:root:current train perplexity4.648387432098389
INFO:root:current mean train loss 3901.8684844060635
INFO:root:current train perplexity4.647395133972168
INFO:root:current mean train loss 3907.532558156483
INFO:root:current train perplexity4.657079219818115
INFO:root:current mean train loss 3905.0861750422296
INFO:root:current train perplexity4.66082763671875
INFO:root:current mean train loss 3907.2251259315653
INFO:root:current train perplexity4.662182331085205
INFO:root:current mean train loss 3909.408226646854
INFO:root:current train perplexity4.665574550628662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.23s/it]
INFO:root:final mean train loss: 3906.08944173013
INFO:root:final train perplexity: 4.669562339782715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 4027.961249168883
INFO:root:eval perplexity: 5.097699165344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/39

 20%|â–ˆâ–‰        | 39/200 [3:10:49<13:11:43, 295.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3844.944247159091
INFO:root:current train perplexity4.575038909912109
INFO:root:current mean train loss 3871.181002780124
INFO:root:current train perplexity4.6039719581604
INFO:root:current mean train loss 3882.127120899363
INFO:root:current train perplexity4.613330364227295
INFO:root:current mean train loss 3881.169397482918
INFO:root:current train perplexity4.6255927085876465
INFO:root:current mean train loss 3884.4601017193204
INFO:root:current train perplexity4.633488655090332
INFO:root:current mean train loss 3888.9532659422393
INFO:root:current train perplexity4.635538101196289
INFO:root:current mean train loss 3887.9584737175223
INFO:root:current train perplexity4.632665634155273
INFO:root:current mean train loss 3890.4246144569706
INFO:root:current train perplexity4.6380438804626465
INFO:root:current mean train loss 3892.1025062495182
INFO:root:current train perplexity4.639097213745117
INFO:root:current mean train loss 3893.553444285555
INFO:root:current train perplexity4.641349792480469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.87s/it]
INFO:root:final mean train loss: 3891.3848262294646
INFO:root:final train perplexity: 4.642550468444824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.02s/it]
INFO:root:eval mean loss: 4025.590415142952
INFO:root:eval perplexity: 5.0928144454956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/40

 20%|â–ˆâ–ˆ        | 40/200 [3:15:49<13:11:00, 296.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.06982421875
INFO:root:current train perplexity4.631128787994385
INFO:root:current mean train loss 3876.1869440158875
INFO:root:current train perplexity4.6180644035339355
INFO:root:current mean train loss 3876.122404751712
INFO:root:current train perplexity4.618743896484375
INFO:root:current mean train loss 3883.804748726489
INFO:root:current train perplexity4.618338584899902
INFO:root:current mean train loss 3883.211616315819
INFO:root:current train perplexity4.618699550628662
INFO:root:current mean train loss 3886.167274901403
INFO:root:current train perplexity4.621201515197754
INFO:root:current mean train loss 3884.1203672442953
INFO:root:current train perplexity4.618481159210205
INFO:root:current mean train loss 3889.72270242959
INFO:root:current train perplexity4.627391338348389
INFO:root:current mean train loss 3886.087936531784
INFO:root:current train perplexity4.623279094696045
INFO:root:current mean train loss 3883.2387344642616
INFO:root:current train perplexity4.623018741607666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.62s/it]
INFO:root:final mean train loss: 3880.1176461865825
INFO:root:final train perplexity: 4.621958255767822
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4021.0372738669103
INFO:root:eval perplexity: 5.083446502685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/41

 20%|â–ˆâ–ˆ        | 41/200 [3:20:31<12:54:34, 292.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3830.6930700231483
INFO:root:current train perplexity4.586597442626953
INFO:root:current mean train loss 3850.0532803272636
INFO:root:current train perplexity4.570995807647705
INFO:root:current mean train loss 3855.2757186553554
INFO:root:current train perplexity4.582729816436768
INFO:root:current mean train loss 3858.1346610999617
INFO:root:current train perplexity4.580015659332275
INFO:root:current mean train loss 3860.4812034589067
INFO:root:current train perplexity4.5883660316467285
INFO:root:current mean train loss 3861.1293018782612
INFO:root:current train perplexity4.584500312805176
INFO:root:current mean train loss 3864.031216513407
INFO:root:current train perplexity4.5849928855896
INFO:root:current mean train loss 3868.6975087581673
INFO:root:current train perplexity4.592650413513184
INFO:root:current mean train loss 3873.7193439672765
INFO:root:current train perplexity4.6003007888793945
INFO:root:current mean train loss 3873.567824741269
INFO:root:current train perplexity4.601424217224121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.30s/it]
INFO:root:final mean train loss: 3869.370875573927
INFO:root:final train perplexity: 4.6024041175842285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 4017.147897273936
INFO:root:eval perplexity: 5.075457572937012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/42

 21%|â–ˆâ–ˆ        | 42/200 [3:25:14<12:42:17, 289.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.7621721540177
INFO:root:current train perplexity4.542839050292969
INFO:root:current mean train loss 3822.709942853009
INFO:root:current train perplexity4.556668758392334
INFO:root:current mean train loss 3839.074692486702
INFO:root:current train perplexity4.557516574859619
INFO:root:current mean train loss 3852.0141798332556
INFO:root:current train perplexity4.572393894195557
INFO:root:current mean train loss 3855.0195048715877
INFO:root:current train perplexity4.572538375854492
INFO:root:current mean train loss 3857.343350704585
INFO:root:current train perplexity4.574644088745117
INFO:root:current mean train loss 3857.5180179625986
INFO:root:current train perplexity4.577920436859131
INFO:root:current mean train loss 3861.329380248193
INFO:root:current train perplexity4.578921794891357
INFO:root:current mean train loss 3858.3915603363585
INFO:root:current train perplexity4.576376914978027
INFO:root:current mean train loss 3858.6298621845754
INFO:root:current train perplexity4.577341556549072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.37s/it]
INFO:root:final mean train loss: 3857.6772274509553
INFO:root:final train perplexity: 4.581219673156738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]
INFO:root:eval mean loss: 4012.7112699468084
INFO:root:eval perplexity: 5.066359519958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:30:30<12:57:45, 297.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3890.9798271711484
INFO:root:current train perplexity4.572652339935303
INFO:root:current mean train loss 3865.238767823973
INFO:root:current train perplexity4.570631504058838
INFO:root:current mean train loss 3855.3676175090022
INFO:root:current train perplexity4.550934314727783
INFO:root:current mean train loss 3853.1760503029336
INFO:root:current train perplexity4.5531086921691895
INFO:root:current mean train loss 3852.4327847241816
INFO:root:current train perplexity4.549928665161133
INFO:root:current mean train loss 3852.228878014215
INFO:root:current train perplexity4.5534281730651855
INFO:root:current mean train loss 3850.7423872169034
INFO:root:current train perplexity4.553201198577881
INFO:root:current mean train loss 3847.985482668973
INFO:root:current train perplexity4.554407596588135
INFO:root:current mean train loss 3849.0505353717194
INFO:root:current train perplexity4.55873966217041
INFO:root:current mean train loss 3848.226158360535
INFO:root:current train perplexity4.55869197845459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.04s/it]
INFO:root:final mean train loss: 3845.2898774916125
INFO:root:final train perplexity: 4.558884620666504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 4011.3617765818926
INFO:root:eval perplexity: 5.063597202301025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/44

 22%|â–ˆâ–ˆâ–       | 44/200 [3:35:45<13:07:19, 302.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.254337086397
INFO:root:current train perplexity4.49077844619751
INFO:root:current mean train loss 3822.285073791908
INFO:root:current train perplexity4.5076093673706055
INFO:root:current mean train loss 3825.4909308080178
INFO:root:current train perplexity4.518705368041992
INFO:root:current mean train loss 3825.4826068932516
INFO:root:current train perplexity4.519715309143066
INFO:root:current mean train loss 3832.3087539842018
INFO:root:current train perplexity4.520790100097656
INFO:root:current mean train loss 3835.206363518744
INFO:root:current train perplexity4.529117584228516
INFO:root:current mean train loss 3831.4189914404524
INFO:root:current train perplexity4.5284600257873535
INFO:root:current mean train loss 3834.3567635730483
INFO:root:current train perplexity4.53274393081665
INFO:root:current mean train loss 3833.161377240012
INFO:root:current train perplexity4.534169673919678
INFO:root:current mean train loss 3836.1827447772903
INFO:root:current train perplexity4.536630153656006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.90s/it]
INFO:root:final mean train loss: 3834.464487137333
INFO:root:final train perplexity: 4.539455890655518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4007.4043782552085
INFO:root:eval perplexity: 5.055500507354736
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:40:32<12:50:00, 298.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3817.533186573093
INFO:root:current train perplexity4.484076976776123
INFO:root:current mean train loss 3829.103859571541
INFO:root:current train perplexity4.520215034484863
INFO:root:current mean train loss 3823.4465737361247
INFO:root:current train perplexity4.517815113067627
INFO:root:current mean train loss 3820.9481599005485
INFO:root:current train perplexity4.514655113220215
INFO:root:current mean train loss 3820.628488711023
INFO:root:current train perplexity4.515568256378174
INFO:root:current mean train loss 3822.1522655725907
INFO:root:current train perplexity4.516361713409424
INFO:root:current mean train loss 3826.996953614022
INFO:root:current train perplexity4.518704414367676
INFO:root:current mean train loss 3829.8724283210845
INFO:root:current train perplexity4.51716947555542
INFO:root:current mean train loss 3827.0788497480717
INFO:root:current train perplexity4.518308162689209
INFO:root:current mean train loss 3826.563920037963
INFO:root:current train perplexity4.5189361572265625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.45s/it]
INFO:root:final mean train loss: 3822.9719238896523
INFO:root:final train perplexity: 4.518919944763184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4005.6038827016846
INFO:root:eval perplexity: 5.051820755004883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:45:11<12:30:10, 292.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3832.003064511427
INFO:root:current train perplexity4.503961086273193
INFO:root:current mean train loss 3818.5612983018336
INFO:root:current train perplexity4.479068756103516
INFO:root:current mean train loss 3811.8961561110136
INFO:root:current train perplexity4.483974456787109
INFO:root:current mean train loss 3817.9836345953254
INFO:root:current train perplexity4.493428707122803
INFO:root:current mean train loss 3822.4731487135305
INFO:root:current train perplexity4.496524810791016
INFO:root:current mean train loss 3819.9812136587852
INFO:root:current train perplexity4.495894432067871
INFO:root:current mean train loss 3822.065296087308
INFO:root:current train perplexity4.503955841064453
INFO:root:current mean train loss 3818.277910971113
INFO:root:current train perplexity4.501091480255127
INFO:root:current mean train loss 3817.6108156268024
INFO:root:current train perplexity4.501274585723877
INFO:root:current mean train loss 3816.8830950164006
INFO:root:current train perplexity4.501596927642822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.63s/it]
INFO:root:final mean train loss: 3813.0025490176295
INFO:root:final train perplexity: 4.5011820793151855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 4006.7661600315823
INFO:root:eval perplexity: 5.054195880889893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:49:57<12:20:08, 290.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3803.2603515625
INFO:root:current train perplexity4.430898666381836
INFO:root:current mean train loss 3794.8321414620536
INFO:root:current train perplexity4.465817928314209
INFO:root:current mean train loss 3795.7229829545454
INFO:root:current train perplexity4.465685844421387
INFO:root:current mean train loss 3803.6820423177082
INFO:root:current train perplexity4.4772233963012695
INFO:root:current mean train loss 3803.3485886101976
INFO:root:current train perplexity4.478988170623779
INFO:root:current mean train loss 3804.98623046875
INFO:root:current train perplexity4.480053424835205
INFO:root:current mean train loss 3804.3302025462963
INFO:root:current train perplexity4.481719017028809
INFO:root:current mean train loss 3804.4940262726814
INFO:root:current train perplexity4.485568523406982
INFO:root:current mean train loss 3805.544816685268
INFO:root:current train perplexity4.4868879318237305
INFO:root:current mean train loss 3806.5440970552886
INFO:root:current train perplexity4.4855637550354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.18s/it]
INFO:root:final mean train loss: 3804.036467644476
INFO:root:final train perplexity: 4.485287189483643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it]
INFO:root:eval mean loss: 4002.7406759059177
INFO:root:eval perplexity: 5.0459747314453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:55:04<12:28:34, 295.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.434611492846
INFO:root:current train perplexity4.441944599151611
INFO:root:current mean train loss 3802.9563548603996
INFO:root:current train perplexity4.4465107917785645
INFO:root:current mean train loss 3789.3561278434186
INFO:root:current train perplexity4.440298080444336
INFO:root:current mean train loss 3787.036193369574
INFO:root:current train perplexity4.450605392456055
INFO:root:current mean train loss 3786.9174971491652
INFO:root:current train perplexity4.453800678253174
INFO:root:current mean train loss 3791.3780063216927
INFO:root:current train perplexity4.449279308319092
INFO:root:current mean train loss 3792.5107622048863
INFO:root:current train perplexity4.4528374671936035
INFO:root:current mean train loss 3791.6367112667626
INFO:root:current train perplexity4.456414222717285
INFO:root:current mean train loss 3792.3493906714502
INFO:root:current train perplexity4.458422660827637
INFO:root:current mean train loss 3795.1897725195513
INFO:root:current train perplexity4.465531826019287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.40s/it]
INFO:root:final mean train loss: 3792.7182249253797
INFO:root:final train perplexity: 4.465302467346191
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it]
INFO:root:eval mean loss: 3999.245292068373
INFO:root:eval perplexity: 5.038847923278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:59:47<12:13:34, 291.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3782.7284324562156
INFO:root:current train perplexity4.394782543182373
INFO:root:current mean train loss 3779.056069259244
INFO:root:current train perplexity4.413568496704102
INFO:root:current mean train loss 3771.699941943192
INFO:root:current train perplexity4.423623561859131
INFO:root:current mean train loss 3776.380806300951
INFO:root:current train perplexity4.430656433105469
INFO:root:current mean train loss 3776.610934317719
INFO:root:current train perplexity4.432862758636475
INFO:root:current mean train loss 3779.616227048303
INFO:root:current train perplexity4.436606407165527
INFO:root:current mean train loss 3778.338842808769
INFO:root:current train perplexity4.43596887588501
INFO:root:current mean train loss 3781.332515518825
INFO:root:current train perplexity4.439400672912598
INFO:root:current mean train loss 3781.309350832544
INFO:root:current train perplexity4.441821575164795
INFO:root:current mean train loss 3785.697327953535
INFO:root:current train perplexity4.447796821594238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.16s/it]
INFO:root:final mean train loss: 3782.8123047121107
INFO:root:final train perplexity: 4.447885990142822
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it]
INFO:root:eval mean loss: 4002.1451061059397
INFO:root:eval perplexity: 5.044760227203369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:04:56<12:22:28, 296.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.216616852115
INFO:root:current train perplexity4.387263774871826
INFO:root:current mean train loss 3767.183463705245
INFO:root:current train perplexity4.401416778564453
INFO:root:current mean train loss 3769.1505702602426
INFO:root:current train perplexity4.408569812774658
INFO:root:current mean train loss 3771.5629527921365
INFO:root:current train perplexity4.411846160888672
INFO:root:current mean train loss 3775.4578360823207
INFO:root:current train perplexity4.423203468322754
INFO:root:current mean train loss 3773.9617494000418
INFO:root:current train perplexity4.427387237548828
INFO:root:current mean train loss 3769.2615933616103
INFO:root:current train perplexity4.426679611206055
INFO:root:current mean train loss 3769.5234121387084
INFO:root:current train perplexity4.42713737487793
INFO:root:current mean train loss 3771.0695746467427
INFO:root:current train perplexity4.428182125091553


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.25s/it]
INFO:root:final mean train loss: 3772.732547021681
INFO:root:final train perplexity: 4.430232524871826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it]
INFO:root:eval mean loss: 4000.17132265348
INFO:root:eval perplexity: 5.040735244750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:09:46<12:11:48, 294.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.75634765625
INFO:root:current train perplexity4.379610538482666
INFO:root:current mean train loss 3757.7527927862147
INFO:root:current train perplexity4.386122703552246
INFO:root:current mean train loss 3757.596926186972
INFO:root:current train perplexity4.395840644836426
INFO:root:current mean train loss 3767.897876056087
INFO:root:current train perplexity4.398154258728027
INFO:root:current mean train loss 3770.4106259357723
INFO:root:current train perplexity4.406893253326416
INFO:root:current mean train loss 3767.5039365870007
INFO:root:current train perplexity4.405813217163086
INFO:root:current mean train loss 3764.3692572654963
INFO:root:current train perplexity4.406507968902588
INFO:root:current mean train loss 3760.8655206445587
INFO:root:current train perplexity4.407607078552246
INFO:root:current mean train loss 3764.527146198788
INFO:root:current train perplexity4.412074565887451
INFO:root:current mean train loss 3765.3307190277874
INFO:root:current train perplexity4.41178560256958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.22s/it]
INFO:root:final mean train loss: 3763.04035974318
INFO:root:final train perplexity: 4.41332483291626
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 3996.8658109624334
INFO:root:eval perplexity: 5.034000873565674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:14:50<12:14:16, 297.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.0604654947915
INFO:root:current train perplexity4.479306221008301
INFO:root:current mean train loss 3735.4493716032607
INFO:root:current train perplexity4.371222019195557
INFO:root:current mean train loss 3739.4410281159157
INFO:root:current train perplexity4.37699556350708
INFO:root:current mean train loss 3739.618505859375
INFO:root:current train perplexity4.382497787475586
INFO:root:current mean train loss 3745.5413791886294
INFO:root:current train perplexity4.382489204406738
INFO:root:current mean train loss 3747.5084965678093
INFO:root:current train perplexity4.384432792663574
INFO:root:current mean train loss 3745.7635900978153
INFO:root:current train perplexity4.389801502227783
INFO:root:current mean train loss 3750.1737188592656
INFO:root:current train perplexity4.394067287445068
INFO:root:current mean train loss 3755.880158406825
INFO:root:current train perplexity4.396214008331299
INFO:root:current mean train loss 3756.5550677190063
INFO:root:current train perplexity4.3967108726501465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.36s/it]
INFO:root:final mean train loss: 3754.64491358111
INFO:root:final train perplexity: 4.398731231689453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it]
INFO:root:eval mean loss: 3993.795754723515
INFO:root:eval perplexity: 5.0277557373046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:19:29<11:55:12, 291.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3742.2296195652175
INFO:root:current train perplexity4.42647647857666
INFO:root:current mean train loss 3747.046372824568
INFO:root:current train perplexity4.388232231140137
INFO:root:current mean train loss 3737.5773203212584
INFO:root:current train perplexity4.377081394195557
INFO:root:current mean train loss 3746.259507879015
INFO:root:current train perplexity4.380817413330078
INFO:root:current mean train loss 3740.6280024102393
INFO:root:current train perplexity4.377821445465088
INFO:root:current mean train loss 3746.987174448046
INFO:root:current train perplexity4.384491443634033
INFO:root:current mean train loss 3749.5389566926665
INFO:root:current train perplexity4.384504318237305
INFO:root:current mean train loss 3744.65785295373
INFO:root:current train perplexity4.3777852058410645
INFO:root:current mean train loss 3747.1676726961196
INFO:root:current train perplexity4.381033420562744
INFO:root:current mean train loss 3749.6682824561553
INFO:root:current train perplexity4.38312292098999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.36s/it]
INFO:root:final mean train loss: 3744.0942756283666
INFO:root:final train perplexity: 4.380459308624268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 3995.592151831228
INFO:root:eval perplexity: 5.031409740447998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [4:24:24<11:52:42, 292.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3716.8459078881046
INFO:root:current train perplexity4.370108127593994
INFO:root:current mean train loss 3723.6170775435353
INFO:root:current train perplexity4.344973564147949
INFO:root:current mean train loss 3735.692705162676
INFO:root:current train perplexity4.360568046569824
INFO:root:current mean train loss 3727.6085961102717
INFO:root:current train perplexity4.353298664093018
INFO:root:current mean train loss 3730.777112637761
INFO:root:current train perplexity4.359684467315674
INFO:root:current mean train loss 3733.1341343536665
INFO:root:current train perplexity4.364969253540039
INFO:root:current mean train loss 3731.8709304737026
INFO:root:current train perplexity4.367057800292969
INFO:root:current mean train loss 3733.222955497606
INFO:root:current train perplexity4.366594314575195
INFO:root:current mean train loss 3734.423168269592
INFO:root:current train perplexity4.366237163543701
INFO:root:current mean train loss 3736.436068984543
INFO:root:current train perplexity4.365268230438232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.32s/it]
INFO:root:final mean train loss: 3735.3794623959448
INFO:root:final train perplexity: 4.365423202514648
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it]
INFO:root:eval mean loss: 3994.2797453318926
INFO:root:eval perplexity: 5.028739929199219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [4:29:38<12:02:56, 299.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3687.5009077023237
INFO:root:current train perplexity4.303965091705322
INFO:root:current mean train loss 3726.883801357352
INFO:root:current train perplexity4.333860874176025
INFO:root:current mean train loss 3728.7818567762815
INFO:root:current train perplexity4.337923526763916
INFO:root:current mean train loss 3722.874259656158
INFO:root:current train perplexity4.329963207244873
INFO:root:current mean train loss 3718.8037359633045
INFO:root:current train perplexity4.329159736633301
INFO:root:current mean train loss 3717.1085451936456
INFO:root:current train perplexity4.335610866546631
INFO:root:current mean train loss 3718.8479661060983
INFO:root:current train perplexity4.338742733001709
INFO:root:current mean train loss 3722.478670897116
INFO:root:current train perplexity4.345503330230713
INFO:root:current mean train loss 3725.390675050283
INFO:root:current train perplexity4.3479766845703125
INFO:root:current mean train loss 3729.3950650313664
INFO:root:current train perplexity4.3509840965271


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.33s/it]
INFO:root:final mean train loss: 3727.134968111592
INFO:root:final train perplexity: 4.351247787475586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 3990.375457114362
INFO:root:eval perplexity: 5.020807266235352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [4:34:16<11:42:31, 292.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3722.3802412317154
INFO:root:current train perplexity4.335048198699951
INFO:root:current mean train loss 3705.725464697598
INFO:root:current train perplexity4.313924789428711
INFO:root:current mean train loss 3712.7547938543776
INFO:root:current train perplexity4.31833028793335
INFO:root:current mean train loss 3715.915618104962
INFO:root:current train perplexity4.3225297927856445
INFO:root:current mean train loss 3714.46539320295
INFO:root:current train perplexity4.328296661376953
INFO:root:current mean train loss 3717.084922999743
INFO:root:current train perplexity4.3299736976623535
INFO:root:current mean train loss 3722.271996051488
INFO:root:current train perplexity4.33436918258667
INFO:root:current mean train loss 3722.394666230024
INFO:root:current train perplexity4.336068153381348
INFO:root:current mean train loss 3723.2523223624744
INFO:root:current train perplexity4.336877822875977
INFO:root:current mean train loss 3723.310820147505
INFO:root:current train perplexity4.337307453155518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.96s/it]
INFO:root:final mean train loss: 3719.053115906254
INFO:root:final train perplexity: 4.337395668029785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 3991.8673589178857
INFO:root:eval perplexity: 5.023837089538574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [4:39:29<11:52:19, 298.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3670.3659712357953
INFO:root:current train perplexity4.249481678009033
INFO:root:current mean train loss 3688.3218324722784
INFO:root:current train perplexity4.289742946624756
INFO:root:current mean train loss 3696.2208649280024
INFO:root:current train perplexity4.291872501373291
INFO:root:current mean train loss 3694.3256038182217
INFO:root:current train perplexity4.291917324066162
INFO:root:current mean train loss 3706.0480425824176
INFO:root:current train perplexity4.305529594421387
INFO:root:current mean train loss 3706.047488210867
INFO:root:current train perplexity4.3095502853393555
INFO:root:current mean train loss 3707.1280422531013
INFO:root:current train perplexity4.314516067504883
INFO:root:current mean train loss 3707.8859294158733
INFO:root:current train perplexity4.319558143615723
INFO:root:current mean train loss 3709.522763614766
INFO:root:current train perplexity4.319243431091309
INFO:root:current mean train loss 3711.770252423511
INFO:root:current train perplexity4.3204851150512695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.01s/it]
INFO:root:final mean train loss: 3709.750149019303
INFO:root:final train perplexity: 4.321505546569824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 3992.4099242298316
INFO:root:eval perplexity: 5.02493953704834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [4:44:50<12:03:22, 305.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3700.080124627976
INFO:root:current train perplexity4.309585094451904
INFO:root:current mean train loss 3681.3361232266107
INFO:root:current train perplexity4.268529415130615
INFO:root:current mean train loss 3689.508630324679
INFO:root:current train perplexity4.275325775146484
INFO:root:current mean train loss 3681.9521020306042
INFO:root:current train perplexity4.276655197143555
INFO:root:current mean train loss 3688.0930355063783
INFO:root:current train perplexity4.284899711608887
INFO:root:current mean train loss 3691.232842074406
INFO:root:current train perplexity4.287801265716553
INFO:root:current mean train loss 3694.11059717607
INFO:root:current train perplexity4.292031288146973
INFO:root:current mean train loss 3695.6850237165177
INFO:root:current train perplexity4.297895431518555
INFO:root:current mean train loss 3697.8437995070794
INFO:root:current train perplexity4.302389621734619
INFO:root:current mean train loss 3702.7467245099947
INFO:root:current train perplexity4.306508541107178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.49s/it]
INFO:root:final mean train loss: 3701.8304183098576
INFO:root:final train perplexity: 4.308022975921631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 3988.9281239611037
INFO:root:eval perplexity: 5.01786994934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [4:49:34<11:42:37, 298.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3688.323953977773
INFO:root:current train perplexity4.270203113555908
INFO:root:current mean train loss 3673.1785524602524
INFO:root:current train perplexity4.250880241394043
INFO:root:current mean train loss 3687.4488214584294
INFO:root:current train perplexity4.2667460441589355
INFO:root:current mean train loss 3692.248990534451
INFO:root:current train perplexity4.279306888580322
INFO:root:current mean train loss 3691.5639036790076
INFO:root:current train perplexity4.2880659103393555
INFO:root:current mean train loss 3692.865206155593
INFO:root:current train perplexity4.291351318359375
INFO:root:current mean train loss 3693.083381846125
INFO:root:current train perplexity4.2919487953186035
INFO:root:current mean train loss 3695.4017712386512
INFO:root:current train perplexity4.291692733764648
INFO:root:current mean train loss 3695.5883388234606
INFO:root:current train perplexity4.292725563049316
INFO:root:current mean train loss 3695.3818595721227
INFO:root:current train perplexity4.293333530426025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.58s/it]
INFO:root:final mean train loss: 3693.8056049346924
INFO:root:final train perplexity: 4.294405937194824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it]
INFO:root:eval mean loss: 3990.0071250969636
INFO:root:eval perplexity: 5.020060062408447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:54:31<11:36:34, 298.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.8461883158625
INFO:root:current train perplexity4.2759928703308105
INFO:root:current mean train loss 3692.962324600646
INFO:root:current train perplexity4.284650802612305
INFO:root:current mean train loss 3688.07858702957
INFO:root:current train perplexity4.284267902374268
INFO:root:current mean train loss 3678.3167624762946
INFO:root:current train perplexity4.277359962463379
INFO:root:current mean train loss 3678.398239740997
INFO:root:current train perplexity4.272698402404785
INFO:root:current mean train loss 3682.0276545127645
INFO:root:current train perplexity4.277639865875244
INFO:root:current mean train loss 3680.4505980186855
INFO:root:current train perplexity4.274152755737305
INFO:root:current mean train loss 3683.1053925931683
INFO:root:current train perplexity4.2767415046691895
INFO:root:current mean train loss 3684.8122255848266
INFO:root:current train perplexity4.276627540588379
INFO:root:current mean train loss 3689.460435253607
INFO:root:current train perplexity4.281371593475342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.21s/it]
INFO:root:final mean train loss: 3686.315881236907
INFO:root:final train perplexity: 4.281734943389893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.23s/it]
INFO:root:eval mean loss: 3991.078260056516
INFO:root:eval perplexity: 5.022233486175537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:59:15<11:21:19, 294.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.234762257543
INFO:root:current train perplexity4.225622653961182
INFO:root:current mean train loss 3674.2469958953043
INFO:root:current train perplexity4.254241466522217
INFO:root:current mean train loss 3679.2323427632296
INFO:root:current train perplexity4.260775089263916
INFO:root:current mean train loss 3681.6925298015585
INFO:root:current train perplexity4.264228343963623
INFO:root:current mean train loss 3682.3751559091056
INFO:root:current train perplexity4.26697301864624
INFO:root:current mean train loss 3682.381344744863
INFO:root:current train perplexity4.265120506286621
INFO:root:current mean train loss 3681.434343229735
INFO:root:current train perplexity4.265100479125977
INFO:root:current mean train loss 3679.4770231719544
INFO:root:current train perplexity4.266209125518799
INFO:root:current mean train loss 3678.0539066353404
INFO:root:current train perplexity4.264393329620361
INFO:root:current mean train loss 3679.8515021450735
INFO:root:current train perplexity4.265982151031494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.64s/it]
INFO:root:final mean train loss: 3676.948381916169
INFO:root:final train perplexity: 4.265939712524414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 3990.446315034907
INFO:root:eval perplexity: 5.020950794219971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:03:58<11:08:52, 290.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3642.3593236019738
INFO:root:current train perplexity4.214347839355469
INFO:root:current mean train loss 3656.574516726763
INFO:root:current train perplexity4.2333855628967285
INFO:root:current mean train loss 3662.9318102820444
INFO:root:current train perplexity4.239163398742676
INFO:root:current mean train loss 3664.7350542672075
INFO:root:current train perplexity4.240652084350586
INFO:root:current mean train loss 3669.4026150173613
INFO:root:current train perplexity4.242006778717041
INFO:root:current mean train loss 3670.919728614102
INFO:root:current train perplexity4.248523712158203
INFO:root:current mean train loss 3670.73527533442
INFO:root:current train perplexity4.248218059539795
INFO:root:current mean train loss 3672.823665057488
INFO:root:current train perplexity4.254709720611572
INFO:root:current mean train loss 3672.6527581071055
INFO:root:current train perplexity4.253957271575928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.80s/it]
INFO:root:final mean train loss: 3669.507569343813
INFO:root:final train perplexity: 4.253434658050537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 3990.972141996343
INFO:root:eval perplexity: 5.022018909454346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:08:53<11:06:56, 292.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.6292317708335
INFO:root:current train perplexity4.282370090484619
INFO:root:current mean train loss 3669.5840460027307
INFO:root:current train perplexity4.237170219421387
INFO:root:current mean train loss 3655.7013594904556
INFO:root:current train perplexity4.225553035736084
INFO:root:current mean train loss 3656.3441246712564
INFO:root:current train perplexity4.235416889190674
INFO:root:current mean train loss 3664.0404740326458
INFO:root:current train perplexity4.239935398101807
INFO:root:current mean train loss 3667.8590687321384
INFO:root:current train perplexity4.236753463745117
INFO:root:current mean train loss 3668.452899888578
INFO:root:current train perplexity4.236990928649902
INFO:root:current mean train loss 3665.365298622533
INFO:root:current train perplexity4.235049724578857
INFO:root:current mean train loss 3666.3425268645897
INFO:root:current train perplexity4.237545967102051
INFO:root:current mean train loss 3666.8863118489585
INFO:root:current train perplexity4.239469528198242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.51s/it]
INFO:root:final mean train loss: 3663.177655681487
INFO:root:final train perplexity: 4.242825984954834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it]
INFO:root:eval mean loss: 3988.0011756842864
INFO:root:eval perplexity: 5.015989780426025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [5:13:31<10:52:34, 287.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.951726740057
INFO:root:current train perplexity4.209122657775879
INFO:root:current mean train loss 3669.337985201999
INFO:root:current train perplexity4.225317478179932
INFO:root:current mean train loss 3645.7292087066794
INFO:root:current train perplexity4.21520471572876
INFO:root:current mean train loss 3634.2714333488243
INFO:root:current train perplexity4.207931995391846
INFO:root:current mean train loss 3641.0715409253344
INFO:root:current train perplexity4.209383487701416
INFO:root:current mean train loss 3647.693587271435
INFO:root:current train perplexity4.215307235717773
INFO:root:current mean train loss 3652.026710422847
INFO:root:current train perplexity4.221076965332031
INFO:root:current mean train loss 3654.288404247429
INFO:root:current train perplexity4.224954605102539
INFO:root:current mean train loss 3658.4156835817084
INFO:root:current train perplexity4.228468894958496
INFO:root:current mean train loss 3656.5768740137896
INFO:root:current train perplexity4.227393627166748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.53s/it]
INFO:root:final mean train loss: 3654.5614725543605
INFO:root:final train perplexity: 4.228427886962891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 3985.612091713763
INFO:root:eval perplexity: 5.01114559173584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/65
####################best################

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [5:18:09<10:41:01, 284.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3587.092220908717
INFO:root:current train perplexity4.186825752258301
INFO:root:current mean train loss 3638.99572446166
INFO:root:current train perplexity4.194009780883789
INFO:root:current mean train loss 3639.9393316120863
INFO:root:current train perplexity4.194206237792969
INFO:root:current mean train loss 3642.039211739567
INFO:root:current train perplexity4.195103168487549
INFO:root:current mean train loss 3644.7643815725687
INFO:root:current train perplexity4.201788902282715
INFO:root:current mean train loss 3641.1427667577373
INFO:root:current train perplexity4.196335315704346
INFO:root:current mean train loss 3646.3789618620003
INFO:root:current train perplexity4.203688144683838
INFO:root:current mean train loss 3645.5220015184937
INFO:root:current train perplexity4.207549571990967
INFO:root:current mean train loss 3644.471956916781
INFO:root:current train perplexity4.204863548278809
INFO:root:current mean train loss 3645.195670608338
INFO:root:current train perplexity4.209903717041016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.68s/it]
INFO:root:final mean train loss: 3645.1096227707403
INFO:root:final train perplexity: 4.212689399719238
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 3987.9429490109706
INFO:root:eval perplexity: 5.015870571136475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [5:22:49<10:33:12, 283.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.5077492042824
INFO:root:current train perplexity4.104869365692139
INFO:root:current mean train loss 3620.6959334245817
INFO:root:current train perplexity4.164159774780273
INFO:root:current mean train loss 3636.512096253786
INFO:root:current train perplexity4.194708347320557
INFO:root:current mean train loss 3638.878520253966
INFO:root:current train perplexity4.1935133934021
INFO:root:current mean train loss 3641.890674742938
INFO:root:current train perplexity4.192954063415527
INFO:root:current mean train loss 3637.193324630129
INFO:root:current train perplexity4.190316200256348
INFO:root:current mean train loss 3636.191494249651
INFO:root:current train perplexity4.19210958480835
INFO:root:current mean train loss 3636.193050421252
INFO:root:current train perplexity4.195843696594238
INFO:root:current mean train loss 3637.2939060492554
INFO:root:current train perplexity4.198424816131592
INFO:root:current mean train loss 3640.2403218126346
INFO:root:current train perplexity4.200595378875732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.06s/it]
INFO:root:final mean train loss: 3638.8075782406713
INFO:root:final train perplexity: 4.20222806930542
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 3988.4288338735596
INFO:root:eval perplexity: 5.0168561935424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [5:28:03<10:48:46, 292.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3605.978466796875
INFO:root:current train perplexity4.148709774017334
INFO:root:current mean train loss 3603.3555284288195
INFO:root:current train perplexity4.155196189880371
INFO:root:current mean train loss 3614.23129467254
INFO:root:current train perplexity4.166539192199707
INFO:root:current mean train loss 3623.4048427297107
INFO:root:current train perplexity4.172729969024658
INFO:root:current mean train loss 3623.6085005836926
INFO:root:current train perplexity4.173797130584717
INFO:root:current mean train loss 3631.701199255257
INFO:root:current train perplexity4.180843830108643
INFO:root:current mean train loss 3632.351564422367
INFO:root:current train perplexity4.178997039794922
INFO:root:current mean train loss 3633.769859095982
INFO:root:current train perplexity4.184483051300049
INFO:root:current mean train loss 3635.304437511695
INFO:root:current train perplexity4.188318729400635
INFO:root:current mean train loss 3637.145020053476
INFO:root:current train perplexity4.190686225891113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.21s/it]
INFO:root:final mean train loss: 3632.2371057079686
INFO:root:final train perplexity: 4.191349029541016
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it]
INFO:root:eval mean loss: 3987.5887096215647
INFO:root:eval perplexity: 5.015152454376221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [5:33:31<11:06:38, 303.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3620.0995128542877
INFO:root:current train perplexity4.1614460945129395
INFO:root:current mean train loss 3630.890293788243
INFO:root:current train perplexity4.175805568695068
INFO:root:current mean train loss 3632.162751374421
INFO:root:current train perplexity4.179819107055664
INFO:root:current mean train loss 3628.689217525738
INFO:root:current train perplexity4.17250394821167
INFO:root:current mean train loss 3621.508502486597
INFO:root:current train perplexity4.165994167327881
INFO:root:current mean train loss 3624.817758240533
INFO:root:current train perplexity4.170374393463135
INFO:root:current mean train loss 3628.251801628718
INFO:root:current train perplexity4.173154354095459
INFO:root:current mean train loss 3629.094947044814
INFO:root:current train perplexity4.176243782043457
INFO:root:current mean train loss 3631.137355890421
INFO:root:current train perplexity4.18012809753418
INFO:root:current mean train loss 3628.312400583245
INFO:root:current train perplexity4.178173542022705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.27s/it]
INFO:root:final mean train loss: 3625.1346158673687
INFO:root:final train perplexity: 4.179620742797852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it]
INFO:root:eval mean loss: 3988.091552734375
INFO:root:eval perplexity: 5.016172409057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [5:38:47<11:10:13, 306.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.969334022672
INFO:root:current train perplexity4.145924091339111
INFO:root:current mean train loss 3597.1924442518625
INFO:root:current train perplexity4.147368907928467
INFO:root:current mean train loss 3603.9037755229083
INFO:root:current train perplexity4.148176193237305
INFO:root:current mean train loss 3614.1545403200676
INFO:root:current train perplexity4.161377906799316
INFO:root:current mean train loss 3606.498642339939
INFO:root:current train perplexity4.157957077026367
INFO:root:current mean train loss 3607.9657330244727
INFO:root:current train perplexity4.16174840927124
INFO:root:current mean train loss 3611.3856574320757
INFO:root:current train perplexity4.162187576293945
INFO:root:current mean train loss 3613.642817064227
INFO:root:current train perplexity4.164775371551514
INFO:root:current mean train loss 3617.0910853958576
INFO:root:current train perplexity4.1651763916015625
INFO:root:current mean train loss 3620.6180505923044
INFO:root:current train perplexity4.1678690910339355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it]
INFO:root:final mean train loss: 3618.46505823443
INFO:root:final train perplexity: 4.168637275695801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it]
INFO:root:eval mean loss: 3986.561632521609
INFO:root:eval perplexity: 5.013070106506348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [5:44:06<11:13:20, 310.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3580.500620696504
INFO:root:current train perplexity4.152800559997559
INFO:root:current mean train loss 3584.8335805449096
INFO:root:current train perplexity4.138839244842529
INFO:root:current mean train loss 3601.1155859752052
INFO:root:current train perplexity4.14811372756958
INFO:root:current mean train loss 3599.8021502056495
INFO:root:current train perplexity4.14792013168335
INFO:root:current mean train loss 3602.396194491251
INFO:root:current train perplexity4.144787788391113
INFO:root:current mean train loss 3603.316980570075
INFO:root:current train perplexity4.146376132965088
INFO:root:current mean train loss 3604.8956467392595
INFO:root:current train perplexity4.147582054138184
INFO:root:current mean train loss 3605.6167432862935
INFO:root:current train perplexity4.150522708892822
INFO:root:current mean train loss 3607.995885136241
INFO:root:current train perplexity4.152326583862305
INFO:root:current mean train loss 3613.082357110271
INFO:root:current train perplexity4.154600620269775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.96s/it]
INFO:root:final mean train loss: 3611.2560127012193
INFO:root:final train perplexity: 4.156797409057617
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 3988.6180342004654
INFO:root:eval perplexity: 5.017241477966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [5:49:19<11:09:09, 311.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.071336433069
INFO:root:current train perplexity4.094324111938477
INFO:root:current mean train loss 3581.38150846744
INFO:root:current train perplexity4.101667404174805
INFO:root:current mean train loss 3582.622155350246
INFO:root:current train perplexity4.113664627075195
INFO:root:current mean train loss 3594.94931720453
INFO:root:current train perplexity4.125036716461182
INFO:root:current mean train loss 3595.1001760740096
INFO:root:current train perplexity4.1247100830078125
INFO:root:current mean train loss 3591.3278950686176
INFO:root:current train perplexity4.127108573913574
INFO:root:current mean train loss 3596.644737323721
INFO:root:current train perplexity4.129528045654297
INFO:root:current mean train loss 3599.575616431205
INFO:root:current train perplexity4.134846210479736
INFO:root:current mean train loss 3599.2572408673946
INFO:root:current train perplexity4.136138439178467
INFO:root:current mean train loss 3605.3165223872156
INFO:root:current train perplexity4.143062114715576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.87s/it]
INFO:root:final mean train loss: 3602.7471153505385
INFO:root:final train perplexity: 4.142866611480713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 3990.897166583555
INFO:root:eval perplexity: 5.021866321563721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [5:54:34<11:06:16, 312.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.9248600260416
INFO:root:current train perplexity4.118518352508545
INFO:root:current mean train loss 3591.2986007254462
INFO:root:current train perplexity4.108251571655273
INFO:root:current mean train loss 3595.2770845170453
INFO:root:current train perplexity4.114584922790527
INFO:root:current mean train loss 3592.4803125
INFO:root:current train perplexity4.121852874755859
INFO:root:current mean train loss 3596.3831342516446
INFO:root:current train perplexity4.128462791442871
INFO:root:current mean train loss 3596.8401396908966
INFO:root:current train perplexity4.127086162567139
INFO:root:current mean train loss 3596.564398148148
INFO:root:current train perplexity4.127438545227051
INFO:root:current mean train loss 3598.3652608366933
INFO:root:current train perplexity4.131763935089111
INFO:root:current mean train loss 3600.1185873325894
INFO:root:current train perplexity4.132745742797852
INFO:root:current mean train loss 3600.47169921875
INFO:root:current train perplexity4.134317874908447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 263.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 263.00s/it]
INFO:root:final mean train loss: 3597.012083361226
INFO:root:final train perplexity: 4.133502960205078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it]
INFO:root:eval mean loss: 3990.144607435727
INFO:root:eval perplexity: 5.02033805847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:59:22<10:45:37, 305.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3556.0914056617094
INFO:root:current train perplexity4.08427619934082
INFO:root:current mean train loss 3574.9416397178106
INFO:root:current train perplexity4.102100372314453
INFO:root:current mean train loss 3584.8963972435404
INFO:root:current train perplexity4.1130805015563965
INFO:root:current mean train loss 3584.293069465976
INFO:root:current train perplexity4.109264373779297
INFO:root:current mean train loss 3586.00314299463
INFO:root:current train perplexity4.115245819091797
INFO:root:current mean train loss 3586.2601479584314
INFO:root:current train perplexity4.118229389190674
INFO:root:current mean train loss 3588.752627281982
INFO:root:current train perplexity4.119528770446777
INFO:root:current mean train loss 3588.4060074183826
INFO:root:current train perplexity4.117619514465332
INFO:root:current mean train loss 3590.7416964538506
INFO:root:current train perplexity4.119141101837158
INFO:root:current mean train loss 3591.489403849822
INFO:root:current train perplexity4.120842933654785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.81s/it]
INFO:root:final mean train loss: 3589.4077405006656
INFO:root:final train perplexity: 4.121120929718018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it]
INFO:root:eval mean loss: 3990.0156648243574
INFO:root:eval perplexity: 5.020076274871826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [6:04:33<10:44:43, 307.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.402893737122
INFO:root:current train perplexity4.112522125244141
INFO:root:current mean train loss 3575.1043656434063
INFO:root:current train perplexity4.0901007652282715
INFO:root:current mean train loss 3581.464526618879
INFO:root:current train perplexity4.097380638122559
INFO:root:current mean train loss 3576.978063558983
INFO:root:current train perplexity4.096722602844238
INFO:root:current mean train loss 3576.7429452806773
INFO:root:current train perplexity4.096564292907715
INFO:root:current mean train loss 3578.1812328977635
INFO:root:current train perplexity4.094480514526367
INFO:root:current mean train loss 3579.6418972871065
INFO:root:current train perplexity4.100625038146973
INFO:root:current mean train loss 3581.7168589132625
INFO:root:current train perplexity4.105833053588867
INFO:root:current mean train loss 3582.9475152457735
INFO:root:current train perplexity4.107981204986572
INFO:root:current mean train loss 3586.230543642785
INFO:root:current train perplexity4.1114397048950195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it]
INFO:root:final mean train loss: 3583.4445359629967
INFO:root:final train perplexity: 4.11143684387207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 3987.848776526485
INFO:root:eval perplexity: 5.015679836273193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [6:09:47<10:43:32, 308.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3563.038169783775
INFO:root:current train perplexity4.080598831176758
INFO:root:current mean train loss 3574.388757753612
INFO:root:current train perplexity4.082983016967773
INFO:root:current mean train loss 3573.6942281563547
INFO:root:current train perplexity4.089451313018799
INFO:root:current mean train loss 3573.3064968329027
INFO:root:current train perplexity4.091658592224121
INFO:root:current mean train loss 3576.804978120303
INFO:root:current train perplexity4.093278408050537
INFO:root:current mean train loss 3576.8241788071264
INFO:root:current train perplexity4.090525150299072
INFO:root:current mean train loss 3580.2826820122496
INFO:root:current train perplexity4.098417282104492
INFO:root:current mean train loss 3578.210617581058
INFO:root:current train perplexity4.098177909851074
INFO:root:current mean train loss 3578.573631074458
INFO:root:current train perplexity4.100177764892578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.96s/it]
INFO:root:final mean train loss: 3576.995694929554
INFO:root:final train perplexity: 4.10098934173584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 3990.807431917664
INFO:root:eval perplexity: 5.021683692932129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [6:15:01<10:41:33, 310.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.1811872209823
INFO:root:current train perplexity4.066710472106934
INFO:root:current mean train loss 3568.522983444071
INFO:root:current train perplexity4.089395046234131
INFO:root:current mean train loss 3562.553943283892
INFO:root:current train perplexity4.078721523284912
INFO:root:current mean train loss 3561.7910689065043
INFO:root:current train perplexity4.07261848449707
INFO:root:current mean train loss 3564.7362261498006
INFO:root:current train perplexity4.075669765472412
INFO:root:current mean train loss 3564.9766954049555
INFO:root:current train perplexity4.076637268066406
INFO:root:current mean train loss 3570.184088064379
INFO:root:current train perplexity4.082607269287109
INFO:root:current mean train loss 3570.9888448108204
INFO:root:current train perplexity4.085221767425537
INFO:root:current mean train loss 3571.2877649545967
INFO:root:current train perplexity4.085744857788086
INFO:root:current mean train loss 3571.1128150410004
INFO:root:current train perplexity4.086750507354736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.40s/it]
INFO:root:final mean train loss: 3569.7120261653777
INFO:root:final train perplexity: 4.089221954345703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 3989.6090529421544
INFO:root:eval perplexity: 5.019251346588135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [6:20:29<10:47:30, 315.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3509.600764973958
INFO:root:current train perplexity3.989175796508789
INFO:root:current mean train loss 3551.4765412703805
INFO:root:current train perplexity4.043842792510986
INFO:root:current mean train loss 3557.7529807867004
INFO:root:current train perplexity4.052502632141113
INFO:root:current mean train loss 3554.297905815972
INFO:root:current train perplexity4.054079055786133
INFO:root:current mean train loss 3559.342644013554
INFO:root:current train perplexity4.064436912536621
INFO:root:current mean train loss 3561.559674131523
INFO:root:current train perplexity4.06919527053833
INFO:root:current mean train loss 3557.4965796493902
INFO:root:current train perplexity4.0651421546936035
INFO:root:current mean train loss 3562.039151278409
INFO:root:current train perplexity4.072012424468994
INFO:root:current mean train loss 3563.0958597943827
INFO:root:current train perplexity4.07456111907959
INFO:root:current mean train loss 3564.1582388789275
INFO:root:current train perplexity4.075527667999268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it]
INFO:root:final mean train loss: 3563.1793258420885
INFO:root:final train perplexity: 4.078696250915527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.24s/it]
INFO:root:eval mean loss: 3991.587469872008
INFO:root:eval perplexity: 5.023268222808838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [6:25:29<10:32:45, 311.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3560.297225288723
INFO:root:current train perplexity4.074293613433838
INFO:root:current mean train loss 3554.6252084127286
INFO:root:current train perplexity4.0721049308776855
INFO:root:current mean train loss 3551.1958314356784
INFO:root:current train perplexity4.070827007293701
INFO:root:current mean train loss 3554.571450059259
INFO:root:current train perplexity4.0666022300720215
INFO:root:current mean train loss 3552.693578120383
INFO:root:current train perplexity4.063715934753418
INFO:root:current mean train loss 3550.993921225203
INFO:root:current train perplexity4.0641679763793945
INFO:root:current mean train loss 3555.951689939055
INFO:root:current train perplexity4.066591739654541
INFO:root:current mean train loss 3556.286331029024
INFO:root:current train perplexity4.065577983856201
INFO:root:current mean train loss 3558.4243288654316
INFO:root:current train perplexity4.06622314453125
INFO:root:current mean train loss 3559.2599753796217
INFO:root:current train perplexity4.0703325271606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.23s/it]
INFO:root:final mean train loss: 3558.5672702789307
INFO:root:final train perplexity: 4.071280479431152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.71s/it]
INFO:root:eval mean loss: 3992.074632577017
INFO:root:eval perplexity: 5.024257659912109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [6:30:59<10:38:34, 316.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.7294134324598
INFO:root:current train perplexity4.034100532531738
INFO:root:current mean train loss 3545.5772416209447
INFO:root:current train perplexity4.043004512786865
INFO:root:current mean train loss 3551.4830433238635
INFO:root:current train perplexity4.045776844024658
INFO:root:current mean train loss 3556.0421234776245
INFO:root:current train perplexity4.049213886260986
INFO:root:current mean train loss 3555.2733361051696
INFO:root:current train perplexity4.056219100952148
INFO:root:current mean train loss 3554.4195030198034
INFO:root:current train perplexity4.058764457702637
INFO:root:current mean train loss 3554.2097500711916
INFO:root:current train perplexity4.058360576629639
INFO:root:current mean train loss 3553.197442301321
INFO:root:current train perplexity4.057326793670654
INFO:root:current mean train loss 3556.6893829088635
INFO:root:current train perplexity4.062153339385986
INFO:root:current mean train loss 3553.225882262856
INFO:root:current train perplexity4.0602874755859375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.91s/it]
INFO:root:final mean train loss: 3551.1522103586503
INFO:root:final train perplexity: 4.059389114379883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it]
INFO:root:eval mean loss: 3991.281972032912
INFO:root:eval perplexity: 5.022647857666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [6:36:30<10:41:52, 320.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3506.40667568109
INFO:root:current train perplexity4.048730373382568
INFO:root:current mean train loss 3526.2696278524054
INFO:root:current train perplexity4.024675369262695
INFO:root:current mean train loss 3529.3836613738886
INFO:root:current train perplexity4.025578498840332
INFO:root:current mean train loss 3533.507399117349
INFO:root:current train perplexity4.023805618286133
INFO:root:current mean train loss 3535.656901783172
INFO:root:current train perplexity4.034831523895264
INFO:root:current mean train loss 3535.633043505044
INFO:root:current train perplexity4.0364203453063965
INFO:root:current mean train loss 3542.5967320306386
INFO:root:current train perplexity4.042974948883057
INFO:root:current mean train loss 3545.4380906947736
INFO:root:current train perplexity4.048646926879883
INFO:root:current mean train loss 3546.573439187742
INFO:root:current train perplexity4.049570083618164
INFO:root:current mean train loss 3546.7699768911407
INFO:root:current train perplexity4.049511432647705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.78s/it]
INFO:root:final mean train loss: 3546.2513371744462
INFO:root:final train perplexity: 4.051547050476074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it]
INFO:root:eval mean loss: 3991.9676851313166
INFO:root:eval perplexity: 5.024040699005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [6:41:47<10:34:20, 319.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.137383643617
INFO:root:current train perplexity4.07843017578125
INFO:root:current mean train loss 3556.111245083971
INFO:root:current train perplexity4.053933143615723
INFO:root:current mean train loss 3537.7897771302505
INFO:root:current train perplexity4.0342230796813965
INFO:root:current mean train loss 3534.9925744664083
INFO:root:current train perplexity4.029749870300293
INFO:root:current mean train loss 3542.0650479105493
INFO:root:current train perplexity4.032240390777588
INFO:root:current mean train loss 3536.3593018024453
INFO:root:current train perplexity4.032145023345947
INFO:root:current mean train loss 3539.1360508536995
INFO:root:current train perplexity4.0354228019714355
INFO:root:current mean train loss 3541.991208976531
INFO:root:current train perplexity4.035248279571533
INFO:root:current mean train loss 3544.464061174089
INFO:root:current train perplexity4.038435459136963
INFO:root:current mean train loss 3541.8165137543724
INFO:root:current train perplexity4.040577411651611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.05s/it]
INFO:root:final mean train loss: 3538.5881151383924
INFO:root:final train perplexity: 4.039316654205322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 3993.3259519752883
INFO:root:eval perplexity: 5.026801586151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [6:47:04<10:27:27, 319.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3539.261709872159
INFO:root:current train perplexity4.029087066650391
INFO:root:current mean train loss 3530.4259419102823
INFO:root:current train perplexity4.023029804229736
INFO:root:current mean train loss 3525.647249348958
INFO:root:current train perplexity4.019389629364014
INFO:root:current mean train loss 3530.0873879016285
INFO:root:current train perplexity4.027712821960449
INFO:root:current mean train loss 3527.1289690290178
INFO:root:current train perplexity4.030892372131348
INFO:root:current mean train loss 3529.996709160332
INFO:root:current train perplexity4.031312942504883
INFO:root:current mean train loss 3531.3813338651003
INFO:root:current train perplexity4.0311455726623535
INFO:root:current mean train loss 3534.2399992885967
INFO:root:current train perplexity4.031847953796387
INFO:root:current mean train loss 3535.02054264894
INFO:root:current train perplexity4.030635356903076
INFO:root:current mean train loss 3538.051259816754
INFO:root:current train perplexity4.03293514251709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.70s/it]
INFO:root:final mean train loss: 3533.4680409585276
INFO:root:final train perplexity: 4.03116512298584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it]
INFO:root:eval mean loss: 3994.648520611702
INFO:root:eval perplexity: 5.029490947723389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [6:52:21<10:20:36, 318.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3525.3167666480654
INFO:root:current train perplexity3.9856863021850586
INFO:root:current mean train loss 3525.0791045580904
INFO:root:current train perplexity4.004106521606445
INFO:root:current mean train loss 3516.6972219953063
INFO:root:current train perplexity4.011477470397949
INFO:root:current mean train loss 3517.3136211636966
INFO:root:current train perplexity4.013861656188965
INFO:root:current mean train loss 3521.86920126468
INFO:root:current train perplexity4.014102935791016
INFO:root:current mean train loss 3524.278881879302
INFO:root:current train perplexity4.017799377441406
INFO:root:current mean train loss 3528.8302081123916
INFO:root:current train perplexity4.021976470947266
INFO:root:current mean train loss 3531.840436982921
INFO:root:current train perplexity4.025291442871094
INFO:root:current mean train loss 3531.190586412768
INFO:root:current train perplexity4.023693084716797
INFO:root:current mean train loss 3530.955939335491
INFO:root:current train perplexity4.0235915184021


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.73s/it]
INFO:root:final mean train loss: 3528.560536107709
INFO:root:final train perplexity: 4.023367881774902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.11s/it]
INFO:root:eval mean loss: 3994.8777651955897
INFO:root:eval perplexity: 5.029956817626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [6:57:37<10:14:13, 317.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3502.80673690581
INFO:root:current train perplexity4.001286506652832
INFO:root:current mean train loss 3510.9785541735196
INFO:root:current train perplexity3.9964914321899414
INFO:root:current mean train loss 3506.1579193453067
INFO:root:current train perplexity3.993741273880005
INFO:root:current mean train loss 3510.5917198818647
INFO:root:current train perplexity4.002424240112305
INFO:root:current mean train loss 3512.7006317592222
INFO:root:current train perplexity4.001303672790527
INFO:root:current mean train loss 3517.1806170301556
INFO:root:current train perplexity4.003535270690918
INFO:root:current mean train loss 3521.4242301747627
INFO:root:current train perplexity4.007900238037109
INFO:root:current mean train loss 3525.1481563107977
INFO:root:current train perplexity4.009555339813232
INFO:root:current mean train loss 3525.731232285089
INFO:root:current train perplexity4.011973857879639
INFO:root:current mean train loss 3524.4151087092077
INFO:root:current train perplexity4.012515544891357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.81s/it]
INFO:root:final mean train loss: 3521.5217816137497
INFO:root:final train perplexity: 4.012209892272949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it]
INFO:root:eval mean loss: 3995.521678302305
INFO:root:eval perplexity: 5.031265735626221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [7:02:57<10:10:17, 318.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3470.3939348051817
INFO:root:current train perplexity3.9939944744110107
INFO:root:current mean train loss 3500.090464330918
INFO:root:current train perplexity3.995795965194702
INFO:root:current mean train loss 3513.9669377590167
INFO:root:current train perplexity3.9993081092834473
INFO:root:current mean train loss 3516.3478933047495
INFO:root:current train perplexity3.995499849319458
INFO:root:current mean train loss 3516.999793576298
INFO:root:current train perplexity3.998262405395508
INFO:root:current mean train loss 3515.625981622409
INFO:root:current train perplexity4.000011444091797
INFO:root:current mean train loss 3513.939719917848
INFO:root:current train perplexity4.000392913818359
INFO:root:current mean train loss 3517.1250288330393
INFO:root:current train perplexity4.002499580383301
INFO:root:current mean train loss 3518.6768228055676
INFO:root:current train perplexity4.002621650695801
INFO:root:current mean train loss 3519.54306251596
INFO:root:current train perplexity4.003333568572998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.02s/it]
INFO:root:final mean train loss: 3516.317480764081
INFO:root:final train perplexity: 4.00398063659668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 3997.4300459192154
INFO:root:eval perplexity: 5.035149574279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [7:08:13<10:03:25, 317.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3485.1628530217313
INFO:root:current train perplexity3.9735233783721924
INFO:root:current mean train loss 3490.9930935619986
INFO:root:current train perplexity3.974668502807617
INFO:root:current mean train loss 3493.651371440821
INFO:root:current train perplexity3.9878416061401367
INFO:root:current mean train loss 3498.9137792464066
INFO:root:current train perplexity3.988543748855591
INFO:root:current mean train loss 3501.360360586178
INFO:root:current train perplexity3.9867935180664062
INFO:root:current mean train loss 3507.3147683866587
INFO:root:current train perplexity3.990338087081909
INFO:root:current mean train loss 3507.869393649927
INFO:root:current train perplexity3.990100383758545
INFO:root:current mean train loss 3510.600524514573
INFO:root:current train perplexity3.993769645690918
INFO:root:current mean train loss 3512.0143646618694
INFO:root:current train perplexity3.9944710731506348
INFO:root:current mean train loss 3514.0262318836276
INFO:root:current train perplexity3.99590802192688


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.04s/it]
INFO:root:final mean train loss: 3511.400612800352
INFO:root:final train perplexity: 3.9962210655212402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 3997.4566641733154
INFO:root:eval perplexity: 5.0352044105529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [7:13:29<9:57:19, 317.16s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.966056743421
INFO:root:current train perplexity3.955087661743164
INFO:root:current mean train loss 3514.3298502604166
INFO:root:current train perplexity3.977090835571289
INFO:root:current mean train loss 3511.9201403601696
INFO:root:current train perplexity3.9822211265563965
INFO:root:current mean train loss 3502.7166182505935
INFO:root:current train perplexity3.977010726928711
INFO:root:current mean train loss 3502.321492266414
INFO:root:current train perplexity3.976642370223999
INFO:root:current mean train loss 3504.1445837710085
INFO:root:current train perplexity3.974966526031494
INFO:root:current mean train loss 3503.472485878485
INFO:root:current train perplexity3.977219343185425
INFO:root:current mean train loss 3504.7409904431997
INFO:root:current train perplexity3.9809813499450684
INFO:root:current mean train loss 3506.418807829958
INFO:root:current train perplexity3.9841580390930176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.30s/it]
INFO:root:final mean train loss: 3505.006702176986
INFO:root:final train perplexity: 3.9861528873443604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 3999.002794630984
INFO:root:eval perplexity: 5.038352966308594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [7:18:49<9:53:28, 317.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3695.11767578125
INFO:root:current train perplexity4.07838249206543
INFO:root:current mean train loss 3509.9557986953882
INFO:root:current train perplexity3.9733519554138184
INFO:root:current mean train loss 3497.268128944735
INFO:root:current train perplexity3.9627840518951416
INFO:root:current mean train loss 3493.1044551232467
INFO:root:current train perplexity3.958373785018921
INFO:root:current mean train loss 3499.702897216191
INFO:root:current train perplexity3.970841884613037
INFO:root:current mean train loss 3499.5894462327597
INFO:root:current train perplexity3.9733760356903076
INFO:root:current mean train loss 3499.8286412177395
INFO:root:current train perplexity3.9714441299438477
INFO:root:current mean train loss 3496.729308474284
INFO:root:current train perplexity3.9709956645965576
INFO:root:current mean train loss 3499.373869595462
INFO:root:current train perplexity3.971975326538086
INFO:root:current mean train loss 3500.56947463533
INFO:root:current train perplexity3.9770851135253906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it]
INFO:root:final mean train loss: 3499.9355894519435
INFO:root:final train perplexity: 3.9781856536865234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it]
INFO:root:eval mean loss: 4000.329993281804
INFO:root:eval perplexity: 5.041058540344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [7:24:04<9:46:51, 317.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3493.6515003551135
INFO:root:current train perplexity3.917046308517456
INFO:root:current mean train loss 3488.65844946509
INFO:root:current train perplexity3.960277795791626
INFO:root:current mean train loss 3485.878372843232
INFO:root:current train perplexity3.958932876586914
INFO:root:current mean train loss 3483.834960152482
INFO:root:current train perplexity3.95923113822937
INFO:root:current mean train loss 3481.517593569419
INFO:root:current train perplexity3.951721668243408
INFO:root:current mean train loss 3483.669605113289
INFO:root:current train perplexity3.953226089477539
INFO:root:current mean train loss 3484.9046497001586
INFO:root:current train perplexity3.958219051361084
INFO:root:current mean train loss 3490.9793273668247
INFO:root:current train perplexity3.959887742996216
INFO:root:current mean train loss 3491.24496456198
INFO:root:current train perplexity3.9619863033294678
INFO:root:current mean train loss 3493.952449124417
INFO:root:current train perplexity3.965709686279297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.98s/it]
INFO:root:final mean train loss: 3493.9318527098626
INFO:root:final train perplexity: 3.96877384185791
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.89s/it]
INFO:root:eval mean loss: 4002.427485039894
INFO:root:eval perplexity: 5.045335292816162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [7:29:34<9:48:43, 321.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3448.2256630345396
INFO:root:current train perplexity3.991107940673828
INFO:root:current mean train loss 3483.487042082458
INFO:root:current train perplexity3.93603253364563
INFO:root:current mean train loss 3498.472117802868
INFO:root:current train perplexity3.9458625316619873
INFO:root:current mean train loss 3495.357265747453
INFO:root:current train perplexity3.9526772499084473
INFO:root:current mean train loss 3495.841095334875
INFO:root:current train perplexity3.9515488147735596
INFO:root:current mean train loss 3493.7979188305335
INFO:root:current train perplexity3.9522130489349365
INFO:root:current mean train loss 3490.241580500934
INFO:root:current train perplexity3.9527015686035156
INFO:root:current mean train loss 3486.47868404468
INFO:root:current train perplexity3.955080986022949
INFO:root:current mean train loss 3487.9894432282126
INFO:root:current train perplexity3.956801414489746
INFO:root:current mean train loss 3492.1292423086406
INFO:root:current train perplexity3.960634231567383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.57s/it]
INFO:root:final mean train loss: 3488.319320678711
INFO:root:final train perplexity: 3.9599955081939697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.02s/it]
INFO:root:eval mean loss: 4001.208757549313
INFO:root:eval perplexity: 5.042849063873291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [7:35:08<9:50:08, 324.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.388481987847
INFO:root:current train perplexity3.9619522094726562
INFO:root:current mean train loss 3474.053589828371
INFO:root:current train perplexity3.9375336170196533
INFO:root:current mean train loss 3473.9714376978936
INFO:root:current train perplexity3.941715955734253
INFO:root:current mean train loss 3477.2936720541857
INFO:root:current train perplexity3.9434566497802734
INFO:root:current mean train loss 3471.947046641723
INFO:root:current train perplexity3.9413676261901855
INFO:root:current mean train loss 3477.997739730343
INFO:root:current train perplexity3.946356773376465
INFO:root:current mean train loss 3480.3395852023523
INFO:root:current train perplexity3.945690393447876
INFO:root:current mean train loss 3482.9240501015515
INFO:root:current train perplexity3.9481308460235596
INFO:root:current mean train loss 3483.581500753382
INFO:root:current train perplexity3.9500129222869873
INFO:root:current mean train loss 3484.026554440989
INFO:root:current train perplexity3.9503774642944336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it]
INFO:root:final mean train loss: 3482.0497275936987
INFO:root:final train perplexity: 3.950212240219116
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]
INFO:root:eval mean loss: 4004.3966471354165
INFO:root:eval perplexity: 5.049354553222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [7:40:44<9:50:57, 328.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.8645438058034
INFO:root:current train perplexity3.9250447750091553
INFO:root:current mean train loss 3471.2715187355325
INFO:root:current train perplexity3.9294919967651367
INFO:root:current mean train loss 3477.6436887051195
INFO:root:current train perplexity3.9390530586242676
INFO:root:current mean train loss 3480.3204757462686
INFO:root:current train perplexity3.94024395942688
INFO:root:current mean train loss 3484.0154397898705
INFO:root:current train perplexity3.944889783859253
INFO:root:current mean train loss 3484.858991220064
INFO:root:current train perplexity3.946687698364258
INFO:root:current mean train loss 3480.293287862943
INFO:root:current train perplexity3.940796375274658
INFO:root:current mean train loss 3476.8812862058885
INFO:root:current train perplexity3.938875913619995
INFO:root:current mean train loss 3478.863865433196
INFO:root:current train perplexity3.9412364959716797
INFO:root:current mean train loss 3477.772597760695
INFO:root:current train perplexity3.939556837081909


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.04s/it]
INFO:root:final mean train loss: 3477.449697063815
INFO:root:final train perplexity: 3.943049669265747
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 4003.667490857713
INFO:root:eval perplexity: 5.047865867614746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [7:46:02<9:39:37, 325.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3437.023187681686
INFO:root:current train perplexity3.919654130935669
INFO:root:current mean train loss 3472.5214058402535
INFO:root:current train perplexity3.9107935428619385
INFO:root:current mean train loss 3466.0035124099795
INFO:root:current train perplexity3.9254963397979736
INFO:root:current mean train loss 3467.5889291123817
INFO:root:current train perplexity3.926734209060669
INFO:root:current mean train loss 3465.902392798568
INFO:root:current train perplexity3.9253761768341064
INFO:root:current mean train loss 3466.4639085520257
INFO:root:current train perplexity3.926027536392212
INFO:root:current mean train loss 3467.9275308611977
INFO:root:current train perplexity3.9297125339508057
INFO:root:current mean train loss 3473.0947830795762
INFO:root:current train perplexity3.931655168533325
INFO:root:current mean train loss 3473.0438199116807
INFO:root:current train perplexity3.9320054054260254
INFO:root:current mean train loss 3473.7060065325095
INFO:root:current train perplexity3.932971954345703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.12s/it]
INFO:root:final mean train loss: 3471.679736475791
INFO:root:final train perplexity: 3.934084177017212
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 4003.562188331117
INFO:root:eval perplexity: 5.0476508140563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [7:51:11<9:25:55, 320.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.234068627451
INFO:root:current train perplexity3.9404244422912598
INFO:root:current mean train loss 3469.556404568502
INFO:root:current train perplexity3.923159599304199
INFO:root:current mean train loss 3471.1189723527764
INFO:root:current train perplexity3.9268414974212646
INFO:root:current mean train loss 3469.643463569489
INFO:root:current train perplexity3.915698766708374
INFO:root:current mean train loss 3467.413487064336
INFO:root:current train perplexity3.917261838912964
INFO:root:current mean train loss 3469.5341473421904
INFO:root:current train perplexity3.9227631092071533
INFO:root:current mean train loss 3469.964175082205
INFO:root:current train perplexity3.92708683013916
INFO:root:current mean train loss 3470.170220305218
INFO:root:current train perplexity3.926147222518921
INFO:root:current mean train loss 3470.168574654818
INFO:root:current train perplexity3.9277703762054443
INFO:root:current mean train loss 3470.9988234526977
INFO:root:current train perplexity3.9300529956817627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.39s/it]
INFO:root:final mean train loss: 3467.339179500457
INFO:root:final train perplexity: 3.9273526668548584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4007.3686661957004
INFO:root:eval perplexity: 5.055427074432373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [7:56:29<9:19:11, 319.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.249569650424
INFO:root:current train perplexity3.875887155532837
INFO:root:current mean train loss 3443.1867445459907
INFO:root:current train perplexity3.8779642581939697
INFO:root:current mean train loss 3446.524241561595
INFO:root:current train perplexity3.8865203857421875
INFO:root:current mean train loss 3454.7907524427665
INFO:root:current train perplexity3.8965840339660645
INFO:root:current mean train loss 3456.127237157884
INFO:root:current train perplexity3.900564193725586
INFO:root:current mean train loss 3460.2670418017665
INFO:root:current train perplexity3.9043378829956055
INFO:root:current mean train loss 3459.9584038463818
INFO:root:current train perplexity3.907435655593872
INFO:root:current mean train loss 3462.75777325737
INFO:root:current train perplexity3.9113004207611084
INFO:root:current mean train loss 3465.500695758149
INFO:root:current train perplexity3.915842056274414
INFO:root:current mean train loss 3465.8979578744134
INFO:root:current train perplexity3.9177157878875732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.49s/it]
INFO:root:final mean train loss: 3461.455218038251
INFO:root:final train perplexity: 3.9182469844818115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 4006.415172387522
INFO:root:eval perplexity: 5.053478240966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [8:01:46<9:12:42, 318.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3461.697108937733
INFO:root:current train perplexity3.9367105960845947
INFO:root:current mean train loss 3461.743500304079
INFO:root:current train perplexity3.9165401458740234
INFO:root:current mean train loss 3466.720715926381
INFO:root:current train perplexity3.917227268218994
INFO:root:current mean train loss 3462.7325941704275
INFO:root:current train perplexity3.9091105461120605
INFO:root:current mean train loss 3459.706869709415
INFO:root:current train perplexity3.9076502323150635
INFO:root:current mean train loss 3457.495776840829
INFO:root:current train perplexity3.907832384109497
INFO:root:current mean train loss 3458.581968659225
INFO:root:current train perplexity3.907932758331299
INFO:root:current mean train loss 3456.689000812317
INFO:root:current train perplexity3.910182476043701
INFO:root:current mean train loss 3460.013017172632
INFO:root:current train perplexity3.9117844104766846
INFO:root:current mean train loss 3460.3052209737752
INFO:root:current train perplexity3.9130842685699463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.87s/it]
INFO:root:final mean train loss: 3457.7473130995227
INFO:root:final train perplexity: 3.9125185012817383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 4007.4740241300974
INFO:root:eval perplexity: 5.055642604827881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [8:07:18<9:14:01, 322.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3441.41451171875
INFO:root:current train perplexity3.9082698822021484
INFO:root:current mean train loss 3445.7745200892855
INFO:root:current train perplexity3.9007301330566406
INFO:root:current mean train loss 3455.4880344460225
INFO:root:current train perplexity3.8963072299957275
INFO:root:current mean train loss 3458.71909765625
INFO:root:current train perplexity3.8967761993408203
INFO:root:current mean train loss 3456.1939715254935
INFO:root:current train perplexity3.89994478225708
INFO:root:current mean train loss 3452.9643117357336
INFO:root:current train perplexity3.902834892272949
INFO:root:current mean train loss 3456.8838472945604
INFO:root:current train perplexity3.9037840366363525
INFO:root:current mean train loss 3455.1036939264113
INFO:root:current train perplexity3.9031224250793457
INFO:root:current mean train loss 3456.1671930803573
INFO:root:current train perplexity3.9037601947784424
INFO:root:current mean train loss 3454.9569173177083
INFO:root:current train perplexity3.905329465866089


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.23s/it]
INFO:root:final mean train loss: 3453.1608315129433
INFO:root:final train perplexity: 3.9054453372955322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.07s/it]
INFO:root:eval mean loss: 4007.4510056515956
INFO:root:eval perplexity: 5.055595397949219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [8:12:56<9:16:34, 327.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3429.6053893307603
INFO:root:current train perplexity3.8708994388580322
INFO:root:current mean train loss 3432.8162474918886
INFO:root:current train perplexity3.8827004432678223
INFO:root:current mean train loss 3447.4058592024626
INFO:root:current train perplexity3.8849806785583496
INFO:root:current mean train loss 3449.0789861853377
INFO:root:current train perplexity3.8840396404266357
INFO:root:current mean train loss 3448.509501771157
INFO:root:current train perplexity3.8862688541412354
INFO:root:current mean train loss 3447.772849552423
INFO:root:current train perplexity3.8876125812530518
INFO:root:current mean train loss 3449.936647831259
INFO:root:current train perplexity3.8922603130340576
INFO:root:current mean train loss 3446.9718574143917
INFO:root:current train perplexity3.8907694816589355
INFO:root:current mean train loss 3448.428245604916
INFO:root:current train perplexity3.8918559551239014
INFO:root:current mean train loss 3448.929213623792
INFO:root:current train perplexity3.8943424224853516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.83s/it]
INFO:root:final mean train loss: 3446.058940026068
INFO:root:final train perplexity: 3.8945183753967285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 4011.3406385056514
INFO:root:eval perplexity: 5.063553333282471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [8:18:25<9:11:55, 327.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.339621072287
INFO:root:current train perplexity3.846959114074707
INFO:root:current mean train loss 3431.956604323462
INFO:root:current train perplexity3.859929323196411
INFO:root:current mean train loss 3435.459984428694
INFO:root:current train perplexity3.870712995529175
INFO:root:current mean train loss 3439.681696821052
INFO:root:current train perplexity3.8767855167388916
INFO:root:current mean train loss 3439.9995181827585
INFO:root:current train perplexity3.878248929977417
INFO:root:current mean train loss 3440.234753397314
INFO:root:current train perplexity3.877944231033325
INFO:root:current mean train loss 3441.492724892027
INFO:root:current train perplexity3.880234718322754
INFO:root:current mean train loss 3442.4714809181414
INFO:root:current train perplexity3.8827383518218994
INFO:root:current mean train loss 3441.2309194922314
INFO:root:current train perplexity3.884099006652832
INFO:root:current mean train loss 3445.410601664985
INFO:root:current train perplexity3.8894107341766357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.34s/it]
INFO:root:final mean train loss: 3442.6760076092137
INFO:root:final train perplexity: 3.8893239498138428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4011.4778628518397
INFO:root:eval perplexity: 5.0638346672058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [8:23:39<8:59:34, 323.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.863890368529
INFO:root:current train perplexity3.8465735912323
INFO:root:current mean train loss 3423.729668852073
INFO:root:current train perplexity3.868683338165283
INFO:root:current mean train loss 3427.285927865019
INFO:root:current train perplexity3.8708081245422363
INFO:root:current mean train loss 3425.6480771019346
INFO:root:current train perplexity3.86818790435791
INFO:root:current mean train loss 3430.5848689566633
INFO:root:current train perplexity3.869839668273926
INFO:root:current mean train loss 3432.9933878241077
INFO:root:current train perplexity3.8737080097198486
INFO:root:current mean train loss 3438.568638792024
INFO:root:current train perplexity3.878727436065674
INFO:root:current mean train loss 3441.913551607478
INFO:root:current train perplexity3.8811380863189697
INFO:root:current mean train loss 3441.281740996941
INFO:root:current train perplexity3.8821442127227783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 259.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 259.00s/it]
INFO:root:final mean train loss: 3437.997307931223
INFO:root:final train perplexity: 3.882150650024414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it]
INFO:root:eval mean loss: 4012.040091007314
INFO:root:eval perplexity: 5.0649847984313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [8:28:56<8:50:44, 321.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.3332170758927
INFO:root:current train perplexity3.8455960750579834
INFO:root:current mean train loss 3452.3976868246205
INFO:root:current train perplexity3.8694710731506348
INFO:root:current mean train loss 3438.3535368546195
INFO:root:current train perplexity3.8607301712036133
INFO:root:current mean train loss 3431.0387603063923
INFO:root:current train perplexity3.8678698539733887
INFO:root:current mean train loss 3437.1492856937193
INFO:root:current train perplexity3.871544599533081
INFO:root:current mean train loss 3436.7132440751357
INFO:root:current train perplexity3.874091625213623
INFO:root:current mean train loss 3434.903770383932
INFO:root:current train perplexity3.8705828189849854
INFO:root:current mean train loss 3433.0896299974584
INFO:root:current train perplexity3.869990587234497
INFO:root:current mean train loss 3434.533399768626
INFO:root:current train perplexity3.872459888458252
INFO:root:current mean train loss 3434.234594376637
INFO:root:current train perplexity3.874082088470459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.67s/it]
INFO:root:final mean train loss: 3433.261632857784
INFO:root:final train perplexity: 3.8749046325683594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4016.2874193123894
INFO:root:eval perplexity: 5.073691368103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [8:34:07<8:40:00, 318.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.5560384114583
INFO:root:current train perplexity3.8132174015045166
INFO:root:current mean train loss 3411.1734629755433
INFO:root:current train perplexity3.8234896659851074
INFO:root:current mean train loss 3409.92390534157
INFO:root:current train perplexity3.833786725997925
INFO:root:current mean train loss 3427.8316607762895
INFO:root:current train perplexity3.8530266284942627
INFO:root:current mean train loss 3432.7333396084337
INFO:root:current train perplexity3.8573107719421387
INFO:root:current mean train loss 3428.3612603344964
INFO:root:current train perplexity3.8548645973205566
INFO:root:current mean train loss 3430.4437269753557
INFO:root:current train perplexity3.85878849029541
INFO:root:current mean train loss 3428.8282264122595
INFO:root:current train perplexity3.861480236053467
INFO:root:current mean train loss 3428.9208469133437
INFO:root:current train perplexity3.8640692234039307
INFO:root:current mean train loss 3429.6267439378416
INFO:root:current train perplexity3.865952253341675


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.51s/it]
INFO:root:final mean train loss: 3429.2160993391467
INFO:root:final train perplexity: 3.868725299835205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it]
INFO:root:eval mean loss: 4013.439075659353
INFO:root:eval perplexity: 5.067850589752197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [8:39:24<8:34:13, 318.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.495403787364
INFO:root:current train perplexity3.7940876483917236
INFO:root:current mean train loss 3409.2536204268295
INFO:root:current train perplexity3.8223326206207275
INFO:root:current mean train loss 3414.43140195838
INFO:root:current train perplexity3.83547306060791
INFO:root:current mean train loss 3411.8152989248742
INFO:root:current train perplexity3.8369081020355225
INFO:root:current mean train loss 3411.9933943511746
INFO:root:current train perplexity3.84089994430542
INFO:root:current mean train loss 3416.968631897556
INFO:root:current train perplexity3.8499999046325684
INFO:root:current mean train loss 3420.9529572757824
INFO:root:current train perplexity3.855198860168457
INFO:root:current mean train loss 3423.116789378566
INFO:root:current train perplexity3.8591341972351074
INFO:root:current mean train loss 3423.8935027742446
INFO:root:current train perplexity3.859175682067871
INFO:root:current mean train loss 3424.626378878741
INFO:root:current train perplexity3.8579213619232178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.11s/it]
INFO:root:final mean train loss: 3423.917195535475
INFO:root:final train perplexity: 3.8606457710266113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4014.5645777925533
INFO:root:eval perplexity: 5.070158004760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [8:44:25<8:20:30, 312.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.8811980216733
INFO:root:current train perplexity3.7951557636260986
INFO:root:current mean train loss 3391.0551720539124
INFO:root:current train perplexity3.819176197052002
INFO:root:current mean train loss 3389.097227154356
INFO:root:current train perplexity3.8282318115234375
INFO:root:current mean train loss 3399.019874964596
INFO:root:current train perplexity3.8378069400787354
INFO:root:current mean train loss 3400.1016440690255
INFO:root:current train perplexity3.8370556831359863
INFO:root:current mean train loss 3404.9834411965926
INFO:root:current train perplexity3.8396012783050537
INFO:root:current mean train loss 3411.528174447182
INFO:root:current train perplexity3.8444125652313232
INFO:root:current mean train loss 3413.864737076244
INFO:root:current train perplexity3.8465240001678467
INFO:root:current mean train loss 3420.0018453035686
INFO:root:current train perplexity3.8525209426879883
INFO:root:current mean train loss 3420.006998785328
INFO:root:current train perplexity3.8510098457336426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.29s/it]
INFO:root:final mean train loss: 3418.9073963165283
INFO:root:final train perplexity: 3.853022336959839
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it]
INFO:root:eval mean loss: 4015.6200029089096
INFO:root:eval perplexity: 5.072322845458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [8:49:45<8:19:01, 315.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.1182329226763
INFO:root:current train perplexity3.8480911254882812
INFO:root:current mean train loss 3419.5137210544067
INFO:root:current train perplexity3.8443803787231445
INFO:root:current mean train loss 3412.4815229471756
INFO:root:current train perplexity3.8428027629852295
INFO:root:current mean train loss 3422.6882871554662
INFO:root:current train perplexity3.845865488052368
INFO:root:current mean train loss 3419.1056083383755
INFO:root:current train perplexity3.842993974685669
INFO:root:current mean train loss 3417.683930745594
INFO:root:current train perplexity3.8423969745635986
INFO:root:current mean train loss 3419.747089797902
INFO:root:current train perplexity3.8428537845611572
INFO:root:current mean train loss 3420.8367274055945
INFO:root:current train perplexity3.8448190689086914
INFO:root:current mean train loss 3418.3912864203107
INFO:root:current train perplexity3.844184398651123
INFO:root:current mean train loss 3417.0666438906082
INFO:root:current train perplexity3.844560146331787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.94s/it]
INFO:root:final mean train loss: 3413.6400855895013
INFO:root:final train perplexity: 3.8450233936309814
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it]
INFO:root:eval mean loss: 4019.550983834774
INFO:root:eval perplexity: 5.080391883850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [8:55:00<8:13:35, 315.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.5030699384974
INFO:root:current train perplexity3.804509162902832
INFO:root:current mean train loss 3394.285325653699
INFO:root:current train perplexity3.8303709030151367
INFO:root:current mean train loss 3394.3067177220396
INFO:root:current train perplexity3.824122667312622
INFO:root:current mean train loss 3396.962519840823
INFO:root:current train perplexity3.8282346725463867
INFO:root:current mean train loss 3403.4178414910166
INFO:root:current train perplexity3.8280136585235596
INFO:root:current mean train loss 3409.894649526537
INFO:root:current train perplexity3.833176612854004
INFO:root:current mean train loss 3412.0719312995075
INFO:root:current train perplexity3.8354122638702393
INFO:root:current mean train loss 3410.9765745926416
INFO:root:current train perplexity3.8361780643463135
INFO:root:current mean train loss 3413.641989247436
INFO:root:current train perplexity3.8408615589141846
INFO:root:current mean train loss 3413.450926960962
INFO:root:current train perplexity3.8416311740875244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.72s/it]
INFO:root:final mean train loss: 3411.9131043341854
INFO:root:final train perplexity: 3.842405319213867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it]
INFO:root:eval mean loss: 4018.179857186392
INFO:root:eval perplexity: 5.077576160430908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [9:00:21<8:11:02, 316.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.199431818182
INFO:root:current train perplexity3.812546968460083
INFO:root:current mean train loss 3397.8199691280242
INFO:root:current train perplexity3.813992738723755
INFO:root:current mean train loss 3390.1228898590684
INFO:root:current train perplexity3.814333200454712
INFO:root:current mean train loss 3399.9023313710386
INFO:root:current train perplexity3.820563554763794
INFO:root:current mean train loss 3403.7114590487636
INFO:root:current train perplexity3.819875478744507
INFO:root:current mean train loss 3402.6168861732826
INFO:root:current train perplexity3.824018716812134
INFO:root:current mean train loss 3403.7734117813693
INFO:root:current train perplexity3.8280844688415527
INFO:root:current mean train loss 3406.919619205298
INFO:root:current train perplexity3.8279128074645996
INFO:root:current mean train loss 3405.6401370042945
INFO:root:current train perplexity3.827021360397339
INFO:root:current mean train loss 3408.4831790944045
INFO:root:current train perplexity3.83196759223938


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.12s/it]
INFO:root:final mean train loss: 3404.9332389831543
INFO:root:final train perplexity: 3.831838369369507
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it]
INFO:root:eval mean loss: 4018.930329884198
INFO:root:eval perplexity: 5.079116344451904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [9:05:06<7:51:10, 307.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.3256564670137
INFO:root:current train perplexity3.8053669929504395
INFO:root:current mean train loss 3375.223343738018
INFO:root:current train perplexity3.8201687335968018
INFO:root:current mean train loss 3382.0631804375594
INFO:root:current train perplexity3.814148187637329
INFO:root:current mean train loss 3391.48429698261
INFO:root:current train perplexity3.8226842880249023
INFO:root:current mean train loss 3395.241187736231
INFO:root:current train perplexity3.8166415691375732
INFO:root:current mean train loss 3399.04143842626
INFO:root:current train perplexity3.8203582763671875
INFO:root:current mean train loss 3401.2457866409786
INFO:root:current train perplexity3.8205904960632324
INFO:root:current mean train loss 3401.866031431746
INFO:root:current train perplexity3.821115255355835
INFO:root:current mean train loss 3401.8176244070464
INFO:root:current train perplexity3.823371648788452
INFO:root:current mean train loss 3404.2403679805134
INFO:root:current train perplexity3.8273184299468994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.72s/it]
INFO:root:final mean train loss: 3402.028263276623
INFO:root:final train perplexity: 3.827449321746826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 4020.383896415115
INFO:root:eval perplexity: 5.082103729248047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [9:10:21<7:49:30, 309.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3378.116221253301
INFO:root:current train perplexity3.7877373695373535
INFO:root:current mean train loss 3378.1195289656434
INFO:root:current train perplexity3.803281784057617
INFO:root:current mean train loss 3381.1574752075644
INFO:root:current train perplexity3.8062939643859863
INFO:root:current mean train loss 3385.9605025216897
INFO:root:current train perplexity3.802366018295288
INFO:root:current mean train loss 3389.2186556611596
INFO:root:current train perplexity3.809826612472534
INFO:root:current mean train loss 3393.5144380746497
INFO:root:current train perplexity3.816802501678467
INFO:root:current mean train loss 3394.9213466956967
INFO:root:current train perplexity3.8180909156799316
INFO:root:current mean train loss 3396.364574150353
INFO:root:current train perplexity3.818268299102783
INFO:root:current mean train loss 3397.815981596674
INFO:root:current train perplexity3.8194429874420166
INFO:root:current mean train loss 3400.4402707823765
INFO:root:current train perplexity3.822733163833618


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.28s/it]
INFO:root:final mean train loss: 3398.622064036708
INFO:root:final train perplexity: 3.8223092555999756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.41s/it]
INFO:root:eval mean loss: 4022.188114680297
INFO:root:eval perplexity: 5.085812091827393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [9:15:34<7:46:06, 310.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.5534822488135
INFO:root:current train perplexity3.7932283878326416
INFO:root:current mean train loss 3391.114451488303
INFO:root:current train perplexity3.7950141429901123
INFO:root:current mean train loss 3397.9269021967407
INFO:root:current train perplexity3.8081443309783936
INFO:root:current mean train loss 3399.7337623938406
INFO:root:current train perplexity3.8127365112304688
INFO:root:current mean train loss 3400.067950095414
INFO:root:current train perplexity3.8083291053771973
INFO:root:current mean train loss 3395.378108470963
INFO:root:current train perplexity3.8034422397613525
INFO:root:current mean train loss 3396.2866958820414
INFO:root:current train perplexity3.805237293243408
INFO:root:current mean train loss 3393.5963061116013
INFO:root:current train perplexity3.807330846786499
INFO:root:current mean train loss 3393.38908349776
INFO:root:current train perplexity3.8109397888183594
INFO:root:current mean train loss 3394.8063643146706
INFO:root:current train perplexity3.8131301403045654


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.73s/it]
INFO:root:final mean train loss: 3392.4167115611413
INFO:root:final train perplexity: 3.812962532043457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.23s/it]
INFO:root:eval mean loss: 4022.49892301086
INFO:root:eval perplexity: 5.086452484130859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [9:20:51<7:43:37, 312.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.9691877693967
INFO:root:current train perplexity3.7911300659179688
INFO:root:current mean train loss 3390.7339963861964
INFO:root:current train perplexity3.794119358062744
INFO:root:current mean train loss 3389.712119923236
INFO:root:current train perplexity3.8001532554626465
INFO:root:current mean train loss 3386.033166535449
INFO:root:current train perplexity3.794888496398926
INFO:root:current mean train loss 3385.9332162594646
INFO:root:current train perplexity3.799433946609497
INFO:root:current mean train loss 3386.103853761845
INFO:root:current train perplexity3.802431344985962
INFO:root:current mean train loss 3390.2065461670986
INFO:root:current train perplexity3.8062961101531982
INFO:root:current mean train loss 3387.941433238862
INFO:root:current train perplexity3.8061881065368652
INFO:root:current mean train loss 3390.824288936989
INFO:root:current train perplexity3.808344841003418
INFO:root:current mean train loss 3392.0372802981733
INFO:root:current train perplexity3.8081352710723877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.65s/it]
INFO:root:final mean train loss: 3389.1439703664473
INFO:root:final train perplexity: 3.808042526245117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.40s/it]
INFO:root:eval mean loss: 4027.2289917857934
INFO:root:eval perplexity: 5.096190452575684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [9:26:08<7:40:23, 313.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.6549162212173
INFO:root:current train perplexity3.7733635902404785
INFO:root:current mean train loss 3358.3437387319714
INFO:root:current train perplexity3.7845582962036133
INFO:root:current mean train loss 3365.9746888241525
INFO:root:current train perplexity3.784640312194824
INFO:root:current mean train loss 3376.2342482941062
INFO:root:current train perplexity3.793836832046509
INFO:root:current mean train loss 3377.9447941327335
INFO:root:current train perplexity3.795419454574585
INFO:root:current mean train loss 3376.4979422433034
INFO:root:current train perplexity3.793682098388672
INFO:root:current mean train loss 3380.41052544683
INFO:root:current train perplexity3.7971768379211426
INFO:root:current mean train loss 3383.79902405169
INFO:root:current train perplexity3.799872875213623
INFO:root:current mean train loss 3385.41524310405
INFO:root:current train perplexity3.8021116256713867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.16s/it]
INFO:root:final mean train loss: 3385.0343122174663
INFO:root:final train perplexity: 3.801873207092285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.27s/it]
INFO:root:eval mean loss: 4025.9084940159573
INFO:root:eval perplexity: 5.093469619750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [9:31:22<7:34:53, 313.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.8175455729165
INFO:root:current train perplexity3.789977788925171
INFO:root:current mean train loss 3358.1912213668083
INFO:root:current train perplexity3.7666196823120117
INFO:root:current mean train loss 3376.9488771936576
INFO:root:current train perplexity3.7882907390594482
INFO:root:current mean train loss 3375.340367484014
INFO:root:current train perplexity3.788151979446411
INFO:root:current mean train loss 3374.9893759450606
INFO:root:current train perplexity3.7893476486206055
INFO:root:current mean train loss 3379.810846347695
INFO:root:current train perplexity3.7935636043548584
INFO:root:current mean train loss 3380.259667644849
INFO:root:current train perplexity3.792938232421875
INFO:root:current mean train loss 3381.541731377245
INFO:root:current train perplexity3.7945897579193115
INFO:root:current mean train loss 3384.585944188784
INFO:root:current train perplexity3.797272205352783
INFO:root:current mean train loss 3382.9639215310945
INFO:root:current train perplexity3.794039249420166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.30s/it]
INFO:root:final mean train loss: 3380.4409700209094
INFO:root:final train perplexity: 3.794990062713623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4025.7131070617243
INFO:root:eval perplexity: 5.093067169189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [9:36:37<7:30:14, 314.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.2393022017045
INFO:root:current train perplexity3.7707626819610596
INFO:root:current mean train loss 3366.223773578266
INFO:root:current train perplexity3.7919561862945557
INFO:root:current mean train loss 3364.5517069016587
INFO:root:current train perplexity3.788634777069092
INFO:root:current mean train loss 3372.8916078426446
INFO:root:current train perplexity3.7872068881988525
INFO:root:current mean train loss 3375.215277975783
INFO:root:current train perplexity3.7881412506103516
INFO:root:current mean train loss 3374.15240681568
INFO:root:current train perplexity3.7878661155700684
INFO:root:current mean train loss 3380.018419630984
INFO:root:current train perplexity3.7875876426696777
INFO:root:current mean train loss 3379.1409783343224
INFO:root:current train perplexity3.7884979248046875
INFO:root:current mean train loss 3376.955331296721
INFO:root:current train perplexity3.786837577819824
INFO:root:current mean train loss 3378.7579231806567
INFO:root:current train perplexity3.7885611057281494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.03s/it]
INFO:root:final mean train loss: 3378.059412248673
INFO:root:final train perplexity: 3.791426420211792
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 4027.2110760195037
INFO:root:eval perplexity: 5.0961527824401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [9:41:54<7:26:19, 315.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3315.0301192434213
INFO:root:current train perplexity3.723500967025757
INFO:root:current mean train loss 3341.198186794249
INFO:root:current train perplexity3.7638542652130127
INFO:root:current mean train loss 3357.09554593857
INFO:root:current train perplexity3.7673134803771973
INFO:root:current mean train loss 3364.6628203676037
INFO:root:current train perplexity3.772444725036621
INFO:root:current mean train loss 3365.624974362321
INFO:root:current train perplexity3.7706894874572754
INFO:root:current mean train loss 3368.762020750542
INFO:root:current train perplexity3.7715706825256348
INFO:root:current mean train loss 3370.4599759251314
INFO:root:current train perplexity3.7753055095672607
INFO:root:current mean train loss 3375.029186179807
INFO:root:current train perplexity3.778975248336792
INFO:root:current mean train loss 3375.9773807735232
INFO:root:current train perplexity3.780700922012329
INFO:root:current mean train loss 3374.0082627920124
INFO:root:current train perplexity3.782421350479126


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.45s/it]
INFO:root:final mean train loss: 3373.748268558133
INFO:root:final train perplexity: 3.784982442855835
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 4027.989979845412
INFO:root:eval perplexity: 5.0977582931518555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [9:47:08<7:20:45, 314.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3388.9347782841437
INFO:root:current train perplexity3.800088405609131
INFO:root:current mean train loss 3376.426682840182
INFO:root:current train perplexity3.773212432861328
INFO:root:current mean train loss 3374.215219102767
INFO:root:current train perplexity3.7690746784210205
INFO:root:current mean train loss 3369.6557520128536
INFO:root:current train perplexity3.770357370376587
INFO:root:current mean train loss 3372.081721357216
INFO:root:current train perplexity3.7737441062927246
INFO:root:current mean train loss 3371.202034011059
INFO:root:current train perplexity3.7720580101013184
INFO:root:current mean train loss 3371.7876767001844
INFO:root:current train perplexity3.7726354598999023
INFO:root:current mean train loss 3372.3453427909003
INFO:root:current train perplexity3.7752537727355957
INFO:root:current mean train loss 3371.531905371448
INFO:root:current train perplexity3.7750580310821533
INFO:root:current mean train loss 3371.795887902845
INFO:root:current train perplexity3.7779932022094727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.02s/it]
INFO:root:final mean train loss: 3368.7911284662064
INFO:root:final train perplexity: 3.777587890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4028.1422474096853
INFO:root:eval perplexity: 5.0980730056762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [9:52:27<7:17:03, 315.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.0003487723216
INFO:root:current train perplexity3.741029977798462
INFO:root:current mean train loss 3360.368874782986
INFO:root:current train perplexity3.7480597496032715
INFO:root:current mean train loss 3358.121845910904
INFO:root:current train perplexity3.756333351135254
INFO:root:current mean train loss 3366.352445778918
INFO:root:current train perplexity3.7647504806518555
INFO:root:current mean train loss 3368.8642561287716
INFO:root:current train perplexity3.766294479370117
INFO:root:current mean train loss 3368.601060984959
INFO:root:current train perplexity3.7673180103302
INFO:root:current mean train loss 3367.983047797736
INFO:root:current train perplexity3.77042555809021
INFO:root:current mean train loss 3369.301123711203
INFO:root:current train perplexity3.770392417907715
INFO:root:current mean train loss 3368.6904036653254
INFO:root:current train perplexity3.771306276321411
INFO:root:current mean train loss 3368.939672982119
INFO:root:current train perplexity3.773776054382324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.03s/it]
INFO:root:final mean train loss: 3366.020317139164
INFO:root:final train perplexity: 3.773460865020752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it]
INFO:root:eval mean loss: 4032.788591533688
INFO:root:eval perplexity: 5.107659816741943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [9:57:29<7:06:04, 311.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.7539914153344
INFO:root:current train perplexity3.7470271587371826
INFO:root:current mean train loss 3346.4094306572333
INFO:root:current train perplexity3.73846435546875
INFO:root:current mean train loss 3348.38091563786
INFO:root:current train perplexity3.7473020553588867
INFO:root:current mean train loss 3353.4758692260384
INFO:root:current train perplexity3.7511343955993652
INFO:root:current mean train loss 3360.433217894681
INFO:root:current train perplexity3.7541940212249756
INFO:root:current mean train loss 3360.3621922838975
INFO:root:current train perplexity3.754579782485962
INFO:root:current mean train loss 3362.471304933539
INFO:root:current train perplexity3.759209632873535
INFO:root:current mean train loss 3363.7886307358262
INFO:root:current train perplexity3.76230525970459
INFO:root:current mean train loss 3362.944439907232
INFO:root:current train perplexity3.7668566703796387
INFO:root:current mean train loss 3363.655557448386
INFO:root:current train perplexity3.7664296627044678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.26s/it]
INFO:root:final mean train loss: 3361.58793633984
INFO:root:final train perplexity: 3.766867160797119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it]
INFO:root:eval mean loss: 4032.3291015625
INFO:root:eval perplexity: 5.106709957122803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [10:02:42<7:01:24, 312.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.9591519224878
INFO:root:current train perplexity3.7688353061676025
INFO:root:current mean train loss 3349.6750472112994
INFO:root:current train perplexity3.746526002883911
INFO:root:current mean train loss 3347.335329580117
INFO:root:current train perplexity3.7505955696105957
INFO:root:current mean train loss 3344.023443760016
INFO:root:current train perplexity3.751983404159546
INFO:root:current mean train loss 3345.584928998926
INFO:root:current train perplexity3.751495838165283
INFO:root:current mean train loss 3349.7021652747844
INFO:root:current train perplexity3.7522432804107666
INFO:root:current mean train loss 3353.6956740231376
INFO:root:current train perplexity3.7548651695251465
INFO:root:current mean train loss 3357.467742229111
INFO:root:current train perplexity3.7579851150512695
INFO:root:current mean train loss 3357.692205516488
INFO:root:current train perplexity3.7595901489257812
INFO:root:current mean train loss 3359.809177017613
INFO:root:current train perplexity3.76094651222229


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.18s/it]
INFO:root:final mean train loss: 3357.778386208319
INFO:root:final train perplexity: 3.7612102031707764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 4034.869125041556
INFO:root:eval perplexity: 5.1119585037231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [10:07:59<6:58:07, 313.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.0631662142478
INFO:root:current train perplexity3.73077654838562
INFO:root:current mean train loss 3339.010490369497
INFO:root:current train perplexity3.7330636978149414
INFO:root:current mean train loss 3339.772164009713
INFO:root:current train perplexity3.729818344116211
INFO:root:current mean train loss 3347.2644716225627
INFO:root:current train perplexity3.742278814315796
INFO:root:current mean train loss 3348.396816278595
INFO:root:current train perplexity3.7453196048736572
INFO:root:current mean train loss 3346.5504414621532
INFO:root:current train perplexity3.7482450008392334
INFO:root:current mean train loss 3352.153542965786
INFO:root:current train perplexity3.7523066997528076
INFO:root:current mean train loss 3354.868200731843
INFO:root:current train perplexity3.7552828788757324
INFO:root:current mean train loss 3356.6057967340294
INFO:root:current train perplexity3.755789279937744
INFO:root:current mean train loss 3356.5008645480316
INFO:root:current train perplexity3.755800485610962


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.98s/it]
INFO:root:final mean train loss: 3354.6404311272404
INFO:root:final train perplexity: 3.756556272506714
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4035.931893423094
INFO:root:eval perplexity: 5.1141557693481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [10:13:10<6:51:53, 312.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.17433098181
INFO:root:current train perplexity3.7509658336639404
INFO:root:current mean train loss 3348.073597434038
INFO:root:current train perplexity3.74552321434021
INFO:root:current mean train loss 3340.9063926439608
INFO:root:current train perplexity3.734158515930176
INFO:root:current mean train loss 3341.4546058093492
INFO:root:current train perplexity3.7384490966796875
INFO:root:current mean train loss 3345.436700138852
INFO:root:current train perplexity3.7377045154571533
INFO:root:current mean train loss 3345.067494333526
INFO:root:current train perplexity3.73858904838562
INFO:root:current mean train loss 3348.631409514969
INFO:root:current train perplexity3.741487979888916
INFO:root:current mean train loss 3348.574518912463
INFO:root:current train perplexity3.74269700050354
INFO:root:current mean train loss 3350.277901021392
INFO:root:current train perplexity3.744145393371582
INFO:root:current mean train loss 3352.8178051985037
INFO:root:current train perplexity3.7489376068115234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.17s/it]
INFO:root:final mean train loss: 3350.754359276064
INFO:root:final train perplexity: 3.7508013248443604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it]
INFO:root:eval mean loss: 4034.5966398631426
INFO:root:eval perplexity: 5.111395359039307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [10:17:49<6:33:22, 302.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.799794921875
INFO:root:current train perplexity3.732579469680786
INFO:root:current mean train loss 3333.903974609375
INFO:root:current train perplexity3.742905378341675
INFO:root:current mean train loss 3343.513106356534
INFO:root:current train perplexity3.746440887451172
INFO:root:current mean train loss 3343.9173841145835
INFO:root:current train perplexity3.742316484451294
INFO:root:current mean train loss 3348.194263466283
INFO:root:current train perplexity3.7457592487335205
INFO:root:current mean train loss 3349.1275025475543
INFO:root:current train perplexity3.743445634841919
INFO:root:current mean train loss 3350.518559751157
INFO:root:current train perplexity3.744873523712158
INFO:root:current mean train loss 3351.267664125504
INFO:root:current train perplexity3.745950937271118
INFO:root:current mean train loss 3349.91045703125
INFO:root:current train perplexity3.7452526092529297
INFO:root:current mean train loss 3349.599960186298
INFO:root:current train perplexity3.7454440593719482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.32s/it]
INFO:root:final mean train loss: 3347.4831063670495
INFO:root:final train perplexity: 3.7459638118743896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.46s/it]
INFO:root:eval mean loss: 4037.9267456920434
INFO:root:eval perplexity: 5.118282318115234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [10:22:27<6:19:08, 295.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.0126364834337
INFO:root:current train perplexity3.7230780124664307
INFO:root:current mean train loss 3315.1904430285176
INFO:root:current train perplexity3.719203233718872
INFO:root:current mean train loss 3323.3794635462677
INFO:root:current train perplexity3.7209384441375732
INFO:root:current mean train loss 3333.131535064458
INFO:root:current train perplexity3.730090379714966
INFO:root:current mean train loss 3336.9156173168994
INFO:root:current train perplexity3.736790418624878
INFO:root:current mean train loss 3345.905918337264
INFO:root:current train perplexity3.738708019256592
INFO:root:current mean train loss 3347.6503577392937
INFO:root:current train perplexity3.7394087314605713
INFO:root:current mean train loss 3345.8205606940455
INFO:root:current train perplexity3.736386775970459
INFO:root:current mean train loss 3345.94769888475
INFO:root:current train perplexity3.738502264022827
INFO:root:current mean train loss 3345.8558330982164
INFO:root:current train perplexity3.7395408153533936


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it]
INFO:root:final mean train loss: 3342.92787010439
INFO:root:final train perplexity: 3.7392375469207764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it]
INFO:root:eval mean loss: 4037.245749182735
INFO:root:eval perplexity: 5.116873264312744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [10:27:06<6:07:50, 290.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.719654125172
INFO:root:current train perplexity3.681579113006592
INFO:root:current mean train loss 3336.025205282641
INFO:root:current train perplexity3.7196664810180664
INFO:root:current mean train loss 3337.8451317855993
INFO:root:current train perplexity3.7215516567230225
INFO:root:current mean train loss 3339.192194867927
INFO:root:current train perplexity3.7210750579833984
INFO:root:current mean train loss 3338.0874649949083
INFO:root:current train perplexity3.7222046852111816
INFO:root:current mean train loss 3341.1532885039924
INFO:root:current train perplexity3.728835344314575
INFO:root:current mean train loss 3342.6193833523653
INFO:root:current train perplexity3.730332851409912
INFO:root:current mean train loss 3344.9815860560207
INFO:root:current train perplexity3.731048345565796
INFO:root:current mean train loss 3342.834073153409
INFO:root:current train perplexity3.7332096099853516
INFO:root:current mean train loss 3342.497529523524
INFO:root:current train perplexity3.7346794605255127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.14s/it]
INFO:root:final mean train loss: 3339.798416876024
INFO:root:final train perplexity: 3.7346243858337402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4038.33648984652
INFO:root:eval perplexity: 5.119131088256836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [10:31:44<5:58:30, 286.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.6696580058397
INFO:root:current train perplexity3.7320287227630615
INFO:root:current mean train loss 3332.380064384422
INFO:root:current train perplexity3.7276554107666016
INFO:root:current mean train loss 3335.0328324231814
INFO:root:current train perplexity3.7278859615325928
INFO:root:current mean train loss 3334.313015815907
INFO:root:current train perplexity3.7261173725128174
INFO:root:current mean train loss 3334.4773335733967
INFO:root:current train perplexity3.7244391441345215
INFO:root:current mean train loss 3336.3390298120567
INFO:root:current train perplexity3.7241127490997314
INFO:root:current mean train loss 3335.4583661648335
INFO:root:current train perplexity3.725112199783325
INFO:root:current mean train loss 3338.3999964555305
INFO:root:current train perplexity3.7272794246673584
INFO:root:current mean train loss 3339.6045513895647
INFO:root:current train perplexity3.7304306030273438


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.40s/it]
INFO:root:final mean train loss: 3337.0097014519474
INFO:root:final train perplexity: 3.7305169105529785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 4040.3685553800974
INFO:root:eval perplexity: 5.12333869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [10:36:26<5:51:52, 285.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.22265625
INFO:root:current train perplexity3.781017303466797
INFO:root:current mean train loss 3325.246116566881
INFO:root:current train perplexity3.7131271362304688
INFO:root:current mean train loss 3329.329227760794
INFO:root:current train perplexity3.7132956981658936
INFO:root:current mean train loss 3329.8071965021886
INFO:root:current train perplexity3.715843677520752
INFO:root:current mean train loss 3323.0108849527796
INFO:root:current train perplexity3.715956687927246
INFO:root:current mean train loss 3327.5333726269723
INFO:root:current train perplexity3.7191526889801025
INFO:root:current mean train loss 3328.592857499099
INFO:root:current train perplexity3.717041492462158
INFO:root:current mean train loss 3332.9788485126414
INFO:root:current train perplexity3.721830129623413
INFO:root:current mean train loss 3334.5413111954963
INFO:root:current train perplexity3.723384380340576
INFO:root:current mean train loss 3334.472188156784
INFO:root:current train perplexity3.721766233444214


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.71s/it]
INFO:root:final mean train loss: 3332.4766071073473
INFO:root:final train perplexity: 3.723851203918457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4041.766071725399
INFO:root:eval perplexity: 5.126235485076904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [10:41:06<5:45:17, 283.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3293.6611328125
INFO:root:current train perplexity3.7300117015838623
INFO:root:current mean train loss 3310.516745923913
INFO:root:current train perplexity3.7250030040740967
INFO:root:current mean train loss 3316.4936761900435
INFO:root:current train perplexity3.7223541736602783
INFO:root:current mean train loss 3324.272585720486
INFO:root:current train perplexity3.7183597087860107
INFO:root:current mean train loss 3326.4987175263554
INFO:root:current train perplexity3.7164065837860107
INFO:root:current mean train loss 3326.4138468029428
INFO:root:current train perplexity3.7181596755981445
INFO:root:current mean train loss 3328.4653117854423
INFO:root:current train perplexity3.717057466506958
INFO:root:current mean train loss 3329.4382109101834
INFO:root:current train perplexity3.7179670333862305
INFO:root:current mean train loss 3329.283461944018
INFO:root:current train perplexity3.7170543670654297
INFO:root:current mean train loss 3331.8702932889346
INFO:root:current train perplexity3.7205982208251953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.37s/it]
INFO:root:final mean train loss: 3330.6728667597617
INFO:root:final train perplexity: 3.7212023735046387
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it]
INFO:root:eval mean loss: 4041.2692576739805
INFO:root:eval perplexity: 5.125205039978027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [10:45:49<5:40:16, 283.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3278.2592985733695
INFO:root:current train perplexity3.69000244140625
INFO:root:current mean train loss 3328.596054449314
INFO:root:current train perplexity3.7074837684631348
INFO:root:current mean train loss 3327.699076425869
INFO:root:current train perplexity3.7088234424591064
INFO:root:current mean train loss 3328.076031286281
INFO:root:current train perplexity3.715996503829956
INFO:root:current mean train loss 3325.88404763224
INFO:root:current train perplexity3.7097835540771484
INFO:root:current mean train loss 3324.309051221917
INFO:root:current train perplexity3.711374282836914
INFO:root:current mean train loss 3327.148428486783
INFO:root:current train perplexity3.7147886753082275
INFO:root:current mean train loss 3328.6438974298712
INFO:root:current train perplexity3.7161567211151123
INFO:root:current mean train loss 3327.178950035123
INFO:root:current train perplexity3.714496374130249
INFO:root:current mean train loss 3327.6981152237945
INFO:root:current train perplexity3.7137954235076904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.85s/it]
INFO:root:final mean train loss: 3326.4824207675074
INFO:root:final train perplexity: 3.715055227279663
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 4043.4914204482493
INFO:root:eval perplexity: 5.129812717437744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [10:50:28<5:33:49, 282.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.607177734375
INFO:root:current train perplexity3.6688244342803955
INFO:root:current mean train loss 3311.740288421398
INFO:root:current train perplexity3.692617654800415
INFO:root:current mean train loss 3326.0683868540314
INFO:root:current train perplexity3.7074174880981445
INFO:root:current mean train loss 3327.7335540679287
INFO:root:current train perplexity3.710460662841797
INFO:root:current mean train loss 3324.770725896353
INFO:root:current train perplexity3.7115228176116943
INFO:root:current mean train loss 3326.5308467771597
INFO:root:current train perplexity3.714376449584961
INFO:root:current mean train loss 3326.5397999517136
INFO:root:current train perplexity3.7118258476257324
INFO:root:current mean train loss 3327.87028384437
INFO:root:current train perplexity3.7118852138519287
INFO:root:current mean train loss 3323.8490726181744
INFO:root:current train perplexity3.708242177963257
INFO:root:current mean train loss 3323.7588391493523
INFO:root:current train perplexity3.707770586013794


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.68s/it]
INFO:root:final mean train loss: 3322.5230575684577
INFO:root:final train perplexity: 3.709256410598755
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 4044.89023714539
INFO:root:eval perplexity: 5.132715225219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [10:55:10<5:29:06, 282.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.677158453526
INFO:root:current train perplexity3.7051517963409424
INFO:root:current mean train loss 3324.067572504496
INFO:root:current train perplexity3.7083146572113037
INFO:root:current mean train loss 3321.8334174375655
INFO:root:current train perplexity3.7014739513397217
INFO:root:current mean train loss 3324.137860953632
INFO:root:current train perplexity3.7047908306121826
INFO:root:current mean train loss 3323.05688198498
INFO:root:current train perplexity3.705836534500122
INFO:root:current mean train loss 3316.6215050295687
INFO:root:current train perplexity3.702737808227539
INFO:root:current mean train loss 3316.2805794729315
INFO:root:current train perplexity3.702681303024292
INFO:root:current mean train loss 3316.6921472613963
INFO:root:current train perplexity3.700759172439575
INFO:root:current mean train loss 3321.036540780505
INFO:root:current train perplexity3.7039601802825928
INFO:root:current mean train loss 3321.1897282057043
INFO:root:current train perplexity3.704801559448242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.97s/it]
INFO:root:final mean train loss: 3319.3273809494513
INFO:root:final train perplexity: 3.7045834064483643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.35s/it]
INFO:root:eval mean loss: 4046.983263380984
INFO:root:eval perplexity: 5.13706111907959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [10:59:48<5:23:05, 280.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.097817278923
INFO:root:current train perplexity3.698133707046509
INFO:root:current mean train loss 3316.4496588674533
INFO:root:current train perplexity3.6933047771453857
INFO:root:current mean train loss 3315.061632164094
INFO:root:current train perplexity3.7007126808166504
INFO:root:current mean train loss 3313.5484538229466
INFO:root:current train perplexity3.6932647228240967
INFO:root:current mean train loss 3315.895482142233
INFO:root:current train perplexity3.6944351196289062
INFO:root:current mean train loss 3316.6622977248057
INFO:root:current train perplexity3.6954376697540283
INFO:root:current mean train loss 3317.3882737786175
INFO:root:current train perplexity3.6986818313598633
INFO:root:current mean train loss 3318.5605102702475
INFO:root:current train perplexity3.7006077766418457
INFO:root:current mean train loss 3317.689684006512
INFO:root:current train perplexity3.6997385025024414
INFO:root:current mean train loss 3318.9936059389847
INFO:root:current train perplexity3.7004480361938477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.16s/it]
INFO:root:final mean train loss: 3317.714304277974
INFO:root:final train perplexity: 3.702225923538208
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]
INFO:root:eval mean loss: 4044.198900155142
INFO:root:eval perplexity: 5.131280422210693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [11:04:27<5:17:32, 280.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.2422807173293
INFO:root:current train perplexity3.6706745624542236
INFO:root:current mean train loss 3290.0092852192543
INFO:root:current train perplexity3.6830461025238037
INFO:root:current mean train loss 3290.7021149280026
INFO:root:current train perplexity3.6840169429779053
INFO:root:current mean train loss 3293.6637936014527
INFO:root:current train perplexity3.6802237033843994
INFO:root:current mean train loss 3299.03143189818
INFO:root:current train perplexity3.6812148094177246
INFO:root:current mean train loss 3302.8695906355574
INFO:root:current train perplexity3.683807849884033
INFO:root:current mean train loss 3305.6062984553914
INFO:root:current train perplexity3.688265323638916
INFO:root:current mean train loss 3307.548426828953
INFO:root:current train perplexity3.689235210418701
INFO:root:current mean train loss 3311.0963039108187
INFO:root:current train perplexity3.691196918487549
INFO:root:current mean train loss 3313.4442993803173
INFO:root:current train perplexity3.6941542625427246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.48s/it]
INFO:root:final mean train loss: 3313.1775819716913
INFO:root:final train perplexity: 3.695605516433716
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 4046.802459067487
INFO:root:eval perplexity: 5.136685848236084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [11:09:10<5:13:48, 281.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.3314228360614
INFO:root:current train perplexity3.690420389175415
INFO:root:current mean train loss 3298.1306811373656
INFO:root:current train perplexity3.683180093765259
INFO:root:current mean train loss 3304.5681746450214
INFO:root:current train perplexity3.689974784851074
INFO:root:current mean train loss 3308.234573406293
INFO:root:current train perplexity3.692784309387207
INFO:root:current mean train loss 3310.4886319055413
INFO:root:current train perplexity3.6918203830718994
INFO:root:current mean train loss 3317.4192332509992
INFO:root:current train perplexity3.694389820098877
INFO:root:current mean train loss 3314.3337582779504
INFO:root:current train perplexity3.690924882888794
INFO:root:current mean train loss 3312.4974280441106
INFO:root:current train perplexity3.689798355102539
INFO:root:current mean train loss 3312.7875470175804
INFO:root:current train perplexity3.6911752223968506
INFO:root:current mean train loss 3314.545294804241
INFO:root:current train perplexity3.6933488845825195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.34s/it]
INFO:root:final mean train loss: 3311.977039952432
INFO:root:final train perplexity: 3.693855047225952
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 4050.289555975731
INFO:root:eval perplexity: 5.143934726715088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [11:13:48<5:08:06, 280.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3301.6946729203346
INFO:root:current train perplexity3.6766247749328613
INFO:root:current mean train loss 3289.3632441292034
INFO:root:current train perplexity3.6613237857818604
INFO:root:current mean train loss 3292.06750803592
INFO:root:current train perplexity3.6663975715637207
INFO:root:current mean train loss 3296.8642229352677
INFO:root:current train perplexity3.6722571849823
INFO:root:current mean train loss 3300.407211530487
INFO:root:current train perplexity3.675661087036133
INFO:root:current mean train loss 3306.5603570353546
INFO:root:current train perplexity3.6786773204803467
INFO:root:current mean train loss 3310.7809036186663
INFO:root:current train perplexity3.6855645179748535
INFO:root:current mean train loss 3309.1138300122607
INFO:root:current train perplexity3.6848154067993164
INFO:root:current mean train loss 3309.730567415327
INFO:root:current train perplexity3.6861045360565186
INFO:root:current mean train loss 3308.414571398687
INFO:root:current train perplexity3.6849119663238525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.88s/it]
INFO:root:final mean train loss: 3306.478935426281
INFO:root:final train perplexity: 3.6858513355255127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]
INFO:root:eval mean loss: 4050.1117107851287
INFO:root:eval perplexity: 5.143564701080322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [11:18:26<5:02:48, 279.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.3733868176423
INFO:root:current train perplexity3.6747000217437744
INFO:root:current mean train loss 3302.110957140363
INFO:root:current train perplexity3.6887545585632324
INFO:root:current mean train loss 3300.231733205925
INFO:root:current train perplexity3.6809918880462646
INFO:root:current mean train loss 3304.153453011626
INFO:root:current train perplexity3.6816892623901367
INFO:root:current mean train loss 3307.3284425357188
INFO:root:current train perplexity3.6836915016174316
INFO:root:current mean train loss 3308.9326943511173
INFO:root:current train perplexity3.683823347091675
INFO:root:current mean train loss 3312.1466393449696
INFO:root:current train perplexity3.684830904006958
INFO:root:current mean train loss 3311.731252883304
INFO:root:current train perplexity3.6831724643707275
INFO:root:current mean train loss 3311.0234150024
INFO:root:current train perplexity3.6842286586761475
INFO:root:current mean train loss 3308.0194781325813
INFO:root:current train perplexity3.6837875843048096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.91s/it]
INFO:root:final mean train loss: 3305.4365317436955
INFO:root:final train perplexity: 3.684335708618164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.31s/it]
INFO:root:eval mean loss: 4051.383056640625
INFO:root:eval perplexity: 5.146209239959717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [11:23:04<4:57:42, 279.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.0346876122485
INFO:root:current train perplexity3.664263963699341
INFO:root:current mean train loss 3297.8168801700367
INFO:root:current train perplexity3.673851490020752
INFO:root:current mean train loss 3295.7861778977026
INFO:root:current train perplexity3.669914722442627
INFO:root:current mean train loss 3302.773858910691
INFO:root:current train perplexity3.6744213104248047
INFO:root:current mean train loss 3306.4429172147716
INFO:root:current train perplexity3.6768386363983154
INFO:root:current mean train loss 3305.9955734434893
INFO:root:current train perplexity3.675473928451538
INFO:root:current mean train loss 3304.797031719091
INFO:root:current train perplexity3.6747775077819824
INFO:root:current mean train loss 3302.369625493865
INFO:root:current train perplexity3.6738178730010986
INFO:root:current mean train loss 3302.5875699667945
INFO:root:current train perplexity3.6750407218933105
INFO:root:current mean train loss 3303.1879840761935
INFO:root:current train perplexity3.677554130554199


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.75s/it]
INFO:root:final mean train loss: 3300.9228128002537
INFO:root:final train perplexity: 3.677780866622925
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4052.0703367409133
INFO:root:eval perplexity: 5.147640228271484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [11:27:45<4:53:44, 279.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.5327354029605
INFO:root:current train perplexity3.656135082244873
INFO:root:current mean train loss 3294.859612880609
INFO:root:current train perplexity3.662738561630249
INFO:root:current mean train loss 3298.0076908434853
INFO:root:current train perplexity3.6695518493652344
INFO:root:current mean train loss 3298.697600623022
INFO:root:current train perplexity3.6738133430480957
INFO:root:current mean train loss 3297.255641867898
INFO:root:current train perplexity3.674143075942993
INFO:root:current mean train loss 3300.0055237329307
INFO:root:current train perplexity3.676823854446411
INFO:root:current mean train loss 3298.0567056120726
INFO:root:current train perplexity3.6749234199523926
INFO:root:current mean train loss 3301.983634593652
INFO:root:current train perplexity3.6785082817077637
INFO:root:current mean train loss 3301.567277518331
INFO:root:current train perplexity3.676544666290283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.57s/it]
INFO:root:final mean train loss: 3299.759645277454
INFO:root:final train perplexity: 3.676093578338623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it]
INFO:root:eval mean loss: 4055.6417920268173
INFO:root:eval perplexity: 5.155078887939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [11:32:24<4:48:48, 279.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.149169921875
INFO:root:current train perplexity3.550804615020752
INFO:root:current mean train loss 3274.0451565344356
INFO:root:current train perplexity3.6385343074798584
INFO:root:current mean train loss 3279.4773598656866
INFO:root:current train perplexity3.6479477882385254
INFO:root:current mean train loss 3285.8792511087045
INFO:root:current train perplexity3.6580896377563477
INFO:root:current mean train loss 3292.338583063547
INFO:root:current train perplexity3.658656120300293
INFO:root:current mean train loss 3293.833648984996
INFO:root:current train perplexity3.659728765487671
INFO:root:current mean train loss 3294.9499244500157
INFO:root:current train perplexity3.6610612869262695
INFO:root:current mean train loss 3295.3375610525204
INFO:root:current train perplexity3.6637561321258545
INFO:root:current mean train loss 3297.95281974821
INFO:root:current train perplexity3.666982889175415
INFO:root:current mean train loss 3298.31947463533
INFO:root:current train perplexity3.6693367958068848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.42s/it]
INFO:root:final mean train loss: 3296.946261313654
INFO:root:final train perplexity: 3.67201566696167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 4055.035661846188
INFO:root:eval perplexity: 5.153815269470215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [11:37:02<4:43:43, 279.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.8940651633525
INFO:root:current train perplexity3.5957467555999756
INFO:root:current mean train loss 3290.7260126337274
INFO:root:current train perplexity3.662393093109131
INFO:root:current mean train loss 3288.3908888107226
INFO:root:current train perplexity3.6546082496643066
INFO:root:current mean train loss 3278.0740790167806
INFO:root:current train perplexity3.643556594848633
INFO:root:current mean train loss 3282.5697588769767
INFO:root:current train perplexity3.6483256816864014
INFO:root:current mean train loss 3285.037177218383
INFO:root:current train perplexity3.656902313232422
INFO:root:current mean train loss 3287.282428348123
INFO:root:current train perplexity3.6571547985076904
INFO:root:current mean train loss 3290.330562972486
INFO:root:current train perplexity3.658315896987915
INFO:root:current mean train loss 3292.4705185896078
INFO:root:current train perplexity3.662936210632324
INFO:root:current mean train loss 3294.761965570544
INFO:root:current train perplexity3.6641342639923096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.88s/it]
INFO:root:final mean train loss: 3292.3516363943777
INFO:root:final train perplexity: 3.665364980697632
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4056.0593556072695
INFO:root:eval perplexity: 5.155950546264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [11:41:40<4:38:48, 278.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.2273206208883
INFO:root:current train perplexity3.6474785804748535
INFO:root:current mean train loss 3263.3596335018383
INFO:root:current train perplexity3.634337902069092
INFO:root:current mean train loss 3265.9214201626714
INFO:root:current train perplexity3.647920846939087
INFO:root:current mean train loss 3274.8521839488635
INFO:root:current train perplexity3.6502459049224854
INFO:root:current mean train loss 3279.392380015662
INFO:root:current train perplexity3.6525933742523193
INFO:root:current mean train loss 3283.298779202794
INFO:root:current train perplexity3.6553821563720703
INFO:root:current mean train loss 3281.943384222915
INFO:root:current train perplexity3.6542441844940186
INFO:root:current mean train loss 3285.202709044137
INFO:root:current train perplexity3.655942916870117
INFO:root:current mean train loss 3287.2333173553875
INFO:root:current train perplexity3.657247543334961
INFO:root:current mean train loss 3288.977344865768
INFO:root:current train perplexity3.657484292984009


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.36s/it]
INFO:root:final mean train loss: 3289.3553256988525
INFO:root:final train perplexity: 3.6610348224639893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.48s/it]
INFO:root:eval mean loss: 4055.6413816627883
INFO:root:eval perplexity: 5.155078411102295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [11:46:22<4:35:02, 279.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.433349609375
INFO:root:current train perplexity3.6602044105529785
INFO:root:current mean train loss 3280.552765132874
INFO:root:current train perplexity3.6556942462921143
INFO:root:current mean train loss 3281.671260884155
INFO:root:current train perplexity3.6558680534362793
INFO:root:current mean train loss 3283.641940522267
INFO:root:current train perplexity3.660414695739746
INFO:root:current mean train loss 3288.0744188652666
INFO:root:current train perplexity3.660043239593506
INFO:root:current mean train loss 3287.671971822373
INFO:root:current train perplexity3.657170057296753
INFO:root:current mean train loss 3288.171084950035
INFO:root:current train perplexity3.6584441661834717
INFO:root:current mean train loss 3288.5443963178086
INFO:root:current train perplexity3.6590495109558105
INFO:root:current mean train loss 3289.389842392023
INFO:root:current train perplexity3.660449504852295
INFO:root:current mean train loss 3289.4827895344524
INFO:root:current train perplexity3.6587471961975098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.61s/it]
INFO:root:final mean train loss: 3287.861719500634
INFO:root:final train perplexity: 3.6588785648345947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.44s/it]
INFO:root:eval mean loss: 4058.1589892231827
INFO:root:eval perplexity: 5.160329341888428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [11:51:01<4:30:10, 279.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.138671875
INFO:root:current train perplexity3.654564380645752
INFO:root:current mean train loss 3311.579510271991
INFO:root:current train perplexity3.6440770626068115
INFO:root:current mean train loss 3298.1425552692817
INFO:root:current train perplexity3.6427066326141357
INFO:root:current mean train loss 3297.2298194088153
INFO:root:current train perplexity3.646387815475464
INFO:root:current mean train loss 3290.1478902882545
INFO:root:current train perplexity3.648080587387085
INFO:root:current mean train loss 3294.7370705863027
INFO:root:current train perplexity3.652838706970215
INFO:root:current mean train loss 3290.6305098886564
INFO:root:current train perplexity3.6489734649658203
INFO:root:current mean train loss 3287.9918131510417
INFO:root:current train perplexity3.6499946117401123
INFO:root:current mean train loss 3286.2008218913734
INFO:root:current train perplexity3.6519882678985596
INFO:root:current mean train loss 3286.500325346758
INFO:root:current train perplexity3.654012680053711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.32s/it]
INFO:root:final mean train loss: 3285.3227134827644
INFO:root:final train perplexity: 3.655214786529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 4057.874740275931
INFO:root:eval perplexity: 5.159735679626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [11:55:40<4:25:23, 279.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.8924816042877
INFO:root:current train perplexity3.636119842529297
INFO:root:current mean train loss 3272.363209544362
INFO:root:current train perplexity3.630183696746826
INFO:root:current mean train loss 3270.0206886574074
INFO:root:current train perplexity3.632038116455078
INFO:root:current mean train loss 3275.690959252004
INFO:root:current train perplexity3.63432240486145
INFO:root:current mean train loss 3276.648458442085
INFO:root:current train perplexity3.6374611854553223
INFO:root:current mean train loss 3278.096431050731
INFO:root:current train perplexity3.639864444732666
INFO:root:current mean train loss 3281.3054446017204
INFO:root:current train perplexity3.643460512161255
INFO:root:current mean train loss 3278.939902632907
INFO:root:current train perplexity3.6445388793945312
INFO:root:current mean train loss 3281.0990414511975
INFO:root:current train perplexity3.647057294845581
INFO:root:current mean train loss 3281.8567119772338
INFO:root:current train perplexity3.64939022064209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.84s/it]
INFO:root:final mean train loss: 3281.609274648851
INFO:root:final train perplexity: 3.6498639583587646
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 4060.506094858156
INFO:root:eval perplexity: 5.165229320526123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [12:00:19<4:20:30, 279.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.52081897212
INFO:root:current train perplexity3.616833448410034
INFO:root:current mean train loss 3271.928911423841
INFO:root:current train perplexity3.6303322315216064
INFO:root:current mean train loss 3273.695681142617
INFO:root:current train perplexity3.6309401988983154
INFO:root:current mean train loss 3269.9282595207887
INFO:root:current train perplexity3.632174015045166
INFO:root:current mean train loss 3273.7934272580032
INFO:root:current train perplexity3.6342360973358154
INFO:root:current mean train loss 3274.8435164934494
INFO:root:current train perplexity3.6379737854003906
INFO:root:current mean train loss 3279.5284436953966
INFO:root:current train perplexity3.641679286956787
INFO:root:current mean train loss 3281.698738921022
INFO:root:current train perplexity3.644669532775879
INFO:root:current mean train loss 3280.7626981813673
INFO:root:current train perplexity3.6442441940307617
INFO:root:current mean train loss 3279.358961167521
INFO:root:current train perplexity3.644380569458008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.53s/it]
INFO:root:final mean train loss: 3278.600669184039
INFO:root:final train perplexity: 3.645533800125122
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4060.844811405696
INFO:root:eval perplexity: 5.1659369468688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [12:04:57<4:15:31, 278.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.7688650357522
INFO:root:current train perplexity3.6345763206481934
INFO:root:current mean train loss 3274.732334352889
INFO:root:current train perplexity3.630162477493286
INFO:root:current mean train loss 3269.5806531280164
INFO:root:current train perplexity3.6323060989379883
INFO:root:current mean train loss 3271.2824611823207
INFO:root:current train perplexity3.636111259460449
INFO:root:current mean train loss 3274.0689912683824
INFO:root:current train perplexity3.6373703479766846
INFO:root:current mean train loss 3275.184134877432
INFO:root:current train perplexity3.6387572288513184
INFO:root:current mean train loss 3280.03341318226
INFO:root:current train perplexity3.6412353515625
INFO:root:current mean train loss 3279.799391996562
INFO:root:current train perplexity3.643018960952759
INFO:root:current mean train loss 3280.5241346792236
INFO:root:current train perplexity3.643984079360962
INFO:root:current mean train loss 3279.564036634841
INFO:root:current train perplexity3.6437759399414062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.76s/it]
INFO:root:final mean train loss: 3277.8023848995085
INFO:root:final train perplexity: 3.644385814666748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4062.50335390348
INFO:root:eval perplexity: 5.169403076171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [12:09:35<4:10:40, 278.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.8914412313434
INFO:root:current train perplexity3.632467746734619
INFO:root:current mean train loss 3286.994596744012
INFO:root:current train perplexity3.6305816173553467
INFO:root:current mean train loss 3281.4271400251637
INFO:root:current train perplexity3.633671283721924
INFO:root:current mean train loss 3282.2287451304924
INFO:root:current train perplexity3.63114857673645
INFO:root:current mean train loss 3278.117848823106
INFO:root:current train perplexity3.6314263343811035
INFO:root:current mean train loss 3275.876285721175
INFO:root:current train perplexity3.6339290142059326
INFO:root:current mean train loss 3277.543136024761
INFO:root:current train perplexity3.6358776092529297
INFO:root:current mean train loss 3277.3784736722823
INFO:root:current train perplexity3.6357932090759277
INFO:root:current mean train loss 3278.48423166946
INFO:root:current train perplexity3.6394407749176025
INFO:root:current mean train loss 3278.921688927983
INFO:root:current train perplexity3.64094614982605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.52s/it]
INFO:root:final mean train loss: 3275.7139735068045
INFO:root:final train perplexity: 3.6413841247558594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4064.21225170379
INFO:root:eval perplexity: 5.172976016998291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [12:14:17<4:06:58, 279.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.7780013020833
INFO:root:current train perplexity3.6108086109161377
INFO:root:current mean train loss 3268.105845424107
INFO:root:current train perplexity3.6302907466888428
INFO:root:current mean train loss 3274.509032315341
INFO:root:current train perplexity3.6371655464172363
INFO:root:current mean train loss 3268.1938444010416
INFO:root:current train perplexity3.630476236343384
INFO:root:current mean train loss 3267.8177076480265
INFO:root:current train perplexity3.6278460025787354
INFO:root:current mean train loss 3269.2871161684784
INFO:root:current train perplexity3.6280617713928223
INFO:root:current mean train loss 3271.943252314815
INFO:root:current train perplexity3.629695177078247
INFO:root:current mean train loss 3272.9580730216735
INFO:root:current train perplexity3.6298129558563232
INFO:root:current mean train loss 3276.572943080357
INFO:root:current train perplexity3.634575366973877
INFO:root:current mean train loss 3274.9061415765223
INFO:root:current train perplexity3.6355035305023193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.38s/it]
INFO:root:final mean train loss: 3272.0691272981703
INFO:root:final train perplexity: 3.6361515522003174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 4063.013704773382
INFO:root:eval perplexity: 5.170468330383301
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [12:18:56<4:02:10, 279.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.4518778237953
INFO:root:current train perplexity3.635364532470703
INFO:root:current mean train loss 3268.7152920081967
INFO:root:current train perplexity3.6348042488098145
INFO:root:current mean train loss 3269.1010397112414
INFO:root:current train perplexity3.6304287910461426
INFO:root:current mean train loss 3272.7054478418736
INFO:root:current train perplexity3.6317243576049805
INFO:root:current mean train loss 3272.9671956885677
INFO:root:current train perplexity3.6308975219726562
INFO:root:current mean train loss 3270.7004201898853
INFO:root:current train perplexity3.6318697929382324
INFO:root:current mean train loss 3271.4008628208503
INFO:root:current train perplexity3.6321568489074707
INFO:root:current mean train loss 3271.0740170143877
INFO:root:current train perplexity3.631889581680298
INFO:root:current mean train loss 3271.425634710327
INFO:root:current train perplexity3.6325716972351074
INFO:root:current mean train loss 3272.967749594672
INFO:root:current train perplexity3.633683443069458


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.50s/it]
INFO:root:final mean train loss: 3270.849099928333
INFO:root:final train perplexity: 3.63440203666687
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 4063.9240532191934
INFO:root:eval perplexity: 5.172373294830322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [12:23:35<3:57:26, 279.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.1714725703982
INFO:root:current train perplexity3.6182034015655518
INFO:root:current mean train loss 3261.4011051517505
INFO:root:current train perplexity3.616687297821045
INFO:root:current mean train loss 3263.736869261437
INFO:root:current train perplexity3.621591806411743
INFO:root:current mean train loss 3264.7235391524137
INFO:root:current train perplexity3.6213021278381348
INFO:root:current mean train loss 3264.6480466761072
INFO:root:current train perplexity3.6223175525665283
INFO:root:current mean train loss 3264.5521581039816
INFO:root:current train perplexity3.62391996383667
INFO:root:current mean train loss 3267.227270896459
INFO:root:current train perplexity3.6251845359802246
INFO:root:current mean train loss 3267.2189135834783
INFO:root:current train perplexity3.6282854080200195
INFO:root:current mean train loss 3268.778177554626
INFO:root:current train perplexity3.628865957260132
INFO:root:current mean train loss 3270.6268393076753
INFO:root:current train perplexity3.6304666996002197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.65s/it]
INFO:root:final mean train loss: 3268.0926925905287
INFO:root:final train perplexity: 3.6304516792297363
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 4066.182866522606
INFO:root:eval perplexity: 5.177099704742432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [12:28:17<3:53:28, 280.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3263.631978969381
INFO:root:current train perplexity3.63810658454895
INFO:root:current mean train loss 3263.677497595399
INFO:root:current train perplexity3.6209630966186523
INFO:root:current mean train loss 3262.925643257473
INFO:root:current train perplexity3.619541645050049
INFO:root:current mean train loss 3260.8669366286813
INFO:root:current train perplexity3.617741107940674
INFO:root:current mean train loss 3263.260750994176
INFO:root:current train perplexity3.619502305984497
INFO:root:current mean train loss 3265.120742415745
INFO:root:current train perplexity3.624476432800293
INFO:root:current mean train loss 3263.3524800356536
INFO:root:current train perplexity3.6248152256011963
INFO:root:current mean train loss 3261.3512774146393
INFO:root:current train perplexity3.624035596847534
INFO:root:current mean train loss 3264.7930925855117
INFO:root:current train perplexity3.624401092529297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.27s/it]
INFO:root:final mean train loss: 3264.6407748191587
INFO:root:final train perplexity: 3.625511407852173
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.90s/it]
INFO:root:eval mean loss: 4067.024287663453
INFO:root:eval perplexity: 5.178861618041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [12:32:55<3:48:19, 279.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3246.985770089286
INFO:root:current train perplexity3.6086044311523438
INFO:root:current mean train loss 3263.5172176182828
INFO:root:current train perplexity3.6202023029327393
INFO:root:current mean train loss 3260.4840612733997
INFO:root:current train perplexity3.6206209659576416
INFO:root:current mean train loss 3257.9491773971904
INFO:root:current train perplexity3.622706651687622
INFO:root:current mean train loss 3258.51448227791
INFO:root:current train perplexity3.6218926906585693
INFO:root:current mean train loss 3260.6253144454204
INFO:root:current train perplexity3.6194276809692383
INFO:root:current mean train loss 3260.3651169300865
INFO:root:current train perplexity3.619899272918701
INFO:root:current mean train loss 3265.2163849092776
INFO:root:current train perplexity3.620589017868042
INFO:root:current mean train loss 3265.967650610866
INFO:root:current train perplexity3.621642589569092
INFO:root:current mean train loss 3268.5006217914483
INFO:root:current train perplexity3.623652935028076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.64s/it]
INFO:root:final mean train loss: 3262.9699168051443
INFO:root:final train perplexity: 3.623121738433838
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.01s/it]
INFO:root:eval mean loss: 4066.150018353834
INFO:root:eval perplexity: 5.177030563354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [12:37:38<3:44:22, 280.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.0111002604167
INFO:root:current train perplexity3.610424280166626
INFO:root:current mean train loss 3259.9046577785325
INFO:root:current train perplexity3.612861156463623
INFO:root:current mean train loss 3258.582404841933
INFO:root:current train perplexity3.6146957874298096
INFO:root:current mean train loss 3252.672498139881
INFO:root:current train perplexity3.611076831817627
INFO:root:current mean train loss 3258.014867869917
INFO:root:current train perplexity3.6129226684570312
INFO:root:current mean train loss 3261.216691159739
INFO:root:current train perplexity3.6173088550567627
INFO:root:current mean train loss 3262.5851344162857
INFO:root:current train perplexity3.615163803100586
INFO:root:current mean train loss 3265.4072033435314
INFO:root:current train perplexity3.6194889545440674
INFO:root:current mean train loss 3264.1711398820935
INFO:root:current train perplexity3.6209821701049805
INFO:root:current mean train loss 3264.378438247097
INFO:root:current train perplexity3.621885299682617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.97s/it]
INFO:root:final mean train loss: 3261.9454762858727
INFO:root:final train perplexity: 3.621657371520996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 4068.2179950687055
INFO:root:eval perplexity: 5.181363105773926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [12:42:16<3:39:11, 279.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.7450853430705
INFO:root:current train perplexity3.5741093158721924
INFO:root:current mean train loss 3250.4170715828254
INFO:root:current train perplexity3.6058192253112793
INFO:root:current mean train loss 3250.6718268287555
INFO:root:current train perplexity3.601435899734497
INFO:root:current mean train loss 3250.3958638194176
INFO:root:current train perplexity3.6002540588378906
INFO:root:current mean train loss 3251.5630650441417
INFO:root:current train perplexity3.6039161682128906
INFO:root:current mean train loss 3254.1573124551865
INFO:root:current train perplexity3.6053099632263184
INFO:root:current mean train loss 3254.1067023851324
INFO:root:current train perplexity3.608372688293457
INFO:root:current mean train loss 3257.8169060122755
INFO:root:current train perplexity3.612372398376465
INFO:root:current mean train loss 3260.059312526105
INFO:root:current train perplexity3.612581253051758
INFO:root:current mean train loss 3260.6157438168675
INFO:root:current train perplexity3.61460280418396


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:17<00:00, 257.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:17<00:00, 257.88s/it]
INFO:root:final mean train loss: 3258.0331392595845
INFO:root:final train perplexity: 3.6160714626312256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4070.675705064273
INFO:root:eval perplexity: 5.186513423919678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [12:46:54<3:33:57, 279.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.8413164692543
INFO:root:current train perplexity3.643937587738037
INFO:root:current mean train loss 3257.5212793714218
INFO:root:current train perplexity3.6198198795318604
INFO:root:current mean train loss 3251.628365124459
INFO:root:current train perplexity3.6045565605163574
INFO:root:current mean train loss 3254.2714297937123
INFO:root:current train perplexity3.6095058917999268
INFO:root:current mean train loss 3251.798385726327
INFO:root:current train perplexity3.6130974292755127
INFO:root:current mean train loss 3250.547538915372
INFO:root:current train perplexity3.61147403717041
INFO:root:current mean train loss 3255.119810754259
INFO:root:current train perplexity3.6154658794403076
INFO:root:current mean train loss 3257.7154993560835
INFO:root:current train perplexity3.6176655292510986
INFO:root:current mean train loss 3260.4808448029485
INFO:root:current train perplexity3.61537504196167
INFO:root:current mean train loss 3258.6937647900445
INFO:root:current train perplexity3.6144635677337646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.82s/it]
INFO:root:final mean train loss: 3256.9193897862588
INFO:root:final train perplexity: 3.61448335647583
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it]
INFO:root:eval mean loss: 4070.3383806377437
INFO:root:eval perplexity: 5.185807228088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [12:51:32<3:29:13, 278.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.1522373297275
INFO:root:current train perplexity3.61018705368042
INFO:root:current mean train loss 3253.3457294711106
INFO:root:current train perplexity3.5961711406707764
INFO:root:current mean train loss 3256.5984315752485
INFO:root:current train perplexity3.6038198471069336
INFO:root:current mean train loss 3253.619385485804
INFO:root:current train perplexity3.606783151626587
INFO:root:current mean train loss 3250.3849057695047
INFO:root:current train perplexity3.6101651191711426
INFO:root:current mean train loss 3252.1353911504234
INFO:root:current train perplexity3.6081972122192383
INFO:root:current mean train loss 3251.954481718872
INFO:root:current train perplexity3.60626220703125
INFO:root:current mean train loss 3254.2394474427015
INFO:root:current train perplexity3.606966018676758
INFO:root:current mean train loss 3254.355571178486
INFO:root:current train perplexity3.605158805847168
INFO:root:current mean train loss 3256.0422428281418
INFO:root:current train perplexity3.609539031982422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.25s/it]
INFO:root:final mean train loss: 3253.5701161661455
INFO:root:final train perplexity: 3.609710216522217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.36s/it]
INFO:root:eval mean loss: 4070.4652350675974
INFO:root:eval perplexity: 5.186073303222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [12:56:10<3:24:16, 278.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.416446766955
INFO:root:current train perplexity3.5657870769500732
INFO:root:current mean train loss 3258.996156861182
INFO:root:current train perplexity3.592970848083496
INFO:root:current mean train loss 3248.9295342943446
INFO:root:current train perplexity3.5934627056121826
INFO:root:current mean train loss 3251.1903283726583
INFO:root:current train perplexity3.5973103046417236
INFO:root:current mean train loss 3253.138849382166
INFO:root:current train perplexity3.6018247604370117
INFO:root:current mean train loss 3248.7376702289475
INFO:root:current train perplexity3.601152181625366
INFO:root:current mean train loss 3248.9845946133596
INFO:root:current train perplexity3.602846384048462
INFO:root:current mean train loss 3251.621183954568
INFO:root:current train perplexity3.604372262954712
INFO:root:current mean train loss 3254.644114452664
INFO:root:current train perplexity3.6061949729919434
INFO:root:current mean train loss 3255.873354951079
INFO:root:current train perplexity3.6081106662750244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.17s/it]
INFO:root:final mean train loss: 3253.1288799162835
INFO:root:final train perplexity: 3.6090824604034424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 4071.9623469359485
INFO:root:eval perplexity: 5.189212799072266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [13:00:52<3:20:18, 279.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.4120161576707
INFO:root:current train perplexity3.617032051086426
INFO:root:current mean train loss 3224.628843245968
INFO:root:current train perplexity3.5963258743286133
INFO:root:current mean train loss 3239.302965111826
INFO:root:current train perplexity3.6011908054351807
INFO:root:current mean train loss 3244.0096610915493
INFO:root:current train perplexity3.6037797927856445
INFO:root:current mean train loss 3245.337342247596
INFO:root:current train perplexity3.6032962799072266
INFO:root:current mean train loss 3248.424464210304
INFO:root:current train perplexity3.6024158000946045
INFO:root:current mean train loss 3252.496538048664
INFO:root:current train perplexity3.605837821960449
INFO:root:current mean train loss 3252.7138303238826
INFO:root:current train perplexity3.6055989265441895
INFO:root:current mean train loss 3254.6714338336074
INFO:root:current train perplexity3.6077263355255127
INFO:root:current mean train loss 3253.936800300638
INFO:root:current train perplexity3.606281042098999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.87s/it]
INFO:root:final mean train loss: 3251.2365926927137
INFO:root:final train perplexity: 3.606388568878174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4073.319595661569
INFO:root:eval perplexity: 5.192061424255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [13:05:30<3:15:23, 279.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.4498310391864
INFO:root:current train perplexity3.5992825031280518
INFO:root:current mean train loss 3255.4855118265914
INFO:root:current train perplexity3.590442657470703
INFO:root:current mean train loss 3251.1476076075332
INFO:root:current train perplexity3.590034008026123
INFO:root:current mean train loss 3242.7814342824554
INFO:root:current train perplexity3.591475486755371
INFO:root:current mean train loss 3246.521569270552
INFO:root:current train perplexity3.5990242958068848
INFO:root:current mean train loss 3248.4187310931948
INFO:root:current train perplexity3.599299669265747
INFO:root:current mean train loss 3246.822117962269
INFO:root:current train perplexity3.6016130447387695
INFO:root:current mean train loss 3251.0421476951587
INFO:root:current train perplexity3.6016628742218018
INFO:root:current mean train loss 3249.256570862453
INFO:root:current train perplexity3.600620746612549
INFO:root:current mean train loss 3249.1534285659236
INFO:root:current train perplexity3.5996639728546143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.45s/it]
INFO:root:final mean train loss: 3246.682342098605
INFO:root:final train perplexity: 3.59991455078125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 4073.7877604166665
INFO:root:eval perplexity: 5.193045139312744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [13:10:12<3:11:22, 280.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.4145370268484
INFO:root:current train perplexity3.6063029766082764
INFO:root:current mean train loss 3237.4148091991046
INFO:root:current train perplexity3.583643674850464
INFO:root:current mean train loss 3239.619298280385
INFO:root:current train perplexity3.5859627723693848
INFO:root:current mean train loss 3236.1863918253034
INFO:root:current train perplexity3.5910089015960693
INFO:root:current mean train loss 3242.341330882597
INFO:root:current train perplexity3.595047950744629
INFO:root:current mean train loss 3242.6018318670644
INFO:root:current train perplexity3.597083330154419
INFO:root:current mean train loss 3244.1588656884546
INFO:root:current train perplexity3.594245433807373
INFO:root:current mean train loss 3245.9285237946865
INFO:root:current train perplexity3.594964027404785
INFO:root:current mean train loss 3247.6558404828324
INFO:root:current train perplexity3.5990989208221436
INFO:root:current mean train loss 3247.729929428022
INFO:root:current train perplexity3.598808526992798


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.19s/it]
INFO:root:final mean train loss: 3245.9337945753527
INFO:root:final train perplexity: 3.598851442337036
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.37s/it]
INFO:root:eval mean loss: 4074.2987571337544
INFO:root:eval perplexity: 5.194118022918701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [13:14:50<3:06:11, 279.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.4248448625394
INFO:root:current train perplexity3.577186346054077
INFO:root:current mean train loss 3235.1410750916552
INFO:root:current train perplexity3.5921924114227295
INFO:root:current mean train loss 3241.4926346536176
INFO:root:current train perplexity3.5950183868408203
INFO:root:current mean train loss 3246.9228251515087
INFO:root:current train perplexity3.5931127071380615
INFO:root:current mean train loss 3245.7333066936326
INFO:root:current train perplexity3.593071222305298
INFO:root:current mean train loss 3247.6758090795015
INFO:root:current train perplexity3.593824625015259
INFO:root:current mean train loss 3243.2059532918356
INFO:root:current train perplexity3.5937461853027344
INFO:root:current mean train loss 3245.0661918826218
INFO:root:current train perplexity3.595095634460449
INFO:root:current mean train loss 3243.8263687984395
INFO:root:current train perplexity3.5957915782928467
INFO:root:current mean train loss 3245.744259079338
INFO:root:current train perplexity3.59615421295166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.04s/it]
INFO:root:final mean train loss: 3243.868263552266
INFO:root:final train perplexity: 3.5959203243255615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4074.9090342420213
INFO:root:eval perplexity: 5.195401191711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [13:19:32<3:02:11, 280.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.4541212059985
INFO:root:current train perplexity3.568881034851074
INFO:root:current mean train loss 3233.1730904808655
INFO:root:current train perplexity3.5743372440338135
INFO:root:current mean train loss 3239.215506417411
INFO:root:current train perplexity3.578026056289673
INFO:root:current mean train loss 3244.70964172521
INFO:root:current train perplexity3.5869436264038086
INFO:root:current mean train loss 3242.512293758823
INFO:root:current train perplexity3.5877108573913574
INFO:root:current mean train loss 3243.985982085818
INFO:root:current train perplexity3.587733030319214
INFO:root:current mean train loss 3242.74263491346
INFO:root:current train perplexity3.587984085083008
INFO:root:current mean train loss 3243.4804678193495
INFO:root:current train perplexity3.5896642208099365
INFO:root:current mean train loss 3243.9204643791395
INFO:root:current train perplexity3.5919384956359863
INFO:root:current mean train loss 3246.2195281827826
INFO:root:current train perplexity3.595768928527832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.56s/it]
INFO:root:final mean train loss: 3243.394687160369
INFO:root:final train perplexity: 3.5952486991882324
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 4075.7290333416445
INFO:root:eval perplexity: 5.1971235275268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [13:24:11<2:57:15, 279.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.7527163856907
INFO:root:current train perplexity3.593472480773926
INFO:root:current mean train loss 3248.4045998597758
INFO:root:current train perplexity3.6012065410614014
INFO:root:current mean train loss 3243.666531216896
INFO:root:current train perplexity3.590101480484009
INFO:root:current mean train loss 3246.8182450306567
INFO:root:current train perplexity3.587387800216675
INFO:root:current mean train loss 3249.1060576467803
INFO:root:current train perplexity3.591513156890869
INFO:root:current mean train loss 3248.2020241104256
INFO:root:current train perplexity3.5911483764648438
INFO:root:current mean train loss 3247.507462623651
INFO:root:current train perplexity3.5903515815734863
INFO:root:current mean train loss 3245.1655853847287
INFO:root:current train perplexity3.5912299156188965
INFO:root:current mean train loss 3245.362080732804
INFO:root:current train perplexity3.592400550842285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.09s/it]
INFO:root:final mean train loss: 3241.7567835161763
INFO:root:final train perplexity: 3.592926025390625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]
INFO:root:eval mean loss: 4076.3358820921985
INFO:root:eval perplexity: 5.198398590087891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [13:28:49<2:52:18, 279.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.1048177083335
INFO:root:current train perplexity3.5732319355010986
INFO:root:current mean train loss 3211.7033857327065
INFO:root:current train perplexity3.5833215713500977
INFO:root:current mean train loss 3236.3379062596214
INFO:root:current train perplexity3.596729278564453
INFO:root:current mean train loss 3234.887344813583
INFO:root:current train perplexity3.5938494205474854
INFO:root:current mean train loss 3234.2073650502093
INFO:root:current train perplexity3.59494948387146
INFO:root:current mean train loss 3236.2074054695267
INFO:root:current train perplexity3.5936691761016846
INFO:root:current mean train loss 3238.155451178353
INFO:root:current train perplexity3.5905535221099854
INFO:root:current mean train loss 3237.4593955592104
INFO:root:current train perplexity3.587378978729248
INFO:root:current mean train loss 3238.495634656172
INFO:root:current train perplexity3.589015007019043
INFO:root:current mean train loss 3242.606122224962
INFO:root:current train perplexity3.590545415878296


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.48s/it]
INFO:root:final mean train loss: 3240.4608792335757
INFO:root:final train perplexity: 3.5910894870758057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it]
INFO:root:eval mean loss: 4077.7561745068706
INFO:root:eval perplexity: 5.201383590698242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [13:33:32<2:48:09, 280.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.4289994673295
INFO:root:current train perplexity3.577615261077881
INFO:root:current mean train loss 3237.262325802365
INFO:root:current train perplexity3.568880558013916
INFO:root:current mean train loss 3240.622304039544
INFO:root:current train perplexity3.5771219730377197
INFO:root:current mean train loss 3241.022584970358
INFO:root:current train perplexity3.5852694511413574
INFO:root:current mean train loss 3244.621366997415
INFO:root:current train perplexity3.5900254249572754
INFO:root:current mean train loss 3241.3645674076565
INFO:root:current train perplexity3.5904581546783447
INFO:root:current mean train loss 3238.347624683536
INFO:root:current train perplexity3.586559295654297
INFO:root:current mean train loss 3237.3455280030325
INFO:root:current train perplexity3.5856192111968994
INFO:root:current mean train loss 3238.6201617409065
INFO:root:current train perplexity3.5853431224823
INFO:root:current mean train loss 3238.961577196676
INFO:root:current train perplexity3.5855965614318848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.33s/it]
INFO:root:final mean train loss: 3235.8625685784123
INFO:root:final train perplexity: 3.584580183029175
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.34s/it]
INFO:root:eval mean loss: 4076.39306640625
INFO:root:eval perplexity: 5.198518753051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [13:38:09<2:43:01, 279.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.1312962582238
INFO:root:current train perplexity3.599821090698242
INFO:root:current mean train loss 3238.727787306329
INFO:root:current train perplexity3.586167097091675
INFO:root:current mean train loss 3243.633741126213
INFO:root:current train perplexity3.594529867172241
INFO:root:current mean train loss 3242.1069902282525
INFO:root:current train perplexity3.5880162715911865
INFO:root:current mean train loss 3238.177186660949
INFO:root:current train perplexity3.586341142654419
INFO:root:current mean train loss 3235.73055107102
INFO:root:current train perplexity3.585214376449585
INFO:root:current mean train loss 3237.967152239625
INFO:root:current train perplexity3.5854053497314453
INFO:root:current mean train loss 3240.4144808327537
INFO:root:current train perplexity3.585744857788086
INFO:root:current mean train loss 3240.26322979863
INFO:root:current train perplexity3.5869431495666504
INFO:root:current mean train loss 3238.135492468036
INFO:root:current train perplexity3.5835132598876953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.80s/it]
INFO:root:final mean train loss: 3234.9058550557784
INFO:root:final train perplexity: 3.58322811126709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it]
INFO:root:eval mean loss: 4078.16587883699
INFO:root:eval perplexity: 5.202246189117432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [13:42:47<2:38:07, 279.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.533953631366
INFO:root:current train perplexity3.5788400173187256
INFO:root:current mean train loss 3228.020156019316
INFO:root:current train perplexity3.565694570541382
INFO:root:current mean train loss 3234.7023646148814
INFO:root:current train perplexity3.5771324634552
INFO:root:current mean train loss 3230.208956003918
INFO:root:current train perplexity3.5745577812194824
INFO:root:current mean train loss 3233.3764048091703
INFO:root:current train perplexity3.5746750831604004
INFO:root:current mean train loss 3236.3790674662
INFO:root:current train perplexity3.574333429336548
INFO:root:current mean train loss 3236.9868635211074
INFO:root:current train perplexity3.577173948287964
INFO:root:current mean train loss 3238.2726631007135
INFO:root:current train perplexity3.5793745517730713
INFO:root:current mean train loss 3235.68156446021
INFO:root:current train perplexity3.580221176147461
INFO:root:current mean train loss 3236.303051994842
INFO:root:current train perplexity3.5814592838287354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:18<00:00, 258.14s/it]
INFO:root:final mean train loss: 3233.7153357228926
INFO:root:final train perplexity: 3.581544876098633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.28s/it]
INFO:root:eval mean loss: 4078.4925112893397
INFO:root:eval perplexity: 5.2029337882995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [13:47:25<2:33:12, 278.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.7564662388395
INFO:root:current train perplexity3.585092544555664
INFO:root:current mean train loss 3235.726361762153
INFO:root:current train perplexity3.580824851989746
INFO:root:current mean train loss 3223.9084701213433
INFO:root:current train perplexity3.5720412731170654
INFO:root:current mean train loss 3230.523575967817
INFO:root:current train perplexity3.5738675594329834
INFO:root:current mean train loss 3233.167886247306
INFO:root:current train perplexity3.576489210128784
INFO:root:current mean train loss 3236.607299120181
INFO:root:current train perplexity3.577575206756592
INFO:root:current mean train loss 3236.2691498523623
INFO:root:current train perplexity3.5799899101257324
INFO:root:current mean train loss 3236.8666165098853
INFO:root:current train perplexity3.578533172607422
INFO:root:current mean train loss 3236.171647817646
INFO:root:current train perplexity3.577814817428589
INFO:root:current mean train loss 3235.4179439442682
INFO:root:current train perplexity3.5791492462158203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.10s/it]
INFO:root:final mean train loss: 3232.66720808706
INFO:root:final train perplexity: 3.580064535140991
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it]
INFO:root:eval mean loss: 4078.4504152122117
INFO:root:eval perplexity: 5.202845096588135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [13:52:03<2:28:33, 278.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.5734238735463
INFO:root:current train perplexity3.5619966983795166
INFO:root:current mean train loss 3252.2823324136803
INFO:root:current train perplexity3.5895485877990723
INFO:root:current mean train loss 3233.326073414995
INFO:root:current train perplexity3.5800416469573975
INFO:root:current mean train loss 3228.485934510523
INFO:root:current train perplexity3.573908567428589
INFO:root:current mean train loss 3229.496808536435
INFO:root:current train perplexity3.5744662284851074
INFO:root:current mean train loss 3227.9797381265826
INFO:root:current train perplexity3.570753812789917
INFO:root:current mean train loss 3232.860987163443
INFO:root:current train perplexity3.5722715854644775
INFO:root:current mean train loss 3234.3206295870837
INFO:root:current train perplexity3.57688570022583
INFO:root:current mean train loss 3235.512709792964
INFO:root:current train perplexity3.5777347087860107
INFO:root:current mean train loss 3233.678540841646
INFO:root:current train perplexity3.5771398544311523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:19<00:00, 259.56s/it]
INFO:root:final mean train loss: 3230.345568010884
INFO:root:final train perplexity: 3.576786756515503
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.92s/it]
INFO:root:eval mean loss: 4078.6371602809177
INFO:root:eval perplexity: 5.203237533569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [13:56:43<2:24:02, 278.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.802011527267
INFO:root:current train perplexity3.565671443939209
INFO:root:current mean train loss 3223.1151632346855
INFO:root:current train perplexity3.559835195541382
INFO:root:current mean train loss 3227.2942429500745
INFO:root:current train perplexity3.573261022567749
INFO:root:current mean train loss 3226.930231425837
INFO:root:current train perplexity3.5717687606811523
INFO:root:current mean train loss 3220.709427725714
INFO:root:current train perplexity3.565812349319458
INFO:root:current mean train loss 3220.8181546690676
INFO:root:current train perplexity3.566620349884033
INFO:root:current mean train loss 3225.6485496321766
INFO:root:current train perplexity3.570065498352051
INFO:root:current mean train loss 3228.3665044914073
INFO:root:current train perplexity3.572862386703491
INFO:root:current mean train loss 3229.4871276783747
INFO:root:current train perplexity3.571805715560913
INFO:root:current mean train loss 3230.629258469703
INFO:root:current train perplexity3.5735156536102295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.01s/it]
INFO:root:final mean train loss: 3228.8786057502994
INFO:root:final train perplexity: 3.574716806411743
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it]
INFO:root:eval mean loss: 4081.6225395473184
INFO:root:eval perplexity: 5.2095232009887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [14:01:24<2:19:48, 279.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.8517404329978
INFO:root:current train perplexity3.5709874629974365
INFO:root:current mean train loss 3212.581642774666
INFO:root:current train perplexity3.553497791290283
INFO:root:current mean train loss 3210.281506394788
INFO:root:current train perplexity3.5590662956237793
INFO:root:current mean train loss 3220.637331481764
INFO:root:current train perplexity3.569875717163086
INFO:root:current mean train loss 3220.7123959609885
INFO:root:current train perplexity3.568676710128784
INFO:root:current mean train loss 3223.226747680009
INFO:root:current train perplexity3.5716636180877686
INFO:root:current mean train loss 3226.6829313472117
INFO:root:current train perplexity3.573148250579834
INFO:root:current mean train loss 3228.5749987776885
INFO:root:current train perplexity3.5734195709228516
INFO:root:current mean train loss 3228.8238919028304
INFO:root:current train perplexity3.5732333660125732
INFO:root:current mean train loss 3228.671312636454
INFO:root:current train perplexity3.572174549102783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.00s/it]
INFO:root:final mean train loss: 3227.081536200739
INFO:root:final train perplexity: 3.572183132171631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.33s/it]
INFO:root:eval mean loss: 4080.523044450909
INFO:root:eval perplexity: 5.207207679748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [14:06:10<2:15:58, 281.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.269789966185
INFO:root:current train perplexity3.5653204917907715
INFO:root:current mean train loss 3243.460405361153
INFO:root:current train perplexity3.578956365585327
INFO:root:current mean train loss 3233.658029391971
INFO:root:current train perplexity3.580522060394287
INFO:root:current mean train loss 3232.5573490984757
INFO:root:current train perplexity3.5801212787628174
INFO:root:current mean train loss 3224.1304479431546
INFO:root:current train perplexity3.573798179626465
INFO:root:current mean train loss 3222.237507061563
INFO:root:current train perplexity3.5692601203918457
INFO:root:current mean train loss 3222.294640399527
INFO:root:current train perplexity3.5691535472869873
INFO:root:current mean train loss 3224.8344207723885
INFO:root:current train perplexity3.5698957443237305
INFO:root:current mean train loss 3227.605890293847
INFO:root:current train perplexity3.57023024559021
INFO:root:current mean train loss 3228.0116182660613
INFO:root:current train perplexity3.570552110671997


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.87s/it]
INFO:root:final mean train loss: 3225.8157287105437
INFO:root:final train perplexity: 3.5703999996185303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it]
INFO:root:eval mean loss: 4081.8068137743794
INFO:root:eval perplexity: 5.209910869598389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [14:10:57<2:12:11, 283.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.083430989583
INFO:root:current train perplexity3.5721914768218994
INFO:root:current mean train loss 3216.4044852120537
INFO:root:current train perplexity3.562142848968506
INFO:root:current mean train loss 3226.9050115411933
INFO:root:current train perplexity3.5667569637298584
INFO:root:current mean train loss 3222.2934088541665
INFO:root:current train perplexity3.5626437664031982
INFO:root:current mean train loss 3223.2435654810856
INFO:root:current train perplexity3.564070224761963
INFO:root:current mean train loss 3224.702875339674
INFO:root:current train perplexity3.5642647743225098
INFO:root:current mean train loss 3222.795679615162
INFO:root:current train perplexity3.5650837421417236
INFO:root:current mean train loss 3224.809197643649
INFO:root:current train perplexity3.566483497619629
INFO:root:current mean train loss 3226.9353295200895
INFO:root:current train perplexity3.567328453063965
INFO:root:current mean train loss 3226.3882361778847
INFO:root:current train perplexity3.5669758319854736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.59s/it]
INFO:root:final mean train loss: 3223.458021286995
INFO:root:final train perplexity: 3.567080497741699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 4083.00677187223
INFO:root:eval perplexity: 5.212438583374023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [14:15:41<2:07:27, 283.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.7990899143447
INFO:root:current train perplexity3.583428382873535
INFO:root:current mean train loss 3227.1460227757857
INFO:root:current train perplexity3.5634610652923584
INFO:root:current mean train loss 3224.9030847987524
INFO:root:current train perplexity3.5659985542297363
INFO:root:current mean train loss 3225.881868447087
INFO:root:current train perplexity3.5619025230407715
INFO:root:current mean train loss 3233.0640098303247
INFO:root:current train perplexity3.5665485858917236
INFO:root:current mean train loss 3226.3787994646495
INFO:root:current train perplexity3.564141273498535
INFO:root:current mean train loss 3224.5199487554905
INFO:root:current train perplexity3.5630910396575928
INFO:root:current mean train loss 3225.5595391323436
INFO:root:current train perplexity3.5643858909606934
INFO:root:current mean train loss 3227.302989022243
INFO:root:current train perplexity3.5666913986206055
INFO:root:current mean train loss 3224.866985084324
INFO:root:current train perplexity3.5654382705688477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.25s/it]
INFO:root:final mean train loss: 3222.391960820844
INFO:root:final train perplexity: 3.565580129623413
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.09s/it]
INFO:root:eval mean loss: 4084.538314494681
INFO:root:eval perplexity: 5.215669631958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [14:20:24<2:02:44, 283.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3197.3322002704326
INFO:root:current train perplexity3.544217586517334
INFO:root:current mean train loss 3200.6832933675555
INFO:root:current train perplexity3.5417966842651367
INFO:root:current mean train loss 3211.4049848314003
INFO:root:current train perplexity3.55046010017395
INFO:root:current mean train loss 3218.583037159327
INFO:root:current train perplexity3.55705189704895
INFO:root:current mean train loss 3214.940445101674
INFO:root:current train perplexity3.5523414611816406
INFO:root:current mean train loss 3217.004207398081
INFO:root:current train perplexity3.553323268890381
INFO:root:current mean train loss 3218.8973973408106
INFO:root:current train perplexity3.5553083419799805
INFO:root:current mean train loss 3219.561081762109
INFO:root:current train perplexity3.5567500591278076
INFO:root:current mean train loss 3223.1331073320007
INFO:root:current train perplexity3.5613784790039062
INFO:root:current mean train loss 3223.65689841385
INFO:root:current train perplexity3.563828945159912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.21s/it]
INFO:root:final mean train loss: 3221.1313529476042
INFO:root:final train perplexity: 3.563807725906372
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it]
INFO:root:eval mean loss: 4084.735031236148
INFO:root:eval perplexity: 5.216084957122803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [14:25:07<1:57:57, 283.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.383414220328
INFO:root:current train perplexity3.566053628921509
INFO:root:current mean train loss 3217.236509696922
INFO:root:current train perplexity3.556948184967041
INFO:root:current mean train loss 3217.2452780426943
INFO:root:current train perplexity3.556518077850342
INFO:root:current mean train loss 3219.5589706688597
INFO:root:current train perplexity3.559075117111206
INFO:root:current mean train loss 3219.6037695508203
INFO:root:current train perplexity3.5588247776031494
INFO:root:current mean train loss 3221.4370072353663
INFO:root:current train perplexity3.562851905822754
INFO:root:current mean train loss 3221.9698397263946
INFO:root:current train perplexity3.5606865882873535
INFO:root:current mean train loss 3220.5575557703964
INFO:root:current train perplexity3.5600686073303223
INFO:root:current mean train loss 3220.735519663776
INFO:root:current train perplexity3.5605478286743164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.51s/it]
INFO:root:final mean train loss: 3220.390984073762
INFO:root:final train perplexity: 3.5627660751342773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4083.182146221188
INFO:root:eval perplexity: 5.212809085845947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [14:29:49<1:53:07, 282.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3194.5676618303573
INFO:root:current train perplexity3.4581940174102783
INFO:root:current mean train loss 3231.5694021064546
INFO:root:current train perplexity3.555814027786255
INFO:root:current mean train loss 3222.808830814085
INFO:root:current train perplexity3.5508804321289062
INFO:root:current mean train loss 3217.945535168974
INFO:root:current train perplexity3.550389051437378
INFO:root:current mean train loss 3218.1272776460764
INFO:root:current train perplexity3.5473780632019043
INFO:root:current mean train loss 3216.6884110731016
INFO:root:current train perplexity3.5496695041656494
INFO:root:current mean train loss 3216.0271072513387
INFO:root:current train perplexity3.5521657466888428
INFO:root:current mean train loss 3218.3059524039736
INFO:root:current train perplexity3.5572376251220703
INFO:root:current mean train loss 3219.929622758868
INFO:root:current train perplexity3.559170961380005
INFO:root:current mean train loss 3222.7734342699146
INFO:root:current train perplexity3.56317400932312


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.77s/it]
INFO:root:final mean train loss: 3219.9515513143233
INFO:root:final train perplexity: 3.5621490478515625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 4085.683465619459
INFO:root:eval perplexity: 5.218084812164307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [14:34:31<1:48:22, 282.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.961881510417
INFO:root:current train perplexity3.528212308883667
INFO:root:current mean train loss 3208.0663828974184
INFO:root:current train perplexity3.527846336364746
INFO:root:current mean train loss 3212.748155886628
INFO:root:current train perplexity3.5537567138671875
INFO:root:current mean train loss 3209.965025886657
INFO:root:current train perplexity3.553976535797119
INFO:root:current mean train loss 3214.203312076431
INFO:root:current train perplexity3.552959442138672
INFO:root:current mean train loss 3213.3498378716627
INFO:root:current train perplexity3.5506534576416016
INFO:root:current mean train loss 3217.4660426194105
INFO:root:current train perplexity3.5534889698028564
INFO:root:current mean train loss 3219.479975688374
INFO:root:current train perplexity3.5553269386291504
INFO:root:current mean train loss 3219.3933635688268
INFO:root:current train perplexity3.555180788040161
INFO:root:current mean train loss 3218.5865800034153
INFO:root:current train perplexity3.557116746902466


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.41s/it]
INFO:root:final mean train loss: 3216.900143531061
INFO:root:final train perplexity: 3.557863235473633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4086.225729651485
INFO:root:eval perplexity: 5.219229221343994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [14:39:13<1:43:34, 282.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3245.5854704483695
INFO:root:current train perplexity3.5684380531311035
INFO:root:current mean train loss 3232.8964466622206
INFO:root:current train perplexity3.553337574005127
INFO:root:current mean train loss 3224.3830938638594
INFO:root:current train perplexity3.545753240585327
INFO:root:current mean train loss 3224.9778678586977
INFO:root:current train perplexity3.5493712425231934
INFO:root:current mean train loss 3227.6691831043145
INFO:root:current train perplexity3.5535964965820312
INFO:root:current mean train loss 3222.6543724979088
INFO:root:current train perplexity3.554595470428467
INFO:root:current mean train loss 3221.444248940359
INFO:root:current train perplexity3.5542585849761963
INFO:root:current mean train loss 3218.284053058545
INFO:root:current train perplexity3.5549323558807373
INFO:root:current mean train loss 3216.376500441411
INFO:root:current train perplexity3.553006410598755
INFO:root:current mean train loss 3217.302212236762
INFO:root:current train perplexity3.5565805435180664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.40s/it]
INFO:root:final mean train loss: 3216.0911376707018
INFO:root:final train perplexity: 3.5567283630371094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.30s/it]
INFO:root:eval mean loss: 4085.959721991356
INFO:root:eval perplexity: 5.2186665534973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [14:44:01<1:39:25, 284.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.0019925025204
INFO:root:current train perplexity3.5367367267608643
INFO:root:current mean train loss 3209.599186322161
INFO:root:current train perplexity3.551037073135376
INFO:root:current mean train loss 3208.6469166413012
INFO:root:current train perplexity3.5579960346221924
INFO:root:current mean train loss 3210.765550503918
INFO:root:current train perplexity3.559483766555786
INFO:root:current mean train loss 3212.285123395809
INFO:root:current train perplexity3.5566961765289307
INFO:root:current mean train loss 3213.5817337754534
INFO:root:current train perplexity3.5530941486358643
INFO:root:current mean train loss 3215.68472314221
INFO:root:current train perplexity3.5562074184417725
INFO:root:current mean train loss 3217.640230233627
INFO:root:current train perplexity3.5574123859405518
INFO:root:current mean train loss 3218.147883409484
INFO:root:current train perplexity3.556107759475708
INFO:root:current mean train loss 3216.224901766833
INFO:root:current train perplexity3.553954601287842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.38s/it]
INFO:root:final mean train loss: 3215.40951630377
INFO:root:final train perplexity: 3.555771589279175
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 4086.593801944814
INFO:root:eval perplexity: 5.220006465911865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [14:48:46<1:34:47, 284.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.654572315705
INFO:root:current train perplexity3.582632541656494
INFO:root:current mean train loss 3212.537195438961
INFO:root:current train perplexity3.55818510055542
INFO:root:current mean train loss 3207.78429920404
INFO:root:current train perplexity3.5505130290985107
INFO:root:current mean train loss 3212.4623029590707
INFO:root:current train perplexity3.5483508110046387
INFO:root:current mean train loss 3211.8274470787655
INFO:root:current train perplexity3.5501210689544678
INFO:root:current mean train loss 3211.412243901467
INFO:root:current train perplexity3.548651933670044
INFO:root:current mean train loss 3210.6836101788685
INFO:root:current train perplexity3.5475306510925293
INFO:root:current mean train loss 3213.029659286726
INFO:root:current train perplexity3.5488715171813965
INFO:root:current mean train loss 3215.272659101702
INFO:root:current train perplexity3.5525012016296387
INFO:root:current mean train loss 3215.494364745574
INFO:root:current train perplexity3.5518245697021484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.17s/it]
INFO:root:final mean train loss: 3213.3680557743196
INFO:root:final train perplexity: 3.5529086589813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 4087.1164516151375
INFO:root:eval perplexity: 5.221109867095947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [14:53:27<1:29:41, 283.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.847915974069
INFO:root:current train perplexity3.535299301147461
INFO:root:current mean train loss 3211.604752936331
INFO:root:current train perplexity3.553995132446289
INFO:root:current mean train loss 3214.8087301524542
INFO:root:current train perplexity3.5513546466827393
INFO:root:current mean train loss 3222.2391100616896
INFO:root:current train perplexity3.557666778564453
INFO:root:current mean train loss 3218.148339734515
INFO:root:current train perplexity3.5531198978424072
INFO:root:current mean train loss 3216.3023572290617
INFO:root:current train perplexity3.553924322128296
INFO:root:current mean train loss 3219.3112445813613
INFO:root:current train perplexity3.5551629066467285
INFO:root:current mean train loss 3217.0550195573965
INFO:root:current train perplexity3.5539824962615967
INFO:root:current mean train loss 3216.915272249945
INFO:root:current train perplexity3.553863048553467
INFO:root:current mean train loss 3216.431703529237
INFO:root:current train perplexity3.553429126739502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.13s/it]
INFO:root:final mean train loss: 3213.1126181694767
INFO:root:final train perplexity: 3.552550792694092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it]
INFO:root:eval mean loss: 4087.85434154754
INFO:root:eval perplexity: 5.222667217254639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [14:58:09<1:24:51, 282.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.5125266335226
INFO:root:current train perplexity3.579047441482544
INFO:root:current mean train loss 3205.9941232988913
INFO:root:current train perplexity3.5620641708374023
INFO:root:current mean train loss 3204.088614430147
INFO:root:current train perplexity3.5464444160461426
INFO:root:current mean train loss 3210.652028774208
INFO:root:current train perplexity3.5484659671783447
INFO:root:current mean train loss 3212.8646189259957
INFO:root:current train perplexity3.546977996826172
INFO:root:current mean train loss 3211.445895798142
INFO:root:current train perplexity3.5508193969726562
INFO:root:current mean train loss 3212.777119364265
INFO:root:current train perplexity3.5491325855255127
INFO:root:current mean train loss 3214.2632460032078
INFO:root:current train perplexity3.5522987842559814
INFO:root:current mean train loss 3215.862543117233
INFO:root:current train perplexity3.552640438079834
INFO:root:current mean train loss 3216.2157252126963
INFO:root:current train perplexity3.5522944927215576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.35s/it]
INFO:root:final mean train loss: 3212.778890794323
INFO:root:final train perplexity: 3.5520832538604736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 4087.2678568955007
INFO:root:eval perplexity: 5.221428871154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [15:02:54<1:20:20, 283.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.9167519221232
INFO:root:current train perplexity3.5560178756713867
INFO:root:current mean train loss 3220.0451735046013
INFO:root:current train perplexity3.550630807876587
INFO:root:current mean train loss 3213.2231584556203
INFO:root:current train perplexity3.5499441623687744
INFO:root:current mean train loss 3212.911294900353
INFO:root:current train perplexity3.55147385597229
INFO:root:current mean train loss 3212.4734255829844
INFO:root:current train perplexity3.5503954887390137
INFO:root:current mean train loss 3211.4406087817774
INFO:root:current train perplexity3.5500259399414062
INFO:root:current mean train loss 3213.9517978766025
INFO:root:current train perplexity3.551029920578003
INFO:root:current mean train loss 3215.451252508601
INFO:root:current train perplexity3.5501296520233154
INFO:root:current mean train loss 3212.4996554307286
INFO:root:current train perplexity3.549053192138672
INFO:root:current mean train loss 3212.651651130906
INFO:root:current train perplexity3.5499489307403564


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.69s/it]
INFO:root:final mean train loss: 3211.357697333059
INFO:root:final train perplexity: 3.5500919818878174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.33s/it]
INFO:root:eval mean loss: 4088.0490791916
INFO:root:eval perplexity: 5.223079204559326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [15:07:36<1:15:29, 283.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.69228309309
INFO:root:current train perplexity3.5441651344299316
INFO:root:current mean train loss 3219.5049784699377
INFO:root:current train perplexity3.5448527336120605
INFO:root:current mean train loss 3215.4765354733627
INFO:root:current train perplexity3.5418903827667236
INFO:root:current mean train loss 3212.265334137045
INFO:root:current train perplexity3.540921211242676
INFO:root:current mean train loss 3211.0692395252786
INFO:root:current train perplexity3.5404555797576904
INFO:root:current mean train loss 3210.9352929003394
INFO:root:current train perplexity3.5413990020751953
INFO:root:current mean train loss 3210.9279035633617
INFO:root:current train perplexity3.5436501502990723
INFO:root:current mean train loss 3209.628739373075
INFO:root:current train perplexity3.5443105697631836
INFO:root:current mean train loss 3213.2816953954684
INFO:root:current train perplexity3.545850992202759
INFO:root:current mean train loss 3212.5882343327594
INFO:root:current train perplexity3.547471523284912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.32s/it]
INFO:root:final mean train loss: 3209.238017420615
INFO:root:final train perplexity: 3.5471243858337402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4088.7512657219636
INFO:root:eval perplexity: 5.224562168121338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [15:12:21<1:10:54, 283.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.7106500939476
INFO:root:current train perplexity3.536592960357666
INFO:root:current mean train loss 3198.7814218531776
INFO:root:current train perplexity3.5433592796325684
INFO:root:current mean train loss 3202.283147121416
INFO:root:current train perplexity3.5513694286346436
INFO:root:current mean train loss 3205.789526946941
INFO:root:current train perplexity3.546581983566284
INFO:root:current mean train loss 3208.49029502789
INFO:root:current train perplexity3.5468478202819824
INFO:root:current mean train loss 3211.1475005734565
INFO:root:current train perplexity3.5464890003204346
INFO:root:current mean train loss 3213.219931870743
INFO:root:current train perplexity3.5488696098327637
INFO:root:current mean train loss 3213.467160735418
INFO:root:current train perplexity3.550025463104248
INFO:root:current mean train loss 3214.9002853584507
INFO:root:current train perplexity3.5504310131073
INFO:root:current mean train loss 3213.753575575364
INFO:root:current train perplexity3.549332857131958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.26s/it]
INFO:root:final mean train loss: 3210.751144962926
INFO:root:final train perplexity: 3.5492429733276367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it]
INFO:root:eval mean loss: 4089.5640531499334
INFO:root:eval perplexity: 5.226278781890869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [15:17:02<1:06:03, 283.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.055487271013
INFO:root:current train perplexity3.558100700378418
INFO:root:current mean train loss 3210.261328386113
INFO:root:current train perplexity3.551746129989624
INFO:root:current mean train loss 3214.523698653909
INFO:root:current train perplexity3.5470991134643555
INFO:root:current mean train loss 3214.655158622012
INFO:root:current train perplexity3.5449795722961426
INFO:root:current mean train loss 3215.066767698441
INFO:root:current train perplexity3.5442235469818115
INFO:root:current mean train loss 3213.1613270436274
INFO:root:current train perplexity3.545386791229248
INFO:root:current mean train loss 3214.3820154004047
INFO:root:current train perplexity3.5462677478790283
INFO:root:current mean train loss 3212.888594320799
INFO:root:current train perplexity3.546598434448242
INFO:root:current mean train loss 3211.9736107930526
INFO:root:current train perplexity3.5467395782470703
INFO:root:current mean train loss 3211.5105720063957
INFO:root:current train perplexity3.546800136566162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.71s/it]
INFO:root:final mean train loss: 3208.611430075861
INFO:root:final train perplexity: 3.5462474822998047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4089.076583970523
INFO:root:eval perplexity: 5.225248336791992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [15:21:45<1:01:16, 282.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.852009662829
INFO:root:current train perplexity3.534461498260498
INFO:root:current mean train loss 3211.6458308293268
INFO:root:current train perplexity3.543816328048706
INFO:root:current mean train loss 3208.822543697034
INFO:root:current train perplexity3.5422096252441406
INFO:root:current mean train loss 3207.21625852947
INFO:root:current train perplexity3.5420002937316895
INFO:root:current mean train loss 3205.577186908144
INFO:root:current train perplexity3.54034161567688
INFO:root:current mean train loss 3209.4502987132355
INFO:root:current train perplexity3.5454773902893066
INFO:root:current mean train loss 3212.968912994604
INFO:root:current train perplexity3.548057794570923
INFO:root:current mean train loss 3211.8422455409786
INFO:root:current train perplexity3.5464816093444824
INFO:root:current mean train loss 3211.0953618736908
INFO:root:current train perplexity3.546811819076538


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.70s/it]
INFO:root:final mean train loss: 3208.275955938524
INFO:root:final train perplexity: 3.5457777976989746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4088.6062409962324
INFO:root:eval perplexity: 5.2242560386657715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [15:26:26<56:28, 282.36s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.9283854166665
INFO:root:current train perplexity3.5045669078826904
INFO:root:current mean train loss 3201.7478572512136
INFO:root:current train perplexity3.51883864402771
INFO:root:current mean train loss 3200.504362059344
INFO:root:current train perplexity3.5286366939544678
INFO:root:current mean train loss 3206.7643011615614
INFO:root:current train perplexity3.538877487182617
INFO:root:current mean train loss 3203.8860196475653
INFO:root:current train perplexity3.538698196411133
INFO:root:current mean train loss 3205.34281372313
INFO:root:current train perplexity3.5421314239501953
INFO:root:current mean train loss 3201.34733639744
INFO:root:current train perplexity3.540231466293335
INFO:root:current mean train loss 3203.317256053854
INFO:root:current train perplexity3.5376360416412354
INFO:root:current mean train loss 3203.659530544637
INFO:root:current train perplexity3.538059949874878
INFO:root:current mean train loss 3208.6475304215983
INFO:root:current train perplexity3.54097843170166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.78s/it]
INFO:root:final mean train loss: 3205.268056131178
INFO:root:final train perplexity: 3.5415728092193604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 4089.300739694149
INFO:root:eval perplexity: 5.225723743438721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [15:31:09<51:49, 282.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3179.6147904829545
INFO:root:current train perplexity3.536111354827881
INFO:root:current mean train loss 3193.249190596847
INFO:root:current train perplexity3.533212900161743
INFO:root:current mean train loss 3206.6469171171507
INFO:root:current train perplexity3.5383384227752686
INFO:root:current mean train loss 3207.3985136467545
INFO:root:current train perplexity3.539302349090576
INFO:root:current mean train loss 3205.3303893894463
INFO:root:current train perplexity3.5431602001190186
INFO:root:current mean train loss 3204.0066749289076
INFO:root:current train perplexity3.5419461727142334
INFO:root:current mean train loss 3202.2795689859095
INFO:root:current train perplexity3.539581060409546
INFO:root:current mean train loss 3204.0596228490904
INFO:root:current train perplexity3.541105270385742
INFO:root:current mean train loss 3203.5223444363633
INFO:root:current train perplexity3.538910388946533
INFO:root:current mean train loss 3206.902789688529
INFO:root:current train perplexity3.541105270385742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 261.47s/it]
INFO:root:final mean train loss: 3205.2651263206235
INFO:root:final train perplexity: 3.5415689945220947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 4089.4899521415114
INFO:root:eval perplexity: 5.2261223793029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [15:35:50<47:01, 282.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.6511487458883
INFO:root:current train perplexity3.545882225036621
INFO:root:current mean train loss 3220.486346589417
INFO:root:current train perplexity3.5436089038848877
INFO:root:current mean train loss 3218.5941178831335
INFO:root:current train perplexity3.54298996925354
INFO:root:current mean train loss 3218.1721489885385
INFO:root:current train perplexity3.5440380573272705
INFO:root:current mean train loss 3209.6875419525654
INFO:root:current train perplexity3.5410571098327637
INFO:root:current mean train loss 3210.0907883249038
INFO:root:current train perplexity3.540832996368408
INFO:root:current mean train loss 3207.6145409998485
INFO:root:current train perplexity3.540661573410034
INFO:root:current mean train loss 3207.5217729974356
INFO:root:current train perplexity3.540954113006592
INFO:root:current mean train loss 3206.2611103360614
INFO:root:current train perplexity3.5416860580444336
INFO:root:current mean train loss 3206.6873488400265
INFO:root:current train perplexity3.5409746170043945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.79s/it]
INFO:root:final mean train loss: 3205.382099274666
INFO:root:final train perplexity: 3.5417325496673584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it]
INFO:root:eval mean loss: 4089.360277108267
INFO:root:eval perplexity: 5.225849151611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [15:40:36<42:28, 283.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.394458912037
INFO:root:current train perplexity3.549391269683838
INFO:root:current mean train loss 3222.6356479915107
INFO:root:current train perplexity3.5372910499572754
INFO:root:current mean train loss 3215.7436534192593
INFO:root:current train perplexity3.5413575172424316
INFO:root:current mean train loss 3212.754645391342
INFO:root:current train perplexity3.5384521484375
INFO:root:current mean train loss 3209.7891265368853
INFO:root:current train perplexity3.5388567447662354
INFO:root:current mean train loss 3213.325746597782
INFO:root:current train perplexity3.540597438812256
INFO:root:current mean train loss 3208.2336659408643
INFO:root:current train perplexity3.53839111328125
INFO:root:current mean train loss 3206.5393032824322
INFO:root:current train perplexity3.537952423095703
INFO:root:current mean train loss 3205.736756182928
INFO:root:current train perplexity3.539090871810913
INFO:root:current mean train loss 3206.1684299045137
INFO:root:current train perplexity3.539760112762451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.35s/it]
INFO:root:final mean train loss: 3204.7055779733964
INFO:root:final train perplexity: 3.5407872200012207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4089.13545475953
INFO:root:eval perplexity: 5.225372791290283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [15:45:19<37:44, 283.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.11572265625
INFO:root:current train perplexity3.5349013805389404
INFO:root:current mean train loss 3204.655036530671
INFO:root:current train perplexity3.537087917327881
INFO:root:current mean train loss 3199.785908410904
INFO:root:current train perplexity3.536560535430908
INFO:root:current mean train loss 3204.930411905317
INFO:root:current train perplexity3.541754961013794
INFO:root:current mean train loss 3209.3745498832614
INFO:root:current train perplexity3.5420732498168945
INFO:root:current mean train loss 3204.5613956629672
INFO:root:current train perplexity3.538163185119629
INFO:root:current mean train loss 3206.0151117279775
INFO:root:current train perplexity3.540292739868164
INFO:root:current mean train loss 3205.102738028805
INFO:root:current train perplexity3.5410637855529785
INFO:root:current mean train loss 3204.244949943862
INFO:root:current train perplexity3.5387022495269775
INFO:root:current mean train loss 3205.2995587190844
INFO:root:current train perplexity3.539351224899292


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.53s/it]
INFO:root:final mean train loss: 3204.4235229492188
INFO:root:final train perplexity: 3.540393590927124
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it]
INFO:root:eval mean loss: 4090.423059341755
INFO:root:eval perplexity: 5.228094577789307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [15:50:03<33:04, 283.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.4548112736193
INFO:root:current train perplexity3.5669925212860107
INFO:root:current mean train loss 3209.037230591674
INFO:root:current train perplexity3.5562613010406494
INFO:root:current mean train loss 3208.775690023791
INFO:root:current train perplexity3.546429395675659
INFO:root:current mean train loss 3204.0746515123906
INFO:root:current train perplexity3.5460145473480225
INFO:root:current mean train loss 3207.9017557182915
INFO:root:current train perplexity3.5427401065826416
INFO:root:current mean train loss 3207.1448383366424
INFO:root:current train perplexity3.5397918224334717
INFO:root:current mean train loss 3206.2972520321005
INFO:root:current train perplexity3.5401837825775146
INFO:root:current mean train loss 3205.13561765278
INFO:root:current train perplexity3.5382139682769775
INFO:root:current mean train loss 3207.6490532093344
INFO:root:current train perplexity3.539397954940796
INFO:root:current mean train loss 3207.434157111612
INFO:root:current train perplexity3.53914737701416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:20<00:00, 260.96s/it]
INFO:root:final mean train loss: 3203.9417097645423
INFO:root:final train perplexity: 3.539720296859741
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it]
INFO:root:eval mean loss: 4089.6951878324467
INFO:root:eval perplexity: 5.226556301116943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [15:54:44<28:16, 282.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.1193560431984
INFO:root:current train perplexity3.509237766265869
INFO:root:current mean train loss 3193.299390780215
INFO:root:current train perplexity3.526165008544922
INFO:root:current mean train loss 3197.548386531997
INFO:root:current train perplexity3.5353245735168457
INFO:root:current mean train loss 3198.864152087785
INFO:root:current train perplexity3.536337375640869
INFO:root:current mean train loss 3201.438844126767
INFO:root:current train perplexity3.5368103981018066
INFO:root:current mean train loss 3204.107084686224
INFO:root:current train perplexity3.5400643348693848
INFO:root:current mean train loss 3207.1271196356565
INFO:root:current train perplexity3.5419883728027344
INFO:root:current mean train loss 3204.5883353445406
INFO:root:current train perplexity3.5398523807525635
INFO:root:current mean train loss 3205.164309222606
INFO:root:current train perplexity3.539865255355835
INFO:root:current mean train loss 3206.0557220811975
INFO:root:current train perplexity3.5403904914855957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 263.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:23<00:00, 263.00s/it]
INFO:root:final mean train loss: 3203.5752674225837
INFO:root:final train perplexity: 3.5392086505889893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it]
INFO:root:eval mean loss: 4089.8824384973404
INFO:root:eval perplexity: 5.22695255279541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [15:59:27<23:34, 282.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.027128575212
INFO:root:current train perplexity3.5541789531707764
INFO:root:current mean train loss 3220.165796051985
INFO:root:current train perplexity3.553029775619507
INFO:root:current mean train loss 3219.689151484073
INFO:root:current train perplexity3.548079252243042
INFO:root:current mean train loss 3215.1106807103065
INFO:root:current train perplexity3.5439016819000244
INFO:root:current mean train loss 3211.292440044594
INFO:root:current train perplexity3.5422050952911377
INFO:root:current mean train loss 3205.005523517861
INFO:root:current train perplexity3.53900408744812
INFO:root:current mean train loss 3203.537407233972
INFO:root:current train perplexity3.5388145446777344
INFO:root:current mean train loss 3204.208469074234
INFO:root:current train perplexity3.539158821105957
INFO:root:current mean train loss 3205.299943668601
INFO:root:current train perplexity3.5378544330596924
INFO:root:current mean train loss 3205.3997195565044
INFO:root:current train perplexity3.538346767425537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.03s/it]
INFO:root:final mean train loss: 3203.1590781058035
INFO:root:final train perplexity: 3.5386271476745605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 4090.1967894642066
INFO:root:eval perplexity: 5.227617263793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [16:04:13<18:55, 283.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.3604207964086
INFO:root:current train perplexity3.5425074100494385
INFO:root:current mean train loss 3204.696927921501
INFO:root:current train perplexity3.539999008178711
INFO:root:current mean train loss 3209.4570980000585
INFO:root:current train perplexity3.540377140045166
INFO:root:current mean train loss 3208.9187184679413
INFO:root:current train perplexity3.5385069847106934
INFO:root:current mean train loss 3210.2696237829564
INFO:root:current train perplexity3.5403201580047607
INFO:root:current mean train loss 3209.9386574074074
INFO:root:current train perplexity3.541140556335449
INFO:root:current mean train loss 3206.5363535273377
INFO:root:current train perplexity3.538712978363037
INFO:root:current mean train loss 3207.3831435381358
INFO:root:current train perplexity3.540754795074463
INFO:root:current mean train loss 3205.919535248612
INFO:root:current train perplexity3.539477825164795
INFO:root:current mean train loss 3205.1110809547085
INFO:root:current train perplexity3.5387091636657715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:24<00:00, 264.07s/it]
INFO:root:final mean train loss: 3202.4966393747636
INFO:root:final train perplexity: 3.537702798843384
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it]
INFO:root:eval mean loss: 4090.071147080009
INFO:root:eval perplexity: 5.227351665496826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [16:09:26<14:37, 292.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.6570735677083
INFO:root:current train perplexity3.5328965187072754
INFO:root:current mean train loss 3204.5721568080357
INFO:root:current train perplexity3.534006118774414
INFO:root:current mean train loss 3202.9449351917615
INFO:root:current train perplexity3.536538600921631
INFO:root:current mean train loss 3199.382970703125
INFO:root:current train perplexity3.534423589706421
INFO:root:current mean train loss 3202.7294089226975
INFO:root:current train perplexity3.5333330631256104
INFO:root:current mean train loss 3203.444088400136
INFO:root:current train perplexity3.5323095321655273
INFO:root:current mean train loss 3205.637540870949
INFO:root:current train perplexity3.5356483459472656
INFO:root:current mean train loss 3203.822861643145
INFO:root:current train perplexity3.5353338718414307
INFO:root:current mean train loss 3205.5557544642857
INFO:root:current train perplexity3.535884380340576
INFO:root:current mean train loss 3204.4989037459936
INFO:root:current train perplexity3.537282705307007


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 262.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:21<00:00, 262.00s/it]
INFO:root:final mean train loss: 3202.074047765424
INFO:root:final train perplexity: 3.5371131896972656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 4090.353423855829
INFO:root:eval perplexity: 5.2279486656188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [16:14:37<09:56, 298.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.4087708254897
INFO:root:current train perplexity3.536635160446167
INFO:root:current mean train loss 3210.795266073258
INFO:root:current train perplexity3.5419888496398926
INFO:root:current mean train loss 3214.1724340216433
INFO:root:current train perplexity3.549678087234497
INFO:root:current mean train loss 3210.481218382833
INFO:root:current train perplexity3.5465147495269775
INFO:root:current mean train loss 3202.454933055933
INFO:root:current train perplexity3.5429515838623047
INFO:root:current mean train loss 3205.8200080570596
INFO:root:current train perplexity3.5453872680664062
INFO:root:current mean train loss 3205.8316019485496
INFO:root:current train perplexity3.540673017501831
INFO:root:current mean train loss 3205.0925682720704
INFO:root:current train perplexity3.537646532058716
INFO:root:current mean train loss 3204.7909307425857
INFO:root:current train perplexity3.5353586673736572
INFO:root:current mean train loss 3204.3738095971357
INFO:root:current train perplexity3.5362308025360107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:25<00:00, 265.12s/it]
INFO:root:final mean train loss: 3201.352229456748
INFO:root:final train perplexity: 3.5361058712005615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it]
INFO:root:eval mean loss: 4090.358694522939
INFO:root:eval perplexity: 5.227960109710693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [16:19:49<05:02, 302.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.7938058035716
INFO:root:current train perplexity3.5431864261627197
INFO:root:current mean train loss 3196.1883397926213
INFO:root:current train perplexity3.525820732116699
INFO:root:current mean train loss 3195.456035391162
INFO:root:current train perplexity3.530620574951172
INFO:root:current mean train loss 3198.3882154381795
INFO:root:current train perplexity3.5302670001983643
INFO:root:current mean train loss 3199.685582675662
INFO:root:current train perplexity3.531121015548706
INFO:root:current mean train loss 3199.7399898212775
INFO:root:current train perplexity3.534038543701172
INFO:root:current mean train loss 3198.9714532126222
INFO:root:current train perplexity3.5327370166778564
INFO:root:current mean train loss 3200.63557891267
INFO:root:current train perplexity3.5325403213500977
INFO:root:current mean train loss 3201.615938026094
INFO:root:current train perplexity3.5333001613616943
INFO:root:current mean train loss 3201.5562728127366
INFO:root:current train perplexity3.532851457595825


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:22<00:00, 262.29s/it]
INFO:root:final mean train loss: 3199.0105307179115
INFO:root:final train perplexity: 3.5328404903411865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 4090.4104073166
INFO:root:eval perplexity: 5.2280683517456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_138/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [16:24:58<00:00, 304.16s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [16:24:58<00:00, 295.49s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.95s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.95s/it]
INFO:root:eval mean loss: 4090.4104073166
INFO:root:eval perplexity: 5.2280683517456055
INFO:root:evalaution complete
INFO:root:save model final: small_val_138/final
