INFO:root:Output: multil6_alll12_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23226.399384469696
INFO:root:current train perplexity9862.6796875
INFO:root:current mean train loss 19247.703610827575
INFO:root:current train perplexity2006.8651123046875
INFO:root:current mean train loss 16803.73955829327
INFO:root:current train perplexity762.9334106445312
INFO:root:current mean train loss 15084.662229303729
INFO:root:current train perplexity383.6914367675781
INFO:root:current mean train loss 13808.790639873498
INFO:root:current train perplexity232.4112091064453
INFO:root:current mean train loss 12841.068697666684
INFO:root:current train perplexity158.2547607421875
INFO:root:current mean train loss 12079.207738873614
INFO:root:current train perplexity117.18930053710938
INFO:root:current mean train loss 11464.623978214957
INFO:root:current train perplexity91.94438934326172
INFO:root:current mean train loss 10960.537708456444
INFO:root:current train perplexity75.32540130615234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it]
INFO:root:final mean train loss: 10558.611221067367
INFO:root:final train perplexity: 64.43635559082031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 6182.30155695922
INFO:root:eval perplexity: 12.181777000427246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 6718.014516843971
INFO:root:eval perplexity: 15.597149848937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/1
  0%|          | 1/200 [09:51<32:40:25, 591.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6498.177734375
INFO:root:current train perplexity13.142712593078613
INFO:root:current mean train loss 6569.816351489486
INFO:root:current train perplexity13.204032897949219
INFO:root:current mean train loss 6475.987193821709
INFO:root:current train perplexity12.732129096984863
INFO:root:current mean train loss 6402.344569103726
INFO:root:current train perplexity12.42672061920166
INFO:root:current mean train loss 6328.892917642429
INFO:root:current train perplexity12.106184959411621
INFO:root:current mean train loss 6275.517360469058
INFO:root:current train perplexity11.843575477600098
INFO:root:current mean train loss 6220.4055115449955
INFO:root:current train perplexity11.607279777526855
INFO:root:current mean train loss 6179.811771376635
INFO:root:current train perplexity11.402627944946289
INFO:root:current mean train loss 6130.973312132125
INFO:root:current train perplexity11.209380149841309
INFO:root:current mean train loss 6085.253580549717
INFO:root:current train perplexity11.00461196899414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.89s/it]
INFO:root:final mean train loss: 6048.95742108745
INFO:root:final train perplexity: 10.875243186950684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 5319.9653458832
INFO:root:eval perplexity: 8.595492362976074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 5960.98645625554
INFO:root:eval perplexity: 11.444726943969727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/2
  1%|          | 2/200 [19:55<32:55:46, 598.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5618.476236979167
INFO:root:current train perplexity9.236857414245605
INFO:root:current mean train loss 5612.925246263587
INFO:root:current train perplexity9.187240600585938
INFO:root:current mean train loss 5603.888544694767
INFO:root:current train perplexity9.110901832580566
INFO:root:current mean train loss 5578.668016803075
INFO:root:current train perplexity9.0225248336792
INFO:root:current mean train loss 5563.573864599021
INFO:root:current train perplexity8.955536842346191
INFO:root:current mean train loss 5535.466164479672
INFO:root:current train perplexity8.86839771270752
INFO:root:current mean train loss 5510.528441787347
INFO:root:current train perplexity8.789822578430176
INFO:root:current mean train loss 5489.714001720935
INFO:root:current train perplexity8.711745262145996
INFO:root:current mean train loss 5469.228749880176
INFO:root:current train perplexity8.635924339294434
INFO:root:current mean train loss 5453.891377967042
INFO:root:current train perplexity8.58340835571289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.26s/it]
INFO:root:final mean train loss: 5437.085423746416
INFO:root:final train perplexity: 8.5427885055542
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 4952.466291278812
INFO:root:eval perplexity: 7.408528804779053
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 5640.016906305408
INFO:root:eval perplexity: 10.03702163696289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/3
  2%|â–         | 3/200 [29:53<32:44:43, 598.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5176.218049422554
INFO:root:current train perplexity7.753843784332275
INFO:root:current mean train loss 5216.631256351626
INFO:root:current train perplexity7.82750940322876
INFO:root:current mean train loss 5218.365102998879
INFO:root:current train perplexity7.786635875701904
INFO:root:current mean train loss 5192.255351441563
INFO:root:current train perplexity7.744705677032471
INFO:root:current mean train loss 5173.075924848552
INFO:root:current train perplexity7.692385673522949
INFO:root:current mean train loss 5150.827891595961
INFO:root:current train perplexity7.641485214233398
INFO:root:current mean train loss 5149.552386386436
INFO:root:current train perplexity7.625478744506836
INFO:root:current mean train loss 5138.698795978129
INFO:root:current train perplexity7.584305763244629
INFO:root:current mean train loss 5129.522717833954
INFO:root:current train perplexity7.554993152618408
INFO:root:current mean train loss 5116.065121271499
INFO:root:current train perplexity7.518095016479492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.17s/it]
INFO:root:final mean train loss: 5103.756096870668
INFO:root:final train perplexity: 7.490080833435059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it]
INFO:root:eval mean loss: 4723.138606078236
INFO:root:eval perplexity: 6.752403736114502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 5438.261656416224
INFO:root:eval perplexity: 9.242201805114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/4
  2%|â–         | 4/200 [39:52<32:35:48, 598.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5006.4884387600805
INFO:root:current train perplexity7.11134147644043
INFO:root:current mean train loss 4957.680768427958
INFO:root:current train perplexity7.040948390960693
INFO:root:current mean train loss 4948.134296367695
INFO:root:current train perplexity7.038231372833252
INFO:root:current mean train loss 4940.20728055372
INFO:root:current train perplexity7.012226104736328
INFO:root:current mean train loss 4937.888312744707
INFO:root:current train perplexity7.001553535461426
INFO:root:current mean train loss 4931.435234227872
INFO:root:current train perplexity6.981597423553467
INFO:root:current mean train loss 4923.760923261688
INFO:root:current train perplexity6.953135013580322
INFO:root:current mean train loss 4911.2386025403985
INFO:root:current train perplexity6.924620628356934
INFO:root:current mean train loss 4902.279257506957
INFO:root:current train perplexity6.904979705810547
INFO:root:current mean train loss 4898.495310192334
INFO:root:current train perplexity6.892667770385742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.09s/it]
INFO:root:final mean train loss: 4889.022585222798
INFO:root:final train perplexity: 6.881666660308838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 4567.342129321809
INFO:root:eval perplexity: 6.340129852294922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 5301.217276498781
INFO:root:eval perplexity: 8.738517761230469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/5
  2%|â–Ž         | 5/200 [49:47<32:21:31, 597.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4800.607171474359
INFO:root:current train perplexity6.70551872253418
INFO:root:current mean train loss 4800.642996149955
INFO:root:current train perplexity6.628813743591309
INFO:root:current mean train loss 4783.859260591004
INFO:root:current train perplexity6.613687992095947
INFO:root:current mean train loss 4779.381262675148
INFO:root:current train perplexity6.5936279296875
INFO:root:current mean train loss 4771.763710804029
INFO:root:current train perplexity6.56906270980835
INFO:root:current mean train loss 4763.643552875696
INFO:root:current train perplexity6.551906585693359
INFO:root:current mean train loss 4762.02360331695
INFO:root:current train perplexity6.5357160568237305
INFO:root:current mean train loss 4754.199071076307
INFO:root:current train perplexity6.52350378036499
INFO:root:current mean train loss 4747.347917268046
INFO:root:current train perplexity6.50580358505249
INFO:root:current mean train loss 4745.647952598759
INFO:root:current train perplexity6.4962897300720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.26s/it]
INFO:root:final mean train loss: 4741.878324324085
INFO:root:final train perplexity: 6.493544101715088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 4472.746140500332
INFO:root:eval perplexity: 6.1021857261657715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 5220.262669340093
INFO:root:eval perplexity: 8.453978538513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/6
  3%|â–Ž         | 6/200 [59:43<32:09:55, 596.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4620.590877451795
INFO:root:current train perplexity6.206701278686523
INFO:root:current mean train loss 4631.221776015093
INFO:root:current train perplexity6.2287445068359375
INFO:root:current mean train loss 4652.299579326923
INFO:root:current train perplexity6.243700981140137
INFO:root:current mean train loss 4657.977067667057
INFO:root:current train perplexity6.258214950561523
INFO:root:current mean train loss 4655.996260879824
INFO:root:current train perplexity6.254110813140869
INFO:root:current mean train loss 4652.430465000857
INFO:root:current train perplexity6.250665187835693
INFO:root:current mean train loss 4645.155597197401
INFO:root:current train perplexity6.238917827606201
INFO:root:current mean train loss 4645.810927302962
INFO:root:current train perplexity6.241034030914307
INFO:root:current mean train loss 4638.737552575266
INFO:root:current train perplexity6.2312703132629395
INFO:root:current mean train loss 4639.43391033362
INFO:root:current train perplexity6.225719451904297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.79s/it]
INFO:root:final mean train loss: 4634.33103992093
INFO:root:final train perplexity: 6.223780155181885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 4405.072080355164
INFO:root:eval perplexity: 5.937463283538818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 5162.3439906776375
INFO:root:eval perplexity: 8.25610637664795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/7
  4%|â–Ž         | 7/200 [1:09:39<31:58:51, 596.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4617.125772372159
INFO:root:current train perplexity6.142184257507324
INFO:root:current mean train loss 4579.58097750756
INFO:root:current train perplexity6.069370269775391
INFO:root:current mean train loss 4601.105312691483
INFO:root:current train perplexity6.1044487953186035
INFO:root:current mean train loss 4603.507693524428
INFO:root:current train perplexity6.109870910644531
INFO:root:current mean train loss 4595.525041852678
INFO:root:current train perplexity6.105222225189209
INFO:root:current mean train loss 4590.072084389077
INFO:root:current train perplexity6.101080417633057
INFO:root:current mean train loss 4586.907091260138
INFO:root:current train perplexity6.096944808959961
INFO:root:current mean train loss 4584.612763219164
INFO:root:current train perplexity6.093052387237549
INFO:root:current mean train loss 4579.934129431652
INFO:root:current train perplexity6.081518173217773
INFO:root:current mean train loss 4575.523078830579
INFO:root:current train perplexity6.0739426612854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.57s/it]
INFO:root:final mean train loss: 4570.250947275469
INFO:root:final train perplexity: 6.068408012390137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it]
INFO:root:eval mean loss: 4344.689721506538
INFO:root:eval perplexity: 5.794244289398193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 5112.896579607159
INFO:root:eval perplexity: 8.090849876403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/8
  4%|â–         | 8/200 [1:19:35<31:48:17, 596.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4489.544658358135
INFO:root:current train perplexity5.90397834777832
INFO:root:current mean train loss 4486.249863700633
INFO:root:current train perplexity5.881601810455322
INFO:root:current mean train loss 4498.244666966195
INFO:root:current train perplexity5.890844345092773
INFO:root:current mean train loss 4497.705738582558
INFO:root:current train perplexity5.887155055999756
INFO:root:current mean train loss 4500.801925494398
INFO:root:current train perplexity5.88744592666626
INFO:root:current mean train loss 4500.693835080623
INFO:root:current train perplexity5.890102386474609
INFO:root:current mean train loss 4492.968857524981
INFO:root:current train perplexity5.88364315032959
INFO:root:current mean train loss 4492.805291932033
INFO:root:current train perplexity5.879203796386719
INFO:root:current mean train loss 4493.449280987471
INFO:root:current train perplexity5.878261089324951
INFO:root:current mean train loss 4489.4833814516
INFO:root:current train perplexity5.869808673858643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.84s/it]
INFO:root:final mean train loss: 4485.07361442812
INFO:root:final train perplexity: 5.867867946624756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it]
INFO:root:eval mean loss: 4264.26859104887
INFO:root:eval perplexity: 5.608846664428711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 5047.87971832059
INFO:root:eval perplexity: 7.878578186035156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/9
  4%|â–         | 9/200 [1:29:33<31:40:56, 597.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4415.942847023548
INFO:root:current train perplexity5.744062423706055
INFO:root:current mean train loss 4430.749171920687
INFO:root:current train perplexity5.742591857910156
INFO:root:current mean train loss 4415.497788320168
INFO:root:current train perplexity5.717922210693359
INFO:root:current mean train loss 4415.617061152291
INFO:root:current train perplexity5.715588092803955
INFO:root:current mean train loss 4419.982924151573
INFO:root:current train perplexity5.714122772216797
INFO:root:current mean train loss 4419.564636978711
INFO:root:current train perplexity5.707729339599609
INFO:root:current mean train loss 4415.372458172271
INFO:root:current train perplexity5.700033187866211
INFO:root:current mean train loss 4414.591307327132
INFO:root:current train perplexity5.697301387786865
INFO:root:current mean train loss 4418.324902119511
INFO:root:current train perplexity5.702393531799316
INFO:root:current mean train loss 4413.309830041919
INFO:root:current train perplexity5.69276237487793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.07s/it]
INFO:root:final mean train loss: 4407.430709592758
INFO:root:final train perplexity: 5.690845489501953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.43s/it]
INFO:root:eval mean loss: 4208.255495761303
INFO:root:eval perplexity: 5.483233451843262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 5001.099091658355
INFO:root:eval perplexity: 7.7293009757995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/10
  5%|â–Œ         | 10/200 [1:39:31<31:31:01, 597.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4388.388572982595
INFO:root:current train perplexity5.592484951019287
INFO:root:current mean train loss 4377.697599783956
INFO:root:current train perplexity5.5787153244018555
INFO:root:current mean train loss 4359.743500084005
INFO:root:current train perplexity5.563480377197266
INFO:root:current mean train loss 4357.671368681976
INFO:root:current train perplexity5.563535213470459
INFO:root:current mean train loss 4353.295922902531
INFO:root:current train perplexity5.563910484313965
INFO:root:current mean train loss 4354.703363659057
INFO:root:current train perplexity5.559629440307617
INFO:root:current mean train loss 4351.626142319243
INFO:root:current train perplexity5.5536274909973145
INFO:root:current mean train loss 4348.2725389747475
INFO:root:current train perplexity5.54895544052124
INFO:root:current mean train loss 4345.727446294617
INFO:root:current train perplexity5.543623924255371
INFO:root:current mean train loss 4342.989529883411
INFO:root:current train perplexity5.540559768676758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.97s/it]
INFO:root:final mean train loss: 4339.220019063642
INFO:root:final train perplexity: 5.5397419929504395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 4169.790461546986
INFO:root:eval perplexity: 5.398605823516846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4971.000367076685
INFO:root:eval perplexity: 7.6347527503967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/11
  6%|â–Œ         | 11/200 [1:49:30<31:22:47, 597.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4286.760051858836
INFO:root:current train perplexity5.406786918640137
INFO:root:current mean train loss 4289.549960049716
INFO:root:current train perplexity5.426253795623779
INFO:root:current mean train loss 4281.885161183853
INFO:root:current train perplexity5.427585124969482
INFO:root:current mean train loss 4282.236509811047
INFO:root:current train perplexity5.405368804931641
INFO:root:current mean train loss 4283.612512232097
INFO:root:current train perplexity5.404088973999023
INFO:root:current mean train loss 4287.926139766557
INFO:root:current train perplexity5.411502361297607
INFO:root:current mean train loss 4284.961776888874
INFO:root:current train perplexity5.410495281219482
INFO:root:current mean train loss 4284.463763264871
INFO:root:current train perplexity5.412174701690674
INFO:root:current mean train loss 4284.055607362422
INFO:root:current train perplexity5.415729999542236
INFO:root:current mean train loss 4283.525049273367
INFO:root:current train perplexity5.412684917449951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.99s/it]
INFO:root:final mean train loss: 4280.1430025408345
INFO:root:final train perplexity: 5.412117004394531
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it]
INFO:root:eval mean loss: 4107.781469899712
INFO:root:eval perplexity: 5.26492166519165
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 4915.006181432846
INFO:root:eval perplexity: 7.461925983428955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/12
  6%|â–Œ         | 12/200 [1:59:22<31:07:42, 596.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4224.131648334704
INFO:root:current train perplexity5.289127826690674
INFO:root:current mean train loss 4225.049124849759
INFO:root:current train perplexity5.283034801483154
INFO:root:current mean train loss 4233.411449781514
INFO:root:current train perplexity5.307938575744629
INFO:root:current mean train loss 4233.58545416337
INFO:root:current train perplexity5.307185649871826
INFO:root:current mean train loss 4231.286875098643
INFO:root:current train perplexity5.302234649658203
INFO:root:current mean train loss 4226.111655560661
INFO:root:current train perplexity5.301337242126465
INFO:root:current mean train loss 4227.976080541816
INFO:root:current train perplexity5.29874849319458
INFO:root:current mean train loss 4230.160076098172
INFO:root:current train perplexity5.301700592041016
INFO:root:current mean train loss 4231.8060235902585
INFO:root:current train perplexity5.302783489227295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.65s/it]
INFO:root:final mean train loss: 4228.437974006899
INFO:root:final train perplexity: 5.30283260345459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 4073.63368863586
INFO:root:eval perplexity: 5.192720890045166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 4893.615679368905
INFO:root:eval perplexity: 7.396940231323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/13
  6%|â–‹         | 13/200 [2:09:17<30:56:44, 595.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4192.419596354167
INFO:root:current train perplexity5.2234721183776855
INFO:root:current mean train loss 4180.227347068416
INFO:root:current train perplexity5.220733642578125
INFO:root:current mean train loss 4182.919239964978
INFO:root:current train perplexity5.204707622528076
INFO:root:current mean train loss 4183.6114207856335
INFO:root:current train perplexity5.195291042327881
INFO:root:current mean train loss 4177.297511704211
INFO:root:current train perplexity5.197896480560303
INFO:root:current mean train loss 4175.9556848362945
INFO:root:current train perplexity5.197112083435059
INFO:root:current mean train loss 4178.002510640159
INFO:root:current train perplexity5.199592113494873
INFO:root:current mean train loss 4185.930921747199
INFO:root:current train perplexity5.20953893661499
INFO:root:current mean train loss 4183.328627570925
INFO:root:current train perplexity5.210474491119385
INFO:root:current mean train loss 4184.514697644137
INFO:root:current train perplexity5.20947790145874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.48s/it]
INFO:root:final mean train loss: 4184.820004124796
INFO:root:final train perplexity: 5.212358474731445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 4050.3647080008864
INFO:root:eval perplexity: 5.14409065246582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 4868.532036098182
INFO:root:eval perplexity: 7.321460247039795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/14
  7%|â–‹         | 14/200 [2:19:15<30:48:58, 596.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4186.297807173295
INFO:root:current train perplexity4.987107753753662
INFO:root:current mean train loss 4156.792073567708
INFO:root:current train perplexity5.122402667999268
INFO:root:current mean train loss 4152.549823200533
INFO:root:current train perplexity5.112957000732422
INFO:root:current mean train loss 4149.7400129999
INFO:root:current train perplexity5.114682674407959
INFO:root:current mean train loss 4145.524864326719
INFO:root:current train perplexity5.114194393157959
INFO:root:current mean train loss 4139.557165216793
INFO:root:current train perplexity5.112922191619873
INFO:root:current mean train loss 4143.136500981357
INFO:root:current train perplexity5.120394229888916
INFO:root:current mean train loss 4141.691421015185
INFO:root:current train perplexity5.118772983551025
INFO:root:current mean train loss 4147.412551296625
INFO:root:current train perplexity5.126744747161865
INFO:root:current mean train loss 4148.503834964154
INFO:root:current train perplexity5.130305767059326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.54s/it]
INFO:root:final mean train loss: 4146.7690117743705
INFO:root:final train perplexity: 5.134695053100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 4007.665522149269
INFO:root:eval perplexity: 5.056033134460449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 4837.082723847518
INFO:root:eval perplexity: 7.227907180786133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/15
  8%|â–Š         | 15/200 [2:29:10<30:38:03, 596.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4091.5770070929275
INFO:root:current train perplexity5.088442802429199
INFO:root:current mean train loss 4111.585658482143
INFO:root:current train perplexity5.08172607421875
INFO:root:current mean train loss 4109.136525890054
INFO:root:current train perplexity5.059914588928223
INFO:root:current mean train loss 4124.302282064313
INFO:root:current train perplexity5.080328941345215
INFO:root:current mean train loss 4115.688904828274
INFO:root:current train perplexity5.0642290115356445
INFO:root:current mean train loss 4117.492146574693
INFO:root:current train perplexity5.062084674835205
INFO:root:current mean train loss 4113.618428318104
INFO:root:current train perplexity5.0589447021484375
INFO:root:current mean train loss 4117.533842508584
INFO:root:current train perplexity5.057651996612549
INFO:root:current mean train loss 4114.81797989879
INFO:root:current train perplexity5.05956506729126
INFO:root:current mean train loss 4114.314002036011
INFO:root:current train perplexity5.061532020568848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.94s/it]
INFO:root:final mean train loss: 4107.434839433239
INFO:root:final train perplexity: 5.05562686920166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 3984.2751672623003
INFO:root:eval perplexity: 5.008436679840088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4813.103524282469
INFO:root:eval perplexity: 7.157382011413574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/16
  8%|â–Š         | 16/200 [2:39:05<30:26:16, 595.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4135.811659071181
INFO:root:current train perplexity5.0175299644470215
INFO:root:current mean train loss 4099.418597364051
INFO:root:current train perplexity5.026481628417969
INFO:root:current mean train loss 4086.2207171066216
INFO:root:current train perplexity5.015369415283203
INFO:root:current mean train loss 4087.846785705753
INFO:root:current train perplexity5.007555961608887
INFO:root:current mean train loss 4086.93298539959
INFO:root:current train perplexity5.005553245544434
INFO:root:current mean train loss 4080.992703113882
INFO:root:current train perplexity5.001099586486816
INFO:root:current mean train loss 4076.191004410885
INFO:root:current train perplexity4.990973949432373
INFO:root:current mean train loss 4080.6957772738997
INFO:root:current train perplexity4.996205806732178
INFO:root:current mean train loss 4081.999965755366
INFO:root:current train perplexity5.001785755157471
INFO:root:current mean train loss 4078.988831422347
INFO:root:current train perplexity4.995649814605713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.79s/it]
INFO:root:final mean train loss: 4079.087376071561
INFO:root:final train perplexity: 4.999400615692139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 3974.826029892509
INFO:root:eval perplexity: 4.9893364906311035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4805.382467932735
INFO:root:eval perplexity: 7.1348185539245605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/17
  8%|â–Š         | 17/200 [2:48:59<30:15:34, 595.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4109.384981863839
INFO:root:current train perplexity5.00375509262085
INFO:root:current mean train loss 4056.239178240741
INFO:root:current train perplexity4.9604811668396
INFO:root:current mean train loss 4049.954209607713
INFO:root:current train perplexity4.938545227050781
INFO:root:current mean train loss 4051.9302807252798
INFO:root:current train perplexity4.941488742828369
INFO:root:current mean train loss 4048.960272988506
INFO:root:current train perplexity4.941679954528809
INFO:root:current mean train loss 4049.990408239632
INFO:root:current train perplexity4.942841529846191
INFO:root:current mean train loss 4054.598819666585
INFO:root:current train perplexity4.94795036315918
INFO:root:current mean train loss 4051.8242509699194
INFO:root:current train perplexity4.947209358215332
INFO:root:current mean train loss 4049.770734994854
INFO:root:current train perplexity4.943905353546143
INFO:root:current mean train loss 4053.6489276090406
INFO:root:current train perplexity4.945671558380127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.16s/it]
INFO:root:final mean train loss: 4049.7653279458323
INFO:root:final train perplexity: 4.941898822784424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 3973.2990099318486
INFO:root:eval perplexity: 4.9862565994262695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4816.06832301363
INFO:root:eval perplexity: 7.166064739227295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/18
  9%|â–‰         | 18/200 [2:58:56<30:06:35, 595.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3967.6813113190406
INFO:root:current train perplexity4.863155364990234
INFO:root:current mean train loss 4003.302961442854
INFO:root:current train perplexity4.857949256896973
INFO:root:current mean train loss 4003.755714699074
INFO:root:current train perplexity4.865652084350586
INFO:root:current mean train loss 4006.8342826109238
INFO:root:current train perplexity4.863687038421631
INFO:root:current mean train loss 4018.0674963406464
INFO:root:current train perplexity4.880151271820068
INFO:root:current mean train loss 4020.9111773243267
INFO:root:current train perplexity4.882499694824219
INFO:root:current mean train loss 4020.3133106380005
INFO:root:current train perplexity4.882193565368652
INFO:root:current mean train loss 4023.2216980884086
INFO:root:current train perplexity4.8821001052856445
INFO:root:current mean train loss 4026.339386167334
INFO:root:current train perplexity4.889542579650879
INFO:root:current mean train loss 4028.3381187139616
INFO:root:current train perplexity4.894974708557129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.86s/it]
INFO:root:final mean train loss: 4026.211548712946
INFO:root:final train perplexity: 4.896188259124756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 3936.595819135084
INFO:root:eval perplexity: 4.9127984046936035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 4778.528394766733
INFO:root:eval perplexity: 7.056901454925537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/19
 10%|â–‰         | 19/200 [3:08:50<29:55:36, 595.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4006.747012867647
INFO:root:current train perplexity4.879034519195557
INFO:root:current mean train loss 4001.518912005898
INFO:root:current train perplexity4.865384578704834
INFO:root:current mean train loss 3990.521463948892
INFO:root:current train perplexity4.837149143218994
INFO:root:current mean train loss 4004.4751936431626
INFO:root:current train perplexity4.855496406555176
INFO:root:current mean train loss 3999.3332026919347
INFO:root:current train perplexity4.849056243896484
INFO:root:current mean train loss 4002.5410652506807
INFO:root:current train perplexity4.84735631942749
INFO:root:current mean train loss 4003.6103894399243
INFO:root:current train perplexity4.845012664794922
INFO:root:current mean train loss 4000.60160346101
INFO:root:current train perplexity4.839611530303955
INFO:root:current mean train loss 4002.831472681496
INFO:root:current train perplexity4.843035697937012
INFO:root:current mean train loss 4003.1203084438257
INFO:root:current train perplexity4.84505558013916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.45s/it]
INFO:root:final mean train loss: 4000.412053323561
INFO:root:final train perplexity: 4.846604347229004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 3932.0249248531695
INFO:root:eval perplexity: 4.903726100921631
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4779.551361300421
INFO:root:eval perplexity: 7.05985164642334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/20
 10%|â–ˆ         | 20/200 [3:18:45<29:45:32, 595.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3969.497244107521
INFO:root:current train perplexity4.791836261749268
INFO:root:current mean train loss 3975.9515004667846
INFO:root:current train perplexity4.768372535705566
INFO:root:current mean train loss 3970.454455047961
INFO:root:current train perplexity4.786086082458496
INFO:root:current mean train loss 3977.4537928164173
INFO:root:current train perplexity4.7861151695251465
INFO:root:current mean train loss 3981.108852145459
INFO:root:current train perplexity4.795718193054199
INFO:root:current mean train loss 3985.8689357914523
INFO:root:current train perplexity4.803738594055176
INFO:root:current mean train loss 3980.5536838930907
INFO:root:current train perplexity4.796192169189453
INFO:root:current mean train loss 3981.557395563138
INFO:root:current train perplexity4.796951770782471
INFO:root:current mean train loss 3984.933890754602
INFO:root:current train perplexity4.802737236022949
INFO:root:current mean train loss 3979.77783661366
INFO:root:current train perplexity4.799476623535156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.26s/it]
INFO:root:final mean train loss: 3976.3694943458804
INFO:root:final train perplexity: 4.800849437713623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 3910.6605250581783
INFO:root:eval perplexity: 4.861545085906982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4765.843824454233
INFO:root:eval perplexity: 7.020391941070557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/21
 10%|â–ˆ         | 21/200 [3:28:40<29:35:12, 595.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3981.0170534048507
INFO:root:current train perplexity4.779924392700195
INFO:root:current mean train loss 3970.6733018338323
INFO:root:current train perplexity4.773362159729004
INFO:root:current mean train loss 3957.5000868665147
INFO:root:current train perplexity4.771544933319092
INFO:root:current mean train loss 3960.9746579370317
INFO:root:current train perplexity4.766632080078125
INFO:root:current mean train loss 3953.647528376773
INFO:root:current train perplexity4.749545574188232
INFO:root:current mean train loss 3950.567263110395
INFO:root:current train perplexity4.750401020050049
INFO:root:current mean train loss 3952.542622853612
INFO:root:current train perplexity4.749775409698486
INFO:root:current mean train loss 3954.0350438880173
INFO:root:current train perplexity4.74926233291626
INFO:root:current mean train loss 3957.270685215722
INFO:root:current train perplexity4.753936290740967
INFO:root:current mean train loss 3957.64615388888
INFO:root:current train perplexity4.7594428062438965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.79s/it]
INFO:root:final mean train loss: 3954.3979511260986
INFO:root:final train perplexity: 4.75941276550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3919.657013588763
INFO:root:eval perplexity: 4.879262924194336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 4771.004217918883
INFO:root:eval perplexity: 7.035220623016357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/22
 11%|â–ˆ         | 22/200 [3:38:35<29:25:18, 595.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3963.63927734375
INFO:root:current train perplexity4.734059810638428
INFO:root:current mean train loss 3958.4201046316966
INFO:root:current train perplexity4.715418815612793
INFO:root:current mean train loss 3939.736203835227
INFO:root:current train perplexity4.7016777992248535
INFO:root:current mean train loss 3931.9617923177084
INFO:root:current train perplexity4.693448066711426
INFO:root:current mean train loss 3925.71502004523
INFO:root:current train perplexity4.696372985839844
INFO:root:current mean train loss 3931.096163383152
INFO:root:current train perplexity4.702211380004883
INFO:root:current mean train loss 3932.4415520109956
INFO:root:current train perplexity4.703634738922119
INFO:root:current mean train loss 3929.5319698210687
INFO:root:current train perplexity4.699288368225098
INFO:root:current mean train loss 3932.344541294643
INFO:root:current train perplexity4.706899642944336
INFO:root:current mean train loss 3931.840936748798
INFO:root:current train perplexity4.710728645324707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.38s/it]
INFO:root:final mean train loss: 3927.889998343683
INFO:root:final train perplexity: 4.709898948669434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.66s/it]
INFO:root:eval mean loss: 3887.3537822750445
INFO:root:eval perplexity: 4.815942287445068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4744.219700590093
INFO:root:eval perplexity: 6.958587169647217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/23
 12%|â–ˆâ–        | 23/200 [3:48:30<29:15:09, 594.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3900.555146366717
INFO:root:current train perplexity4.661746025085449
INFO:root:current mean train loss 3896.964303438781
INFO:root:current train perplexity4.659582614898682
INFO:root:current mean train loss 3910.7736462704283
INFO:root:current train perplexity4.667732238769531
INFO:root:current mean train loss 3907.429381527415
INFO:root:current train perplexity4.668213367462158
INFO:root:current mean train loss 3902.194709983178
INFO:root:current train perplexity4.66165828704834
INFO:root:current mean train loss 3902.1894556375964
INFO:root:current train perplexity4.658891677856445
INFO:root:current mean train loss 3902.9494911294382
INFO:root:current train perplexity4.663696765899658
INFO:root:current mean train loss 3902.871837708533
INFO:root:current train perplexity4.665503025054932
INFO:root:current mean train loss 3905.513049219635
INFO:root:current train perplexity4.667456150054932
INFO:root:current mean train loss 3907.744958235313
INFO:root:current train perplexity4.667505264282227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it]
INFO:root:final mean train loss: 3905.638102439142
INFO:root:final train perplexity: 4.668730735778809
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3877.736480496454
INFO:root:eval perplexity: 4.797249794006348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 4743.315369085217
INFO:root:eval perplexity: 6.956015110015869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/24
 12%|â–ˆâ–        | 24/200 [3:58:23<29:03:43, 594.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3893.1132061298076
INFO:root:current train perplexity4.629566669464111
INFO:root:current mean train loss 3859.284607892261
INFO:root:current train perplexity4.58263635635376
INFO:root:current mean train loss 3869.494837810084
INFO:root:current train perplexity4.603739261627197
INFO:root:current mean train loss 3876.9827871493367
INFO:root:current train perplexity4.616555213928223
INFO:root:current mean train loss 3882.8880453634165
INFO:root:current train perplexity4.625505447387695
INFO:root:current mean train loss 3880.741956991593
INFO:root:current train perplexity4.618015289306641
INFO:root:current mean train loss 3879.735856449552
INFO:root:current train perplexity4.6204633712768555
INFO:root:current mean train loss 3885.538373288855
INFO:root:current train perplexity4.626367568969727
INFO:root:current mean train loss 3884.3183854057065
INFO:root:current train perplexity4.62877893447876
INFO:root:current mean train loss 3885.9233245695636
INFO:root:current train perplexity4.627236366271973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.46s/it]
INFO:root:final mean train loss: 3882.9809331586284
INFO:root:final train perplexity: 4.627183437347412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 3863.470246010638
INFO:root:eval perplexity: 4.769655704498291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4731.243558843085
INFO:root:eval perplexity: 6.9217634201049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/25
 12%|â–ˆâ–Ž        | 25/200 [4:08:15<28:52:01, 593.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3880.735995205966
INFO:root:current train perplexity4.580531120300293
INFO:root:current mean train loss 3880.142522917321
INFO:root:current train perplexity4.5971903800964355
INFO:root:current mean train loss 3862.4918282295152
INFO:root:current train perplexity4.579527378082275
INFO:root:current mean train loss 3855.639404908756
INFO:root:current train perplexity4.576744556427002
INFO:root:current mean train loss 3856.8994982151803
INFO:root:current train perplexity4.57741641998291
INFO:root:current mean train loss 3860.081885743818
INFO:root:current train perplexity4.573431491851807
INFO:root:current mean train loss 3862.8300278299357
INFO:root:current train perplexity4.580708026885986
INFO:root:current mean train loss 3863.075833011479
INFO:root:current train perplexity4.580865859985352
INFO:root:current mean train loss 3861.1676404229524
INFO:root:current train perplexity4.57964563369751

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.07s/it]
INFO:root:final mean train loss: 3856.4191871150847
INFO:root:final train perplexity: 4.578946113586426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 3864.3033092309397
INFO:root:eval perplexity: 4.7712626457214355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 4735.654402496121
INFO:root:eval perplexity: 6.934257984161377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/26
 13%|â–ˆâ–Ž        | 26/200 [4:18:06<28:39:05, 592.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3743.1251395089284
INFO:root:current train perplexity4.522102355957031
INFO:root:current mean train loss 3791.9634519202687
INFO:root:current train perplexity4.488720417022705
INFO:root:current mean train loss 3811.147114187047
INFO:root:current train perplexity4.512824535369873
INFO:root:current mean train loss 3820.582486130904
INFO:root:current train perplexity4.518980026245117
INFO:root:current mean train loss 3828.229735128417
INFO:root:current train perplexity4.523469924926758
INFO:root:current mean train loss 3828.9577925642566
INFO:root:current train perplexity4.5260396003723145
INFO:root:current mean train loss 3825.4642746248196
INFO:root:current train perplexity4.521554470062256
INFO:root:current mean train loss 3825.4399597081638
INFO:root:current train perplexity4.521744251251221
INFO:root:current mean train loss 3828.567789411013
INFO:root:current train perplexity4.523865699768066
INFO:root:current mean train loss 3829.9474712737733
INFO:root:current train perplexity4.52536678314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.13s/it]
INFO:root:final mean train loss: 3828.691875334709
INFO:root:final train perplexity: 4.5291290283203125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3846.013410419437
INFO:root:eval perplexity: 4.736104488372803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 4722.825894835993
INFO:root:eval perplexity: 6.89797830581665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/27
 14%|â–ˆâ–Ž        | 27/200 [4:27:57<28:28:05, 592.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3808.6606282552084
INFO:root:current train perplexity4.4710588455200195
INFO:root:current mean train loss 3800.6654594089673
INFO:root:current train perplexity4.4731340408325195
INFO:root:current mean train loss 3785.872216796875
INFO:root:current train perplexity4.465413570404053
INFO:root:current mean train loss 3790.7767973400296
INFO:root:current train perplexity4.468553066253662
INFO:root:current mean train loss 3798.4119870105424
INFO:root:current train perplexity4.475105285644531
INFO:root:current mean train loss 3802.8565936931127
INFO:root:current train perplexity4.477211952209473
INFO:root:current mean train loss 3798.60667357406
INFO:root:current train perplexity4.472807884216309
INFO:root:current mean train loss 3803.5503660402096
INFO:root:current train perplexity4.4847307205200195
INFO:root:current mean train loss 3806.3987595259778
INFO:root:current train perplexity4.487980842590332
INFO:root:current mean train loss 3808.7583882983263
INFO:root:current train perplexity4.492281436920166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.78s/it]
INFO:root:final mean train loss: 3807.2876332806004
INFO:root:final train perplexity: 4.491044044494629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3823.1611674423757
INFO:root:eval perplexity: 4.692540168762207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4702.394219581117
INFO:root:eval perplexity: 6.8405866622924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/28
 14%|â–ˆâ–        | 28/200 [4:37:50<28:18:43, 592.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3816.930918817935
INFO:root:current train perplexity4.481032371520996
INFO:root:current mean train loss 3786.8074147294205
INFO:root:current train perplexity4.4356207847595215
INFO:root:current mean train loss 3792.4640292180493
INFO:root:current train perplexity4.448392868041992
INFO:root:current mean train loss 3785.8073027525156
INFO:root:current train perplexity4.44866418838501
INFO:root:current mean train loss 3792.411163979388
INFO:root:current train perplexity4.453397750854492
INFO:root:current mean train loss 3795.953338331292
INFO:root:current train perplexity4.453607082366943
INFO:root:current mean train loss 3788.144807524704
INFO:root:current train perplexity4.446813583374023
INFO:root:current mean train loss 3787.503555741053
INFO:root:current train perplexity4.449075698852539
INFO:root:current mean train loss 3788.255932350205
INFO:root:current train perplexity4.448365211486816
INFO:root:current mean train loss 3789.121024977993
INFO:root:current train perplexity4.450509548187256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.76s/it]
INFO:root:final mean train loss: 3784.6302539456274
INFO:root:final train perplexity: 4.451076984405518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3804.948948636968
INFO:root:eval perplexity: 4.658108711242676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4681.219773312832
INFO:root:eval perplexity: 6.781613826751709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/29
 14%|â–ˆâ–        | 29/200 [4:47:41<28:07:03, 591.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.4329558341733
INFO:root:current train perplexity4.4408793449401855
INFO:root:current mean train loss 3774.3242932967555
INFO:root:current train perplexity4.412954807281494
INFO:root:current mean train loss 3760.5678922314664
INFO:root:current train perplexity4.4155402183532715
INFO:root:current mean train loss 3761.103851226161
INFO:root:current train perplexity4.4028239250183105
INFO:root:current mean train loss 3760.458416790531
INFO:root:current train perplexity4.4050750732421875
INFO:root:current mean train loss 3767.2733873845045
INFO:root:current train perplexity4.415650367736816
INFO:root:current mean train loss 3768.9481934367573
INFO:root:current train perplexity4.416401386260986
INFO:root:current mean train loss 3767.6095399869614
INFO:root:current train perplexity4.414332866668701
INFO:root:current mean train loss 3769.4329482903695
INFO:root:current train perplexity4.420629024505615
INFO:root:current mean train loss 3769.1062981987616
INFO:root:current train perplexity4.417531967163086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.47s/it]
INFO:root:final mean train loss: 3765.336247351862
INFO:root:final train perplexity: 4.417324542999268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 3810.0363959995566
INFO:root:eval perplexity: 4.667701721191406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4688.206989694149
INFO:root:eval perplexity: 6.801017761230469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/30
 15%|â–ˆâ–Œ        | 30/200 [4:57:33<27:57:54, 592.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3741.5357196514424
INFO:root:current train perplexity4.347898006439209
INFO:root:current mean train loss 3730.371007686039
INFO:root:current train perplexity4.356368064880371
INFO:root:current mean train loss 3735.0674910924427
INFO:root:current train perplexity4.349825382232666
INFO:root:current mean train loss 3737.1504676841355
INFO:root:current train perplexity4.358215808868408
INFO:root:current mean train loss 3735.946866324388
INFO:root:current train perplexity4.360542297363281
INFO:root:current mean train loss 3738.6957237795687
INFO:root:current train perplexity4.370295524597168
INFO:root:current mean train loss 3740.406045976379
INFO:root:current train perplexity4.373065948486328
INFO:root:current mean train loss 3740.0720565031925
INFO:root:current train perplexity4.374068737030029
INFO:root:current mean train loss 3744.7193316890457
INFO:root:current train perplexity4.376489639282227
INFO:root:current mean train loss 3745.0774209181977
INFO:root:current train perplexity4.376208305358887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.79s/it]
INFO:root:final mean train loss: 3742.545903482745
INFO:root:final train perplexity: 4.37778377532959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3799.9320094331783
INFO:root:eval perplexity: 4.648669242858887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 4684.412029726285
INFO:root:eval perplexity: 6.790472507476807
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/31
 16%|â–ˆâ–Œ        | 31/200 [5:07:25<27:47:53, 592.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3761.466267037899
INFO:root:current train perplexity4.384364128112793
INFO:root:current mean train loss 3733.624795719069
INFO:root:current train perplexity4.345513820648193
INFO:root:current mean train loss 3732.2876579500885
INFO:root:current train perplexity4.33723258972168
INFO:root:current mean train loss 3721.170054147154
INFO:root:current train perplexity4.32985782623291
INFO:root:current mean train loss 3725.665715228258
INFO:root:current train perplexity4.338429927825928
INFO:root:current mean train loss 3722.9242271409394
INFO:root:current train perplexity4.338931083679199
INFO:root:current mean train loss 3724.3551921579165
INFO:root:current train perplexity4.342811107635498
INFO:root:current mean train loss 3726.1810595245565
INFO:root:current train perplexity4.346816062927246
INFO:root:current mean train loss 3727.0107591937535
INFO:root:current train perplexity4.346617221832275
INFO:root:current mean train loss 3727.512521294631
INFO:root:current train perplexity4.3492655754089355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.78s/it]
INFO:root:final mean train loss: 3727.414691925049
INFO:root:final train perplexity: 4.3517279624938965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3792.6470176750886
INFO:root:eval perplexity: 4.634994983673096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 4681.164201019504
INFO:root:eval perplexity: 6.781459331512451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/32
 16%|â–ˆâ–Œ        | 32/200 [5:17:16<27:36:29, 591.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3740.290256569602
INFO:root:current train perplexity4.361327648162842
INFO:root:current mean train loss 3726.2388152091735
INFO:root:current train perplexity4.323040962219238
INFO:root:current mean train loss 3712.863304227941
INFO:root:current train perplexity4.326918125152588
INFO:root:current mean train loss 3708.680078125
INFO:root:current train perplexity4.321959972381592
INFO:root:current mean train loss 3712.703665328812
INFO:root:current train perplexity4.321797847747803
INFO:root:current mean train loss 3707.518767155828
INFO:root:current train perplexity4.3174238204956055
INFO:root:current mean train loss 3709.193029132872
INFO:root:current train perplexity4.316962718963623
INFO:root:current mean train loss 3711.0188408655836
INFO:root:current train perplexity4.321865558624268
INFO:root:current mean train loss 3711.013196157712
INFO:root:current train perplexity4.319324970245361
INFO:root:current mean train loss 3710.231768958606
INFO:root:current train perplexity4.316593647003174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.85s/it]
INFO:root:final mean train loss: 3708.282963414346
INFO:root:final train perplexity: 4.319004058837891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 3790.2836048315603
INFO:root:eval perplexity: 4.6305670738220215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4681.966320714207
INFO:root:eval perplexity: 6.783684253692627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/33
 16%|â–ˆâ–‹        | 33/200 [5:27:13<27:30:59, 593.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.1119210379466
INFO:root:current train perplexity4.311652660369873
INFO:root:current mean train loss 3689.0265604030865
INFO:root:current train perplexity4.300153732299805
INFO:root:current mean train loss 3681.928543845057
INFO:root:current train perplexity4.2926201820373535
INFO:root:current mean train loss 3680.2420973764633
INFO:root:current train perplexity4.280729293823242
INFO:root:current mean train loss 3676.5539034025714
INFO:root:current train perplexity4.269664287567139
INFO:root:current mean train loss 3683.0760309412467
INFO:root:current train perplexity4.274782180786133
INFO:root:current mean train loss 3689.4539435891543
INFO:root:current train perplexity4.282840728759766
INFO:root:current mean train loss 3693.5776184801975
INFO:root:current train perplexity4.286435127258301
INFO:root:current mean train loss 3694.34584315931
INFO:root:current train perplexity4.287022113800049
INFO:root:current mean train loss 3692.3650409385546
INFO:root:current train perplexity4.287334442138672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.85s/it]
INFO:root:final mean train loss: 3689.2368215130223
INFO:root:final train perplexity: 4.286672115325928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 3777.1463198830897
INFO:root:eval perplexity: 4.606033802032471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 4664.607889378324
INFO:root:eval perplexity: 6.735702991485596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/34
 17%|â–ˆâ–‹        | 34/200 [5:36:59<27:15:09, 591.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3655.050516477773
INFO:root:current train perplexity4.240818977355957
INFO:root:current mean train loss 3657.8425035978617
INFO:root:current train perplexity4.244726181030273
INFO:root:current mean train loss 3666.766905161727
INFO:root:current train perplexity4.248660564422607
INFO:root:current mean train loss 3666.6681029944407
INFO:root:current train perplexity4.250648021697998
INFO:root:current mean train loss 3676.8233950993563
INFO:root:current train perplexity4.260919570922852
INFO:root:current mean train loss 3670.936748765187
INFO:root:current train perplexity4.258504390716553
INFO:root:current mean train loss 3669.834054961112
INFO:root:current train perplexity4.25486421585083
INFO:root:current mean train loss 3673.238110256566
INFO:root:current train perplexity4.256503582000732
INFO:root:current mean train loss 3672.5459850499606
INFO:root:current train perplexity4.254575729370117
INFO:root:current mean train loss 3674.1187551795024
INFO:root:current train perplexity4.256134986877441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.78s/it]
INFO:root:final mean train loss: 3670.5243449672575
INFO:root:final train perplexity: 4.255141735076904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 3772.066574204898
INFO:root:eval perplexity: 4.59658145904541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 4669.392500207779
INFO:root:eval perplexity: 6.748895645141602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/35
 18%|â–ˆâ–Š        | 35/200 [5:46:50<27:06:04, 591.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3678.3208625890034
INFO:root:current train perplexity4.211526870727539
INFO:root:current mean train loss 3646.540954248865
INFO:root:current train perplexity4.200873374938965
INFO:root:current mean train loss 3645.1544911374326
INFO:root:current train perplexity4.208771705627441
INFO:root:current mean train loss 3664.2028228840286
INFO:root:current train perplexity4.235917091369629
INFO:root:current mean train loss 3663.028912060445
INFO:root:current train perplexity4.2249345779418945
INFO:root:current mean train loss 3656.5908915728896
INFO:root:current train perplexity4.225274562835693
INFO:root:current mean train loss 3656.960784327826
INFO:root:current train perplexity4.223982334136963
INFO:root:current mean train loss 3658.4849638834844
INFO:root:current train perplexity4.224061012268066
INFO:root:current mean train loss 3659.0271687686645
INFO:root:current train perplexity4.2238969802856445
INFO:root:current mean train loss 3656.75920602177
INFO:root:current train perplexity4.2255120277404785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it]
INFO:root:final mean train loss: 3652.8695665790187
INFO:root:final train perplexity: 4.2256059646606445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3761.064023714539
INFO:root:eval perplexity: 4.57617712020874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 4663.91091810727
INFO:root:eval perplexity: 6.733784198760986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/36
 18%|â–ˆâ–Š        | 36/200 [5:56:43<26:57:20, 591.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.4888873922414
INFO:root:current train perplexity4.203274250030518
INFO:root:current mean train loss 3643.3443962545957
INFO:root:current train perplexity4.195465087890625
INFO:root:current mean train loss 3642.1865344961348
INFO:root:current train perplexity4.192159652709961
INFO:root:current mean train loss 3636.1060945574936
INFO:root:current train perplexity4.189108371734619
INFO:root:current mean train loss 3644.902307153972
INFO:root:current train perplexity4.198908805847168
INFO:root:current mean train loss 3637.1674280637776
INFO:root:current train perplexity4.193990707397461
INFO:root:current mean train loss 3640.204669447098
INFO:root:current train perplexity4.1999430656433105
INFO:root:current mean train loss 3637.8673832468035
INFO:root:current train perplexity4.196591854095459
INFO:root:current mean train loss 3639.459286041432
INFO:root:current train perplexity4.19729471206665
INFO:root:current mean train loss 3640.340357014232
INFO:root:current train perplexity4.200099945068359

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.86s/it]
INFO:root:final mean train loss: 3637.6402065523207
INFO:root:final train perplexity: 4.200293064117432
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it]
INFO:root:eval mean loss: 3745.640735815603
INFO:root:eval perplexity: 4.547724723815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4646.723909851507
INFO:root:eval perplexity: 6.686624526977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/37
 18%|â–ˆâ–Š        | 37/200 [6:06:36<26:48:40, 592.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3642.629864823191
INFO:root:current train perplexity4.183741092681885
INFO:root:current mean train loss 3613.3348595252405
INFO:root:current train perplexity4.169658184051514
INFO:root:current mean train loss 3617.8008433196505
INFO:root:current train perplexity4.164327144622803
INFO:root:current mean train loss 3619.1289742385284
INFO:root:current train perplexity4.164906978607178
INFO:root:current mean train loss 3626.9661566840277
INFO:root:current train perplexity4.168942451477051
INFO:root:current mean train loss 3626.762259962579
INFO:root:current train perplexity4.174705982208252
INFO:root:current mean train loss 3626.3819659116457
INFO:root:current train perplexity4.174437046051025
INFO:root:current mean train loss 3626.03958671138
INFO:root:current train perplexity4.171425819396973
INFO:root:current mean train loss 3624.9818015668643
INFO:root:current train perplexity4.170871734619141

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.32s/it]
INFO:root:final mean train loss: 3620.988852777789
INFO:root:final train perplexity: 4.172790050506592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 3733.670404961769
INFO:root:eval perplexity: 4.5257649421691895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 4636.5166864056955
INFO:root:eval perplexity: 6.658774375915527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/38
 19%|â–ˆâ–‰        | 38/200 [6:16:30<26:40:11, 592.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.3633626302085
INFO:root:current train perplexity4.277990341186523
INFO:root:current mean train loss 3618.294101752124
INFO:root:current train perplexity4.15073299407959
INFO:root:current mean train loss 3606.4399847021245
INFO:root:current train perplexity4.139463901519775
INFO:root:current mean train loss 3604.485888994173
INFO:root:current train perplexity4.140233993530273
INFO:root:current mean train loss 3607.459711344603
INFO:root:current train perplexity4.147083282470703
INFO:root:current mean train loss 3598.9352600219
INFO:root:current train perplexity4.13651704788208
INFO:root:current mean train loss 3598.6778550282443
INFO:root:current train perplexity4.136904716491699
INFO:root:current mean train loss 3605.1273104801967
INFO:root:current train perplexity4.144392490386963
INFO:root:current mean train loss 3605.912549314582
INFO:root:current train perplexity4.143019676208496
INFO:root:current mean train loss 3608.6883100169575
INFO:root:current train perplexity4.147619247436523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.86s/it]
INFO:root:final mean train loss: 3606.916644065611
INFO:root:final train perplexity: 4.14968729019165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3720.258782136525
INFO:root:eval perplexity: 4.501287460327148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4626.7761161209
INFO:root:eval perplexity: 6.63230562210083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/39
 20%|â–ˆâ–‰        | 39/200 [6:26:26<26:32:43, 593.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.09130859375
INFO:root:current train perplexity4.140161514282227
INFO:root:current mean train loss 3590.296094189893
INFO:root:current train perplexity4.098191261291504
INFO:root:current mean train loss 3581.763615178836
INFO:root:current train perplexity4.095033645629883
INFO:root:current mean train loss 3587.5257352479402
INFO:root:current train perplexity4.1091742515563965
INFO:root:current mean train loss 3596.6009067062046
INFO:root:current train perplexity4.115161895751953
INFO:root:current mean train loss 3604.984955968689
INFO:root:current train perplexity4.128659725189209
INFO:root:current mean train loss 3601.9619640094365
INFO:root:current train perplexity4.125174045562744
INFO:root:current mean train loss 3601.4015254840233
INFO:root:current train perplexity4.125399589538574
INFO:root:current mean train loss 3599.7666626729156
INFO:root:current train perplexity4.126453399658203
INFO:root:current mean train loss 3599.4049939219435
INFO:root:current train perplexity4.127613544464111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.50s/it]
INFO:root:final mean train loss: 3592.823987899288
INFO:root:final train perplexity: 4.126679420471191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3756.949007507757
INFO:root:eval perplexity: 4.568568229675293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4662.180196559176
INFO:root:eval perplexity: 6.7290191650390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/40
 20%|â–ˆâ–ˆ        | 40/200 [6:36:19<26:22:22, 593.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3542.6072291324012
INFO:root:current train perplexity4.110811710357666
INFO:root:current mean train loss 3563.576561679359
INFO:root:current train perplexity4.0959882736206055
INFO:root:current mean train loss 3574.6050183718608
INFO:root:current train perplexity4.108375549316406
INFO:root:current mean train loss 3570.3233187206115
INFO:root:current train perplexity4.0985026359558105
INFO:root:current mean train loss 3580.6762974996273
INFO:root:current train perplexity4.101724147796631
INFO:root:current mean train loss 3580.918643311958
INFO:root:current train perplexity4.106515884399414
INFO:root:current mean train loss 3582.0098385910997
INFO:root:current train perplexity4.101191997528076
INFO:root:current mean train loss 3580.412862509779
INFO:root:current train perplexity4.099767684936523
INFO:root:current mean train loss 3582.3614211309523
INFO:root:current train perplexity4.102747917175293
INFO:root:current mean train loss 3581.50793789105
INFO:root:current train perplexity4.104121208190918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.21s/it]
INFO:root:final mean train loss: 3578.56791797761
INFO:root:final train perplexity: 4.10353422164917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3712.560462031804
INFO:root:eval perplexity: 4.4872965812683105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 4623.193525598404
INFO:root:eval perplexity: 6.62259578704834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/41
 20%|â–ˆâ–ˆ        | 41/200 [6:46:13<26:12:43, 593.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3552.5412326388887
INFO:root:current train perplexity4.053650379180908
INFO:root:current mean train loss 3587.902907003568
INFO:root:current train perplexity4.090010166168213
INFO:root:current mean train loss 3587.4978048853936
INFO:root:current train perplexity4.095562934875488
INFO:root:current mean train loss 3581.1569742091933
INFO:root:current train perplexity4.085353374481201
INFO:root:current mean train loss 3578.5045300378733
INFO:root:current train perplexity4.084033966064453
INFO:root:current mean train loss 3577.2956408621917
INFO:root:current train perplexity4.086908340454102
INFO:root:current mean train loss 3578.1119250429874
INFO:root:current train perplexity4.087901592254639
INFO:root:current mean train loss 3574.8880203855742
INFO:root:current train perplexity4.086738586425781
INFO:root:current mean train loss 3573.1489620923708
INFO:root:current train perplexity4.084143161773682
INFO:root:current mean train loss 3567.793227902508
INFO:root:current train perplexity4.080998420715332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.07s/it]
INFO:root:final mean train loss: 3563.9640531847554
INFO:root:final train perplexity: 4.079959392547607
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3745.850939162234
INFO:root:eval perplexity: 4.548111915588379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 4660.443735109154
INFO:root:eval perplexity: 6.724244117736816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/42
 21%|â–ˆâ–ˆ        | 42/200 [6:56:04<26:01:19, 592.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.3968191964286
INFO:root:current train perplexity4.047154426574707
INFO:root:current mean train loss 3523.8021647135415
INFO:root:current train perplexity4.030789375305176
INFO:root:current mean train loss 3538.7000966173537
INFO:root:current train perplexity4.039968967437744
INFO:root:current mean train loss 3546.3348341301307
INFO:root:current train perplexity4.055502414703369
INFO:root:current mean train loss 3545.020695267601
INFO:root:current train perplexity4.049383640289307
INFO:root:current mean train loss 3547.442498265917
INFO:root:current train perplexity4.051413059234619
INFO:root:current mean train loss 3552.20426996186
INFO:root:current train perplexity4.0553107261657715
INFO:root:current mean train loss 3549.910498046875
INFO:root:current train perplexity4.051941394805908
INFO:root:current mean train loss 3550.604066184038
INFO:root:current train perplexity4.0555291175842285
INFO:root:current mean train loss 3556.817872660428
INFO:root:current train perplexity4.062592029571533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.12s/it]
INFO:root:final mean train loss: 3553.118409987419
INFO:root:final train perplexity: 4.062538146972656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3708.111151512633
INFO:root:eval perplexity: 4.4792304039001465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4619.197663868573
INFO:root:eval perplexity: 6.6117844581604
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:05:59<25:53:05, 593.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3511.7528274890988
INFO:root:current train perplexity3.9806861877441406
INFO:root:current mean train loss 3529.0303144121503
INFO:root:current train perplexity4.006807804107666
INFO:root:current mean train loss 3533.835361810378
INFO:root:current train perplexity4.019233703613281
INFO:root:current mean train loss 3538.457399240388
INFO:root:current train perplexity4.029280185699463
INFO:root:current mean train loss 3544.5867795922686
INFO:root:current train perplexity4.036733627319336
INFO:root:current mean train loss 3556.489682248504
INFO:root:current train perplexity4.068355560302734
INFO:root:current mean train loss 3607.3380018741495
INFO:root:current train perplexity4.149057388305664
INFO:root:current mean train loss 3653.1103325044164
INFO:root:current train perplexity4.220920562744141
INFO:root:current mean train loss 3683.025001969343
INFO:root:current train perplexity4.270168304443359
INFO:root:current mean train loss 3703.0100656875497
INFO:root:current train perplexity4.301815509796143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.47s/it]
INFO:root:final mean train loss: 3705.006695408975
INFO:root:final train perplexity: 4.313425540924072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 3841.1176740497563
INFO:root:eval perplexity: 4.726737976074219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 4754.757852324357
INFO:root:eval perplexity: 6.988637447357178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:15:56<25:45:59, 594.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.1426786534926
INFO:root:current train perplexity4.524978160858154
INFO:root:current mean train loss 3827.3424985771935
INFO:root:current train perplexity4.526073932647705
INFO:root:current mean train loss 3803.9341520636203
INFO:root:current train perplexity4.494596004486084
INFO:root:current mean train loss 3794.069515391293
INFO:root:current train perplexity4.472520351409912
INFO:root:current mean train loss 3793.399396198552
INFO:root:current train perplexity4.471956729888916
INFO:root:current mean train loss 3789.2460955223455
INFO:root:current train perplexity4.460438251495361
INFO:root:current mean train loss 3783.321249309956
INFO:root:current train perplexity4.446992874145508
INFO:root:current mean train loss 3779.4392915565704
INFO:root:current train perplexity4.4383931159973145
INFO:root:current mean train loss 3780.4674894196164
INFO:root:current train perplexity4.437413692474365
INFO:root:current mean train loss 3777.544386870728
INFO:root:current train perplexity4.430976867675781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.99s/it]
INFO:root:final mean train loss: 3787.6863053844822
INFO:root:final train perplexity: 4.456447124481201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3852.8352864583335
INFO:root:eval perplexity: 4.7491865158081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 4768.867265417221
INFO:root:eval perplexity: 7.029077529907227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:25:52<25:36:41, 594.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7219.015144994703
INFO:root:current train perplexity16.77720069885254
INFO:root:current mean train loss 9351.24085931358
INFO:root:current train perplexity39.61015319824219
INFO:root:current mean train loss 10875.996409530346
INFO:root:current train perplexity72.86125946044922
INFO:root:current mean train loss 9118.736481137927
INFO:root:current train perplexity36.37782287597656
INFO:root:current mean train loss 8088.913434861792
INFO:root:current train perplexity24.15018653869629
INFO:root:current mean train loss 7407.3406639576815
INFO:root:current train perplexity18.491426467895508
INFO:root:current mean train loss 6918.757349040331
INFO:root:current train perplexity15.30936336517334
INFO:root:current mean train loss 6561.109376929965
INFO:root:current train perplexity13.308999061584473
INFO:root:current mean train loss 6285.992711308117
INFO:root:current train perplexity11.934703826904297
INFO:root:current mean train loss 6071.156399692062
INFO:root:current train perplexity10.950928688049316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.25s/it]
INFO:root:final mean train loss: 6006.085196033601
INFO:root:final train perplexity: 10.692839622497559
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 4151.136162940492
INFO:root:eval perplexity: 5.358036518096924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 5049.751438871343
INFO:root:eval perplexity: 7.884610176086426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [7:35:47<25:26:58, 594.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4168.153017869637
INFO:root:current train perplexity5.166182994842529
INFO:root:current mean train loss 4142.695349047998
INFO:root:current train perplexity5.137831211090088
INFO:root:current mean train loss 4134.420722875702
INFO:root:current train perplexity5.127760887145996
INFO:root:current mean train loss 4118.20594825017
INFO:root:current train perplexity5.086248397827148
INFO:root:current mean train loss 4096.066032981465
INFO:root:current train perplexity5.046566009521484
INFO:root:current mean train loss 4098.960081500772
INFO:root:current train perplexity5.046464443206787
INFO:root:current mean train loss 4109.735006764196
INFO:root:current train perplexity5.061172008514404
INFO:root:current mean train loss 4124.415054977795
INFO:root:current train perplexity5.079334259033203
INFO:root:current mean train loss 4142.485726643598
INFO:root:current train perplexity5.112878322601318
INFO:root:current mean train loss 4155.095553661453
INFO:root:current train perplexity5.14486837387085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.06s/it]
INFO:root:final mean train loss: 4156.498138981481
INFO:root:final train perplexity: 5.154441833496094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 4199.924785641068
INFO:root:eval perplexity: 5.464792728424072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 5075.743879169437
INFO:root:eval perplexity: 7.968860626220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:45:41<25:16:48, 594.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4451.538567708333
INFO:root:current train perplexity5.753137588500977
INFO:root:current mean train loss 4502.449765625
INFO:root:current train perplexity5.915197372436523
INFO:root:current mean train loss 4491.196246448863
INFO:root:current train perplexity5.903672218322754
INFO:root:current mean train loss 4465.182552083334
INFO:root:current train perplexity5.8298726081848145
INFO:root:current mean train loss 4446.803533100329
INFO:root:current train perplexity5.775858402252197
INFO:root:current mean train loss 4425.820830502717
INFO:root:current train perplexity5.716640949249268
INFO:root:current mean train loss 4398.293038194444
INFO:root:current train perplexity5.650647163391113
INFO:root:current mean train loss 4461.847818800403
INFO:root:current train perplexity5.799524307250977
INFO:root:current mean train loss 5041.83580859375
INFO:root:current train perplexity7.2942304611206055
INFO:root:current mean train loss 4997.824836488381
INFO:root:current train perplexity7.171199798583984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.56s/it]
INFO:root:final mean train loss: 4985.266752673733
INFO:root:final train perplexity: 7.14799690246582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 4253.726934771165
INFO:root:eval perplexity: 5.584989547729492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 5117.74755859375
INFO:root:eval perplexity: 8.106917381286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/48
 24%|â–ˆâ–ˆâ–       | 48/200 [7:55:31<25:03:05, 593.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4397.29932523061
INFO:root:current train perplexity5.673640251159668
INFO:root:current mean train loss 4379.956540300546
INFO:root:current train perplexity5.634706497192383
INFO:root:current mean train loss 4400.152658631018
INFO:root:current train perplexity5.665140628814697
INFO:root:current mean train loss 4406.475359007833
INFO:root:current train perplexity5.683124542236328
INFO:root:current mean train loss 4405.021444948564
INFO:root:current train perplexity5.692493438720703
INFO:root:current mean train loss 4416.403318637435
INFO:root:current train perplexity5.712479114532471
INFO:root:current mean train loss 4425.160472596198
INFO:root:current train perplexity5.729547500610352
INFO:root:current mean train loss 4441.654903640844
INFO:root:current train perplexity5.767975330352783
INFO:root:current mean train loss 4449.4349051418285
INFO:root:current train perplexity5.783776760101318
INFO:root:current mean train loss 4457.129250480831
INFO:root:current train perplexity5.795788288116455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.16s/it]
INFO:root:final mean train loss: 4453.927412586828
INFO:root:final train perplexity: 5.796204090118408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 4284.562498268506
INFO:root:eval perplexity: 5.655063629150391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 5122.134369112921
INFO:root:eval perplexity: 8.121468544006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:05:23<24:52:00, 592.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4541.699006803743
INFO:root:current train perplexity5.990977764129639
INFO:root:current mean train loss 4572.496979558655
INFO:root:current train perplexity6.035268783569336
INFO:root:current mean train loss 4583.142787867805
INFO:root:current train perplexity6.060047626495361
INFO:root:current mean train loss 4597.7910555866365
INFO:root:current train perplexity6.09635591506958
INFO:root:current mean train loss 4604.788915319501
INFO:root:current train perplexity6.115024089813232
INFO:root:current mean train loss 4602.028725561152
INFO:root:current train perplexity6.117023944854736
INFO:root:current mean train loss 4604.967313421445
INFO:root:current train perplexity6.137396812438965
INFO:root:current mean train loss 4614.978560070323
INFO:root:current train perplexity6.164630889892578
INFO:root:current mean train loss 4612.874013025217
INFO:root:current train perplexity6.161459922790527
INFO:root:current mean train loss 4611.44876249527
INFO:root:current train perplexity6.1590399742126465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.27s/it]
INFO:root:final mean train loss: 4607.878649311681
INFO:root:final train perplexity: 6.15916633605957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 4282.9130894004875
INFO:root:eval perplexity: 5.65129280090332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 5124.791763630319
INFO:root:eval perplexity: 8.130301475524902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:15:16<24:42:18, 592.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4515.064191721906
INFO:root:current train perplexity5.913876533508301
INFO:root:current mean train loss 4482.140982009658
INFO:root:current train perplexity5.854228496551514
INFO:root:current mean train loss 4467.48915329745
INFO:root:current train perplexity5.82752799987793
INFO:root:current mean train loss 4477.464900043076
INFO:root:current train perplexity5.830208778381348
INFO:root:current mean train loss 4474.348213027618
INFO:root:current train perplexity5.837742328643799
INFO:root:current mean train loss 4473.2627079474905
INFO:root:current train perplexity5.838568687438965
INFO:root:current mean train loss 4472.557629761266
INFO:root:current train perplexity5.837500095367432
INFO:root:current mean train loss 4469.836855395416
INFO:root:current train perplexity5.832080841064453
INFO:root:current mean train loss 4467.503552123888
INFO:root:current train perplexity5.823431491851807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.25s/it]
INFO:root:final mean train loss: 4465.626876954109
INFO:root:final train perplexity: 5.823021411895752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 4249.037528396499
INFO:root:eval perplexity: 5.574408054351807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 5106.067973251884
INFO:root:eval perplexity: 8.068288803100586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [8:25:13<24:35:51, 594.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4478.008858816965
INFO:root:current train perplexity5.878280162811279
INFO:root:current mean train loss 4435.107488043955
INFO:root:current train perplexity5.728884696960449
INFO:root:current mean train loss 4446.255682461504
INFO:root:current train perplexity5.769435882568359
INFO:root:current mean train loss 4459.006944886248
INFO:root:current train perplexity5.793729305267334
INFO:root:current mean train loss 4448.098508642698
INFO:root:current train perplexity5.771189212799072
INFO:root:current mean train loss 4447.460195447331
INFO:root:current train perplexity5.753842830657959
INFO:root:current mean train loss 4446.169870392298
INFO:root:current train perplexity5.755705833435059
INFO:root:current mean train loss 4444.677511298842
INFO:root:current train perplexity5.754432678222656
INFO:root:current mean train loss 4438.118607569509
INFO:root:current train perplexity5.742984771728516
INFO:root:current mean train loss 4437.096811851829
INFO:root:current train perplexity5.739536762237549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.56s/it]
INFO:root:final mean train loss: 4426.111406880041
INFO:root:final train perplexity: 5.732943058013916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 4208.483407094969
INFO:root:eval perplexity: 5.483739376068115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 5087.513100482048
INFO:root:eval perplexity: 8.007305145263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [8:35:08<24:26:06, 594.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4337.4431640625
INFO:root:current train perplexity5.67588996887207
INFO:root:current mean train loss 4529.00390625
INFO:root:current train perplexity6.0210771560668945
INFO:root:current mean train loss 4478.118912381904
INFO:root:current train perplexity5.871719837188721
INFO:root:current mean train loss 4444.21795014881
INFO:root:current train perplexity5.775850772857666
INFO:root:current mean train loss 4421.667889919051
INFO:root:current train perplexity5.713014602661133
INFO:root:current mean train loss 4405.737877825394
INFO:root:current train perplexity5.674680233001709
INFO:root:current mean train loss 4391.54456300813
INFO:root:current train perplexity5.639723300933838
INFO:root:current mean train loss 4379.484010325612
INFO:root:current train perplexity5.616734504699707
INFO:root:current mean train loss 4368.790391643501
INFO:root:current train perplexity5.594024181365967
INFO:root:current mean train loss 4362.369522978569
INFO:root:current train perplexity5.577547550201416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.94s/it]
INFO:root:final mean train loss: 4352.655997614706
INFO:root:final train perplexity: 5.569185256958008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 4158.493726797983
INFO:root:eval perplexity: 5.374001502990723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 5054.787779463099
INFO:root:eval perplexity: 7.900863170623779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [8:44:59<24:13:58, 593.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4203.814845872962
INFO:root:current train perplexity5.391413688659668
INFO:root:current mean train loss 4284.065076378303
INFO:root:current train perplexity5.447123050689697
INFO:root:current mean train loss 4300.661682402607
INFO:root:current train perplexity5.475954532623291
INFO:root:current mean train loss 4320.0382272820725
INFO:root:current train perplexity5.502031326293945
INFO:root:current mean train loss 4319.076224974143
INFO:root:current train perplexity5.494210243225098
INFO:root:current mean train loss 4318.104380153562
INFO:root:current train perplexity5.496888160705566
INFO:root:current mean train loss 4368.474864880116
INFO:root:current train perplexity5.598206520080566
INFO:root:current mean train loss 4445.500767202628
INFO:root:current train perplexity5.773392677307129
INFO:root:current mean train loss 4468.242065874659
INFO:root:current train perplexity5.822173118591309
INFO:root:current mean train loss 4464.9925178701415
INFO:root:current train perplexity5.809651851654053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.86s/it]
INFO:root:final mean train loss: 4464.588078345022
INFO:root:final train perplexity: 5.820634365081787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 4241.787630554632
INFO:root:eval perplexity: 5.558089256286621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 5133.2008792525485
INFO:root:eval perplexity: 8.158303260803223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:54:53<24:04:01, 593.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4410.263238722278
INFO:root:current train perplexity5.687351226806641
INFO:root:current mean train loss 4685.425598610448
INFO:root:current train perplexity6.309657573699951
INFO:root:current mean train loss 5155.642700723755
INFO:root:current train perplexity7.624547958374023
INFO:root:current mean train loss 6076.382148673527
INFO:root:current train perplexity10.925989151000977
INFO:root:current mean train loss 6497.86407314929
INFO:root:current train perplexity12.89974594116211
INFO:root:current mean train loss 7168.766589608345
INFO:root:current train perplexity16.833532333374023
INFO:root:current mean train loss 7492.545831115046
INFO:root:current train perplexity19.141700744628906
INFO:root:current mean train loss 7723.825041680917
INFO:root:current train perplexity20.977407455444336
INFO:root:current mean train loss 7922.342339213861
INFO:root:current train perplexity22.752809524536133
INFO:root:current mean train loss 8066.501576031317
INFO:root:current train perplexity24.068906784057617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.80s/it]
INFO:root:final mean train loss: 8118.2419802758
INFO:root:final train perplexity: 24.603313446044922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 4677.2123538619235
INFO:root:eval perplexity: 6.6281609535217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 5470.254761607935
INFO:root:eval perplexity: 9.363907814025879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:04:47<23:54:24, 593.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8994.335649539264
INFO:root:current train perplexity35.315467834472656
INFO:root:current mean train loss 8939.098998145233
INFO:root:current train perplexity33.71272659301758
INFO:root:current mean train loss 8908.677775235356
INFO:root:current train perplexity33.520442962646484
INFO:root:current mean train loss 8814.008744411412
INFO:root:current train perplexity32.3973274230957
INFO:root:current mean train loss 8538.725511416216
INFO:root:current train perplexity29.011581420898438
INFO:root:current mean train loss 8175.997748833198
INFO:root:current train perplexity25.125755310058594
INFO:root:current mean train loss 7811.733341891628
INFO:root:current train perplexity21.751750946044922
INFO:root:current mean train loss 7481.237763235792
INFO:root:current train perplexity19.091934204101562
INFO:root:current mean train loss 7189.429296991396
INFO:root:current train perplexity17.03192710876465
INFO:root:current mean train loss 6948.040906944721
INFO:root:current train perplexity15.492203712463379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.71s/it]
INFO:root:final mean train loss: 6839.071539848082
INFO:root:final train perplexity: 14.8531494140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 4343.894036042775
INFO:root:eval perplexity: 5.7923808097839355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 5216.631825548538
INFO:root:eval perplexity: 8.441436767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:14:38<23:42:58, 592.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5557.988115026596
INFO:root:current train perplexity8.997142791748047
INFO:root:current mean train loss 6295.339737457483
INFO:root:current train perplexity11.946123123168945
INFO:root:current mean train loss 6818.846068841725
INFO:root:current train perplexity14.667877197265625
INFO:root:current mean train loss 6511.195349085915
INFO:root:current train perplexity12.99444580078125
INFO:root:current mean train loss 6207.342097271742
INFO:root:current train perplexity11.528069496154785
INFO:root:current mean train loss 5985.6808738359805
INFO:root:current train perplexity10.564352035522461
INFO:root:current mean train loss 5805.866784498165
INFO:root:current train perplexity9.847774505615234
INFO:root:current mean train loss 5671.32073737659
INFO:root:current train perplexity9.32887077331543
INFO:root:current mean train loss 5567.515480879206
INFO:root:current train perplexity8.956629753112793
INFO:root:current mean train loss 5480.7252667758385
INFO:root:current train perplexity8.671551704406738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.97s/it]
INFO:root:final mean train loss: 5449.068962589387
INFO:root:final train perplexity: 8.583272933959961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 4306.371242658466
INFO:root:eval perplexity: 5.705153942108154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 5179.382286125887
INFO:root:eval perplexity: 8.313834190368652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [9:24:30<23:32:36, 592.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4903.058931107955
INFO:root:current train perplexity6.821072101593018
INFO:root:current mean train loss 4928.326338835685
INFO:root:current train perplexity6.984561443328857
INFO:root:current mean train loss 4987.242748544731
INFO:root:current train perplexity7.146488189697266
INFO:root:current mean train loss 5045.784047645247
INFO:root:current train perplexity7.305251598358154
INFO:root:current mean train loss 5072.641723901099
INFO:root:current train perplexity7.400111675262451
INFO:root:current mean train loss 5134.8691027942
INFO:root:current train perplexity7.579082012176514
INFO:root:current mean train loss 5177.456271618559
INFO:root:current train perplexity7.704797267913818
INFO:root:current mean train loss 5314.3446709437085
INFO:root:current train perplexity8.141188621520996
INFO:root:current mean train loss 5533.892160087719
INFO:root:current train perplexity8.860151290893555
INFO:root:current mean train loss 5801.799864508344
INFO:root:current train perplexity9.850289344787598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.26s/it]
INFO:root:final mean train loss: 5872.364988142444
INFO:root:final train perplexity: 10.143346786499023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 4531.344411430629
INFO:root:eval perplexity: 6.248507499694824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 5358.933990262079
INFO:root:eval perplexity: 8.947209358215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [9:34:23<23:22:31, 592.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7633.256386408731
INFO:root:current train perplexity20.46947479248047
INFO:root:current mean train loss 7093.136308354103
INFO:root:current train perplexity16.543943405151367
INFO:root:current mean train loss 6558.569699827709
INFO:root:current train perplexity13.347105026245117
INFO:root:current mean train loss 6689.568966027462
INFO:root:current train perplexity14.016653060913086
INFO:root:current mean train loss 6813.952606135259
INFO:root:current train perplexity14.702378273010254
INFO:root:current mean train loss 6967.213698934281
INFO:root:current train perplexity15.632278442382812
INFO:root:current mean train loss 7084.009848846389
INFO:root:current train perplexity16.329002380371094
INFO:root:current mean train loss 7090.20540385915
INFO:root:current train perplexity16.363222122192383
INFO:root:current mean train loss 6975.438937685581
INFO:root:current train perplexity15.645746231079102
INFO:root:current mean train loss 6817.906144028265
INFO:root:current train perplexity14.703710556030273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.97s/it]
INFO:root:final mean train loss: 6767.150268923851
INFO:root:final train perplexity: 14.437612533569336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.92s/it]
INFO:root:eval mean loss: 4480.304761954233
INFO:root:eval perplexity: 6.1208672523498535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 5328.444008685173
INFO:root:eval perplexity: 8.836348533630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [9:44:17<23:14:10, 593.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5916.132289832746
INFO:root:current train perplexity10.353371620178223
INFO:root:current mean train loss 5636.14416860837
INFO:root:current train perplexity9.233931541442871
INFO:root:current mean train loss 5458.952368254151
INFO:root:current train perplexity8.621975898742676
INFO:root:current mean train loss 5341.080949397742
INFO:root:current train perplexity8.215399742126465
INFO:root:current mean train loss 5256.0424255241505
INFO:root:current train perplexity7.9440460205078125
INFO:root:current mean train loss 5201.014780983199
INFO:root:current train perplexity7.758533477783203
INFO:root:current mean train loss 5141.124435311102
INFO:root:current train perplexity7.590734958648682
INFO:root:current mean train loss 5099.426487389551
INFO:root:current train perplexity7.471952438354492
INFO:root:current mean train loss 5063.295517230554
INFO:root:current train perplexity7.363982200622559
INFO:root:current mean train loss 5036.999873278192
INFO:root:current train perplexity7.286238670349121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.04s/it]
INFO:root:final mean train loss: 5029.474980631182
INFO:root:final train perplexity: 7.27376127243042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.75s/it]
INFO:root:eval mean loss: 4370.369303385417
INFO:root:eval perplexity: 5.854724884033203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 5234.223411181294
INFO:root:eval perplexity: 8.502379417419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [9:54:13<23:05:39, 593.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4814.943656052215
INFO:root:current train perplexity6.676724433898926
INFO:root:current mean train loss 4789.503979901362
INFO:root:current train perplexity6.6029767990112305
INFO:root:current mean train loss 4779.372654849911
INFO:root:current train perplexity6.58384370803833
INFO:root:current mean train loss 4781.416734519295
INFO:root:current train perplexity6.6023101806640625
INFO:root:current mean train loss 4786.275045056433
INFO:root:current train perplexity6.613707542419434
INFO:root:current mean train loss 4789.449815819301
INFO:root:current train perplexity6.619515419006348
INFO:root:current mean train loss 4800.1363721350335
INFO:root:current train perplexity6.643548488616943
INFO:root:current mean train loss 4807.108041158536
INFO:root:current train perplexity6.658810138702393
INFO:root:current mean train loss 4806.529122449161
INFO:root:current train perplexity6.654495716094971
INFO:root:current mean train loss 4802.9089392875385
INFO:root:current train perplexity6.643192291259766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.55s/it]
INFO:root:final mean train loss: 4799.6582653907035
INFO:root:final train perplexity: 6.64326810836792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 4363.752839649823
INFO:root:eval perplexity: 5.839081287384033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 5226.934170337434
INFO:root:eval perplexity: 8.477073669433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:04:05<22:54:26, 593.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4967.39187657148
INFO:root:current train perplexity7.13882303237915
INFO:root:current mean train loss 4897.430473450034
INFO:root:current train perplexity6.9045305252075195
INFO:root:current mean train loss 4851.455807144218
INFO:root:current train perplexity6.78617000579834
INFO:root:current mean train loss 4852.115178228964
INFO:root:current train perplexity6.78042459487915
INFO:root:current mean train loss 4856.913508546426
INFO:root:current train perplexity6.793716907501221
INFO:root:current mean train loss 4826.450585022492
INFO:root:current train perplexity6.709511756896973
INFO:root:current mean train loss 4807.774065442481
INFO:root:current train perplexity6.6669416427612305
INFO:root:current mean train loss 4798.5279229247735
INFO:root:current train perplexity6.6424431800842285
INFO:root:current mean train loss 4871.507153292789
INFO:root:current train perplexity6.832388877868652
INFO:root:current mean train loss 4900.954607900757
INFO:root:current train perplexity6.902080535888672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.68s/it]
INFO:root:final mean train loss: 4895.653673602688
INFO:root:final train perplexity: 6.899692535400391
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 4415.6511195838875
INFO:root:eval perplexity: 5.962916374206543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 5286.646842794215
INFO:root:eval perplexity: 8.686610221862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:13:54<22:41:34, 591.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4869.526886307566
INFO:root:current train perplexity6.813851833343506
INFO:root:current mean train loss 5465.657542067308
INFO:root:current train perplexity8.596394538879395
INFO:root:current mean train loss 5392.801991194386
INFO:root:current train perplexity8.355271339416504
INFO:root:current mean train loss 5284.583394729035
INFO:root:current train perplexity8.00406551361084
INFO:root:current mean train loss 5214.714314038826
INFO:root:current train perplexity7.7883124351501465
INFO:root:current mean train loss 5155.80340730042
INFO:root:current train perplexity7.620872974395752
INFO:root:current mean train loss 5113.4927200427155
INFO:root:current train perplexity7.504971027374268
INFO:root:current mean train loss 5078.380275894261
INFO:root:current train perplexity7.4097442626953125
INFO:root:current mean train loss 5054.319610357018
INFO:root:current train perplexity7.335195064544678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.76s/it]
INFO:root:final mean train loss: 5023.365328511884
INFO:root:final train perplexity: 7.256247043609619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.29s/it]
INFO:root:eval mean loss: 4372.396920711436
INFO:root:eval perplexity: 5.859527111053467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 5246.54597116024
INFO:root:eval perplexity: 8.545327186584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [10:23:50<22:34:27, 593.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4782.147786458333
INFO:root:current train perplexity6.062308311462402
INFO:root:current mean train loss 4749.404699825546
INFO:root:current train perplexity6.463498592376709
INFO:root:current mean train loss 4771.185429014009
INFO:root:current train perplexity6.555047988891602
INFO:root:current mean train loss 4766.279752926464
INFO:root:current train perplexity6.545101165771484
INFO:root:current mean train loss 4763.207746709251
INFO:root:current train perplexity6.546095848083496
INFO:root:current mean train loss 4754.846731621987
INFO:root:current train perplexity6.525613307952881
INFO:root:current mean train loss 4746.3605673617585
INFO:root:current train perplexity6.513645648956299
INFO:root:current mean train loss 4744.3292512418875
INFO:root:current train perplexity6.503479480743408
INFO:root:current mean train loss 4747.407821864298
INFO:root:current train perplexity6.509693145751953
INFO:root:current mean train loss 4759.778204595792
INFO:root:current train perplexity6.531478404998779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it]
INFO:root:final mean train loss: 4758.973577314808
INFO:root:final train perplexity: 6.537487030029297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 4363.11094027039
INFO:root:eval perplexity: 5.837565898895264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 5236.685978016955
INFO:root:eval perplexity: 8.510944366455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [10:33:42<22:24:06, 592.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4728.297141335227
INFO:root:current train perplexity6.3973798751831055
INFO:root:current mean train loss 4689.280744123029
INFO:root:current train perplexity6.349209308624268
INFO:root:current mean train loss 4711.243913840343
INFO:root:current train perplexity6.403915882110596
INFO:root:current mean train loss 4730.588931558983
INFO:root:current train perplexity6.467041015625
INFO:root:current mean train loss 4753.3486042997265
INFO:root:current train perplexity6.522040367126465
INFO:root:current mean train loss 4746.925381834027
INFO:root:current train perplexity6.511490821838379
INFO:root:current mean train loss 4740.621944845796
INFO:root:current train perplexity6.496636867523193
INFO:root:current mean train loss 4743.431434599156
INFO:root:current train perplexity6.506387233734131
INFO:root:current mean train loss 4740.521772165922
INFO:root:current train perplexity6.49007511138916
INFO:root:current mean train loss 4735.319200333596
INFO:root:current train perplexity6.478278636932373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it]
INFO:root:final mean train loss: 4728.425248607512
INFO:root:final train perplexity: 6.459168910980225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 4327.241671514849
INFO:root:eval perplexity: 5.753506660461426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 5201.958662317154
INFO:root:eval perplexity: 8.390938758850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [10:43:34<22:13:15, 592.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4628.840049342105
INFO:root:current train perplexity6.241490840911865
INFO:root:current mean train loss 4599.629769974396
INFO:root:current train perplexity6.205365180969238
INFO:root:current mean train loss 4617.991840798017
INFO:root:current train perplexity6.210465908050537
INFO:root:current mean train loss 4637.092956351636
INFO:root:current train perplexity6.241501331329346
INFO:root:current mean train loss 4658.8279099931015
INFO:root:current train perplexity6.282365798950195
INFO:root:current mean train loss 4661.046608279895
INFO:root:current train perplexity6.286992073059082
INFO:root:current mean train loss 4670.815359876691
INFO:root:current train perplexity6.301572322845459
INFO:root:current mean train loss 4694.274518306132
INFO:root:current train perplexity6.357611656188965
INFO:root:current mean train loss 4726.687158083887
INFO:root:current train perplexity6.441348552703857
INFO:root:current mean train loss 4718.109115451152
INFO:root:current train perplexity6.425939559936523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.12s/it]
INFO:root:final mean train loss: 4707.163136266893
INFO:root:final train perplexity: 6.405212879180908
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 4300.291976604056
INFO:root:eval perplexity: 5.691147327423096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 5183.669440519725
INFO:root:eval perplexity: 8.32841968536377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [10:53:25<22:02:56, 592.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4618.454770688658
INFO:root:current train perplexity6.13480281829834
INFO:root:current mean train loss 4639.1270915354335
INFO:root:current train perplexity6.195175647735596
INFO:root:current mean train loss 4604.152068419604
INFO:root:current train perplexity6.144990921020508
INFO:root:current mean train loss 4677.243149130351
INFO:root:current train perplexity6.333834171295166
INFO:root:current mean train loss 4676.490606017637
INFO:root:current train perplexity6.3244099617004395
INFO:root:current mean train loss 4719.435287446632
INFO:root:current train perplexity6.441896438598633
INFO:root:current mean train loss 4730.049000230512
INFO:root:current train perplexity6.471462249755859
INFO:root:current mean train loss 4715.9053466461055
INFO:root:current train perplexity6.426809787750244
INFO:root:current mean train loss 4704.201309148749
INFO:root:current train perplexity6.3885674476623535
INFO:root:current mean train loss 4694.633865175381
INFO:root:current train perplexity6.3660888671875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.09s/it]
INFO:root:final mean train loss: 4686.300625708795
INFO:root:final train perplexity: 6.352708339691162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 4451.66613856106
INFO:root:eval perplexity: 6.050391674041748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 5320.1793585161795
INFO:root:eval perplexity: 8.806538581848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:03:16<21:51:33, 591.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4722.430106026785
INFO:root:current train perplexity6.425477027893066
INFO:root:current mean train loss 4667.014252387153
INFO:root:current train perplexity6.296125411987305
INFO:root:current mean train loss 4645.655980925864
INFO:root:current train perplexity6.2480010986328125
INFO:root:current mean train loss 4616.793183739505
INFO:root:current train perplexity6.182430267333984
INFO:root:current mean train loss 4614.644777074353
INFO:root:current train perplexity6.172589302062988
INFO:root:current mean train loss 4603.1204676547895
INFO:root:current train perplexity6.14682149887085
INFO:root:current mean train loss 4597.995183316929
INFO:root:current train perplexity6.130874156951904
INFO:root:current mean train loss 4600.316375690902
INFO:root:current train perplexity6.1327714920043945
INFO:root:current mean train loss 4602.898655033682
INFO:root:current train perplexity6.135092735290527
INFO:root:current mean train loss 4600.643894656584
INFO:root:current train perplexity6.135234355926514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.26s/it]
INFO:root:final mean train loss: 4600.619479148619
INFO:root:final train perplexity: 6.141552448272705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4337.915771484375
INFO:root:eval perplexity: 5.7783942222595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 5209.859871938719
INFO:root:eval perplexity: 8.418092727661133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [11:13:03<21:38:53, 590.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4691.0182708030525
INFO:root:current train perplexity6.329805850982666
INFO:root:current mean train loss 4630.270159527972
INFO:root:current train perplexity6.184791088104248
INFO:root:current mean train loss 4618.2599746013375
INFO:root:current train perplexity6.139481544494629
INFO:root:current mean train loss 4632.245026079629
INFO:root:current train perplexity6.198731899261475
INFO:root:current mean train loss 4678.055764364066
INFO:root:current train perplexity6.303683757781982
INFO:root:current mean train loss 4709.366488799205
INFO:root:current train perplexity6.383383274078369
INFO:root:current mean train loss 4747.94070230487
INFO:root:current train perplexity6.490785121917725
INFO:root:current mean train loss 4743.668986057369
INFO:root:current train perplexity6.481873035430908
INFO:root:current mean train loss 4739.677259126168
INFO:root:current train perplexity6.470863342285156
INFO:root:current mean train loss 4744.394971635157
INFO:root:current train perplexity6.490580081939697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.62s/it]
INFO:root:final mean train loss: 4750.406522935436
INFO:root:final train perplexity: 6.5154266357421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 4438.792038937832
INFO:root:eval perplexity: 6.018975257873535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 5309.7063022911125
INFO:root:eval perplexity: 8.768904685974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [11:23:00<21:33:02, 592.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4931.795783547794
INFO:root:current train perplexity6.9097795486450195
INFO:root:current mean train loss 4879.150759261175
INFO:root:current train perplexity6.802574634552002
INFO:root:current mean train loss 4845.793445359188
INFO:root:current train perplexity6.745707988739014
INFO:root:current mean train loss 4827.289446447649
INFO:root:current train perplexity6.702520847320557
INFO:root:current mean train loss 4799.691238978486
INFO:root:current train perplexity6.631868362426758
INFO:root:current mean train loss 4774.826322967474
INFO:root:current train perplexity6.578185081481934
INFO:root:current mean train loss 4763.097704628096
INFO:root:current train perplexity6.550400257110596
INFO:root:current mean train loss 4761.22323523063
INFO:root:current train perplexity6.549235820770264
INFO:root:current mean train loss 4761.948732476957
INFO:root:current train perplexity6.540196895599365
INFO:root:current mean train loss 4757.773802298978
INFO:root:current train perplexity6.525331497192383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.40s/it]
INFO:root:final mean train loss: 4750.8968860257055
INFO:root:final train perplexity: 6.516688823699951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 4326.359146442819
INFO:root:eval perplexity: 5.751453399658203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 5199.639106479943
INFO:root:eval perplexity: 8.38298511505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [11:32:51<21:22:56, 592.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4662.351603879767
INFO:root:current train perplexity6.377453804016113
INFO:root:current mean train loss 4680.173213934749
INFO:root:current train perplexity6.327753067016602
INFO:root:current mean train loss 4670.125382706926
INFO:root:current train perplexity6.324529647827148
INFO:root:current mean train loss 4676.167945628046
INFO:root:current train perplexity6.326810359954834
INFO:root:current mean train loss 4695.489631204044
INFO:root:current train perplexity6.369480609893799
INFO:root:current mean train loss 4728.809263717297
INFO:root:current train perplexity6.4595489501953125
INFO:root:current mean train loss 4742.193943978803
INFO:root:current train perplexity6.496391296386719
INFO:root:current mean train loss 4759.237729923213
INFO:root:current train perplexity6.531119346618652
INFO:root:current mean train loss 4751.22151654813
INFO:root:current train perplexity6.51400089263916
INFO:root:current mean train loss 4750.883333367277
INFO:root:current train perplexity6.508477210998535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.67s/it]
INFO:root:final mean train loss: 4747.483812516735
INFO:root:final train perplexity: 6.507918834686279
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 4376.215321642288
INFO:root:eval perplexity: 5.868581771850586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 5220.385936114805
INFO:root:eval perplexity: 8.454405784606934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [11:42:44<21:13:32, 592.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4795.470819729478
INFO:root:current train perplexity6.646800994873047
INFO:root:current mean train loss 4846.170263964259
INFO:root:current train perplexity6.720941543579102
INFO:root:current mean train loss 4869.169428107444
INFO:root:current train perplexity6.800229072570801
INFO:root:current mean train loss 4876.423065767626
INFO:root:current train perplexity6.837324142456055
INFO:root:current mean train loss 4880.256536904443
INFO:root:current train perplexity6.864945411682129
INFO:root:current mean train loss 4892.797444230875
INFO:root:current train perplexity6.882909774780273
INFO:root:current mean train loss 4895.9489800997935
INFO:root:current train perplexity6.89389705657959
INFO:root:current mean train loss 4895.175930853773
INFO:root:current train perplexity6.891763687133789
INFO:root:current mean train loss 4879.663926772455
INFO:root:current train perplexity6.8408355712890625
INFO:root:current mean train loss 4862.734748658868
INFO:root:current train perplexity6.796578884124756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.53s/it]
INFO:root:final mean train loss: 4854.494148500504
INFO:root:final train perplexity: 6.788557529449463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 4401.624135984596
INFO:root:eval perplexity: 5.929189205169678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 5265.67176072141
INFO:root:eval perplexity: 8.612421989440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [11:52:37<21:03:38, 592.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5034.680745442708
INFO:root:current train perplexity7.235426902770996
INFO:root:current mean train loss 5160.707200055804
INFO:root:current train perplexity7.616608142852783
INFO:root:current mean train loss 5028.388138316762
INFO:root:current train perplexity7.223640441894531
INFO:root:current mean train loss 4973.933900390625
INFO:root:current train perplexity7.100316047668457
INFO:root:current mean train loss 4935.967710217928
INFO:root:current train perplexity7.003011226654053
INFO:root:current mean train loss 4889.341680112092
INFO:root:current train perplexity6.881369113922119
INFO:root:current mean train loss 4859.203303313078
INFO:root:current train perplexity6.798720836639404
INFO:root:current mean train loss 4836.45367219002
INFO:root:current train perplexity6.732229709625244
INFO:root:current mean train loss 4809.42532282366
INFO:root:current train perplexity6.665391445159912
INFO:root:current mean train loss 4812.188851913061
INFO:root:current train perplexity6.669002056121826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.64s/it]
INFO:root:final mean train loss: 4807.790903460595
INFO:root:final train perplexity: 6.664617538452148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 4502.063824592753
INFO:root:eval perplexity: 6.174960136413574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 5387.1887276291
INFO:root:eval perplexity: 9.05118465423584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:02:32<20:55:37, 593.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4864.1688158885545
INFO:root:current train perplexity6.769659519195557
INFO:root:current mean train loss 4770.581972549522
INFO:root:current train perplexity6.524518966674805
INFO:root:current mean train loss 4684.238468453235
INFO:root:current train perplexity6.3141865730285645
INFO:root:current mean train loss 4621.997327839425
INFO:root:current train perplexity6.171502113342285
INFO:root:current mean train loss 4582.522237015561
INFO:root:current train perplexity6.072876930236816
INFO:root:current mean train loss 4556.840254140759
INFO:root:current train perplexity6.01996374130249
INFO:root:current mean train loss 4544.075580647191
INFO:root:current train perplexity5.9917216300964355
INFO:root:current mean train loss 4530.4709853054155
INFO:root:current train perplexity5.9612603187561035
INFO:root:current mean train loss 4521.720359447993
INFO:root:current train perplexity5.940941333770752
INFO:root:current mean train loss 4515.710697581542
INFO:root:current train perplexity5.929710865020752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.07s/it]
INFO:root:final mean train loss: 4511.633640289307
INFO:root:final train perplexity: 5.929677963256836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 4245.501405972961
INFO:root:eval perplexity: 5.56644344329834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 5142.766800684286
INFO:root:eval perplexity: 8.190279006958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [12:12:26<20:46:08, 593.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4472.358964521806
INFO:root:current train perplexity5.833589553833008
INFO:root:current mean train loss 4515.221900820108
INFO:root:current train perplexity5.936586380004883
INFO:root:current mean train loss 4486.345784505208
INFO:root:current train perplexity5.884902000427246
INFO:root:current mean train loss 4483.195132672634
INFO:root:current train perplexity5.8643083572387695
INFO:root:current mean train loss 4475.176595715058
INFO:root:current train perplexity5.844296932220459
INFO:root:current mean train loss 4465.2188768209335
INFO:root:current train perplexity5.82354211807251
INFO:root:current mean train loss 4463.632187132553
INFO:root:current train perplexity5.810807704925537
INFO:root:current mean train loss 4464.55950457046
INFO:root:current train perplexity5.8153862953186035
INFO:root:current mean train loss 4465.8171293556225
INFO:root:current train perplexity5.814967155456543
INFO:root:current mean train loss 4461.137226739877
INFO:root:current train perplexity5.8049235343933105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.84s/it]
INFO:root:final mean train loss: 4457.686008699478
INFO:root:final train perplexity: 5.80480432510376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 4223.1587762494455
INFO:root:eval perplexity: 5.5163774490356445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 5113.302091990802
INFO:root:eval perplexity: 8.092190742492676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [12:22:19<20:36:13, 593.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4409.459975733902
INFO:root:current train perplexity5.708751678466797
INFO:root:current mean train loss 4401.971841630025
INFO:root:current train perplexity5.690614700317383
INFO:root:current mean train loss 4412.196940648516
INFO:root:current train perplexity5.695289134979248
INFO:root:current mean train loss 4415.752021655701
INFO:root:current train perplexity5.694178581237793
INFO:root:current mean train loss 4424.8311701528055
INFO:root:current train perplexity5.713400840759277
INFO:root:current mean train loss 4419.796598660528
INFO:root:current train perplexity5.708068370819092
INFO:root:current mean train loss 4416.611050105061
INFO:root:current train perplexity5.7019805908203125
INFO:root:current mean train loss 4412.172409726025
INFO:root:current train perplexity5.691450595855713
INFO:root:current mean train loss 4408.172168566202
INFO:root:current train perplexity5.681237697601318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.89s/it]
INFO:root:final mean train loss: 4402.369256173411
INFO:root:final train perplexity: 5.679492950439453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 4228.442555961879
INFO:root:eval perplexity: 5.528176307678223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 5122.33662663453
INFO:root:eval perplexity: 8.122142791748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [12:32:11<20:25:39, 593.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.518205915178
INFO:root:current train perplexity5.823073387145996
INFO:root:current mean train loss 4386.509845484083
INFO:root:current train perplexity5.7072906494140625
INFO:root:current mean train loss 4357.856558537138
INFO:root:current train perplexity5.617630958557129
INFO:root:current mean train loss 4353.5002918554055
INFO:root:current train perplexity5.60106086730957
INFO:root:current mean train loss 4362.765118723127
INFO:root:current train perplexity5.613430023193359
INFO:root:current mean train loss 4366.721277120316
INFO:root:current train perplexity5.609334468841553
INFO:root:current mean train loss 4371.858375913818
INFO:root:current train perplexity5.614007949829102
INFO:root:current mean train loss 4371.393561593883
INFO:root:current train perplexity5.607633590698242
INFO:root:current mean train loss 4373.914823964626
INFO:root:current train perplexity5.613000869750977
INFO:root:current mean train loss 4374.277006475245
INFO:root:current train perplexity5.610421180725098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.02s/it]
INFO:root:final mean train loss: 4371.387964863931
INFO:root:final train perplexity: 5.610495567321777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 4195.234056405142
INFO:root:eval perplexity: 5.454437255859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 5091.133484319592
INFO:root:eval perplexity: 8.019166946411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [12:42:01<20:13:47, 592.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4335.497884114583
INFO:root:current train perplexity5.517226219177246
INFO:root:current mean train loss 4335.536287788723
INFO:root:current train perplexity5.5444159507751465
INFO:root:current mean train loss 4363.618736373546
INFO:root:current train perplexity5.604865550994873
INFO:root:current mean train loss 4371.2416480654765
INFO:root:current train perplexity5.624966621398926
INFO:root:current mean train loss 4372.985681005271
INFO:root:current train perplexity5.615151405334473
INFO:root:current mean train loss 4371.55106521162
INFO:root:current train perplexity5.609094142913818
INFO:root:current mean train loss 4367.135778709349
INFO:root:current train perplexity5.595846652984619
INFO:root:current mean train loss 4363.770268452251
INFO:root:current train perplexity5.583301067352295
INFO:root:current mean train loss 4368.000052123274
INFO:root:current train perplexity5.590572834014893
INFO:root:current mean train loss 4362.097262156335
INFO:root:current train perplexity5.582518577575684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.28s/it]
INFO:root:final mean train loss: 4358.311675902336
INFO:root:final train perplexity: 5.581625461578369
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 4179.452115539118
INFO:root:eval perplexity: 5.419739246368408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 5074.345306612921
INFO:root:eval perplexity: 7.964305877685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [12:51:52<20:03:09, 591.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4351.770359205163
INFO:root:current train perplexity5.574031829833984
INFO:root:current mean train loss 4321.0729385003815
INFO:root:current train perplexity5.528628349304199
INFO:root:current mean train loss 4352.90415564567
INFO:root:current train perplexity5.590698719024658
INFO:root:current mean train loss 4366.539512988584
INFO:root:current train perplexity5.633406162261963
INFO:root:current mean train loss 4391.184370036384
INFO:root:current train perplexity5.665498733520508
INFO:root:current mean train loss 4375.4241012077255
INFO:root:current train perplexity5.637724876403809
INFO:root:current mean train loss 4375.604186913749
INFO:root:current train perplexity5.621657848358154
INFO:root:current mean train loss 4370.708582539117
INFO:root:current train perplexity5.605332851409912
INFO:root:current mean train loss 4364.173441297084
INFO:root:current train perplexity5.589386463165283
INFO:root:current mean train loss 4360.969231668557
INFO:root:current train perplexity5.57850980758667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.59s/it]
INFO:root:final mean train loss: 4354.061482829432
INFO:root:final train perplexity: 5.572274208068848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 4159.835099457004
INFO:root:eval perplexity: 5.376917362213135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 5062.188170088099
INFO:root:eval perplexity: 7.924809455871582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:01:44<19:53:40, 591.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4306.153273059475
INFO:root:current train perplexity5.410292148590088
INFO:root:current mean train loss 4307.8889868350425
INFO:root:current train perplexity5.433815956115723
INFO:root:current mean train loss 4296.3804239380415
INFO:root:current train perplexity5.435953617095947
INFO:root:current mean train loss 4297.698901588463
INFO:root:current train perplexity5.432973861694336
INFO:root:current mean train loss 4291.494349645628
INFO:root:current train perplexity5.432864189147949
INFO:root:current mean train loss 4308.987621472605
INFO:root:current train perplexity5.4666361808776855
INFO:root:current mean train loss 4299.642920927843
INFO:root:current train perplexity5.453895092010498
INFO:root:current mean train loss 4299.435690153151
INFO:root:current train perplexity5.452502727508545
INFO:root:current mean train loss 4301.9026860169415
INFO:root:current train perplexity5.453956127166748
INFO:root:current mean train loss 4303.19982162787
INFO:root:current train perplexity5.454118728637695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.10s/it]
INFO:root:final mean train loss: 4300.851715210945
INFO:root:final train perplexity: 5.456515789031982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 4142.946122839096
INFO:root:eval perplexity: 5.340320587158203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 5041.414717004654
INFO:root:eval perplexity: 7.857776165008545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [13:11:41<19:46:39, 593.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4299.321088741987
INFO:root:current train perplexity5.4217071533203125
INFO:root:current mean train loss 4292.476313090153
INFO:root:current train perplexity5.429561614990234
INFO:root:current mean train loss 4287.632113787919
INFO:root:current train perplexity5.420273303985596
INFO:root:current mean train loss 4291.670495137352
INFO:root:current train perplexity5.413886547088623
INFO:root:current mean train loss 4283.773730023847
INFO:root:current train perplexity5.4141387939453125
INFO:root:current mean train loss 4286.942004145408
INFO:root:current train perplexity5.419269561767578
INFO:root:current mean train loss 4287.796533050298
INFO:root:current train perplexity5.417192459106445
INFO:root:current mean train loss 4287.78001839479
INFO:root:current train perplexity5.415363311767578
INFO:root:current mean train loss 4284.178452538364
INFO:root:current train perplexity5.409027099609375
INFO:root:current mean train loss 4275.537771856696
INFO:root:current train perplexity5.397482395172119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.35s/it]
INFO:root:final mean train loss: 4270.488735629666
INFO:root:final train perplexity: 5.391541957855225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 4085.964835092531
INFO:root:eval perplexity: 5.218677997589111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4998.573562513852
INFO:root:eval perplexity: 7.721320152282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [13:21:36<19:37:31, 593.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4205.634272149268
INFO:root:current train perplexity5.273074150085449
INFO:root:current mean train loss 4178.0895398198345
INFO:root:current train perplexity5.199002742767334
INFO:root:current mean train loss 4171.290688456794
INFO:root:current train perplexity5.1665568351745605
INFO:root:current mean train loss 4171.081378332133
INFO:root:current train perplexity5.161334991455078
INFO:root:current mean train loss 4156.174380855005
INFO:root:current train perplexity5.135157585144043
INFO:root:current mean train loss 4145.328005384484
INFO:root:current train perplexity5.113853454589844
INFO:root:current mean train loss 4139.022620176053
INFO:root:current train perplexity5.103893756866455
INFO:root:current mean train loss 4124.750468017905
INFO:root:current train perplexity5.083221435546875
INFO:root:current mean train loss 4116.5840261700305
INFO:root:current train perplexity5.068924903869629
INFO:root:current mean train loss 4109.7962939092195
INFO:root:current train perplexity5.055752754211426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.91s/it]
INFO:root:final mean train loss: 4105.585383938205
INFO:root:final train perplexity: 5.051939487457275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 3981.023406333112
INFO:root:eval perplexity: 5.001855850219727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4894.611044160018
INFO:root:eval perplexity: 7.3999528884887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [13:31:28<19:26:42, 593.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4062.9572931463067
INFO:root:current train perplexity4.934001922607422
INFO:root:current mean train loss 4405.380972782258
INFO:root:current train perplexity5.687292575836182
INFO:root:current mean train loss 4510.486915977329
INFO:root:current train perplexity5.907846450805664
INFO:root:current mean train loss 4541.937757207306
INFO:root:current train perplexity5.997310638427734
INFO:root:current mean train loss 4482.693073381696
INFO:root:current train perplexity5.8544602394104
INFO:root:current mean train loss 4421.6934187605575
INFO:root:current train perplexity5.712087631225586
INFO:root:current mean train loss 4362.6039137046755
INFO:root:current train perplexity5.58494758605957
INFO:root:current mean train loss 4316.801232020903
INFO:root:current train perplexity5.484130382537842
INFO:root:current mean train loss 4282.803212376644
INFO:root:current train perplexity5.411655426025391
INFO:root:current mean train loss 4255.670669635553
INFO:root:current train perplexity5.3531975746154785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.86s/it]
INFO:root:final mean train loss: 4243.366766345116
INFO:root:final train perplexity: 5.334157943725586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 3972.2158324329566
INFO:root:eval perplexity: 4.984073638916016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 4887.587996246121
INFO:root:eval perplexity: 7.378732681274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [13:41:12<19:11:35, 590.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3982.278990730407
INFO:root:current train perplexity4.813528537750244
INFO:root:current mean train loss 4036.1414697565183
INFO:root:current train perplexity4.9041619300842285
INFO:root:current mean train loss 4059.4180662205918
INFO:root:current train perplexity4.952032566070557
INFO:root:current mean train loss 4043.4436243651
INFO:root:current train perplexity4.939050674438477
INFO:root:current mean train loss 4032.057263895451
INFO:root:current train perplexity4.9177374839782715
INFO:root:current mean train loss 4028.3575931637156
INFO:root:current train perplexity4.899785995483398
INFO:root:current mean train loss 4019.807804987981
INFO:root:current train perplexity4.885535717010498
INFO:root:current mean train loss 4015.9485874401007
INFO:root:current train perplexity4.874549865722656
INFO:root:current mean train loss 4008.054178284328
INFO:root:current train perplexity4.86216926574707
INFO:root:current mean train loss 4005.868074569623
INFO:root:current train perplexity4.852572917938232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.69s/it]
INFO:root:final mean train loss: 4003.4725233508693
INFO:root:final train perplexity: 4.852459907531738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 3937.4352230856603
INFO:root:eval perplexity: 4.914466857910156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4851.247274628768
INFO:root:eval perplexity: 7.269893646240234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [13:50:57<18:58:41, 588.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3944.3280906139967
INFO:root:current train perplexity4.741257667541504
INFO:root:current mean train loss 3938.5361827828033
INFO:root:current train perplexity4.726778030395508
INFO:root:current mean train loss 3932.5235942544973
INFO:root:current train perplexity4.707622051239014
INFO:root:current mean train loss 3947.837313505517
INFO:root:current train perplexity4.727639675140381
INFO:root:current mean train loss 3938.3758557880506
INFO:root:current train perplexity4.7148237228393555
INFO:root:current mean train loss 3939.921262724387
INFO:root:current train perplexity4.714053630828857
INFO:root:current mean train loss 3935.28145338988
INFO:root:current train perplexity4.70808744430542
INFO:root:current mean train loss 3930.0070097808243
INFO:root:current train perplexity4.702882766723633
INFO:root:current mean train loss 3927.2806636140213
INFO:root:current train perplexity4.702045440673828
INFO:root:current mean train loss 3926.3264979825085
INFO:root:current train perplexity4.700704574584961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.28s/it]
INFO:root:final mean train loss: 3922.8552814606696
INFO:root:final train perplexity: 4.700551986694336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 3908.5035391733154
INFO:root:eval perplexity: 4.857306957244873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 4828.682485593971
INFO:root:eval perplexity: 7.203121662139893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [14:00:41<18:46:00, 587.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3859.806668438489
INFO:root:current train perplexity4.610965251922607
INFO:root:current mean train loss 3883.6526097132505
INFO:root:current train perplexity4.627262592315674
INFO:root:current mean train loss 3889.7082178259407
INFO:root:current train perplexity4.633152008056641
INFO:root:current mean train loss 3891.3042185438653
INFO:root:current train perplexity4.625795364379883
INFO:root:current mean train loss 3889.1416168531446
INFO:root:current train perplexity4.618617534637451
INFO:root:current mean train loss 3877.4823476629967
INFO:root:current train perplexity4.6055378913879395
INFO:root:current mean train loss 3875.4865945582887
INFO:root:current train perplexity4.600827693939209
INFO:root:current mean train loss 3874.9762459633744
INFO:root:current train perplexity4.5990705490112305
INFO:root:current mean train loss 3868.366533403104
INFO:root:current train perplexity4.592282772064209
INFO:root:current mean train loss 3864.769920528361
INFO:root:current train perplexity4.590178489685059

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.32s/it]
INFO:root:final mean train loss: 3862.2906374777517
INFO:root:final train perplexity: 4.589564800262451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 3871.300367422983
INFO:root:eval perplexity: 4.784780025482178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4786.878279449246
INFO:root:eval perplexity: 7.0810370445251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [14:10:29<18:36:10, 587.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3835.389059132543
INFO:root:current train perplexity4.5509257316589355
INFO:root:current mean train loss 3834.0546326662766
INFO:root:current train perplexity4.549630641937256
INFO:root:current mean train loss 3822.6381546711673
INFO:root:current train perplexity4.534530162811279
INFO:root:current mean train loss 3822.5520246638807
INFO:root:current train perplexity4.525127410888672
INFO:root:current mean train loss 3819.553975130743
INFO:root:current train perplexity4.519765377044678
INFO:root:current mean train loss 3820.713173029573
INFO:root:current train perplexity4.515116214752197
INFO:root:current mean train loss 3823.202756123772
INFO:root:current train perplexity4.517176628112793
INFO:root:current mean train loss 3821.8896630176896
INFO:root:current train perplexity4.510123252868652
INFO:root:current mean train loss 3819.3181369785793
INFO:root:current train perplexity4.508844375610352
INFO:root:current mean train loss 3823.651647689495
INFO:root:current train perplexity4.514436721801758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.16s/it]
INFO:root:final mean train loss: 3820.1966870830906
INFO:root:final train perplexity: 4.513975143432617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.86s/it]
INFO:root:eval mean loss: 3871.5595928219195
INFO:root:eval perplexity: 4.785283088684082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4787.918109000997
INFO:root:eval perplexity: 7.084047794342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [14:20:23<18:30:01, 589.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3807.857038959704
INFO:root:current train perplexity4.461758136749268
INFO:root:current mean train loss 3803.2005170773236
INFO:root:current train perplexity4.458512306213379
INFO:root:current mean train loss 3801.011079018803
INFO:root:current train perplexity4.461624622344971
INFO:root:current mean train loss 3802.500968527492
INFO:root:current train perplexity4.465731620788574
INFO:root:current mean train loss 3799.5884854403407
INFO:root:current train perplexity4.4704270362854
INFO:root:current mean train loss 3797.0331321395747
INFO:root:current train perplexity4.466500282287598
INFO:root:current mean train loss 3797.385349454811
INFO:root:current train perplexity4.467233657836914
INFO:root:current mean train loss 3822.9070567388953
INFO:root:current train perplexity4.511911392211914
INFO:root:current mean train loss 3853.1163396909915
INFO:root:current train perplexity4.563772678375244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.42s/it]
INFO:root:final mean train loss: 3848.842331178727
INFO:root:final train perplexity: 4.565279006958008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 3879.251374806073
INFO:root:eval perplexity: 4.800189971923828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 4796.265046681073
INFO:root:eval perplexity: 7.1082682609558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [14:30:16<18:22:23, 590.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.1079915364585
INFO:root:current train perplexity4.3502516746521
INFO:root:current mean train loss 3795.1072393621057
INFO:root:current train perplexity4.4711761474609375
INFO:root:current mean train loss 3791.829943426724
INFO:root:current train perplexity4.468815326690674
INFO:root:current mean train loss 3803.363904896349
INFO:root:current train perplexity4.482963562011719
INFO:root:current mean train loss 3801.947021484375
INFO:root:current train perplexity4.476401329040527
INFO:root:current mean train loss 3803.912853931101
INFO:root:current train perplexity4.478012561798096
INFO:root:current mean train loss 3799.9661749844527
INFO:root:current train perplexity4.47090482711792
INFO:root:current mean train loss 3796.080095141914
INFO:root:current train perplexity4.460772514343262
INFO:root:current mean train loss 3790.645491698611
INFO:root:current train perplexity4.456554412841797
INFO:root:current mean train loss 3784.127356781648
INFO:root:current train perplexity4.445067405700684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.33s/it]
INFO:root:final mean train loss: 3779.067049457181
INFO:root:final train perplexity: 4.441318511962891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3843.939773451352
INFO:root:eval perplexity: 4.7321343421936035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 4767.294080369016
INFO:root:eval perplexity: 7.024556636810303
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [14:40:10<18:14:19, 591.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.3294788707385
INFO:root:current train perplexity4.440707683563232
INFO:root:current mean train loss 3729.208590670749
INFO:root:current train perplexity4.331056118011475
INFO:root:current mean train loss 3728.9247780750147
INFO:root:current train perplexity4.351927280426025
INFO:root:current mean train loss 3745.3739096098775
INFO:root:current train perplexity4.369505882263184
INFO:root:current mean train loss 3741.83392616142
INFO:root:current train perplexity4.3769989013671875
INFO:root:current mean train loss 3743.3485434694535
INFO:root:current train perplexity4.3756256103515625
INFO:root:current mean train loss 3741.5825191316744
INFO:root:current train perplexity4.368666172027588
INFO:root:current mean train loss 3738.27609866715
INFO:root:current train perplexity4.364182472229004
INFO:root:current mean train loss 3735.3682173459656
INFO:root:current train perplexity4.3615403175354
INFO:root:current mean train loss 3732.9951118276617
INFO:root:current train perplexity4.356237411499023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.39s/it]
INFO:root:final mean train loss: 3729.0411926392585
INFO:root:final train perplexity: 4.35452127456665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3803.874832045102
INFO:root:eval perplexity: 4.656085968017578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4729.618418592087
INFO:root:eval perplexity: 6.917165756225586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [14:50:04<18:05:47, 592.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3622.565185546875
INFO:root:current train perplexity4.247825622558594
INFO:root:current mean train loss 3704.133848558955
INFO:root:current train perplexity4.3309149742126465
INFO:root:current mean train loss 3713.9548886094462
INFO:root:current train perplexity4.330628395080566
INFO:root:current mean train loss 3713.9671925511852
INFO:root:current train perplexity4.320140838623047
INFO:root:current mean train loss 3712.254410263462
INFO:root:current train perplexity4.319244384765625
INFO:root:current mean train loss 3712.193215901222
INFO:root:current train perplexity4.31870698928833
INFO:root:current mean train loss 3713.354276050081
INFO:root:current train perplexity4.323966979980469
INFO:root:current mean train loss 3715.255917778599
INFO:root:current train perplexity4.326878547668457
INFO:root:current mean train loss 3716.0372217571926
INFO:root:current train perplexity4.324733257293701
INFO:root:current mean train loss 3711.588212603713
INFO:root:current train perplexity4.318685531616211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it]
INFO:root:final mean train loss: 3706.808836413968
INFO:root:final train perplexity: 4.316493511199951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 3793.451332903923
INFO:root:eval perplexity: 4.636502742767334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 4722.592186461104
INFO:root:eval perplexity: 6.8973188400268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [14:59:55<17:55:26, 591.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.126365379051
INFO:root:current train perplexity4.212361812591553
INFO:root:current mean train loss 3670.926056148499
INFO:root:current train perplexity4.264354228973389
INFO:root:current mean train loss 3675.6478319882294
INFO:root:current train perplexity4.268871307373047
INFO:root:current mean train loss 3694.7873505291955
INFO:root:current train perplexity4.29677677154541
INFO:root:current mean train loss 3698.869797003074
INFO:root:current train perplexity4.30587100982666
INFO:root:current mean train loss 3704.505468379388
INFO:root:current train perplexity4.310244083404541
INFO:root:current mean train loss 3709.241464423221
INFO:root:current train perplexity4.317513942718506
INFO:root:current mean train loss 3712.404643776328
INFO:root:current train perplexity4.319977760314941
INFO:root:current mean train loss 3711.25922243425
INFO:root:current train perplexity4.3188300132751465
INFO:root:current mean train loss 3709.115564636428
INFO:root:current train perplexity4.317107677459717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.34s/it]
INFO:root:final mean train loss: 3705.883622938587
INFO:root:final train perplexity: 4.314918041229248
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3784.99200049867
INFO:root:eval perplexity: 4.620670795440674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 4714.948676792443
INFO:root:eval perplexity: 6.875796318054199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [15:09:47<17:45:23, 591.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3636.7760463169643
INFO:root:current train perplexity4.236085891723633
INFO:root:current mean train loss 3680.5040436921295
INFO:root:current train perplexity4.29304838180542
INFO:root:current mean train loss 3681.4157984956782
INFO:root:current train perplexity4.281779766082764
INFO:root:current mean train loss 3677.2503257637595
INFO:root:current train perplexity4.276015281677246
INFO:root:current mean train loss 3685.713388447378
INFO:root:current train perplexity4.280349254608154
INFO:root:current mean train loss 3689.3447283878504
INFO:root:current train perplexity4.279986381530762
INFO:root:current mean train loss 3689.5532795583167
INFO:root:current train perplexity4.279826641082764
INFO:root:current mean train loss 3687.460334954294
INFO:root:current train perplexity4.27617883682251
INFO:root:current mean train loss 3683.347979919068
INFO:root:current train perplexity4.272486209869385
INFO:root:current mean train loss 3684.5933572860963
INFO:root:current train perplexity4.273094177246094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.70s/it]
INFO:root:final mean train loss: 3680.2041184210007
INFO:root:final train perplexity: 4.271422863006592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3772.1886012300533
INFO:root:eval perplexity: 4.596808910369873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 4705.626677817487
INFO:root:eval perplexity: 6.849635124206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [15:19:38<17:35:08, 591.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.1448662336484
INFO:root:current train perplexity4.202777862548828
INFO:root:current mean train loss 3666.8354987297857
INFO:root:current train perplexity4.231362342834473
INFO:root:current mean train loss 3659.186468179334
INFO:root:current train perplexity4.228930950164795
INFO:root:current mean train loss 3662.550749931669
INFO:root:current train perplexity4.231542587280273
INFO:root:current mean train loss 3663.74901682421
INFO:root:current train perplexity4.238230228424072
INFO:root:current mean train loss 3665.305313812874
INFO:root:current train perplexity4.239535331726074
INFO:root:current mean train loss 3663.7772811011614
INFO:root:current train perplexity4.238086700439453
INFO:root:current mean train loss 3663.6338984821878
INFO:root:current train perplexity4.2394118309021
INFO:root:current mean train loss 3668.9740958977422
INFO:root:current train perplexity4.246696949005127
INFO:root:current mean train loss 3667.3840712611013
INFO:root:current train perplexity4.244161605834961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.63s/it]
INFO:root:final mean train loss: 3664.1455934586065
INFO:root:final train perplexity: 4.244446277618408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3766.3344432208555
INFO:root:eval perplexity: 4.585939407348633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 4700.008399476396
INFO:root:eval perplexity: 6.833917140960693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [15:29:29<17:24:46, 591.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3646.9924699371936
INFO:root:current train perplexity4.229437828063965
INFO:root:current mean train loss 3637.6316370679842
INFO:root:current train perplexity4.215605735778809
INFO:root:current mean train loss 3637.267775577378
INFO:root:current train perplexity4.21483850479126
INFO:root:current mean train loss 3640.5232323105856
INFO:root:current train perplexity4.218310832977295
INFO:root:current mean train loss 3653.5733114779655
INFO:root:current train perplexity4.228104114532471
INFO:root:current mean train loss 3652.9482253502156
INFO:root:current train perplexity4.223494052886963
INFO:root:current mean train loss 3654.2712593605993
INFO:root:current train perplexity4.2240986824035645
INFO:root:current mean train loss 3652.399916972682
INFO:root:current train perplexity4.2171735763549805
INFO:root:current mean train loss 3649.6968892295827
INFO:root:current train perplexity4.216374397277832
INFO:root:current mean train loss 3651.4435436998883
INFO:root:current train perplexity4.218210220336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.42s/it]
INFO:root:final mean train loss: 3648.242836490754
INFO:root:final train perplexity: 4.217899799346924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3753.4413335272607
INFO:root:eval perplexity: 4.562092304229736
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 4687.4089840287015
INFO:root:eval perplexity: 6.798797607421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [15:39:21<17:15:14, 591.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3631.5790808726165
INFO:root:current train perplexity4.220894813537598
INFO:root:current mean train loss 3650.5862461306015
INFO:root:current train perplexity4.220523834228516
INFO:root:current mean train loss 3649.418953796151
INFO:root:current train perplexity4.206535339355469
INFO:root:current mean train loss 3645.3317803088003
INFO:root:current train perplexity4.206517696380615
INFO:root:current mean train loss 3643.388370821419
INFO:root:current train perplexity4.202447414398193
INFO:root:current mean train loss 3642.4779893469085
INFO:root:current train perplexity4.200097560882568
INFO:root:current mean train loss 3641.7875176344364
INFO:root:current train perplexity4.20111083984375
INFO:root:current mean train loss 3644.7358482069335
INFO:root:current train perplexity4.204830646514893
INFO:root:current mean train loss 3641.8833471082835
INFO:root:current train perplexity4.203542232513428
INFO:root:current mean train loss 3642.5392615802593
INFO:root:current train perplexity4.203542232513428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.37s/it]
INFO:root:final mean train loss: 3639.2434640084543
INFO:root:final train perplexity: 4.202950954437256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 3764.956574135638
INFO:root:eval perplexity: 4.583385467529297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 4699.263798274047
INFO:root:eval perplexity: 6.831836700439453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [15:49:08<17:02:58, 590.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.2383140450092
INFO:root:current train perplexity4.136983871459961
INFO:root:current mean train loss 3619.801610158589
INFO:root:current train perplexity4.15369176864624
INFO:root:current mean train loss 3611.9657791652035
INFO:root:current train perplexity4.144074440002441
INFO:root:current mean train loss 3624.1435473699335
INFO:root:current train perplexity4.158448219299316
INFO:root:current mean train loss 3621.311126120851
INFO:root:current train perplexity4.160898685455322
INFO:root:current mean train loss 3625.981418616347
INFO:root:current train perplexity4.170461177825928
INFO:root:current mean train loss 3622.2357849395617
INFO:root:current train perplexity4.171109199523926
INFO:root:current mean train loss 3620.845502910589
INFO:root:current train perplexity4.168500900268555
INFO:root:current mean train loss 3624.944963043811
INFO:root:current train perplexity4.171680450439453
INFO:root:current mean train loss 3623.7080191737496
INFO:root:current train perplexity4.172882080078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.37s/it]
INFO:root:final mean train loss: 3620.8591893103817
INFO:root:final train perplexity: 4.172576427459717
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3744.621211491578
INFO:root:eval perplexity: 4.5458502769470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 4675.190952598626
INFO:root:eval perplexity: 6.764917373657227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [15:59:01<16:54:57, 591.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3640.8030989583335
INFO:root:current train perplexity4.16306734085083
INFO:root:current mean train loss 3628.240834263393
INFO:root:current train perplexity4.181642055511475
INFO:root:current mean train loss 3620.7966832386364
INFO:root:current train perplexity4.168705463409424
INFO:root:current mean train loss 3615.603072265625
INFO:root:current train perplexity4.165586948394775
INFO:root:current mean train loss 3615.6213831208884
INFO:root:current train perplexity4.158482551574707
INFO:root:current mean train loss 3615.109722316576
INFO:root:current train perplexity4.1584367752075195
INFO:root:current mean train loss 3616.1180107060186
INFO:root:current train perplexity4.156060218811035
INFO:root:current mean train loss 3610.366853578629
INFO:root:current train perplexity4.153709888458252
INFO:root:current mean train loss 3611.140327566964
INFO:root:current train perplexity4.1536865234375
INFO:root:current mean train loss 3613.343157301683
INFO:root:current train perplexity4.154308319091797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.08s/it]
INFO:root:final mean train loss: 3609.957980801982
INFO:root:final train perplexity: 4.154669761657715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 3751.265129792775
INFO:root:eval perplexity: 4.558080196380615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4682.193451144171
INFO:root:eval perplexity: 6.784313678741455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [16:08:56<16:46:48, 592.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.0743187594126
INFO:root:current train perplexity4.108885765075684
INFO:root:current mean train loss 3588.329827313866
INFO:root:current train perplexity4.102023124694824
INFO:root:current mean train loss 3589.044134241111
INFO:root:current train perplexity4.12066125869751
INFO:root:current mean train loss 3590.9029397590975
INFO:root:current train perplexity4.126310348510742
INFO:root:current mean train loss 3593.1406765576476
INFO:root:current train perplexity4.128178596496582
INFO:root:current mean train loss 3595.914665523156
INFO:root:current train perplexity4.129639148712158
INFO:root:current mean train loss 3590.802314009883
INFO:root:current train perplexity4.124065399169922
INFO:root:current mean train loss 3593.4912312046017
INFO:root:current train perplexity4.128303527832031
INFO:root:current mean train loss 3596.2421957946985
INFO:root:current train perplexity4.129984378814697
INFO:root:current mean train loss 3595.171877235265
INFO:root:current train perplexity4.125901222229004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.29s/it]
INFO:root:final mean train loss: 3592.600482448455
INFO:root:final train perplexity: 4.126315593719482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3751.228842877327
INFO:root:eval perplexity: 4.558013439178467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 4680.7270473182625
INFO:root:eval perplexity: 6.780246734619141
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [16:18:48<16:36:55, 592.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3571.689624828297
INFO:root:current train perplexity4.116125106811523
INFO:root:current mean train loss 3589.3849752535994
INFO:root:current train perplexity4.108839988708496
INFO:root:current mean train loss 3581.7735927096755
INFO:root:current train perplexity4.10517692565918
INFO:root:current mean train loss 3573.3079343829922
INFO:root:current train perplexity4.09783935546875
INFO:root:current mean train loss 3582.3050435176933
INFO:root:current train perplexity4.102668762207031
INFO:root:current mean train loss 3580.0649203382773
INFO:root:current train perplexity4.097701072692871
INFO:root:current mean train loss 3584.8801767705318
INFO:root:current train perplexity4.104522228240967
INFO:root:current mean train loss 3586.4930375167905
INFO:root:current train perplexity4.110030651092529
INFO:root:current mean train loss 3587.0392567712715
INFO:root:current train perplexity4.11002254486084
INFO:root:current mean train loss 3586.0914012243
INFO:root:current train perplexity4.110987663269043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.01s/it]
INFO:root:final mean train loss: 3583.1342404888524
INFO:root:final train perplexity: 4.110933780670166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 3729.7299458388743
INFO:root:eval perplexity: 4.518558979034424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 4666.901026083223
INFO:root:eval perplexity: 6.74202299118042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [16:28:39<16:26:37, 591.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.632639875316
INFO:root:current train perplexity4.098265647888184
INFO:root:current mean train loss 3577.380547758323
INFO:root:current train perplexity4.096592426300049
INFO:root:current mean train loss 3577.0886867357335
INFO:root:current train perplexity4.094621658325195
INFO:root:current mean train loss 3568.2145237360983
INFO:root:current train perplexity4.083917140960693
INFO:root:current mean train loss 3567.3765230656627
INFO:root:current train perplexity4.085585117340088
INFO:root:current mean train loss 3572.7015166879696
INFO:root:current train perplexity4.092057704925537
INFO:root:current mean train loss 3569.617131616595
INFO:root:current train perplexity4.089943885803223
INFO:root:current mean train loss 3575.695620807748
INFO:root:current train perplexity4.093985557556152
INFO:root:current mean train loss 3575.574727942071
INFO:root:current train perplexity4.092963218688965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.03s/it]
INFO:root:final mean train loss: 3571.8561097421953
INFO:root:final train perplexity: 4.092681884765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 3734.5128199800533
INFO:root:eval perplexity: 4.527307510375977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4667.09851853391
INFO:root:eval perplexity: 6.742568016052246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [16:38:29<16:15:34, 591.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3463.960623604911
INFO:root:current train perplexity3.97421932220459
INFO:root:current mean train loss 3588.459634656104
INFO:root:current train perplexity4.085421562194824
INFO:root:current mean train loss 3565.09960229846
INFO:root:current train perplexity4.078970432281494
INFO:root:current mean train loss 3557.9255172282164
INFO:root:current train perplexity4.065177917480469
INFO:root:current mean train loss 3550.1305504501306
INFO:root:current train perplexity4.058859825134277
INFO:root:current mean train loss 3551.257409451276
INFO:root:current train perplexity4.061660289764404
INFO:root:current mean train loss 3554.728264646829
INFO:root:current train perplexity4.064814567565918
INFO:root:current mean train loss 3555.5326599380082
INFO:root:current train perplexity4.064557075500488
INFO:root:current mean train loss 3557.589486161129
INFO:root:current train perplexity4.069094181060791
INFO:root:current mean train loss 3560.579921196682
INFO:root:current train perplexity4.072335720062256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.67s/it]
INFO:root:final mean train loss: 3558.064865666051
INFO:root:final train perplexity: 4.070474147796631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 3718.514452778701
INFO:root:eval perplexity: 4.498112678527832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 4658.5432163536125
INFO:root:eval perplexity: 6.719020366668701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [16:48:26<16:08:25, 592.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.012662760417
INFO:root:current train perplexity4.062123775482178
INFO:root:current mean train loss 3563.133600118886
INFO:root:current train perplexity4.086703777313232
INFO:root:current mean train loss 3564.8240291151888
INFO:root:current train perplexity4.073134422302246
INFO:root:current mean train loss 3551.8379813058036
INFO:root:current train perplexity4.063499927520752
INFO:root:current mean train loss 3554.8699918815887
INFO:root:current train perplexity4.063117027282715
INFO:root:current mean train loss 3557.2240604141384
INFO:root:current train perplexity4.0605149269104
INFO:root:current mean train loss 3554.729311563135
INFO:root:current train perplexity4.05840539932251
INFO:root:current mean train loss 3555.3239496831293
INFO:root:current train perplexity4.058870792388916
INFO:root:current mean train loss 3552.839984243194
INFO:root:current train perplexity4.056675434112549
INFO:root:current mean train loss 3553.4274800952016
INFO:root:current train perplexity4.057352066040039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.60s/it]
INFO:root:final mean train loss: 3548.766140660932
INFO:root:final train perplexity: 4.055568218231201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 3721.1879501883864
INFO:root:eval perplexity: 4.502978801727295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 4660.550485164561
INFO:root:eval perplexity: 6.724537372589111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [16:58:12<15:55:16, 590.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.0887504245925
INFO:root:current train perplexity4.0510573387146
INFO:root:current mean train loss 3556.9907901422766
INFO:root:current train perplexity4.055891036987305
INFO:root:current mean train loss 3543.135943630886
INFO:root:current train perplexity4.038833141326904
INFO:root:current mean train loss 3544.7613695457626
INFO:root:current train perplexity4.047167778015137
INFO:root:current mean train loss 3550.1839238881503
INFO:root:current train perplexity4.046830177307129
INFO:root:current mean train loss 3552.4220080403024
INFO:root:current train perplexity4.052034378051758
INFO:root:current mean train loss 3548.8793851261535
INFO:root:current train perplexity4.046095371246338
INFO:root:current mean train loss 3547.275236981868
INFO:root:current train perplexity4.046326637268066
INFO:root:current mean train loss 3548.504636595345
INFO:root:current train perplexity4.048501491546631
INFO:root:current mean train loss 3546.699068245108
INFO:root:current train perplexity4.046820640563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.93s/it]
INFO:root:final mean train loss: 3540.912023482784
INFO:root:final train perplexity: 4.043021202087402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3705.0230808122783
INFO:root:eval perplexity: 4.4736409187316895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 4642.521546708776
INFO:root:eval perplexity: 6.675144672393799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [17:08:06<15:46:44, 591.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3615.2883852066534
INFO:root:current train perplexity4.065502643585205
INFO:root:current mean train loss 3554.1610713114264
INFO:root:current train perplexity4.034181118011475
INFO:root:current mean train loss 3532.493296173228
INFO:root:current train perplexity4.012149810791016
INFO:root:current mean train loss 3534.0817723576756
INFO:root:current train perplexity4.0198588371276855
INFO:root:current mean train loss 3531.7451947913646
INFO:root:current train perplexity4.018043518066406
INFO:root:current mean train loss 3526.5979969434147
INFO:root:current train perplexity4.01945161819458
INFO:root:current mean train loss 3531.12427067341
INFO:root:current train perplexity4.026034832000732
INFO:root:current mean train loss 3526.614351327377
INFO:root:current train perplexity4.02208137512207
INFO:root:current mean train loss 3527.249452372894
INFO:root:current train perplexity4.0220537185668945
INFO:root:current mean train loss 3529.330677856052
INFO:root:current train perplexity4.022661209106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.79s/it]
INFO:root:final mean train loss: 3527.8547592163086
INFO:root:final train perplexity: 4.022247791290283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3704.03170191988
INFO:root:eval perplexity: 4.471848011016846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 4645.373377590315
INFO:root:eval perplexity: 6.682933807373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [17:17:58<15:37:21, 592.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3502.1682629707534
INFO:root:current train perplexity3.9685580730438232
INFO:root:current mean train loss 3510.5562858307103
INFO:root:current train perplexity3.9925811290740967
INFO:root:current mean train loss 3517.5188141507583
INFO:root:current train perplexity4.003199100494385
INFO:root:current mean train loss 3525.862123202434
INFO:root:current train perplexity4.006476879119873
INFO:root:current mean train loss 3520.4502987524916
INFO:root:current train perplexity4.005004405975342
INFO:root:current mean train loss 3517.06644022133
INFO:root:current train perplexity4.000627040863037
INFO:root:current mean train loss 3518.89277412522
INFO:root:current train perplexity4.003813743591309
INFO:root:current mean train loss 3521.489575294422
INFO:root:current train perplexity4.006440162658691
INFO:root:current mean train loss 3519.6636164123024
INFO:root:current train perplexity4.005464553833008
INFO:root:current mean train loss 3522.4896436534877
INFO:root:current train perplexity4.01077938079834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.38s/it]
INFO:root:final mean train loss: 3520.684464916106
INFO:root:final train perplexity: 4.010885238647461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 3707.3555033798757
INFO:root:eval perplexity: 4.477862358093262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4652.072663868573
INFO:root:eval perplexity: 6.701265811920166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [17:27:54<15:29:23, 593.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.6023936170213
INFO:root:current train perplexity4.006604194641113
INFO:root:current mean train loss 3524.0738749601405
INFO:root:current train perplexity4.007094383239746
INFO:root:current mean train loss 3500.652493001961
INFO:root:current train perplexity3.981656789779663
INFO:root:current mean train loss 3502.9542099130945
INFO:root:current train perplexity3.979556083679199
INFO:root:current mean train loss 3503.038506492939
INFO:root:current train perplexity3.9823241233825684
INFO:root:current mean train loss 3501.0177566556217
INFO:root:current train perplexity3.983959913253784
INFO:root:current mean train loss 3504.9307010420694
INFO:root:current train perplexity3.987746477127075
INFO:root:current mean train loss 3504.058595710969
INFO:root:current train perplexity3.9875895977020264
INFO:root:current mean train loss 3508.0601231598657
INFO:root:current train perplexity3.989718437194824
INFO:root:current mean train loss 3509.8609001699447
INFO:root:current train perplexity3.991075038909912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.83s/it]
INFO:root:final mean train loss: 3509.158788865612
INFO:root:final train perplexity: 3.9926881790161133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 3693.8124722960993
INFO:root:eval perplexity: 4.453406810760498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 4634.9149542193045
INFO:root:eval perplexity: 6.65441370010376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [17:37:47<15:19:04, 592.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.4081853693183
INFO:root:current train perplexity3.971637725830078
INFO:root:current mean train loss 3500.5606461063508
INFO:root:current train perplexity3.9700803756713867
INFO:root:current mean train loss 3494.2571662454043
INFO:root:current train perplexity3.9673070907592773
INFO:root:current mean train loss 3490.3014311454667
INFO:root:current train perplexity3.963871717453003
INFO:root:current mean train loss 3495.594101991758
INFO:root:current train perplexity3.968625783920288
INFO:root:current mean train loss 3496.6085950696793
INFO:root:current train perplexity3.970269203186035
INFO:root:current mean train loss 3495.977111536856
INFO:root:current train perplexity3.9703047275543213
INFO:root:current mean train loss 3500.4846896342096
INFO:root:current train perplexity3.9754323959350586
INFO:root:current mean train loss 3501.1530953033625
INFO:root:current train perplexity3.9749109745025635
INFO:root:current mean train loss 3499.211238138089
INFO:root:current train perplexity3.971571445465088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.47s/it]
INFO:root:final mean train loss: 3497.4657627228767
INFO:root:final train perplexity: 3.9743118286132812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 3713.5894939882537
INFO:root:eval perplexity: 4.489164352416992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4658.479171861148
INFO:root:eval perplexity: 6.718842506408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [17:47:38<15:08:17, 592.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3450.922797309028
INFO:root:current train perplexity3.974593162536621
INFO:root:current mean train loss 3476.283635987826
INFO:root:current train perplexity3.9538185596466064
INFO:root:current mean train loss 3479.203931685183
INFO:root:current train perplexity3.9515411853790283
INFO:root:current mean train loss 3484.871056758996
INFO:root:current train perplexity3.953333616256714
INFO:root:current mean train loss 3482.9027550452215
INFO:root:current train perplexity3.953002691268921
INFO:root:current mean train loss 3489.374059863455
INFO:root:current train perplexity3.963181734085083
INFO:root:current mean train loss 3492.520834069806
INFO:root:current train perplexity3.9668519496917725
INFO:root:current mean train loss 3490.7946668552386
INFO:root:current train perplexity3.962553024291992
INFO:root:current mean train loss 3493.3618727028716
INFO:root:current train perplexity3.9667911529541016
INFO:root:current mean train loss 3495.304254486306
INFO:root:current train perplexity3.9673187732696533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.53s/it]
INFO:root:final mean train loss: 3493.0909843444824
INFO:root:final train perplexity: 3.9674577713012695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3698.5984094498003
INFO:root:eval perplexity: 4.462033748626709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 4641.977357255651
INFO:root:eval perplexity: 6.673659324645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [17:57:29<14:57:58, 592.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.0057527783893
INFO:root:current train perplexity3.971442699432373
INFO:root:current mean train loss 3491.650333516082
INFO:root:current train perplexity3.9582653045654297
INFO:root:current mean train loss 3495.452596178794
INFO:root:current train perplexity3.9636716842651367
INFO:root:current mean train loss 3508.304906634308
INFO:root:current train perplexity3.973010540008545
INFO:root:current mean train loss 3499.927281341229
INFO:root:current train perplexity3.966233491897583
INFO:root:current mean train loss 3494.697622215685
INFO:root:current train perplexity3.9577791690826416
INFO:root:current mean train loss 3489.494551043219
INFO:root:current train perplexity3.9529876708984375
INFO:root:current mean train loss 3489.2534907992867
INFO:root:current train perplexity3.9528231620788574
INFO:root:current mean train loss 3488.2851220534944
INFO:root:current train perplexity3.955911874771118
INFO:root:current mean train loss 3488.8567902774203
INFO:root:current train perplexity3.9567999839782715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.69s/it]
INFO:root:final mean train loss: 3486.1483939386185
INFO:root:final train perplexity: 3.9566051959991455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 3695.2586314965647
INFO:root:eval perplexity: 4.456011772155762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 4640.052358640846
INFO:root:eval perplexity: 6.668408393859863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [18:07:21<14:48:09, 592.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3473.204861797864
INFO:root:current train perplexity3.9358808994293213
INFO:root:current mean train loss 3474.773661181913
INFO:root:current train perplexity3.9279019832611084
INFO:root:current mean train loss 3478.8126408840167
INFO:root:current train perplexity3.932149648666382
INFO:root:current mean train loss 3480.7219760059365
INFO:root:current train perplexity3.934953451156616
INFO:root:current mean train loss 3482.7343571609144
INFO:root:current train perplexity3.9422101974487305
INFO:root:current mean train loss 3479.5718806502323
INFO:root:current train perplexity3.94362735748291
INFO:root:current mean train loss 3475.695384771378
INFO:root:current train perplexity3.939812421798706
INFO:root:current mean train loss 3478.276404795812
INFO:root:current train perplexity3.939110279083252
INFO:root:current mean train loss 3479.6446712350685
INFO:root:current train perplexity3.9405369758605957
INFO:root:current mean train loss 3478.063729431339
INFO:root:current train perplexity3.9403398036956787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.78s/it]
INFO:root:final mean train loss: 3476.2435051702682
INFO:root:final train perplexity: 3.941174030303955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 3700.444722060616
INFO:root:eval perplexity: 4.465365886688232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 4642.050729305186
INFO:root:eval perplexity: 6.673859119415283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [18:17:15<14:39:07, 592.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.797360475036
INFO:root:current train perplexity3.9522550106048584
INFO:root:current mean train loss 3470.7200647037935
INFO:root:current train perplexity3.932549238204956
INFO:root:current mean train loss 3482.781536673835
INFO:root:current train perplexity3.942100763320923
INFO:root:current mean train loss 3477.91985626615
INFO:root:current train perplexity3.9384593963623047
INFO:root:current mean train loss 3476.7771321948794
INFO:root:current train perplexity3.9344534873962402
INFO:root:current mean train loss 3476.292816941945
INFO:root:current train perplexity3.934291124343872
INFO:root:current mean train loss 3472.12314211472
INFO:root:current train perplexity3.932440757751465
INFO:root:current mean train loss 3474.1287663422213
INFO:root:current train perplexity3.9347920417785645
INFO:root:current mean train loss 3473.399275064737
INFO:root:current train perplexity3.9347076416015625
INFO:root:current mean train loss 3472.9657809828554
INFO:root:current train perplexity3.932220935821533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.30s/it]
INFO:root:final mean train loss: 3470.917678833008
INFO:root:final train perplexity: 3.93290114402771
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 3675.2073983266846
INFO:root:eval perplexity: 4.420027732849121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 4620.140950520833
INFO:root:eval perplexity: 6.614333629608154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [18:27:11<14:30:29, 593.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3458.2948833264804
INFO:root:current train perplexity3.914152145385742
INFO:root:current mean train loss 3450.2602426382214
INFO:root:current train perplexity3.9246110916137695
INFO:root:current mean train loss 3454.2221447960806
INFO:root:current train perplexity3.919348955154419
INFO:root:current mean train loss 3447.4835548111155
INFO:root:current train perplexity3.910884141921997
INFO:root:current mean train loss 3450.74209280303
INFO:root:current train perplexity3.9140326976776123
INFO:root:current mean train loss 3455.510800452994
INFO:root:current train perplexity3.912675619125366
INFO:root:current mean train loss 3458.52074598134
INFO:root:current train perplexity3.9120659828186035
INFO:root:current mean train loss 3461.9006931136987
INFO:root:current train perplexity3.9147872924804688
INFO:root:current mean train loss 3463.0514651165327
INFO:root:current train perplexity3.913724422454834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.44s/it]
INFO:root:final mean train loss: 3460.298538700227
INFO:root:final train perplexity: 3.91645884513855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3677.264340231605
INFO:root:eval perplexity: 4.423705577850342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4620.762908286237
INFO:root:eval perplexity: 6.616016387939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [18:37:07<14:21:44, 594.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.9619140625
INFO:root:current train perplexity3.8337693214416504
INFO:root:current mean train loss 3441.5037948460254
INFO:root:current train perplexity3.8932952880859375
INFO:root:current mean train loss 3443.4617541082976
INFO:root:current train perplexity3.9005115032196045
INFO:root:current mean train loss 3448.786017591017
INFO:root:current train perplexity3.899681568145752
INFO:root:current mean train loss 3443.457826675907
INFO:root:current train perplexity3.8965909481048584
INFO:root:current mean train loss 3449.213865246024
INFO:root:current train perplexity3.897426128387451
INFO:root:current mean train loss 3450.315513901845
INFO:root:current train perplexity3.8976998329162598
INFO:root:current mean train loss 3454.5048908000313
INFO:root:current train perplexity3.901761054992676
INFO:root:current mean train loss 3455.4469530763545
INFO:root:current train perplexity3.905965805053711
INFO:root:current mean train loss 3454.557907560735
INFO:root:current train perplexity3.9053587913513184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.73s/it]
INFO:root:final mean train loss: 3452.3763552019673
INFO:root:final train perplexity: 3.9042367935180664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3674.006051570811
INFO:root:eval perplexity: 4.417881488800049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 4621.706454662566
INFO:root:eval perplexity: 6.618569850921631
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [18:47:00<14:11:15, 593.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3432.047274502841
INFO:root:current train perplexity3.8926093578338623
INFO:root:current mean train loss 3404.9003730292793
INFO:root:current train perplexity3.8465166091918945
INFO:root:current mean train loss 3437.294639551244
INFO:root:current train perplexity3.8947255611419678
INFO:root:current mean train loss 3450.8676145498393
INFO:root:current train perplexity3.9118030071258545
INFO:root:current mean train loss 3448.1287743784214
INFO:root:current train perplexity3.902341604232788
INFO:root:current mean train loss 3445.4373213139065
INFO:root:current train perplexity3.895000457763672
INFO:root:current mean train loss 3442.1964001444867
INFO:root:current train perplexity3.889162540435791
INFO:root:current mean train loss 3444.7746080701695
INFO:root:current train perplexity3.8901960849761963
INFO:root:current mean train loss 3441.800211086814
INFO:root:current train perplexity3.887281656265259
INFO:root:current mean train loss 3442.2337864897777
INFO:root:current train perplexity3.888270378112793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.33s/it]
INFO:root:final mean train loss: 3443.4464372204197
INFO:root:final train perplexity: 3.8905069828033447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3674.00013678801
INFO:root:eval perplexity: 4.417870044708252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 4623.603685311392
INFO:root:eval perplexity: 6.6237053871154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [18:57:01<14:04:41, 596.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.370476973684
INFO:root:current train perplexity3.900339126586914
INFO:root:current mean train loss 3468.78496134782
INFO:root:current train perplexity3.895193099975586
INFO:root:current mean train loss 3437.6379316495436
INFO:root:current train perplexity3.8814430236816406
INFO:root:current mean train loss 3438.617058924373
INFO:root:current train perplexity3.880699634552002
INFO:root:current mean train loss 3442.3152438143275
INFO:root:current train perplexity3.886017322540283
INFO:root:current mean train loss 3440.267317520171
INFO:root:current train perplexity3.8864190578460693
INFO:root:current mean train loss 3438.950802311566
INFO:root:current train perplexity3.884054183959961
INFO:root:current mean train loss 3437.9397417474356
INFO:root:current train perplexity3.8811261653900146
INFO:root:current mean train loss 3437.862739013374
INFO:root:current train perplexity3.8783769607543945
INFO:root:current mean train loss 3439.1019487681924
INFO:root:current train perplexity3.8807179927825928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.02s/it]
INFO:root:final mean train loss: 3438.2439665640554
INFO:root:final train perplexity: 3.882528781890869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3675.224354845412
INFO:root:eval perplexity: 4.420057773590088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 4623.8588901817375
INFO:root:eval perplexity: 6.6243977546691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [19:06:53<13:52:42, 594.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3509.127106843171
INFO:root:current train perplexity3.916747808456421
INFO:root:current mean train loss 3456.1066510057826
INFO:root:current train perplexity3.890578269958496
INFO:root:current mean train loss 3441.110612911275
INFO:root:current train perplexity3.875260353088379
INFO:root:current mean train loss 3438.8565251994937
INFO:root:current train perplexity3.8770952224731445
INFO:root:current mean train loss 3448.1467393790253
INFO:root:current train perplexity3.8854942321777344
INFO:root:current mean train loss 3440.6138510658798
INFO:root:current train perplexity3.879167318344116
INFO:root:current mean train loss 3432.394200277861
INFO:root:current train perplexity3.871237277984619
INFO:root:current mean train loss 3433.99114444528
INFO:root:current train perplexity3.873701333999634
INFO:root:current mean train loss 3432.9157475721736
INFO:root:current train perplexity3.8739421367645264
INFO:root:current mean train loss 3434.7609831677287
INFO:root:current train perplexity3.8744330406188965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.02s/it]
INFO:root:final mean train loss: 3433.794565754552
INFO:root:final train perplexity: 3.8757190704345703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3711.3240456006206
INFO:root:eval perplexity: 4.485054016113281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4662.138278825909
INFO:root:eval perplexity: 6.728904724121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [19:16:45<13:41:51, 594.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3436.9788155691963
INFO:root:current train perplexity3.851991891860962
INFO:root:current mean train loss 3437.0808684172453
INFO:root:current train perplexity3.8492674827575684
INFO:root:current mean train loss 3432.722381981383
INFO:root:current train perplexity3.8525006771087646
INFO:root:current mean train loss 3437.187546641791
INFO:root:current train perplexity3.8535704612731934
INFO:root:current mean train loss 3434.2912945626795
INFO:root:current train perplexity3.8599588871002197
INFO:root:current mean train loss 3435.814338584258
INFO:root:current train perplexity3.8647730350494385
INFO:root:current mean train loss 3432.397121831939
INFO:root:current train perplexity3.863485097885132
INFO:root:current mean train loss 3432.1160295758928
INFO:root:current train perplexity3.860314130783081
INFO:root:current mean train loss 3435.210111807635
INFO:root:current train perplexity3.8681142330169678
INFO:root:current mean train loss 3431.7644815863137
INFO:root:current train perplexity3.8644542694091797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.15s/it]
INFO:root:final mean train loss: 3428.5327144130583
INFO:root:final train perplexity: 3.867682695388794
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 3669.4580303219195
INFO:root:eval perplexity: 4.409763336181641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 4620.862022454012
INFO:root:eval perplexity: 6.616283893585205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [19:26:39<13:31:35, 593.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.552251771439
INFO:root:current train perplexity3.8308286666870117
INFO:root:current mean train loss 3413.3832580993226
INFO:root:current train perplexity3.8310463428497314
INFO:root:current mean train loss 3429.964740266525
INFO:root:current train perplexity3.849900245666504
INFO:root:current mean train loss 3423.598725343932
INFO:root:current train perplexity3.856077194213867
INFO:root:current mean train loss 3422.761781025148
INFO:root:current train perplexity3.8548312187194824
INFO:root:current mean train loss 3425.2668232224046
INFO:root:current train perplexity3.8609459400177
INFO:root:current mean train loss 3428.287210752211
INFO:root:current train perplexity3.8637707233428955
INFO:root:current mean train loss 3430.0845173441708
INFO:root:current train perplexity3.8657922744750977
INFO:root:current mean train loss 3427.5112133818025
INFO:root:current train perplexity3.8633482456207275
INFO:root:current mean train loss 3428.8698023677757
INFO:root:current train perplexity3.863400936126709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.82s/it]
INFO:root:final mean train loss: 3423.946018157467
INFO:root:final train perplexity: 3.860689640045166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 3667.5026630374555
INFO:root:eval perplexity: 4.40627908706665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 4618.055130762411
INFO:root:eval perplexity: 6.6086955070495605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [19:36:34<13:22:08, 594.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.998597388174
INFO:root:current train perplexity3.8486108779907227
INFO:root:current mean train loss 3410.0218659457782
INFO:root:current train perplexity3.833207607269287
INFO:root:current mean train loss 3416.8714186223856
INFO:root:current train perplexity3.843998670578003
INFO:root:current mean train loss 3417.5512187555646
INFO:root:current train perplexity3.8471293449401855
INFO:root:current mean train loss 3423.1298167700247
INFO:root:current train perplexity3.8511171340942383
INFO:root:current mean train loss 3420.1594938357816
INFO:root:current train perplexity3.845133066177368
INFO:root:current mean train loss 3416.972226472494
INFO:root:current train perplexity3.848356246948242
INFO:root:current mean train loss 3419.712890625
INFO:root:current train perplexity3.8527450561523438
INFO:root:current mean train loss 3418.4398518975836
INFO:root:current train perplexity3.8510735034942627
INFO:root:current mean train loss 3419.1353424746158
INFO:root:current train perplexity3.8505241870880127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.51s/it]
INFO:root:final mean train loss: 3417.2210633062546
INFO:root:final train perplexity: 3.8504602909088135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 3664.304761954233
INFO:root:eval perplexity: 4.400583267211914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4616.0924738890735
INFO:root:eval perplexity: 6.603392124176025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [19:46:33<13:14:14, 595.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.7798596398306
INFO:root:current train perplexity3.812683343887329
INFO:root:current mean train loss 3386.4370516411163
INFO:root:current train perplexity3.8148019313812256
INFO:root:current mean train loss 3385.5616723727076
INFO:root:current train perplexity3.810920000076294
INFO:root:current mean train loss 3394.580764983026
INFO:root:current train perplexity3.820021152496338
INFO:root:current mean train loss 3402.0404906428716
INFO:root:current train perplexity3.8208401203155518
INFO:root:current mean train loss 3403.8488188659994
INFO:root:current train perplexity3.8243894577026367
INFO:root:current mean train loss 3405.3576200771768
INFO:root:current train perplexity3.8265159130096436
INFO:root:current mean train loss 3407.227928272192
INFO:root:current train perplexity3.829895257949829
INFO:root:current mean train loss 3409.7630468863686
INFO:root:current train perplexity3.833242893218994
INFO:root:current mean train loss 3409.0419506912312
INFO:root:current train perplexity3.833099842071533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.08s/it]
INFO:root:final mean train loss: 3406.183647217289
INFO:root:final train perplexity: 3.8337290287017822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3652.5423090508643
INFO:root:eval perplexity: 4.379703044891357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4607.504510541335
INFO:root:eval perplexity: 6.580244064331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [19:56:29<13:04:23, 595.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.7957271746736
INFO:root:current train perplexity3.800278425216675
INFO:root:current mean train loss 3397.623636028724
INFO:root:current train perplexity3.8139421939849854
INFO:root:current mean train loss 3409.905641020014
INFO:root:current train perplexity3.8234663009643555
INFO:root:current mean train loss 3407.1569152333104
INFO:root:current train perplexity3.8236687183380127
INFO:root:current mean train loss 3408.654451096594
INFO:root:current train perplexity3.8319809436798096
INFO:root:current mean train loss 3403.89609986428
INFO:root:current train perplexity3.8283495903015137
INFO:root:current mean train loss 3400.682078028369
INFO:root:current train perplexity3.8237717151641846
INFO:root:current mean train loss 3402.3108352601453
INFO:root:current train perplexity3.826976776123047
INFO:root:current mean train loss 3399.8922202210388
INFO:root:current train perplexity3.8226583003997803
INFO:root:current mean train loss 3403.0271352079562
INFO:root:current train perplexity3.8242194652557373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it]
INFO:root:final mean train loss: 3400.5598047318
INFO:root:final train perplexity: 3.82523250579834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3655.338204025377
INFO:root:eval perplexity: 4.384657382965088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 4609.5374383588205
INFO:root:eval perplexity: 6.585717678070068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [20:06:21<12:53:05, 594.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3382.065625
INFO:root:current train perplexity3.811431407928467
INFO:root:current mean train loss 3405.381919642857
INFO:root:current train perplexity3.822312116622925
INFO:root:current mean train loss 3393.068875177557
INFO:root:current train perplexity3.821697473526001
INFO:root:current mean train loss 3396.854135416667
INFO:root:current train perplexity3.8215816020965576
INFO:root:current mean train loss 3405.3426243832237
INFO:root:current train perplexity3.822892665863037
INFO:root:current mean train loss 3406.1637045686143
INFO:root:current train perplexity3.8255667686462402
INFO:root:current mean train loss 3405.243976056134
INFO:root:current train perplexity3.822263717651367
INFO:root:current mean train loss 3401.187652469758
INFO:root:current train perplexity3.8173139095306396
INFO:root:current mean train loss 3402.1438359375
INFO:root:current train perplexity3.8184633255004883
INFO:root:current mean train loss 3400.6204690004006
INFO:root:current train perplexity3.819446563720703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.92s/it]
INFO:root:final mean train loss: 3396.4012667748234
INFO:root:final train perplexity: 3.8189616203308105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3649.451564924091
INFO:root:eval perplexity: 4.374232769012451
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4603.080656443927
INFO:root:eval perplexity: 6.568351745605469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [20:16:12<12:41:56, 593.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.524987645896
INFO:root:current train perplexity3.7856690883636475
INFO:root:current mean train loss 3393.483695942196
INFO:root:current train perplexity3.812822103500366
INFO:root:current mean train loss 3401.930168879748
INFO:root:current train perplexity3.825334310531616
INFO:root:current mean train loss 3400.8654976389116
INFO:root:current train perplexity3.8264288902282715
INFO:root:current mean train loss 3400.820507104846
INFO:root:current train perplexity3.8264849185943604
INFO:root:current mean train loss 3396.6252202709584
INFO:root:current train perplexity3.8224356174468994
INFO:root:current mean train loss 3393.6716569534683
INFO:root:current train perplexity3.8173418045043945
INFO:root:current mean train loss 3395.6782744153097
INFO:root:current train perplexity3.815300941467285
INFO:root:current mean train loss 3392.872797481066
INFO:root:current train perplexity3.8113651275634766
INFO:root:current mean train loss 3395.9196352643376
INFO:root:current train perplexity3.8145060539245605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.80s/it]
INFO:root:final mean train loss: 3393.5137981907014
INFO:root:final train perplexity: 3.8146142959594727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 3656.3619999445923
INFO:root:eval perplexity: 4.386472702026367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4611.86217655696
INFO:root:eval perplexity: 6.591979503631592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [20:26:03<12:30:43, 592.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3403.123975145948
INFO:root:current train perplexity3.8011608123779297
INFO:root:current mean train loss 3388.1213059350457
INFO:root:current train perplexity3.8055148124694824
INFO:root:current mean train loss 3384.8560702923646
INFO:root:current train perplexity3.803875207901001
INFO:root:current mean train loss 3389.311820027773
INFO:root:current train perplexity3.7981107234954834
INFO:root:current mean train loss 3382.287369924262
INFO:root:current train perplexity3.7946197986602783
INFO:root:current mean train loss 3381.103844037516
INFO:root:current train perplexity3.794975757598877
INFO:root:current mean train loss 3382.092028649602
INFO:root:current train perplexity3.7933998107910156
INFO:root:current mean train loss 3384.0923848495772
INFO:root:current train perplexity3.7972443103790283
INFO:root:current mean train loss 3386.489807197408
INFO:root:current train perplexity3.8011155128479004
INFO:root:current mean train loss 3389.8524185935134
INFO:root:current train perplexity3.8051116466522217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.77s/it]
INFO:root:final mean train loss: 3387.06397210398
INFO:root:final train perplexity: 3.8049192428588867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 3660.493472268395
INFO:root:eval perplexity: 4.3938069343566895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4618.048332917775
INFO:root:eval perplexity: 6.608676433563232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [20:35:53<12:19:50, 591.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3377.254811296559
INFO:root:current train perplexity3.7752268314361572
INFO:root:current mean train loss 3392.663244199513
INFO:root:current train perplexity3.7977192401885986
INFO:root:current mean train loss 3387.270468619356
INFO:root:current train perplexity3.797137498855591
INFO:root:current mean train loss 3383.6319577018717
INFO:root:current train perplexity3.7968626022338867
INFO:root:current mean train loss 3379.235284044652
INFO:root:current train perplexity3.796769857406616
INFO:root:current mean train loss 3380.355299604158
INFO:root:current train perplexity3.7954394817352295
INFO:root:current mean train loss 3381.4134030758228
INFO:root:current train perplexity3.7960638999938965
INFO:root:current mean train loss 3383.1241774385953
INFO:root:current train perplexity3.7953855991363525
INFO:root:current mean train loss 3384.8149213101365
INFO:root:current train perplexity3.7976479530334473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.95s/it]
INFO:root:final mean train loss: 3384.839677626087
INFO:root:final train perplexity: 3.801581382751465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3652.4020857574246
INFO:root:eval perplexity: 4.379455089569092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4609.898813234154
INFO:root:eval perplexity: 6.586690425872803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [20:45:43<12:09:30, 591.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3411.5216238839284
INFO:root:current train perplexity3.8303937911987305
INFO:root:current mean train loss 3365.9968740873246
INFO:root:current train perplexity3.7645187377929688
INFO:root:current mean train loss 3384.7922610960145
INFO:root:current train perplexity3.785555839538574
INFO:root:current mean train loss 3387.90297517559
INFO:root:current train perplexity3.7816781997680664
INFO:root:current mean train loss 3377.806049768696
INFO:root:current train perplexity3.7724974155426025
INFO:root:current mean train loss 3379.933453621949
INFO:root:current train perplexity3.7799813747406006
INFO:root:current mean train loss 3383.8370572487643
INFO:root:current train perplexity3.787778615951538
INFO:root:current mean train loss 3381.2756965777494
INFO:root:current train perplexity3.7873456478118896
INFO:root:current mean train loss 3383.9025645959186
INFO:root:current train perplexity3.7930774688720703
INFO:root:current mean train loss 3381.602953859306
INFO:root:current train perplexity3.791274309158325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.49s/it]
INFO:root:final mean train loss: 3378.0151033709126
INFO:root:final train perplexity: 3.7913596630096436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 3642.761323969415
INFO:root:eval perplexity: 4.362414836883545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4599.997752521055
INFO:root:eval perplexity: 6.560076713562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [20:55:35<11:59:52, 591.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.8120279947916
INFO:root:current train perplexity3.682925224304199
INFO:root:current mean train loss 3347.564523182745
INFO:root:current train perplexity3.7648355960845947
INFO:root:current mean train loss 3352.44230559593
INFO:root:current train perplexity3.7728734016418457
INFO:root:current mean train loss 3369.5333891369046
INFO:root:current train perplexity3.777879476547241
INFO:root:current mean train loss 3370.8723003341493
INFO:root:current train perplexity3.7775073051452637
INFO:root:current mean train loss 3370.140321127882
INFO:root:current train perplexity3.7741923332214355
INFO:root:current mean train loss 3372.28688111344
INFO:root:current train perplexity3.778346300125122
INFO:root:current mean train loss 3373.6441498442964
INFO:root:current train perplexity3.779742956161499
INFO:root:current mean train loss 3374.3114102041795
INFO:root:current train perplexity3.779478073120117
INFO:root:current mean train loss 3377.481868222763
INFO:root:current train perplexity3.782047986984253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.22s/it]
INFO:root:final mean train loss: 3370.927796886813
INFO:root:final train perplexity: 3.780773162841797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 3654.2054417386967
INFO:root:eval perplexity: 4.3826494216918945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4611.87849069149
INFO:root:eval perplexity: 6.592023849487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [21:05:26<11:49:36, 591.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3396.8156101392665
INFO:root:current train perplexity3.8124356269836426
INFO:root:current mean train loss 3372.861266593623
INFO:root:current train perplexity3.7852935791015625
INFO:root:current mean train loss 3358.579001935608
INFO:root:current train perplexity3.7661867141723633
INFO:root:current mean train loss 3367.3399140443594
INFO:root:current train perplexity3.7751975059509277
INFO:root:current mean train loss 3370.820915637005
INFO:root:current train perplexity3.775906801223755
INFO:root:current mean train loss 3369.7805689270135
INFO:root:current train perplexity3.7749996185302734
INFO:root:current mean train loss 3367.938111723139
INFO:root:current train perplexity3.773083448410034
INFO:root:current mean train loss 3371.253169100644
INFO:root:current train perplexity3.7773046493530273
INFO:root:current mean train loss 3368.56772306681
INFO:root:current train perplexity3.7768287658691406
INFO:root:current mean train loss 3372.1753942752066
INFO:root:current train perplexity3.7780356407165527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.09s/it]
INFO:root:final mean train loss: 3367.7426201605026
INFO:root:final train perplexity: 3.77602481842041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 3650.160305158466
INFO:root:eval perplexity: 4.375486373901367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 4607.838787538785
INFO:root:eval perplexity: 6.581143856048584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [21:15:18<11:39:58, 591.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.2803679435483
INFO:root:current train perplexity3.674455404281616
INFO:root:current mean train loss 3330.8020410901718
INFO:root:current train perplexity3.7365293502807617
INFO:root:current mean train loss 3339.1108778916396
INFO:root:current train perplexity3.741887331008911
INFO:root:current mean train loss 3344.7675375578265
INFO:root:current train perplexity3.7502756118774414
INFO:root:current mean train loss 3343.000923882504
INFO:root:current train perplexity3.748293876647949
INFO:root:current mean train loss 3350.8982586474517
INFO:root:current train perplexity3.7574901580810547
INFO:root:current mean train loss 3350.2153223584837
INFO:root:current train perplexity3.755718946456909
INFO:root:current mean train loss 3356.8468657153085
INFO:root:current train perplexity3.7597787380218506
INFO:root:current mean train loss 3362.406606075135
INFO:root:current train perplexity3.763648748397827
INFO:root:current mean train loss 3361.2407315722344
INFO:root:current train perplexity3.7632813453674316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.05s/it]
INFO:root:final mean train loss: 3359.47393964952
INFO:root:final train perplexity: 3.7637269496917725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 3636.152799132868
INFO:root:eval perplexity: 4.350772380828857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 4596.759621911015
INFO:root:eval perplexity: 6.551396369934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [21:25:11<11:30:34, 591.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.7364408052886
INFO:root:current train perplexity3.7351417541503906
INFO:root:current mean train loss 3345.013447054856
INFO:root:current train perplexity3.757984161376953
INFO:root:current mean train loss 3346.075829669521
INFO:root:current train perplexity3.7478528022766113
INFO:root:current mean train loss 3347.696681559965
INFO:root:current train perplexity3.752983570098877
INFO:root:current mean train loss 3351.0963660307516
INFO:root:current train perplexity3.758709192276001
INFO:root:current mean train loss 3353.115682796556
INFO:root:current train perplexity3.759075164794922
INFO:root:current mean train loss 3349.0002578950266
INFO:root:current train perplexity3.7526350021362305
INFO:root:current mean train loss 3352.766268553366
INFO:root:current train perplexity3.754636526107788
INFO:root:current mean train loss 3352.0605526948
INFO:root:current train perplexity3.7536184787750244
INFO:root:current mean train loss 3352.5789905422157
INFO:root:current train perplexity3.751112461090088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.28s/it]
INFO:root:final mean train loss: 3350.9485565923874
INFO:root:final train perplexity: 3.751088857650757
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 3635.167151484929
INFO:root:eval perplexity: 4.349038124084473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 4595.97294367797
INFO:root:eval perplexity: 6.549289226531982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [21:35:04<11:21:12, 592.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.389653631981
INFO:root:current train perplexity3.6924080848693848
INFO:root:current mean train loss 3343.9463604777848
INFO:root:current train perplexity3.7410223484039307
INFO:root:current mean train loss 3344.2791199471785
INFO:root:current train perplexity3.736611843109131
INFO:root:current mean train loss 3341.1133579397065
INFO:root:current train perplexity3.732484817504883
INFO:root:current mean train loss 3344.437583564912
INFO:root:current train perplexity3.7341840267181396
INFO:root:current mean train loss 3347.4885651136883
INFO:root:current train perplexity3.738172769546509
INFO:root:current mean train loss 3345.7204404945905
INFO:root:current train perplexity3.735933780670166
INFO:root:current mean train loss 3343.6397504078814
INFO:root:current train perplexity3.734621286392212
INFO:root:current mean train loss 3346.703418718178
INFO:root:current train perplexity3.7417542934417725
INFO:root:current mean train loss 3348.3479163744887
INFO:root:current train perplexity3.7432878017425537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it]
INFO:root:final mean train loss: 3347.355619615124
INFO:root:final train perplexity: 3.7457759380340576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 3638.397940561281
INFO:root:eval perplexity: 4.354724884033203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4598.3237166168
INFO:root:eval perplexity: 6.555587291717529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [21:44:55<11:10:59, 592.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.349920099432
INFO:root:current train perplexity3.7211992740631104
INFO:root:current mean train loss 3351.931227948589
INFO:root:current train perplexity3.732015371322632
INFO:root:current mean train loss 3348.7572476256128
INFO:root:current train perplexity3.736060857772827
INFO:root:current mean train loss 3353.020048415493
INFO:root:current train perplexity3.743712902069092
INFO:root:current mean train loss 3347.731697501717
INFO:root:current train perplexity3.738880157470703
INFO:root:current mean train loss 3348.863110571509
INFO:root:current train perplexity3.744750738143921
INFO:root:current mean train loss 3348.659438737476
INFO:root:current train perplexity3.7427477836608887
INFO:root:current mean train loss 3345.7156557196813
INFO:root:current train perplexity3.7402613162994385
INFO:root:current mean train loss 3344.771052631579
INFO:root:current train perplexity3.738569974899292
INFO:root:current mean train loss 3344.2091467093423
INFO:root:current train perplexity3.7371926307678223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it]
INFO:root:final mean train loss: 3342.9089408382292
INFO:root:final train perplexity: 3.7392098903656006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3634.885248711769
INFO:root:eval perplexity: 4.348543167114258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 4595.998022634087
INFO:root:eval perplexity: 6.549356937408447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [21:54:47<11:01:00, 591.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.4552021329364
INFO:root:current train perplexity3.7411317825317383
INFO:root:current mean train loss 3358.9914835362347
INFO:root:current train perplexity3.742677688598633
INFO:root:current mean train loss 3361.928695156547
INFO:root:current train perplexity3.740567922592163
INFO:root:current mean train loss 3356.6207292204717
INFO:root:current train perplexity3.741050958633423
INFO:root:current mean train loss 3350.0160104574447
INFO:root:current train perplexity3.7398908138275146
INFO:root:current mean train loss 3345.605247592418
INFO:root:current train perplexity3.7332351207733154
INFO:root:current mean train loss 3344.9635928515036
INFO:root:current train perplexity3.73260760307312
INFO:root:current mean train loss 3343.7624754899452
INFO:root:current train perplexity3.730257272720337
INFO:root:current mean train loss 3343.758203747375
INFO:root:current train perplexity3.734581470489502
INFO:root:current mean train loss 3341.59994250146
INFO:root:current train perplexity3.7331295013427734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.02s/it]
INFO:root:final mean train loss: 3339.3730860064106
INFO:root:final train perplexity: 3.7339975833892822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3627.9639139378323
INFO:root:eval perplexity: 4.336389541625977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4590.676712793661
INFO:root:eval perplexity: 6.535120010375977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [22:04:40<10:51:25, 592.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3305.88798759353
INFO:root:current train perplexity3.687410593032837
INFO:root:current mean train loss 3320.9359851859467
INFO:root:current train perplexity3.709360361099243
INFO:root:current mean train loss 3319.2037808464024
INFO:root:current train perplexity3.702716588973999
INFO:root:current mean train loss 3323.03006614829
INFO:root:current train perplexity3.709160566329956
INFO:root:current mean train loss 3324.408407353039
INFO:root:current train perplexity3.7078258991241455
INFO:root:current mean train loss 3326.377227195299
INFO:root:current train perplexity3.716996908187866
INFO:root:current mean train loss 3389.1456289731977
INFO:root:current train perplexity3.8089301586151123
INFO:root:current mean train loss 3417.6542873753647
INFO:root:current train perplexity3.852277994155884
INFO:root:current mean train loss 3437.3070151047646
INFO:root:current train perplexity3.878683090209961
INFO:root:current mean train loss 3446.1877275461025
INFO:root:current train perplexity3.8910045623779297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.48s/it]
INFO:root:final mean train loss: 3445.351144729122
INFO:root:final train perplexity: 3.893430233001709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3738.1912417580897
INFO:root:eval perplexity: 4.5340471267700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 4702.267888062389
INFO:root:eval perplexity: 6.84023380279541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [22:14:34<10:42:10, 592.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.6000111253957
INFO:root:current train perplexity3.9826760292053223
INFO:root:current mean train loss 3486.9702489416027
INFO:root:current train perplexity3.9523963928222656
INFO:root:current mean train loss 3483.2510588177643
INFO:root:current train perplexity3.9438769817352295
INFO:root:current mean train loss 3478.757325507091
INFO:root:current train perplexity3.9377195835113525
INFO:root:current mean train loss 3480.9135303855687
INFO:root:current train perplexity3.9391751289367676
INFO:root:current mean train loss 3472.405716179566
INFO:root:current train perplexity3.929582357406616
INFO:root:current mean train loss 3469.931956677444
INFO:root:current train perplexity3.9246063232421875
INFO:root:current mean train loss 3462.899785757983
INFO:root:current train perplexity3.9155144691467285
INFO:root:current mean train loss 3461.5842810100257
INFO:root:current train perplexity3.9135522842407227
INFO:root:current mean train loss 3458.843431046109
INFO:root:current train perplexity3.910447597503662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.45s/it]
INFO:root:final mean train loss: 3455.948247232745
INFO:root:final train perplexity: 3.9097423553466797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.52s/it]
INFO:root:eval mean loss: 3685.4738423232493
INFO:root:eval perplexity: 4.438416004180908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 4647.28113572141
INFO:root:eval perplexity: 6.688149452209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [22:24:28<10:32:46, 593.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3407.5459713990663
INFO:root:current train perplexity3.842261552810669
INFO:root:current mean train loss 3408.945718530665
INFO:root:current train perplexity3.8308467864990234
INFO:root:current mean train loss 3411.2654914457207
INFO:root:current train perplexity3.8350889682769775
INFO:root:current mean train loss 3411.014277495155
INFO:root:current train perplexity3.8400819301605225
INFO:root:current mean train loss 3407.7234448192057
INFO:root:current train perplexity3.8356142044067383
INFO:root:current mean train loss 3401.9859816699054
INFO:root:current train perplexity3.8251471519470215
INFO:root:current mean train loss 3401.8284551406705
INFO:root:current train perplexity3.822838306427002
INFO:root:current mean train loss 3393.9719576417565
INFO:root:current train perplexity3.814793825149536
INFO:root:current mean train loss 3393.566538917172
INFO:root:current train perplexity3.8116626739501953
INFO:root:current mean train loss 3392.261468672825
INFO:root:current train perplexity3.8090476989746094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.85s/it]
INFO:root:final mean train loss: 3390.0259045631656
INFO:root:final train perplexity: 3.809368371963501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 3648.5407004931294
INFO:root:eval perplexity: 4.372621536254883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4614.075004848182
INFO:root:eval perplexity: 6.5979485511779785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [22:34:20<10:22:21, 592.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.114095908717
INFO:root:current train perplexity3.7348718643188477
INFO:root:current mean train loss 3355.7438789563303
INFO:root:current train perplexity3.7514657974243164
INFO:root:current mean train loss 3350.391757150424
INFO:root:current train perplexity3.747748613357544
INFO:root:current mean train loss 3345.015008776701
INFO:root:current train perplexity3.7448065280914307
INFO:root:current mean train loss 3350.448728002683
INFO:root:current train perplexity3.7475030422210693
INFO:root:current mean train loss 3351.957064896271
INFO:root:current train perplexity3.7531728744506836
INFO:root:current mean train loss 3350.4387407261693
INFO:root:current train perplexity3.7527074813842773
INFO:root:current mean train loss 3351.207111708923
INFO:root:current train perplexity3.754545211791992
INFO:root:current mean train loss 3352.475112386522
INFO:root:current train perplexity3.7513017654418945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.23s/it]
INFO:root:final mean train loss: 3353.878110393401
INFO:root:final train perplexity: 3.755427122116089
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3637.6468583776596
INFO:root:eval perplexity: 4.3534016609191895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 4605.766251800754
INFO:root:eval perplexity: 6.5755696296691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [22:44:09<10:11:23, 591.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.8297526041665
INFO:root:current train perplexity3.479097843170166
INFO:root:current mean train loss 3338.0741950470265
INFO:root:current train perplexity3.733116626739502
INFO:root:current mean train loss 3321.6979800069275
INFO:root:current train perplexity3.7135908603668213
INFO:root:current mean train loss 3333.5926139000617
INFO:root:current train perplexity3.7236714363098145
INFO:root:current mean train loss 3336.872356253877
INFO:root:current train perplexity3.725823163986206
INFO:root:current mean train loss 3339.031603348658
INFO:root:current train perplexity3.731998920440674
INFO:root:current mean train loss 3341.022265382074
INFO:root:current train perplexity3.731996774673462
INFO:root:current mean train loss 3340.4473479312987
INFO:root:current train perplexity3.730262517929077
INFO:root:current mean train loss 3341.6726533312576
INFO:root:current train perplexity3.730422258377075
INFO:root:current mean train loss 3342.7626006843507
INFO:root:current train perplexity3.7327451705932617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.63s/it]
INFO:root:final mean train loss: 3339.1577869538337
INFO:root:final train perplexity: 3.733680486679077
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 3649.333790447695
INFO:root:eval perplexity: 4.374024391174316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4616.744097337655
INFO:root:eval perplexity: 6.605151653289795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [22:53:54<9:59:33, 589.73s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.0142933238635
INFO:root:current train perplexity3.7337687015533447
INFO:root:current mean train loss 3341.4665131440033
INFO:root:current train perplexity3.7257304191589355
INFO:root:current mean train loss 3340.460907416321
INFO:root:current train perplexity3.716275930404663
INFO:root:current mean train loss 3336.695354890977
INFO:root:current train perplexity3.7126219272613525
INFO:root:current mean train loss 3338.2467738984565
INFO:root:current train perplexity3.7207605838775635
INFO:root:current mean train loss 3345.396546007369
INFO:root:current train perplexity3.7229785919189453
INFO:root:current mean train loss 3342.08562023706
INFO:root:current train perplexity3.7200546264648438
INFO:root:current mean train loss 3333.6329392058938
INFO:root:current train perplexity3.713552474975586
INFO:root:current mean train loss 3332.549208635173
INFO:root:current train perplexity3.713479518890381
INFO:root:current mean train loss 3331.1468059652852
INFO:root:current train perplexity3.715775966644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.48s/it]
INFO:root:final mean train loss: 3327.0196508592176
INFO:root:final train perplexity: 3.7158427238464355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 3650.720181945368
INFO:root:eval perplexity: 4.376477241516113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4610.999909962323
INFO:root:eval perplexity: 6.589656829833984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [23:03:46<9:50:20, 590.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.0616904810854
INFO:root:current train perplexity3.7635977268218994
INFO:root:current mean train loss 3317.234549386161
INFO:root:current train perplexity3.710200548171997
INFO:root:current mean train loss 3316.2224399793095
INFO:root:current train perplexity3.7066497802734375
INFO:root:current mean train loss 3326.2201972411344
INFO:root:current train perplexity3.7095987796783447
INFO:root:current mean train loss 3320.24255982902
INFO:root:current train perplexity3.7059388160705566
INFO:root:current mean train loss 3321.004688064487
INFO:root:current train perplexity3.7077691555023193
INFO:root:current mean train loss 3325.9071232267265
INFO:root:current train perplexity3.710723400115967
INFO:root:current mean train loss 3325.4062910862526
INFO:root:current train perplexity3.707444906234741
INFO:root:current mean train loss 3326.3544480692917
INFO:root:current train perplexity3.7090985774993896
INFO:root:current mean train loss 3322.66850777212
INFO:root:current train perplexity3.705484390258789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.11s/it]
INFO:root:final mean train loss: 3318.8487474995277
INFO:root:final train perplexity: 3.703883409500122
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 3624.237877811946
INFO:root:eval perplexity: 4.329861640930176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 4593.81005859375
INFO:root:eval perplexity: 6.54349946975708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [23:13:36<9:40:29, 590.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.6537452980324
INFO:root:current train perplexity3.687739849090576
INFO:root:current mean train loss 3297.903149221826
INFO:root:current train perplexity3.6815598011016846
INFO:root:current mean train loss 3307.081423587211
INFO:root:current train perplexity3.6884398460388184
INFO:root:current mean train loss 3315.4079881020643
INFO:root:current train perplexity3.692826986312866
INFO:root:current mean train loss 3312.1139038943575
INFO:root:current train perplexity3.688537120819092
INFO:root:current mean train loss 3311.5725723063924
INFO:root:current train perplexity3.688732624053955
INFO:root:current mean train loss 3311.230745209081
INFO:root:current train perplexity3.6888883113861084
INFO:root:current mean train loss 3314.2730533227304
INFO:root:current train perplexity3.6898727416992188
INFO:root:current mean train loss 3315.7131262044663
INFO:root:current train perplexity3.6927525997161865
INFO:root:current mean train loss 3315.9195934571367
INFO:root:current train perplexity3.6941990852355957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it]
INFO:root:final mean train loss: 3310.8667972933863
INFO:root:final train perplexity: 3.6922380924224854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3630.83989396332
INFO:root:eval perplexity: 4.34143590927124
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4596.421987547096
INFO:root:eval perplexity: 6.5504913330078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [23:23:28<9:31:05, 590.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3385.124825613839
INFO:root:current train perplexity3.7276554107666016
INFO:root:current mean train loss 3331.9692183883103
INFO:root:current train perplexity3.6873741149902344
INFO:root:current mean train loss 3325.6324135638297
INFO:root:current train perplexity3.6814157962799072
INFO:root:current mean train loss 3311.6826470673973
INFO:root:current train perplexity3.678020477294922
INFO:root:current mean train loss 3312.3057903421336
INFO:root:current train perplexity3.6840670108795166
INFO:root:current mean train loss 3304.406542512412
INFO:root:current train perplexity3.6751959323883057
INFO:root:current mean train loss 3307.912202417569
INFO:root:current train perplexity3.6790804862976074
INFO:root:current mean train loss 3310.481624348958
INFO:root:current train perplexity3.6823384761810303
INFO:root:current mean train loss 3312.6912015812127
INFO:root:current train perplexity3.6863043308258057
INFO:root:current mean train loss 3311.978365746156
INFO:root:current train perplexity3.6879756450653076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.24s/it]
INFO:root:final mean train loss: 3308.4440092271375
INFO:root:final train perplexity: 3.6887102127075195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 3624.585708942819
INFO:root:eval perplexity: 4.330470085144043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 4591.272895542443
INFO:root:eval perplexity: 6.536713123321533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [23:33:19<9:21:13, 590.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.1929676144623
INFO:root:current train perplexity3.716069221496582
INFO:root:current mean train loss 3327.239170741368
INFO:root:current train perplexity3.6798436641693115
INFO:root:current mean train loss 3316.661548755787
INFO:root:current train perplexity3.676705837249756
INFO:root:current mean train loss 3317.58748846916
INFO:root:current train perplexity3.6853065490722656
INFO:root:current mean train loss 3313.634519279945
INFO:root:current train perplexity3.687865972518921
INFO:root:current mean train loss 3319.663189798429
INFO:root:current train perplexity3.6952943801879883
INFO:root:current mean train loss 3317.6511272234643
INFO:root:current train perplexity3.694059371948242
INFO:root:current mean train loss 3315.910313972073
INFO:root:current train perplexity3.693080186843872
INFO:root:current mean train loss 3311.9432580117514
INFO:root:current train perplexity3.6907875537872314
INFO:root:current mean train loss 3309.9467335900217
INFO:root:current train perplexity3.6871707439422607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 516.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 516.00s/it]
INFO:root:final mean train loss: 3306.359384782853
INFO:root:final train perplexity: 3.6856777667999268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 3618.69810539949
INFO:root:eval perplexity: 4.320172309875488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4589.598954870346
INFO:root:eval perplexity: 6.532240390777588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [23:43:11<9:11:44, 591.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.5925053615197
INFO:root:current train perplexity3.6738572120666504
INFO:root:current mean train loss 3301.81462289166
INFO:root:current train perplexity3.6697006225585938
INFO:root:current mean train loss 3310.9376293653513
INFO:root:current train perplexity3.682689905166626
INFO:root:current mean train loss 3309.0910282841437
INFO:root:current train perplexity3.6823313236236572
INFO:root:current mean train loss 3311.8784601926277
INFO:root:current train perplexity3.684530258178711
INFO:root:current mean train loss 3309.229392936139
INFO:root:current train perplexity3.6812047958374023
INFO:root:current mean train loss 3306.5252556163596
INFO:root:current train perplexity3.6777071952819824
INFO:root:current mean train loss 3309.121616165425
INFO:root:current train perplexity3.6798295974731445
INFO:root:current mean train loss 3304.0736630503634
INFO:root:current train perplexity3.675572156906128
INFO:root:current mean train loss 3303.0904593643204
INFO:root:current train perplexity3.674919366836548

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.30s/it]
INFO:root:final mean train loss: 3297.877969864876
INFO:root:final train perplexity: 3.673365354537964
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 3627.7446012023493
INFO:root:eval perplexity: 4.336004734039307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4600.9945734984485
INFO:root:eval perplexity: 6.562751293182373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [23:53:05<9:02:47, 592.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.881235930879
INFO:root:current train perplexity3.665135145187378
INFO:root:current mean train loss 3275.4328106574294
INFO:root:current train perplexity3.6388251781463623
INFO:root:current mean train loss 3286.730378257722
INFO:root:current train perplexity3.6663193702697754
INFO:root:current mean train loss 3287.666454262056
INFO:root:current train perplexity3.662130355834961
INFO:root:current mean train loss 3288.8748148999184
INFO:root:current train perplexity3.6627790927886963
INFO:root:current mean train loss 3292.310480489714
INFO:root:current train perplexity3.6689646244049072
INFO:root:current mean train loss 3294.0128486876424
INFO:root:current train perplexity3.6691770553588867
INFO:root:current mean train loss 3296.623125681921
INFO:root:current train perplexity3.672330379486084
INFO:root:current mean train loss 3298.2756538080253
INFO:root:current train perplexity3.674172878265381
INFO:root:current mean train loss 3302.864408268297
INFO:root:current train perplexity3.6777591705322266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.92s/it]
INFO:root:final mean train loss: 3301.3493064757317
INFO:root:final train perplexity: 3.6783998012542725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 3632.418287344858
INFO:root:eval perplexity: 4.344207286834717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4595.144051626219
INFO:root:eval perplexity: 6.547070026397705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [24:02:58<8:52:58, 592.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3411.449113077192
INFO:root:current train perplexity3.806745767593384
INFO:root:current mean train loss 3437.2833303120324
INFO:root:current train perplexity3.8658089637756348
INFO:root:current mean train loss 3441.336340743504
INFO:root:current train perplexity3.880789279937744
INFO:root:current mean train loss 3436.805634127001
INFO:root:current train perplexity3.8800852298736572
INFO:root:current mean train loss 3441.7949574243844
INFO:root:current train perplexity3.8827767372131348
INFO:root:current mean train loss 3445.7193510940256
INFO:root:current train perplexity3.893226146697998
INFO:root:current mean train loss 3450.2177529399364
INFO:root:current train perplexity3.90081524848938
INFO:root:current mean train loss 3459.3383925934036
INFO:root:current train perplexity3.912991523742676
INFO:root:current mean train loss 3464.975398396951
INFO:root:current train perplexity3.9192521572113037
INFO:root:current mean train loss 3465.609188423038
INFO:root:current train perplexity3.9198474884033203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.14s/it]
INFO:root:final mean train loss: 3462.865374411306
INFO:root:final train perplexity: 3.920426845550537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3667.4158338181514
INFO:root:eval perplexity: 4.406123638153076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4634.762703969969
INFO:root:eval perplexity: 6.654000282287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [24:12:49<8:42:53, 591.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3484.3550716145833
INFO:root:current train perplexity3.9593379497528076
INFO:root:current mean train loss 3484.402974330357
INFO:root:current train perplexity3.9676268100738525
INFO:root:current mean train loss 3512.908251065341
INFO:root:current train perplexity3.992978096008301
INFO:root:current mean train loss 3516.9849173177086
INFO:root:current train perplexity3.999295234680176
INFO:root:current mean train loss 3516.108445209704
INFO:root:current train perplexity4.001656532287598
INFO:root:current mean train loss 3525.701853345788
INFO:root:current train perplexity4.015472888946533
INFO:root:current mean train loss 3528.723666087963
INFO:root:current train perplexity4.021735191345215
INFO:root:current mean train loss 3533.9937276335686
INFO:root:current train perplexity4.026854515075684
INFO:root:current mean train loss 3537.0283881138394
INFO:root:current train perplexity4.031824111938477
INFO:root:current mean train loss 3540.2258385917467
INFO:root:current train perplexity4.037896156311035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it]
INFO:root:final mean train loss: 3538.8972413462975
INFO:root:final train perplexity: 4.039808750152588
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3706.7884599401596
INFO:root:eval perplexity: 4.47683572769165
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 4677.8494137162015
INFO:root:eval perplexity: 6.772273063659668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [24:22:41<8:33:05, 592.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3599.513465973268
INFO:root:current train perplexity4.143193244934082
INFO:root:current mean train loss 3573.1411973296617
INFO:root:current train perplexity4.110476970672607
INFO:root:current mean train loss 3585.336274810899
INFO:root:current train perplexity4.123488426208496
INFO:root:current mean train loss 3603.3527634423954
INFO:root:current train perplexity4.136462688446045
INFO:root:current mean train loss 3606.606350284679
INFO:root:current train perplexity4.1355366706848145
INFO:root:current mean train loss 3602.000966093348
INFO:root:current train perplexity4.136070251464844
INFO:root:current mean train loss 3598.3557715129714
INFO:root:current train perplexity4.128933906555176
INFO:root:current mean train loss 3590.806972693666
INFO:root:current train perplexity4.1213059425354
INFO:root:current mean train loss 3590.3028930802307
INFO:root:current train perplexity4.119154930114746
INFO:root:current mean train loss 3592.9432533240874
INFO:root:current train perplexity4.122196197509766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.33s/it]
INFO:root:final mean train loss: 3589.887588070285
INFO:root:final train perplexity: 4.121901035308838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 3698.366093195922
INFO:root:eval perplexity: 4.461615085601807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4669.518899254765
INFO:root:eval perplexity: 6.749242305755615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [24:32:33<8:23:02, 591.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.5215943724243
INFO:root:current train perplexity4.093573570251465
INFO:root:current mean train loss 3556.1549641074935
INFO:root:current train perplexity4.079838275909424
INFO:root:current mean train loss 3568.5609722334084
INFO:root:current train perplexity4.083146095275879
INFO:root:current mean train loss 3568.526565746883
INFO:root:current train perplexity4.086057662963867
INFO:root:current mean train loss 3575.552607580989
INFO:root:current train perplexity4.0952677726745605
INFO:root:current mean train loss 3577.903279415847
INFO:root:current train perplexity4.09660005569458
INFO:root:current mean train loss 3576.812627900009
INFO:root:current train perplexity4.094627857208252
INFO:root:current mean train loss 3578.433075221239
INFO:root:current train perplexity4.0976433753967285
INFO:root:current mean train loss 3578.1455552157863
INFO:root:current train perplexity4.0976409912109375
INFO:root:current mean train loss 3575.722825744198
INFO:root:current train perplexity4.0944504737854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.49s/it]
INFO:root:final mean train loss: 3573.0709274045885
INFO:root:final train perplexity: 4.094644546508789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3686.6364936558066
INFO:root:eval perplexity: 4.440503120422363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4656.233988876884
INFO:root:eval perplexity: 6.7126784324646
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [24:42:25<8:13:14, 591.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.5204880839647
INFO:root:current train perplexity4.099302768707275
INFO:root:current mean train loss 3564.7108123625944
INFO:root:current train perplexity4.08331298828125
INFO:root:current mean train loss 3573.42900733565
INFO:root:current train perplexity4.088963508605957
INFO:root:current mean train loss 3584.4294311217495
INFO:root:current train perplexity4.098972320556641
INFO:root:current mean train loss 3583.816366130699
INFO:root:current train perplexity4.104414463043213
INFO:root:current mean train loss 3585.1963314508557
INFO:root:current train perplexity4.106287956237793
INFO:root:current mean train loss 3584.267175764485
INFO:root:current train perplexity4.105807781219482
INFO:root:current mean train loss 3586.0693781044665
INFO:root:current train perplexity4.1096577644348145
INFO:root:current mean train loss 3587.308209208148
INFO:root:current train perplexity4.111455917358398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.16s/it]
INFO:root:final mean train loss: 3582.3692741394043
INFO:root:final train perplexity: 4.10969352722168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 3694.6262414810503
INFO:root:eval perplexity: 4.454871654510498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 4662.118375304743
INFO:root:eval perplexity: 6.7288498878479
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [24:52:12<8:02:17, 590.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3574.9961983816966
INFO:root:current train perplexity4.198265552520752
INFO:root:current mean train loss 3589.0862295560746
INFO:root:current train perplexity4.105679988861084
INFO:root:current mean train loss 3581.6503269361415
INFO:root:current train perplexity4.101332187652588
INFO:root:current mean train loss 3581.933640669534
INFO:root:current train perplexity4.11541748046875
INFO:root:current mean train loss 3580.3408683008292
INFO:root:current train perplexity4.105045318603516
INFO:root:current mean train loss 3581.943357930381
INFO:root:current train perplexity4.108468532562256
INFO:root:current mean train loss 3585.7188573896983
INFO:root:current train perplexity4.117397785186768
INFO:root:current mean train loss 3591.7697021829695
INFO:root:current train perplexity4.1254801750183105
INFO:root:current mean train loss 3593.8215685989776
INFO:root:current train perplexity4.12553071975708
INFO:root:current mean train loss 3594.589877935071
INFO:root:current train perplexity4.128287315368652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.00s/it]
INFO:root:final mean train loss: 3595.083490064067
INFO:root:final train perplexity: 4.130359172821045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 3735.91953402039
INFO:root:eval perplexity: 4.529883861541748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 4700.689962184176
INFO:root:eval perplexity: 6.835821151733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [25:02:04<7:52:38, 590.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.570833333333
INFO:root:current train perplexity4.105293273925781
INFO:root:current mean train loss 3597.5197350543476
INFO:root:current train perplexity4.127837657928467
INFO:root:current mean train loss 3604.8255405159885
INFO:root:current train perplexity4.137669563293457
INFO:root:current mean train loss 3605.654111638145
INFO:root:current train perplexity4.133963584899902
INFO:root:current mean train loss 3605.3809505600525
INFO:root:current train perplexity4.1401686668396
INFO:root:current mean train loss 3605.5944539783072
INFO:root:current train perplexity4.140244960784912
INFO:root:current mean train loss 3606.0874388656
INFO:root:current train perplexity4.141253471374512
INFO:root:current mean train loss 3607.521850073754
INFO:root:current train perplexity4.1439433097839355
INFO:root:current mean train loss 3611.294395250192
INFO:root:current train perplexity4.150498390197754
INFO:root:current mean train loss 3616.170698055413
INFO:root:current train perplexity4.161132335662842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.42s/it]
INFO:root:final mean train loss: 3619.760767905943
INFO:root:final train perplexity: 4.170768737792969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3703.271811627327
INFO:root:eval perplexity: 4.470473766326904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 4667.059004114029
INFO:root:eval perplexity: 6.742457866668701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [25:11:58<7:43:45, 592.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.5270146908965
INFO:root:current train perplexity4.650354862213135
INFO:root:current mean train loss 3870.966779011052
INFO:root:current train perplexity4.603863716125488
INFO:root:current mean train loss 3913.728509056194
INFO:root:current train perplexity4.6699113845825195
INFO:root:current mean train loss 4025.3444348031153
INFO:root:current train perplexity4.8800530433654785
INFO:root:current mean train loss 4111.679307725694
INFO:root:current train perplexity5.048718452453613
INFO:root:current mean train loss 4221.652181767597
INFO:root:current train perplexity5.274407386779785
INFO:root:current mean train loss 4312.070543316739
INFO:root:current train perplexity5.468100070953369
INFO:root:current mean train loss 4477.321935714363
INFO:root:current train perplexity5.836344242095947
INFO:root:current mean train loss 4739.502933543913
INFO:root:current train perplexity6.469583034515381
INFO:root:current mean train loss 5020.707502338249
INFO:root:current train perplexity7.235325336456299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.66s/it]
INFO:root:final mean train loss: 5174.019935115691
INFO:root:final train perplexity: 7.700617790222168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 4160.0556675254875
INFO:root:eval perplexity: 5.377397537231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 5096.631951947585
INFO:root:eval perplexity: 8.037217140197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [25:21:51<7:33:56, 592.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7272.068453881048
INFO:root:current train perplexity17.855470657348633
INFO:root:current mean train loss 7120.013910424618
INFO:root:current train perplexity16.63378143310547
INFO:root:current mean train loss 7192.025202499323
INFO:root:current train perplexity17.022485733032227
INFO:root:current mean train loss 7279.500390920034
INFO:root:current train perplexity17.578763961791992
INFO:root:current mean train loss 7326.036189457656
INFO:root:current train perplexity17.898117065429688
INFO:root:current mean train loss 7217.192243040843
INFO:root:current train perplexity17.153106689453125
INFO:root:current mean train loss 7084.398086958944
INFO:root:current train perplexity16.27412986755371
INFO:root:current mean train loss 6921.539170710072
INFO:root:current train perplexity15.248931884765625
INFO:root:current mean train loss 6706.16151562265
INFO:root:current train perplexity14.044649124145508
INFO:root:current mean train loss 6467.528293564547
INFO:root:current train perplexity12.794126510620117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.70s/it]
INFO:root:final mean train loss: 6325.947104607859
INFO:root:final train perplexity: 12.131061553955078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3917.6203890320257
INFO:root:eval perplexity: 4.875246047973633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 4862.685889710771
INFO:root:eval perplexity: 7.3039774894714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [25:31:44<7:24:15, 592.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4212.2052346254
INFO:root:current train perplexity5.287838935852051
INFO:root:current mean train loss 4158.936121220211
INFO:root:current train perplexity5.154886722564697
INFO:root:current mean train loss 4150.331621624935
INFO:root:current train perplexity5.132896900177002
INFO:root:current mean train loss 4108.819235832642
INFO:root:current train perplexity5.046628952026367
INFO:root:current mean train loss 4080.078406401267
INFO:root:current train perplexity4.982848644256592
INFO:root:current mean train loss 4035.059870166106
INFO:root:current train perplexity4.904050827026367
INFO:root:current mean train loss 4000.130719156519
INFO:root:current train perplexity4.838689804077148
INFO:root:current mean train loss 3972.338164168217
INFO:root:current train perplexity4.787731647491455
INFO:root:current mean train loss 3947.9447340118445
INFO:root:current train perplexity4.742458820343018
INFO:root:current mean train loss 3928.592669697234
INFO:root:current train perplexity4.703693389892578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.49s/it]
INFO:root:final mean train loss: 3915.741791878977
INFO:root:final train perplexity: 4.6873779296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3770.743567500554
INFO:root:eval perplexity: 4.5941243171691895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4728.011433053524
INFO:root:eval perplexity: 6.912621021270752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [25:41:37<7:14:34, 592.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3748.6303243434177
INFO:root:current train perplexity4.4343791007995605
INFO:root:current mean train loss 3797.417756164966
INFO:root:current train perplexity4.474637508392334
INFO:root:current mean train loss 3828.1578038018724
INFO:root:current train perplexity4.512627601623535
INFO:root:current mean train loss 3836.051178770038
INFO:root:current train perplexity4.536296367645264
INFO:root:current mean train loss 3846.5601945915478
INFO:root:current train perplexity4.554532527923584
INFO:root:current mean train loss 3853.8614294411277
INFO:root:current train perplexity4.560314178466797
INFO:root:current mean train loss 3857.927143833921
INFO:root:current train perplexity4.571878433227539
INFO:root:current mean train loss 3868.0992145665996
INFO:root:current train perplexity4.5887274742126465
INFO:root:current mean train loss 3869.1709004551913
INFO:root:current train perplexity4.59168815612793
INFO:root:current mean train loss 3867.4450729998516
INFO:root:current train perplexity4.593344211578369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.93s/it]
INFO:root:final mean train loss: 3867.101124240506
INFO:root:final train perplexity: 4.5982842445373535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 3780.6644901789673
INFO:root:eval perplexity: 4.61259126663208
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4731.619102532137
INFO:root:eval perplexity: 6.922825336456299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [25:51:32<7:05:12, 593.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3813.228848544034
INFO:root:current train perplexity4.492798805236816
INFO:root:current mean train loss 3819.9294071320564
INFO:root:current train perplexity4.519178867340088
INFO:root:current mean train loss 3827.858993949142
INFO:root:current train perplexity4.538126468658447
INFO:root:current mean train loss 3829.2897192726673
INFO:root:current train perplexity4.547488212585449
INFO:root:current mean train loss 3838.3718846583106
INFO:root:current train perplexity4.5590972900390625
INFO:root:current mean train loss 3834.4915694503097
INFO:root:current train perplexity4.545458793640137
INFO:root:current mean train loss 3839.0567077170804
INFO:root:current train perplexity4.547379970550537
INFO:root:current mean train loss 3836.456631570778
INFO:root:current train perplexity4.541740894317627
INFO:root:current mean train loss 3837.759912966009
INFO:root:current train perplexity4.54547119140625
INFO:root:current mean train loss 3839.225008947562
INFO:root:current train perplexity4.5443315505981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it]
INFO:root:final mean train loss: 3836.62722692182
INFO:root:final train perplexity: 4.543331146240234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 3770.4827802942154
INFO:root:eval perplexity: 4.593638896942139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4725.335734915226
INFO:root:eval perplexity: 6.9050612449646
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [26:01:24<6:55:01, 592.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3871.8491172185018
INFO:root:current train perplexity4.620975494384766
INFO:root:current mean train loss 3850.3609956144555
INFO:root:current train perplexity4.582968235015869
INFO:root:current mean train loss 3841.9968762996077
INFO:root:current train perplexity4.572879314422607
INFO:root:current mean train loss 3847.083391173812
INFO:root:current train perplexity4.571372032165527
INFO:root:current mean train loss 3848.630483936285
INFO:root:current train perplexity4.56562614440918
INFO:root:current mean train loss 3848.497223388238
INFO:root:current train perplexity4.566141128540039
INFO:root:current mean train loss 3862.3160803609303
INFO:root:current train perplexity4.589686870574951
INFO:root:current mean train loss 3873.973136531885
INFO:root:current train perplexity4.606600284576416
INFO:root:current mean train loss 3881.6543545861095
INFO:root:current train perplexity4.6191582679748535
INFO:root:current mean train loss 3884.7808643947137
INFO:root:current train perplexity4.622880458831787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.31s/it]
INFO:root:final mean train loss: 3882.5546323714716
INFO:root:final train perplexity: 4.626404285430908
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3810.9393388464096
INFO:root:eval perplexity: 4.669406414031982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4760.81754730441
INFO:root:eval perplexity: 7.005977153778076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [26:11:17<6:45:08, 592.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3886.59023575044
INFO:root:current train perplexity4.651043891906738
INFO:root:current mean train loss 3877.4466374269005
INFO:root:current train perplexity4.6182861328125
INFO:root:current mean train loss 3889.1952647529406
INFO:root:current train perplexity4.629806995391846
INFO:root:current mean train loss 3895.9396393562583
INFO:root:current train perplexity4.6409125328063965
INFO:root:current mean train loss 3907.886942156814
INFO:root:current train perplexity4.671612739562988
INFO:root:current mean train loss 3920.0419357486867
INFO:root:current train perplexity4.691520690917969
INFO:root:current mean train loss 3924.174953136643
INFO:root:current train perplexity4.693260192871094
INFO:root:current mean train loss 3928.918754686487
INFO:root:current train perplexity4.703490257263184
INFO:root:current mean train loss 3924.3223746613985
INFO:root:current train perplexity4.698404312133789
INFO:root:current mean train loss 3918.812587749823
INFO:root:current train perplexity4.688571453094482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.31s/it]
INFO:root:final mean train loss: 3914.806096415366
INFO:root:final train perplexity: 4.685647964477539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3768.684840425532
INFO:root:eval perplexity: 4.590301036834717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 4717.857473819814
INFO:root:eval perplexity: 6.883978843688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [26:21:08<6:35:00, 592.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3925.6306924940664
INFO:root:current train perplexity4.664795398712158
INFO:root:current mean train loss 3890.403166190206
INFO:root:current train perplexity4.6298346519470215
INFO:root:current mean train loss 3871.6924816938285
INFO:root:current train perplexity4.606646537780762
INFO:root:current mean train loss 3878.3987080516163
INFO:root:current train perplexity4.613002300262451
INFO:root:current mean train loss 3879.036814775248
INFO:root:current train perplexity4.620368480682373
INFO:root:current mean train loss 3890.726971930996
INFO:root:current train perplexity4.6390700340271
INFO:root:current mean train loss 3901.1363282688235
INFO:root:current train perplexity4.650803565979004
INFO:root:current mean train loss 3898.436661021241
INFO:root:current train perplexity4.6518168449401855
INFO:root:current mean train loss 3898.7090660329563
INFO:root:current train perplexity4.651782512664795
INFO:root:current mean train loss 3900.2014000554614
INFO:root:current train perplexity4.652805805206299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.29s/it]
INFO:root:final mean train loss: 3897.221601301624
INFO:root:final train perplexity: 4.65325403213501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 3787.0931959219856
INFO:root:eval perplexity: 4.624597072601318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 4735.555774878103
INFO:root:eval perplexity: 6.933979034423828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [26:31:01<6:25:07, 592.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3990.9647567573634
INFO:root:current train perplexity4.793224811553955
INFO:root:current mean train loss 3963.2327404328207
INFO:root:current train perplexity4.774266719818115
INFO:root:current mean train loss 3974.347861260072
INFO:root:current train perplexity4.7890825271606445
INFO:root:current mean train loss 3976.2615011052567
INFO:root:current train perplexity4.790707111358643
INFO:root:current mean train loss 3968.822653141844
INFO:root:current train perplexity4.779565334320068
INFO:root:current mean train loss 3972.6195935536894
INFO:root:current train perplexity4.783010482788086
INFO:root:current mean train loss 3966.8799414488944
INFO:root:current train perplexity4.777565002441406
INFO:root:current mean train loss 3974.0955864834814
INFO:root:current train perplexity4.787871837615967
INFO:root:current mean train loss 3970.1189339174357
INFO:root:current train perplexity4.78663969039917
INFO:root:current mean train loss 3979.5818172868385
INFO:root:current train perplexity4.801408290863037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.51s/it]
INFO:root:final mean train loss: 3976.512103849842
INFO:root:final train perplexity: 4.801119327545166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 3824.652108266844
INFO:root:eval perplexity: 4.695371627807617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 4774.44930532469
INFO:root:eval perplexity: 7.045139789581299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [26:40:51<6:14:55, 592.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4048.153232935855
INFO:root:current train perplexity4.895665645599365
INFO:root:current mean train loss 4030.999047225561
INFO:root:current train perplexity4.868050575256348
INFO:root:current mean train loss 4035.747011553231
INFO:root:current train perplexity4.89389705657959
INFO:root:current mean train loss 4033.2455825998813
INFO:root:current train perplexity4.894948482513428
INFO:root:current mean train loss 4029.494538648201
INFO:root:current train perplexity4.8876142501831055
INFO:root:current mean train loss 4032.0240291819855
INFO:root:current train perplexity4.889164924621582
INFO:root:current mean train loss 4028.6196552523606
INFO:root:current train perplexity4.887145042419434
INFO:root:current mean train loss 4024.6578429024175
INFO:root:current train perplexity4.883728504180908
INFO:root:current mean train loss 4026.4094260103875
INFO:root:current train perplexity4.8885626792907715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.19s/it]
INFO:root:final mean train loss: 4025.2408209154682
INFO:root:final train perplexity: 4.894313335418701
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3816.2775913536125
INFO:root:eval perplexity: 4.679496765136719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4766.3184147828015
INFO:root:eval perplexity: 7.021752834320068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [26:50:43<6:05:01, 591.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3933.1190592447915
INFO:root:current train perplexity4.746774196624756
INFO:root:current mean train loss 4011.790935034891
INFO:root:current train perplexity4.885831356048584
INFO:root:current mean train loss 4030.1483785695045
INFO:root:current train perplexity4.901401042938232
INFO:root:current mean train loss 4043.1610764103752
INFO:root:current train perplexity4.908644199371338
INFO:root:current mean train loss 4048.6711147109568
INFO:root:current train perplexity4.925309181213379
INFO:root:current mean train loss 4046.6758778384383
INFO:root:current train perplexity4.921034336090088
INFO:root:current mean train loss 4041.9822230805607
INFO:root:current train perplexity4.918183326721191
INFO:root:current mean train loss 4044.4417969444567
INFO:root:current train perplexity4.922529697418213
INFO:root:current mean train loss 4053.0267825001947
INFO:root:current train perplexity4.942750930786133
INFO:root:current mean train loss 4059.1433438019103
INFO:root:current train perplexity4.952790260314941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.61s/it]
INFO:root:final mean train loss: 4062.9484885431107
INFO:root:final train perplexity: 4.967668056488037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3985.1026204427085
INFO:root:eval perplexity: 5.010112762451172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 4948.517233557735
INFO:root:eval perplexity: 7.564883232116699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [27:00:35<5:55:03, 591.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4337.055331143466
INFO:root:current train perplexity5.44044828414917
INFO:root:current mean train loss 4189.885456257039
INFO:root:current train perplexity5.219786167144775
INFO:root:current mean train loss 4156.731346962011
INFO:root:current train perplexity5.131732940673828
INFO:root:current mean train loss 4132.087675530044
INFO:root:current train perplexity5.103760242462158
INFO:root:current mean train loss 4128.2597614668875
INFO:root:current train perplexity5.09296989440918
INFO:root:current mean train loss 4126.347052348337
INFO:root:current train perplexity5.093814373016357
INFO:root:current mean train loss 4172.718177008746
INFO:root:current train perplexity5.185704708099365
INFO:root:current mean train loss 4171.542778862848
INFO:root:current train perplexity5.189607620239258
INFO:root:current mean train loss 4170.631319358817
INFO:root:current train perplexity5.1834869384765625
INFO:root:current mean train loss 4170.2170621869855
INFO:root:current train perplexity5.17831563949585

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 515.00s/it]
INFO:root:final mean train loss: 4165.685355770973
INFO:root:final train perplexity: 5.173158168792725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 3863.3098612034573
INFO:root:eval perplexity: 4.769345760345459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4813.896420309729
INFO:root:eval perplexity: 7.159701824188232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [27:10:26<5:45:09, 591.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4013.4683388157896
INFO:root:current train perplexity5.009098052978516
INFO:root:current mean train loss 4091.4955746947217
INFO:root:current train perplexity5.055328845977783
INFO:root:current mean train loss 4104.769863459617
INFO:root:current train perplexity5.040308475494385
INFO:root:current mean train loss 4100.304175493486
INFO:root:current train perplexity5.042092800140381
INFO:root:current mean train loss 4105.59193089014
INFO:root:current train perplexity5.0461883544921875
INFO:root:current mean train loss 4113.931903581858
INFO:root:current train perplexity5.061115741729736
INFO:root:current mean train loss 4120.896452033269
INFO:root:current train perplexity5.071665287017822
INFO:root:current mean train loss 4118.959861787204
INFO:root:current train perplexity5.076927185058594
INFO:root:current mean train loss 4124.929084153693
INFO:root:current train perplexity5.089554309844971
INFO:root:current mean train loss 4126.136118094991
INFO:root:current train perplexity5.090757846832275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.51s/it]
INFO:root:final mean train loss: 4126.077683725664
INFO:root:final train perplexity: 5.0929484367370605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it]
INFO:root:eval mean loss: 3862.382888685727
INFO:root:eval perplexity: 4.767558574676514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 4814.424906845634
INFO:root:eval perplexity: 7.161249160766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [27:20:20<5:35:40, 592.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4118.301088686342
INFO:root:current train perplexity5.09004545211792
INFO:root:current mean train loss 4180.5180260365405
INFO:root:current train perplexity5.157527446746826
INFO:root:current mean train loss 4159.42635342098
INFO:root:current train perplexity5.133543491363525
INFO:root:current mean train loss 4151.314868985331
INFO:root:current train perplexity5.130691051483154
INFO:root:current mean train loss 4148.307000832479
INFO:root:current train perplexity5.122481346130371
INFO:root:current mean train loss 4144.2894919466025
INFO:root:current train perplexity5.12075138092041
INFO:root:current mean train loss 4142.240314197692
INFO:root:current train perplexity5.112285137176514
INFO:root:current mean train loss 4138.590012667104
INFO:root:current train perplexity5.107152938842773
INFO:root:current mean train loss 4141.885003270953
INFO:root:current train perplexity5.110630512237549
INFO:root:current mean train loss 4142.136333181635
INFO:root:current train perplexity5.118955135345459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.06s/it]
INFO:root:final mean train loss: 4140.520188916114
INFO:root:final train perplexity: 5.122050762176514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3889.553946420656
INFO:root:eval perplexity: 4.820229530334473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 4838.290534269725
INFO:root:eval perplexity: 7.231479167938232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [27:30:13<5:25:51, 592.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4215.711725725447
INFO:root:current train perplexity5.205557346343994
INFO:root:current mean train loss 4190.431154152199
INFO:root:current train perplexity5.170984268188477
INFO:root:current mean train loss 4181.212624667553
INFO:root:current train perplexity5.173916339874268
INFO:root:current mean train loss 4190.473449889226
INFO:root:current train perplexity5.193116188049316
INFO:root:current mean train loss 4194.121363707794
INFO:root:current train perplexity5.202181816101074
INFO:root:current mean train loss 4185.407139402015
INFO:root:current train perplexity5.197102069854736
INFO:root:current mean train loss 4182.407287309301
INFO:root:current train perplexity5.20106840133667
INFO:root:current mean train loss 4185.700813802084
INFO:root:current train perplexity5.207909107208252
INFO:root:current mean train loss 4185.244720714821
INFO:root:current train perplexity5.209859848022461
INFO:root:current mean train loss 4198.252254710478
INFO:root:current train perplexity5.232094764709473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.86s/it]
INFO:root:final mean train loss: 4194.3717785496865
INFO:root:final train perplexity: 5.232038497924805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 3934.9541396553636
INFO:root:eval perplexity: 4.9095377922058105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4890.946055310837
INFO:root:eval perplexity: 7.388871192932129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [27:40:08<5:16:21, 593.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4158.832173192224
INFO:root:current train perplexity5.15567684173584
INFO:root:current mean train loss 4193.062583656578
INFO:root:current train perplexity5.183964729309082
INFO:root:current mean train loss 4192.263411659272
INFO:root:current train perplexity5.205811500549316
INFO:root:current mean train loss 4201.432180866208
INFO:root:current train perplexity5.235040187835693
INFO:root:current mean train loss 4203.356629933514
INFO:root:current train perplexity5.238405704498291
INFO:root:current mean train loss 4209.074581139215
INFO:root:current train perplexity5.248262882232666
INFO:root:current mean train loss 4220.595140044834
INFO:root:current train perplexity5.2649245262146
INFO:root:current mean train loss 4223.617183228361
INFO:root:current train perplexity5.2778801918029785
INFO:root:current mean train loss 4219.14709371293
INFO:root:current train perplexity5.277265548706055
INFO:root:current mean train loss 4219.583270852664
INFO:root:current train perplexity5.279880523681641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.46s/it]
INFO:root:final mean train loss: 4217.525319868519
INFO:root:final train perplexity: 5.280050277709961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it]
INFO:root:eval mean loss: 3902.855866993573
INFO:root:eval perplexity: 4.846225738525391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4852.06302464262
INFO:root:eval perplexity: 7.2723188400268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [27:50:01<5:06:31, 593.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4269.324539483762
INFO:root:current train perplexity5.345226764678955
INFO:root:current mean train loss 4296.074029581437
INFO:root:current train perplexity5.39055061340332
INFO:root:current mean train loss 4291.822728616783
INFO:root:current train perplexity5.400950908660889
INFO:root:current mean train loss 4271.7086762431
INFO:root:current train perplexity5.37247371673584
INFO:root:current mean train loss 4274.714630465285
INFO:root:current train perplexity5.385077476501465
INFO:root:current mean train loss 4262.541412630445
INFO:root:current train perplexity5.36720085144043
INFO:root:current mean train loss 4261.026661206317
INFO:root:current train perplexity5.357907295227051
INFO:root:current mean train loss 4261.403430842211
INFO:root:current train perplexity5.3629255294799805
INFO:root:current mean train loss 4255.070261147272
INFO:root:current train perplexity5.3521881103515625
INFO:root:current mean train loss 4255.576949736297
INFO:root:current train perplexity5.355472087860107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.90s/it]
INFO:root:final mean train loss: 4252.797337378225
INFO:root:final train perplexity: 5.354040622711182
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 3917.475845661569
INFO:root:eval perplexity: 4.8749613761901855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4868.69174389129
INFO:root:eval perplexity: 7.321937561035156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [27:59:53<4:56:25, 592.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4228.164542505297
INFO:root:current train perplexity5.32409143447876
INFO:root:current mean train loss 4221.766002727005
INFO:root:current train perplexity5.270282745361328
INFO:root:current mean train loss 4221.202603726773
INFO:root:current train perplexity5.271275520324707
INFO:root:current mean train loss 4215.0614357100885
INFO:root:current train perplexity5.269171714782715
INFO:root:current mean train loss 4226.961258233762
INFO:root:current train perplexity5.287783622741699
INFO:root:current mean train loss 4231.566448614294
INFO:root:current train perplexity5.2977471351623535
INFO:root:current mean train loss 4228.40423130157
INFO:root:current train perplexity5.29426908493042
INFO:root:current mean train loss 4226.433419731452
INFO:root:current train perplexity5.292325973510742
INFO:root:current mean train loss 4227.533940378529
INFO:root:current train perplexity5.298494815826416
INFO:root:current mean train loss 4233.604067041678
INFO:root:current train perplexity5.309882640838623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.28s/it]
INFO:root:final mean train loss: 4233.710964756628
INFO:root:final train perplexity: 5.313876152038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.59s/it]
INFO:root:eval mean loss: 3937.1499819924647
INFO:root:eval perplexity: 4.9138994216918945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4886.748038217531
INFO:root:eval perplexity: 7.376199245452881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [28:09:46<4:46:35, 592.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4308.503275857043
INFO:root:current train perplexity5.387382507324219
INFO:root:current mean train loss 4260.05322996585
INFO:root:current train perplexity5.33111572265625
INFO:root:current mean train loss 4265.061731917135
INFO:root:current train perplexity5.3441619873046875
INFO:root:current mean train loss 4250.82148796726
INFO:root:current train perplexity5.326784133911133
INFO:root:current mean train loss 4240.430619102985
INFO:root:current train perplexity5.318730354309082
INFO:root:current mean train loss 4241.655559344687
INFO:root:current train perplexity5.321635723114014
INFO:root:current mean train loss 4243.991845263891
INFO:root:current train perplexity5.321844577789307
INFO:root:current mean train loss 4241.390476987756
INFO:root:current train perplexity5.31835412979126
INFO:root:current mean train loss 4242.750978252055
INFO:root:current train perplexity5.322207450866699
INFO:root:current mean train loss 4240.315151968071
INFO:root:current train perplexity5.320460319519043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.15s/it]
INFO:root:final mean train loss: 4236.776636431294
INFO:root:final train perplexity: 5.320306777954102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 3933.099025861591
INFO:root:eval perplexity: 4.905857563018799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 4881.772613308954
INFO:root:eval perplexity: 7.361207008361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [28:19:40<4:36:50, 593.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4248.866481119791
INFO:root:current train perplexity5.370481967926025
INFO:root:current mean train loss 4240.728168247768
INFO:root:current train perplexity5.344921112060547
INFO:root:current mean train loss 4258.777397017046
INFO:root:current train perplexity5.396673679351807
INFO:root:current mean train loss 4262.974628255209
INFO:root:current train perplexity5.389113426208496
INFO:root:current mean train loss 4268.8520281661185
INFO:root:current train perplexity5.386045455932617
INFO:root:current mean train loss 4269.2900390625
INFO:root:current train perplexity5.387438774108887
INFO:root:current mean train loss 4268.951726345486
INFO:root:current train perplexity5.380975246429443
INFO:root:current mean train loss 4271.290756363407
INFO:root:current train perplexity5.3811235427856445
INFO:root:current mean train loss 4269.086055524554
INFO:root:current train perplexity5.380831718444824
INFO:root:current mean train loss 4269.495194310897
INFO:root:current train perplexity5.382505416870117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.88s/it]
INFO:root:final mean train loss: 4267.125979515814
INFO:root:final train perplexity: 5.384393692016602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 3971.4212291528147
INFO:root:eval perplexity: 4.982471942901611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4914.865578942265
INFO:root:eval perplexity: 7.4614973068237305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [28:29:34<4:27:02, 593.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4256.875161779933
INFO:root:current train perplexity5.353793144226074
INFO:root:current mean train loss 4259.439609214908
INFO:root:current train perplexity5.346582889556885
INFO:root:current mean train loss 4246.161905780697
INFO:root:current train perplexity5.325497150421143
INFO:root:current mean train loss 4253.46787287859
INFO:root:current train perplexity5.337637424468994
INFO:root:current mean train loss 4247.527230019895
INFO:root:current train perplexity5.332133769989014
INFO:root:current mean train loss 4250.724153338738
INFO:root:current train perplexity5.346863269805908
INFO:root:current mean train loss 4252.005967325906
INFO:root:current train perplexity5.3554182052612305
INFO:root:current mean train loss 4255.8499835368775
INFO:root:current train perplexity5.3616509437561035
INFO:root:current mean train loss 4257.99337917168
INFO:root:current train perplexity5.362903118133545
INFO:root:current mean train loss 4255.499851230687
INFO:root:current train perplexity5.3544135093688965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.43s/it]
INFO:root:final mean train loss: 4252.7424610507105
INFO:root:final train perplexity: 5.3539252281188965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3943.300646193484
INFO:root:eval perplexity: 4.926136493682861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4891.476539990581
INFO:root:eval perplexity: 7.390474319458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [28:39:31<4:17:36, 594.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4207.565236521291
INFO:root:current train perplexity5.281773090362549
INFO:root:current mean train loss 4248.564883886207
INFO:root:current train perplexity5.320850372314453
INFO:root:current mean train loss 4241.013744865496
INFO:root:current train perplexity5.333193302154541
INFO:root:current mean train loss 4249.476838485054
INFO:root:current train perplexity5.344131946563721
INFO:root:current mean train loss 4254.330069672066
INFO:root:current train perplexity5.352632522583008
INFO:root:current mean train loss 4256.772303547351
INFO:root:current train perplexity5.357693672180176
INFO:root:current mean train loss 4256.400775384972
INFO:root:current train perplexity5.354290962219238
INFO:root:current mean train loss 4263.4845953747235
INFO:root:current train perplexity5.366430759429932
INFO:root:current mean train loss 4267.323672653181
INFO:root:current train perplexity5.37710428237915
INFO:root:current mean train loss 4274.130363456657
INFO:root:current train perplexity5.392186641693115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.11s/it]
INFO:root:final mean train loss: 4270.763285113919
INFO:root:final train perplexity: 5.392125606536865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 3943.441783715647
INFO:root:eval perplexity: 4.926417350769043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4891.161221118684
INFO:root:eval perplexity: 7.38952112197876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [28:49:22<4:07:16, 593.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4296.351572364268
INFO:root:current train perplexity5.428003311157227
INFO:root:current mean train loss 4271.377675732177
INFO:root:current train perplexity5.4198455810546875
INFO:root:current mean train loss 4277.416834598401
INFO:root:current train perplexity5.417107105255127
INFO:root:current mean train loss 4289.741024925595
INFO:root:current train perplexity5.432192325592041
INFO:root:current mean train loss 4292.597786393098
INFO:root:current train perplexity5.439224720001221
INFO:root:current mean train loss 4299.136576912041
INFO:root:current train perplexity5.445551872253418
INFO:root:current mean train loss 4301.221222142122
INFO:root:current train perplexity5.453118801116943
INFO:root:current mean train loss 4303.402783447571
INFO:root:current train perplexity5.455503463745117
INFO:root:current mean train loss 4302.821815091856
INFO:root:current train perplexity5.456238746643066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.34s/it]
INFO:root:final mean train loss: 4301.243425799954
INFO:root:final train perplexity: 5.4573588371276855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3950.8313715508643
INFO:root:eval perplexity: 4.941161155700684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 4896.517424022052
INFO:root:eval perplexity: 7.40572452545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [28:59:16<3:57:26, 593.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.985421316965
INFO:root:current train perplexity5.309832572937012
INFO:root:current mean train loss 4333.366083162968
INFO:root:current train perplexity5.536893844604492
INFO:root:current mean train loss 4305.732820520078
INFO:root:current train perplexity5.461541652679443
INFO:root:current mean train loss 4310.864656230914
INFO:root:current train perplexity5.468544006347656
INFO:root:current mean train loss 4303.8512667719215
INFO:root:current train perplexity5.461349964141846
INFO:root:current mean train loss 4299.4898558848
INFO:root:current train perplexity5.4471845626831055
INFO:root:current mean train loss 4302.102193163098
INFO:root:current train perplexity5.451959609985352
INFO:root:current mean train loss 4300.717549325384
INFO:root:current train perplexity5.451559066772461
INFO:root:current mean train loss 4300.737449296197
INFO:root:current train perplexity5.449829578399658
INFO:root:current mean train loss 4298.041660834568
INFO:root:current train perplexity5.446260452270508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.89s/it]
INFO:root:final mean train loss: 4294.193179776592
INFO:root:final train perplexity: 5.442201137542725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 3951.0267429216533
INFO:root:eval perplexity: 4.941551685333252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 4899.457668439716
INFO:root:eval perplexity: 7.414632320404053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [29:09:07<3:47:15, 592.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4324.682421875
INFO:root:current train perplexity5.496965408325195
INFO:root:current mean train loss 4294.721677564538
INFO:root:current train perplexity5.444818019866943
INFO:root:current mean train loss 4288.391936546148
INFO:root:current train perplexity5.4352216720581055
INFO:root:current mean train loss 4292.37935655382
INFO:root:current train perplexity5.4449896812438965
INFO:root:current mean train loss 4299.347324454066
INFO:root:current train perplexity5.451743125915527
INFO:root:current mean train loss 4304.461895100121
INFO:root:current train perplexity5.459990501403809
INFO:root:current mean train loss 4302.140077966209
INFO:root:current train perplexity5.458950519561768
INFO:root:current mean train loss 4301.513137838724
INFO:root:current train perplexity5.45517110824585
INFO:root:current mean train loss 4298.022569377876
INFO:root:current train perplexity5.45046329498291
INFO:root:current mean train loss 4296.97511980234
INFO:root:current train perplexity5.443380832672119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.23s/it]
INFO:root:final mean train loss: 4293.353237275154
INFO:root:final train perplexity: 5.440397262573242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3942.6530727088875
INFO:root:eval perplexity: 4.924846649169922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4888.676596783577
INFO:root:eval perplexity: 7.382017135620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [29:18:59<3:37:14, 592.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4202.55029296875
INFO:root:current train perplexity5.339827060699463
INFO:root:current mean train loss 4291.421166396723
INFO:root:current train perplexity5.425534248352051
INFO:root:current mean train loss 4276.274103139013
INFO:root:current train perplexity5.411664962768555
INFO:root:current mean train loss 4288.679445626935
INFO:root:current train perplexity5.432775497436523
INFO:root:current mean train loss 4287.893272454012
INFO:root:current train perplexity5.440390110015869
INFO:root:current mean train loss 4297.319375149378
INFO:root:current train perplexity5.449826717376709
INFO:root:current mean train loss 4297.008216527262
INFO:root:current train perplexity5.452089309692383
INFO:root:current mean train loss 4302.25706251891
INFO:root:current train perplexity5.455784797668457
INFO:root:current mean train loss 4297.858976009549
INFO:root:current train perplexity5.443073749542236
INFO:root:current mean train loss 4296.073047509819
INFO:root:current train perplexity5.444127559661865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.66s/it]
INFO:root:final mean train loss: 4294.192141317552
INFO:root:final train perplexity: 5.442197799682617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3963.82513124723
INFO:root:eval perplexity: 4.967191219329834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 4909.739870761303
INFO:root:eval perplexity: 7.4458746910095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [29:28:52<3:27:28, 592.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4385.579841859879
INFO:root:current train perplexity5.632784843444824
INFO:root:current mean train loss 4343.51867209864
INFO:root:current train perplexity5.51915168762207
INFO:root:current mean train loss 4329.730509968547
INFO:root:current train perplexity5.5166802406311035
INFO:root:current mean train loss 4312.697296603569
INFO:root:current train perplexity5.478588581085205
INFO:root:current mean train loss 4304.82653383755
INFO:root:current train perplexity5.4732584953308105
INFO:root:current mean train loss 4305.502828077183
INFO:root:current train perplexity5.467950820922852
INFO:root:current mean train loss 4305.73482188181
INFO:root:current train perplexity5.468116283416748
INFO:root:current mean train loss 4307.0504813344305
INFO:root:current train perplexity5.463351249694824
INFO:root:current mean train loss 4305.138669230878
INFO:root:current train perplexity5.460210800170898
INFO:root:current mean train loss 4302.153122325205
INFO:root:current train perplexity5.452847957611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.30s/it]
INFO:root:final mean train loss: 4298.741755208662
INFO:root:final train perplexity: 5.4519758224487305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3944.8648326684397
INFO:root:eval perplexity: 4.929253578186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4890.5710379959
INFO:root:eval perplexity: 7.3877387046813965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [29:38:44<3:17:29, 592.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4311.7179612379805
INFO:root:current train perplexity5.380321025848389
INFO:root:current mean train loss 4310.970908624663
INFO:root:current train perplexity5.432351589202881
INFO:root:current mean train loss 4306.58766997908
INFO:root:current train perplexity5.4439191818237305
INFO:root:current mean train loss 4305.49017243962
INFO:root:current train perplexity5.439944267272949
INFO:root:current mean train loss 4300.55730464301
INFO:root:current train perplexity5.437047004699707
INFO:root:current mean train loss 4288.7911152742345
INFO:root:current train perplexity5.427718162536621
INFO:root:current mean train loss 4290.568956163194
INFO:root:current train perplexity5.433380126953125
INFO:root:current mean train loss 4286.966881448749
INFO:root:current train perplexity5.422945499420166
INFO:root:current mean train loss 4293.763048865371
INFO:root:current train perplexity5.434967517852783
INFO:root:current mean train loss 4297.198228927466
INFO:root:current train perplexity5.442506790161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.43s/it]
INFO:root:final mean train loss: 4295.048387281357
INFO:root:final train perplexity: 5.444036960601807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3972.4674669630986
INFO:root:eval perplexity: 4.984580993652344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 4917.910821143617
INFO:root:eval perplexity: 7.470794677734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [29:48:34<3:07:25, 591.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4755.742483585439
INFO:root:current train perplexity6.57060432434082
INFO:root:current mean train loss 4735.789193704825
INFO:root:current train perplexity6.481609344482422
INFO:root:current mean train loss 4671.876512288082
INFO:root:current train perplexity6.317981243133545
INFO:root:current mean train loss 4630.038255499145
INFO:root:current train perplexity6.2096381187438965
INFO:root:current mean train loss 4602.762730813934
INFO:root:current train perplexity6.151438236236572
INFO:root:current mean train loss 4579.239990680701
INFO:root:current train perplexity6.097496509552002
INFO:root:current mean train loss 4564.429057337954
INFO:root:current train perplexity6.052626132965088
INFO:root:current mean train loss 4546.956634807459
INFO:root:current train perplexity6.007936954498291
INFO:root:current mean train loss 4532.142831489356
INFO:root:current train perplexity5.970176696777344
INFO:root:current mean train loss 4516.380460294021
INFO:root:current train perplexity5.929173946380615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.18s/it]
INFO:root:final mean train loss: 4505.104578510408
INFO:root:final train perplexity: 5.91442346572876
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 3974.921880194481
INFO:root:eval perplexity: 4.989530086517334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4918.125777440714
INFO:root:eval perplexity: 7.471451759338379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [29:58:26<2:57:33, 591.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4352.008709161932
INFO:root:current train perplexity5.528278350830078
INFO:root:current mean train loss 4371.553725113407
INFO:root:current train perplexity5.571908950805664
INFO:root:current mean train loss 4344.090331073836
INFO:root:current train perplexity5.536985397338867
INFO:root:current mean train loss 4331.002042528609
INFO:root:current train perplexity5.515255928039551
INFO:root:current mean train loss 4328.057305438702
INFO:root:current train perplexity5.509738922119141
INFO:root:current mean train loss 4317.23682080518
INFO:root:current train perplexity5.4931464195251465
INFO:root:current mean train loss 4316.157928792939
INFO:root:current train perplexity5.489407539367676
INFO:root:current mean train loss 4316.171958428187
INFO:root:current train perplexity5.4817962646484375
INFO:root:current mean train loss 4316.11032357913
INFO:root:current train perplexity5.482151508331299
INFO:root:current mean train loss 4316.821202910259
INFO:root:current train perplexity5.482748985290527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.77s/it]
INFO:root:final mean train loss: 4312.742116866573
INFO:root:final train perplexity: 5.48217248916626
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3966.00360497008
INFO:root:eval perplexity: 4.971568584442139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 4910.945272675643
INFO:root:eval perplexity: 7.449544906616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [30:08:18<2:47:43, 591.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4296.272894965277
INFO:root:current train perplexity5.391328811645508
INFO:root:current mean train loss 4306.91693227569
INFO:root:current train perplexity5.466350078582764
INFO:root:current mean train loss 4292.811771291291
INFO:root:current train perplexity5.452186107635498
INFO:root:current mean train loss 4302.215837799156
INFO:root:current train perplexity5.461887359619141
INFO:root:current mean train loss 4305.622541192798
INFO:root:current train perplexity5.4667439460754395
INFO:root:current mean train loss 4304.971913854351
INFO:root:current train perplexity5.467892646789551
INFO:root:current mean train loss 4311.637338491587
INFO:root:current train perplexity5.469770431518555
INFO:root:current mean train loss 4308.594768159199
INFO:root:current train perplexity5.460580348968506
INFO:root:current mean train loss 4306.445617746505
INFO:root:current train perplexity5.457583904266357
INFO:root:current mean train loss 4302.1054857359
INFO:root:current train perplexity5.4535722732543945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.26s/it]
INFO:root:final mean train loss: 4300.129560409054
INFO:root:final train perplexity: 5.454961776733398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 3956.0926158715647
INFO:root:eval perplexity: 4.95168399810791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4901.972853640293
INFO:root:eval perplexity: 7.422264575958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [30:18:08<2:37:40, 591.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4255.096800038512
INFO:root:current train perplexity5.373664379119873
INFO:root:current mean train loss 4288.5380659493785
INFO:root:current train perplexity5.409538269042969
INFO:root:current mean train loss 4283.496151406826
INFO:root:current train perplexity5.417070388793945
INFO:root:current mean train loss 4289.54872809973
INFO:root:current train perplexity5.4168782234191895
INFO:root:current mean train loss 4296.171618419088
INFO:root:current train perplexity5.435853481292725
INFO:root:current mean train loss 4296.022139834857
INFO:root:current train perplexity5.441531658172607
INFO:root:current mean train loss 4294.250760801859
INFO:root:current train perplexity5.437748432159424
INFO:root:current mean train loss 4301.711202856477
INFO:root:current train perplexity5.450500965118408
INFO:root:current mean train loss 4302.166274060885
INFO:root:current train perplexity5.453080177307129
INFO:root:current mean train loss 4304.877783102552
INFO:root:current train perplexity5.4564738273620605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.70s/it]
INFO:root:final mean train loss: 4299.366181650469
INFO:root:final train perplexity: 5.453318119049072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3961.431391289894
INFO:root:eval perplexity: 4.962385177612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 4907.428821753103
INFO:root:eval perplexity: 7.438840866088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [30:28:02<2:28:02, 592.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4289.947828075554
INFO:root:current train perplexity5.416743278503418
INFO:root:current mean train loss 4305.701591960545
INFO:root:current train perplexity5.455500602722168
INFO:root:current mean train loss 4300.884931885641
INFO:root:current train perplexity5.467983245849609
INFO:root:current mean train loss 4304.591856782858
INFO:root:current train perplexity5.465116500854492
INFO:root:current mean train loss 4303.210328422658
INFO:root:current train perplexity5.455196857452393
INFO:root:current mean train loss 4309.157601417449
INFO:root:current train perplexity5.4566168785095215
INFO:root:current mean train loss 4309.235801730486
INFO:root:current train perplexity5.458658218383789
INFO:root:current mean train loss 4307.311615891267
INFO:root:current train perplexity5.4581146240234375
INFO:root:current mean train loss 4306.363491227602
INFO:root:current train perplexity5.4608306884765625
INFO:root:current mean train loss 4307.002870834397
INFO:root:current train perplexity5.464731216430664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.41s/it]
INFO:root:final mean train loss: 4305.426891142322
INFO:root:final train perplexity: 5.466373443603516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3963.5502202460107
INFO:root:eval perplexity: 4.966638565063477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 4908.135227933843
INFO:root:eval perplexity: 7.440990924835205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [30:37:56<2:18:18, 592.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4346.297523235453
INFO:root:current train perplexity5.483552932739258
INFO:root:current mean train loss 4349.289458086147
INFO:root:current train perplexity5.520488739013672
INFO:root:current mean train loss 4325.430833344675
INFO:root:current train perplexity5.481356620788574
INFO:root:current mean train loss 4309.570713092498
INFO:root:current train perplexity5.468642234802246
INFO:root:current mean train loss 4306.573411632123
INFO:root:current train perplexity5.46647310256958
INFO:root:current mean train loss 4307.301634286494
INFO:root:current train perplexity5.467998504638672
INFO:root:current mean train loss 4313.5282549240355
INFO:root:current train perplexity5.476718902587891
INFO:root:current mean train loss 4318.768606493706
INFO:root:current train perplexity5.4822211265563965
INFO:root:current mean train loss 4317.214602086563
INFO:root:current train perplexity5.485620498657227
INFO:root:current mean train loss 4319.019235659273
INFO:root:current train perplexity5.488565921783447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.24s/it]
INFO:root:final mean train loss: 4315.081490055208
INFO:root:final train perplexity: 5.487235069274902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 3975.093962973737
INFO:root:eval perplexity: 4.989878177642822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4920.4361199994455
INFO:root:eval perplexity: 7.478512763977051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [30:47:47<2:08:17, 592.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4316.402837171053
INFO:root:current train perplexity5.515834331512451
INFO:root:current mean train loss 4327.118949068509
INFO:root:current train perplexity5.5115156173706055
INFO:root:current mean train loss 4323.541218385858
INFO:root:current train perplexity5.50545597076416
INFO:root:current mean train loss 4315.392869857595
INFO:root:current train perplexity5.484785556793213
INFO:root:current mean train loss 4317.275746725063
INFO:root:current train perplexity5.491211891174316
INFO:root:current mean train loss 4323.086268218225
INFO:root:current train perplexity5.503139019012451
INFO:root:current mean train loss 4328.680698839366
INFO:root:current train perplexity5.5024003982543945
INFO:root:current mean train loss 4331.333108846797
INFO:root:current train perplexity5.506831169128418
INFO:root:current mean train loss 4326.067844361033
INFO:root:current train perplexity5.497078895568848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.33s/it]
INFO:root:final mean train loss: 4321.593194038637
INFO:root:final train perplexity: 5.501348972320557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.58s/it]
INFO:root:eval mean loss: 3967.963394489694
INFO:root:eval perplexity: 4.9755096435546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 4912.837771151928
INFO:root:eval perplexity: 7.455312728881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [30:57:39<1:58:22, 591.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4374.084635416667
INFO:root:current train perplexity5.415529251098633
INFO:root:current mean train loss 4341.16322815534
INFO:root:current train perplexity5.51124382019043
INFO:root:current mean train loss 4346.836313933574
INFO:root:current train perplexity5.5137810707092285
INFO:root:current mean train loss 4341.6058055512585
INFO:root:current train perplexity5.517093658447266
INFO:root:current mean train loss 4331.400674748953
INFO:root:current train perplexity5.503866195678711
INFO:root:current mean train loss 4335.8846010848965
INFO:root:current train perplexity5.510035037994385
INFO:root:current mean train loss 4330.651680157157
INFO:root:current train perplexity5.507473945617676
INFO:root:current mean train loss 4331.160513952481
INFO:root:current train perplexity5.516108512878418
INFO:root:current mean train loss 4329.036991713205
INFO:root:current train perplexity5.513669967651367
INFO:root:current mean train loss 4328.704685553364
INFO:root:current train perplexity5.5104193687438965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.58s/it]
INFO:root:final mean train loss: 4325.551117558633
INFO:root:final train perplexity: 5.509947776794434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 3971.2850904532356
INFO:root:eval perplexity: 4.98219633102417
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 4915.492471464982
INFO:root:eval perplexity: 7.463411808013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [31:07:30<1:48:28, 591.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4387.863991477273
INFO:root:current train perplexity5.690692901611328
INFO:root:current mean train loss 4329.255432678772
INFO:root:current train perplexity5.514029026031494
INFO:root:current mean train loss 4316.226543986967
INFO:root:current train perplexity5.493720054626465
INFO:root:current mean train loss 4326.252081082948
INFO:root:current train perplexity5.499754428863525
INFO:root:current mean train loss 4326.668498018362
INFO:root:current train perplexity5.508448123931885
INFO:root:current mean train loss 4321.038505419826
INFO:root:current train perplexity5.49805212020874
INFO:root:current mean train loss 4330.0629583130885
INFO:root:current train perplexity5.512452125549316
INFO:root:current mean train loss 4332.7481313455955
INFO:root:current train perplexity5.519626140594482
INFO:root:current mean train loss 4334.841820054813
INFO:root:current train perplexity5.525097370147705
INFO:root:current mean train loss 4334.990573652751
INFO:root:current train perplexity5.524531841278076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.84s/it]
INFO:root:final mean train loss: 4333.894672947546
INFO:root:final train perplexity: 5.5281147956848145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3977.7697788536125
INFO:root:eval perplexity: 4.995278835296631
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 4922.230170933068
INFO:root:eval perplexity: 7.484003067016602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [31:17:23<1:38:40, 592.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4255.474557976973
INFO:root:current train perplexity5.328084468841553
INFO:root:current mean train loss 4321.926991695115
INFO:root:current train perplexity5.493830680847168
INFO:root:current mean train loss 4335.648735150899
INFO:root:current train perplexity5.5196533203125
INFO:root:current mean train loss 4325.176721841937
INFO:root:current train perplexity5.5056281089782715
INFO:root:current mean train loss 4321.500883334576
INFO:root:current train perplexity5.494879245758057
INFO:root:current mean train loss 4319.398983170761
INFO:root:current train perplexity5.4960126876831055
INFO:root:current mean train loss 4316.557718551217
INFO:root:current train perplexity5.487666130065918
INFO:root:current mean train loss 4319.084463827799
INFO:root:current train perplexity5.491489887237549
INFO:root:current mean train loss 4319.4595292944905
INFO:root:current train perplexity5.4937920570373535
INFO:root:current mean train loss 4319.14118793143
INFO:root:current train perplexity5.492845058441162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.43s/it]
INFO:root:final mean train loss: 4319.9554587948705
INFO:root:final train perplexity: 5.497797012329102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3966.437338971077
INFO:root:eval perplexity: 4.972440242767334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 4911.368257563165
INFO:root:eval perplexity: 7.450832843780518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [31:27:15<1:28:50, 592.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4318.889992042824
INFO:root:current train perplexity5.464756965637207
INFO:root:current mean train loss 4291.081783264641
INFO:root:current train perplexity5.448302745819092
INFO:root:current mean train loss 4304.803781921118
INFO:root:current train perplexity5.476829528808594
INFO:root:current mean train loss 4312.617715351443
INFO:root:current train perplexity5.48538875579834
INFO:root:current mean train loss 4316.922703477203
INFO:root:current train perplexity5.48289155960083
INFO:root:current mean train loss 4321.612257434475
INFO:root:current train perplexity5.486563682556152
INFO:root:current mean train loss 4322.758817487166
INFO:root:current train perplexity5.492300987243652
INFO:root:current mean train loss 4322.086424437973
INFO:root:current train perplexity5.494296550750732
INFO:root:current mean train loss 4318.212637923217
INFO:root:current train perplexity5.48967981338501
INFO:root:current mean train loss 4323.6634683454695
INFO:root:current train perplexity5.497574806213379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.49s/it]
INFO:root:final mean train loss: 4319.024570157451
INFO:root:final train perplexity: 5.4957780838012695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3965.33549943207
INFO:root:eval perplexity: 4.970226764678955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 4908.727369376108
INFO:root:eval perplexity: 7.442793369293213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [31:37:07<1:18:57, 592.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4465.381598772321
INFO:root:current train perplexity5.651054382324219
INFO:root:current mean train loss 4345.939514612269
INFO:root:current train perplexity5.547893047332764
INFO:root:current mean train loss 4337.628061627327
INFO:root:current train perplexity5.5045857429504395
INFO:root:current mean train loss 4330.691268510961
INFO:root:current train perplexity5.50468635559082
INFO:root:current mean train loss 4326.1642718435705
INFO:root:current train perplexity5.495722770690918
INFO:root:current mean train loss 4326.301056877921
INFO:root:current train perplexity5.5017571449279785
INFO:root:current mean train loss 4328.5177565206695
INFO:root:current train perplexity5.5060577392578125
INFO:root:current mean train loss 4328.369872382546
INFO:root:current train perplexity5.512290000915527
INFO:root:current mean train loss 4326.863585621725
INFO:root:current train perplexity5.506898880004883
INFO:root:current mean train loss 4329.3595368900405
INFO:root:current train perplexity5.507920265197754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.01s/it]
INFO:root:final mean train loss: 4321.886684048561
INFO:root:final train perplexity: 5.501987457275391
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 3968.6582896996897
INFO:root:eval perplexity: 4.976909160614014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4911.683110663232
INFO:root:eval perplexity: 7.451794147491455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [31:46:58<1:09:03, 591.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4333.022063499273
INFO:root:current train perplexity5.515982151031494
INFO:root:current mean train loss 4318.654324191433
INFO:root:current train perplexity5.509392738342285
INFO:root:current mean train loss 4334.6594479407795
INFO:root:current train perplexity5.524620532989502
INFO:root:current mean train loss 4334.853015243486
INFO:root:current train perplexity5.525033950805664
INFO:root:current mean train loss 4333.230518900783
INFO:root:current train perplexity5.518359184265137
INFO:root:current mean train loss 4328.290330862253
INFO:root:current train perplexity5.507277011871338
INFO:root:current mean train loss 4326.323930185653
INFO:root:current train perplexity5.501049995422363
INFO:root:current mean train loss 4325.602746729895
INFO:root:current train perplexity5.5019073486328125
INFO:root:current mean train loss 4321.668461954608
INFO:root:current train perplexity5.497480392456055
INFO:root:current mean train loss 4323.160987829732
INFO:root:current train perplexity5.4998064041137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.38s/it]
INFO:root:final mean train loss: 4321.894529404179
INFO:root:final train perplexity: 5.5020036697387695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3967.109432139295
INFO:root:eval perplexity: 4.973792552947998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 4910.233874598293
INFO:root:eval perplexity: 7.447378635406494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [31:56:52<59:13, 592.21s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4278.961502374387
INFO:root:current train perplexity5.475677013397217
INFO:root:current mean train loss 4309.284081061155
INFO:root:current train perplexity5.497464179992676
INFO:root:current mean train loss 4319.641267936068
INFO:root:current train perplexity5.482898235321045
INFO:root:current mean train loss 4312.831250834669
INFO:root:current train perplexity5.48862886428833
INFO:root:current mean train loss 4321.310812668896
INFO:root:current train perplexity5.495577812194824
INFO:root:current mean train loss 4322.899104345082
INFO:root:current train perplexity5.504878520965576
INFO:root:current mean train loss 4324.01101858019
INFO:root:current train perplexity5.5010271072387695
INFO:root:current mean train loss 4318.13639203718
INFO:root:current train perplexity5.490118503570557
INFO:root:current mean train loss 4324.009751567549
INFO:root:current train perplexity5.498548984527588
INFO:root:current mean train loss 4323.74416604027
INFO:root:current train perplexity5.49740743637085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.04s/it]
INFO:root:final mean train loss: 4318.479094474546
INFO:root:final train perplexity: 5.494594573974609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3968.887736868351
INFO:root:eval perplexity: 4.9773712158203125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 4913.505114832668
INFO:root:eval perplexity: 7.457347869873047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [32:06:45<49:22, 592.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4297.180068193856
INFO:root:current train perplexity5.455324649810791
INFO:root:current mean train loss 4310.387110296286
INFO:root:current train perplexity5.459652900695801
INFO:root:current mean train loss 4319.476898075531
INFO:root:current train perplexity5.493921756744385
INFO:root:current mean train loss 4306.362348211177
INFO:root:current train perplexity5.466614723205566
INFO:root:current mean train loss 4315.493954993021
INFO:root:current train perplexity5.480635643005371
INFO:root:current mean train loss 4309.725103333939
INFO:root:current train perplexity5.473573684692383
INFO:root:current mean train loss 4314.185634676712
INFO:root:current train perplexity5.4803619384765625
INFO:root:current mean train loss 4322.603492465415
INFO:root:current train perplexity5.49148416519165
INFO:root:current mean train loss 4323.66157959837
INFO:root:current train perplexity5.4932427406311035
INFO:root:current mean train loss 4321.848056192567
INFO:root:current train perplexity5.491842746734619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.38s/it]
INFO:root:final mean train loss: 4317.565036712154
INFO:root:final train perplexity: 5.492614269256592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 3962.781121869459
INFO:root:eval perplexity: 4.965094566345215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 4906.49375277039
INFO:root:eval perplexity: 7.435997009277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [32:16:37<39:30, 592.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4323.06741196362
INFO:root:current train perplexity5.495378494262695
INFO:root:current mean train loss 4327.198503871164
INFO:root:current train perplexity5.487547874450684
INFO:root:current mean train loss 4328.117406952248
INFO:root:current train perplexity5.494427680969238
INFO:root:current mean train loss 4327.960109284529
INFO:root:current train perplexity5.494499683380127
INFO:root:current mean train loss 4329.815820730728
INFO:root:current train perplexity5.504502773284912
INFO:root:current mean train loss 4323.34956373319
INFO:root:current train perplexity5.500119209289551
INFO:root:current mean train loss 4325.640694911333
INFO:root:current train perplexity5.50264310836792
INFO:root:current mean train loss 4322.315486664256
INFO:root:current train perplexity5.4996418952941895
INFO:root:current mean train loss 4325.550977238322
INFO:root:current train perplexity5.504255771636963
INFO:root:current mean train loss 4326.0255951274885
INFO:root:current train perplexity5.504001140594482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.73s/it]
INFO:root:final mean train loss: 4322.020393556164
INFO:root:final train perplexity: 5.502277374267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 3966.2236535904253
INFO:root:eval perplexity: 4.972011566162109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 4909.544352213542
INFO:root:eval perplexity: 7.445278167724609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [32:26:29<29:36, 592.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4314.453141276042
INFO:root:current train perplexity5.502242565155029
INFO:root:current mean train loss 4315.323401227679
INFO:root:current train perplexity5.484074592590332
INFO:root:current mean train loss 4304.541202947443
INFO:root:current train perplexity5.444570064544678
INFO:root:current mean train loss 4308.214771484375
INFO:root:current train perplexity5.464646816253662
INFO:root:current mean train loss 4313.233225740131
INFO:root:current train perplexity5.480040073394775
INFO:root:current mean train loss 4314.314564368206
INFO:root:current train perplexity5.485039234161377
INFO:root:current mean train loss 4318.632144097222
INFO:root:current train perplexity5.489307880401611
INFO:root:current mean train loss 4321.443173513105
INFO:root:current train perplexity5.489425182342529
INFO:root:current mean train loss 4321.912010323661
INFO:root:current train perplexity5.493760108947754
INFO:root:current mean train loss 4320.411118289263
INFO:root:current train perplexity5.490877151489258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.27s/it]
INFO:root:final mean train loss: 4315.622408466955
INFO:root:final train perplexity: 5.488406181335449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 3960.0629848182625
INFO:root:eval perplexity: 4.9596405029296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 4902.745626246676
INFO:root:eval perplexity: 7.4246110916137695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [32:36:22<19:45, 592.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4279.233339608434
INFO:root:current train perplexity5.443721294403076
INFO:root:current mean train loss 4279.239453925461
INFO:root:current train perplexity5.445454120635986
INFO:root:current mean train loss 4295.906413910667
INFO:root:current train perplexity5.466464042663574
INFO:root:current mean train loss 4299.345703125
INFO:root:current train perplexity5.474863052368164
INFO:root:current mean train loss 4299.704391195167
INFO:root:current train perplexity5.47620964050293
INFO:root:current mean train loss 4302.8638872045185
INFO:root:current train perplexity5.469337463378906
INFO:root:current mean train loss 4310.165527701203
INFO:root:current train perplexity5.479457855224609
INFO:root:current mean train loss 4315.132189832276
INFO:root:current train perplexity5.486536502838135
INFO:root:current mean train loss 4316.668690388767
INFO:root:current train perplexity5.486169338226318
INFO:root:current mean train loss 4318.686989614462
INFO:root:current train perplexity5.487819194793701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.21s/it]
INFO:root:final mean train loss: 4315.315726310976
INFO:root:final train perplexity: 5.487741470336914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3959.334876094304
INFO:root:eval perplexity: 4.958180904388428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4901.764172276707
INFO:root:eval perplexity: 7.421630859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [32:46:14<09:52, 592.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4285.281767792754
INFO:root:current train perplexity5.461467742919922
INFO:root:current mean train loss 4283.610929319371
INFO:root:current train perplexity5.439732551574707
INFO:root:current mean train loss 4297.166704420371
INFO:root:current train perplexity5.447843074798584
INFO:root:current mean train loss 4306.162783727622
INFO:root:current train perplexity5.455845355987549
INFO:root:current mean train loss 4297.241613694947
INFO:root:current train perplexity5.450799465179443
INFO:root:current mean train loss 4303.312659042539
INFO:root:current train perplexity5.458672046661377
INFO:root:current mean train loss 4306.440849425651
INFO:root:current train perplexity5.463657379150391
INFO:root:current mean train loss 4306.444143958399
INFO:root:current train perplexity5.464719295501709
INFO:root:current mean train loss 4310.08114867205
INFO:root:current train perplexity5.468966007232666
INFO:root:current mean train loss 4310.641484049807
INFO:root:current train perplexity5.470536708831787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.83s/it]
INFO:root:final mean train loss: 4307.346941917173
INFO:root:final train perplexity: 5.470515727996826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3959.9699516566934
INFO:root:eval perplexity: 4.95945405960083
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 4902.653668342753
INFO:root:eval perplexity: 7.42432975769043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_200e_128/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [32:56:09<00:00, 593.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [32:56:09<00:00, 592.85s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.74s/it]
INFO:root:eval mean loss: 3959.9699516566934
INFO:root:eval perplexity: 4.95945405960083
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it]
INFO:root:eval mean loss: 4902.653668342753
INFO:root:eval perplexity: 7.42432975769043
INFO:root:evalaution complete
INFO:root:save model final: multil6_alll12_not_concat_200e_128/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x153d3a792f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x153d3a78a8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x153d3a6afe09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x153d3a793a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x153d3a6ad948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x153d3a793a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x153d3a668b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x153d3a0cd46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x153e36929a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x153e36929be0]
python(+0x24a989) [0x5557b8d96989]
python(+0x24a9bd) [0x5557b8d969bd]
python(+0x24aa14) [0x5557b8d96a14]
python(+0x108f75) [0x5557b8c54f75]
python(Py_RunMain+0x313) [0x5557b8d99983]
python(Py_BytesMain+0x39) [0x5557b8d99bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x153e369070b3]
python(+0x1d6e13) [0x5557b8d22e13]
/opt/slurm/data/slurmd/job30006052/slurm_script: line 255: 2109483 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L12-v1 --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected --output multil6_alll12_not_concat_200e_128 --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self --batch_size 128
"
