INFO:root:Output: small_val_130
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24456.504616477272
INFO:root:current train perplexity15510.4033203125
INFO:root:current mean train loss 20545.77498822236
INFO:root:current train perplexity3285.683837890625
INFO:root:current mean train loss 17752.343171901128
INFO:root:current train perplexity1095.50634765625
INFO:root:current mean train loss 15857.624586368265
INFO:root:current train perplexity514.6813354492188
INFO:root:current mean train loss 14484.443897560746
INFO:root:current train perplexity299.54302978515625
INFO:root:current mean train loss 13439.809798557491
INFO:root:current train perplexity199.07139587402344
INFO:root:current mean train loss 12628.63960512786
INFO:root:current train perplexity144.5758819580078
INFO:root:current mean train loss 11977.408160958033
INFO:root:current train perplexity112.10962677001953
INFO:root:current mean train loss 11444.510278890608
INFO:root:current train perplexity90.91234588623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.39s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 6413.421518312279
INFO:root:eval perplexity: 13.375164031982422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/1

  0%|          | 1/200 [04:42<15:37:30, 282.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6824.351283482143
INFO:root:current train perplexity14.514778137207031
INFO:root:current mean train loss 6731.451390917056
INFO:root:current train perplexity14.400511741638184
INFO:root:current mean train loss 6703.808320123792
INFO:root:current train perplexity14.167659759521484
INFO:root:current mean train loss 6631.072877964678
INFO:root:current train perplexity13.741968154907227
INFO:root:current mean train loss 6578.123836283016
INFO:root:current train perplexity13.445140838623047
INFO:root:current mean train loss 6528.213047606941
INFO:root:current train perplexity13.175403594970703
INFO:root:current mean train loss 6485.289438967257
INFO:root:current train perplexity12.903581619262695
INFO:root:current mean train loss 6437.911543051627
INFO:root:current train perplexity12.663368225097656
INFO:root:current mean train loss 6393.586166816721
INFO:root:current train perplexity12.436691284179688
INFO:root:current mean train loss 6349.306305772809
INFO:root:current train perplexity12.233607292175293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 5543.260385499779
INFO:root:eval perplexity: 9.407731056213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/2

  1%|          | 2/200 [09:31<15:44:57, 286.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5990.62158203125
INFO:root:current train perplexity10.652318000793457
INFO:root:current mean train loss 5884.517115319293
INFO:root:current train perplexity10.251827239990234
INFO:root:current mean train loss 5862.489539425872
INFO:root:current train perplexity10.111956596374512
INFO:root:current mean train loss 5842.047022259425
INFO:root:current train perplexity9.9979887008667
INFO:root:current mean train loss 5818.12116434488
INFO:root:current train perplexity9.909810066223145
INFO:root:current mean train loss 5792.768439965109
INFO:root:current train perplexity9.823504447937012
INFO:root:current mean train loss 5767.419918699187
INFO:root:current train perplexity9.74110221862793
INFO:root:current mean train loss 5748.7495902534965
INFO:root:current train perplexity9.663702011108398
INFO:root:current mean train loss 5735.576200033551
INFO:root:current train perplexity9.592738151550293
INFO:root:current mean train loss 5716.402096674351
INFO:root:current train perplexity9.507741928100586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 5179.4041375775705
INFO:root:eval perplexity: 8.120558738708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/3

  2%|â–         | 3/200 [14:19<15:42:48, 287.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5566.69191576087
INFO:root:current train perplexity8.827677726745605
INFO:root:current mean train loss 5487.050590701219
INFO:root:current train perplexity8.72310733795166
INFO:root:current mean train loss 5486.463659175309
INFO:root:current train perplexity8.664252281188965
INFO:root:current mean train loss 5458.939672322465
INFO:root:current train perplexity8.581427574157715
INFO:root:current mean train loss 5446.373515532654
INFO:root:current train perplexity8.556482315063477
INFO:root:current mean train loss 5429.788640505497
INFO:root:current train perplexity8.501914978027344
INFO:root:current mean train loss 5419.820821942717
INFO:root:current train perplexity8.468781471252441
INFO:root:current mean train loss 5409.537898864324
INFO:root:current train perplexity8.432368278503418
INFO:root:current mean train loss 5398.6531980938635
INFO:root:current train perplexity8.395819664001465
INFO:root:current mean train loss 5387.816827875305
INFO:root:current train perplexity8.360363960266113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4958.517353030807
INFO:root:eval perplexity: 7.4266791343688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/4

  2%|â–         | 4/200 [19:05<15:36:52, 286.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5319.954133064516
INFO:root:current train perplexity7.967215061187744
INFO:root:current mean train loss 5239.184212488072
INFO:root:current train perplexity7.880289554595947
INFO:root:current mean train loss 5241.839032061688
INFO:root:current train perplexity7.903142929077148
INFO:root:current mean train loss 5231.999837731307
INFO:root:current train perplexity7.859522342681885
INFO:root:current mean train loss 5225.518857172637
INFO:root:current train perplexity7.827626705169678
INFO:root:current mean train loss 5215.627086459805
INFO:root:current train perplexity7.799554824829102
INFO:root:current mean train loss 5207.601576428784
INFO:root:current train perplexity7.773909091949463
INFO:root:current mean train loss 5199.694421436816
INFO:root:current train perplexity7.757957935333252
INFO:root:current mean train loss 5186.459240561071
INFO:root:current train perplexity7.733442783355713
INFO:root:current mean train loss 5178.540307590964
INFO:root:current train perplexity7.704286575317383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.40s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4818.920237006871
INFO:root:eval perplexity: 7.019063949584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/5

  2%|â–Ž         | 5/200 [23:49<15:28:27, 285.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5077.658904246795
INFO:root:current train perplexity7.331205368041992
INFO:root:current mean train loss 5070.327787769784
INFO:root:current train perplexity7.394251346588135
INFO:root:current mean train loss 5076.533705707375
INFO:root:current train perplexity7.400297164916992
INFO:root:current mean train loss 5060.034750069137
INFO:root:current train perplexity7.3399481773376465
INFO:root:current mean train loss 5057.692806582788
INFO:root:current train perplexity7.329746723175049
INFO:root:current mean train loss 5045.225274307166
INFO:root:current train perplexity7.305456161499023
INFO:root:current mean train loss 5037.067947507091
INFO:root:current train perplexity7.284330368041992
INFO:root:current mean train loss 5036.6716503509815
INFO:root:current train perplexity7.278465270996094
INFO:root:current mean train loss 5032.196122616209
INFO:root:current train perplexity7.26042366027832
INFO:root:current mean train loss 5024.11183980631
INFO:root:current train perplexity7.244724750518799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 4701.99372506649
INFO:root:eval perplexity: 6.694914817810059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/6

  3%|â–Ž         | 6/200 [28:41<15:30:07, 287.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4885.828062666224
INFO:root:current train perplexity6.9166975021362305
INFO:root:current mean train loss 4940.540208466199
INFO:root:current train perplexity6.995786666870117
INFO:root:current mean train loss 4921.632253052252
INFO:root:current train perplexity6.976747512817383
INFO:root:current mean train loss 4923.286628129503
INFO:root:current train perplexity6.972968578338623
INFO:root:current mean train loss 4920.094203325993
INFO:root:current train perplexity6.9615092277526855
INFO:root:current mean train loss 4910.498694048503
INFO:root:current train perplexity6.937844276428223
INFO:root:current mean train loss 4910.422413845151
INFO:root:current train perplexity6.935608863830566
INFO:root:current mean train loss 4907.450996041457
INFO:root:current train perplexity6.923862934112549
INFO:root:current mean train loss 4903.902962316448
INFO:root:current train perplexity6.915287494659424
INFO:root:current mean train loss 4901.378865516928
INFO:root:current train perplexity6.903594493865967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 4615.0382815962985
INFO:root:eval perplexity: 6.463596343994141
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/7

  4%|â–Ž         | 7/200 [33:24<15:21:15, 286.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4790.7765625
INFO:root:current train perplexity6.708078384399414
INFO:root:current mean train loss 4838.368526335686
INFO:root:current train perplexity6.757443428039551
INFO:root:current mean train loss 4832.471744791666
INFO:root:current train perplexity6.716643810272217
INFO:root:current mean train loss 4831.830460497359
INFO:root:current train perplexity6.709681987762451
INFO:root:current mean train loss 4826.104531893888
INFO:root:current train perplexity6.692960262298584
INFO:root:current mean train loss 4819.609757706926
INFO:root:current train perplexity6.673919200897217
INFO:root:current mean train loss 4818.610131649571
INFO:root:current train perplexity6.6729607582092285
INFO:root:current mean train loss 4820.395823416805
INFO:root:current train perplexity6.6682891845703125
INFO:root:current mean train loss 4812.046055487025
INFO:root:current train perplexity6.653439044952393
INFO:root:current mean train loss 4803.927153039103
INFO:root:current train perplexity6.643087863922119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.86s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4541.523198553857
INFO:root:eval perplexity: 6.2742791175842285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/8

  4%|â–         | 8/200 [37:32<14:36:45, 273.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4746.267074342758
INFO:root:current train perplexity6.447434425354004
INFO:root:current mean train loss 4733.411821798313
INFO:root:current train perplexity6.464931964874268
INFO:root:current mean train loss 4726.368656056916
INFO:root:current train perplexity6.460956573486328
INFO:root:current mean train loss 4736.6232062725985
INFO:root:current train perplexity6.459858417510986
INFO:root:current mean train loss 4740.887684239167
INFO:root:current train perplexity6.469256401062012
INFO:root:current mean train loss 4733.506893611929
INFO:root:current train perplexity6.457733154296875
INFO:root:current mean train loss 4730.338129610318
INFO:root:current train perplexity6.454069137573242
INFO:root:current mean train loss 4728.805340568172
INFO:root:current train perplexity6.447761058807373
INFO:root:current mean train loss 4723.781115623642
INFO:root:current train perplexity6.438966751098633
INFO:root:current mean train loss 4720.282933125243
INFO:root:current train perplexity6.429773330688477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4484.949353806516
INFO:root:eval perplexity: 6.132373809814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/9

  4%|â–         | 9/200 [42:18<14:43:55, 277.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4640.773788237236
INFO:root:current train perplexity6.210967540740967
INFO:root:current mean train loss 4651.307588633041
INFO:root:current train perplexity6.259942054748535
INFO:root:current mean train loss 4673.648079847498
INFO:root:current train perplexity6.296051502227783
INFO:root:current mean train loss 4667.765848082673
INFO:root:current train perplexity6.283881664276123
INFO:root:current mean train loss 4661.12418360619
INFO:root:current train perplexity6.279733180999756
INFO:root:current mean train loss 4662.563125530183
INFO:root:current train perplexity6.277804374694824
INFO:root:current mean train loss 4663.756731877562
INFO:root:current train perplexity6.282209396362305
INFO:root:current mean train loss 4653.918780968811
INFO:root:current train perplexity6.268108367919922
INFO:root:current mean train loss 4656.260873087238
INFO:root:current train perplexity6.2652058601379395
INFO:root:current mean train loss 4652.114832837844
INFO:root:current train perplexity6.258450508117676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4438.4353875775705
INFO:root:eval perplexity: 6.018108367919922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/10

  5%|â–Œ         | 10/200 [46:26<14:10:28, 268.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4636.915910551819
INFO:root:current train perplexity6.142136573791504
INFO:root:current mean train loss 4599.288626047486
INFO:root:current train perplexity6.10917854309082
INFO:root:current mean train loss 4608.804222845262
INFO:root:current train perplexity6.1217546463012695
INFO:root:current mean train loss 4602.212636177646
INFO:root:current train perplexity6.122474193572998
INFO:root:current mean train loss 4605.680444386906
INFO:root:current train perplexity6.120540618896484
INFO:root:current mean train loss 4599.727860366742
INFO:root:current train perplexity6.121453762054443
INFO:root:current mean train loss 4599.156298900037
INFO:root:current train perplexity6.118598461151123
INFO:root:current mean train loss 4597.084802042382
INFO:root:current train perplexity6.115013122558594
INFO:root:current mean train loss 4592.142690335253
INFO:root:current train perplexity6.112277030944824
INFO:root:current mean train loss 4591.308998739147
INFO:root:current train perplexity6.112093448638916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it]
INFO:root:eval mean loss: 4391.178291916001
INFO:root:eval perplexity: 5.904198169708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/11

  6%|â–Œ         | 11/200 [51:09<14:19:57, 273.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4537.492487764906
INFO:root:current train perplexity5.972553730010986
INFO:root:current mean train loss 4559.956387606534
INFO:root:current train perplexity6.008540630340576
INFO:root:current mean train loss 4545.835053659897
INFO:root:current train perplexity5.979472637176514
INFO:root:current mean train loss 4545.910539178577
INFO:root:current train perplexity5.992180824279785
INFO:root:current mean train loss 4542.739497942602
INFO:root:current train perplexity5.989778518676758
INFO:root:current mean train loss 4539.0600664960875
INFO:root:current train perplexity5.983022689819336
INFO:root:current mean train loss 4538.296947140534
INFO:root:current train perplexity5.983851909637451
INFO:root:current mean train loss 4535.619414546438
INFO:root:current train perplexity5.978062629699707
INFO:root:current mean train loss 4536.725191238902
INFO:root:current train perplexity5.979896545410156
INFO:root:current mean train loss 4536.070736468623
INFO:root:current train perplexity5.979102611541748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4358.073585023271
INFO:root:eval perplexity: 5.825687408447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/12

  6%|â–Œ         | 12/200 [55:18<13:52:43, 265.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4501.947687088816
INFO:root:current train perplexity5.892828464508057
INFO:root:current mean train loss 4483.608330829327
INFO:root:current train perplexity5.879720211029053
INFO:root:current mean train loss 4487.225140691207
INFO:root:current train perplexity5.887282371520996
INFO:root:current mean train loss 4480.958196326147
INFO:root:current train perplexity5.872931003570557
INFO:root:current mean train loss 4487.422610874369
INFO:root:current train perplexity5.875287055969238
INFO:root:current mean train loss 4481.449029592306
INFO:root:current train perplexity5.870285511016846
INFO:root:current mean train loss 4479.493833253709
INFO:root:current train perplexity5.86757230758667
INFO:root:current mean train loss 4483.400847582548
INFO:root:current train perplexity5.861837387084961
INFO:root:current mean train loss 4485.058777878405
INFO:root:current train perplexity5.86420202255249


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it]
INFO:root:eval mean loss: 4321.795929604388
INFO:root:eval perplexity: 5.740850925445557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/13

  6%|â–‹         | 13/200 [59:24<13:29:20, 259.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4704.91015625
INFO:root:current train perplexity6.035126686096191
INFO:root:current mean train loss 4462.496691064927
INFO:root:current train perplexity5.7712483406066895
INFO:root:current mean train loss 4458.4164028825435
INFO:root:current train perplexity5.766435146331787
INFO:root:current mean train loss 4457.066299891708
INFO:root:current train perplexity5.773448944091797
INFO:root:current mean train loss 4458.211676585763
INFO:root:current train perplexity5.776669502258301
INFO:root:current mean train loss 4453.791338880777
INFO:root:current train perplexity5.777560710906982
INFO:root:current mean train loss 4449.154877873005
INFO:root:current train perplexity5.776743412017822
INFO:root:current mean train loss 4445.7591946901675
INFO:root:current train perplexity5.770312786102295
INFO:root:current mean train loss 4444.1133274634185
INFO:root:current train perplexity5.7672905921936035
INFO:root:current mean train loss 4444.037108563902
INFO:root:current train perplexity5.7659101486206055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4297.6229914671985
INFO:root:eval perplexity: 5.685008525848389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/14

  7%|â–‹         | 14/200 [1:03:30<13:12:32, 255.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4378.383167613636
INFO:root:current train perplexity5.567871570587158
INFO:root:current mean train loss 4392.180545291385
INFO:root:current train perplexity5.677176475524902
INFO:root:current mean train loss 4385.062170236597
INFO:root:current train perplexity5.677134037017822
INFO:root:current mean train loss 4388.930708023513
INFO:root:current train perplexity5.673669815063477
INFO:root:current mean train loss 4386.660419993157
INFO:root:current train perplexity5.669035911560059
INFO:root:current mean train loss 4389.701393082651
INFO:root:current train perplexity5.672464847564697
INFO:root:current mean train loss 4397.521684562321
INFO:root:current train perplexity5.678391933441162
INFO:root:current mean train loss 4398.548347398031
INFO:root:current train perplexity5.6747965812683105
INFO:root:current mean train loss 4400.272049420565
INFO:root:current train perplexity5.67753791809082
INFO:root:current mean train loss 4402.7404176814625
INFO:root:current train perplexity5.674314975738525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4270.402999986148
INFO:root:eval perplexity: 5.622776508331299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/15

  8%|â–Š         | 15/200 [1:07:38<13:01:23, 253.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4419.222373560855
INFO:root:current train perplexity5.658977508544922
INFO:root:current mean train loss 4363.817764410452
INFO:root:current train perplexity5.574059009552002
INFO:root:current mean train loss 4362.499421420162
INFO:root:current train perplexity5.590375900268555
INFO:root:current mean train loss 4360.922781917368
INFO:root:current train perplexity5.590950012207031
INFO:root:current mean train loss 4365.564773595987
INFO:root:current train perplexity5.595933437347412
INFO:root:current mean train loss 4363.236983400319
INFO:root:current train perplexity5.591595649719238
INFO:root:current mean train loss 4361.823118342337
INFO:root:current train perplexity5.590612888336182
INFO:root:current mean train loss 4364.214247829559
INFO:root:current train perplexity5.592491149902344
INFO:root:current mean train loss 4364.186274527339
INFO:root:current train perplexity5.593822479248047
INFO:root:current mean train loss 4364.577268781029
INFO:root:current train perplexity5.5920186042785645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4249.20080652981
INFO:root:eval perplexity: 5.574775695800781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/16

  8%|â–Š         | 16/200 [1:11:43<12:49:24, 250.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4360.557644314236
INFO:root:current train perplexity5.593189716339111
INFO:root:current mean train loss 4310.738292784203
INFO:root:current train perplexity5.524986267089844
INFO:root:current mean train loss 4323.5337484082465
INFO:root:current train perplexity5.521686553955078
INFO:root:current mean train loss 4321.530846831995
INFO:root:current train perplexity5.513847827911377
INFO:root:current mean train loss 4328.09187863638
INFO:root:current train perplexity5.5171308517456055
INFO:root:current mean train loss 4327.345328343661
INFO:root:current train perplexity5.510456085205078
INFO:root:current mean train loss 4327.5794558973785
INFO:root:current train perplexity5.508294105529785
INFO:root:current mean train loss 4326.687702834852
INFO:root:current train perplexity5.513618469238281
INFO:root:current mean train loss 4327.14948520868
INFO:root:current train perplexity5.511052131652832
INFO:root:current mean train loss 4329.413485464283
INFO:root:current train perplexity5.516286373138428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.49s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it]
INFO:root:eval mean loss: 4225.516298551086
INFO:root:eval perplexity: 5.521639347076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/17

  8%|â–Š         | 17/200 [1:15:49<12:40:31, 249.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4263.252022879465
INFO:root:current train perplexity5.424173355102539
INFO:root:current mean train loss 4298.455680338541
INFO:root:current train perplexity5.4455366134643555
INFO:root:current mean train loss 4292.087807513298
INFO:root:current train perplexity5.446494102478027
INFO:root:current mean train loss 4295.493430795243
INFO:root:current train perplexity5.446339130401611
INFO:root:current mean train loss 4296.496457996587
INFO:root:current train perplexity5.452578067779541
INFO:root:current mean train loss 4307.108101818049
INFO:root:current train perplexity5.454444408416748
INFO:root:current mean train loss 4301.916006013164
INFO:root:current train perplexity5.446646690368652
INFO:root:current mean train loss 4300.0825534119895
INFO:root:current train perplexity5.442171096801758
INFO:root:current mean train loss 4300.61015332616
INFO:root:current train perplexity5.4486846923828125
INFO:root:current mean train loss 4299.706255744485
INFO:root:current train perplexity5.4512529373168945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 4209.272015943595
INFO:root:eval perplexity: 5.48548698425293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/18

  9%|â–‰         | 18/200 [1:19:55<12:33:17, 248.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4271.008050962936
INFO:root:current train perplexity5.410614967346191
INFO:root:current mean train loss 4282.354270241477
INFO:root:current train perplexity5.406573295593262
INFO:root:current mean train loss 4274.694613233025
INFO:root:current train perplexity5.394947528839111
INFO:root:current mean train loss 4280.040797820244
INFO:root:current train perplexity5.406567573547363
INFO:root:current mean train loss 4280.9319900271585
INFO:root:current train perplexity5.402824401855469
INFO:root:current mean train loss 4281.021023070614
INFO:root:current train perplexity5.400018692016602
INFO:root:current mean train loss 4277.588880856338
INFO:root:current train perplexity5.395359039306641
INFO:root:current mean train loss 4274.430633503848
INFO:root:current train perplexity5.391247272491455
INFO:root:current mean train loss 4270.741296951457
INFO:root:current train perplexity5.388473033905029
INFO:root:current mean train loss 4269.815040046312
INFO:root:current train perplexity5.385717868804932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it]
INFO:root:eval mean loss: 4192.227613516733
INFO:root:eval perplexity: 5.44780969619751
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/19

 10%|â–‰         | 19/200 [1:24:38<13:00:41, 258.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4212.455403645833
INFO:root:current train perplexity5.249670505523682
INFO:root:current mean train loss 4209.89125879553
INFO:root:current train perplexity5.259561061859131
INFO:root:current mean train loss 4240.404126657433
INFO:root:current train perplexity5.290388107299805
INFO:root:current mean train loss 4233.013088302395
INFO:root:current train perplexity5.302666187286377
INFO:root:current mean train loss 4239.161489550132
INFO:root:current train perplexity5.307387351989746
INFO:root:current mean train loss 4237.891413250765
INFO:root:current train perplexity5.313381671905518
INFO:root:current mean train loss 4244.665475215414
INFO:root:current train perplexity5.324579238891602
INFO:root:current mean train loss 4246.186857952418
INFO:root:current train perplexity5.32649040222168
INFO:root:current mean train loss 4246.687141104675
INFO:root:current train perplexity5.330807685852051
INFO:root:current mean train loss 4248.944265852967
INFO:root:current train perplexity5.333850383758545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it]
INFO:root:eval mean loss: 4177.870776886635
INFO:root:eval perplexity: 5.416274070739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/20

 10%|â–ˆ         | 20/200 [1:29:18<13:15:23, 265.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.700340141684
INFO:root:current train perplexity5.284562110900879
INFO:root:current mean train loss 4236.069011952142
INFO:root:current train perplexity5.270050048828125
INFO:root:current mean train loss 4228.550038459218
INFO:root:current train perplexity5.271419048309326
INFO:root:current mean train loss 4227.404706269585
INFO:root:current train perplexity5.2824835777282715
INFO:root:current mean train loss 4223.224949788943
INFO:root:current train perplexity5.277323246002197
INFO:root:current mean train loss 4220.531066130227
INFO:root:current train perplexity5.2752685546875
INFO:root:current mean train loss 4222.286679628224
INFO:root:current train perplexity5.275889873504639
INFO:root:current mean train loss 4225.838724048398
INFO:root:current train perplexity5.284883975982666
INFO:root:current mean train loss 4223.829598085983
INFO:root:current train perplexity5.2837233543396
INFO:root:current mean train loss 4220.748189693447
INFO:root:current train perplexity5.279080390930176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4169.274273811503
INFO:root:eval perplexity: 5.397479057312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/21

 10%|â–ˆ         | 21/200 [1:34:01<13:27:10, 270.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4164.1373163479475
INFO:root:current train perplexity5.205516815185547
INFO:root:current mean train loss 4183.332151127433
INFO:root:current train perplexity5.23724365234375
INFO:root:current mean train loss 4187.052092477177
INFO:root:current train perplexity5.223677158355713
INFO:root:current mean train loss 4183.851703529462
INFO:root:current train perplexity5.213071823120117
INFO:root:current mean train loss 4189.250664982602
INFO:root:current train perplexity5.22005033493042
INFO:root:current mean train loss 4189.661155633405
INFO:root:current train perplexity5.216780185699463
INFO:root:current mean train loss 4191.880124390929
INFO:root:current train perplexity5.218750476837158
INFO:root:current mean train loss 4193.502074717853
INFO:root:current train perplexity5.22027587890625
INFO:root:current mean train loss 4194.869997510723
INFO:root:current train perplexity5.220973491668701
INFO:root:current mean train loss 4193.585249513234
INFO:root:current train perplexity5.223714351654053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4147.829118877438
INFO:root:eval perplexity: 5.3508758544921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/22

 11%|â–ˆ         | 22/200 [1:38:08<13:01:00, 263.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.074404296875
INFO:root:current train perplexity5.171098232269287
INFO:root:current mean train loss 4170.49826032366
INFO:root:current train perplexity5.177918910980225
INFO:root:current mean train loss 4163.049855291193
INFO:root:current train perplexity5.158409595489502
INFO:root:current mean train loss 4163.396958333334
INFO:root:current train perplexity5.165791034698486
INFO:root:current mean train loss 4164.450578741777
INFO:root:current train perplexity5.169146537780762
INFO:root:current mean train loss 4170.009301970109
INFO:root:current train perplexity5.1756134033203125
INFO:root:current mean train loss 4168.283776765046
INFO:root:current train perplexity5.178430557250977
INFO:root:current mean train loss 4172.556497605847
INFO:root:current train perplexity5.180980205535889
INFO:root:current mean train loss 4172.566868861607
INFO:root:current train perplexity5.1803812980651855
INFO:root:current mean train loss 4173.980619741586
INFO:root:current train perplexity5.180662155151367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 4137.726356452238
INFO:root:eval perplexity: 5.3290605545043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/23

 12%|â–ˆâ–        | 23/200 [1:42:41<13:05:37, 266.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4156.587031720633
INFO:root:current train perplexity5.103262424468994
INFO:root:current mean train loss 4151.0216564741295
INFO:root:current train perplexity5.119438648223877
INFO:root:current mean train loss 4150.9367986348825
INFO:root:current train perplexity5.121291637420654
INFO:root:current mean train loss 4155.659597850033
INFO:root:current train perplexity5.128840923309326
INFO:root:current mean train loss 4157.282326139525
INFO:root:current train perplexity5.133912086486816
INFO:root:current mean train loss 4150.909381532751
INFO:root:current train perplexity5.127963066101074
INFO:root:current mean train loss 4145.615995750595
INFO:root:current train perplexity5.121660232543945
INFO:root:current mean train loss 4150.599686078185
INFO:root:current train perplexity5.132081985473633
INFO:root:current mean train loss 4150.035873188438
INFO:root:current train perplexity5.135411739349365
INFO:root:current mean train loss 4150.421044971547
INFO:root:current train perplexity5.135810375213623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]
INFO:root:eval mean loss: 4128.704634862589
INFO:root:eval perplexity: 5.309656143188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/24

 12%|â–ˆâ–        | 24/200 [1:47:31<13:21:46, 273.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4102.2654211023355
INFO:root:current train perplexity5.065553665161133
INFO:root:current mean train loss 4113.9537538857985
INFO:root:current train perplexity5.0816264152526855
INFO:root:current mean train loss 4109.8395685674395
INFO:root:current train perplexity5.0676960945129395
INFO:root:current mean train loss 4119.595156774497
INFO:root:current train perplexity5.085139274597168
INFO:root:current mean train loss 4120.3361662264515
INFO:root:current train perplexity5.08917236328125
INFO:root:current mean train loss 4125.858177843433
INFO:root:current train perplexity5.09224271774292
INFO:root:current mean train loss 4128.509603806757
INFO:root:current train perplexity5.095760822296143
INFO:root:current mean train loss 4131.722863661505
INFO:root:current train perplexity5.095137119293213
INFO:root:current mean train loss 4130.412633551224
INFO:root:current train perplexity5.097519874572754
INFO:root:current mean train loss 4129.480023088658
INFO:root:current train perplexity5.093204975128174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it]
INFO:root:eval mean loss: 4116.035438483488
INFO:root:eval perplexity: 5.282522201538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/25

 12%|â–ˆâ–Ž        | 25/200 [1:52:19<13:30:09, 277.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4080.4410881273675
INFO:root:current train perplexity5.062607288360596
INFO:root:current mean train loss 4089.203278354664
INFO:root:current train perplexity5.030820846557617
INFO:root:current mean train loss 4103.300824525763
INFO:root:current train perplexity5.042540073394775
INFO:root:current mean train loss 4109.816199434133
INFO:root:current train perplexity5.052746772766113
INFO:root:current mean train loss 4109.284598004603
INFO:root:current train perplexity5.049691677093506
INFO:root:current mean train loss 4108.1195918164385
INFO:root:current train perplexity5.04528284072876
INFO:root:current mean train loss 4108.545373133495
INFO:root:current train perplexity5.04689884185791
INFO:root:current mean train loss 4111.9631864048815
INFO:root:current train perplexity5.0504350662231445
INFO:root:current mean train loss 4111.9543155589545
INFO:root:current train perplexity5.055024147033691


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4110.693250290891
INFO:root:eval perplexity: 5.271124362945557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/26

 13%|â–ˆâ–Ž        | 26/200 [1:57:04<13:32:00, 280.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4138.722133091518
INFO:root:current train perplexity5.098102569580078
INFO:root:current mean train loss 4077.8371467946845
INFO:root:current train perplexity5.016151428222656
INFO:root:current mean train loss 4087.3931395304953
INFO:root:current train perplexity5.0246357917785645
INFO:root:current mean train loss 4089.313641973738
INFO:root:current train perplexity5.020779132843018
INFO:root:current mean train loss 4096.587142606918
INFO:root:current train perplexity5.032413005828857
INFO:root:current mean train loss 4087.7099652713573
INFO:root:current train perplexity5.020442485809326
INFO:root:current mean train loss 4090.658278740218
INFO:root:current train perplexity5.014484882354736
INFO:root:current mean train loss 4092.0446549433123
INFO:root:current train perplexity5.0183539390563965
INFO:root:current mean train loss 4089.7704013224134
INFO:root:current train perplexity5.015011310577393
INFO:root:current mean train loss 4087.9008385301818
INFO:root:current train perplexity5.012473106384277


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]
INFO:root:eval mean loss: 4095.7056287400264
INFO:root:eval perplexity: 5.239274978637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/27

 14%|â–ˆâ–Ž        | 27/200 [2:01:50<13:32:26, 281.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4088.9892415364584
INFO:root:current train perplexity4.9276018142700195
INFO:root:current mean train loss 4042.996932319973
INFO:root:current train perplexity4.94580078125
INFO:root:current mean train loss 4045.2839275981105
INFO:root:current train perplexity4.951429843902588
INFO:root:current mean train loss 4059.7936972966268
INFO:root:current train perplexity4.967684745788574
INFO:root:current mean train loss 4071.1585755129895
INFO:root:current train perplexity4.983058929443359
INFO:root:current mean train loss 4066.4246472997575
INFO:root:current train perplexity4.973851680755615
INFO:root:current mean train loss 4069.7887318184708
INFO:root:current train perplexity4.976040840148926
INFO:root:current mean train loss 4070.9380873033215
INFO:root:current train perplexity4.975363731384277
INFO:root:current mean train loss 4074.261633076112
INFO:root:current train perplexity4.978894233703613
INFO:root:current mean train loss 4071.114519296448
INFO:root:current train perplexity4.9774489402771


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4090.8917643229165
INFO:root:eval perplexity: 5.229085445404053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/28

 14%|â–ˆâ–        | 28/200 [2:06:40<13:34:37, 284.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4085.42919921875
INFO:root:current train perplexity4.960743427276611
INFO:root:current mean train loss 4053.62682609248
INFO:root:current train perplexity4.928163528442383
INFO:root:current mean train loss 4061.793575269759
INFO:root:current train perplexity4.951765537261963
INFO:root:current mean train loss 4051.8958774247776
INFO:root:current train perplexity4.9419145584106445
INFO:root:current mean train loss 4063.260806829935
INFO:root:current train perplexity4.950360298156738
INFO:root:current mean train loss 4064.214991728161
INFO:root:current train perplexity4.9499406814575195
INFO:root:current mean train loss 4056.2260538410414
INFO:root:current train perplexity4.943994045257568
INFO:root:current mean train loss 4053.3237422874527
INFO:root:current train perplexity4.942967891693115
INFO:root:current mean train loss 4056.561677397384
INFO:root:current train perplexity4.945085525512695
INFO:root:current mean train loss 4054.587132810384
INFO:root:current train perplexity4.9444403648376465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4085.5112322002437
INFO:root:eval perplexity: 5.217722415924072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/29

 14%|â–ˆâ–        | 29/200 [2:10:55<13:05:31, 275.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4059.1192508820563
INFO:root:current train perplexity4.904839515686035
INFO:root:current mean train loss 4040.065565735329
INFO:root:current train perplexity4.899974822998047
INFO:root:current mean train loss 4055.6319659344563
INFO:root:current train perplexity4.91459321975708
INFO:root:current mean train loss 4057.737117340918
INFO:root:current train perplexity4.914592742919922
INFO:root:current mean train loss 4053.900504481765
INFO:root:current train perplexity4.908540725708008
INFO:root:current mean train loss 4050.1195006289727
INFO:root:current train perplexity4.91052770614624
INFO:root:current mean train loss 4044.8680777814234
INFO:root:current train perplexity4.907168865203857
INFO:root:current mean train loss 4045.2805656714904
INFO:root:current train perplexity4.911393642425537
INFO:root:current mean train loss 4042.4851943841195
INFO:root:current train perplexity4.908779621124268
INFO:root:current mean train loss 4037.813069311812
INFO:root:current train perplexity4.91166877746582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4073.47895369293
INFO:root:eval perplexity: 5.1923956871032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/30

 15%|â–ˆâ–Œ        | 30/200 [2:15:07<12:40:17, 268.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4017.6046674679487
INFO:root:current train perplexity4.898929119110107
INFO:root:current mean train loss 4013.4597132840604
INFO:root:current train perplexity4.885628700256348
INFO:root:current mean train loss 4017.7052170502093
INFO:root:current train perplexity4.870606899261475
INFO:root:current mean train loss 4014.8824869791665
INFO:root:current train perplexity4.869484901428223
INFO:root:current mean train loss 4021.7387806538295
INFO:root:current train perplexity4.873421669006348
INFO:root:current mean train loss 4019.512186648452
INFO:root:current train perplexity4.875011920928955
INFO:root:current mean train loss 4018.997995678061
INFO:root:current train perplexity4.876770973205566
INFO:root:current mean train loss 4023.4350381110453
INFO:root:current train perplexity4.880262851715088
INFO:root:current mean train loss 4023.0556806489312
INFO:root:current train perplexity4.883087158203125
INFO:root:current mean train loss 4022.1605522310138
INFO:root:current train perplexity4.882766246795654


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4068.015152302194
INFO:root:eval perplexity: 5.180936813354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/31

 16%|â–ˆâ–Œ        | 31/200 [2:19:56<12:53:10, 274.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3995.1075621259974
INFO:root:current train perplexity4.827685356140137
INFO:root:current mean train loss 3993.3370967527635
INFO:root:current train perplexity4.8232526779174805
INFO:root:current mean train loss 3984.893467706225
INFO:root:current train perplexity4.808860778808594
INFO:root:current mean train loss 3996.7064022536924
INFO:root:current train perplexity4.824134826660156
INFO:root:current mean train loss 4001.0002468715043
INFO:root:current train perplexity4.8322434425354
INFO:root:current mean train loss 4002.3791744922587
INFO:root:current train perplexity4.841301441192627
INFO:root:current mean train loss 4006.7391630995216
INFO:root:current train perplexity4.8476996421813965
INFO:root:current mean train loss 4002.161119085718
INFO:root:current train perplexity4.847775936126709
INFO:root:current mean train loss 4004.3585267050066
INFO:root:current train perplexity4.85109806060791
INFO:root:current mean train loss 4004.3821948010163
INFO:root:current train perplexity4.850192070007324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 4060.526310048205
INFO:root:eval perplexity: 5.165271759033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/32

 16%|â–ˆâ–Œ        | 32/200 [2:24:43<12:59:01, 278.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.6548783735793
INFO:root:current train perplexity4.747931003570557
INFO:root:current mean train loss 4003.839593308972
INFO:root:current train perplexity4.812814235687256
INFO:root:current mean train loss 3982.65599341299
INFO:root:current train perplexity4.800782680511475
INFO:root:current mean train loss 3975.4308167363556
INFO:root:current train perplexity4.805843353271484
INFO:root:current mean train loss 3985.173825442136
INFO:root:current train perplexity4.817600727081299
INFO:root:current mean train loss 3986.789527906813
INFO:root:current train perplexity4.819089412689209
INFO:root:current mean train loss 3990.8757234762643
INFO:root:current train perplexity4.820850849151611
INFO:root:current mean train loss 3992.3385179532283
INFO:root:current train perplexity4.820859909057617
INFO:root:current mean train loss 3993.1531872487208
INFO:root:current train perplexity4.821722030639648
INFO:root:current mean train loss 3991.955911015216
INFO:root:current train perplexity4.824333667755127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4056.229080091977
INFO:root:eval perplexity: 5.156303882598877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/33

 16%|â–ˆâ–‹        | 33/200 [2:29:27<12:59:07, 279.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3921.1151103670636
INFO:root:current train perplexity4.740232944488525
INFO:root:current mean train loss 3948.6032505152416
INFO:root:current train perplexity4.778262615203857
INFO:root:current mean train loss 3948.4115264080324
INFO:root:current train perplexity4.778922080993652
INFO:root:current mean train loss 3958.7213548392306
INFO:root:current train perplexity4.781093120574951
INFO:root:current mean train loss 3968.675829761744
INFO:root:current train perplexity4.784553527832031
INFO:root:current mean train loss 3965.623627955706
INFO:root:current train perplexity4.779098987579346
INFO:root:current mean train loss 3968.5073669341537
INFO:root:current train perplexity4.785802364349365
INFO:root:current mean train loss 3966.8883966968383
INFO:root:current train perplexity4.782383441925049
INFO:root:current mean train loss 3969.103309958448
INFO:root:current train perplexity4.784369468688965
INFO:root:current mean train loss 3976.0794445762754
INFO:root:current train perplexity4.794399261474609


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4048.576426404588
INFO:root:eval perplexity: 5.1403727531433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/34

 17%|â–ˆâ–‹        | 34/200 [2:34:17<13:03:07, 283.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3998.2222401793574
INFO:root:current train perplexity4.785482883453369
INFO:root:current mean train loss 3959.198549147935
INFO:root:current train perplexity4.756343841552734
INFO:root:current mean train loss 3953.3391599760726
INFO:root:current train perplexity4.755795955657959
INFO:root:current mean train loss 3955.0432740902966
INFO:root:current train perplexity4.750200271606445
INFO:root:current mean train loss 3953.66083217224
INFO:root:current train perplexity4.748531818389893
INFO:root:current mean train loss 3957.41877856146
INFO:root:current train perplexity4.757656574249268
INFO:root:current mean train loss 3959.5696259227134
INFO:root:current train perplexity4.761135578155518
INFO:root:current mean train loss 3958.268731380715
INFO:root:current train perplexity4.760287284851074
INFO:root:current mean train loss 3961.823614144572
INFO:root:current train perplexity4.7641282081604
INFO:root:current mean train loss 3960.324587098111
INFO:root:current train perplexity4.765203952789307


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it]
INFO:root:eval mean loss: 4046.3392671625666
INFO:root:eval perplexity: 5.1357245445251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/35

 18%|â–ˆâ–Š        | 35/200 [2:38:31<12:34:52, 274.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3975.8284680330303
INFO:root:current train perplexity4.770950794219971
INFO:root:current mean train loss 3951.1586695836245
INFO:root:current train perplexity4.73186731338501
INFO:root:current mean train loss 3953.7309946586583
INFO:root:current train perplexity4.741847038269043
INFO:root:current mean train loss 3950.0157042329733
INFO:root:current train perplexity4.73579740524292
INFO:root:current mean train loss 3947.8768379354774
INFO:root:current train perplexity4.737809658050537
INFO:root:current mean train loss 3950.3711810334357
INFO:root:current train perplexity4.735551834106445
INFO:root:current mean train loss 3950.6975417663843
INFO:root:current train perplexity4.738805294036865
INFO:root:current mean train loss 3948.339337604802
INFO:root:current train perplexity4.73847770690918
INFO:root:current mean train loss 3946.6417715443686
INFO:root:current train perplexity4.737299919128418
INFO:root:current mean train loss 3946.712661447028
INFO:root:current train perplexity4.7397685050964355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 4040.121623587101
INFO:root:eval perplexity: 5.122828483581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/36

 18%|â–ˆâ–Š        | 36/200 [2:43:20<12:41:28, 278.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.56298828125
INFO:root:current train perplexity4.690184116363525
INFO:root:current mean train loss 3906.1111949573865
INFO:root:current train perplexity4.680898189544678
INFO:root:current mean train loss 3918.10884418554
INFO:root:current train perplexity4.690659523010254
INFO:root:current mean train loss 3924.2628460866845
INFO:root:current train perplexity4.701327800750732
INFO:root:current mean train loss 3920.184046939168
INFO:root:current train perplexity4.703762054443359
INFO:root:current mean train loss 3921.695727164741
INFO:root:current train perplexity4.706991672515869
INFO:root:current mean train loss 3926.6416356782206
INFO:root:current train perplexity4.709301948547363
INFO:root:current mean train loss 3929.9651254268583
INFO:root:current train perplexity4.712352275848389
INFO:root:current mean train loss 3931.353984639233
INFO:root:current train perplexity4.710912227630615
INFO:root:current mean train loss 3933.5688461721124
INFO:root:current train perplexity4.715421676635742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it]
INFO:root:eval mean loss: 4036.075105274823
INFO:root:eval perplexity: 5.114452838897705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/37

 18%|â–ˆâ–Š        | 37/200 [2:48:10<12:46:11, 282.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3892.847527754934
INFO:root:current train perplexity4.644445419311523
INFO:root:current mean train loss 3892.805651542468
INFO:root:current train perplexity4.650361061096191
INFO:root:current mean train loss 3902.721493478549
INFO:root:current train perplexity4.667900562286377
INFO:root:current mean train loss 3897.0221265575556
INFO:root:current train perplexity4.671067237854004
INFO:root:current mean train loss 3904.2294566761366
INFO:root:current train perplexity4.677515506744385
INFO:root:current mean train loss 3908.701930557379
INFO:root:current train perplexity4.681231498718262
INFO:root:current mean train loss 3909.9040439523383
INFO:root:current train perplexity4.682186603546143
INFO:root:current mean train loss 3916.0468108171185
INFO:root:current train perplexity4.688183784484863
INFO:root:current mean train loss 3921.8737105556042
INFO:root:current train perplexity4.6927995681762695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4031.5290406139184
INFO:root:eval perplexity: 5.105059623718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/38

 19%|â–ˆâ–‰        | 38/200 [2:52:59<12:47:50, 284.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3832.5662434895835
INFO:root:current train perplexity4.493240833282471
INFO:root:current mean train loss 3909.0925695919295
INFO:root:current train perplexity4.6544575691223145
INFO:root:current mean train loss 3901.0157633062654
INFO:root:current train perplexity4.650028228759766
INFO:root:current mean train loss 3903.7405743992367
INFO:root:current train perplexity4.650504112243652
INFO:root:current mean train loss 3898.2596402227437
INFO:root:current train perplexity4.645268440246582
INFO:root:current mean train loss 3901.188609068247
INFO:root:current train perplexity4.646152019500732
INFO:root:current mean train loss 3906.841646260883
INFO:root:current train perplexity4.655813217163086
INFO:root:current mean train loss 3904.3408439278096
INFO:root:current train perplexity4.659459114074707
INFO:root:current mean train loss 3907.0214497149364
INFO:root:current train perplexity4.661808967590332
INFO:root:current mean train loss 3908.6656511714423
INFO:root:current train perplexity4.664209365844727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it]
INFO:root:eval mean loss: 4028.468034893063
INFO:root:eval perplexity: 5.098743915557861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/39

 20%|â–ˆâ–‰        | 39/200 [2:57:52<12:49:51, 286.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.220525568182
INFO:root:current train perplexity4.570112228393555
INFO:root:current mean train loss 3871.6320470861488
INFO:root:current train perplexity4.604791641235352
INFO:root:current mean train loss 3883.2419722859895
INFO:root:current train perplexity4.615355491638184
INFO:root:current mean train loss 3884.755615234375
INFO:root:current train perplexity4.632143020629883
INFO:root:current mean train loss 3887.54333763401
INFO:root:current train perplexity4.63913106918335
INFO:root:current mean train loss 3891.8414223030823
INFO:root:current train perplexity4.6408209800720215
INFO:root:current mean train loss 3890.37427157388
INFO:root:current train perplexity4.637080669403076
INFO:root:current mean train loss 3892.5440847233212
INFO:root:current train perplexity4.6419219970703125
INFO:root:current mean train loss 3893.9428054677865
INFO:root:current train perplexity4.642465114593506
INFO:root:current mean train loss 3895.0520022211167
INFO:root:current train perplexity4.644092559814453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.28s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4024.557743586547
INFO:root:eval perplexity: 5.090688705444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/40

 20%|â–ˆâ–ˆ        | 40/200 [3:02:01<12:14:38, 275.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3883.3199270148025
INFO:root:current train perplexity4.622464656829834
INFO:root:current mean train loss 3872.657322987789
INFO:root:current train perplexity4.611635684967041
INFO:root:current mean train loss 3872.9823795127
INFO:root:current train perplexity4.613022327423096
INFO:root:current mean train loss 3881.618408203125
INFO:root:current train perplexity4.614363193511963
INFO:root:current mean train loss 3882.2046720008575
INFO:root:current train perplexity4.6168670654296875
INFO:root:current mean train loss 3885.998395445719
INFO:root:current train perplexity4.620894432067871
INFO:root:current mean train loss 3885.5457927352586
INFO:root:current train perplexity4.621075630187988
INFO:root:current mean train loss 3890.471364919267
INFO:root:current train perplexity4.628756523132324
INFO:root:current mean train loss 3886.6704939212264
INFO:root:current train perplexity4.624340057373047
INFO:root:current mean train loss 3883.6368871778086
INFO:root:current train perplexity4.623744010925293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4023.354383103391
INFO:root:eval perplexity: 5.088212490081787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/41

 20%|â–ˆâ–ˆ        | 41/200 [3:06:50<12:20:50, 279.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3825.3918095341437
INFO:root:current train perplexity4.576939105987549
INFO:root:current mean train loss 3847.4468888410433
INFO:root:current train perplexity4.566296100616455
INFO:root:current mean train loss 3854.2443062534417
INFO:root:current train perplexity4.580864906311035
INFO:root:current mean train loss 3856.412624534117
INFO:root:current train perplexity4.576906681060791
INFO:root:current mean train loss 3858.1385134980605
INFO:root:current train perplexity4.584125995635986
INFO:root:current mean train loss 3859.0694216415145
INFO:root:current train perplexity4.580777645111084
INFO:root:current mean train loss 3861.652193060332
INFO:root:current train perplexity4.5806965827941895
INFO:root:current mean train loss 3866.640766715741
INFO:root:current train perplexity4.588931083679199
INFO:root:current mean train loss 3871.7069093272935
INFO:root:current train perplexity4.596654891967773
INFO:root:current mean train loss 3871.956471596464
INFO:root:current train perplexity4.598505020141602


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it]
INFO:root:eval mean loss: 4016.272147537123
INFO:root:eval perplexity: 5.073660373687744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/42

 21%|â–ˆâ–ˆ        | 42/200 [3:10:57<11:50:04, 269.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3799.3686941964284
INFO:root:current train perplexity4.545749187469482
INFO:root:current mean train loss 3822.701710792824
INFO:root:current train perplexity4.55665397644043
INFO:root:current mean train loss 3839.7489392869015
INFO:root:current train perplexity4.558730602264404
INFO:root:current mean train loss 3851.9510013409513
INFO:root:current train perplexity4.5722808837890625
INFO:root:current mean train loss 3855.653717111171
INFO:root:current train perplexity4.5736823081970215
INFO:root:current mean train loss 3857.981243154936
INFO:root:current train perplexity4.575795650482178
INFO:root:current mean train loss 3858.1878052719
INFO:root:current train perplexity4.57913064956665
INFO:root:current mean train loss 3862.4961814413264
INFO:root:current train perplexity4.581027984619141
INFO:root:current mean train loss 3859.6377263052022
INFO:root:current train perplexity4.5786261558532715
INFO:root:current mean train loss 3859.6486523959725
INFO:root:current train perplexity4.5791802406311035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4012.0906904504654
INFO:root:eval perplexity: 5.065088272094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:15:48<12:02:56, 276.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.4026560228926
INFO:root:current train perplexity4.562700271606445
INFO:root:current mean train loss 3864.9676027097903
INFO:root:current train perplexity4.5701446533203125
INFO:root:current mean train loss 3855.079389909658
INFO:root:current train perplexity4.550418376922607
INFO:root:current mean train loss 3850.8818893210187
INFO:root:current train perplexity4.5490007400512695
INFO:root:current mean train loss 3850.9972461157945
INFO:root:current train perplexity4.547361373901367
INFO:root:current mean train loss 3850.97415166753
INFO:root:current train perplexity4.551180839538574
INFO:root:current mean train loss 3849.5931838823144
INFO:root:current train perplexity4.551142692565918
INFO:root:current mean train loss 3847.3082914493607
INFO:root:current train perplexity4.55319356918335
INFO:root:current mean train loss 3848.456211655731
INFO:root:current train perplexity4.557672023773193
INFO:root:current mean train loss 3847.7068572706785
INFO:root:current train perplexity4.5577592849731445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.87s/it]
INFO:root:eval mean loss: 4014.3936758920654
INFO:root:eval perplexity: 5.069808006286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/44

 22%|â–ˆâ–ˆâ–       | 44/200 [3:19:55<11:35:05, 267.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3781.3075166590074
INFO:root:current train perplexity4.481975078582764
INFO:root:current mean train loss 3819.9353286035803
INFO:root:current train perplexity4.503439426422119
INFO:root:current mean train loss 3825.993387777017
INFO:root:current train perplexity4.5196003913879395
INFO:root:current mean train loss 3825.1658911202367
INFO:root:current train perplexity4.519151210784912
INFO:root:current mean train loss 3832.411969711405
INFO:root:current train perplexity4.5209736824035645
INFO:root:current mean train loss 3836.1268148820327
INFO:root:current train perplexity4.530759334564209
INFO:root:current mean train loss 3831.8885334911433
INFO:root:current train perplexity4.529297828674316
INFO:root:current mean train loss 3834.5670492728445
INFO:root:current train perplexity4.533119201660156
INFO:root:current mean train loss 3833.1295695321683
INFO:root:current train perplexity4.534112453460693
INFO:root:current mean train loss 3835.7843296119217
INFO:root:current train perplexity4.53591775894165


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4009.380648132757
INFO:root:eval perplexity: 5.059541702270508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:24:33<11:38:46, 270.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3820.3336740267478
INFO:root:current train perplexity4.489015579223633
INFO:root:current mean train loss 3829.6749597705384
INFO:root:current train perplexity4.521232604980469
INFO:root:current mean train loss 3824.932716163429
INFO:root:current train perplexity4.5204644203186035
INFO:root:current mean train loss 3822.227781162953
INFO:root:current train perplexity4.516934394836426
INFO:root:current mean train loss 3822.45512120864
INFO:root:current train perplexity4.518823623657227
INFO:root:current mean train loss 3823.5039210993405
INFO:root:current train perplexity4.518770217895508
INFO:root:current mean train loss 3828.845796113311
INFO:root:current train perplexity4.521998405456543
INFO:root:current mean train loss 3831.8386513530345
INFO:root:current train perplexity4.52066707611084
INFO:root:current mean train loss 3828.9943952815775
INFO:root:current train perplexity4.521719932556152
INFO:root:current mean train loss 3828.589890592414
INFO:root:current train perplexity4.522546768188477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4007.3414990580673
INFO:root:eval perplexity: 5.055370807647705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:29:26<11:51:35, 277.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3829.379135815065
INFO:root:current train perplexity4.499321937561035
INFO:root:current mean train loss 3818.4998464984096
INFO:root:current train perplexity4.478960037231445
INFO:root:current mean train loss 3812.5411216935863
INFO:root:current train perplexity4.48511266708374
INFO:root:current mean train loss 3818.9165471464153
INFO:root:current train perplexity4.495079517364502
INFO:root:current mean train loss 3824.1450190084647
INFO:root:current train perplexity4.499483108520508
INFO:root:current mean train loss 3822.1327987213404
INFO:root:current train perplexity4.499701976776123
INFO:root:current mean train loss 3823.7424587266914
INFO:root:current train perplexity4.506932258605957
INFO:root:current mean train loss 3819.771677904987
INFO:root:current train perplexity4.50374174118042
INFO:root:current mean train loss 3819.161332461523
INFO:root:current train perplexity4.504025936126709
INFO:root:current mean train loss 3818.001205807265
INFO:root:current train perplexity4.503582000732422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it]
INFO:root:eval mean loss: 4008.5976943428636
INFO:root:eval perplexity: 5.057939529418945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:34:14<11:55:39, 280.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3805.2782356770836
INFO:root:current train perplexity4.43440055847168
INFO:root:current mean train loss 3795.227152622768
INFO:root:current train perplexity4.466513633728027
INFO:root:current mean train loss 3795.290223721591
INFO:root:current train perplexity4.464924335479736
INFO:root:current mean train loss 3803.606175130208
INFO:root:current train perplexity4.477088928222656
INFO:root:current mean train loss 3802.941755242599
INFO:root:current train perplexity4.478270053863525
INFO:root:current mean train loss 3804.942109375
INFO:root:current train perplexity4.479976177215576
INFO:root:current mean train loss 3804.4874052372684
INFO:root:current train perplexity4.481997489929199
INFO:root:current mean train loss 3803.8055106476813
INFO:root:current train perplexity4.484350681304932
INFO:root:current mean train loss 3805.3599037388394
INFO:root:current train perplexity4.486559867858887
INFO:root:current mean train loss 3806.357096854968
INFO:root:current train perplexity4.485233306884766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4004.4216066184617
INFO:root:eval perplexity: 5.0494065284729
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:39:02<11:56:10, 282.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.616899237575
INFO:root:current train perplexity4.442262172698975
INFO:root:current mean train loss 3800.4282333290644
INFO:root:current train perplexity4.442101955413818
INFO:root:current mean train loss 3788.4137907533677
INFO:root:current train perplexity4.438652992248535
INFO:root:current mean train loss 3786.962162665225
INFO:root:current train perplexity4.450476169586182
INFO:root:current mean train loss 3788.0742996247413
INFO:root:current train perplexity4.455833435058594
INFO:root:current mean train loss 3792.2419316339247
INFO:root:current train perplexity4.450793743133545
INFO:root:current mean train loss 3793.18213855749
INFO:root:current train perplexity4.454014778137207
INFO:root:current mean train loss 3792.456576331517
INFO:root:current train perplexity4.457854747772217
INFO:root:current mean train loss 3793.335725432209
INFO:root:current train perplexity4.4601569175720215
INFO:root:current mean train loss 3796.3897510113334
INFO:root:current train perplexity4.467646598815918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 4002.149078152704
INFO:root:eval perplexity: 5.044767379760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:43:52<11:57:16, 285.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3784.612996866415
INFO:root:current train perplexity4.398025035858154
INFO:root:current mean train loss 3780.617979998364
INFO:root:current train perplexity4.4162774085998535
INFO:root:current mean train loss 3771.9511584514603
INFO:root:current train perplexity4.424061298370361
INFO:root:current mean train loss 3777.308653068055
INFO:root:current train perplexity4.432276725769043
INFO:root:current mean train loss 3778.0983200539395
INFO:root:current train perplexity4.435462951660156
INFO:root:current mean train loss 3781.145921323102
INFO:root:current train perplexity4.43928337097168
INFO:root:current mean train loss 3779.36737051714
INFO:root:current train perplexity4.437768459320068
INFO:root:current mean train loss 3782.2075473095765
INFO:root:current train perplexity4.44093132019043
INFO:root:current mean train loss 3781.8667441559696
INFO:root:current train perplexity4.4427971839904785
INFO:root:current mean train loss 3786.006668414165
INFO:root:current train perplexity4.448338508605957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4000.3887428662456
INFO:root:eval perplexity: 5.0411787033081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:48:00<11:24:47, 273.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.306403882576
INFO:root:current train perplexity4.389143466949463
INFO:root:current mean train loss 3769.73756477701
INFO:root:current train perplexity4.4058403968811035
INFO:root:current mean train loss 3771.8949893198683
INFO:root:current train perplexity4.413333892822266
INFO:root:current mean train loss 3774.2538205866226
INFO:root:current train perplexity4.416520118713379
INFO:root:current mean train loss 3777.974787954816
INFO:root:current train perplexity4.4275898933410645
INFO:root:current mean train loss 3776.2861629734452
INFO:root:current train perplexity4.431445121765137
INFO:root:current mean train loss 3771.656803944251
INFO:root:current train perplexity4.43086576461792
INFO:root:current mean train loss 3771.5375383780506
INFO:root:current train perplexity4.430658340454102
INFO:root:current mean train loss 3772.938575142085
INFO:root:current train perplexity4.4314494132995605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it]
INFO:root:eval mean loss: 4002.0017747811394
INFO:root:eval perplexity: 5.044467449188232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:52:08<11:00:20, 265.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3705.427315848214
INFO:root:current train perplexity4.370331287384033
INFO:root:current mean train loss 3762.724150755695
INFO:root:current train perplexity4.394710540771484
INFO:root:current mean train loss 3761.411875849185
INFO:root:current train perplexity4.4024529457092285
INFO:root:current mean train loss 3770.425680253715
INFO:root:current train perplexity4.402525901794434
INFO:root:current mean train loss 3771.4057491218136
INFO:root:current train perplexity4.4086174964904785
INFO:root:current mean train loss 3768.6019462871363
INFO:root:current train perplexity4.407717704772949
INFO:root:current mean train loss 3765.6840120469524
INFO:root:current train perplexity4.408792018890381
INFO:root:current mean train loss 3762.837769072666
INFO:root:current train perplexity4.411037921905518
INFO:root:current mean train loss 3766.1767584175573
INFO:root:current train perplexity4.414946556091309
INFO:root:current mean train loss 3766.829081374466
INFO:root:current train perplexity4.414392471313477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 3997.9634585549647
INFO:root:eval perplexity: 5.036236763000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:56:15<10:42:00, 260.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.025602213542
INFO:root:current train perplexity4.482801914215088
INFO:root:current mean train loss 3737.2605298913045
INFO:root:current train perplexity4.374349594116211
INFO:root:current mean train loss 3741.7444188317586
INFO:root:current train perplexity4.380978107452393
INFO:root:current mean train loss 3741.241720920139
INFO:root:current train perplexity4.385308742523193
INFO:root:current mean train loss 3747.3939659026732
INFO:root:current train perplexity4.385693073272705
INFO:root:current mean train loss 3749.399921780188
INFO:root:current train perplexity4.387704849243164
INFO:root:current mean train loss 3747.605124571265
INFO:root:current train perplexity4.3929948806762695
INFO:root:current mean train loss 3752.0226579572773
INFO:root:current train perplexity4.397274971008301
INFO:root:current mean train loss 3757.757017170725
INFO:root:current train perplexity4.399468421936035
INFO:root:current mean train loss 3758.7177045978483
INFO:root:current train perplexity4.400461196899414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.95s/it]
INFO:root:eval mean loss: 3995.146122492797
INFO:root:eval perplexity: 5.030501365661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:00:30<10:34:20, 258.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3745.9772312330165
INFO:root:current train perplexity4.43307638168335
INFO:root:current mean train loss 3753.730635480183
INFO:root:current train perplexity4.399824619293213
INFO:root:current mean train loss 3740.9117667022842
INFO:root:current train perplexity4.38284969329834
INFO:root:current mean train loss 3749.495782338429
INFO:root:current train perplexity4.386412143707275
INFO:root:current mean train loss 3744.2929335429594
INFO:root:current train perplexity4.384159564971924
INFO:root:current mean train loss 3750.9047860898663
INFO:root:current train perplexity4.39127254486084
INFO:root:current mean train loss 3752.2166338533307
INFO:root:current train perplexity4.389135360717773
INFO:root:current mean train loss 3747.4924961369725
INFO:root:current train perplexity4.382680892944336
INFO:root:current mean train loss 3749.6292580735494
INFO:root:current train perplexity4.385287761688232
INFO:root:current mean train loss 3751.688212319288
INFO:root:current train perplexity4.386612892150879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]
INFO:root:eval mean loss: 3997.162715397828
INFO:root:eval perplexity: 5.034605979919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [4:04:48<10:28:59, 258.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3719.3465458039313
INFO:root:current train perplexity4.374446392059326
INFO:root:current mean train loss 3725.4421349445374
INFO:root:current train perplexity4.348103046417236
INFO:root:current mean train loss 3736.6494172331577
INFO:root:current train perplexity4.362213134765625
INFO:root:current mean train loss 3727.1867815922396
INFO:root:current train perplexity4.352574348449707
INFO:root:current mean train loss 3731.832667375109
INFO:root:current train perplexity4.361501216888428
INFO:root:current mean train loss 3735.071237567679
INFO:root:current train perplexity4.368307590484619
INFO:root:current mean train loss 3733.405299360514
INFO:root:current train perplexity4.369704723358154
INFO:root:current mean train loss 3735.047218333191
INFO:root:current train perplexity4.3697404861450195
INFO:root:current mean train loss 3736.146803726215
INFO:root:current train perplexity4.369208335876465
INFO:root:current mean train loss 3738.3265007174746
INFO:root:current train perplexity4.368523597717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 3995.649928316157
INFO:root:eval perplexity: 5.031527042388916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [4:08:56<10:17:10, 255.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.741955879407
INFO:root:current train perplexity4.309490203857422
INFO:root:current mean train loss 3728.5170178310477
INFO:root:current train perplexity4.336647033691406
INFO:root:current mean train loss 3730.995024230191
INFO:root:current train perplexity4.341704368591309
INFO:root:current mean train loss 3725.8990503721884
INFO:root:current train perplexity4.3351216316223145
INFO:root:current mean train loss 3722.950155271213
INFO:root:current train perplexity4.33623743057251
INFO:root:current mean train loss 3719.9369483056007
INFO:root:current train perplexity4.340453147888184
INFO:root:current mean train loss 3721.715814963566
INFO:root:current train perplexity4.343656063079834
INFO:root:current mean train loss 3725.120314416124
INFO:root:current train perplexity4.350036144256592
INFO:root:current mean train loss 3727.5565821360065
INFO:root:current train perplexity4.351693630218506
INFO:root:current mean train loss 3731.3583440973607
INFO:root:current train perplexity4.354352951049805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 3992.741801376884
INFO:root:eval perplexity: 5.025613307952881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [4:13:01<10:05:28, 252.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3725.126994680851
INFO:root:current train perplexity4.339742183685303
INFO:root:current mean train loss 3706.7113726349917
INFO:root:current train perplexity4.315603256225586
INFO:root:current mean train loss 3712.752327737538
INFO:root:current train perplexity4.318325519561768
INFO:root:current mean train loss 3715.511877758015
INFO:root:current train perplexity4.321842670440674
INFO:root:current mean train loss 3714.479787668659
INFO:root:current train perplexity4.3283209800720215
INFO:root:current mean train loss 3717.248761443813
INFO:root:current train perplexity4.330253601074219
INFO:root:current mean train loss 3722.014886917987
INFO:root:current train perplexity4.333930015563965
INFO:root:current mean train loss 3722.408980322331
INFO:root:current train perplexity4.336092472076416
INFO:root:current mean train loss 3723.8501333982067
INFO:root:current train perplexity4.337899208068848
INFO:root:current mean train loss 3723.558238237939
INFO:root:current train perplexity4.337730884552002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 3991.4050414173316
INFO:root:eval perplexity: 5.022898197174072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [4:17:07<9:57:03, 250.51s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.559912109375
INFO:root:current train perplexity4.253158092498779
INFO:root:current mean train loss 3687.496118951613
INFO:root:current train perplexity4.2883453369140625
INFO:root:current mean train loss 3695.104991000306
INFO:root:current train perplexity4.289985179901123
INFO:root:current mean train loss 3693.6020280864877
INFO:root:current train perplexity4.2906928062438965
INFO:root:current mean train loss 3704.6375504378434
INFO:root:current train perplexity4.303138256072998
INFO:root:current mean train loss 3705.5773125175956
INFO:root:current train perplexity4.308751583099365
INFO:root:current mean train loss 3706.2360582657443
INFO:root:current train perplexity4.312999248504639
INFO:root:current mean train loss 3707.552813276076
INFO:root:current train perplexity4.318990230560303
INFO:root:current mean train loss 3709.6914839181286
INFO:root:current train perplexity4.319530963897705
INFO:root:current mean train loss 3712.4802772721696
INFO:root:current train perplexity4.321694850921631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 3992.2715449772827
INFO:root:eval perplexity: 5.024657726287842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [4:21:44<10:11:17, 258.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3701.4158567398313
INFO:root:current train perplexity4.311858654022217
INFO:root:current mean train loss 3679.4126500790835
INFO:root:current train perplexity4.265294075012207
INFO:root:current mean train loss 3688.952204134981
INFO:root:current train perplexity4.274389266967773
INFO:root:current mean train loss 3681.5200302922694
INFO:root:current train perplexity4.2759270668029785
INFO:root:current mean train loss 3688.691033447793
INFO:root:current train perplexity4.2859110832214355
INFO:root:current mean train loss 3691.9400853754996
INFO:root:current train perplexity4.288997650146484
INFO:root:current mean train loss 3694.551413879855
INFO:root:current train perplexity4.2927775382995605
INFO:root:current mean train loss 3696.708128122952
INFO:root:current train perplexity4.299630641937256
INFO:root:current mean train loss 3698.961687461526
INFO:root:current train perplexity4.304287433624268
INFO:root:current mean train loss 3703.989345784252
INFO:root:current train perplexity4.308619022369385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 3988.1310688857493
INFO:root:eval perplexity: 5.016252517700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [4:25:57<10:03:04, 256.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.7526305292695
INFO:root:current train perplexity4.2675628662109375
INFO:root:current mean train loss 3674.9859469229714
INFO:root:current train perplexity4.253908634185791
INFO:root:current mean train loss 3689.1653309501844
INFO:root:current train perplexity4.269628047943115
INFO:root:current mean train loss 3693.3592703683034
INFO:root:current train perplexity4.281177520751953
INFO:root:current mean train loss 3690.9868205530124
INFO:root:current train perplexity4.28709077835083
INFO:root:current mean train loss 3692.135969653021
INFO:root:current train perplexity4.290117263793945
INFO:root:current mean train loss 3693.1703595816643
INFO:root:current train perplexity4.2920966148376465
INFO:root:current mean train loss 3695.07807370197
INFO:root:current train perplexity4.291145324707031
INFO:root:current mean train loss 3695.703102576062
INFO:root:current train perplexity4.292919158935547
INFO:root:current mean train loss 3695.308718208918
INFO:root:current train perplexity4.293209552764893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 3992.312153701241
INFO:root:eval perplexity: 5.024740695953369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:30:47<10:22:10, 266.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3678.440871612935
INFO:root:current train perplexity4.27362060546875
INFO:root:current mean train loss 3691.2825198040327
INFO:root:current train perplexity4.281815528869629
INFO:root:current mean train loss 3688.7190632700494
INFO:root:current train perplexity4.285350799560547
INFO:root:current mean train loss 3678.7295752854966
INFO:root:current train perplexity4.27805757522583
INFO:root:current mean train loss 3679.3260291623174
INFO:root:current train perplexity4.274263381958008
INFO:root:current mean train loss 3682.8468297981435
INFO:root:current train perplexity4.279023170471191
INFO:root:current mean train loss 3681.251220343566
INFO:root:current train perplexity4.275503158569336
INFO:root:current mean train loss 3684.1869095495026
INFO:root:current train perplexity4.278567314147949
INFO:root:current mean train loss 3685.371552589946
INFO:root:current train perplexity4.277570724487305
INFO:root:current mean train loss 3689.7412840051234
INFO:root:current train perplexity4.2818450927734375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 3989.659844581117
INFO:root:eval perplexity: 5.01935338973999
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:35:38<10:34:55, 274.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3668.1607259114585
INFO:root:current train perplexity4.23048734664917
INFO:root:current mean train loss 3675.4768849745155
INFO:root:current train perplexity4.2563042640686035
INFO:root:current mean train loss 3680.9213518415177
INFO:root:current train perplexity4.263611316680908
INFO:root:current mean train loss 3682.798581460958
INFO:root:current train perplexity4.266086578369141
INFO:root:current mean train loss 3683.8497251788694
INFO:root:current train perplexity4.2694525718688965
INFO:root:current mean train loss 3683.255475903695
INFO:root:current train perplexity4.266589641571045
INFO:root:current mean train loss 3681.995661262168
INFO:root:current train perplexity4.266044616699219
INFO:root:current mean train loss 3680.580236645787
INFO:root:current train perplexity4.268065452575684
INFO:root:current mean train loss 3679.304434826839
INFO:root:current train perplexity4.266496658325195
INFO:root:current mean train loss 3680.7170791084886
INFO:root:current train perplexity4.26743745803833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]
INFO:root:eval mean loss: 3989.927459067487
INFO:root:eval perplexity: 5.0198974609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:40:17<10:33:48, 275.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.5496530633222
INFO:root:current train perplexity4.219659805297852
INFO:root:current mean train loss 3659.7948192107374
INFO:root:current train perplexity4.238769054412842
INFO:root:current mean train loss 3664.5184653072033
INFO:root:current train perplexity4.241816997528076
INFO:root:current mean train loss 3667.806867459454
INFO:root:current train perplexity4.245791435241699
INFO:root:current mean train loss 3671.3417786261048
INFO:root:current train perplexity4.245246887207031
INFO:root:current mean train loss 3672.7831075203517
INFO:root:current train perplexity4.251644611358643
INFO:root:current mean train loss 3672.4746406390514
INFO:root:current train perplexity4.251131534576416
INFO:root:current mean train loss 3674.210280930621
INFO:root:current train perplexity4.257036209106445
INFO:root:current mean train loss 3673.987768418296
INFO:root:current train perplexity4.25619649887085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 3991.0511448636967
INFO:root:eval perplexity: 5.02217960357666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:44:25<10:10:12, 267.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3689.0150553385415
INFO:root:current train perplexity4.310250759124756
INFO:root:current mean train loss 3675.3623165389868
INFO:root:current train perplexity4.246815204620361
INFO:root:current mean train loss 3660.7465267087437
INFO:root:current train perplexity4.23396635055542
INFO:root:current mean train loss 3659.871421688067
INFO:root:current train perplexity4.241318702697754
INFO:root:current mean train loss 3666.6358015566843
INFO:root:current train perplexity4.244275093078613
INFO:root:current mean train loss 3670.4359385678117
INFO:root:current train perplexity4.241052150726318
INFO:root:current mean train loss 3670.387641868781
INFO:root:current train perplexity4.240218162536621
INFO:root:current mean train loss 3666.7937522226175
INFO:root:current train perplexity4.237432479858398
INFO:root:current mean train loss 3667.0336926223927
INFO:root:current train perplexity4.238698959350586
INFO:root:current mean train loss 3666.954637968923
INFO:root:current train perplexity4.239583969116211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 3986.6981694647607
INFO:root:eval perplexity: 5.0133466720581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:48:31<9:51:36, 261.00s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3639.9532581676135
INFO:root:current train perplexity4.212451934814453
INFO:root:current mean train loss 3669.8538455447633
INFO:root:current train perplexity4.2261738777160645
INFO:root:current mean train loss 3645.033490077014
INFO:root:current train perplexity4.214047908782959
INFO:root:current mean train loss 3634.4750945161777
INFO:root:current train perplexity4.208271026611328
INFO:root:current mean train loss 3640.995949404083
INFO:root:current train perplexity4.209258079528809
INFO:root:current mean train loss 3647.4943384219055
INFO:root:current train perplexity4.2149763107299805
INFO:root:current mean train loss 3651.5949679060964
INFO:root:current train perplexity4.220358371734619
INFO:root:current mean train loss 3653.8798161974773
INFO:root:current train perplexity4.224274635314941
INFO:root:current mean train loss 3658.134727995434
INFO:root:current train perplexity4.228001117706299
INFO:root:current mean train loss 3656.3786079750103
INFO:root:current train perplexity4.22706413269043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.50s/it]
INFO:root:eval mean loss: 3986.1536770002217
INFO:root:eval perplexity: 5.012242317199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/65
######################best#################
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:52:43<9:41:14, 258.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.5599043996713
INFO:root:current train perplexity4.192625522613525
INFO:root:current mean train loss 3644.2797174533875
INFO:root:current train perplexity4.202749252319336
INFO:root:current mean train loss 3643.525486497574
INFO:root:current train perplexity4.200134754180908
INFO:root:current mean train loss 3646.272604819749
INFO:root:current train perplexity4.202101707458496
INFO:root:current mean train loss 3647.5274125055935
INFO:root:current train perplexity4.206364154815674
INFO:root:current mean train loss 3644.00682464776
INFO:root:current train perplexity4.201071739196777
INFO:root:current mean train loss 3649.4008307880654
INFO:root:current train perplexity4.208693504333496
INFO:root:current mean train loss 3647.4419621028555
INFO:root:current train perplexity4.210735321044922
INFO:root:current mean train loss 3646.3181969126795
INFO:root:current train perplexity4.2079243659973145
INFO:root:current mean train loss 3647.355961813112
INFO:root:current train perplexity4.213491439819336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.75s/it]
INFO:root:eval mean loss: 3987.7127070866577
INFO:root:eval perplexity: 5.015404224395752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:57:13<9:44:34, 261.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3608.94835973669
INFO:root:current train perplexity4.115245342254639
INFO:root:current mean train loss 3624.5099674735484
INFO:root:current train perplexity4.170421600341797
INFO:root:current mean train loss 3639.7050996351873
INFO:root:current train perplexity4.199992656707764
INFO:root:current mean train loss 3640.7567090142393
INFO:root:current train perplexity4.196617603302002
INFO:root:current mean train loss 3643.391429463371
INFO:root:current train perplexity4.195432186126709
INFO:root:current mean train loss 3638.141470921786
INFO:root:current train perplexity4.1918816566467285
INFO:root:current mean train loss 3638.1139583800586
INFO:root:current train perplexity4.195286273956299
INFO:root:current mean train loss 3638.5967448364427
INFO:root:current train perplexity4.199823379516602
INFO:root:current mean train loss 3639.171963563709
INFO:root:current train perplexity4.201536178588867
INFO:root:current mean train loss 3642.0600111878034
INFO:root:current train perplexity4.203609466552734


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.49s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 3988.1572888962764
INFO:root:eval perplexity: 5.016305923461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [5:02:03<9:58:49, 270.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3608.7111188616072
INFO:root:current train perplexity4.153186321258545
INFO:root:current mean train loss 3609.1743977864585
INFO:root:current train perplexity4.164764404296875
INFO:root:current mean train loss 3616.021188289561
INFO:root:current train perplexity4.169484615325928
INFO:root:current mean train loss 3625.2115977728545
INFO:root:current train perplexity4.175703048706055
INFO:root:current mean train loss 3625.0813869432473
INFO:root:current train perplexity4.17622184753418
INFO:root:current mean train loss 3632.363756297459
INFO:root:current train perplexity4.1819353103637695
INFO:root:current mean train loss 3633.3125853531005
INFO:root:current train perplexity4.180578708648682
INFO:root:current mean train loss 3634.17496047247
INFO:root:current train perplexity4.185151100158691
INFO:root:current mean train loss 3635.7126002877058
INFO:root:current train perplexity4.188992023468018
INFO:root:current mean train loss 3637.176391209893
INFO:root:current train perplexity4.190738677978516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 3987.3397831477173
INFO:root:eval perplexity: 5.014647483825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [5:06:09<9:38:37, 263.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3616.876107149346
INFO:root:current train perplexity4.1561665534973145
INFO:root:current mean train loss 3632.1216315422857
INFO:root:current train perplexity4.177830219268799
INFO:root:current mean train loss 3632.4859372990613
INFO:root:current train perplexity4.180351734161377
INFO:root:current mean train loss 3630.186267196611
INFO:root:current train perplexity4.174962997436523
INFO:root:current mean train loss 3623.3536655262415
INFO:root:current train perplexity4.1690239906311035
INFO:root:current mean train loss 3625.664099817996
INFO:root:current train perplexity4.171764850616455
INFO:root:current mean train loss 3629.2538876451936
INFO:root:current train perplexity4.174801349639893
INFO:root:current mean train loss 3629.6870915655495
INFO:root:current train perplexity4.177218437194824
INFO:root:current mean train loss 3631.438692031806
INFO:root:current train perplexity4.180624008178711
INFO:root:current mean train loss 3628.553969058606
INFO:root:current train perplexity4.178570747375488


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it]
INFO:root:eval mean loss: 3990.1107792414673
INFO:root:eval perplexity: 5.020269870758057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [5:10:25<9:29:14, 260.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.5913851868872
INFO:root:current train perplexity4.148579120635986
INFO:root:current mean train loss 3598.9074286656664
INFO:root:current train perplexity4.150182723999023
INFO:root:current mean train loss 3604.1625937655626
INFO:root:current train perplexity4.148601055145264
INFO:root:current mean train loss 3613.355555694667
INFO:root:current train perplexity4.160066604614258
INFO:root:current mean train loss 3606.1496268058827
INFO:root:current train perplexity4.157383918762207
INFO:root:current mean train loss 3607.3475242102427
INFO:root:current train perplexity4.160731792449951
INFO:root:current mean train loss 3611.9711820306497
INFO:root:current train perplexity4.163150310516357
INFO:root:current mean train loss 3613.212859091524
INFO:root:current train perplexity4.164068222045898
INFO:root:current mean train loss 3616.3847538626433
INFO:root:current train perplexity4.164015293121338
INFO:root:current mean train loss 3619.4945477827614
INFO:root:current train perplexity4.1660237312316895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 3988.670261247784
INFO:root:eval perplexity: 5.017345905303955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [5:14:32<9:16:07, 256.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3577.421655687235
INFO:root:current train perplexity4.147719860076904
INFO:root:current mean train loss 3585.520239104265
INFO:root:current train perplexity4.139965057373047
INFO:root:current mean train loss 3600.3136707438466
INFO:root:current train perplexity4.146799564361572
INFO:root:current mean train loss 3599.7040376370996
INFO:root:current train perplexity4.147759437561035
INFO:root:current mean train loss 3602.4055505557258
INFO:root:current train perplexity4.14480447769165
INFO:root:current mean train loss 3602.9198996009895
INFO:root:current train perplexity4.145726680755615
INFO:root:current mean train loss 3604.8343818907674
INFO:root:current train perplexity4.147482395172119
INFO:root:current mean train loss 3605.6923313467555
INFO:root:current train perplexity4.150646209716797
INFO:root:current mean train loss 3608.3853619079237
INFO:root:current train perplexity4.1529645919799805
INFO:root:current mean train loss 3614.181103719288
INFO:root:current train perplexity4.156400680541992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 3988.244949232602
INFO:root:eval perplexity: 5.016482830047607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [5:18:40<9:06:23, 254.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.233340135261
INFO:root:current train perplexity4.088144779205322
INFO:root:current mean train loss 3581.780681313155
INFO:root:current train perplexity4.1023125648498535
INFO:root:current mean train loss 3582.5216699950256
INFO:root:current train perplexity4.113501071929932
INFO:root:current mean train loss 3597.1440529472497
INFO:root:current train perplexity4.128606796264648
INFO:root:current mean train loss 3597.3123881239962
INFO:root:current train perplexity4.128308296203613
INFO:root:current mean train loss 3593.080649939374
INFO:root:current train perplexity4.129965305328369
INFO:root:current mean train loss 3599.0335545118064
INFO:root:current train perplexity4.133419513702393
INFO:root:current mean train loss 3602.037004652359
INFO:root:current train perplexity4.138861656188965
INFO:root:current mean train loss 3601.1891039504035
INFO:root:current train perplexity4.139291286468506
INFO:root:current mean train loss 3607.2882338862137
INFO:root:current train perplexity4.1462836265563965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.33s/it]
INFO:root:eval mean loss: 3988.9068768007537
INFO:root:eval perplexity: 5.017826080322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [5:22:46<8:56:50, 251.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3614.611396484375
INFO:root:current train perplexity4.119626045227051
INFO:root:current mean train loss 3593.9868722098213
INFO:root:current train perplexity4.112598419189453
INFO:root:current mean train loss 3596.1420676491475
INFO:root:current train perplexity4.115984916687012
INFO:root:current mean train loss 3593.4771484375
INFO:root:current train perplexity4.123473167419434
INFO:root:current mean train loss 3596.48064453125
INFO:root:current train perplexity4.128620624542236
INFO:root:current mean train loss 3597.193376783288
INFO:root:current train perplexity4.127660274505615
INFO:root:current mean train loss 3596.872302155671
INFO:root:current train perplexity4.1279401779174805
INFO:root:current mean train loss 3598.484352318548
INFO:root:current train perplexity4.131958484649658
INFO:root:current mean train loss 3600.464688058036
INFO:root:current train perplexity4.133309841156006
INFO:root:current mean train loss 3600.9359392528045
INFO:root:current train perplexity4.135075569152832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it]
INFO:root:eval mean loss: 3989.233045212766
INFO:root:eval perplexity: 5.01848840713501
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:26:53<8:49:35, 250.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3559.6047980986446
INFO:root:current train perplexity4.0899577140808105
INFO:root:current mean train loss 3578.1067241397714
INFO:root:current train perplexity4.107229232788086
INFO:root:current mean train loss 3587.1868529842095
INFO:root:current train perplexity4.11679744720459
INFO:root:current mean train loss 3585.5124607335183
INFO:root:current train perplexity4.111240386962891
INFO:root:current mean train loss 3588.0621542604813
INFO:root:current train perplexity4.118589401245117
INFO:root:current mean train loss 3588.4952084785054
INFO:root:current train perplexity4.121863842010498
INFO:root:current mean train loss 3590.909084962367
INFO:root:current train perplexity4.123034954071045
INFO:root:current mean train loss 3590.129299119971
INFO:root:current train perplexity4.120419502258301
INFO:root:current mean train loss 3591.9546628370967
INFO:root:current train perplexity4.121110916137695
INFO:root:current mean train loss 3592.586945604575
INFO:root:current train perplexity4.122626304626465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.64s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 3989.647637549867
INFO:root:eval perplexity: 5.01932954788208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [5:31:03<8:45:26, 250.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.6035585508243
INFO:root:current train perplexity4.107995986938477
INFO:root:current mean train loss 3575.882964608557
INFO:root:current train perplexity4.091355323791504
INFO:root:current mean train loss 3582.208505322433
INFO:root:current train perplexity4.098581314086914
INFO:root:current mean train loss 3578.1638320961874
INFO:root:current train perplexity4.09863805770874
INFO:root:current mean train loss 3577.4027753468686
INFO:root:current train perplexity4.097630500793457
INFO:root:current mean train loss 3578.696418362019
INFO:root:current train perplexity4.095312118530273
INFO:root:current mean train loss 3580.405675863219
INFO:root:current train perplexity4.101859092712402
INFO:root:current mean train loss 3581.9949140970684
INFO:root:current train perplexity4.106283664703369
INFO:root:current mean train loss 3583.636307738847
INFO:root:current train perplexity4.109097480773926
INFO:root:current mean train loss 3586.746734034041
INFO:root:current train perplexity4.112276554107666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.55s/it]
INFO:root:eval mean loss: 3988.4806574828235
INFO:root:eval perplexity: 5.016961574554443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [5:35:57<9:08:23, 263.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3561.873749704072
INFO:root:current train perplexity4.078723430633545
INFO:root:current mean train loss 3574.0629747860394
INFO:root:current train perplexity4.082458972930908
INFO:root:current mean train loss 3573.8344179491532
INFO:root:current train perplexity4.089677333831787
INFO:root:current mean train loss 3573.7011749344065
INFO:root:current train perplexity4.0922956466674805
INFO:root:current mean train loss 3577.9731959035257
INFO:root:current train perplexity4.095163345336914
INFO:root:current mean train loss 3577.9078566817093
INFO:root:current train perplexity4.0922722816467285
INFO:root:current mean train loss 3581.4734152164924
INFO:root:current train perplexity4.100340843200684
INFO:root:current mean train loss 3579.559475589604
INFO:root:current train perplexity4.100357532501221
INFO:root:current mean train loss 3579.9133862929298
INFO:root:current train perplexity4.102344036102295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:04<00:00, 244.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:04<00:00, 244.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.55s/it]
INFO:root:eval mean loss: 3988.9464016095967
INFO:root:eval perplexity: 5.017906188964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:41:06<9:32:20, 276.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.2766462053573
INFO:root:current train perplexity4.112058639526367
INFO:root:current mean train loss 3577.4693751825353
INFO:root:current train perplexity4.103860378265381
INFO:root:current mean train loss 3569.558944038723
INFO:root:current train perplexity4.090010166168213
INFO:root:current mean train loss 3566.2776968393728
INFO:root:current train perplexity4.079829216003418
INFO:root:current mean train loss 3568.271738713145
INFO:root:current train perplexity4.081353187561035
INFO:root:current mean train loss 3567.808920233913
INFO:root:current train perplexity4.081191062927246
INFO:root:current mean train loss 3572.873618413432
INFO:root:current train perplexity4.086935520172119
INFO:root:current mean train loss 3573.2142325351397
INFO:root:current train perplexity4.088806629180908
INFO:root:current mean train loss 3573.413922731761
INFO:root:current train perplexity4.089169979095459
INFO:root:current mean train loss 3572.7292423942254
INFO:root:current train perplexity4.089354991912842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it]
INFO:root:eval mean loss: 3990.0312274905805
INFO:root:eval perplexity: 5.020107746124268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:45:56<9:35:56, 280.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.190218098958
INFO:root:current train perplexity4.00428581237793
INFO:root:current mean train loss 3555.589892578125
INFO:root:current train perplexity4.0503926277160645
INFO:root:current mean train loss 3561.8694040697674
INFO:root:current train perplexity4.059069633483887
INFO:root:current mean train loss 3555.180320715526
INFO:root:current train perplexity4.055487632751465
INFO:root:current mean train loss 3561.1638695406627
INFO:root:current train perplexity4.06735372543335
INFO:root:current mean train loss 3563.4243614418992
INFO:root:current train perplexity4.072186470031738
INFO:root:current mean train loss 3559.286837842988
INFO:root:current train perplexity4.06801176071167
INFO:root:current mean train loss 3563.551809030813
INFO:root:current train perplexity4.074440956115723
INFO:root:current mean train loss 3564.2924583013805
INFO:root:current train perplexity4.076484203338623
INFO:root:current mean train loss 3565.877701289276
INFO:root:current train perplexity4.078290939331055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it]
INFO:root:eval mean loss: 3990.630975385084
INFO:root:eval perplexity: 5.021325588226318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:50:16<9:18:25, 274.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.956160835598
INFO:root:current train perplexity4.0657172203063965
INFO:root:current mean train loss 3550.2663276486282
INFO:root:current train perplexity4.065098762512207
INFO:root:current mean train loss 3549.1696076671105
INFO:root:current train perplexity4.067568302154541
INFO:root:current mean train loss 3552.112396901606
INFO:root:current train perplexity4.062657833099365
INFO:root:current mean train loss 3551.063604693041
INFO:root:current train perplexity4.061102867126465
INFO:root:current mean train loss 3550.3782597208115
INFO:root:current train perplexity4.063180446624756
INFO:root:current mean train loss 3555.088592872191
INFO:root:current train perplexity4.0652079582214355
INFO:root:current mean train loss 3555.3123105630834
INFO:root:current train perplexity4.064017295837402
INFO:root:current mean train loss 3557.8722067702006
INFO:root:current train perplexity4.065338134765625
INFO:root:current mean train loss 3559.2217347051055
INFO:root:current train perplexity4.070271015167236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it]
INFO:root:eval mean loss: 3992.0820780003323
INFO:root:eval perplexity: 5.02427339553833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:55:04<9:22:03, 278.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.3050418976813
INFO:root:current train perplexity4.0334272384643555
INFO:root:current mean train loss 3545.412163421398
INFO:root:current train perplexity4.042741775512695
INFO:root:current mean train loss 3553.4754643956303
INFO:root:current train perplexity4.048951625823975
INFO:root:current mean train loss 3557.77917222314
INFO:root:current train perplexity4.051980495452881
INFO:root:current mean train loss 3555.4380228347954
INFO:root:current train perplexity4.056482315063477
INFO:root:current mean train loss 3555.568735471104
INFO:root:current train perplexity4.060603141784668
INFO:root:current mean train loss 3554.759966818542
INFO:root:current train perplexity4.059240341186523
INFO:root:current mean train loss 3554.390906212594
INFO:root:current train perplexity4.059236526489258
INFO:root:current mean train loss 3557.7353609638235
INFO:root:current train perplexity4.063827991485596
INFO:root:current mean train loss 3554.2535792431695
INFO:root:current train perplexity4.061933517456055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 3992.161631482713
INFO:root:eval perplexity: 5.024435043334961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:59:55<9:24:39, 282.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.922832782452
INFO:root:current train perplexity4.041496276855469
INFO:root:current mean train loss 3523.981824696493
INFO:root:current train perplexity4.021040916442871
INFO:root:current mean train loss 3527.66053420829
INFO:root:current train perplexity4.022841930389404
INFO:root:current mean train loss 3532.748782897769
INFO:root:current train perplexity4.022602558135986
INFO:root:current mean train loss 3535.6125343687713
INFO:root:current train perplexity4.03476095199585
INFO:root:current mean train loss 3535.863945729215
INFO:root:current train perplexity4.036787986755371
INFO:root:current mean train loss 3542.8022415089495
INFO:root:current train perplexity4.043302536010742
INFO:root:current mean train loss 3545.605180340304
INFO:root:current train perplexity4.048913955688477
INFO:root:current mean train loss 3547.2132860804345
INFO:root:current train perplexity4.050591945648193
INFO:root:current mean train loss 3546.9470425444288
INFO:root:current train perplexity4.049794673919678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it]
INFO:root:eval mean loss: 3993.139404296875
INFO:root:eval perplexity: 5.026421546936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [6:04:24<9:12:00, 278.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3550.6199769365026
INFO:root:current train perplexity4.082443714141846
INFO:root:current mean train loss 3557.302033508716
INFO:root:current train perplexity4.0558342933654785
INFO:root:current mean train loss 3538.911153569395
INFO:root:current train perplexity4.036007404327393
INFO:root:current mean train loss 3536.781848038995
INFO:root:current train perplexity4.032594203948975
INFO:root:current mean train loss 3542.7229337073545
INFO:root:current train perplexity4.033285140991211
INFO:root:current mean train loss 3537.0435422796218
INFO:root:current train perplexity4.033233165740967
INFO:root:current mean train loss 3540.1418189118044
INFO:root:current train perplexity4.037023067474365
INFO:root:current mean train loss 3543.221727404409
INFO:root:current train perplexity4.037204742431641
INFO:root:current mean train loss 3545.8869969031325
INFO:root:current train perplexity4.040698528289795
INFO:root:current mean train loss 3543.515324400244
INFO:root:current train perplexity4.043283939361572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.37s/it]
INFO:root:eval mean loss: 3995.0555255429963
INFO:root:eval perplexity: 5.030317783355713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [6:08:37<8:52:49, 270.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.2088201349434
INFO:root:current train perplexity4.027416706085205
INFO:root:current mean train loss 3531.3678805443546
INFO:root:current train perplexity4.024523735046387
INFO:root:current mean train loss 3526.2820111443016
INFO:root:current train perplexity4.0203962326049805
INFO:root:current mean train loss 3530.555928147007
INFO:root:current train perplexity4.028458595275879
INFO:root:current mean train loss 3528.2373905391482
INFO:root:current train perplexity4.032658576965332
INFO:root:current mean train loss 3531.169073321368
INFO:root:current train perplexity4.033179759979248
INFO:root:current mean train loss 3532.651489816913
INFO:root:current train perplexity4.033168315887451
INFO:root:current mean train loss 3535.455096233444
INFO:root:current train perplexity4.033782005310059
INFO:root:current mean train loss 3536.2128469366776
INFO:root:current train perplexity4.032530784606934
INFO:root:current mean train loss 3538.9242698789267
INFO:root:current train perplexity4.034322261810303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.32s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.89s/it]
INFO:root:eval mean loss: 3995.001482158688
INFO:root:eval perplexity: 5.030208587646484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [6:13:26<8:58:33, 276.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3523.2658730158732
INFO:root:current train perplexity3.9824817180633545
INFO:root:current mean train loss 3525.65206965347
INFO:root:current train perplexity4.005009651184082
INFO:root:current mean train loss 3516.922663119356
INFO:root:current train perplexity4.011835098266602
INFO:root:current mean train loss 3517.462316255596
INFO:root:current train perplexity4.014097690582275
INFO:root:current mean train loss 3521.6183080158276
INFO:root:current train perplexity4.013704776763916
INFO:root:current mean train loss 3523.7418865522313
INFO:root:current train perplexity4.016948223114014
INFO:root:current mean train loss 3528.1212856010793
INFO:root:current train perplexity4.020852565765381
INFO:root:current mean train loss 3531.3182566631513
INFO:root:current train perplexity4.024462699890137
INFO:root:current mean train loss 3530.231579688858
INFO:root:current train perplexity4.022171974182129
INFO:root:current mean train loss 3530.29567838136
INFO:root:current train perplexity4.022543907165527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 3995.880691420102
INFO:root:eval perplexity: 5.031996726989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [6:18:15<9:01:18, 279.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.931265817562
INFO:root:current train perplexity3.9904112815856934
INFO:root:current mean train loss 3508.890869140625
INFO:root:current train perplexity3.9932003021240234
INFO:root:current mean train loss 3506.0357553404638
INFO:root:current train perplexity3.99354887008667
INFO:root:current mean train loss 3510.0180532450304
INFO:root:current train perplexity4.001516819000244
INFO:root:current mean train loss 3512.752548703722
INFO:root:current train perplexity4.0013861656188965
INFO:root:current mean train loss 3518.095570151735
INFO:root:current train perplexity4.004980564117432
INFO:root:current mean train loss 3522.650658415611
INFO:root:current train perplexity4.009838104248047
INFO:root:current mean train loss 3526.3172852829116
INFO:root:current train perplexity4.0114030838012695
INFO:root:current mean train loss 3526.9082774042945
INFO:root:current train perplexity4.013834476470947
INFO:root:current mean train loss 3525.788815593621
INFO:root:current train perplexity4.0146894454956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it]
INFO:root:eval mean loss: 3996.19707862367
INFO:root:eval perplexity: 5.0326409339904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [6:22:58<8:58:32, 280.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.7646546182755
INFO:root:current train perplexity4.002564430236816
INFO:root:current mean train loss 3502.1503619828036
INFO:root:current train perplexity3.999054431915283
INFO:root:current mean train loss 3514.2258362035172
INFO:root:current train perplexity3.9997172355651855
INFO:root:current mean train loss 3517.126676131679
INFO:root:current train perplexity3.9967265129089355
INFO:root:current mean train loss 3517.8685713033337
INFO:root:current train perplexity3.999631404876709
INFO:root:current mean train loss 3515.753455496411
INFO:root:current train perplexity4.000212669372559
INFO:root:current mean train loss 3513.943111638784
INFO:root:current train perplexity4.000398635864258
INFO:root:current mean train loss 3516.8680659674865
INFO:root:current train perplexity4.00209379196167
INFO:root:current mean train loss 3518.323822958884
INFO:root:current train perplexity4.002064228057861
INFO:root:current mean train loss 3519.2354134081334
INFO:root:current train perplexity4.002848148345947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.02s/it]
INFO:root:eval mean loss: 3995.512688386525
INFO:root:eval perplexity: 5.031248092651367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [6:27:59<9:05:31, 287.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3480.0428031833694
INFO:root:current train perplexity3.9654786586761475
INFO:root:current mean train loss 3489.6954313064
INFO:root:current train perplexity3.9726297855377197
INFO:root:current mean train loss 3492.4254852188587
INFO:root:current train perplexity3.9859066009521484
INFO:root:current mean train loss 3496.7743358365633
INFO:root:current train perplexity3.9851717948913574
INFO:root:current mean train loss 3501.1192208354723
INFO:root:current train perplexity3.9864141941070557
INFO:root:current mean train loss 3507.8347176286998
INFO:root:current train perplexity3.991157293319702
INFO:root:current mean train loss 3507.9155003354713
INFO:root:current train perplexity3.9901716709136963
INFO:root:current mean train loss 3510.671323124305
INFO:root:current train perplexity3.993882179260254
INFO:root:current mean train loss 3511.8343636599843
INFO:root:current train perplexity3.994187831878662
INFO:root:current mean train loss 3513.6028851139026
INFO:root:current train perplexity3.9952406883239746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 3997.8065609762853
INFO:root:eval perplexity: 5.03591775894165
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [6:32:35<8:54:04, 283.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.436274157072
INFO:root:current train perplexity3.9589314460754395
INFO:root:current mean train loss 3514.565795272436
INFO:root:current train perplexity3.977459669113159
INFO:root:current mean train loss 3511.992749437235
INFO:root:current train perplexity3.982335090637207
INFO:root:current mean train loss 3503.6412770717957
INFO:root:current train perplexity3.9784603118896484
INFO:root:current mean train loss 3503.385180910669
INFO:root:current train perplexity3.9783101081848145
INFO:root:current mean train loss 3504.587073677127
INFO:root:current train perplexity3.9756598472595215
INFO:root:current mean train loss 3504.268573305418
INFO:root:current train perplexity3.9784674644470215
INFO:root:current mean train loss 3506.496796383648
INFO:root:current train perplexity3.9837372303009033
INFO:root:current mean train loss 3508.712681673359
INFO:root:current train perplexity3.987762212753296


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it]
INFO:root:eval mean loss: 3999.4109510056514
INFO:root:eval perplexity: 5.039185047149658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [6:37:18<8:49:17, 283.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3688.9213053385415
INFO:root:current train perplexity4.068779468536377
INFO:root:current mean train loss 3509.3928341171118
INFO:root:current train perplexity3.9724724292755127
INFO:root:current mean train loss 3500.091137815579
INFO:root:current train perplexity3.9671902656555176
INFO:root:current mean train loss 3493.7337255698226
INFO:root:current train perplexity3.959355354309082
INFO:root:current mean train loss 3498.767360639927
INFO:root:current train perplexity3.96937894821167
INFO:root:current mean train loss 3499.0205713958435
INFO:root:current train perplexity3.9724843502044678
INFO:root:current mean train loss 3500.2635921142983
INFO:root:current train perplexity3.9721243381500244
INFO:root:current mean train loss 3496.611429184633
INFO:root:current train perplexity3.9708101749420166
INFO:root:current mean train loss 3498.848493868209
INFO:root:current train perplexity3.9711532592773438
INFO:root:current mean train loss 3499.863502139137
INFO:root:current train perplexity3.9759774208068848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4002.047337308843
INFO:root:eval perplexity: 5.044559955596924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [6:41:26<8:24:40, 272.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.7834028764205
INFO:root:current train perplexity3.9233765602111816
INFO:root:current mean train loss 3488.8764252533783
INFO:root:current train perplexity3.960618257522583
INFO:root:current mean train loss 3485.943972619224
INFO:root:current train perplexity3.959035873413086
INFO:root:current mean train loss 3484.328044143137
INFO:root:current train perplexity3.9600017070770264
INFO:root:current mean train loss 3482.6806878231446
INFO:root:current train perplexity3.953535795211792
INFO:root:current mean train loss 3484.874677027275
INFO:root:current train perplexity3.9551069736480713
INFO:root:current mean train loss 3487.0940173160034
INFO:root:current train perplexity3.961641788482666
INFO:root:current mean train loss 3492.5472966662273
INFO:root:current train perplexity3.962336301803589
INFO:root:current mean train loss 3492.917602990617
INFO:root:current train perplexity3.9646003246307373
INFO:root:current mean train loss 3495.452835836735
INFO:root:current train perplexity3.9680566787719727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it]
INFO:root:eval mean loss: 4001.719939536237
INFO:root:eval perplexity: 5.043891906738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [6:45:48<8:13:57, 269.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3452.6468056126646
INFO:root:current train perplexity3.998197078704834
INFO:root:current mean train loss 3485.4489848673843
INFO:root:current train perplexity3.9390711784362793
INFO:root:current mean train loss 3497.5259636308506
INFO:root:current train perplexity3.944397449493408
INFO:root:current mean train loss 3494.501813069406
INFO:root:current train perplexity3.951347589492798
INFO:root:current mean train loss 3495.4500694548033
INFO:root:current train perplexity3.950941562652588
INFO:root:current mean train loss 3493.6850661202434
INFO:root:current train perplexity3.9520373344421387
INFO:root:current mean train loss 3490.634350704261
INFO:root:current train perplexity3.953312873840332
INFO:root:current mean train loss 3487.6073210269255
INFO:root:current train perplexity3.9568419456481934
INFO:root:current mean train loss 3488.395761492197
INFO:root:current train perplexity3.957434892654419
INFO:root:current mean train loss 3492.5005642597253
INFO:root:current train perplexity3.961214065551758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4001.045967697252
INFO:root:eval perplexity: 5.042518138885498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:50:39<8:21:44, 276.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.634865089699
INFO:root:current train perplexity3.9623398780822754
INFO:root:current mean train loss 3471.9875430610236
INFO:root:current train perplexity3.934325695037842
INFO:root:current mean train loss 3473.7073603558647
INFO:root:current train perplexity3.941305160522461
INFO:root:current mean train loss 3477.593369976825
INFO:root:current train perplexity3.943922996520996
INFO:root:current mean train loss 3472.5531906378073
INFO:root:current train perplexity3.9423117637634277
INFO:root:current mean train loss 3478.539948262571
INFO:root:current train perplexity3.94720196723938
INFO:root:current mean train loss 3480.947596986518
INFO:root:current train perplexity3.946636438369751
INFO:root:current mean train loss 3483.5118752417898
INFO:root:current train perplexity3.9490458965301514
INFO:root:current mean train loss 3484.45973362398
INFO:root:current train perplexity3.951380729675293
INFO:root:current mean train loss 3484.7554964561423
INFO:root:current train perplexity3.9515130519866943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.86s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it]
INFO:root:eval mean loss: 4004.5003636136967
INFO:root:eval perplexity: 5.04956579208374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:55:35<8:27:45, 282.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.7666224888394
INFO:root:current train perplexity3.9279940128326416
INFO:root:current mean train loss 3472.035465494792
INFO:root:current train perplexity3.9306752681732178
INFO:root:current mean train loss 3478.3417231133644
INFO:root:current train perplexity3.9401369094848633
INFO:root:current mean train loss 3480.126805183069
INFO:root:current train perplexity3.939943313598633
INFO:root:current mean train loss 3484.016586408944
INFO:root:current train perplexity3.944892168045044
INFO:root:current mean train loss 3485.0567830023365
INFO:root:current train perplexity3.946995258331299
INFO:root:current mean train loss 3480.895484359621
INFO:root:current train perplexity3.9417319297790527
INFO:root:current mean train loss 3477.59048781622
INFO:root:current train perplexity3.939976215362549
INFO:root:current mean train loss 3479.003646613024
INFO:root:current train perplexity3.941453695297241
INFO:root:current mean train loss 3478.2723750313335
INFO:root:current train perplexity3.940333127975464


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4003.75663508422
INFO:root:eval perplexity: 5.04804801940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [7:00:27<8:28:15, 285.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.1700127180234
INFO:root:current train perplexity3.9167678356170654
INFO:root:current mean train loss 3474.68268206403
INFO:root:current train perplexity3.914114475250244
INFO:root:current mean train loss 3466.3780361850568
INFO:root:current train perplexity3.926076650619507
INFO:root:current mean train loss 3467.947510477405
INFO:root:current train perplexity3.9272899627685547
INFO:root:current mean train loss 3466.4785900245133
INFO:root:current train perplexity3.926269054412842
INFO:root:current mean train loss 3466.846392833506
INFO:root:current train perplexity3.9266200065612793
INFO:root:current mean train loss 3469.364902905691
INFO:root:current train perplexity3.9319424629211426
INFO:root:current mean train loss 3475.653053827915
INFO:root:current train perplexity3.935622453689575
INFO:root:current mean train loss 3475.482850786347
INFO:root:current train perplexity3.93578839302063
INFO:root:current mean train loss 3475.8668706090934
INFO:root:current train perplexity3.936323881149292


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4005.756970994016
INFO:root:eval perplexity: 5.052133083343506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [7:05:13<8:23:54, 285.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.025510301777
INFO:root:current train perplexity3.946345567703247
INFO:root:current mean train loss 3476.1613931213783
INFO:root:current train perplexity3.9333813190460205
INFO:root:current mean train loss 3475.520404709288
INFO:root:current train perplexity3.93365740776062
INFO:root:current mean train loss 3473.6484903623577
INFO:root:current train perplexity3.9218735694885254
INFO:root:current mean train loss 3471.0830013165187
INFO:root:current train perplexity3.922926187515259
INFO:root:current mean train loss 3472.9089226973683
INFO:root:current train perplexity3.927981376647949
INFO:root:current mean train loss 3472.4396218858005
INFO:root:current train perplexity3.9309208393096924
INFO:root:current mean train loss 3472.016607414073
INFO:root:current train perplexity3.929004669189453
INFO:root:current mean train loss 3471.6765196964966
INFO:root:current train perplexity3.9301064014434814
INFO:root:current mean train loss 3472.8109496685233
INFO:root:current train perplexity3.9328627586364746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4008.0478809978945
INFO:root:eval perplexity: 5.0568156242370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [7:10:06<8:23:19, 287.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3424.2047553628177
INFO:root:current train perplexity3.8590424060821533
INFO:root:current mean train loss 3443.032814649666
INFO:root:current train perplexity3.8777284622192383
INFO:root:current mean train loss 3446.950256583313
INFO:root:current train perplexity3.8871726989746094
INFO:root:current mean train loss 3456.7813968924092
INFO:root:current train perplexity3.8996384143829346
INFO:root:current mean train loss 3458.600242332176
INFO:root:current train perplexity3.904365301132202
INFO:root:current mean train loss 3463.1314987701253
INFO:root:current train perplexity3.908742904663086
INFO:root:current mean train loss 3462.6303032974915
INFO:root:current train perplexity3.9115498065948486
INFO:root:current mean train loss 3465.9565867146325
INFO:root:current train perplexity3.9162309169769287
INFO:root:current mean train loss 3468.111010941138
INFO:root:current train perplexity3.919870376586914
INFO:root:current mean train loss 3468.6373080988496
INFO:root:current train perplexity3.9219465255737305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 4006.739351313165
INFO:root:eval perplexity: 5.054140567779541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [7:14:56<8:19:31, 288.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.5007214902053
INFO:root:current train perplexity3.9379632472991943
INFO:root:current mean train loss 3462.889467159431
INFO:root:current train perplexity3.9183099269866943
INFO:root:current mean train loss 3466.936704485604
INFO:root:current train perplexity3.9175608158111572
INFO:root:current mean train loss 3465.4815537455297
INFO:root:current train perplexity3.913343667984009
INFO:root:current mean train loss 3462.3407743074144
INFO:root:current train perplexity3.9117064476013184
INFO:root:current mean train loss 3459.3094342482364
INFO:root:current train perplexity3.910627603530884
INFO:root:current mean train loss 3459.8394056145753
INFO:root:current train perplexity3.909870147705078
INFO:root:current mean train loss 3458.1092565902054
INFO:root:current train perplexity3.9123735427856445
INFO:root:current mean train loss 3461.570210563545
INFO:root:current train perplexity3.914186716079712
INFO:root:current mean train loss 3461.541567024302
INFO:root:current train perplexity3.914991617202759


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.05s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4008.81382805574
INFO:root:eval perplexity: 5.058382034301758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [7:19:35<8:10:21, 285.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.7337141927082
INFO:root:current train perplexity3.914961814880371
INFO:root:current mean train loss 3446.5639383370535
INFO:root:current train perplexity3.901946783065796
INFO:root:current mean train loss 3457.163348721591
INFO:root:current train perplexity3.898876905441284
INFO:root:current mean train loss 3460.2972747395834
INFO:root:current train perplexity3.899195909500122
INFO:root:current mean train loss 3457.26173828125
INFO:root:current train perplexity3.9015848636627197
INFO:root:current mean train loss 3454.1209022588314
INFO:root:current train perplexity3.9046151638031006
INFO:root:current mean train loss 3458.5881669560185
INFO:root:current train perplexity3.9064064025878906
INFO:root:current mean train loss 3456.9934431703628
INFO:root:current train perplexity3.9060304164886475
INFO:root:current mean train loss 3457.562077845982
INFO:root:current train perplexity3.9059066772460938
INFO:root:current mean train loss 3456.3159252303685
INFO:root:current train perplexity3.9074230194091797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]
INFO:root:eval mean loss: 4008.185908757203
INFO:root:eval perplexity: 5.0570969581604
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [7:24:26<8:07:58, 287.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.9983910250376
INFO:root:current train perplexity3.880678415298462
INFO:root:current mean train loss 3438.1395163614243
INFO:root:current train perplexity3.890876531600952
INFO:root:current mean train loss 3452.2881368360754
INFO:root:current train perplexity3.8924548625946045
INFO:root:current mean train loss 3452.2562953859333
INFO:root:current train perplexity3.88889741897583
INFO:root:current mean train loss 3452.105106330066
INFO:root:current train perplexity3.891773223876953
INFO:root:current mean train loss 3451.4079610782055
INFO:root:current train perplexity3.893181562423706
INFO:root:current mean train loss 3453.114953059229
INFO:root:current train perplexity3.8971359729766846
INFO:root:current mean train loss 3450.4425290474337
INFO:root:current train perplexity3.8960962295532227
INFO:root:current mean train loss 3451.4971585127937
INFO:root:current train perplexity3.8965654373168945
INFO:root:current mean train loss 3452.2543699433336
INFO:root:current train perplexity3.8994500637054443


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 4010.5670676806294
INFO:root:eval perplexity: 5.0619683265686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [7:29:20<8:07:00, 289.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.030509529533
INFO:root:current train perplexity3.8464901447296143
INFO:root:current mean train loss 3429.163276392752
INFO:root:current train perplexity3.8556888103485107
INFO:root:current mean train loss 3434.9099951675257
INFO:root:current train perplexity3.8698742389678955
INFO:root:current mean train loss 3441.016168852901
INFO:root:current train perplexity3.878824234008789
INFO:root:current mean train loss 3441.859291465122
INFO:root:current train perplexity3.881091356277466
INFO:root:current mean train loss 3441.8473914544998
INFO:root:current train perplexity3.880408525466919
INFO:root:current mean train loss 3443.103113199281
INFO:root:current train perplexity3.8826968669891357
INFO:root:current mean train loss 3443.726584105365
INFO:root:current train perplexity3.8846588134765625
INFO:root:current mean train loss 3442.344202934291
INFO:root:current train perplexity3.8858046531677246
INFO:root:current mean train loss 3446.0160181871215
INFO:root:current train perplexity3.8903391361236572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.99s/it]
INFO:root:eval mean loss: 4010.4226853390956
INFO:root:eval perplexity: 5.061674118041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [7:33:47<7:50:39, 282.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.878380977746
INFO:root:current train perplexity3.846595525741577
INFO:root:current mean train loss 3423.495585839353
INFO:root:current train perplexity3.8683254718780518
INFO:root:current mean train loss 3428.063707638744
INFO:root:current train perplexity3.871997356414795
INFO:root:current mean train loss 3425.3201442326517
INFO:root:current train perplexity3.867687225341797
INFO:root:current mean train loss 3430.2748289547844
INFO:root:current train perplexity3.8693668842315674
INFO:root:current mean train loss 3432.9972052215935
INFO:root:current train perplexity3.873713493347168
INFO:root:current mean train loss 3438.3490508902228
INFO:root:current train perplexity3.8783912658691406
INFO:root:current mean train loss 3441.9520219366004
INFO:root:current train perplexity3.881197452545166
INFO:root:current mean train loss 3441.555422637566
INFO:root:current train perplexity3.8825626373291016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4011.6244770888743
INFO:root:eval perplexity: 5.064134120941162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [7:38:46<7:54:21, 287.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3374.2845284598216
INFO:root:current train perplexity3.8256945610046387
INFO:root:current mean train loss 3456.492155556367
INFO:root:current train perplexity3.875685214996338
INFO:root:current mean train loss 3441.175338966259
INFO:root:current train perplexity3.8650126457214355
INFO:root:current mean train loss 3434.2273649035524
INFO:root:current train perplexity3.8727355003356934
INFO:root:current mean train loss 3439.601182192491
INFO:root:current train perplexity3.8752846717834473
INFO:root:current mean train loss 3438.6691157775517
INFO:root:current train perplexity3.877079486846924
INFO:root:current mean train loss 3436.8985038644205
INFO:root:current train perplexity3.8736252784729004
INFO:root:current mean train loss 3436.0269203887465
INFO:root:current train perplexity3.874474048614502
INFO:root:current mean train loss 3437.3729951426
INFO:root:current train perplexity3.8767967224121094
INFO:root:current mean train loss 3436.7601798834585
INFO:root:current train perplexity3.8779430389404297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 4017.065625346299
INFO:root:eval perplexity: 5.075288772583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [7:43:29<7:47:13, 286.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3402.3392578125
INFO:root:current train perplexity3.803919792175293
INFO:root:current mean train loss 3410.5110670006793
INFO:root:current train perplexity3.822493314743042
INFO:root:current mean train loss 3411.583529024346
INFO:root:current train perplexity3.8362951278686523
INFO:root:current mean train loss 3426.595334201389
INFO:root:current train perplexity3.8511524200439453
INFO:root:current mean train loss 3433.182804263931
INFO:root:current train perplexity3.8579916954040527
INFO:root:current mean train loss 3428.6212023096177
INFO:root:current train perplexity3.8552589416503906
INFO:root:current mean train loss 3430.2742072376777
INFO:root:current train perplexity3.8585307598114014
INFO:root:current mean train loss 3427.927861054961
INFO:root:current train perplexity3.860110282897949
INFO:root:current mean train loss 3428.363382500959
INFO:root:current train perplexity3.863219738006592
INFO:root:current mean train loss 3429.7487939719945
INFO:root:current train perplexity3.866138458251953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4013.5206653784353
INFO:root:eval perplexity: 5.068018913269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [7:48:11<7:40:50, 285.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.725978685462
INFO:root:current train perplexity3.8095531463623047
INFO:root:current mean train loss 3414.6633221385923
INFO:root:current train perplexity3.830474615097046
INFO:root:current mean train loss 3420.0421826828756
INFO:root:current train perplexity3.8439552783966064
INFO:root:current mean train loss 3416.812360167134
INFO:root:current train perplexity3.8444721698760986
INFO:root:current mean train loss 3416.2352903830524
INFO:root:current train perplexity3.847332000732422
INFO:root:current mean train loss 3420.503113609883
INFO:root:current train perplexity3.8553719520568848
INFO:root:current mean train loss 3423.87860842195
INFO:root:current train perplexity3.8596506118774414
INFO:root:current mean train loss 3425.1882310711662
INFO:root:current train perplexity3.8622891902923584
INFO:root:current mean train loss 3425.8547404811857
INFO:root:current train perplexity3.862161636352539
INFO:root:current mean train loss 3426.78729955605
INFO:root:current train perplexity3.86120867729187


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4014.850324481937
INFO:root:eval perplexity: 5.07074499130249
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [7:53:02<7:38:43, 286.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.6871062247983
INFO:root:current train perplexity3.8069231510162354
INFO:root:current mean train loss 3395.892024615339
INFO:root:current train perplexity3.8264834880828857
INFO:root:current mean train loss 3392.553115910782
INFO:root:current train perplexity3.8334758281707764
INFO:root:current mean train loss 3403.293997681033
INFO:root:current train perplexity3.8443024158477783
INFO:root:current mean train loss 3404.245572614559
INFO:root:current train perplexity3.8433494567871094
INFO:root:current mean train loss 3409.5736440310147
INFO:root:current train perplexity3.846571683883667
INFO:root:current mean train loss 3414.9016759422047
INFO:root:current train perplexity3.8495349884033203
INFO:root:current mean train loss 3416.714634677454
INFO:root:current train perplexity3.8508522510528564
INFO:root:current mean train loss 3422.821674516772
INFO:root:current train perplexity3.856807231903076
INFO:root:current mean train loss 3422.997936998607
INFO:root:current train perplexity3.855553150177002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4014.776897024601
INFO:root:eval perplexity: 5.070592880249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [7:57:50<7:34:45, 287.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.4833233173076
INFO:root:current train perplexity3.848647117614746
INFO:root:current mean train loss 3417.803270079249
INFO:root:current train perplexity3.8417916297912598
INFO:root:current mean train loss 3412.704486671352
INFO:root:current train perplexity3.8431413173675537
INFO:root:current mean train loss 3422.442714094764
INFO:root:current train perplexity3.8454947471618652
INFO:root:current mean train loss 3418.875702947039
INFO:root:current train perplexity3.8426461219787598
INFO:root:current mean train loss 3418.21895790454
INFO:root:current train perplexity3.8432068824768066
INFO:root:current mean train loss 3421.3527984857933
INFO:root:current train perplexity3.8452837467193604
INFO:root:current mean train loss 3422.0177244772285
INFO:root:current train perplexity3.846606969833374
INFO:root:current mean train loss 3419.9512335648838
INFO:root:current train perplexity3.8465473651885986
INFO:root:current mean train loss 3419.33727728343
INFO:root:current train perplexity3.8480021953582764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it]
INFO:root:eval mean loss: 4017.357144835993
INFO:root:eval perplexity: 5.075886249542236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [8:02:39<7:30:50, 287.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.550303357713
INFO:root:current train perplexity3.790949583053589
INFO:root:current mean train loss 3388.9973260788693
INFO:root:current train perplexity3.8223652839660645
INFO:root:current mean train loss 3390.353129151379
INFO:root:current train perplexity3.818152904510498
INFO:root:current mean train loss 3395.271394317363
INFO:root:current train perplexity3.8256771564483643
INFO:root:current mean train loss 3401.555658600741
INFO:root:current train perplexity3.8252034187316895
INFO:root:current mean train loss 3408.408814592379
INFO:root:current train perplexity3.8309326171875
INFO:root:current mean train loss 3410.9781333770043
INFO:root:current train perplexity3.8337597846984863
INFO:root:current mean train loss 3409.9368113730966
INFO:root:current train perplexity3.8346056938171387
INFO:root:current mean train loss 3412.937579266437
INFO:root:current train perplexity3.8397953510284424
INFO:root:current mean train loss 3412.4929634907935
INFO:root:current train perplexity3.8401806354522705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it]
INFO:root:eval mean loss: 4018.8417189577794
INFO:root:eval perplexity: 5.078934192657471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [8:07:39<7:31:36, 291.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3397.7707075639205
INFO:root:current train perplexity3.8239586353302
INFO:root:current mean train loss 3401.6959661668348
INFO:root:current train perplexity3.8198208808898926
INFO:root:current mean train loss 3394.1608857996325
INFO:root:current train perplexity3.8204214572906494
INFO:root:current mean train loss 3404.0481961102555
INFO:root:current train perplexity3.8268134593963623
INFO:root:current mean train loss 3407.2954595209476
INFO:root:current train perplexity3.825270414352417
INFO:root:current mean train loss 3406.314572336008
INFO:root:current train perplexity3.829597234725952
INFO:root:current mean train loss 3406.4073570193227
INFO:root:current train perplexity3.832063674926758
INFO:root:current mean train loss 3409.4268205453227
INFO:root:current train perplexity3.8316967487335205
INFO:root:current mean train loss 3408.6758863304094
INFO:root:current train perplexity3.8316028118133545
INFO:root:current mean train loss 3411.5678414389727
INFO:root:current train perplexity3.8366293907165527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.46s/it]
INFO:root:eval mean loss: 4020.015264849291
INFO:root:eval perplexity: 5.08134651184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [8:12:48<7:34:38, 296.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.3149220300097
INFO:root:current train perplexity3.811429262161255
INFO:root:current mean train loss 3377.8187233392446
INFO:root:current train perplexity3.824108123779297
INFO:root:current mean train loss 3384.6147163884266
INFO:root:current train perplexity3.818002223968506
INFO:root:current mean train loss 3393.370201930527
INFO:root:current train perplexity3.8255362510681152
INFO:root:current mean train loss 3397.2603746583086
INFO:root:current train perplexity3.8196823596954346
INFO:root:current mean train loss 3401.018128850744
INFO:root:current train perplexity3.8233368396759033
INFO:root:current mean train loss 3402.832443674585
INFO:root:current train perplexity3.822979688644409
INFO:root:current mean train loss 3403.4736680097067
INFO:root:current train perplexity3.8235366344451904
INFO:root:current mean train loss 3403.0499540574306
INFO:root:current train perplexity3.8252289295196533
INFO:root:current mean train loss 3405.361619420512
INFO:root:current train perplexity3.829010486602783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.09s/it]
INFO:root:eval mean loss: 4019.325285350177
INFO:root:eval perplexity: 5.079928398132324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [8:17:41<7:28:29, 295.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3382.096418353873
INFO:root:current train perplexity3.7936856746673584
INFO:root:current mean train loss 3378.0513751827484
INFO:root:current train perplexity3.8031792640686035
INFO:root:current mean train loss 3382.6477059790127
INFO:root:current train perplexity3.808537006378174
INFO:root:current mean train loss 3388.410281939648
INFO:root:current train perplexity3.806042432785034
INFO:root:current mean train loss 3392.2634023354562
INFO:root:current train perplexity3.8144078254699707
INFO:root:current mean train loss 3395.6600540615423
INFO:root:current train perplexity3.8200366497039795
INFO:root:current mean train loss 3396.9954421019233
INFO:root:current train perplexity3.8212168216705322
INFO:root:current mean train loss 3398.769328274461
INFO:root:current train perplexity3.821892023086548
INFO:root:current mean train loss 3400.151499208435
INFO:root:current train perplexity3.822962760925293
INFO:root:current mean train loss 3402.437688322686
INFO:root:current train perplexity3.8257455825805664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4022.49654566988
INFO:root:eval perplexity: 5.086446762084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [8:22:35<7:22:31, 295.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3385.4619480567644
INFO:root:current train perplexity3.7901065349578857
INFO:root:current mean train loss 3389.58814976868
INFO:root:current train perplexity3.792736530303955
INFO:root:current mean train loss 3396.7362519951275
INFO:root:current train perplexity3.8063600063323975
INFO:root:current mean train loss 3398.0862763336904
INFO:root:current train perplexity3.810264825820923
INFO:root:current mean train loss 3399.8736335260633
INFO:root:current train perplexity3.8080379962921143
INFO:root:current mean train loss 3396.0458170572915
INFO:root:current train perplexity3.8044416904449463
INFO:root:current mean train loss 3397.7170607913754
INFO:root:current train perplexity3.807380199432373
INFO:root:current mean train loss 3394.927655397545
INFO:root:current train perplexity3.80932879447937
INFO:root:current mean train loss 3394.9013060829066
INFO:root:current train perplexity3.8132128715515137
INFO:root:current mean train loss 3396.402943752394
INFO:root:current train perplexity3.815531015396118


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4020.1243333748894
INFO:root:eval perplexity: 5.081570625305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [8:27:22<7:14:08, 292.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.335109666846
INFO:root:current train perplexity3.7961416244506836
INFO:root:current mean train loss 3393.2941215637534
INFO:root:current train perplexity3.7979414463043213
INFO:root:current mean train loss 3391.868347805967
INFO:root:current train perplexity3.80338191986084
INFO:root:current mean train loss 3388.1597998173047
INFO:root:current train perplexity3.7980690002441406
INFO:root:current mean train loss 3387.8246233115697
INFO:root:current train perplexity3.8022680282592773
INFO:root:current mean train loss 3388.0332821483707
INFO:root:current train perplexity3.805326223373413
INFO:root:current mean train loss 3392.488668960949
INFO:root:current train perplexity3.809722900390625
INFO:root:current mean train loss 3390.7807068103757
INFO:root:current train perplexity3.8104543685913086
INFO:root:current mean train loss 3392.648998445427
INFO:root:current train perplexity3.8110861778259277
INFO:root:current mean train loss 3393.424213506047
INFO:root:current train perplexity3.8102176189422607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4025.0998240802305
INFO:root:eval perplexity: 5.0918049812316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [8:32:15<7:09:14, 292.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.7032509251644
INFO:root:current train perplexity3.783872604370117
INFO:root:current mean train loss 3361.513948567708
INFO:root:current train perplexity3.789316415786743
INFO:root:current mean train loss 3369.39403055482
INFO:root:current train perplexity3.7897603511810303
INFO:root:current mean train loss 3379.4013851117484
INFO:root:current train perplexity3.7985849380493164
INFO:root:current mean train loss 3380.007772549716
INFO:root:current train perplexity3.7985119819641113
INFO:root:current mean train loss 3378.822812171744
INFO:root:current train perplexity3.797166347503662
INFO:root:current mean train loss 3382.1786909144557
INFO:root:current train perplexity3.7998275756835938
INFO:root:current mean train loss 3385.725217730444
INFO:root:current train perplexity3.802762269973755
INFO:root:current mean train loss 3387.054213130674
INFO:root:current train perplexity3.8045709133148193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it]
INFO:root:eval mean loss: 4027.1394700936394
INFO:root:eval perplexity: 5.096004486083984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [8:37:06<7:03:34, 292.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.3878580729165
INFO:root:current train perplexity3.7847201824188232
INFO:root:current mean train loss 3357.235180901092
INFO:root:current train perplexity3.765197515487671
INFO:root:current mean train loss 3375.5086699988456
INFO:root:current train perplexity3.786139488220215
INFO:root:current mean train loss 3374.812449238088
INFO:root:current train perplexity3.787363290786743
INFO:root:current mean train loss 3375.385737946844
INFO:root:current train perplexity3.7899410724639893
INFO:root:current mean train loss 3380.4242853426317
INFO:root:current train perplexity3.7944817543029785
INFO:root:current mean train loss 3381.7119205405265
INFO:root:current train perplexity3.7951114177703857
INFO:root:current mean train loss 3382.510757467994
INFO:root:current train perplexity3.7960402965545654
INFO:root:current mean train loss 3385.8837349441546
INFO:root:current train perplexity3.79921555519104
INFO:root:current mean train loss 3384.525632602696
INFO:root:current train perplexity3.7963762283325195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.83s/it]
INFO:root:eval mean loss: 4024.231640971299
INFO:root:eval perplexity: 5.090017318725586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [8:42:02<7:00:21, 293.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.0937056107955
INFO:root:current train perplexity3.7675492763519287
INFO:root:current mean train loss 3370.6263790646117
INFO:root:current train perplexity3.7985730171203613
INFO:root:current mean train loss 3369.537702949126
INFO:root:current train perplexity3.7961208820343018
INFO:root:current mean train loss 3377.180515694082
INFO:root:current train perplexity3.7936251163482666
INFO:root:current mean train loss 3378.1843077573753
INFO:root:current train perplexity3.7925820350646973
INFO:root:current mean train loss 3375.8932231149097
INFO:root:current train perplexity3.7904694080352783
INFO:root:current mean train loss 3381.3743019416174
INFO:root:current train perplexity3.789611339569092
INFO:root:current mean train loss 3380.0700027744815
INFO:root:current train perplexity3.7898850440979004
INFO:root:current mean train loss 3378.028912752389
INFO:root:current train perplexity3.7884409427642822
INFO:root:current mean train loss 3379.7603865622427
INFO:root:current train perplexity3.7900590896606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4027.8777721215647
INFO:root:eval perplexity: 5.097527980804443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [8:46:52<6:54:15, 292.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3326.0912957442433
INFO:root:current train perplexity3.739870309829712
INFO:root:current mean train loss 3342.6125590861343
INFO:root:current train perplexity3.7659668922424316
INFO:root:current mean train loss 3360.5331340075627
INFO:root:current train perplexity3.7724335193634033
INFO:root:current mean train loss 3367.3785503710324
INFO:root:current train perplexity3.7764892578125
INFO:root:current mean train loss 3367.5603615845016
INFO:root:current train perplexity3.773568630218506
INFO:root:current mean train loss 3370.3948845247774
INFO:root:current train perplexity3.773998260498047
INFO:root:current mean train loss 3372.3679092727684
INFO:root:current train perplexity3.7781450748443604
INFO:root:current mean train loss 3376.466980574691
INFO:root:current train perplexity3.7811148166656494
INFO:root:current mean train loss 3376.709249680441
INFO:root:current train perplexity3.7817909717559814
INFO:root:current mean train loss 3374.7128467912644
INFO:root:current train perplexity3.7834725379943848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4027.3916621647827
INFO:root:eval perplexity: 5.096525192260742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [8:51:43<6:48:46, 291.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3381.4758029513887
INFO:root:current train perplexity3.7889392375946045
INFO:root:current mean train loss 3377.1572265625
INFO:root:current train perplexity3.774296998977661
INFO:root:current mean train loss 3374.1468844644824
INFO:root:current train perplexity3.7689735889434814
INFO:root:current mean train loss 3368.44830863556
INFO:root:current train perplexity3.7685649394989014
INFO:root:current mean train loss 3372.3846061045447
INFO:root:current train perplexity3.774193525314331
INFO:root:current mean train loss 3372.3916946787535
INFO:root:current train perplexity3.7738256454467773
INFO:root:current mean train loss 3372.6879193611694
INFO:root:current train perplexity3.773973226547241
INFO:root:current mean train loss 3373.0667094948203
INFO:root:current train perplexity3.776326894760132
INFO:root:current mean train loss 3372.6439907161616
INFO:root:current train perplexity3.77671217918396
INFO:root:current mean train loss 3373.4917850761867
INFO:root:current train perplexity3.78052020072937


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 4029.4483737810283
INFO:root:eval perplexity: 5.100765228271484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [8:56:37<6:44:47, 292.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.5614885602677
INFO:root:current train perplexity3.749213933944702
INFO:root:current mean train loss 3359.966315827546
INFO:root:current train perplexity3.747466802597046
INFO:root:current mean train loss 3359.119598778258
INFO:root:current train perplexity3.7578108310699463
INFO:root:current mean train loss 3365.6385559993005
INFO:root:current train perplexity3.7636923789978027
INFO:root:current mean train loss 3368.3982623922416
INFO:root:current train perplexity3.765604019165039
INFO:root:current mean train loss 3367.8871563777743
INFO:root:current train perplexity3.7662596702575684
INFO:root:current mean train loss 3367.706270761565
INFO:root:current train perplexity3.770014762878418
INFO:root:current mean train loss 3369.4299479166666
INFO:root:current train perplexity3.770583391189575
INFO:root:current mean train loss 3369.2589147876124
INFO:root:current train perplexity3.772151470184326
INFO:root:current mean train loss 3369.559339749749
INFO:root:current train perplexity3.7746970653533936


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4031.6941801030584
INFO:root:eval perplexity: 5.1053996086120605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [9:01:31<6:40:25, 292.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.9803835846656
INFO:root:current train perplexity3.7517905235290527
INFO:root:current mean train loss 3352.169402862762
INFO:root:current train perplexity3.7469589710235596
INFO:root:current mean train loss 3352.7052438994983
INFO:root:current train perplexity3.753701686859131
INFO:root:current mean train loss 3357.122466774098
INFO:root:current train perplexity3.75653076171875
INFO:root:current mean train loss 3362.6913164194766
INFO:root:current train perplexity3.7575318813323975
INFO:root:current mean train loss 3362.401140581837
INFO:root:current train perplexity3.757594585418701
INFO:root:current mean train loss 3364.838503824237
INFO:root:current train perplexity3.7627170085906982
INFO:root:current mean train loss 3365.52381669015
INFO:root:current train perplexity3.7648777961730957
INFO:root:current mean train loss 3363.720063088486
INFO:root:current train perplexity3.768009662628174
INFO:root:current mean train loss 3364.5103111226636
INFO:root:current train perplexity3.7676987648010254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it]
INFO:root:eval mean loss: 4032.4823093279033
INFO:root:eval perplexity: 5.107027530670166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [9:05:50<6:21:51, 282.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.7033930759803
INFO:root:current train perplexity3.759564161300659
INFO:root:current mean train loss 3351.5593374896525
INFO:root:current train perplexity3.7493114471435547
INFO:root:current mean train loss 3348.9618391667705
INFO:root:current train perplexity3.7530055046081543
INFO:root:current mean train loss 3344.8645770733174
INFO:root:current train perplexity3.7532310485839844
INFO:root:current mean train loss 3346.9230854178213
INFO:root:current train perplexity3.7534801959991455
INFO:root:current mean train loss 3351.0450654350047
INFO:root:current train perplexity3.754232883453369
INFO:root:current mean train loss 3355.9436755202332
INFO:root:current train perplexity3.7581961154937744
INFO:root:current mean train loss 3360.003744031396
INFO:root:current train perplexity3.7617456912994385
INFO:root:current mean train loss 3359.1381210524382
INFO:root:current train perplexity3.7617347240448
INFO:root:current mean train loss 3361.350143352392
INFO:root:current train perplexity3.763232469558716


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4036.062551944814
INFO:root:eval perplexity: 5.114427089691162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [9:10:38<6:19:12, 284.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.5384831832625
INFO:root:current train perplexity3.7314743995666504
INFO:root:current mean train loss 3339.774496978184
INFO:root:current train perplexity3.7341887950897217
INFO:root:current mean train loss 3341.145406008687
INFO:root:current train perplexity3.7318379878997803
INFO:root:current mean train loss 3347.7968219555187
INFO:root:current train perplexity3.743065118789673
INFO:root:current mean train loss 3349.9538068916804
INFO:root:current train perplexity3.747620105743408
INFO:root:current mean train loss 3348.294406515541
INFO:root:current train perplexity3.7508273124694824
INFO:root:current mean train loss 3353.596766748269
INFO:root:current train perplexity3.7544431686401367
INFO:root:current mean train loss 3356.6164795243535
INFO:root:current train perplexity3.757873058319092
INFO:root:current mean train loss 3358.686311413162
INFO:root:current train perplexity3.758870840072632
INFO:root:current mean train loss 3358.384349389419
INFO:root:current train perplexity3.7585904598236084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4034.2401529947915
INFO:root:eval perplexity: 5.110659122467041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [9:15:31<6:17:45, 286.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.410498775653
INFO:root:current train perplexity3.7498326301574707
INFO:root:current mean train loss 3349.5017382227734
INFO:root:current train perplexity3.747633934020996
INFO:root:current mean train loss 3343.7837005500937
INFO:root:current train perplexity3.7383978366851807
INFO:root:current mean train loss 3342.1881738813436
INFO:root:current train perplexity3.7395315170288086
INFO:root:current mean train loss 3346.5875006273423
INFO:root:current train perplexity3.7393994331359863
INFO:root:current mean train loss 3345.5874695147154
INFO:root:current train perplexity3.7393553256988525
INFO:root:current mean train loss 3348.755236029446
INFO:root:current train perplexity3.741670846939087
INFO:root:current mean train loss 3348.412479883067
INFO:root:current train perplexity3.7424583435058594
INFO:root:current mean train loss 3350.5485490669153
INFO:root:current train perplexity3.7445449829101562
INFO:root:current mean train loss 3353.3429282029633
INFO:root:current train perplexity3.7497141361236572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4034.0353796126997
INFO:root:eval perplexity: 5.110235691070557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [9:19:44<5:59:52, 276.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.91845703125
INFO:root:current train perplexity3.734224557876587
INFO:root:current mean train loss 3334.8955845424107
INFO:root:current train perplexity3.744375228881836
INFO:root:current mean train loss 3344.1752592329544
INFO:root:current train perplexity3.7474212646484375
INFO:root:current mean train loss 3344.840056640625
INFO:root:current train perplexity3.7436795234680176
INFO:root:current mean train loss 3349.080083264803
INFO:root:current train perplexity3.7470688819885254
INFO:root:current mean train loss 3350.167735224185
INFO:root:current train perplexity3.744981050491333
INFO:root:current mean train loss 3351.081117621528
INFO:root:current train perplexity3.745703935623169
INFO:root:current mean train loss 3352.065187436996
INFO:root:current train perplexity3.7471282482147217
INFO:root:current mean train loss 3351.0648172433034
INFO:root:current train perplexity3.7469570636749268
INFO:root:current mean train loss 3350.974353215144
INFO:root:current train perplexity3.747474431991577


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 4036.528500387855
INFO:root:eval perplexity: 5.115390777587891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [9:23:54<5:44:41, 268.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3329.8224038733056
INFO:root:current train perplexity3.7346019744873047
INFO:root:current mean train loss 3321.871891542862
INFO:root:current train perplexity3.729062557220459
INFO:root:current mean train loss 3328.2562268799693
INFO:root:current train perplexity3.7281203269958496
INFO:root:current mean train loss 3338.2790113005876
INFO:root:current train perplexity3.7376818656921387
INFO:root:current mean train loss 3340.11041676776
INFO:root:current train perplexity3.741508960723877
INFO:root:current mean train loss 3349.15302005722
INFO:root:current train perplexity3.7434957027435303
INFO:root:current mean train loss 3350.6929765424825
INFO:root:current train perplexity3.743893623352051
INFO:root:current mean train loss 3348.5897944853527
INFO:root:current train perplexity3.7404658794403076
INFO:root:current mean train loss 3348.626154069047
INFO:root:current train perplexity3.742450714111328
INFO:root:current mean train loss 3348.724161825248
INFO:root:current train perplexity3.743771553039551


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 4036.400046057735
INFO:root:eval perplexity: 5.115123748779297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [9:27:58<5:31:11, 261.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.8235963255493
INFO:root:current train perplexity3.6831791400909424
INFO:root:current mean train loss 3337.1774493312337
INFO:root:current train perplexity3.7213547229766846
INFO:root:current mean train loss 3340.900768162049
INFO:root:current train perplexity3.726031541824341
INFO:root:current mean train loss 3342.1295743586156
INFO:root:current train perplexity3.725379467010498
INFO:root:current mean train loss 3340.845703125
INFO:root:current train perplexity3.7262496948242188
INFO:root:current mean train loss 3343.823550358238
INFO:root:current train perplexity3.7327592372894287
INFO:root:current mean train loss 3345.2218952096146
INFO:root:current train perplexity3.734158515930176
INFO:root:current mean train loss 3347.2172030558627
INFO:root:current train perplexity3.734333038330078
INFO:root:current mean train loss 3345.5912918792965
INFO:root:current train perplexity3.7372679710388184
INFO:root:current mean train loss 3344.924042209968
INFO:root:current train perplexity3.738253593444824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it]
INFO:root:eval mean loss: 4038.0576708638077
INFO:root:eval perplexity: 5.11855411529541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [9:32:48<5:37:26, 269.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.245457504735
INFO:root:current train perplexity3.732874631881714
INFO:root:current mean train loss 3332.3500915220634
INFO:root:current train perplexity3.727611780166626
INFO:root:current mean train loss 3336.0978277200043
INFO:root:current train perplexity3.7294528484344482
INFO:root:current mean train loss 3334.6160469533206
INFO:root:current train perplexity3.7265625
INFO:root:current mean train loss 3335.193129912168
INFO:root:current train perplexity3.7254905700683594
INFO:root:current mean train loss 3336.945109117409
INFO:root:current train perplexity3.7250020503997803
INFO:root:current mean train loss 3336.491397448364
INFO:root:current train perplexity3.7266294956207275
INFO:root:current mean train loss 3339.4039247056867
INFO:root:current train perplexity3.7287540435791016
INFO:root:current mean train loss 3341.1461030919772
INFO:root:current train perplexity3.7326979637145996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4039.631655862145
INFO:root:eval perplexity: 5.12181282043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [9:37:39<5:40:50, 276.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.2721121651784
INFO:root:current train perplexity3.7780847549438477
INFO:root:current mean train loss 3326.577552296291
INFO:root:current train perplexity3.715078353881836
INFO:root:current mean train loss 3330.689448407307
INFO:root:current train perplexity3.71528697013855
INFO:root:current mean train loss 3331.567308854591
INFO:root:current train perplexity3.7184226512908936
INFO:root:current mean train loss 3324.919059884636
INFO:root:current train perplexity3.7187581062316895
INFO:root:current mean train loss 3329.927663588665
INFO:root:current train perplexity3.7226693630218506
INFO:root:current mean train loss 3331.7802533270697
INFO:root:current train perplexity3.721717596054077
INFO:root:current mean train loss 3335.540877497348
INFO:root:current train perplexity3.7255918979644775
INFO:root:current mean train loss 3337.237577870876
INFO:root:current train perplexity3.727343797683716
INFO:root:current mean train loss 3337.2225859956416
INFO:root:current train perplexity3.7258031368255615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4041.66761725676
INFO:root:eval perplexity: 5.126030921936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [9:42:29<5:40:55, 280.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.461376953125
INFO:root:current train perplexity3.737175226211548
INFO:root:current mean train loss 3312.9111009680705
INFO:root:current train perplexity3.7285473346710205
INFO:root:current mean train loss 3320.9479889625727
INFO:root:current train perplexity3.7289304733276367
INFO:root:current mean train loss 3326.03667999752
INFO:root:current train perplexity3.720952272415161
INFO:root:current mean train loss 3328.0715373211597
INFO:root:current train perplexity3.7187142372131348
INFO:root:current mean train loss 3327.3010922330095
INFO:root:current train perplexity3.7194621562957764
INFO:root:current mean train loss 3329.0547156853404
INFO:root:current train perplexity3.717921733856201
INFO:root:current mean train loss 3330.416603952688
INFO:root:current train perplexity3.719402313232422
INFO:root:current mean train loss 3330.6611840370974
INFO:root:current train perplexity3.7190747261047363
INFO:root:current mean train loss 3333.121668481045
INFO:root:current train perplexity3.7224345207214355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4041.961250900377
INFO:root:eval perplexity: 5.126639366149902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [9:47:17<5:39:21, 282.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.5238620923915
INFO:root:current train perplexity3.693331718444824
INFO:root:current mean train loss 3331.166273659807
INFO:root:current train perplexity3.7112374305725098
INFO:root:current mean train loss 3329.6385153184556
INFO:root:current train perplexity3.711657762527466
INFO:root:current mean train loss 3331.9555286135837
INFO:root:current train perplexity3.7216873168945312
INFO:root:current mean train loss 3329.8034777630023
INFO:root:current train perplexity3.715519905090332
INFO:root:current mean train loss 3328.3837685229446
INFO:root:current train perplexity3.7173447608947754
INFO:root:current mean train loss 3329.881074908457
INFO:root:current train perplexity3.718794584274292
INFO:root:current mean train loss 3330.790777900242
INFO:root:current train perplexity3.719303846359253
INFO:root:current mean train loss 3329.0908146762035
INFO:root:current train perplexity3.7172985076904297
INFO:root:current mean train loss 3329.9856025803256
INFO:root:current train perplexity3.717146635055542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 4041.576994334552
INFO:root:eval perplexity: 5.125843524932861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [9:51:30<5:23:50, 273.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.6748913180445
INFO:root:current train perplexity3.6789984703063965
INFO:root:current mean train loss 3318.3974348461356
INFO:root:current train perplexity3.702326774597168
INFO:root:current mean train loss 3330.389695997362
INFO:root:current train perplexity3.7137348651885986
INFO:root:current mean train loss 3329.668921709781
INFO:root:current train perplexity3.7132911682128906
INFO:root:current mean train loss 3326.8923826992095
INFO:root:current train perplexity3.714630126953125
INFO:root:current mean train loss 3328.7936781831154
INFO:root:current train perplexity3.717693567276001
INFO:root:current mean train loss 3327.8856114116975
INFO:root:current train perplexity3.7137959003448486
INFO:root:current mean train loss 3329.1377711263467
INFO:root:current train perplexity3.713740110397339
INFO:root:current mean train loss 3326.084170638726
INFO:root:current train perplexity3.7115113735198975
INFO:root:current mean train loss 3325.5661353614223
INFO:root:current train perplexity3.7104132175445557


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 4044.704208915115
INFO:root:eval perplexity: 5.13232946395874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [9:57:01<5:39:24, 290.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.809044471154
INFO:root:current train perplexity3.7038848400115967
INFO:root:current mean train loss 3327.693561361848
INFO:root:current train perplexity3.713620185852051
INFO:root:current mean train loss 3324.9909330870814
INFO:root:current train perplexity3.7060816287994385
INFO:root:current mean train loss 3325.6127483176624
INFO:root:current train perplexity3.706943988800049
INFO:root:current mean train loss 3325.518473492668
INFO:root:current train perplexity3.7094337940216064
INFO:root:current mean train loss 3319.1439917852795
INFO:root:current train perplexity3.7064266204833984
INFO:root:current mean train loss 3319.317919234155
INFO:root:current train perplexity3.707123041152954
INFO:root:current mean train loss 3319.724494407561
INFO:root:current train perplexity3.7051892280578613
INFO:root:current mean train loss 3324.3083781263967
INFO:root:current train perplexity3.7087416648864746
INFO:root:current mean train loss 3324.4654368115184
INFO:root:current train perplexity3.7095894813537598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it]
INFO:root:eval mean loss: 4044.2540274545654
INFO:root:eval perplexity: 5.131394386291504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [10:01:55<5:35:44, 291.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.735294423205
INFO:root:current train perplexity3.7005455493927
INFO:root:current mean train loss 3316.2143886851613
INFO:root:current train perplexity3.692962646484375
INFO:root:current mean train loss 3317.477065607604
INFO:root:current train perplexity3.704242467880249
INFO:root:current mean train loss 3314.1953462716137
INFO:root:current train perplexity3.694206476211548
INFO:root:current mean train loss 3316.641834779607
INFO:root:current train perplexity3.6955223083496094
INFO:root:current mean train loss 3317.519381284278
INFO:root:current train perplexity3.696685791015625
INFO:root:current mean train loss 3317.9457362556755
INFO:root:current train perplexity3.699495315551758
INFO:root:current mean train loss 3318.6528130752176
INFO:root:current train perplexity3.700742244720459
INFO:root:current mean train loss 3317.926064014998
INFO:root:current train perplexity3.7000837326049805
INFO:root:current mean train loss 3319.519734141945
INFO:root:current train perplexity3.7012157440185547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4044.9891521913787
INFO:root:eval perplexity: 5.132920742034912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [10:06:54<5:33:12, 294.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.969211647727
INFO:root:current train perplexity3.6804702281951904
INFO:root:current mean train loss 3294.156876890121
INFO:root:current train perplexity3.6891047954559326
INFO:root:current mean train loss 3295.9323347503064
INFO:root:current train perplexity3.6916606426239014
INFO:root:current mean train loss 3297.1486541318222
INFO:root:current train perplexity3.685300350189209
INFO:root:current mean train loss 3302.953632061298
INFO:root:current train perplexity3.686922788619995
INFO:root:current mean train loss 3306.1046514287727
INFO:root:current train perplexity3.6885159015655518
INFO:root:current mean train loss 3308.2732011867843
INFO:root:current train perplexity3.6921510696411133
INFO:root:current mean train loss 3310.554781275869
INFO:root:current train perplexity3.693615198135376
INFO:root:current mean train loss 3313.957154890808
INFO:root:current train perplexity3.6953632831573486
INFO:root:current mean train loss 3316.0568502535994
INFO:root:current train perplexity3.6979613304138184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4047.251496010638
INFO:root:eval perplexity: 5.137618541717529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [10:11:42<5:26:13, 292.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.253142826141
INFO:root:current train perplexity3.693227767944336
INFO:root:current mean train loss 3299.610633148006
INFO:root:current train perplexity3.685335159301758
INFO:root:current mean train loss 3305.280066428529
INFO:root:current train perplexity3.6910128593444824
INFO:root:current mean train loss 3309.0578209743026
INFO:root:current train perplexity3.6939849853515625
INFO:root:current mean train loss 3311.096768274163
INFO:root:current train perplexity3.6927061080932617
INFO:root:current mean train loss 3317.634333717251
INFO:root:current train perplexity3.6947028636932373
INFO:root:current mean train loss 3314.228092521564
INFO:root:current train perplexity3.6907713413238525
INFO:root:current mean train loss 3312.816348014622
INFO:root:current train perplexity3.6902623176574707
INFO:root:current mean train loss 3312.806140462051
INFO:root:current train perplexity3.6912026405334473
INFO:root:current mean train loss 3314.681643160209
INFO:root:current train perplexity3.693547010421753


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.67s/it]
INFO:root:eval mean loss: 4048.7989735704787
INFO:root:eval perplexity: 5.140834331512451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [10:16:36<5:21:49, 292.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.933019503741
INFO:root:current train perplexity3.694411277770996
INFO:root:current mean train loss 3295.021974083973
INFO:root:current train perplexity3.669506788253784
INFO:root:current mean train loss 3296.0607126383766
INFO:root:current train perplexity3.6721792221069336
INFO:root:current mean train loss 3299.5489742145382
INFO:root:current train perplexity3.676149368286133
INFO:root:current mean train loss 3303.855573974091
INFO:root:current train perplexity3.6806631088256836
INFO:root:current mean train loss 3309.8767299351466
INFO:root:current train perplexity3.6834864616394043
INFO:root:current mean train loss 3313.592023187174
INFO:root:current train perplexity3.6896488666534424
INFO:root:current mean train loss 3311.4217173060556
INFO:root:current train perplexity3.688169479370117
INFO:root:current mean train loss 3312.0317660308733
INFO:root:current train perplexity3.6894495487213135
INFO:root:current mean train loss 3310.715396397882
INFO:root:current train perplexity3.6882565021514893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4047.4388419076904
INFO:root:eval perplexity: 5.138008117675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [10:21:17<5:13:17, 289.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.1168846420096
INFO:root:current train perplexity3.675774574279785
INFO:root:current mean train loss 3302.3158647760997
INFO:root:current train perplexity3.6890528202056885
INFO:root:current mean train loss 3302.2021528127802
INFO:root:current train perplexity3.683856725692749
INFO:root:current mean train loss 3307.0830535486066
INFO:root:current train perplexity3.685946226119995
INFO:root:current mean train loss 3309.3576405312174
INFO:root:current train perplexity3.6866402626037598
INFO:root:current mean train loss 3310.6128216415696
INFO:root:current train perplexity3.686263084411621
INFO:root:current mean train loss 3313.1875474618005
INFO:root:current train perplexity3.6863412857055664
INFO:root:current mean train loss 3313.198661520178
INFO:root:current train perplexity3.6853013038635254
INFO:root:current mean train loss 3311.8388991285374
INFO:root:current train perplexity3.6854119300842285
INFO:root:current mean train loss 3309.002130183063
INFO:root:current train perplexity3.6852147579193115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4050.0612810283687
INFO:root:eval perplexity: 5.143459320068359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [10:25:27<4:56:01, 277.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3284.2583512931033
INFO:root:current train perplexity3.66894268989563
INFO:root:current mean train loss 3299.927120759525
INFO:root:current train perplexity3.6769113540649414
INFO:root:current mean train loss 3299.2747100936413
INFO:root:current train perplexity3.6749680042266846
INFO:root:current mean train loss 3306.488575858971
INFO:root:current train perplexity3.6798033714294434
INFO:root:current mean train loss 3309.809962842499
INFO:root:current train perplexity3.6817173957824707
INFO:root:current mean train loss 3309.105289907634
INFO:root:current train perplexity3.6799774169921875
INFO:root:current mean train loss 3308.6942058713157
INFO:root:current train perplexity3.680422782897949
INFO:root:current mean train loss 3305.550181911134
INFO:root:current train perplexity3.67842435836792
INFO:root:current mean train loss 3305.3145392760885
INFO:root:current train perplexity3.6789917945861816
INFO:root:current mean train loss 3306.35933863863
INFO:root:current train perplexity3.682154417037964


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.25s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4051.763800005541
INFO:root:eval perplexity: 5.147001266479492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [10:29:36<4:42:13, 268.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.9128854851974
INFO:root:current train perplexity3.6581292152404785
INFO:root:current mean train loss 3294.412280899439
INFO:root:current train perplexity3.662092685699463
INFO:root:current mean train loss 3297.5090530654134
INFO:root:current train perplexity3.6688311100006104
INFO:root:current mean train loss 3298.6036151354824
INFO:root:current train perplexity3.673677682876587
INFO:root:current mean train loss 3297.7485548847853
INFO:root:current train perplexity3.674858570098877
INFO:root:current mean train loss 3299.981360376182
INFO:root:current train perplexity3.676788806915283
INFO:root:current mean train loss 3298.1266857997975
INFO:root:current train perplexity3.67502498626709
INFO:root:current mean train loss 3302.229667845912
INFO:root:current train perplexity3.6788651943206787
INFO:root:current mean train loss 3302.259032930342
INFO:root:current train perplexity3.6775479316711426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it]
INFO:root:eval mean loss: 4053.268952931073
INFO:root:eval perplexity: 5.150135517120361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [10:33:44<4:31:26, 262.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.6011555989585
INFO:root:current train perplexity3.530094861984253
INFO:root:current mean train loss 3270.7365746359224
INFO:root:current train perplexity3.6337890625
INFO:root:current mean train loss 3275.4322263219674
INFO:root:current train perplexity3.64212965965271
INFO:root:current mean train loss 3283.7257849564253
INFO:root:current train perplexity3.6549811363220215
INFO:root:current mean train loss 3289.9559268620114
INFO:root:current train perplexity3.6552231311798096
INFO:root:current mean train loss 3291.9288968338406
INFO:root:current train perplexity3.6569838523864746
INFO:root:current mean train loss 3293.7863660214553
INFO:root:current train perplexity3.65938401222229
INFO:root:current mean train loss 3294.5962483608196
INFO:root:current train perplexity3.6626856327056885
INFO:root:current mean train loss 3297.5778848118384
INFO:root:current train perplexity3.6664412021636963
INFO:root:current mean train loss 3298.26516754049
INFO:root:current train perplexity3.6692583560943604


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it]
INFO:root:eval mean loss: 4053.7344286763077
INFO:root:eval perplexity: 5.15110445022583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [10:37:51<4:22:15, 257.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.950350674716
INFO:root:current train perplexity3.5958237648010254
INFO:root:current mean train loss 3288.510278100366
INFO:root:current train perplexity3.659193515777588
INFO:root:current mean train loss 3287.5906432816205
INFO:root:current train perplexity3.653456211090088
INFO:root:current mean train loss 3277.6474962633138
INFO:root:current train perplexity3.642943859100342
INFO:root:current mean train loss 3283.517168847894
INFO:root:current train perplexity3.649688243865967
INFO:root:current mean train loss 3285.7322025784306
INFO:root:current train perplexity3.6579055786132812
INFO:root:current mean train loss 3288.3684010107663
INFO:root:current train perplexity3.658722400665283
INFO:root:current mean train loss 3291.9126598073794
INFO:root:current train perplexity3.660597801208496
INFO:root:current mean train loss 3294.4705390600916
INFO:root:current train perplexity3.665825605392456
INFO:root:current mean train loss 3297.482388376012
INFO:root:current train perplexity3.668064832687378


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.87s/it]
INFO:root:eval mean loss: 4054.8037247894504
INFO:root:eval perplexity: 5.153332233428955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [10:42:01<4:15:31, 255.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.7969777960525
INFO:root:current train perplexity3.6482996940612793
INFO:root:current mean train loss 3269.096942292542
INFO:root:current train perplexity3.642592430114746
INFO:root:current mean train loss 3272.031902156464
INFO:root:current train perplexity3.656764268875122
INFO:root:current mean train loss 3279.9003921556623
INFO:root:current train perplexity3.6575393676757812
INFO:root:current mean train loss 3283.0253824675565
INFO:root:current train perplexity3.657839775085449
INFO:root:current mean train loss 3286.3338851193703
INFO:root:current train perplexity3.659764528274536
INFO:root:current mean train loss 3285.2031186894183
INFO:root:current train perplexity3.6589505672454834
INFO:root:current mean train loss 3288.4427787345708
INFO:root:current train perplexity3.66062068939209
INFO:root:current mean train loss 3290.400455013736
INFO:root:current train perplexity3.6618199348449707
INFO:root:current mean train loss 3291.9542049038528
INFO:root:current train perplexity3.6617801189422607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4054.442289311835
INFO:root:eval perplexity: 5.152578353881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [10:46:11<4:09:47, 254.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.3959689670137
INFO:root:current train perplexity3.660149335861206
INFO:root:current mean train loss 3283.4035759873277
INFO:root:current train perplexity3.6598145961761475
INFO:root:current mean train loss 3283.7013202952917
INFO:root:current train perplexity3.658801317214966
INFO:root:current mean train loss 3285.1950825449157
INFO:root:current train perplexity3.66266131401062
INFO:root:current mean train loss 3289.272585580723
INFO:root:current train perplexity3.661773681640625
INFO:root:current mean train loss 3289.5063847174456
INFO:root:current train perplexity3.6598172187805176
INFO:root:current mean train loss 3290.43484326717
INFO:root:current train perplexity3.661712169647217
INFO:root:current mean train loss 3290.033645734826
INFO:root:current train perplexity3.6611993312835693
INFO:root:current mean train loss 3291.023148782308
INFO:root:current train perplexity3.662808418273926
INFO:root:current mean train loss 3290.5267374806162
INFO:root:current train perplexity3.6602532863616943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4057.23915738586
INFO:root:eval perplexity: 5.158409595489502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [10:50:18<4:03:23, 251.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.2453404017856
INFO:root:current train perplexity3.651883840560913
INFO:root:current mean train loss 3313.396117259838
INFO:root:current train perplexity3.646662950515747
INFO:root:current mean train loss 3301.93085106383
INFO:root:current train perplexity3.6481196880340576
INFO:root:current mean train loss 3300.7008322644588
INFO:root:current train perplexity3.6513566970825195
INFO:root:current mean train loss 3292.9594951059626
INFO:root:current train perplexity3.6521172523498535
INFO:root:current mean train loss 3296.8687541070385
INFO:root:current train perplexity3.6559019088745117
INFO:root:current mean train loss 3292.5938011349654
INFO:root:current train perplexity3.6517932415008545
INFO:root:current mean train loss 3289.6828825866282
INFO:root:current train perplexity3.652425765991211
INFO:root:current mean train loss 3287.5154238398204
INFO:root:current train perplexity3.653881788253784
INFO:root:current mean train loss 3287.94722515249
INFO:root:current train perplexity3.6560981273651123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4057.485554147274
INFO:root:eval perplexity: 5.158924579620361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [10:54:24<3:57:31, 250.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.868396847747
INFO:root:current train perplexity3.627516746520996
INFO:root:current mean train loss 3269.8466711511146
INFO:root:current train perplexity3.626586437225342
INFO:root:current mean train loss 3267.795641235854
INFO:root:current train perplexity3.628852367401123
INFO:root:current mean train loss 3274.161031739705
INFO:root:current train perplexity3.6321325302124023
INFO:root:current mean train loss 3276.967687464729
INFO:root:current train perplexity3.637918710708618
INFO:root:current mean train loss 3279.1332697578555
INFO:root:current train perplexity3.6413521766662598
INFO:root:current mean train loss 3282.121116151706
INFO:root:current train perplexity3.64463210105896
INFO:root:current mean train loss 3279.597696994869
INFO:root:current train perplexity3.645484209060669
INFO:root:current mean train loss 3281.925861471771
INFO:root:current train perplexity3.648247003555298
INFO:root:current mean train loss 3283.818528435263
INFO:root:current train perplexity3.652215003967285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]
INFO:root:eval mean loss: 4059.4516878601507
INFO:root:eval perplexity: 5.163027286529541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [10:58:30<3:52:21, 248.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.681161917892
INFO:root:current train perplexity3.615642786026001
INFO:root:current mean train loss 3274.0910903223303
INFO:root:current train perplexity3.6334264278411865
INFO:root:current mean train loss 3275.61520227683
INFO:root:current train perplexity3.6336865425109863
INFO:root:current mean train loss 3271.601156990073
INFO:root:current train perplexity3.6345715522766113
INFO:root:current mean train loss 3276.183924503707
INFO:root:current train perplexity3.6376616954803467
INFO:root:current mean train loss 3278.2712140922754
INFO:root:current train perplexity3.6428959369659424
INFO:root:current mean train loss 3282.8187524001537
INFO:root:current train perplexity3.646404504776001
INFO:root:current mean train loss 3285.245311264668
INFO:root:current train perplexity3.6497669219970703
INFO:root:current mean train loss 3284.0985768695837
INFO:root:current train perplexity3.649038314819336
INFO:root:current mean train loss 3282.6728520759398
INFO:root:current train perplexity3.6491470336914062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4060.3714608266846
INFO:root:eval perplexity: 5.164947986602783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [11:02:36<3:47:18, 247.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.0016469147245
INFO:root:current train perplexity3.634908676147461
INFO:root:current mean train loss 3276.3147448653694
INFO:root:current train perplexity3.632425308227539
INFO:root:current mean train loss 3269.6167510632845
INFO:root:current train perplexity3.632357597351074
INFO:root:current mean train loss 3271.3946808626392
INFO:root:current train perplexity3.6362721920013428
INFO:root:current mean train loss 3274.1341433057596
INFO:root:current train perplexity3.637463092803955
INFO:root:current mean train loss 3276.6762302241727
INFO:root:current train perplexity3.6408989429473877
INFO:root:current mean train loss 3281.6354787823643
INFO:root:current train perplexity3.6435344219207764
INFO:root:current mean train loss 3280.7738608057475
INFO:root:current train perplexity3.644418954849243
INFO:root:current mean train loss 3281.0547389429025
INFO:root:current train perplexity3.6447460651397705
INFO:root:current mean train loss 3280.5839612083714
INFO:root:current train perplexity3.6452417373657227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4061.4203235815603
INFO:root:eval perplexity: 5.167138576507568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [11:06:44<3:43:09, 247.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.6225513059703
INFO:root:current train perplexity3.629220724105835
INFO:root:current mean train loss 3285.824332779753
INFO:root:current train perplexity3.628916025161743
INFO:root:current mean train loss 3282.1743685261586
INFO:root:current train perplexity3.6347386837005615
INFO:root:current mean train loss 3284.0134204168085
INFO:root:current train perplexity3.633694648742676
INFO:root:current mean train loss 3279.891318212995
INFO:root:current train perplexity3.6339609622955322
INFO:root:current mean train loss 3277.33416694224
INFO:root:current train perplexity3.636016368865967
INFO:root:current mean train loss 3278.694054095999
INFO:root:current train perplexity3.637526273727417
INFO:root:current mean train loss 3278.345103754991
INFO:root:current train perplexity3.6371772289276123
INFO:root:current mean train loss 3279.2651553038495
INFO:root:current train perplexity3.6405608654022217
INFO:root:current mean train loss 3280.0147234217457
INFO:root:current train perplexity3.642514705657959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4061.8461723598184
INFO:root:eval perplexity: 5.168030261993408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [11:10:51<3:38:41, 247.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.5490234375
INFO:root:current train perplexity3.613335371017456
INFO:root:current mean train loss 3268.5140122767857
INFO:root:current train perplexity3.630875825881958
INFO:root:current mean train loss 3276.064747869318
INFO:root:current train perplexity3.639397382736206
INFO:root:current mean train loss 3269.6148470052085
INFO:root:current train perplexity3.632512331008911
INFO:root:current mean train loss 3270.2443981291117
INFO:root:current train perplexity3.631319522857666
INFO:root:current mean train loss 3271.0582447350544
INFO:root:current train perplexity3.6305956840515137
INFO:root:current mean train loss 3273.779114945023
INFO:root:current train perplexity3.632321834564209
INFO:root:current mean train loss 3274.7785458669355
INFO:root:current train perplexity3.6324167251586914
INFO:root:current mean train loss 3278.2123736049107
INFO:root:current train perplexity3.636922836303711
INFO:root:current mean train loss 3276.3182076322114
INFO:root:current train perplexity3.6375272274017334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4061.952281762522
INFO:root:eval perplexity: 5.168250560760498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [11:14:56<3:34:06, 247.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.6389866105046
INFO:root:current train perplexity3.6399343013763428
INFO:root:current mean train loss 3267.8043819906934
INFO:root:current train perplexity3.6334967613220215
INFO:root:current mean train loss 3269.5550903751655
INFO:root:current train perplexity3.6310787200927734
INFO:root:current mean train loss 3272.1249808767134
INFO:root:current train perplexity3.6308939456939697
INFO:root:current mean train loss 3272.7437893253427
INFO:root:current train perplexity3.6305785179138184
INFO:root:current mean train loss 3271.8503765544597
INFO:root:current train perplexity3.633517026901245
INFO:root:current mean train loss 3272.118252710926
INFO:root:current train perplexity3.6331844329833984
INFO:root:current mean train loss 3272.0382315488305
INFO:root:current train perplexity3.633270502090454
INFO:root:current mean train loss 3272.6820509360846
INFO:root:current train perplexity3.634370803833008
INFO:root:current mean train loss 3274.0013240220464
INFO:root:current train perplexity3.635164260864258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.86s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4062.7710497700577
INFO:root:eval perplexity: 5.169962406158447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [11:19:02<3:29:44, 246.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.625273652129
INFO:root:current train perplexity3.6174259185791016
INFO:root:current mean train loss 3260.578774337369
INFO:root:current train perplexity3.6155149936676025
INFO:root:current mean train loss 3263.0692360999246
INFO:root:current train perplexity3.620638608932495
INFO:root:current mean train loss 3264.4014252567536
INFO:root:current train perplexity3.620842695236206
INFO:root:current mean train loss 3265.4551074616534
INFO:root:current train perplexity3.6234703063964844
INFO:root:current mean train loss 3264.8002450494396
INFO:root:current train perplexity3.624274253845215
INFO:root:current mean train loss 3268.409552788079
INFO:root:current train perplexity3.6268742084503174
INFO:root:current mean train loss 3268.5522167721833
INFO:root:current train perplexity3.6301941871643066
INFO:root:current mean train loss 3270.236810104079
INFO:root:current train perplexity3.630953788757324
INFO:root:current mean train loss 3271.891721538771
INFO:root:current train perplexity3.632277727127075


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.64s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4067.4767789367243
INFO:root:eval perplexity: 5.179809093475342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [11:23:08<3:25:13, 246.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.870146780303
INFO:root:current train perplexity3.635570764541626
INFO:root:current mean train loss 3265.007899605449
INFO:root:current train perplexity3.622863292694092
INFO:root:current mean train loss 3264.9439260425374
INFO:root:current train perplexity3.622422933578491
INFO:root:current mean train loss 3262.0144618137138
INFO:root:current train perplexity3.6193790435791016
INFO:root:current mean train loss 3264.0669302472133
INFO:root:current train perplexity3.620652914047241
INFO:root:current mean train loss 3265.6660543451326
INFO:root:current train perplexity3.625256299972534
INFO:root:current mean train loss 3264.6299194859844
INFO:root:current train perplexity3.626643419265747
INFO:root:current mean train loss 3262.821579342342
INFO:root:current train perplexity3.6261398792266846
INFO:root:current mean train loss 3267.2297610409137
INFO:root:current train perplexity3.6278860569000244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.97s/it]
INFO:root:eval mean loss: 4064.5127299423757
INFO:root:eval perplexity: 5.173604965209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [11:27:15<3:21:26, 246.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.5635114397323
INFO:root:current train perplexity3.616568088531494
INFO:root:current mean train loss 3267.3767477730726
INFO:root:current train perplexity3.625714063644409
INFO:root:current mean train loss 3262.396050347222
INFO:root:current train perplexity3.6233537197113037
INFO:root:current mean train loss 3259.6308848228828
INFO:root:current train perplexity3.625114679336548
INFO:root:current mean train loss 3259.4369349374233
INFO:root:current train perplexity3.6232128143310547
INFO:root:current mean train loss 3261.515801725068
INFO:root:current train perplexity3.620698928833008
INFO:root:current mean train loss 3261.026051051534
INFO:root:current train perplexity3.620842695236206
INFO:root:current mean train loss 3266.036992311815
INFO:root:current train perplexity3.621760129928589
INFO:root:current mean train loss 3267.1673025819005
INFO:root:current train perplexity3.6233553886413574
INFO:root:current mean train loss 3269.629533694098
INFO:root:current train perplexity3.6252641677856445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4065.871346548094
INFO:root:eval perplexity: 5.17644739151001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [11:31:20<3:17:00, 246.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.8248372395833
INFO:root:current train perplexity3.611576557159424
INFO:root:current mean train loss 3261.488952105978
INFO:root:current train perplexity3.615117311477661
INFO:root:current mean train loss 3261.519764035247
INFO:root:current train perplexity3.6188852787017822
INFO:root:current mean train loss 3254.6228531125994
INFO:root:current train perplexity3.613858222961426
INFO:root:current mean train loss 3260.024708796122
INFO:root:current train perplexity3.615786552429199
INFO:root:current mean train loss 3263.078739381068
INFO:root:current train perplexity3.6199657917022705
INFO:root:current mean train loss 3263.0405205951474
INFO:root:current train perplexity3.6158125400543213
INFO:root:current mean train loss 3265.6797055971374
INFO:root:current train perplexity3.619877815246582
INFO:root:current mean train loss 3264.3878612682133
INFO:root:current train perplexity3.621291160583496
INFO:root:current mean train loss 3265.139724748122
INFO:root:current train perplexity3.6229727268218994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 4067.4067105773493
INFO:root:eval perplexity: 5.179662704467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [11:35:28<3:13:16, 246.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.1791673743205
INFO:root:current train perplexity3.5662381649017334
INFO:root:current mean train loss 3251.4891605532266
INFO:root:current train perplexity3.6073451042175293
INFO:root:current mean train loss 3251.633991600687
INFO:root:current train perplexity3.602802276611328
INFO:root:current mean train loss 3252.0558938419117
INFO:root:current train perplexity3.602609872817993
INFO:root:current mean train loss 3254.202770620937
INFO:root:current train perplexity3.6076691150665283
INFO:root:current mean train loss 3256.4533840784834
INFO:root:current train perplexity3.6085736751556396
INFO:root:current mean train loss 3256.779627620887
INFO:root:current train perplexity3.612178087234497
INFO:root:current mean train loss 3259.8786229388184
INFO:root:current train perplexity3.615309953689575
INFO:root:current mean train loss 3262.4763195459636
INFO:root:current train perplexity3.616022825241089
INFO:root:current mean train loss 3263.3593990702025
INFO:root:current train perplexity3.6185126304626465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]
INFO:root:eval mean loss: 4068.6478522550974
INFO:root:eval perplexity: 5.182261943817139
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [11:39:32<3:08:28, 245.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.822541267641
INFO:root:current train perplexity3.6353089809417725
INFO:root:current mean train loss 3254.529311784351
INFO:root:current train perplexity3.615546226501465
INFO:root:current mean train loss 3252.355692809794
INFO:root:current train perplexity3.605590343475342
INFO:root:current mean train loss 3255.0079991089974
INFO:root:current train perplexity3.6105551719665527
INFO:root:current mean train loss 3252.259965582403
INFO:root:current train perplexity3.6137561798095703
INFO:root:current mean train loss 3251.587942119821
INFO:root:current train perplexity3.6129589080810547
INFO:root:current mean train loss 3256.192808027313
INFO:root:current train perplexity3.616997718811035
INFO:root:current mean train loss 3259.5210505327677
INFO:root:current train perplexity3.6202449798583984
INFO:root:current mean train loss 3261.9000439511883
INFO:root:current train perplexity3.617398262023926
INFO:root:current mean train loss 3260.199831068324
INFO:root:current train perplexity3.616610527038574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4068.9384107657356
INFO:root:eval perplexity: 5.182872295379639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [11:43:40<3:04:54, 246.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.576960637019
INFO:root:current train perplexity3.6150121688842773
INFO:root:current mean train loss 3251.3230612775405
INFO:root:current train perplexity3.5933101177215576
INFO:root:current mean train loss 3256.258656266344
INFO:root:current train perplexity3.6033387184143066
INFO:root:current mean train loss 3255.146096198608
INFO:root:current train perplexity3.608954668045044
INFO:root:current mean train loss 3251.529570490461
INFO:root:current train perplexity3.611797332763672
INFO:root:current mean train loss 3252.8383965713415
INFO:root:current train perplexity3.6091983318328857
INFO:root:current mean train loss 3252.350741438649
INFO:root:current train perplexity3.606825828552246
INFO:root:current mean train loss 3254.22073880455
INFO:root:current train perplexity3.6069397926330566
INFO:root:current mean train loss 3254.9808519838534
INFO:root:current train perplexity3.6060471534729004
INFO:root:current mean train loss 3256.7974639015074
INFO:root:current train perplexity3.610614538192749


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4069.534472309951
INFO:root:eval perplexity: 5.184119701385498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [11:47:46<3:00:38, 246.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.504425698138
INFO:root:current train perplexity3.556156873703003
INFO:root:current mean train loss 3254.3982016634777
INFO:root:current train perplexity3.586493730545044
INFO:root:current mean train loss 3244.9898933688637
INFO:root:current train perplexity3.587893486022949
INFO:root:current mean train loss 3247.458517201009
INFO:root:current train perplexity3.5920283794403076
INFO:root:current mean train loss 3250.410316825713
INFO:root:current train perplexity3.5979557037353516
INFO:root:current mean train loss 3246.5884257705384
INFO:root:current train perplexity3.5981016159057617
INFO:root:current mean train loss 3247.5442796379925
INFO:root:current train perplexity3.600800037384033
INFO:root:current mean train loss 3251.0135169584587
INFO:root:current train perplexity3.6035091876983643
INFO:root:current mean train loss 3254.8053942683737
INFO:root:current train perplexity3.6064250469207764
INFO:root:current mean train loss 3256.0086142712184
INFO:root:current train perplexity3.6083030700683594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.83s/it]
INFO:root:eval mean loss: 4071.4421178939497
INFO:root:eval perplexity: 5.1881208419799805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [11:51:56<2:57:14, 247.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.549493963068
INFO:root:current train perplexity3.6229982376098633
INFO:root:current mean train loss 3225.21898469002
INFO:root:current train perplexity3.5971686840057373
INFO:root:current mean train loss 3236.5495433134192
INFO:root:current train perplexity3.5972707271575928
INFO:root:current mean train loss 3242.888525390625
INFO:root:current train perplexity3.6021833419799805
INFO:root:current mean train loss 3245.187109911573
INFO:root:current train perplexity3.6030821800231934
INFO:root:current mean train loss 3248.6493859093466
INFO:root:current train perplexity3.6027352809906006
INFO:root:current mean train loss 3253.539096418774
INFO:root:current train perplexity3.607320785522461
INFO:root:current mean train loss 3253.805473600476
INFO:root:current train perplexity3.6071512699127197
INFO:root:current mean train loss 3255.8202319764255
INFO:root:current train perplexity3.609360456466675
INFO:root:current mean train loss 3254.8180387966295
INFO:root:current train perplexity3.6075339317321777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4071.853861923759
INFO:root:eval perplexity: 5.188985347747803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [11:56:03<2:53:03, 247.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.2076396639386
INFO:root:current train perplexity3.6003527641296387
INFO:root:current mean train loss 3257.9006677171205
INFO:root:current train perplexity3.593848705291748
INFO:root:current mean train loss 3253.9742603374525
INFO:root:current train perplexity3.5940260887145996
INFO:root:current mean train loss 3245.621419943397
INFO:root:current train perplexity3.595499277114868
INFO:root:current mean train loss 3249.5358601975904
INFO:root:current train perplexity3.6033060550689697
INFO:root:current mean train loss 3251.0956176974632
INFO:root:current train perplexity3.603100299835205
INFO:root:current mean train loss 3250.0423442213423
INFO:root:current train perplexity3.6061923503875732
INFO:root:current mean train loss 3253.692998123669
INFO:root:current train perplexity3.6054277420043945
INFO:root:current mean train loss 3252.445763721665
INFO:root:current train perplexity3.6051509380340576
INFO:root:current mean train loss 3252.0835800091672
INFO:root:current train perplexity3.6038241386413574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.87s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it]
INFO:root:eval mean loss: 4071.0644133006426
INFO:root:eval perplexity: 5.187329292297363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [12:00:13<2:49:27, 248.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.1276305292695
INFO:root:current train perplexity3.6030516624450684
INFO:root:current mean train loss 3236.784729360837
INFO:root:current train perplexity3.5827529430389404
INFO:root:current mean train loss 3239.1071687254957
INFO:root:current train perplexity3.5852386951446533
INFO:root:current mean train loss 3237.5845391204093
INFO:root:current train perplexity3.5929927825927734
INFO:root:current mean train loss 3242.3931332727907
INFO:root:current train perplexity3.5951216220855713
INFO:root:current mean train loss 3242.591855879214
INFO:root:current train perplexity3.597069263458252
INFO:root:current mean train loss 3244.9524114981136
INFO:root:current train perplexity3.5953707695007324
INFO:root:current mean train loss 3247.471209455557
INFO:root:current train perplexity3.5971508026123047
INFO:root:current mean train loss 3249.422001134651
INFO:root:current train perplexity3.6016063690185547
INFO:root:current mean train loss 3249.090392877832
INFO:root:current train perplexity3.600739002227783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 4071.3955961186834
INFO:root:eval perplexity: 5.188024520874023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [12:04:22<2:45:33, 248.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.1361037628562
INFO:root:current train perplexity3.579596519470215
INFO:root:current mean train loss 3236.7674444614177
INFO:root:current train perplexity3.5945024490356445
INFO:root:current mean train loss 3243.370572216622
INFO:root:current train perplexity3.597684621810913
INFO:root:current mean train loss 3248.3636993166638
INFO:root:current train perplexity3.5951530933380127
INFO:root:current mean train loss 3246.8028103185347
INFO:root:current train perplexity3.594586133956909
INFO:root:current mean train loss 3249.380085630532
INFO:root:current train perplexity3.596238851547241
INFO:root:current mean train loss 3245.80681932587
INFO:root:current train perplexity3.5974345207214355
INFO:root:current mean train loss 3247.2947081344273
INFO:root:current train perplexity3.5982556343078613
INFO:root:current mean train loss 3246.1809654192443
INFO:root:current train perplexity3.599133253097534
INFO:root:current mean train loss 3248.263208780883
INFO:root:current train perplexity3.5997278690338135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4073.6199267231827
INFO:root:eval perplexity: 5.192692756652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [12:08:29<2:41:16, 248.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.6718918372844
INFO:root:current train perplexity3.5691864490509033
INFO:root:current mean train loss 3231.983653022644
INFO:root:current train perplexity3.5726630687713623
INFO:root:current mean train loss 3238.5868221907667
INFO:root:current train perplexity3.5771405696868896
INFO:root:current mean train loss 3243.7207340368623
INFO:root:current train perplexity3.585547685623169
INFO:root:current mean train loss 3241.541478339162
INFO:root:current train perplexity3.586338520050049
INFO:root:current mean train loss 3243.6839639121063
INFO:root:current train perplexity3.587306261062622
INFO:root:current mean train loss 3242.3444518598753
INFO:root:current train perplexity3.5874221324920654
INFO:root:current mean train loss 3243.7206885448104
INFO:root:current train perplexity3.5900039672851562
INFO:root:current mean train loss 3243.8675505456417
INFO:root:current train perplexity3.5918633937835693
INFO:root:current mean train loss 3245.976652042965
INFO:root:current train perplexity3.5954251289367676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4073.5400044326243
INFO:root:eval perplexity: 5.192523956298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [12:12:39<2:37:22, 248.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.6051166735197
INFO:root:current train perplexity3.5875930786132812
INFO:root:current mean train loss 3244.1540076622596
INFO:root:current train perplexity3.5951740741729736
INFO:root:current mean train loss 3241.1288127317266
INFO:root:current train perplexity3.586513042449951
INFO:root:current mean train loss 3245.802736229233
INFO:root:current train perplexity3.5859556198120117
INFO:root:current mean train loss 3248.608314591225
INFO:root:current train perplexity3.5908093452453613
INFO:root:current mean train loss 3248.0556443671217
INFO:root:current train perplexity3.5909416675567627
INFO:root:current mean train loss 3246.996130634555
INFO:root:current train perplexity3.5896286964416504
INFO:root:current mean train loss 3244.6145931603774
INFO:root:current train perplexity3.5904507637023926
INFO:root:current mean train loss 3244.578582729574
INFO:root:current train perplexity3.591291904449463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 4073.785963126108
INFO:root:eval perplexity: 5.1930413246154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [12:16:44<2:32:36, 247.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.30419921875
INFO:root:current train perplexity3.587571382522583
INFO:root:current mean train loss 3216.435376213592
INFO:root:current train perplexity3.5900654792785645
INFO:root:current mean train loss 3237.614920479911
INFO:root:current train perplexity3.598546028137207
INFO:root:current mean train loss 3235.662568649443
INFO:root:current train perplexity3.594951629638672
INFO:root:current mean train loss 3235.33786942172
INFO:root:current train perplexity3.596558094024658
INFO:root:current mean train loss 3236.8752082233163
INFO:root:current train perplexity3.5946173667907715
INFO:root:current mean train loss 3239.2545491941337
INFO:root:current train perplexity3.592111349105835
INFO:root:current mean train loss 3238.874284247755
INFO:root:current train perplexity3.5893826484680176
INFO:root:current mean train loss 3239.147491949136
INFO:root:current train perplexity3.5899384021759033
INFO:root:current mean train loss 3243.529768393549
INFO:root:current train perplexity3.591853618621826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.84s/it]
INFO:root:eval mean loss: 4076.2839372783687
INFO:root:eval perplexity: 5.198288917541504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [12:20:48<2:27:59, 246.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.7558371803975
INFO:root:current train perplexity3.5766730308532715
INFO:root:current mean train loss 3240.1253563133446
INFO:root:current train perplexity3.5728981494903564
INFO:root:current mean train loss 3242.983636792802
INFO:root:current train perplexity3.5804452896118164
INFO:root:current mean train loss 3243.1578639971863
INFO:root:current train perplexity3.5882863998413086
INFO:root:current mean train loss 3247.726618337515
INFO:root:current train perplexity3.5944201946258545
INFO:root:current mean train loss 3244.324982226945
INFO:root:current train perplexity3.594651937484741
INFO:root:current mean train loss 3241.6459561362008
INFO:root:current train perplexity3.5912277698516846
INFO:root:current mean train loss 3241.0736223051817
INFO:root:current train perplexity3.590895414352417
INFO:root:current mean train loss 3242.461292422068
INFO:root:current train perplexity3.5907769203186035
INFO:root:current mean train loss 3242.449446275127
INFO:root:current train perplexity3.5905308723449707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4074.7038920517507
INFO:root:eval perplexity: 5.194969177246094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [12:24:58<2:24:21, 247.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.024105674342
INFO:root:current train perplexity3.605339765548706
INFO:root:current mean train loss 3242.0988790047268
INFO:root:current train perplexity3.5909371376037598
INFO:root:current mean train loss 3244.3313567975883
INFO:root:current train perplexity3.5955190658569336
INFO:root:current mean train loss 3243.966212927361
INFO:root:current train perplexity3.5906460285186768
INFO:root:current mean train loss 3240.81735193075
INFO:root:current train perplexity3.5900776386260986
INFO:root:current mean train loss 3238.728373092034
INFO:root:current train perplexity3.5894579887390137
INFO:root:current mean train loss 3241.3072898260803
INFO:root:current train perplexity3.5901315212249756
INFO:root:current mean train loss 3243.045787402751
INFO:root:current train perplexity3.5894651412963867
INFO:root:current mean train loss 3242.902538704785
INFO:root:current train perplexity3.590677261352539
INFO:root:current mean train loss 3241.0905594353576
INFO:root:current train perplexity3.5876898765563965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.67s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4075.9382029864805
INFO:root:eval perplexity: 5.197561740875244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [12:29:04<2:19:58, 247.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.597710503472
INFO:root:current train perplexity3.5959575176239014
INFO:root:current mean train loss 3236.690554641363
INFO:root:current train perplexity3.5778913497924805
INFO:root:current mean train loss 3241.696228833976
INFO:root:current train perplexity3.5870039463043213
INFO:root:current mean train loss 3235.695743292479
INFO:root:current train perplexity3.5823006629943848
INFO:root:current mean train loss 3238.335335438927
INFO:root:current train perplexity3.5816662311553955
INFO:root:current mean train loss 3240.7324260443843
INFO:root:current train perplexity3.58046293258667
INFO:root:current mean train loss 3240.9414109225477
INFO:root:current train perplexity3.5827484130859375
INFO:root:current mean train loss 3241.981345238351
INFO:root:current train perplexity3.5846059322357178
INFO:root:current mean train loss 3238.853767145934
INFO:root:current train perplexity3.5847010612487793
INFO:root:current mean train loss 3239.2994180656688
INFO:root:current train perplexity3.5856921672821045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it]
INFO:root:eval mean loss: 4076.5918955701463
INFO:root:eval perplexity: 5.198936939239502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [12:33:14<2:16:18, 247.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.14775390625
INFO:root:current train perplexity3.5870401859283447
INFO:root:current mean train loss 3235.5285083912036
INFO:root:current train perplexity3.580545663833618
INFO:root:current mean train loss 3225.698862408577
INFO:root:current train perplexity3.5745677947998047
INFO:root:current mean train loss 3231.7326463386194
INFO:root:current train perplexity3.5755717754364014
INFO:root:current mean train loss 3233.7931040095186
INFO:root:current train perplexity3.57737135887146
INFO:root:current mean train loss 3237.2933671327396
INFO:root:current train perplexity3.578542947769165
INFO:root:current mean train loss 3236.737385042446
INFO:root:current train perplexity3.580650568008423
INFO:root:current mean train loss 3237.644736195259
INFO:root:current train perplexity3.579630136489868
INFO:root:current mean train loss 3237.6467051249065
INFO:root:current train perplexity3.5798943042755127
INFO:root:current mean train loss 3237.0554415942515
INFO:root:current train perplexity3.5814599990844727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4076.87969581117
INFO:root:eval perplexity: 5.199542045593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [12:37:19<2:11:51, 247.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.999148346657
INFO:root:current train perplexity3.557014226913452
INFO:root:current mean train loss 3251.27502014587
INFO:root:current train perplexity3.588127851486206
INFO:root:current mean train loss 3235.211956259645
INFO:root:current train perplexity3.5827057361602783
INFO:root:current mean train loss 3229.5724748883927
INFO:root:current train perplexity3.5754404067993164
INFO:root:current mean train loss 3231.08275595637
INFO:root:current train perplexity3.576702833175659
INFO:root:current mean train loss 3229.3444914141633
INFO:root:current train perplexity3.5726757049560547
INFO:root:current mean train loss 3233.837343112121
INFO:root:current train perplexity3.5736453533172607
INFO:root:current mean train loss 3235.5286778158647
INFO:root:current train perplexity3.5785887241363525
INFO:root:current mean train loss 3236.866350239565
INFO:root:current train perplexity3.579643726348877
INFO:root:current mean train loss 3235.2074571368803
INFO:root:current train perplexity3.579296588897705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4077.5832484901375
INFO:root:eval perplexity: 5.201021194458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [12:41:26<2:07:36, 246.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.4870461856617
INFO:root:current train perplexity3.5764379501342773
INFO:root:current mean train loss 3228.157279917736
INFO:root:current train perplexity3.566913366317749
INFO:root:current mean train loss 3230.102530308454
INFO:root:current train perplexity3.577223062515259
INFO:root:current mean train loss 3228.2094782207087
INFO:root:current train perplexity3.5735719203948975
INFO:root:current mean train loss 3222.629173667891
INFO:root:current train perplexity3.568516254425049
INFO:root:current mean train loss 3223.258958764604
INFO:root:current train perplexity3.570059299468994
INFO:root:current mean train loss 3227.3519217729936
INFO:root:current train perplexity3.572465419769287
INFO:root:current mean train loss 3229.981038303096
INFO:root:current train perplexity3.5751373767852783
INFO:root:current mean train loss 3231.561853931037
INFO:root:current train perplexity3.57472825050354
INFO:root:current mean train loss 3232.585762930468
INFO:root:current train perplexity3.576272964477539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it]
INFO:root:eval mean loss: 4079.82232969027
INFO:root:eval perplexity: 5.205732345581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [12:45:35<2:03:52, 247.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.007758706303
INFO:root:current train perplexity3.568387031555176
INFO:root:current mean train loss 3210.7012640035377
INFO:root:current train perplexity3.550861358642578
INFO:root:current mean train loss 3212.321951729911
INFO:root:current train perplexity3.561939239501953
INFO:root:current mean train loss 3222.038436847145
INFO:root:current train perplexity3.5718531608581543
INFO:root:current mean train loss 3220.7604145390796
INFO:root:current train perplexity3.568743944168091
INFO:root:current mean train loss 3223.9890769999442
INFO:root:current train perplexity3.5727388858795166
INFO:root:current mean train loss 3227.9839048718463
INFO:root:current train perplexity3.574983596801758
INFO:root:current mean train loss 3229.725391332654
INFO:root:current train perplexity3.575040817260742
INFO:root:current mean train loss 3230.6115617496725
INFO:root:current train perplexity3.5757534503936768
INFO:root:current mean train loss 3230.491841273462
INFO:root:current train perplexity3.574740171432495


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it]
INFO:root:eval mean loss: 4078.951265375665
INFO:root:eval perplexity: 5.203898906707764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [12:49:41<1:59:30, 247.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.497901119403
INFO:root:current train perplexity3.567030429840088
INFO:root:current mean train loss 3244.1341676997567
INFO:root:current train perplexity3.579904079437256
INFO:root:current mean train loss 3235.0330513371955
INFO:root:current train perplexity3.5824642181396484
INFO:root:current mean train loss 3233.974784996594
INFO:root:current train perplexity3.582124948501587
INFO:root:current mean train loss 3225.694932435258
INFO:root:current train perplexity3.57600736618042
INFO:root:current mean train loss 3224.2468687996034
INFO:root:current train perplexity3.5720932483673096
INFO:root:current mean train loss 3224.42381751019
INFO:root:current train perplexity3.5721545219421387
INFO:root:current mean train loss 3226.984094890808
INFO:root:current train perplexity3.572924852371216
INFO:root:current mean train loss 3230.183418599517
INFO:root:current train perplexity3.5738608837127686
INFO:root:current mean train loss 3230.4177034017093
INFO:root:current train perplexity3.5739405155181885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 4080.5984111812945
INFO:root:eval perplexity: 5.207366466522217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [12:53:47<1:55:10, 246.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.2564518229165
INFO:root:current train perplexity3.569608211517334
INFO:root:current mean train loss 3215.9045758928573
INFO:root:current train perplexity3.5614395141601562
INFO:root:current mean train loss 3228.5750328480112
INFO:root:current train perplexity3.5691046714782715
INFO:root:current mean train loss 3225.06125390625
INFO:root:current train perplexity3.5665338039398193
INFO:root:current mean train loss 3225.469304070724
INFO:root:current train perplexity3.567199945449829
INFO:root:current mean train loss 3226.7118529211957
INFO:root:current train perplexity3.5670881271362305
INFO:root:current mean train loss 3224.7090577980325
INFO:root:current train perplexity3.5677754878997803
INFO:root:current mean train loss 3226.2092275705645
INFO:root:current train perplexity3.5684525966644287
INFO:root:current mean train loss 3228.447584821429
INFO:root:current train perplexity3.56945538520813
INFO:root:current mean train loss 3227.6922172976765
INFO:root:current train perplexity3.568809986114502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.17s/it]
INFO:root:eval mean loss: 4080.1069110843305
INFO:root:eval perplexity: 5.206332206726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [12:57:52<1:50:50, 246.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.49315523814
INFO:root:current train perplexity3.5872509479522705
INFO:root:current mean train loss 3228.2667830003415
INFO:root:current train perplexity3.5650336742401123
INFO:root:current mean train loss 3226.0102452793726
INFO:root:current train perplexity3.5675551891326904
INFO:root:current mean train loss 3226.7307320139116
INFO:root:current train perplexity3.5630931854248047
INFO:root:current mean train loss 3233.825439958592
INFO:root:current train perplexity3.5676167011260986
INFO:root:current mean train loss 3227.4759368634755
INFO:root:current train perplexity3.565681219100952
INFO:root:current mean train loss 3226.3119380833637
INFO:root:current train perplexity3.565607786178589
INFO:root:current mean train loss 3227.628915604047
INFO:root:current train perplexity3.567293643951416
INFO:root:current mean train loss 3229.0287405772224
INFO:root:current train perplexity3.569117546081543
INFO:root:current mean train loss 3227.0812074306173
INFO:root:current train perplexity3.568551778793335


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4081.680388754987
INFO:root:eval perplexity: 5.2096452713012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [13:01:59<1:46:46, 246.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.250257554945
INFO:root:current train perplexity3.553934097290039
INFO:root:current mean train loss 3205.067817408377
INFO:root:current train perplexity3.547938108444214
INFO:root:current mean train loss 3216.744370503114
INFO:root:current train perplexity3.5579476356506348
INFO:root:current mean train loss 3221.261959768622
INFO:root:current train perplexity3.5608112812042236
INFO:root:current mean train loss 3217.5986745799387
INFO:root:current train perplexity3.5560667514801025
INFO:root:current mean train loss 3219.1834157049757
INFO:root:current train perplexity3.5563764572143555
INFO:root:current mean train loss 3222.0516207263026
INFO:root:current train perplexity3.55972957611084
INFO:root:current mean train loss 3221.994751748183
INFO:root:current train perplexity3.5601632595062256
INFO:root:current mean train loss 3224.764696936816
INFO:root:current train perplexity3.563668727874756
INFO:root:current mean train loss 3225.229757268542
INFO:root:current train perplexity3.5660393238067627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4083.2399833084
INFO:root:eval perplexity: 5.2129316329956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [13:06:09<1:43:05, 247.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.2121384745897
INFO:root:current train perplexity3.565812349319458
INFO:root:current mean train loss 3218.0073659312184
INFO:root:current train perplexity3.5580294132232666
INFO:root:current mean train loss 3218.100154812918
INFO:root:current train perplexity3.557717800140381
INFO:root:current mean train loss 3219.0753996808426
INFO:root:current train perplexity3.558396339416504
INFO:root:current mean train loss 3220.758804229553
INFO:root:current train perplexity3.560446262359619
INFO:root:current mean train loss 3221.50631178918
INFO:root:current train perplexity3.5629491806030273
INFO:root:current mean train loss 3223.229025561069
INFO:root:current train perplexity3.5624539852142334
INFO:root:current mean train loss 3222.2440177907934
INFO:root:current train perplexity3.562437057495117
INFO:root:current mean train loss 3222.457855462232
INFO:root:current train perplexity3.5629661083221436


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it]
INFO:root:eval mean loss: 4081.8014998199246
INFO:root:eval perplexity: 5.20989990234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [13:10:17<1:39:06, 247.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.6233258928573
INFO:root:current train perplexity3.471726655960083
INFO:root:current mean train loss 3234.8733571845796
INFO:root:current train perplexity3.5604283809661865
INFO:root:current mean train loss 3226.573585399683
INFO:root:current train perplexity3.5561399459838867
INFO:root:current mean train loss 3220.5387054343955
INFO:root:current train perplexity3.554016351699829
INFO:root:current mean train loss 3221.72556554246
INFO:root:current train perplexity3.5524046421051025
INFO:root:current mean train loss 3219.3496729382396
INFO:root:current train perplexity3.553391456604004
INFO:root:current mean train loss 3218.463625057918
INFO:root:current train perplexity3.5555787086486816
INFO:root:current mean train loss 3219.8132389829384
INFO:root:current train perplexity3.5593526363372803
INFO:root:current mean train loss 3221.3731454993417
INFO:root:current train perplexity3.561197519302368
INFO:root:current mean train loss 3224.2542155306814
INFO:root:current train perplexity3.5652546882629395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it]
INFO:root:eval mean loss: 4082.821219802748
INFO:root:eval perplexity: 5.212048530578613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [13:14:24<1:34:51, 247.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.5180501302084
INFO:root:current train perplexity3.5262234210968018
INFO:root:current mean train loss 3212.3196543817935
INFO:root:current train perplexity3.533747911453247
INFO:root:current mean train loss 3218.1874647983286
INFO:root:current train perplexity3.561394691467285
INFO:root:current mean train loss 3214.538475012401
INFO:root:current train perplexity3.560403347015381
INFO:root:current mean train loss 3217.2233827889686
INFO:root:current train perplexity3.557194471359253
INFO:root:current mean train loss 3216.023741846177
INFO:root:current train perplexity3.554399013519287
INFO:root:current mean train loss 3219.4029971735263
INFO:root:current train perplexity3.5562026500701904
INFO:root:current mean train loss 3221.748471986997
INFO:root:current train perplexity3.5585057735443115
INFO:root:current mean train loss 3221.854949314609
INFO:root:current train perplexity3.5586304664611816
INFO:root:current mean train loss 3220.726377860314
INFO:root:current train perplexity3.560119152069092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it]
INFO:root:eval mean loss: 4083.963851604056
INFO:root:eval perplexity: 5.2144575119018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [13:18:33<1:30:51, 247.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.7348314368205
INFO:root:current train perplexity3.557474374771118
INFO:root:current mean train loss 3235.2460858104673
INFO:root:current train perplexity3.5566134452819824
INFO:root:current mean train loss 3228.220686702985
INFO:root:current train perplexity3.5510988235473633
INFO:root:current mean train loss 3229.0963055401025
INFO:root:current train perplexity3.5551180839538574
INFO:root:current mean train loss 3230.593069522939
INFO:root:current train perplexity3.55768084526062
INFO:root:current mean train loss 3224.8244129421605
INFO:root:current train perplexity3.5576322078704834
INFO:root:current mean train loss 3223.9894600220705
INFO:root:current train perplexity3.557821750640869
INFO:root:current mean train loss 3220.989339868063
INFO:root:current train perplexity3.5587239265441895
INFO:root:current mean train loss 3219.8584503507554
INFO:root:current train perplexity3.5578856468200684
INFO:root:current mean train loss 3220.635844022972
INFO:root:current train perplexity3.5612595081329346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4083.3285925033247
INFO:root:eval perplexity: 5.213119029998779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [13:22:38<1:26:28, 247.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3197.5672095514115
INFO:root:current train perplexity3.5501668453216553
INFO:root:current mean train loss 3209.9834748479248
INFO:root:current train perplexity3.5515763759613037
INFO:root:current mean train loss 3209.9936618557226
INFO:root:current train perplexity3.559891939163208
INFO:root:current mean train loss 3209.295486127502
INFO:root:current train perplexity3.55741548538208
INFO:root:current mean train loss 3213.153580313769
INFO:root:current train perplexity3.5579161643981934
INFO:root:current mean train loss 3215.3946687227813
INFO:root:current train perplexity3.555636405944824
INFO:root:current mean train loss 3216.6053542244454
INFO:root:current train perplexity3.557499885559082
INFO:root:current mean train loss 3218.711097143254
INFO:root:current train perplexity3.558915138244629
INFO:root:current mean train loss 3219.2574144126993
INFO:root:current train perplexity3.5576634407043457
INFO:root:current mean train loss 3218.2027426616205
INFO:root:current train perplexity3.5567266941070557


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4083.4768083721187
INFO:root:eval perplexity: 5.213431358337402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [13:26:43<1:22:09, 246.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.586244240785
INFO:root:current train perplexity3.583951234817505
INFO:root:current mean train loss 3214.0723095351846
INFO:root:current train perplexity3.5603439807891846
INFO:root:current mean train loss 3210.481663915403
INFO:root:current train perplexity3.554298162460327
INFO:root:current mean train loss 3214.6712657287057
INFO:root:current train perplexity3.5514426231384277
INFO:root:current mean train loss 3214.171346121334
INFO:root:current train perplexity3.5534050464630127
INFO:root:current mean train loss 3213.530627192283
INFO:root:current train perplexity3.551619052886963
INFO:root:current mean train loss 3213.0678745323503
INFO:root:current train perplexity3.550868511199951
INFO:root:current mean train loss 3215.7442288327766
INFO:root:current train perplexity3.552670955657959
INFO:root:current mean train loss 3217.8329007281736
INFO:root:current train perplexity3.5560882091522217
INFO:root:current mean train loss 3217.7205419245875
INFO:root:current train perplexity3.554943084716797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it]
INFO:root:eval mean loss: 4085.2826525099736
INFO:root:eval perplexity: 5.217239856719971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [13:30:53<1:18:20, 247.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.99710667387
INFO:root:current train perplexity3.5368905067443848
INFO:root:current mean train loss 3213.727960910927
INFO:root:current train perplexity3.556976079940796
INFO:root:current mean train loss 3218.5185635833122
INFO:root:current train perplexity3.5565521717071533
INFO:root:current mean train loss 3224.4847908129955
INFO:root:current train perplexity3.5608155727386475
INFO:root:current mean train loss 3220.4002677354238
INFO:root:current train perplexity3.5562734603881836
INFO:root:current mean train loss 3218.0051965800676
INFO:root:current train perplexity3.5563104152679443
INFO:root:current mean train loss 3220.686223072836
INFO:root:current train perplexity3.5570898056030273
INFO:root:current mean train loss 3219.0423092108017
INFO:root:current train perplexity3.556767463684082
INFO:root:current mean train loss 3218.807503908556
INFO:root:current train perplexity3.5565147399902344
INFO:root:current mean train loss 3218.6011788872756
INFO:root:current train perplexity3.556469440460205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4084.686268907912
INFO:root:eval perplexity: 5.215981483459473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [13:35:02<1:14:24, 248.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.9334428267043
INFO:root:current train perplexity3.5782265663146973
INFO:root:current mean train loss 3205.009845955141
INFO:root:current train perplexity3.5606746673583984
INFO:root:current mean train loss 3204.381624348958
INFO:root:current train perplexity3.546855926513672
INFO:root:current mean train loss 3211.070773960167
INFO:root:current train perplexity3.5490517616271973
INFO:root:current mean train loss 3212.7161690848216
INFO:root:current train perplexity3.5467705726623535
INFO:root:current mean train loss 3210.9517507742116
INFO:root:current train perplexity3.5501275062561035
INFO:root:current mean train loss 3212.8204291656725
INFO:root:current train perplexity3.5491936206817627
INFO:root:current mean train loss 3214.7514234530217
INFO:root:current train perplexity3.552982807159424
INFO:root:current mean train loss 3216.1185292740315
INFO:root:current train perplexity3.552999258041382
INFO:root:current mean train loss 3216.884343044421
INFO:root:current train perplexity3.5532305240631104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4084.860663231383
INFO:root:eval perplexity: 5.216348648071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [13:39:08<1:10:03, 247.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.714293464782
INFO:root:current train perplexity3.557141065597534
INFO:root:current mean train loss 3222.211993445648
INFO:root:current train perplexity3.553659677505493
INFO:root:current mean train loss 3214.700439453125
INFO:root:current train perplexity3.5520122051239014
INFO:root:current mean train loss 3214.4405063597624
INFO:root:current train perplexity3.553616762161255
INFO:root:current mean train loss 3214.331404288438
INFO:root:current train perplexity3.5529983043670654
INFO:root:current mean train loss 3213.813091054479
INFO:root:current train perplexity3.5533504486083984
INFO:root:current mean train loss 3216.1439615885415
INFO:root:current train perplexity3.554100275039673
INFO:root:current mean train loss 3217.37614326927
INFO:root:current train perplexity3.552824020385742
INFO:root:current mean train loss 3214.7200086114026
INFO:root:current train perplexity3.5521624088287354
INFO:root:current mean train loss 3214.5024725893204
INFO:root:current train perplexity3.5525410175323486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it]
INFO:root:eval mean loss: 4085.222476174645
INFO:root:eval perplexity: 5.217112064361572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [13:43:16<1:06:02, 247.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.4028870488555
INFO:root:current train perplexity3.553544044494629
INFO:root:current mean train loss 3220.166869403326
INFO:root:current train perplexity3.5457756519317627
INFO:root:current mean train loss 3219.1825793502076
INFO:root:current train perplexity3.5470566749572754
INFO:root:current mean train loss 3216.1661268373064
INFO:root:current train perplexity3.5463621616363525
INFO:root:current mean train loss 3215.350452722764
INFO:root:current train perplexity3.5464284420013428
INFO:root:current mean train loss 3215.7364097902528
INFO:root:current train perplexity3.5481011867523193
INFO:root:current mean train loss 3214.3388340775196
INFO:root:current train perplexity3.5484158992767334
INFO:root:current mean train loss 3212.8370461074296
INFO:root:current train perplexity3.5487964153289795
INFO:root:current mean train loss 3216.157748759956
INFO:root:current train perplexity3.549870252609253
INFO:root:current mean train loss 3215.3552779129923
INFO:root:current train perplexity3.551342248916626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4085.697746980275
INFO:root:eval perplexity: 5.218114852905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [13:47:26<1:02:03, 248.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.2468756180774
INFO:root:current train perplexity3.534553050994873
INFO:root:current mean train loss 3197.007505619326
INFO:root:current train perplexity3.5408742427825928
INFO:root:current mean train loss 3199.7181855888775
INFO:root:current train perplexity3.5477664470672607
INFO:root:current mean train loss 3203.895011801204
INFO:root:current train perplexity3.5439295768737793
INFO:root:current mean train loss 3207.4723275011415
INFO:root:current train perplexity3.545423746109009
INFO:root:current mean train loss 3210.4562052198025
INFO:root:current train perplexity3.545522928237915
INFO:root:current mean train loss 3212.2856193621133
INFO:root:current train perplexity3.547562837600708
INFO:root:current mean train loss 3213.0792147008383
INFO:root:current train perplexity3.5494821071624756
INFO:root:current mean train loss 3214.333270006755
INFO:root:current train perplexity3.549638271331787
INFO:root:current mean train loss 3213.3023697850167
INFO:root:current train perplexity3.548701524734497


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4086.3856123254654
INFO:root:eval perplexity: 5.219566822052002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [13:51:32<57:48, 247.75s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.062107130029
INFO:root:current train perplexity3.56937313079834
INFO:root:current mean train loss 3214.797330642129
INFO:root:current train perplexity3.558112621307373
INFO:root:current mean train loss 3217.6297050236826
INFO:root:current train perplexity3.5514416694641113
INFO:root:current mean train loss 3217.849129294856
INFO:root:current train perplexity3.5494394302368164
INFO:root:current mean train loss 3217.794794540875
INFO:root:current train perplexity3.5480306148529053
INFO:root:current mean train loss 3215.6165748609187
INFO:root:current train perplexity3.5488169193267822
INFO:root:current mean train loss 3217.1742261417394
INFO:root:current train perplexity3.5501697063446045
INFO:root:current mean train loss 3214.6033136738606
INFO:root:current train perplexity3.5489954948425293
INFO:root:current mean train loss 3213.677396101237
INFO:root:current train perplexity3.5491225719451904
INFO:root:current mean train loss 3213.2315961998165
INFO:root:current train perplexity3.5492072105407715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 4086.3291812112147
INFO:root:eval perplexity: 5.219448089599609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [13:55:39<53:37, 247.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.0951762952304
INFO:root:current train perplexity3.537576675415039
INFO:root:current mean train loss 3211.757317958734
INFO:root:current train perplexity3.543971300125122
INFO:root:current mean train loss 3208.471359408104
INFO:root:current train perplexity3.541719436645508
INFO:root:current mean train loss 3206.481156670293
INFO:root:current train perplexity3.540973424911499
INFO:root:current mean train loss 3204.9320721867107
INFO:root:current train perplexity3.539440631866455
INFO:root:current mean train loss 3208.5375451352415
INFO:root:current train perplexity3.5442006587982178
INFO:root:current mean train loss 3211.754815015175
INFO:root:current train perplexity3.546360492706299
INFO:root:current mean train loss 3211.7569283731327
INFO:root:current train perplexity3.54636287689209
INFO:root:current mean train loss 3210.8104134842006
INFO:root:current train perplexity3.5464131832122803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 4086.103877507203
INFO:root:eval perplexity: 5.2189717292785645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [13:59:44<49:20, 246.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.1031901041665
INFO:root:current train perplexity3.5020532608032227
INFO:root:current mean train loss 3208.5995477472693
INFO:root:current train perplexity3.5283257961273193
INFO:root:current mean train loss 3206.7293442599293
INFO:root:current train perplexity3.5373013019561768
INFO:root:current mean train loss 3210.875083797442
INFO:root:current train perplexity3.544614791870117
INFO:root:current mean train loss 3208.2156597733792
INFO:root:current train perplexity3.5447466373443604
INFO:root:current mean train loss 3208.8805433997577
INFO:root:current train perplexity3.547079086303711
INFO:root:current mean train loss 3205.6357656703462
INFO:root:current train perplexity3.546231508255005
INFO:root:current mean train loss 3207.0515751411363
INFO:root:current train perplexity3.542851209640503
INFO:root:current mean train loss 3207.276023931254
INFO:root:current train perplexity3.5431103706359863
INFO:root:current mean train loss 3212.0887528226226
INFO:root:current train perplexity3.545783281326294


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it]
INFO:root:eval mean loss: 4086.579816669437
INFO:root:eval perplexity: 5.219976425170898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [14:03:50<45:12, 246.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.6701438210225
INFO:root:current train perplexity3.5502641201019287
INFO:root:current mean train loss 3194.327531144426
INFO:root:current train perplexity3.534719467163086
INFO:root:current mean train loss 3208.2418519512735
INFO:root:current train perplexity3.540562868118286
INFO:root:current mean train loss 3208.0828508088825
INFO:root:current train perplexity3.540257692337036
INFO:root:current mean train loss 3204.6654293310903
INFO:root:current train perplexity3.5422303676605225
INFO:root:current mean train loss 3204.0271808303264
INFO:root:current train perplexity3.5419747829437256
INFO:root:current mean train loss 3202.4503111893923
INFO:root:current train perplexity3.5398199558258057
INFO:root:current mean train loss 3204.8949065604124
INFO:root:current train perplexity3.5422725677490234
INFO:root:current mean train loss 3204.9100042265527
INFO:root:current train perplexity3.54084849357605
INFO:root:current mean train loss 3208.3787936934
INFO:root:current train perplexity3.543166160583496


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4087.082020861037
INFO:root:eval perplexity: 5.221036911010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [14:07:55<40:59, 245.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.5004625822367
INFO:root:current train perplexity3.5541274547576904
INFO:root:current mean train loss 3224.82136497177
INFO:root:current train perplexity3.5496480464935303
INFO:root:current mean train loss 3220.8387055418807
INFO:root:current train perplexity3.546116352081299
INFO:root:current mean train loss 3220.006320869661
INFO:root:current train perplexity3.5465941429138184
INFO:root:current mean train loss 3211.6023333783937
INFO:root:current train perplexity3.543728828430176
INFO:root:current mean train loss 3212.438343908056
INFO:root:current train perplexity3.5441086292266846
INFO:root:current mean train loss 3210.1794169338145
INFO:root:current train perplexity3.5442426204681396
INFO:root:current mean train loss 3209.164538896797
INFO:root:current train perplexity3.543247699737549
INFO:root:current mean train loss 3206.622769049527
INFO:root:current train perplexity3.542191505432129
INFO:root:current mean train loss 3207.12873277467
INFO:root:current train perplexity3.541591167449951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 4086.9968798481827
INFO:root:eval perplexity: 5.2208571434021
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [14:12:03<36:59, 246.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.1282552083335
INFO:root:current train perplexity3.5531699657440186
INFO:root:current mean train loss 3223.953661340428
INFO:root:current train perplexity3.5391194820404053
INFO:root:current mean train loss 3216.4358092992843
INFO:root:current train perplexity3.54232120513916
INFO:root:current mean train loss 3214.871919497802
INFO:root:current train perplexity3.541400671005249
INFO:root:current mean train loss 3211.7901539858385
INFO:root:current train perplexity3.5416460037231445
INFO:root:current mean train loss 3214.917757501186
INFO:root:current train perplexity3.542816162109375
INFO:root:current mean train loss 3211.251070402836
INFO:root:current train perplexity3.5425984859466553
INFO:root:current mean train loss 3208.9297603727864
INFO:root:current train perplexity3.5412867069244385
INFO:root:current mean train loss 3207.760770527887
INFO:root:current train perplexity3.5419161319732666
INFO:root:current mean train loss 3207.800725152963
INFO:root:current train perplexity3.5420382022857666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it]
INFO:root:eval mean loss: 4086.4508290392287
INFO:root:eval perplexity: 5.219704627990723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [14:16:10<32:52, 246.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.9348214285715
INFO:root:current train perplexity3.5388522148132324
INFO:root:current mean train loss 3204.5314362702547
INFO:root:current train perplexity3.536914587020874
INFO:root:current mean train loss 3199.98075340758
INFO:root:current train perplexity3.536832332611084
INFO:root:current mean train loss 3203.211896571828
INFO:root:current train perplexity3.539354085922241
INFO:root:current mean train loss 3207.9509743175286
INFO:root:current train perplexity3.5400867462158203
INFO:root:current mean train loss 3203.0877701518693
INFO:root:current train perplexity3.5361080169677734
INFO:root:current mean train loss 3204.983421121432
INFO:root:current train perplexity3.5388529300689697
INFO:root:current mean train loss 3203.6952739689627
INFO:root:current train perplexity3.539098024368286
INFO:root:current mean train loss 3203.9499611129304
INFO:root:current train perplexity3.5382907390594482
INFO:root:current mean train loss 3204.913664041611
INFO:root:current train perplexity3.5388119220733643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4087.579096368019
INFO:root:eval perplexity: 5.2220869064331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [14:20:16<28:45, 246.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.7716887718025
INFO:root:current train perplexity3.561793804168701
INFO:root:current mean train loss 3206.9706297120847
INFO:root:current train perplexity3.553356647491455
INFO:root:current mean train loss 3205.8855151266716
INFO:root:current train perplexity3.5423877239227295
INFO:root:current mean train loss 3202.3079745011846
INFO:root:current train perplexity3.5435409545898438
INFO:root:current mean train loss 3207.1202670887415
INFO:root:current train perplexity3.5416483879089355
INFO:root:current mean train loss 3207.448278156653
INFO:root:current train perplexity3.540215015411377
INFO:root:current mean train loss 3206.495782783947
INFO:root:current train perplexity3.5404610633850098
INFO:root:current mean train loss 3205.5227500946335
INFO:root:current train perplexity3.5387542247772217
INFO:root:current mean train loss 3208.838763217768
INFO:root:current train perplexity3.5410573482513428
INFO:root:current mean train loss 3208.509897662878
INFO:root:current train perplexity3.540647506713867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4087.402286610705
INFO:root:eval perplexity: 5.221712112426758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [14:24:24<24:41, 246.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3185.0427198223038
INFO:root:current train perplexity3.520242214202881
INFO:root:current mean train loss 3196.5064721518006
INFO:root:current train perplexity3.530630588531494
INFO:root:current mean train loss 3200.6805901394423
INFO:root:current train perplexity3.539700984954834
INFO:root:current mean train loss 3200.661020827769
INFO:root:current train perplexity3.5388474464416504
INFO:root:current mean train loss 3203.114022333183
INFO:root:current train perplexity3.539149045944214
INFO:root:current mean train loss 3205.159758801469
INFO:root:current train perplexity3.541534423828125
INFO:root:current mean train loss 3208.093230216734
INFO:root:current train perplexity3.5433380603790283
INFO:root:current mean train loss 3205.3592856009695
INFO:root:current train perplexity3.540928602218628
INFO:root:current mean train loss 3206.352604759566
INFO:root:current train perplexity3.5415244102478027
INFO:root:current mean train loss 3207.37404936621
INFO:root:current train perplexity3.5422310829162598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4087.668670004987
INFO:root:eval perplexity: 5.2222747802734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [14:28:30<20:33, 246.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.242746126854
INFO:root:current train perplexity3.560091972351074
INFO:root:current mean train loss 3216.12539001081
INFO:root:current train perplexity3.547382354736328
INFO:root:current mean train loss 3217.1831111245174
INFO:root:current train perplexity3.544583559036255
INFO:root:current mean train loss 3214.299646234114
INFO:root:current train perplexity3.5427703857421875
INFO:root:current mean train loss 3210.7522174777027
INFO:root:current train perplexity3.5414512157440186
INFO:root:current mean train loss 3205.559368972915
INFO:root:current train perplexity3.5397770404815674
INFO:root:current mean train loss 3204.464547002442
INFO:root:current train perplexity3.5401086807250977
INFO:root:current mean train loss 3205.309069486475
INFO:root:current train perplexity3.5406951904296875
INFO:root:current mean train loss 3207.216784085328
INFO:root:current train perplexity3.5405290126800537
INFO:root:current mean train loss 3207.690906767303
INFO:root:current train perplexity3.5415446758270264


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.64s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4087.3938455784573
INFO:root:eval perplexity: 5.221695423126221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [14:32:36<16:25, 246.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.8782102670243
INFO:root:current train perplexity3.5390491485595703
INFO:root:current mean train loss 3207.555465241392
INFO:root:current train perplexity3.543992757797241
INFO:root:current mean train loss 3212.0579911707046
INFO:root:current train perplexity3.544005870819092
INFO:root:current mean train loss 3211.095790935797
INFO:root:current train perplexity3.5415420532226562
INFO:root:current mean train loss 3212.5163825155582
INFO:root:current train perplexity3.543454170227051
INFO:root:current mean train loss 3212.0388812245096
INFO:root:current train perplexity3.544072389602661
INFO:root:current mean train loss 3208.9027097779235
INFO:root:current train perplexity3.5420145988464355
INFO:root:current mean train loss 3208.833606227591
INFO:root:current train perplexity3.5427796840667725
INFO:root:current mean train loss 3207.476991928435
INFO:root:current train perplexity3.5416526794433594
INFO:root:current mean train loss 3206.46047093136
INFO:root:current train perplexity3.5405921936035156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4087.7432108128323
INFO:root:eval perplexity: 5.222432613372803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [14:36:44<12:21, 247.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.3067740885417
INFO:root:current train perplexity3.5310165882110596
INFO:root:current mean train loss 3203.3608984375
INFO:root:current train perplexity3.532320499420166
INFO:root:current mean train loss 3203.4349014559657
INFO:root:current train perplexity3.537222385406494
INFO:root:current mean train loss 3200.79157421875
INFO:root:current train perplexity3.536388397216797
INFO:root:current mean train loss 3203.4471787623356
INFO:root:current train perplexity3.534332513809204
INFO:root:current mean train loss 3204.8989644191574
INFO:root:current train perplexity3.534334659576416
INFO:root:current mean train loss 3206.603810402199
INFO:root:current train perplexity3.5369937419891357
INFO:root:current mean train loss 3204.459885332661
INFO:root:current train perplexity3.536221504211426
INFO:root:current mean train loss 3206.3691255580356
INFO:root:current train perplexity3.537018299102783
INFO:root:current mean train loss 3205.126962890625
INFO:root:current train perplexity3.5381593704223633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4087.7907056876106
INFO:root:eval perplexity: 5.222533226013184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [14:40:51<08:14, 247.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.6212702371986
INFO:root:current train perplexity3.5467333793640137
INFO:root:current mean train loss 3213.155046640198
INFO:root:current train perplexity3.5452828407287598
INFO:root:current mean train loss 3214.8191979074645
INFO:root:current train perplexity3.5505828857421875
INFO:root:current mean train loss 3211.508695995839
INFO:root:current train perplexity3.5479516983032227
INFO:root:current mean train loss 3204.308162081069
INFO:root:current train perplexity3.545546293258667
INFO:root:current mean train loss 3207.7659009668473
INFO:root:current train perplexity3.548112630844116
INFO:root:current mean train loss 3207.8634567595855
INFO:root:current train perplexity3.543511390686035
INFO:root:current mean train loss 3207.4842078743613
INFO:root:current train perplexity3.5409836769104004
INFO:root:current mean train loss 3207.17963358446
INFO:root:current train perplexity3.5386884212493896
INFO:root:current mean train loss 3206.639843153929
INFO:root:current train perplexity3.5393903255462646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4087.8087720938606
INFO:root:eval perplexity: 5.222570896148682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [14:44:57<04:06, 246.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.4962064302886
INFO:root:current train perplexity3.5413689613342285
INFO:root:current mean train loss 3196.9567065813153
INFO:root:current train perplexity3.5268893241882324
INFO:root:current mean train loss 3195.0206378530393
INFO:root:current train perplexity3.5300140380859375
INFO:root:current mean train loss 3198.2342813399137
INFO:root:current train perplexity3.5300519466400146
INFO:root:current mean train loss 3201.0188520318866
INFO:root:current train perplexity3.5329782962799072
INFO:root:current mean train loss 3201.8616086182055
INFO:root:current train perplexity3.5369985103607178
INFO:root:current mean train loss 3201.571643437387
INFO:root:current train perplexity3.536363124847412
INFO:root:current mean train loss 3202.8159485249093
INFO:root:current train perplexity3.535579204559326
INFO:root:current mean train loss 3204.242111325933
INFO:root:current train perplexity3.5369601249694824
INFO:root:current mean train loss 3204.1804689470864
INFO:root:current train perplexity3.536508083343506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4087.782645583998
INFO:root:eval perplexity: 5.2225165367126465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_130/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:49:06<00:00, 247.34s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:49:06<00:00, 266.73s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it]
INFO:root:eval mean loss: 4087.782645583998
INFO:root:eval perplexity: 5.2225165367126465
INFO:root:evalaution complete
INFO:root:save model final: small_val_130/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x150581c38f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x150581c308e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x150581b55e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x150581c39a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x150581b53948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x150581c39a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x150581b0eb46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x15058157346a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x15067dd8fa27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x15067dd8fbe0]
python(+0x24a989) [0x565253bc9989]
python(+0x24a9bd) [0x565253bc99bd]
python(+0x24aa14) [0x565253bc9a14]
python(+0x108f75) [0x565253a87f75]
python(Py_RunMain+0x313) [0x565253bcc983]
python(Py_BytesMain+0x39) [0x565253bccbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x15067dd6d0b3]
python(+0x1d6e13) [0x565253b55e13]
/opt/slurm/data/slurmd/job26146192/slurm_script: line 129: 1873762 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_130_final  --output small_val_130 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
