INFO:root:Output: small_val_180
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24476.478969381315
INFO:root:current train perplexity15633.1259765625
INFO:root:current mean train loss 20570.39837370446
INFO:root:current train perplexity3317.72216796875
INFO:root:current mean train loss 17772.158372961956
INFO:root:current train perplexity1104.0989990234375
INFO:root:current mean train loss 15873.632587327695
INFO:root:current train perplexity517.9349975585938
INFO:root:current mean train loss 14496.87759014122
INFO:root:current train perplexity301.0129699707031
INFO:root:current mean train loss 13452.096955211811
INFO:root:current train perplexity200.0373077392578
INFO:root:current mean train loss 12639.536144687723
INFO:root:current train perplexity145.19773864746094
INFO:root:current mean train loss 11987.31182471742
INFO:root:current train perplexity112.54803466796875
INFO:root:current mean train loss 11453.669170714857
INFO:root:current train perplexity91.24105834960938


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.88s/it]
INFO:root:final mean train loss: 11023.77341707291
INFO:root:final train perplexity: 77.41633605957031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 6415.3271969193265
INFO:root:eval perplexity: 13.38547134399414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/1

  0%|          | 1/200 [03:43<12:20:34, 223.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6833.769182477678
INFO:root:current train perplexity14.56845760345459
INFO:root:current mean train loss 6733.497951044101
INFO:root:current train perplexity14.41219711303711
INFO:root:current mean train loss 6706.441939349335
INFO:root:current train perplexity14.182421684265137
INFO:root:current mean train loss 6635.3951388182
INFO:root:current train perplexity13.765463829040527
INFO:root:current mean train loss 6582.147634895194
INFO:root:current train perplexity13.466536521911621
INFO:root:current mean train loss 6533.02724936822
INFO:root:current train perplexity13.200475692749023
INFO:root:current mean train loss 6489.771743397344
INFO:root:current train perplexity12.926416397094727
INFO:root:current mean train loss 6442.575883188208
INFO:root:current train perplexity12.68667984008789
INFO:root:current mean train loss 6398.55934765141
INFO:root:current train perplexity12.461100578308105
INFO:root:current mean train loss 6354.145706462755
INFO:root:current train perplexity12.256978034973145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.53s/it]
INFO:root:final mean train loss: 6316.914808704007
INFO:root:final train perplexity: 12.087907791137695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.93s/it]
INFO:root:eval mean loss: 5549.757348459663
INFO:root:eval perplexity: 9.432476997375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/2

  1%|          | 2/200 [07:37<12:38:46, 229.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6004.439225260417
INFO:root:current train perplexity10.710600852966309
INFO:root:current mean train loss 5896.800513756793
INFO:root:current train perplexity10.30175495147705
INFO:root:current mean train loss 5871.509888263082
INFO:root:current train perplexity10.148019790649414
INFO:root:current mean train loss 5850.48517485119
INFO:root:current train perplexity10.031291961669922
INFO:root:current mean train loss 5825.426344832455
INFO:root:current train perplexity9.938390731811523
INFO:root:current mean train loss 5798.829612598604
INFO:root:current train perplexity9.84701919555664
INFO:root:current mean train loss 5773.376213954522
INFO:root:current train perplexity9.764031410217285
INFO:root:current mean train loss 5753.969056626966
INFO:root:current train perplexity9.683624267578125
INFO:root:current mean train loss 5740.373109183282
INFO:root:current train perplexity9.610891342163086
INFO:root:current mean train loss 5721.248153603142
INFO:root:current train perplexity9.525910377502441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.70s/it]
INFO:root:final mean train loss: 5697.624473202613
INFO:root:final train perplexity: 9.467620849609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.99s/it]
INFO:root:eval mean loss: 5183.070461408466
INFO:root:eval perplexity: 8.132606506347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/3

  2%|â–         | 3/200 [11:34<12:45:10, 233.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5566.367548403533
INFO:root:current train perplexity8.826556205749512
INFO:root:current mean train loss 5485.287403137703
INFO:root:current train perplexity8.717041015625
INFO:root:current mean train loss 5484.274006796525
INFO:root:current train perplexity8.65678596496582
INFO:root:current mean train loss 5458.201558871904
INFO:root:current train perplexity8.57893180847168
INFO:root:current mean train loss 5445.204301261451
INFO:root:current train perplexity8.552539825439453
INFO:root:current mean train loss 5429.709685520734
INFO:root:current train perplexity8.501649856567383
INFO:root:current mean train loss 5420.154109556832
INFO:root:current train perplexity8.469892501831055
INFO:root:current mean train loss 5409.943143261584
INFO:root:current train perplexity8.4337158203125
INFO:root:current mean train loss 5399.315720995026
INFO:root:current train perplexity8.398014068603516
INFO:root:current mean train loss 5388.778055275765
INFO:root:current train perplexity8.363532066345215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.31s/it]
INFO:root:final mean train loss: 5377.939640906549
INFO:root:final train perplexity: 8.345754623413086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.77s/it]
INFO:root:eval mean loss: 4961.276232130984
INFO:root:eval perplexity: 7.434970378875732
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/4

  2%|â–         | 4/200 [15:33<12:49:06, 235.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5317.465678553427
INFO:root:current train perplexity7.95948600769043
INFO:root:current mean train loss 5242.367750328006
INFO:root:current train perplexity7.890180587768555
INFO:root:current mean train loss 5244.831931902732
INFO:root:current train perplexity7.912479400634766
INFO:root:current mean train loss 5233.048664381136
INFO:root:current train perplexity7.8627705574035645
INFO:root:current mean train loss 5225.802019513124
INFO:root:current train perplexity7.828500270843506
INFO:root:current mean train loss 5215.395277924906
INFO:root:current train perplexity7.798842430114746
INFO:root:current mean train loss 5207.420945640601
INFO:root:current train perplexity7.773355007171631
INFO:root:current mean train loss 5199.682307252479
INFO:root:current train perplexity7.75792121887207
INFO:root:current mean train loss 5186.407887593073
INFO:root:current train perplexity7.733286380767822
INFO:root:current mean train loss 5178.370706166924
INFO:root:current train perplexity7.703770637512207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.49s/it]
INFO:root:final mean train loss: 5168.8395337750835
INFO:root:final train perplexity: 7.68489408493042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it]
INFO:root:eval mean loss: 4818.039592337101
INFO:root:eval perplexity: 7.016563892364502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/5

  2%|â–Ž         | 5/200 [19:26<12:42:22, 234.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5072.743902744391
INFO:root:current train perplexity7.31708288192749
INFO:root:current mean train loss 5069.817621683903
INFO:root:current train perplexity7.392761707305908
INFO:root:current mean train loss 5077.373390101988
INFO:root:current train perplexity7.402748107910156
INFO:root:current mean train loss 5060.118964901364
INFO:root:current train perplexity7.3401923179626465
INFO:root:current mean train loss 5057.7035309741605
INFO:root:current train perplexity7.32977819442749
INFO:root:current mean train loss 5044.940678810587
INFO:root:current train perplexity7.304637432098389
INFO:root:current mean train loss 5036.832441589642
INFO:root:current train perplexity7.283652305603027
INFO:root:current mean train loss 5036.643762818208
INFO:root:current train perplexity7.278386116027832
INFO:root:current mean train loss 5032.5493391034715
INFO:root:current train perplexity7.261435031890869
INFO:root:current mean train loss 5024.313342922158
INFO:root:current train perplexity7.245298385620117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.84s/it]
INFO:root:final mean train loss: 5015.691746927077
INFO:root:final train perplexity: 7.234313488006592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.05s/it]
INFO:root:eval mean loss: 4702.344802748227
INFO:root:eval perplexity: 6.695865154266357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/6

  3%|â–Ž         | 6/200 [23:20<12:37:39, 234.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4889.8408203125
INFO:root:current train perplexity6.927693843841553
INFO:root:current mean train loss 4941.829998405612
INFO:root:current train perplexity6.9993414878845215
INFO:root:current mean train loss 4922.99085510501
INFO:root:current train perplexity6.980490207672119
INFO:root:current mean train loss 4922.9353343952625
INFO:root:current train perplexity6.972002029418945
INFO:root:current mean train loss 4920.209742467142
INFO:root:current train perplexity6.961827278137207
INFO:root:current mean train loss 4910.887029393281
INFO:root:current train perplexity6.938906192779541
INFO:root:current mean train loss 4910.746386567813
INFO:root:current train perplexity6.936495304107666
INFO:root:current mean train loss 4907.768495858434
INFO:root:current train perplexity6.924728870391846
INFO:root:current mean train loss 4904.267887696466
INFO:root:current train perplexity6.916284084320068
INFO:root:current mean train loss 4902.1417959469045
INFO:root:current train perplexity6.90566873550415


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.55s/it]
INFO:root:final mean train loss: 4897.014384854225
INFO:root:final train perplexity: 6.903398036956787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it]
INFO:root:eval mean loss: 4614.079113682957
INFO:root:eval perplexity: 6.4610915184021
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/7

  4%|â–Ž         | 7/200 [27:10<12:28:41, 232.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4787.743829900568
INFO:root:current train perplexity6.700002193450928
INFO:root:current mean train loss 4837.738419858871
INFO:root:current train perplexity6.75576114654541
INFO:root:current mean train loss 4829.987161075368
INFO:root:current train perplexity6.710071086883545
INFO:root:current mean train loss 4830.292206756162
INFO:root:current train perplexity6.7056169509887695
INFO:root:current mean train loss 4824.578822544643
INFO:root:current train perplexity6.688937187194824
INFO:root:current mean train loss 4818.546913710586
INFO:root:current train perplexity6.671125888824463
INFO:root:current mean train loss 4816.844353828721
INFO:root:current train perplexity6.66832160949707
INFO:root:current mean train loss 4818.0226743584435
INFO:root:current train perplexity6.662063121795654
INFO:root:current mean train loss 4809.070648871528
INFO:root:current train perplexity6.645647048950195
INFO:root:current mean train loss 4802.229839352913
INFO:root:current train perplexity6.638644695281982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it]
INFO:root:final mean train loss: 4797.639135852937
INFO:root:final train perplexity: 6.637978553771973
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.08s/it]
INFO:root:eval mean loss: 4547.872295406693
INFO:root:eval perplexity: 6.290409088134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/8

  4%|â–         | 8/200 [30:59<12:21:48, 231.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4742.1363854786705
INFO:root:current train perplexity6.436988353729248
INFO:root:current mean train loss 4732.507854438267
INFO:root:current train perplexity6.462627410888672
INFO:root:current mean train loss 4725.951290696293
INFO:root:current train perplexity6.459891319274902
INFO:root:current mean train loss 4736.4392130197575
INFO:root:current train perplexity6.4593892097473145
INFO:root:current mean train loss 4741.003438533511
INFO:root:current train perplexity6.469552516937256
INFO:root:current mean train loss 4732.247684783664
INFO:root:current train perplexity6.454530715942383
INFO:root:current mean train loss 4729.595654149581
INFO:root:current train perplexity6.4521803855896
INFO:root:current mean train loss 4727.799794448312
INFO:root:current train perplexity6.4452056884765625
INFO:root:current mean train loss 4722.846739095995
INFO:root:current train perplexity6.436594009399414
INFO:root:current mean train loss 4719.150722737377
INFO:root:current train perplexity6.426903247833252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.53s/it]
INFO:root:final mean train loss: 4716.885739357241
INFO:root:final train perplexity: 6.42982816696167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.49s/it]
INFO:root:eval mean loss: 4485.276000110815
INFO:root:eval perplexity: 6.133182525634766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/9

  4%|â–         | 9/200 [34:51<12:18:08, 231.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4640.76552871919
INFO:root:current train perplexity6.210947513580322
INFO:root:current mean train loss 4650.429778874269
INFO:root:current train perplexity6.257776260375977
INFO:root:current mean train loss 4674.420755196322
INFO:root:current train perplexity6.297966957092285
INFO:root:current mean train loss 4668.84136189669
INFO:root:current train perplexity6.286542892456055
INFO:root:current mean train loss 4661.544943127156
INFO:root:current train perplexity6.280773639678955
INFO:root:current mean train loss 4662.381059048681
INFO:root:current train perplexity6.277353763580322
INFO:root:current mean train loss 4663.8568688291725
INFO:root:current train perplexity6.2824554443359375
INFO:root:current mean train loss 4654.031863676435
INFO:root:current train perplexity6.2683892250061035
INFO:root:current mean train loss 4656.400549274362
INFO:root:current train perplexity6.265552043914795
INFO:root:current mean train loss 4651.67308338295
INFO:root:current train perplexity6.257360458374023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.79s/it]
INFO:root:final mean train loss: 4647.401033586071
INFO:root:final train perplexity: 6.25595760345459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it]
INFO:root:eval mean loss: 4438.657744279145
INFO:root:eval perplexity: 6.018648624420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/10

  5%|â–Œ         | 10/200 [38:44<12:15:13, 232.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4633.570467019383
INFO:root:current train perplexity6.134098529815674
INFO:root:current mean train loss 4596.841311321578
INFO:root:current train perplexity6.103298187255859
INFO:root:current mean train loss 4605.966911507337
INFO:root:current train perplexity6.114928722381592
INFO:root:current mean train loss 4601.329979566911
INFO:root:current train perplexity6.120347023010254
INFO:root:current mean train loss 4604.764101542112
INFO:root:current train perplexity6.1183342933654785
INFO:root:current mean train loss 4598.045116681509
INFO:root:current train perplexity6.117397785186768
INFO:root:current mean train loss 4597.153720861331
INFO:root:current train perplexity6.113775253295898
INFO:root:current mean train loss 4595.110520173099
INFO:root:current train perplexity6.110260486602783
INFO:root:current mean train loss 4589.942663893629
INFO:root:current train perplexity6.1069793701171875
INFO:root:current mean train loss 4589.91319092545
INFO:root:current train perplexity6.108730316162109


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.88s/it]
INFO:root:final mean train loss: 4587.016635341029
INFO:root:final train perplexity: 6.108680248260498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it]
INFO:root:eval mean loss: 4392.303193220855
INFO:root:eval perplexity: 5.90688419342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/11

  6%|â–Œ         | 11/200 [42:31<12:06:19, 230.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4537.030610183189
INFO:root:current train perplexity5.971467971801758
INFO:root:current mean train loss 4556.883616727941
INFO:root:current train perplexity6.001285552978516
INFO:root:current mean train loss 4544.1570853522435
INFO:root:current train perplexity5.975527763366699
INFO:root:current mean train loss 4545.791855922965
INFO:root:current train perplexity5.991900444030762
INFO:root:current mean train loss 4542.360993246279
INFO:root:current train perplexity5.988886833190918
INFO:root:current mean train loss 4539.425862768846
INFO:root:current train perplexity5.983887195587158
INFO:root:current mean train loss 4538.52659178266
INFO:root:current train perplexity5.984394073486328
INFO:root:current mean train loss 4535.312688922034
INFO:root:current train perplexity5.9773406982421875
INFO:root:current mean train loss 4536.381609962919
INFO:root:current train perplexity5.979085922241211
INFO:root:current mean train loss 4535.699555649221
INFO:root:current train perplexity5.978229999542236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.99s/it]
INFO:root:final mean train loss: 4532.259001270418
INFO:root:final train perplexity: 5.978127479553223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it]
INFO:root:eval mean loss: 4357.564541431184
INFO:root:eval perplexity: 5.824489116668701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/12

  6%|â–Œ         | 12/200 [46:26<12:06:53, 231.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4499.186497738487
INFO:root:current train perplexity5.886420726776123
INFO:root:current mean train loss 4483.541839443109
INFO:root:current train perplexity5.879566192626953
INFO:root:current mean train loss 4486.942021153337
INFO:root:current train perplexity5.886622428894043
INFO:root:current mean train loss 4481.040807332872
INFO:root:current train perplexity5.873121738433838
INFO:root:current mean train loss 4487.006505977746
INFO:root:current train perplexity5.87432336807251
INFO:root:current mean train loss 4481.394157858456
INFO:root:current train perplexity5.870159149169922
INFO:root:current mean train loss 4478.996950174235
INFO:root:current train perplexity5.866422176361084
INFO:root:current mean train loss 4482.959033203125
INFO:root:current train perplexity5.86081600189209
INFO:root:current mean train loss 4484.347339549145
INFO:root:current train perplexity5.862557411193848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.11s/it]
INFO:root:final mean train loss: 4483.226841834284
INFO:root:final train perplexity: 5.863594055175781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.20s/it]
INFO:root:eval mean loss: 4321.619306848404
INFO:root:eval perplexity: 5.740440368652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/13

  6%|â–‹         | 13/200 [50:20<12:04:24, 232.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4731.08251953125
INFO:root:current train perplexity6.095778465270996
INFO:root:current mean train loss 4460.1776443037015
INFO:root:current train perplexity5.765992641448975
INFO:root:current mean train loss 4456.207232094751
INFO:root:current train perplexity5.7614312171936035
INFO:root:current mean train loss 4454.868265586324
INFO:root:current train perplexity5.768459320068359
INFO:root:current mean train loss 4455.894081134654
INFO:root:current train perplexity5.77140474319458
INFO:root:current mean train loss 4451.890676449118
INFO:root:current train perplexity5.773237228393555
INFO:root:current mean train loss 4447.552504809934
INFO:root:current train perplexity5.773094654083252
INFO:root:current mean train loss 4443.839842360864
INFO:root:current train perplexity5.76594877243042
INFO:root:current mean train loss 4442.494998613597
INFO:root:current train perplexity5.763612270355225
INFO:root:current mean train loss 4442.8380314857595
INFO:root:current train perplexity5.763184070587158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.19s/it]
INFO:root:final mean train loss: 4439.391348438879
INFO:root:final train perplexity: 5.763058185577393
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.21s/it]
INFO:root:eval mean loss: 4295.460059632646
INFO:root:eval perplexity: 5.6800384521484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/14

  7%|â–‹         | 14/200 [54:06<11:54:18, 230.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4390.787375710227
INFO:root:current train perplexity5.595022201538086
INFO:root:current mean train loss 4392.006077122044
INFO:root:current train perplexity5.676784515380859
INFO:root:current mean train loss 4384.21577981524
INFO:root:current train perplexity5.675230979919434
INFO:root:current mean train loss 4388.396773261656
INFO:root:current train perplexity5.67247200012207
INFO:root:current mean train loss 4386.941730582801
INFO:root:current train perplexity5.6696672439575195
INFO:root:current mean train loss 4390.399586537579
INFO:root:current train perplexity5.6740312576293945
INFO:root:current mean train loss 4397.945934239464
INFO:root:current train perplexity5.679342746734619
INFO:root:current mean train loss 4399.101417595157
INFO:root:current train perplexity5.676036357879639
INFO:root:current mean train loss 4401.286689730078
INFO:root:current train perplexity5.679812908172607
INFO:root:current mean train loss 4403.511289426969
INFO:root:current train perplexity5.676039695739746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.01s/it]
INFO:root:final mean train loss: 4400.055282838883
INFO:root:final train perplexity: 5.67431116104126
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.08s/it]
INFO:root:eval mean loss: 4271.013109139517
INFO:root:eval perplexity: 5.62416410446167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/15

  8%|â–Š         | 15/200 [57:58<11:52:13, 230.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4426.400172183388
INFO:root:current train perplexity5.674930572509766
INFO:root:current mean train loss 4362.179045348608
INFO:root:current train perplexity5.570465087890625
INFO:root:current mean train loss 4360.554906000285
INFO:root:current train perplexity5.586089134216309
INFO:root:current mean train loss 4359.598840982562
INFO:root:current train perplexity5.588029384613037
INFO:root:current mean train loss 4364.8063621065785
INFO:root:current train perplexity5.594259262084961
INFO:root:current mean train loss 4362.819158124097
INFO:root:current train perplexity5.590674877166748
INFO:root:current mean train loss 4361.3395992149635
INFO:root:current train perplexity5.589545249938965
INFO:root:current mean train loss 4363.631640692911
INFO:root:current train perplexity5.5912065505981445
INFO:root:current mean train loss 4363.22988805899
INFO:root:current train perplexity5.591712474822998
INFO:root:current mean train loss 4362.950928000034
INFO:root:current train perplexity5.588432312011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.97s/it]
INFO:root:final mean train loss: 4363.331549121487
INFO:root:final train perplexity: 5.592690944671631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.39s/it]
INFO:root:eval mean loss: 4247.508690367354
INFO:root:eval perplexity: 5.5709614753723145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/16

  8%|â–Š         | 16/200 [1:01:51<11:50:03, 231.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4357.370071976273
INFO:root:current train perplexity5.586155414581299
INFO:root:current mean train loss 4308.95785402313
INFO:root:current train perplexity5.521085739135742
INFO:root:current mean train loss 4323.200046892208
INFO:root:current train perplexity5.520959377288818
INFO:root:current mean train loss 4322.091661739058
INFO:root:current train perplexity5.515069007873535
INFO:root:current mean train loss 4328.332575563524
INFO:root:current train perplexity5.517655372619629
INFO:root:current mean train loss 4327.945990256611
INFO:root:current train perplexity5.511761665344238
INFO:root:current mean train loss 4327.905490710975
INFO:root:current train perplexity5.509002685546875
INFO:root:current mean train loss 4326.695099590569
INFO:root:current train perplexity5.513633728027344
INFO:root:current mean train loss 4326.561048145594
INFO:root:current train perplexity5.5097737312316895
INFO:root:current mean train loss 4328.5337356518
INFO:root:current train perplexity5.514372825622559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.85s/it]
INFO:root:final mean train loss: 4329.288386560255
INFO:root:final train perplexity: 5.518077373504639
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.26s/it]
INFO:root:eval mean loss: 4226.218086837876
INFO:root:eval perplexity: 5.523205280303955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/17

  8%|â–Š         | 17/200 [1:05:41<11:44:51, 231.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4252.240122767857
INFO:root:current train perplexity5.400535583496094
INFO:root:current mean train loss 4292.96943359375
INFO:root:current train perplexity5.433770656585693
INFO:root:current mean train loss 4289.214905044881
INFO:root:current train perplexity5.440318584442139
INFO:root:current mean train loss 4291.187073664879
INFO:root:current train perplexity5.437092304229736
INFO:root:current mean train loss 4292.07629534842
INFO:root:current train perplexity5.443072319030762
INFO:root:current mean train loss 4303.646006589515
INFO:root:current train perplexity5.447012424468994
INFO:root:current mean train loss 4299.329551396408
INFO:root:current train perplexity5.441099643707275
INFO:root:current mean train loss 4297.670098918474
INFO:root:current train perplexity5.437001705169678
INFO:root:current mean train loss 4298.813284466224
INFO:root:current train perplexity5.444826126098633
INFO:root:current mean train loss 4298.0911561037765
INFO:root:current train perplexity5.447782039642334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.55s/it]
INFO:root:final mean train loss: 4296.864361609182
INFO:root:final train perplexity: 5.447938442230225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it]
INFO:root:eval mean loss: 4211.388522966534
INFO:root:eval perplexity: 5.490184307098389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/18

  9%|â–‰         | 18/200 [1:09:58<12:05:07, 239.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4262.651276344477
INFO:root:current train perplexity5.392770767211914
INFO:root:current mean train loss 4279.0937824382645
INFO:root:current train perplexity5.399631977081299
INFO:root:current mean train loss 4271.308283299576
INFO:root:current train perplexity5.387749671936035
INFO:root:current mean train loss 4277.548965498588
INFO:root:current train perplexity5.4012579917907715
INFO:root:current mean train loss 4279.279645174944
INFO:root:current train perplexity5.399308204650879
INFO:root:current mean train loss 4279.542390096253
INFO:root:current train perplexity5.396873950958252
INFO:root:current mean train loss 4275.744830521603
INFO:root:current train perplexity5.391438961029053
INFO:root:current mean train loss 4272.442413371152
INFO:root:current train perplexity5.387024879455566
INFO:root:current mean train loss 4269.062588910049
INFO:root:current train perplexity5.3849077224731445
INFO:root:current mean train loss 4268.4702311543115
INFO:root:current train perplexity5.3828630447387695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.22s/it]
INFO:root:final mean train loss: 4267.429071118755
INFO:root:final train perplexity: 5.385036945343018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.97s/it]
INFO:root:eval mean loss: 4193.45104374446
INFO:root:eval perplexity: 5.450507164001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/19

 10%|â–‰         | 19/200 [1:14:11<12:13:03, 243.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4208.909122242647
INFO:root:current train perplexity5.2423481941223145
INFO:root:current mean train loss 4209.793924293771
INFO:root:current train perplexity5.2593584060668945
INFO:root:current mean train loss 4239.39437562251
INFO:root:current train perplexity5.288290023803711
INFO:root:current mean train loss 4232.674465951077
INFO:root:current train perplexity5.301957130432129
INFO:root:current mean train loss 4238.473560274044
INFO:root:current train perplexity5.305950164794922
INFO:root:current mean train loss 4237.131006922782
INFO:root:current train perplexity5.311790943145752
INFO:root:current mean train loss 4244.63421171455
INFO:root:current train perplexity5.324513912200928
INFO:root:current mean train loss 4245.518492920897
INFO:root:current train perplexity5.325087070465088
INFO:root:current mean train loss 4245.65671360899
INFO:root:current train perplexity5.328641891479492
INFO:root:current mean train loss 4248.050070135877
INFO:root:current train perplexity5.331972122192383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.57s/it]
INFO:root:final mean train loss: 4241.576524303806
INFO:root:final train perplexity: 5.330391883850098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 4180.697916666667
INFO:root:eval perplexity: 5.422471046447754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/20

 10%|â–ˆ         | 20/200 [1:17:53<11:50:18, 236.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.4555953720865
INFO:root:current train perplexity5.284055233001709
INFO:root:current mean train loss 4238.532874533215
INFO:root:current train perplexity5.275146484375
INFO:root:current mean train loss 4230.463365709459
INFO:root:current train perplexity5.27538537979126
INFO:root:current mean train loss 4227.790572907599
INFO:root:current train perplexity5.283286094665527
INFO:root:current mean train loss 4222.712350217865
INFO:root:current train perplexity5.27625846862793
INFO:root:current mean train loss 4218.858434250615
INFO:root:current train perplexity5.271792411804199
INFO:root:current mean train loss 4221.130268473184
INFO:root:current train perplexity5.273487091064453
INFO:root:current mean train loss 4225.075878520257
INFO:root:current train perplexity5.28329610824585
INFO:root:current mean train loss 4223.211665942866
INFO:root:current train perplexity5.282436370849609
INFO:root:current mean train loss 4220.266591633945
INFO:root:current train perplexity5.278079032897949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.36s/it]
INFO:root:final mean train loss: 4215.7389814930575
INFO:root:final train perplexity: 5.276331424713135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.78s/it]
INFO:root:eval mean loss: 4169.905178205341
INFO:root:eval perplexity: 5.398857116699219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/21

 10%|â–ˆ         | 21/200 [1:21:41<11:38:37, 234.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4169.737935080457
INFO:root:current train perplexity5.217080593109131
INFO:root:current mean train loss 4185.969175418694
INFO:root:current train perplexity5.242713928222656
INFO:root:current mean train loss 4189.447982502341
INFO:root:current train perplexity5.228621482849121
INFO:root:current mean train loss 4185.4663624776485
INFO:root:current train perplexity5.216395378112793
INFO:root:current mean train loss 4189.6762031375465
INFO:root:current train perplexity5.2209272384643555
INFO:root:current mean train loss 4190.049818896743
INFO:root:current train perplexity5.2175798416137695
INFO:root:current mean train loss 4192.236145843094
INFO:root:current train perplexity5.219482898712158
INFO:root:current mean train loss 4193.383743863063
INFO:root:current train perplexity5.220032215118408
INFO:root:current mean train loss 4194.8248813369555
INFO:root:current train perplexity5.220880508422852
INFO:root:current mean train loss 4193.656831443494
INFO:root:current train perplexity5.223862171173096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.46s/it]
INFO:root:final mean train loss: 4191.7985751859605
INFO:root:final train perplexity: 5.2267303466796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.98s/it]
INFO:root:eval mean loss: 4150.3205635666
INFO:root:eval perplexity: 5.356269359588623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/22

 11%|â–ˆ         | 22/200 [1:25:36<11:35:51, 234.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.799554036458
INFO:root:current train perplexity5.172573089599609
INFO:root:current mean train loss 4171.854421037947
INFO:root:current train perplexity5.180688858032227
INFO:root:current mean train loss 4163.994524147727
INFO:root:current train perplexity5.1603312492370605
INFO:root:current mean train loss 4163.754335286459
INFO:root:current train perplexity5.166518211364746
INFO:root:current mean train loss 4163.906592824836
INFO:root:current train perplexity5.1680378913879395
INFO:root:current mean train loss 4169.1846535326085
INFO:root:current train perplexity5.173930644989014
INFO:root:current mean train loss 4167.257235243055
INFO:root:current train perplexity5.176334857940674
INFO:root:current mean train loss 4171.968567918347
INFO:root:current train perplexity5.179779529571533
INFO:root:current mean train loss 4172.105163504464
INFO:root:current train perplexity5.179439544677734
INFO:root:current mean train loss 4173.625415414664
INFO:root:current train perplexity5.17993688583374


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.04s/it]
INFO:root:final mean train loss: 4168.509798357563
INFO:root:final train perplexity: 5.178926467895508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it]
INFO:root:eval mean loss: 4140.229116453346
INFO:root:eval perplexity: 5.3344573974609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/23

 12%|â–ˆâ–        | 23/200 [1:29:32<11:32:22, 234.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4153.893010518637
INFO:root:current train perplexity5.097874641418457
INFO:root:current mean train loss 4150.510271249573
INFO:root:current train perplexity5.118409633636475
INFO:root:current mean train loss 4150.917860051347
INFO:root:current train perplexity5.121253967285156
INFO:root:current mean train loss 4155.826856488658
INFO:root:current train perplexity5.129179000854492
INFO:root:current mean train loss 4157.707110102872
INFO:root:current train perplexity5.13477087020874
INFO:root:current mean train loss 4151.434123907858
INFO:root:current train perplexity5.129024028778076
INFO:root:current mean train loss 4146.255909061013
INFO:root:current train perplexity5.122952938079834
INFO:root:current mean train loss 4151.373256717453
INFO:root:current train perplexity5.133646488189697
INFO:root:current mean train loss 4150.3319646159225
INFO:root:current train perplexity5.136011600494385
INFO:root:current mean train loss 4151.003815349218
INFO:root:current train perplexity5.136990547180176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.95s/it]
INFO:root:final mean train loss: 4147.7590010243075
INFO:root:final train perplexity: 5.136700630187988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.83s/it]
INFO:root:eval mean loss: 4134.038852989251
INFO:root:eval perplexity: 5.3211212158203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/24

 12%|â–ˆâ–        | 24/200 [1:33:34<11:34:51, 236.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4100.6397155091
INFO:root:current train perplexity5.06229829788208
INFO:root:current mean train loss 4112.841400625818
INFO:root:current train perplexity5.079391956329346
INFO:root:current mean train loss 4109.617395564863
INFO:root:current train perplexity5.067250728607178
INFO:root:current mean train loss 4119.144446955922
INFO:root:current train perplexity5.084234237670898
INFO:root:current mean train loss 4118.865974752578
INFO:root:current train perplexity5.08621883392334
INFO:root:current mean train loss 4124.766146742148
INFO:root:current train perplexity5.090049743652344
INFO:root:current mean train loss 4127.260092794636
INFO:root:current train perplexity5.093250274658203
INFO:root:current mean train loss 4131.340512590372
INFO:root:current train perplexity5.094370365142822
INFO:root:current mean train loss 4130.242255727851
INFO:root:current train perplexity5.097177028656006
INFO:root:current mean train loss 4129.697863289133
INFO:root:current train perplexity5.0936431884765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.56s/it]
INFO:root:final mean train loss: 4126.371946211784
INFO:root:final train perplexity: 5.093540191650391
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it]
INFO:root:eval mean loss: 4123.062579648715
INFO:root:eval perplexity: 5.297554969787598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/25

 12%|â–ˆâ–Ž        | 25/200 [1:37:28<11:28:56, 236.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4079.3608250473485
INFO:root:current train perplexity5.060433864593506
INFO:root:current mean train loss 4091.259671158527
INFO:root:current train perplexity5.034909725189209
INFO:root:current mean train loss 4104.240276017716
INFO:root:current train perplexity5.044407367706299
INFO:root:current mean train loss 4110.571246842693
INFO:root:current train perplexity5.054250240325928
INFO:root:current mean train loss 4110.204403435778
INFO:root:current train perplexity5.0515217781066895
INFO:root:current mean train loss 4108.3457642620515
INFO:root:current train perplexity5.0457329750061035
INFO:root:current mean train loss 4108.835705234598
INFO:root:current train perplexity5.047475337982178
INFO:root:current mean train loss 4112.225205518128
INFO:root:current train perplexity5.050955772399902
INFO:root:current mean train loss 4112.615127919911
INFO:root:current train perplexity5.056340217590332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.33s/it]
INFO:root:final mean train loss: 4106.771375225437
INFO:root:final train perplexity: 5.0543036460876465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.11s/it]
INFO:root:eval mean loss: 4114.25323096742
INFO:root:eval perplexity: 5.278718948364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/26

 13%|â–ˆâ–Ž        | 26/200 [1:41:47<11:45:00, 243.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4134.970633370535
INFO:root:current train perplexity5.09058141708374
INFO:root:current mean train loss 4077.775792202103
INFO:root:current train perplexity5.016030311584473
INFO:root:current mean train loss 4087.4167810707277
INFO:root:current train perplexity5.024682521820068
INFO:root:current mean train loss 4089.77975255115
INFO:root:current train perplexity5.021703720092773
INFO:root:current mean train loss 4098.412585659168
INFO:root:current train perplexity5.036037445068359
INFO:root:current mean train loss 4089.9157868936454
INFO:root:current train perplexity5.024816036224365
INFO:root:current mean train loss 4092.2618555009267
INFO:root:current train perplexity5.017655372619629
INFO:root:current mean train loss 4093.6873850087295
INFO:root:current train perplexity5.021605014801025
INFO:root:current mean train loss 4091.7639559494073
INFO:root:current train perplexity5.018955230712891
INFO:root:current mean train loss 4090.0133830515265
INFO:root:current train perplexity5.0166497230529785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.31s/it]
INFO:root:final mean train loss: 4087.7296864294235
INFO:root:final train perplexity: 5.016475677490234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.67s/it]
INFO:root:eval mean loss: 4102.3315914505765
INFO:root:eval perplexity: 5.253331661224365
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/27

 14%|â–ˆâ–Ž        | 27/200 [1:45:47<11:38:15, 242.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.263313802084
INFO:root:current train perplexity4.9416022300720215
INFO:root:current mean train loss 4049.6336553158967
INFO:root:current train perplexity4.958796501159668
INFO:root:current mean train loss 4048.5522267896076
INFO:root:current train perplexity4.957834243774414
INFO:root:current mean train loss 4062.009357173859
INFO:root:current train perplexity4.9720330238342285
INFO:root:current mean train loss 4073.030266378012
INFO:root:current train perplexity4.986739158630371
INFO:root:current mean train loss 4067.1570682266383
INFO:root:current train perplexity4.975289344787598
INFO:root:current mean train loss 4070.7100272325965
INFO:root:current train perplexity4.977848529815674
INFO:root:current mean train loss 4071.58051348066
INFO:root:current train perplexity4.976624011993408
INFO:root:current mean train loss 4075.098383279812
INFO:root:current train perplexity4.980535984039307
INFO:root:current mean train loss 4071.897162899163
INFO:root:current train perplexity4.97898530960083


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.36s/it]
INFO:root:final mean train loss: 4070.5153707688855
INFO:root:final train perplexity: 4.982520580291748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.88s/it]
INFO:root:eval mean loss: 4096.392997146499
INFO:root:eval perplexity: 5.240731716156006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/28

 14%|â–ˆâ–        | 28/200 [1:49:59<11:42:39, 245.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4084.1353282099185
INFO:root:current train perplexity4.95822811126709
INFO:root:current mean train loss 4057.2205443343496
INFO:root:current train perplexity4.9351372718811035
INFO:root:current mean train loss 4065.2511593942686
INFO:root:current train perplexity4.958513259887695
INFO:root:current mean train loss 4054.1730488402186
INFO:root:current train perplexity4.946354389190674
INFO:root:current mean train loss 4065.7329263168585
INFO:root:current train perplexity4.955180644989014
INFO:root:current mean train loss 4067.2673839328395
INFO:root:current train perplexity4.955890655517578
INFO:root:current mean train loss 4059.3856685142455
INFO:root:current train perplexity4.950152397155762
INFO:root:current mean train loss 4056.079789410983
INFO:root:current train perplexity4.948341369628906
INFO:root:current mean train loss 4059.265053360894
INFO:root:current train perplexity4.9503560066223145
INFO:root:current mean train loss 4057.060481806101
INFO:root:current train perplexity4.949263572692871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.30s/it]
INFO:root:final mean train loss: 4052.724896461733
INFO:root:final train perplexity: 4.9476728439331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.08s/it]
INFO:root:eval mean loss: 4091.531669021498
INFO:root:eval perplexity: 5.230439186096191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/29

 14%|â–ˆâ–        | 29/200 [1:53:56<11:31:26, 242.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4062.625047253024
INFO:root:current train perplexity4.9115800857543945
INFO:root:current mean train loss 4042.6846858599715
INFO:root:current train perplexity4.905025959014893
INFO:root:current mean train loss 4057.836778781115
INFO:root:current train perplexity4.918849468231201
INFO:root:current mean train loss 4059.777782613057
INFO:root:current train perplexity4.918529987335205
INFO:root:current mean train loss 4056.9912284974985
INFO:root:current train perplexity4.9144978523254395
INFO:root:current mean train loss 4052.5740665644125
INFO:root:current train perplexity4.915265083312988
INFO:root:current mean train loss 4047.7213902783283
INFO:root:current train perplexity4.912677764892578
INFO:root:current mean train loss 4047.712759036209
INFO:root:current train perplexity4.916096210479736
INFO:root:current mean train loss 4044.2898428098674
INFO:root:current train perplexity4.912267208099365
INFO:root:current mean train loss 4039.157855401618
INFO:root:current train perplexity4.914272785186768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.16s/it]
INFO:root:final mean train loss: 4036.150382134222
INFO:root:final train perplexity: 4.91542387008667
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.54s/it]
INFO:root:eval mean loss: 4080.3331653784353
INFO:root:eval perplexity: 5.206808567047119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/30

 15%|â–ˆâ–Œ        | 30/200 [1:57:51<11:20:39, 240.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4019.730136969151
INFO:root:current train perplexity4.903049468994141
INFO:root:current mean train loss 4014.4006312528104
INFO:root:current train perplexity4.887447357177734
INFO:root:current mean train loss 4020.5113009528636
INFO:root:current train perplexity4.87599515914917
INFO:root:current mean train loss 4016.3759002235433
INFO:root:current train perplexity4.872352123260498
INFO:root:current mean train loss 4024.0425388622934
INFO:root:current train perplexity4.877845764160156
INFO:root:current mean train loss 4021.587124231795
INFO:root:current train perplexity4.878999710083008
INFO:root:current mean train loss 4021.219192815312
INFO:root:current train perplexity4.881041526794434
INFO:root:current mean train loss 4025.5664650551844
INFO:root:current train perplexity4.884363174438477
INFO:root:current mean train loss 4025.054537058161
INFO:root:current train perplexity4.886936664581299
INFO:root:current mean train loss 4023.7213292066026
INFO:root:current train perplexity4.885770320892334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.19s/it]
INFO:root:final mean train loss: 4020.1818713526573
INFO:root:final train perplexity: 4.884554386138916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.62s/it]
INFO:root:eval mean loss: 4078.4573481133643
INFO:root:eval perplexity: 5.202859878540039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/31

 16%|â–ˆâ–Œ        | 31/200 [2:01:43<11:09:33, 237.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3990.17525660738
INFO:root:current train perplexity4.818310260772705
INFO:root:current mean train loss 3991.6290341331846
INFO:root:current train perplexity4.82000732421875
INFO:root:current mean train loss 3983.5415859454074
INFO:root:current train perplexity4.806300163269043
INFO:root:current mean train loss 3995.7524005988835
INFO:root:current train perplexity4.822323799133301
INFO:root:current mean train loss 4000.8331465411775
INFO:root:current train perplexity4.831925392150879
INFO:root:current mean train loss 4003.013274644367
INFO:root:current train perplexity4.842512130737305
INFO:root:current mean train loss 4007.4296467470053
INFO:root:current train perplexity4.849018573760986
INFO:root:current mean train loss 4002.9654248504435
INFO:root:current train perplexity4.849313735961914
INFO:root:current mean train loss 4004.683823766787
INFO:root:current train perplexity4.851720333099365
INFO:root:current mean train loss 4004.756948340153
INFO:root:current train perplexity4.850909233093262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.04s/it]
INFO:root:final mean train loss: 4003.28257443828
INFO:root:final train perplexity: 4.8520965576171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.54s/it]
INFO:root:eval mean loss: 4071.142005000554
INFO:root:eval perplexity: 5.187491416931152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/32

 16%|â–ˆâ–Œ        | 32/200 [2:05:38<11:03:48, 237.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.9001598011364
INFO:root:current train perplexity4.748387336730957
INFO:root:current mean train loss 4002.090461189516
INFO:root:current train perplexity4.809512138366699
INFO:root:current mean train loss 3981.673001876532
INFO:root:current train perplexity4.798923969268799
INFO:root:current mean train loss 3976.499522034551
INFO:root:current train perplexity4.8078718185424805
INFO:root:current mean train loss 3986.294854266827
INFO:root:current train perplexity4.81973123550415
INFO:root:current mean train loss 3987.7644940350506
INFO:root:current train perplexity4.820943832397461
INFO:root:current mean train loss 3992.282089769203
INFO:root:current train perplexity4.823525428771973
INFO:root:current mean train loss 3993.8755794701988
INFO:root:current train perplexity4.823780536651611
INFO:root:current mean train loss 3993.9471091465643
INFO:root:current train perplexity4.823230743408203
INFO:root:current mean train loss 3992.9227774255564
INFO:root:current train perplexity4.826173305511475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.61s/it]
INFO:root:final mean train loss: 3989.0079034374608
INFO:root:final train perplexity: 4.824847221374512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it]
INFO:root:eval mean loss: 4065.8796784962324
INFO:root:eval perplexity: 5.176464080810547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/33

 16%|â–ˆâ–‹        | 33/200 [2:09:40<11:03:41, 238.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3922.8377278645835
INFO:root:current train perplexity4.743474960327148
INFO:root:current mean train loss 3952.393085877588
INFO:root:current train perplexity4.785440444946289
INFO:root:current mean train loss 3951.1952772249288
INFO:root:current train perplexity4.7841949462890625
INFO:root:current mean train loss 3960.712851616305
INFO:root:current train perplexity4.784858703613281
INFO:root:current mean train loss 3971.2145547887417
INFO:root:current train perplexity4.789347171783447
INFO:root:current mean train loss 3967.832312250222
INFO:root:current train perplexity4.783264636993408
INFO:root:current mean train loss 3970.7471259161716
INFO:root:current train perplexity4.790033340454102
INFO:root:current mean train loss 3968.9342516177917
INFO:root:current train perplexity4.7862443923950195
INFO:root:current mean train loss 3970.926156089314
INFO:root:current train perplexity4.7878098487854
INFO:root:current mean train loss 3978.090386284722
INFO:root:current train perplexity4.798201084136963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.56s/it]
INFO:root:final mean train loss: 3974.8331533862697
INFO:root:final train perplexity: 4.797940254211426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.48s/it]
INFO:root:eval mean loss: 4059.307660474845
INFO:root:eval perplexity: 5.162726402282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/34

 17%|â–ˆâ–‹        | 34/200 [2:13:58<11:15:51, 244.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3990.4073606679135
INFO:root:current train perplexity4.770861625671387
INFO:root:current mean train loss 3959.194283111751
INFO:root:current train perplexity4.756335258483887
INFO:root:current mean train loss 3955.1747218058117
INFO:root:current train perplexity4.759241580963135
INFO:root:current mean train loss 3956.8759910398417
INFO:root:current train perplexity4.7536301612854
INFO:root:current mean train loss 3956.5915869451633
INFO:root:current train perplexity4.754018783569336
INFO:root:current mean train loss 3959.925866763354
INFO:root:current train perplexity4.762360572814941
INFO:root:current mean train loss 3962.417639833271
INFO:root:current train perplexity4.766481876373291
INFO:root:current mean train loss 3961.1681976912087
INFO:root:current train perplexity4.765731334686279
INFO:root:current mean train loss 3964.235193473737
INFO:root:current train perplexity4.7686567306518555
INFO:root:current mean train loss 3962.902527295475
INFO:root:current train perplexity4.770049571990967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.15s/it]
INFO:root:final mean train loss: 3960.210151610836
INFO:root:final train perplexity: 4.770339488983154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.73s/it]
INFO:root:eval mean loss: 4055.8739888076243
INFO:root:eval perplexity: 5.1555633544921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/35

 18%|â–ˆâ–Š        | 35/200 [2:18:03<11:12:16, 244.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3974.138690417326
INFO:root:current train perplexity4.76778507232666
INFO:root:current mean train loss 3953.269932240747
INFO:root:current train perplexity4.73579740524292
INFO:root:current mean train loss 3955.791528407818
INFO:root:current train perplexity4.745694160461426
INFO:root:current mean train loss 3952.6891497206875
INFO:root:current train perplexity4.740784645080566
INFO:root:current mean train loss 3949.977675149237
INFO:root:current train perplexity4.741732597351074
INFO:root:current mean train loss 3952.7393122065255
INFO:root:current train perplexity4.7399678230285645
INFO:root:current mean train loss 3952.5521040679077
INFO:root:current train perplexity4.742269039154053
INFO:root:current mean train loss 3950.6656335872312
INFO:root:current train perplexity4.742824077606201
INFO:root:current mean train loss 3948.7357015251705
INFO:root:current train perplexity4.7412109375
INFO:root:current mean train loss 3948.7609000434913
INFO:root:current train perplexity4.743597507476807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.73s/it]
INFO:root:final mean train loss: 3945.716445984379
INFO:root:final train perplexity: 4.74314022064209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.71s/it]
INFO:root:eval mean loss: 4052.6955635666
INFO:root:eval perplexity: 5.1489410400390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/36

 18%|â–ˆâ–Š        | 36/200 [2:22:28<11:25:31, 250.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3901.8485542385056
INFO:root:current train perplexity4.694435119628906
INFO:root:current mean train loss 3907.937492166611
INFO:root:current train perplexity4.684277534484863
INFO:root:current mean train loss 3921.7418940208513
INFO:root:current train perplexity4.697386264801025
INFO:root:current mean train loss 3928.096677794937
INFO:root:current train perplexity4.708441734313965
INFO:root:current mean train loss 3923.9374929815835
INFO:root:current train perplexity4.710740089416504
INFO:root:current mean train loss 3925.439975926986
INFO:root:current train perplexity4.713957786560059
INFO:root:current mean train loss 3929.7328600487854
INFO:root:current train perplexity4.715049743652344
INFO:root:current mean train loss 3932.4106439108164
INFO:root:current train perplexity4.716900825500488
INFO:root:current mean train loss 3933.919300926578
INFO:root:current train perplexity4.715679168701172
INFO:root:current mean train loss 3936.3598751543504
INFO:root:current train perplexity4.720613956451416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.01s/it]
INFO:root:final mean train loss: 3933.4944291268625
INFO:root:final train perplexity: 4.72032356262207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it]
INFO:root:eval mean loss: 4045.6381697417996
INFO:root:eval perplexity: 5.134268283843994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/37

 18%|â–ˆâ–Š        | 37/200 [2:26:27<11:11:33, 247.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3891.650773540296
INFO:root:current train perplexity4.6422529220581055
INFO:root:current mean train loss 3895.4432529547275
INFO:root:current train perplexity4.655206203460693
INFO:root:current mean train loss 3905.586154329979
INFO:root:current train perplexity4.673182964324951
INFO:root:current mean train loss 3898.5630877917324
INFO:root:current train perplexity4.673914909362793
INFO:root:current mean train loss 3905.0728481100064
INFO:root:current train perplexity4.679075241088867
INFO:root:current mean train loss 3909.4458569951416
INFO:root:current train perplexity4.682607173919678
INFO:root:current mean train loss 3910.5102145627247
INFO:root:current train perplexity4.683306694030762
INFO:root:current mean train loss 3917.256762541765
INFO:root:current train perplexity4.690423011779785
INFO:root:current mean train loss 3922.405151503579
INFO:root:current train perplexity4.693781852722168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.89s/it]
INFO:root:final mean train loss: 3919.134925288539
INFO:root:final train perplexity: 4.693656921386719
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it]
INFO:root:eval mean loss: 4043.733917885638
INFO:root:eval perplexity: 5.130316734313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/38

 19%|â–ˆâ–‰        | 38/200 [2:30:57<11:25:31, 253.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3854.3684895833335
INFO:root:current train perplexity4.53181266784668
INFO:root:current mean train loss 3913.079689396238
INFO:root:current train perplexity4.661764621734619
INFO:root:current mean train loss 3902.938118168873
INFO:root:current train perplexity4.653550148010254
INFO:root:current mean train loss 3905.118843305229
INFO:root:current train perplexity4.65302848815918
INFO:root:current mean train loss 3901.0407436172068
INFO:root:current train perplexity4.650361061096191
INFO:root:current mean train loss 3903.7952524113134
INFO:root:current train perplexity4.650922775268555
INFO:root:current mean train loss 3908.933316004612
INFO:root:current train perplexity4.65964937210083
INFO:root:current mean train loss 3907.7820859124954
INFO:root:current train perplexity4.665782928466797
INFO:root:current mean train loss 3910.405449778176
INFO:root:current train perplexity4.668028831481934
INFO:root:current mean train loss 3912.2659026660262
INFO:root:current train perplexity4.6708292961120605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.73s/it]
INFO:root:final mean train loss: 3908.7898610638035
INFO:root:final train perplexity: 4.674539566040039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.76s/it]
INFO:root:eval mean loss: 4039.633730191711
INFO:root:eval perplexity: 5.121817588806152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/39

 20%|â–ˆâ–‰        | 39/200 [2:35:13<11:23:35, 254.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3848.9760520241475
INFO:root:current train perplexity4.582339286804199
INFO:root:current mean train loss 3876.340378220017
INFO:root:current train perplexity4.613351821899414
INFO:root:current mean train loss 3887.9846989780804
INFO:root:current train perplexity4.623985767364502
INFO:root:current mean train loss 3887.4820105255226
INFO:root:current train perplexity4.637129306793213
INFO:root:current mean train loss 3890.290762574133
INFO:root:current train perplexity4.6441650390625
INFO:root:current mean train loss 3894.4027374327297
INFO:root:current train perplexity4.645511150360107
INFO:root:current mean train loss 3892.5779531825387
INFO:root:current train perplexity4.641111373901367
INFO:root:current mean train loss 3895.248133749231
INFO:root:current train perplexity4.646875381469727
INFO:root:current mean train loss 3896.3873440028706
INFO:root:current train perplexity4.646941184997559
INFO:root:current mean train loss 3897.3961180300666
INFO:root:current train perplexity4.6483869552612305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.84s/it]
INFO:root:final mean train loss: 3895.3751210858745
INFO:root:final train perplexity: 4.649865627288818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.47s/it]
INFO:root:eval mean loss: 4036.4269153784353
INFO:root:eval perplexity: 5.115179061889648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/40

 20%|â–ˆâ–ˆ        | 40/200 [2:39:10<11:04:35, 249.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3893.9205643503287
INFO:root:current train perplexity4.6418232917785645
INFO:root:current mean train loss 3878.7280376017593
INFO:root:current train perplexity4.622698783874512
INFO:root:current mean train loss 3876.249663331193
INFO:root:current train perplexity4.61897611618042
INFO:root:current mean train loss 3886.159593731632
INFO:root:current train perplexity4.622625827789307
INFO:root:current mean train loss 3886.2268002312053
INFO:root:current train perplexity4.624189853668213
INFO:root:current mean train loss 3889.5444486467363
INFO:root:current train perplexity4.627352714538574
INFO:root:current mean train loss 3888.441064689772
INFO:root:current train perplexity4.626348495483398
INFO:root:current mean train loss 3893.703928049483
INFO:root:current train perplexity4.634653568267822
INFO:root:current mean train loss 3890.1143546937005
INFO:root:current train perplexity4.630619525909424
INFO:root:current mean train loss 3886.8996061339603
INFO:root:current train perplexity4.629695415496826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.72s/it]
INFO:root:final mean train loss: 3883.933680995818
INFO:root:final train perplexity: 4.628922462463379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.35s/it]
INFO:root:eval mean loss: 4035.521290447695
INFO:root:eval perplexity: 5.113306522369385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/41

 20%|â–ˆâ–ˆ        | 41/200 [2:43:06<10:49:59, 245.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3828.7024377893517
INFO:root:current train perplexity4.582968711853027
INFO:root:current mean train loss 3851.8190110574556
INFO:root:current train perplexity4.574182987213135
INFO:root:current mean train loss 3858.6136544517485
INFO:root:current train perplexity4.588773727416992
INFO:root:current mean train loss 3860.5369831983467
INFO:root:current train perplexity4.584357261657715
INFO:root:current mean train loss 3861.8519095570477
INFO:root:current train perplexity4.590848445892334
INFO:root:current mean train loss 3863.355598464184
INFO:root:current train perplexity4.588527679443359
INFO:root:current mean train loss 3865.680446399646
INFO:root:current train perplexity4.587974548339844
INFO:root:current mean train loss 3870.68165472941
INFO:root:current train perplexity4.596242904663086
INFO:root:current mean train loss 3875.5726423159763
INFO:root:current train perplexity4.603660583496094
INFO:root:current mean train loss 3875.8172137312904
INFO:root:current train perplexity4.605504989624023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.38s/it]
INFO:root:final mean train loss: 3871.876980689264
INFO:root:final train perplexity: 4.6069560050964355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.42s/it]
INFO:root:eval mean loss: 4029.0424943207004
INFO:root:eval perplexity: 5.099928855895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/42

 21%|â–ˆâ–ˆ        | 42/200 [2:46:59<10:36:49, 241.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3804.317354910714
INFO:root:current train perplexity4.554724216461182
INFO:root:current mean train loss 3825.0749095775464
INFO:root:current train perplexity4.560945987701416
INFO:root:current mean train loss 3842.387315076463
INFO:root:current train perplexity4.563485622406006
INFO:root:current mean train loss 3854.4371953708023
INFO:root:current train perplexity4.576767444610596
INFO:root:current mean train loss 3857.0716841774424
INFO:root:current train perplexity4.576239585876465
INFO:root:current mean train loss 3860.484955917786
INFO:root:current train perplexity4.580313205718994
INFO:root:current mean train loss 3860.0283245417077
INFO:root:current train perplexity4.582455635070801
INFO:root:current mean train loss 3864.225014615221
INFO:root:current train perplexity4.584148406982422
INFO:root:current mean train loss 3861.591668226048
INFO:root:current train perplexity4.582153797149658
INFO:root:current mean train loss 3861.597347614472
INFO:root:current train perplexity4.582699298858643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it]
INFO:root:final mean train loss: 3860.440966944541
INFO:root:final train perplexity: 4.586217880249023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.16s/it]
INFO:root:eval mean loss: 4027.577641913231
INFO:root:eval perplexity: 5.096909523010254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/43

 22%|â–ˆâ–ˆâ–       | 43/200 [2:50:51<10:24:26, 238.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3900.899283475654
INFO:root:current train perplexity4.590407371520996
INFO:root:current mean train loss 3870.822996339598
INFO:root:current train perplexity4.580677509307861
INFO:root:current mean train loss 3861.5560779963994
INFO:root:current train perplexity4.56201696395874
INFO:root:current mean train loss 3857.31252918299
INFO:root:current train perplexity4.560523509979248
INFO:root:current mean train loss 3857.398733995838
INFO:root:current train perplexity4.558823585510254
INFO:root:current mean train loss 3857.985883905962
INFO:root:current train perplexity4.563754558563232
INFO:root:current mean train loss 3856.703294721399
INFO:root:current train perplexity4.563897609710693
INFO:root:current mean train loss 3853.6274949660374
INFO:root:current train perplexity4.564544200897217
INFO:root:current mean train loss 3854.883072858745
INFO:root:current train perplexity4.569231986999512
INFO:root:current mean train loss 3853.536321548996
INFO:root:current train perplexity4.568245887756348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.59s/it]
INFO:root:final mean train loss: 3850.6522002066336
INFO:root:final train perplexity: 4.568540573120117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it]
INFO:root:eval mean loss: 4024.37496363863
INFO:root:eval perplexity: 5.0903120040893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/44

 22%|â–ˆâ–ˆâ–       | 44/200 [2:54:46<10:17:31, 237.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3790.680242800245
INFO:root:current train perplexity4.4986701011657715
INFO:root:current mean train loss 3830.402397105236
INFO:root:current train perplexity4.522047519683838
INFO:root:current mean train loss 3833.292178940488
INFO:root:current train perplexity4.532625198364258
INFO:root:current mean train loss 3831.100027404959
INFO:root:current train perplexity4.52973747253418
INFO:root:current mean train loss 3837.638001706278
INFO:root:current train perplexity4.530284881591797
INFO:root:current mean train loss 3841.1677733488827
INFO:root:current train perplexity4.539764404296875
INFO:root:current mean train loss 3836.8553554927516
INFO:root:current train perplexity4.538175582885742
INFO:root:current mean train loss 3839.6562633285826
INFO:root:current train perplexity4.542222023010254
INFO:root:current mean train loss 3837.8912934461296
INFO:root:current train perplexity4.5426344871521
INFO:root:current mean train loss 3840.6619199157135
INFO:root:current train perplexity4.544646739959717


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.62s/it]
INFO:root:final mean train loss: 3838.771101059452
INFO:root:final train perplexity: 4.547175884246826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.52s/it]
INFO:root:eval mean loss: 4021.473321143617
INFO:root:eval perplexity: 5.0843424797058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:58:34<10:06:19, 234.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3826.6911703853284
INFO:root:current train perplexity4.500247001647949
INFO:root:current mean train loss 3830.945180449096
INFO:root:current train perplexity4.523495674133301
INFO:root:current mean train loss 3826.969462626689
INFO:root:current train perplexity4.524096965789795
INFO:root:current mean train loss 3825.3354090953603
INFO:root:current train perplexity4.522474765777588
INFO:root:current mean train loss 3824.7456352549702
INFO:root:current train perplexity4.522908687591553
INFO:root:current mean train loss 3826.3295003109624
INFO:root:current train perplexity4.523809432983398
INFO:root:current mean train loss 3831.2081033941104
INFO:root:current train perplexity4.526209831237793
INFO:root:current mean train loss 3834.2875233525815
INFO:root:current train perplexity4.525028705596924
INFO:root:current mean train loss 3831.554833870689
INFO:root:current train perplexity4.5262837409973145
INFO:root:current mean train loss 3830.4379460212463
INFO:root:current train perplexity4.52584171295166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.82s/it]
INFO:root:final mean train loss: 3827.031052312543
INFO:root:final train perplexity: 4.526162624359131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it]
INFO:root:eval mean loss: 4020.582133408134
INFO:root:eval perplexity: 5.082510948181152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:02:38<10:09:38, 237.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3844.48097160681
INFO:root:current train perplexity4.526086807250977
INFO:root:current mean train loss 3826.891667348896
INFO:root:current train perplexity4.493743896484375
INFO:root:current mean train loss 3817.9095006364114
INFO:root:current train perplexity4.494600772857666
INFO:root:current mean train loss 3824.1659032005705
INFO:root:current train perplexity4.504374980926514
INFO:root:current mean train loss 3828.637882992338
INFO:root:current train perplexity4.50744104385376
INFO:root:current mean train loss 3825.6778157552085
INFO:root:current train perplexity4.505983829498291
INFO:root:current mean train loss 3827.1755535806315
INFO:root:current train perplexity4.513028621673584
INFO:root:current mean train loss 3822.9645665055614
INFO:root:current train perplexity4.509410381317139
INFO:root:current mean train loss 3822.528728339911
INFO:root:current train perplexity4.510005950927734
INFO:root:current mean train loss 3821.2811846096984
INFO:root:current train perplexity4.509407997131348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.49s/it]
INFO:root:final mean train loss: 3817.56689828442
INFO:root:final train perplexity: 4.509294033050537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.09s/it]
INFO:root:eval mean loss: 4023.086436170213
INFO:root:eval perplexity: 5.087658882141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:06:32<10:03:25, 236.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3806.6142220052084
INFO:root:current train perplexity4.43671989440918
INFO:root:current mean train loss 3799.537568359375
INFO:root:current train perplexity4.474111557006836
INFO:root:current mean train loss 3800.2513050426137
INFO:root:current train perplexity4.473665714263916
INFO:root:current mean train loss 3808.071365234375
INFO:root:current train perplexity4.4849748611450195
INFO:root:current mean train loss 3807.6528212376643
INFO:root:current train perplexity4.486594200134277
INFO:root:current mean train loss 3809.335884001359
INFO:root:current train perplexity4.487740993499756
INFO:root:current mean train loss 3808.430806568287
INFO:root:current train perplexity4.488970756530762
INFO:root:current mean train loss 3808.120798576109
INFO:root:current train perplexity4.49199104309082
INFO:root:current mean train loss 3809.6506185825892
INFO:root:current train perplexity4.494160175323486
INFO:root:current mean train loss 3810.4561435797277
INFO:root:current train perplexity4.492487907409668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.35s/it]
INFO:root:final mean train loss: 3807.9914739055016
INFO:root:final train perplexity: 4.49229097366333
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.59s/it]
INFO:root:eval mean loss: 4019.4460431903813
INFO:root:eval perplexity: 5.08017635345459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:10:28<9:58:57, 236.43s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3805.4776449548194
INFO:root:current train perplexity4.455994606018066
INFO:root:current mean train loss 3809.9509464118
INFO:root:current train perplexity4.458730220794678
INFO:root:current mean train loss 3794.6464188107334
INFO:root:current train perplexity4.449549198150635
INFO:root:current mean train loss 3791.189762284799
INFO:root:current train perplexity4.457900524139404
INFO:root:current mean train loss 3791.701785006632
INFO:root:current train perplexity4.46221399307251
INFO:root:current mean train loss 3796.1232998097125
INFO:root:current train perplexity4.45759916305542
INFO:root:current mean train loss 3797.8601610398746
INFO:root:current train perplexity4.462227821350098
INFO:root:current mean train loss 3796.437124902718
INFO:root:current train perplexity4.464853286743164
INFO:root:current mean train loss 3797.1198984839502
INFO:root:current train perplexity4.466813564300537
INFO:root:current mean train loss 3800.3690226526737
INFO:root:current train perplexity4.474660873413086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.16s/it]
INFO:root:final mean train loss: 3797.9586783378354
INFO:root:final train perplexity: 4.474545001983643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.03s/it]
INFO:root:eval mean loss: 4014.1537808898493
INFO:root:eval perplexity: 5.069316387176514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:14:47<10:11:49, 243.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3792.298583984375
INFO:root:current train perplexity4.41127347946167
INFO:root:current mean train loss 3786.4625224967276
INFO:root:current train perplexity4.4264302253723145
INFO:root:current mean train loss 3779.2293915109535
INFO:root:current train perplexity4.436773777008057
INFO:root:current mean train loss 3782.517885330083
INFO:root:current train perplexity4.441387176513672
INFO:root:current mean train loss 3783.6214482759992
INFO:root:current train perplexity4.445132732391357
INFO:root:current mean train loss 3786.319688309671
INFO:root:current train perplexity4.448346138000488
INFO:root:current mean train loss 3784.251487809221
INFO:root:current train perplexity4.446322917938232
INFO:root:current mean train loss 3787.4008992770227
INFO:root:current train perplexity4.450031757354736
INFO:root:current mean train loss 3787.0966629730465
INFO:root:current train perplexity4.451969146728516
INFO:root:current mean train loss 3791.2296493638055
INFO:root:current train perplexity4.457507610321045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.53s/it]
INFO:root:final mean train loss: 3788.353161104264
INFO:root:final train perplexity: 4.4576191902160645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 4014.367464539007
INFO:root:eval perplexity: 5.069754123687744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:19:14<10:25:39, 250.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.229849767203
INFO:root:current train perplexity4.389010906219482
INFO:root:current mean train loss 3769.0209543812816
INFO:root:current train perplexity4.404598712921143
INFO:root:current mean train loss 3772.9885849968646
INFO:root:current train perplexity4.4152350425720215
INFO:root:current mean train loss 3775.6787207276
INFO:root:current train perplexity4.418997764587402
INFO:root:current mean train loss 3780.0273491318576
INFO:root:current train perplexity4.431169509887695
INFO:root:current mean train loss 3779.1461607562082
INFO:root:current train perplexity4.436445236206055
INFO:root:current mean train loss 3775.027379724942
INFO:root:current train perplexity4.436763763427734
INFO:root:current mean train loss 3774.8734554056828
INFO:root:current train perplexity4.436495304107666
INFO:root:current mean train loss 3775.9660663541085
INFO:root:current train perplexity4.436746597290039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.10s/it]
INFO:root:final mean train loss: 3777.9432450571367
INFO:root:final train perplexity: 4.439350605010986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 4015.23775660738
INFO:root:eval perplexity: 5.071538925170898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:22:59<10:02:28, 242.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.001220703125
INFO:root:current train perplexity4.387017726898193
INFO:root:current mean train loss 3766.9958359192465
INFO:root:current train perplexity4.402101993560791
INFO:root:current mean train loss 3768.644077172026
INFO:root:current train perplexity4.415017127990723
INFO:root:current mean train loss 3778.1474609375
INFO:root:current train perplexity4.415910243988037
INFO:root:current mean train loss 3779.7804791874614
INFO:root:current train perplexity4.4231648445129395
INFO:root:current mean train loss 3776.3341110199394
INFO:root:current train perplexity4.421153545379639
INFO:root:current mean train loss 3772.001026838576
INFO:root:current train perplexity4.4197773933410645
INFO:root:current mean train loss 3767.8731843120136
INFO:root:current train perplexity4.419806957244873
INFO:root:current mean train loss 3771.334565835076
INFO:root:current train perplexity4.423933982849121
INFO:root:current mean train loss 3771.6867492743077
INFO:root:current train perplexity4.422852993011475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.17s/it]
INFO:root:final mean train loss: 3769.6101102521343
INFO:root:final train perplexity: 4.424778461456299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4013.921907898382
INFO:root:eval perplexity: 5.068840980529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:26:44<9:45:52, 237.52s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.687955729167
INFO:root:current train perplexity4.483981132507324
INFO:root:current mean train loss 3739.2967646059783
INFO:root:current train perplexity4.377868175506592
INFO:root:current mean train loss 3744.02940475109
INFO:root:current train perplexity4.384932041168213
INFO:root:current mean train loss 3744.053996155754
INFO:root:current train perplexity4.3901848793029785
INFO:root:current mean train loss 3750.1988216538025
INFO:root:current train perplexity4.3905487060546875
INFO:root:current mean train loss 3752.5929915048546
INFO:root:current train perplexity4.393233776092529
INFO:root:current mean train loss 3750.8676055163874
INFO:root:current train perplexity4.398658752441406
INFO:root:current mean train loss 3754.7361358855987
INFO:root:current train perplexity4.401987075805664
INFO:root:current mean train loss 3760.9319066334356
INFO:root:current train perplexity4.404978275299072
INFO:root:current mean train loss 3761.3769131019467
INFO:root:current train perplexity4.40507698059082


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.51s/it]
INFO:root:final mean train loss: 3759.2361100719822
INFO:root:final train perplexity: 4.406705856323242
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4011.8420860344636
INFO:root:eval perplexity: 5.064579963684082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [3:30:27<9:31:20, 233.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3749.4759999150815
INFO:root:current train perplexity4.439246654510498
INFO:root:current mean train loss 3756.9671263655996
INFO:root:current train perplexity4.405447959899902
INFO:root:current mean train loss 3745.374779944997
INFO:root:current train perplexity4.3905839920043945
INFO:root:current mean train loss 3753.7991002321983
INFO:root:current train perplexity4.393860816955566
INFO:root:current mean train loss 3747.984912340241
INFO:root:current train perplexity4.390553951263428
INFO:root:current mean train loss 3754.515618931495
INFO:root:current train perplexity4.397531509399414
INFO:root:current mean train loss 3756.7315515117125
INFO:root:current train perplexity4.39695405960083
INFO:root:current mean train loss 3752.3424901263184
INFO:root:current train perplexity4.391070365905762
INFO:root:current mean train loss 3754.4815274837674
INFO:root:current train perplexity4.3936848640441895
INFO:root:current mean train loss 3756.4796866006736
INFO:root:current train perplexity4.394904613494873


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.36s/it]
INFO:root:final mean train loss: 3750.802967071533
INFO:root:final train perplexity: 4.392068386077881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.89s/it]
INFO:root:eval mean loss: 4009.4835438829787
INFO:root:eval perplexity: 5.059751987457275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:34:40<9:41:50, 239.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3726.302962764617
INFO:root:current train perplexity4.386537551879883
INFO:root:current mean train loss 3730.3315168773856
INFO:root:current train perplexity4.356497764587402
INFO:root:current mean train loss 3743.2842431006493
INFO:root:current train perplexity4.373636722564697
INFO:root:current mean train loss 3734.3868987207325
INFO:root:current train perplexity4.364957809448242
INFO:root:current mean train loss 3737.9736560370143
INFO:root:current train perplexity4.372085094451904
INFO:root:current mean train loss 3741.0911757187205
INFO:root:current train perplexity4.3787007331848145
INFO:root:current mean train loss 3740.134323773029
INFO:root:current train perplexity4.38133430480957
INFO:root:current mean train loss 3741.1804342830883
INFO:root:current train perplexity4.380334854125977
INFO:root:current mean train loss 3742.7958658266584
INFO:root:current train perplexity4.38068962097168
INFO:root:current mean train loss 3744.545723264635
INFO:root:current train perplexity4.3792524337768555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.67s/it]
INFO:root:final mean train loss: 3742.903713964647
INFO:root:final train perplexity: 4.378402233123779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 4012.612412040115
INFO:root:eval perplexity: 5.066158294677734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:38:51<9:46:32, 242.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3697.091796875
INFO:root:current train perplexity4.320335388183594
INFO:root:current mean train loss 3733.5699682441546
INFO:root:current train perplexity4.345278263092041
INFO:root:current mean train loss 3734.060939134414
INFO:root:current train perplexity4.346944808959961
INFO:root:current mean train loss 3729.8976193768435
INFO:root:current train perplexity4.3419508934021
INFO:root:current mean train loss 3726.9655172222024
INFO:root:current train perplexity4.343104839324951
INFO:root:current mean train loss 3724.2568472612766
INFO:root:current train perplexity4.347858428955078
INFO:root:current mean train loss 3725.869914692146
INFO:root:current train perplexity4.350782871246338
INFO:root:current mean train loss 3729.171419094638
INFO:root:current train perplexity4.356997013092041
INFO:root:current mean train loss 3731.6375253743295
INFO:root:current train perplexity4.358705520629883
INFO:root:current mean train loss 3734.9772052216454
INFO:root:current train perplexity4.360570907592773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.75s/it]
INFO:root:final mean train loss: 3732.7859737027075
INFO:root:final train perplexity: 4.360959529876709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 4006.041218209774
INFO:root:eval perplexity: 5.0527143478393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:43:17<9:58:52, 249.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.487315076463
INFO:root:current train perplexity4.338648796081543
INFO:root:current mean train loss 3709.7937659438776
INFO:root:current train perplexity4.3208537101745605
INFO:root:current mean train loss 3717.749927845078
INFO:root:current train perplexity4.326837062835693
INFO:root:current mean train loss 3720.542629626711
INFO:root:current train perplexity4.330415725708008
INFO:root:current mean train loss 3719.288298946099
INFO:root:current train perplexity4.336538314819336
INFO:root:current mean train loss 3722.120453717722
INFO:root:current train perplexity4.3385796546936035
INFO:root:current mean train loss 3727.005677873237
INFO:root:current train perplexity4.342460632324219
INFO:root:current mean train loss 3727.2513762733224
INFO:root:current train perplexity4.344374656677246
INFO:root:current mean train loss 3728.7344199656877
INFO:root:current train perplexity4.346256732940674
INFO:root:current mean train loss 3728.4383028024354
INFO:root:current train perplexity4.346080303192139


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.99s/it]
INFO:root:final mean train loss: 3724.1420109041273
INFO:root:final train perplexity: 4.3461127281188965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4008.14146477449
INFO:root:eval perplexity: 5.0570068359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:47:03<9:38:05, 242.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.561399147727
INFO:root:current train perplexity4.264912128448486
INFO:root:current mean train loss 3693.897397933468
INFO:root:current train perplexity4.299197196960449
INFO:root:current mean train loss 3702.4496428844977
INFO:root:current train perplexity4.302421569824219
INFO:root:current mean train loss 3700.954581591109
INFO:root:current train perplexity4.303150653839111
INFO:root:current mean train loss 3712.375133606628
INFO:root:current train perplexity4.316274166107178
INFO:root:current mean train loss 3712.927810916385
INFO:root:current train perplexity4.321253776550293
INFO:root:current mean train loss 3713.609496138478
INFO:root:current train perplexity4.325558662414551
INFO:root:current mean train loss 3714.214872852856
INFO:root:current train perplexity4.330360412597656
INFO:root:current mean train loss 3715.6590925963997
INFO:root:current train perplexity4.329709529876709
INFO:root:current mean train loss 3717.8561855775524
INFO:root:current train perplexity4.330863952636719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.69s/it]
INFO:root:final mean train loss: 3715.8712842387536
INFO:root:final train perplexity: 4.331953525543213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it]
INFO:root:eval mean loss: 4007.183914076352
INFO:root:eval perplexity: 5.055048942565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:50:52<9:24:16, 238.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3709.9286295572915
INFO:root:current train perplexity4.326375484466553
INFO:root:current mean train loss 3686.6807104941527
INFO:root:current train perplexity4.277533054351807
INFO:root:current mean train loss 3694.6684960194866
INFO:root:current train perplexity4.284022331237793
INFO:root:current mean train loss 3688.087550980329
INFO:root:current train perplexity4.28702449798584
INFO:root:current mean train loss 3694.4369974816077
INFO:root:current train perplexity4.295638561248779
INFO:root:current mean train loss 3697.4752797860237
INFO:root:current train perplexity4.298370838165283
INFO:root:current mean train loss 3699.9269106305383
INFO:root:current train perplexity4.301886558532715
INFO:root:current mean train loss 3701.8496237738573
INFO:root:current train perplexity4.308361053466797
INFO:root:current mean train loss 3704.1581343808843
INFO:root:current train perplexity4.313121795654297
INFO:root:current mean train loss 3709.0171732521253
INFO:root:current train perplexity4.3171706199646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it]
INFO:root:final mean train loss: 3708.3251617185533
INFO:root:final train perplexity: 4.319076061248779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.70s/it]
INFO:root:eval mean loss: 4005.7448540004434
INFO:root:eval perplexity: 5.052107810974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [3:54:40<9:12:46, 235.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3697.3534881161972
INFO:root:current train perplexity4.28540563583374
INFO:root:current mean train loss 3680.3805238601058
INFO:root:current train perplexity4.26295804977417
INFO:root:current mean train loss 3695.5565757610702
INFO:root:current train perplexity4.280378818511963
INFO:root:current mean train loss 3700.00500323766
INFO:root:current train perplexity4.292394638061523
INFO:root:current mean train loss 3698.2916194972468
INFO:root:current train perplexity4.2994585037231445
INFO:root:current mean train loss 3698.786216615587
INFO:root:current train perplexity4.301385402679443
INFO:root:current mean train loss 3699.715272724362
INFO:root:current train perplexity4.3031907081604
INFO:root:current mean train loss 3701.906749047503
INFO:root:current train perplexity4.302711009979248
INFO:root:current mean train loss 3701.8459195160017
INFO:root:current train perplexity4.303328990936279
INFO:root:current mean train loss 3701.9345823812437
INFO:root:current train perplexity4.304440975189209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it]
INFO:root:final mean train loss: 3700.4795287962884
INFO:root:final train perplexity: 4.305728912353516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.06s/it]
INFO:root:eval mean loss: 4006.247059923537
INFO:root:eval perplexity: 5.053134918212891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [3:59:07<9:31:14, 244.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.689153357397
INFO:root:current train perplexity4.287561416625977
INFO:root:current mean train loss 3699.825307153457
INFO:root:current train perplexity4.296252250671387
INFO:root:current mean train loss 3695.8946292562723
INFO:root:current train perplexity4.29749870300293
INFO:root:current mean train loss 3685.650084644006
INFO:root:current train perplexity4.289772033691406
INFO:root:current mean train loss 3686.526406943176
INFO:root:current train perplexity4.286431789398193
INFO:root:current mean train loss 3689.6890837516194
INFO:root:current train perplexity4.290594577789307
INFO:root:current mean train loss 3687.8520950070188
INFO:root:current train perplexity4.286656379699707
INFO:root:current mean train loss 3690.8815758133424
INFO:root:current train perplexity4.289883613586426
INFO:root:current mean train loss 3692.3606851380296
INFO:root:current train perplexity4.289376735687256
INFO:root:current mean train loss 3696.683029408596
INFO:root:current train perplexity4.293577671051025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.52s/it]
INFO:root:final mean train loss: 3693.4530119742117
INFO:root:final train perplexity: 4.293808937072754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.26s/it]
INFO:root:eval mean loss: 4007.8345384530144
INFO:root:eval perplexity: 5.056378364562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:03:16<9:30:13, 246.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.036062657148
INFO:root:current train perplexity4.236937999725342
INFO:root:current mean train loss 3682.8377731241644
INFO:root:current train perplexity4.2686686515808105
INFO:root:current mean train loss 3686.38043999755
INFO:root:current train perplexity4.272790908813477
INFO:root:current mean train loss 3688.4478510578165
INFO:root:current train perplexity4.275590419769287
INFO:root:current mean train loss 3689.0518475479657
INFO:root:current train perplexity4.278212547302246
INFO:root:current mean train loss 3689.275937965822
INFO:root:current train perplexity4.276719570159912
INFO:root:current mean train loss 3687.9391787777477
INFO:root:current train perplexity4.276046276092529
INFO:root:current mean train loss 3686.338683539152
INFO:root:current train perplexity4.277766227722168
INFO:root:current mean train loss 3685.2636278361047
INFO:root:current train perplexity4.276533603668213
INFO:root:current mean train loss 3686.8161586463875
INFO:root:current train perplexity4.277710437774658


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.61s/it]
INFO:root:final mean train loss: 3683.957608499835
INFO:root:final train perplexity: 4.2777533531188965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.45s/it]
INFO:root:eval mean loss: 4008.5349467392507
INFO:root:eval perplexity: 5.057811737060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:06:57<9:08:46, 238.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3652.7211297286185
INFO:root:current train perplexity4.23162841796875
INFO:root:current mean train loss 3668.768176582532
INFO:root:current train perplexity4.253805637359619
INFO:root:current mean train loss 3673.9046643273305
INFO:root:current train perplexity4.257544994354248
INFO:root:current mean train loss 3674.268676448774
INFO:root:current train perplexity4.256619930267334
INFO:root:current mean train loss 3677.9431517321655
INFO:root:current train perplexity4.256297588348389
INFO:root:current mean train loss 3679.493943260898
INFO:root:current train perplexity4.262903213500977
INFO:root:current mean train loss 3679.5163872808002
INFO:root:current train perplexity4.262943267822266
INFO:root:current mean train loss 3681.06946952388
INFO:root:current train perplexity4.268563747406006
INFO:root:current mean train loss 3680.7650431542424
INFO:root:current train perplexity4.267583847045898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.68s/it]
INFO:root:final mean train loss: 3677.1651140643703
INFO:root:final train perplexity: 4.2663044929504395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.00s/it]
INFO:root:eval mean loss: 4006.616550310284
INFO:root:eval perplexity: 5.053889274597168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:10:44<8:56:36, 235.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3695.2111002604165
INFO:root:current train perplexity4.320840358734131
INFO:root:current mean train loss 3675.742237276244
INFO:root:current train perplexity4.247450351715088
INFO:root:current mean train loss 3662.9130197910254
INFO:root:current train perplexity4.237583160400391
INFO:root:current mean train loss 3664.040809354373
INFO:root:current train perplexity4.2483062744140625
INFO:root:current mean train loss 3670.9887101620657
INFO:root:current train perplexity4.251566410064697
INFO:root:current mean train loss 3674.235865568309
INFO:root:current train perplexity4.247401714324951
INFO:root:current mean train loss 3674.072338907675
INFO:root:current train perplexity4.246371746063232
INFO:root:current mean train loss 3670.9375149332104
INFO:root:current train perplexity4.2443528175354
INFO:root:current mean train loss 3671.5100526346514
INFO:root:current train perplexity4.24617862701416
INFO:root:current mean train loss 3671.3173703756574
INFO:root:current train perplexity4.246875762939453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.62s/it]
INFO:root:final mean train loss: 3667.8551640664377
INFO:root:final train perplexity: 4.2506632804870605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.41s/it]
INFO:root:eval mean loss: 4002.213674991689
INFO:root:eval perplexity: 5.0448994636535645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/64
##############best#############
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:14:53<9:02:29, 239.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3642.937899502841
INFO:root:current train perplexity4.2174224853515625
INFO:root:current mean train loss 3677.189167194538
INFO:root:current train perplexity4.23836612701416
INFO:root:current mean train loss 3652.6307899511257
INFO:root:current train perplexity4.226700782775879
INFO:root:current mean train loss 3642.07899087495
INFO:root:current train perplexity4.22094202041626
INFO:root:current mean train loss 3648.3059616645755
INFO:root:current train perplexity4.221421718597412
INFO:root:current mean train loss 3654.970520138974
INFO:root:current train perplexity4.227423667907715
INFO:root:current mean train loss 3659.174903782222
INFO:root:current train perplexity4.232992172241211
INFO:root:current mean train loss 3661.6970709305774
INFO:root:current train perplexity4.237316131591797
INFO:root:current mean train loss 3665.690950480695
INFO:root:current train perplexity4.240610599517822
INFO:root:current mean train loss 3664.034830639836
INFO:root:current train perplexity4.239842414855957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it]
INFO:root:final mean train loss: 3662.350826140373
INFO:root:final train perplexity: 4.2414422035217285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 4004.2553433898493
INFO:root:eval perplexity: 5.049066066741943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:19:25<9:20:33, 249.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.7965794613488
INFO:root:current train perplexity4.194695472717285
INFO:root:current mean train loss 3648.123736213235
INFO:root:current train perplexity4.209118843078613
INFO:root:current mean train loss 3648.815036164027
INFO:root:current train perplexity4.208895206451416
INFO:root:current mean train loss 3651.772610942398
INFO:root:current train perplexity4.211210250854492
INFO:root:current mean train loss 3654.7570672592856
INFO:root:current train perplexity4.218358039855957
INFO:root:current mean train loss 3650.2980025627708
INFO:root:current train perplexity4.211495399475098
INFO:root:current mean train loss 3655.791556757371
INFO:root:current train perplexity4.219298362731934
INFO:root:current mean train loss 3653.83183770319
INFO:root:current train perplexity4.221353530883789
INFO:root:current mean train loss 3652.679615062672
INFO:root:current train perplexity4.218486785888672
INFO:root:current mean train loss 3653.272950812704
INFO:root:current train perplexity4.223334312438965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.87s/it]
INFO:root:final mean train loss: 3653.324884230091
INFO:root:final train perplexity: 4.226365089416504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it]
INFO:root:eval mean loss: 4005.86254190215
INFO:root:eval perplexity: 5.052349090576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:23:59<9:32:47, 256.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3614.9072175202546
INFO:root:current train perplexity4.1248698234558105
INFO:root:current mean train loss 3631.3662359282725
INFO:root:current train perplexity4.181701183319092
INFO:root:current mean train loss 3645.238186605176
INFO:root:current train perplexity4.209165096282959
INFO:root:current mean train loss 3646.295708052609
INFO:root:current train perplexity4.205785274505615
INFO:root:current mean train loss 3649.337039849239
INFO:root:current train perplexity4.205260753631592
INFO:root:current mean train loss 3643.0696542005157
INFO:root:current train perplexity4.2000274658203125
INFO:root:current mean train loss 3643.1068296295603
INFO:root:current train perplexity4.203550815582275
INFO:root:current mean train loss 3643.423926184233
INFO:root:current train perplexity4.207827091217041
INFO:root:current mean train loss 3643.8494166013265
INFO:root:current train perplexity4.209295749664307
INFO:root:current mean train loss 3647.3149743270465
INFO:root:current train perplexity4.212328910827637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.42s/it]
INFO:root:final mean train loss: 3645.571778020551
INFO:root:final train perplexity: 4.213457107543945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it]
INFO:root:eval mean loss: 4004.3146574412676
INFO:root:eval perplexity: 5.049187183380127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:27:54<9:14:03, 249.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.9805943080355
INFO:root:current train perplexity4.155266284942627
INFO:root:current mean train loss 3611.512724247685
INFO:root:current train perplexity4.168615341186523
INFO:root:current mean train loss 3621.817517869016
INFO:root:current train perplexity4.1790385246276855
INFO:root:current mean train loss 3631.2139903509797
INFO:root:current train perplexity4.185596466064453
INFO:root:current mean train loss 3631.3930585488506
INFO:root:current train perplexity4.186628341674805
INFO:root:current mean train loss 3638.9355751679323
INFO:root:current train perplexity4.192774772644043
INFO:root:current mean train loss 3639.1876668614664
INFO:root:current train perplexity4.1902594566345215
INFO:root:current mean train loss 3640.555994233631
INFO:root:current train perplexity4.195683479309082
INFO:root:current mean train loss 3641.995787916355
INFO:root:current train perplexity4.199375629425049
INFO:root:current mean train loss 3643.693129856701
INFO:root:current train perplexity4.201510429382324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.54s/it]
INFO:root:final mean train loss: 3639.2345856082056
INFO:root:final train perplexity: 4.202935695648193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it]
INFO:root:eval mean loss: 4007.1939463513963
INFO:root:eval perplexity: 5.055069923400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [4:31:41<8:55:08, 243.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.4278252180234
INFO:root:current train perplexity4.166905879974365
INFO:root:current mean train loss 3637.9652244727927
INFO:root:current train perplexity4.187451362609863
INFO:root:current mean train loss 3638.1613437982255
INFO:root:current train perplexity4.189704418182373
INFO:root:current mean train loss 3635.3015264839196
INFO:root:current train perplexity4.183379173278809
INFO:root:current mean train loss 3629.8700075171064
INFO:root:current train perplexity4.179741859436035
INFO:root:current mean train loss 3631.9625399257598
INFO:root:current train perplexity4.182129383087158
INFO:root:current mean train loss 3635.7853092650416
INFO:root:current train perplexity4.18555212020874
INFO:root:current mean train loss 3636.6485065034067
INFO:root:current train perplexity4.188687324523926
INFO:root:current mean train loss 3638.69707187639
INFO:root:current train perplexity4.192594051361084
INFO:root:current mean train loss 3635.3247013354985
INFO:root:current train perplexity4.189734935760498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it]
INFO:root:final mean train loss: 3632.0501393964214
INFO:root:final train perplexity: 4.191039562225342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.96s/it]
INFO:root:eval mean loss: 4006.955130069814
INFO:root:eval perplexity: 5.0545806884765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [4:35:28<8:40:24, 238.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.142999387255
INFO:root:current train perplexity4.169182777404785
INFO:root:current mean train loss 3606.5270769738204
INFO:root:current train perplexity4.1627068519592285
INFO:root:current mean train loss 3611.5412879731075
INFO:root:current train perplexity4.160702228546143
INFO:root:current mean train loss 3621.5615470864495
INFO:root:current train perplexity4.173555850982666
INFO:root:current mean train loss 3613.2870898870565
INFO:root:current train perplexity4.169125080108643
INFO:root:current mean train loss 3614.8301392709277
INFO:root:current train perplexity4.173054218292236
INFO:root:current mean train loss 3618.6604135164653
INFO:root:current train perplexity4.174160957336426
INFO:root:current mean train loss 3620.729269502642
INFO:root:current train perplexity4.176443576812744
INFO:root:current mean train loss 3623.9246196455456
INFO:root:current train perplexity4.176418304443359
INFO:root:current mean train loss 3627.296039890165
INFO:root:current train perplexity4.178856372833252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.19s/it]
INFO:root:final mean train loss: 3625.2260188441123
INFO:root:final train perplexity: 4.179771423339844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.17s/it]
INFO:root:eval mean loss: 4008.73700340758
INFO:root:eval perplexity: 5.058225154876709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [4:39:13<8:27:59, 234.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3583.2329846398306
INFO:root:current train perplexity4.157315254211426
INFO:root:current mean train loss 3589.544834352889
INFO:root:current train perplexity4.146572589874268
INFO:root:current mean train loss 3604.6262442688226
INFO:root:current train perplexity4.153870582580566
INFO:root:current mean train loss 3605.380689360637
INFO:root:current train perplexity4.157073974609375
INFO:root:current mean train loss 3607.951629838133
INFO:root:current train perplexity4.1538872718811035
INFO:root:current mean train loss 3608.8574856398145
INFO:root:current train perplexity4.155454158782959
INFO:root:current mean train loss 3610.6750225246587
INFO:root:current train perplexity4.1570515632629395
INFO:root:current mean train loss 3611.8421983078065
INFO:root:current train perplexity4.1607346534729
INFO:root:current mean train loss 3614.5470117073814
INFO:root:current train perplexity4.163073539733887
INFO:root:current mean train loss 3619.9048210517954
INFO:root:current train perplexity4.1657891273498535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.23s/it]
INFO:root:final mean train loss: 3617.798536239132
INFO:root:final train perplexity: 4.167541027069092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 4007.9527613863033
INFO:root:eval perplexity: 5.056620121002197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [4:42:58<8:17:59, 231.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3588.3459800606342
INFO:root:current train perplexity4.1044464111328125
INFO:root:current mean train loss 3590.083443464633
INFO:root:current train perplexity4.115757465362549
INFO:root:current mean train loss 3591.3953432233147
INFO:root:current train perplexity4.127935886383057
INFO:root:current mean train loss 3606.0551085926854
INFO:root:current train perplexity4.143135070800781
INFO:root:current mean train loss 3605.7902879081907
INFO:root:current train perplexity4.142126083374023
INFO:root:current mean train loss 3601.5941930700233
INFO:root:current train perplexity4.143867015838623
INFO:root:current mean train loss 3607.2611568971374
INFO:root:current train perplexity4.146851062774658
INFO:root:current mean train loss 3609.7122495569183
INFO:root:current train perplexity4.151407241821289
INFO:root:current mean train loss 3608.9000729887543
INFO:root:current train perplexity4.151901721954346
INFO:root:current mean train loss 3615.1687902945646
INFO:root:current train perplexity4.159186840057373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.41s/it]
INFO:root:final mean train loss: 3612.5454182778635
INFO:root:final train perplexity: 4.158912658691406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 4013.0276069370566
INFO:root:eval perplexity: 5.0670084953308105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [4:46:47<8:11:49, 230.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3619.5565690104168
INFO:root:current train perplexity4.1276140213012695
INFO:root:current mean train loss 3600.0537123325894
INFO:root:current train perplexity4.1224284172058105
INFO:root:current mean train loss 3604.670496271307
INFO:root:current train perplexity4.129819869995117
INFO:root:current mean train loss 3602.4050989583334
INFO:root:current train perplexity4.138011932373047
INFO:root:current mean train loss 3604.7680494449014
INFO:root:current train perplexity4.1421332359313965
INFO:root:current mean train loss 3605.020177055027
INFO:root:current train perplexity4.1404128074646
INFO:root:current mean train loss 3604.9257606336805
INFO:root:current train perplexity4.141064643859863
INFO:root:current mean train loss 3606.8489440524195
INFO:root:current train perplexity4.145607948303223
INFO:root:current mean train loss 3608.252019810268
INFO:root:current train perplexity4.146015644073486
INFO:root:current mean train loss 3608.6512357271636
INFO:root:current train perplexity4.147670269012451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.46s/it]
INFO:root:final mean train loss: 3605.428061762164
INFO:root:final train perplexity: 4.147251129150391
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.15s/it]
INFO:root:eval mean loss: 4010.881733779366
INFO:root:eval perplexity: 5.062613010406494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [4:50:31<8:04:12, 228.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3566.6362363516564
INFO:root:current train perplexity4.101353645324707
INFO:root:current mean train loss 3584.9032936304643
INFO:root:current train perplexity4.118266582489014
INFO:root:current mean train loss 3596.4577792002538
INFO:root:current train perplexity4.1318817138671875
INFO:root:current mean train loss 3596.165450850604
INFO:root:current train perplexity4.12854528427124
INFO:root:current mean train loss 3597.1540350430255
INFO:root:current train perplexity4.133389472961426
INFO:root:current mean train loss 3597.649215148612
INFO:root:current train perplexity4.136782646179199
INFO:root:current mean train loss 3600.201775613676
INFO:root:current train perplexity4.138176918029785
INFO:root:current mean train loss 3599.4031581756863
INFO:root:current train perplexity4.1355180740356445
INFO:root:current mean train loss 3601.079291511095
INFO:root:current train perplexity4.135962963104248
INFO:root:current mean train loss 3601.6607026481433
INFO:root:current train perplexity4.137402057647705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.63s/it]
INFO:root:final mean train loss: 3599.6611001414635
INFO:root:final train perplexity: 4.1378254890441895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it]
INFO:root:eval mean loss: 4011.736554950687
INFO:root:eval perplexity: 5.064363479614258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [4:54:18<7:59:06, 228.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3603.5540570269573
INFO:root:current train perplexity4.127353668212891
INFO:root:current mean train loss 3584.5506022987565
INFO:root:current train perplexity4.105350494384766
INFO:root:current mean train loss 3591.5767843239905
INFO:root:current train perplexity4.113729476928711
INFO:root:current mean train loss 3587.115860648777
INFO:root:current train perplexity4.113128662109375
INFO:root:current mean train loss 3586.865362163474
INFO:root:current train perplexity4.112945079803467
INFO:root:current mean train loss 3588.825475392608
INFO:root:current train perplexity4.111686706542969
INFO:root:current mean train loss 3590.078194603044
INFO:root:current train perplexity4.11752986907959
INFO:root:current mean train loss 3591.24138223718
INFO:root:current train perplexity4.121283054351807
INFO:root:current mean train loss 3592.591978815937
INFO:root:current train perplexity4.1236348152160645
INFO:root:current mean train loss 3595.3873437598545
INFO:root:current train perplexity4.126307487487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.36s/it]
INFO:root:final mean train loss: 3592.605350309803
INFO:root:final train perplexity: 4.1263227462768555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 4009.7836377299423
INFO:root:eval perplexity: 5.060366153717041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [4:58:04<7:54:02, 227.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3574.9596724076705
INFO:root:current train perplexity4.099843978881836
INFO:root:current mean train loss 3584.9207892489794
INFO:root:current train perplexity4.099942684173584
INFO:root:current mean train loss 3582.2489156563547
INFO:root:current train perplexity4.103261947631836
INFO:root:current mean train loss 3581.808523995536
INFO:root:current train perplexity4.105398178100586
INFO:root:current mean train loss 3584.974187143819
INFO:root:current train perplexity4.106474876403809
INFO:root:current mean train loss 3585.294614559422
INFO:root:current train perplexity4.104194641113281
INFO:root:current mean train loss 3589.0935463748433
INFO:root:current train perplexity4.112669467926025
INFO:root:current mean train loss 3587.0565761523194
INFO:root:current train perplexity4.11249303817749
INFO:root:current mean train loss 3587.908878517363
INFO:root:current train perplexity4.115297794342041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.53s/it]
INFO:root:final mean train loss: 3586.157576653265
INFO:root:final train perplexity: 4.115839958190918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.99s/it]
INFO:root:eval mean loss: 4010.040880568484
INFO:root:eval perplexity: 5.0608930587768555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:01:57<7:53:55, 229.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3574.696602957589
INFO:root:current train perplexity4.09977388381958
INFO:root:current mean train loss 3579.1737254490363
INFO:root:current train perplexity4.106621265411377
INFO:root:current mean train loss 3572.035643351827
INFO:root:current train perplexity4.094010353088379
INFO:root:current mean train loss 3571.119298879021
INFO:root:current train perplexity4.0876240730285645
INFO:root:current mean train loss 3574.5909366841984
INFO:root:current train perplexity4.091531753540039
INFO:root:current mean train loss 3573.602022851948
INFO:root:current train perplexity4.090521812438965
INFO:root:current mean train loss 3578.9447385483163
INFO:root:current train perplexity4.096724510192871
INFO:root:current mean train loss 3579.674234220297
INFO:root:current train perplexity4.099229335784912
INFO:root:current mean train loss 3580.2551596262197
INFO:root:current train perplexity4.100209712982178
INFO:root:current mean train loss 3579.6524796827625
INFO:root:current train perplexity4.100530624389648


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.82s/it]
INFO:root:final mean train loss: 3578.117125788043
INFO:root:final train perplexity: 4.102804660797119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4012.8779954842644
INFO:root:eval perplexity: 5.066701889038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:05:46<7:49:28, 229.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3528.77119140625
INFO:root:current train perplexity4.01943826675415
INFO:root:current mean train loss 3563.182939877717
INFO:root:current train perplexity4.062509536743164
INFO:root:current mean train loss 3568.811979923692
INFO:root:current train perplexity4.070168972015381
INFO:root:current mean train loss 3564.376945374504
INFO:root:current train perplexity4.070202350616455
INFO:root:current mean train loss 3570.162594126506
INFO:root:current train perplexity4.081799507141113
INFO:root:current mean train loss 3571.4135358199333
INFO:root:current train perplexity4.085026264190674
INFO:root:current mean train loss 3568.6891407043954
INFO:root:current train perplexity4.083117485046387
INFO:root:current mean train loss 3572.8805991859704
INFO:root:current train perplexity4.089452266693115
INFO:root:current mean train loss 3573.3514992930404
INFO:root:current train perplexity4.091069221496582
INFO:root:current mean train loss 3574.4042229657616
INFO:root:current train perplexity4.0920209884643555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.21s/it]
INFO:root:final mean train loss: 3573.5356561599237
INFO:root:final train perplexity: 4.095395088195801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it]
INFO:root:eval mean loss: 4012.5880637743794
INFO:root:eval perplexity: 5.066108226776123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:09:32<7:43:58, 228.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3572.4629649286685
INFO:root:current train perplexity4.093897819519043
INFO:root:current mean train loss 3559.1524132209097
INFO:root:current train perplexity4.07939338684082
INFO:root:current mean train loss 3554.238138925869
INFO:root:current train perplexity4.07572603225708
INFO:root:current mean train loss 3559.5648832055435
INFO:root:current train perplexity4.074624061584473
INFO:root:current mean train loss 3558.3695307882685
INFO:root:current train perplexity4.072829246520996
INFO:root:current mean train loss 3558.206102768732
INFO:root:current train perplexity4.075758934020996
INFO:root:current mean train loss 3563.377204711326
INFO:root:current train perplexity4.078521728515625
INFO:root:current mean train loss 3563.822293989886
INFO:root:current train perplexity4.07767915725708
INFO:root:current mean train loss 3566.3243753797083
INFO:root:current train perplexity4.0789055824279785
INFO:root:current mean train loss 3567.1505117695356
INFO:root:current train perplexity4.083017826080322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.58s/it]
INFO:root:final mean train loss: 3566.3691427169306
INFO:root:final train perplexity: 4.083832263946533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.12s/it]
INFO:root:eval mean loss: 4014.6112311613474
INFO:root:eval perplexity: 5.070255279541016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:13:17<7:38:02, 227.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.0553962953627
INFO:root:current train perplexity4.039383888244629
INFO:root:current mean train loss 3554.6355166835638
INFO:root:current train perplexity4.057459354400635
INFO:root:current mean train loss 3560.137159471388
INFO:root:current train perplexity4.059580326080322
INFO:root:current mean train loss 3565.489356648886
INFO:root:current train perplexity4.064286231994629
INFO:root:current mean train loss 3564.0754145292562
INFO:root:current train perplexity4.070304870605469
INFO:root:current mean train loss 3563.8404405381943
INFO:root:current train perplexity4.073862552642822
INFO:root:current mean train loss 3562.956176564357
INFO:root:current train perplexity4.072375297546387
INFO:root:current mean train loss 3562.5592162918947
INFO:root:current train perplexity4.072326183319092
INFO:root:current mean train loss 3565.9845680209273
INFO:root:current train perplexity4.077061176300049
INFO:root:current mean train loss 3562.59593179377
INFO:root:current train perplexity4.075318813323975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.86s/it]
INFO:root:final mean train loss: 3560.2012416470434
INFO:root:final train perplexity: 4.073906898498535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 4016.33945589539
INFO:root:eval perplexity: 5.073799133300781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:17:00<7:32:06, 226.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3516.1299954927886
INFO:root:current train perplexity4.0644612312316895
INFO:root:current mean train loss 3537.557915776754
INFO:root:current train perplexity4.0426554679870605
INFO:root:current mean train loss 3538.212376806028
INFO:root:current train perplexity4.0396270751953125
INFO:root:current mean train loss 3542.718426639703
INFO:root:current train perplexity4.0384345054626465
INFO:root:current mean train loss 3544.532593051502
INFO:root:current train perplexity4.048985958099365
INFO:root:current mean train loss 3544.2393715032176
INFO:root:current train perplexity4.0501532554626465
INFO:root:current mean train loss 3551.250008787534
INFO:root:current train perplexity4.056795120239258
INFO:root:current mean train loss 3553.908620377516
INFO:root:current train perplexity4.062196254730225
INFO:root:current mean train loss 3555.655046756276
INFO:root:current train perplexity4.064099311828613
INFO:root:current mean train loss 3555.7715423551485
INFO:root:current train perplexity4.063911437988281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.48s/it]
INFO:root:final mean train loss: 3554.786787279191
INFO:root:final train perplexity: 4.065213680267334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 4018.5077917220747
INFO:root:eval perplexity: 5.078249454498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [5:20:49<7:30:13, 227.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3560.578395113032
INFO:root:current train perplexity4.0985822677612305
INFO:root:current mean train loss 3564.312322292198
INFO:root:current train perplexity4.067040920257568
INFO:root:current mean train loss 3547.7485321909794
INFO:root:current train perplexity4.050094127655029
INFO:root:current mean train loss 3546.9446729500633
INFO:root:current train perplexity4.048784255981445
INFO:root:current mean train loss 3553.8549935769715
INFO:root:current train perplexity4.050998210906982
INFO:root:current mean train loss 3547.9427644217035
INFO:root:current train perplexity4.050602912902832
INFO:root:current mean train loss 3550.227374918494
INFO:root:current train perplexity4.053105354309082
INFO:root:current mean train loss 3553.591185706367
INFO:root:current train perplexity4.0537261962890625
INFO:root:current mean train loss 3555.756398098528
INFO:root:current train perplexity4.056434154510498
INFO:root:current mean train loss 3552.9088174725284
INFO:root:current train perplexity4.058285236358643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it]
INFO:root:final mean train loss: 3549.686699898012
INFO:root:final train perplexity: 4.057041645050049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it]
INFO:root:eval mean loss: 4016.3981535350176
INFO:root:eval perplexity: 5.07391881942749
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [5:24:36<7:26:18, 226.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3542.330681818182
INFO:root:current train perplexity4.033958435058594
INFO:root:current mean train loss 3538.7845592867943
INFO:root:current train perplexity4.03631067276001
INFO:root:current mean train loss 3535.0474532781864
INFO:root:current train perplexity4.03432559967041
INFO:root:current mean train loss 3540.420164640185
INFO:root:current train perplexity4.044172763824463
INFO:root:current mean train loss 3537.0316717462224
INFO:root:current train perplexity4.046699047088623
INFO:root:current mean train loss 3540.1338075380067
INFO:root:current train perplexity4.047483921051025
INFO:root:current mean train loss 3541.083026821923
INFO:root:current train perplexity4.046614170074463
INFO:root:current mean train loss 3543.561201689259
INFO:root:current train perplexity4.046701431274414
INFO:root:current mean train loss 3544.6372255916485
INFO:root:current train perplexity4.045948028564453
INFO:root:current mean train loss 3547.2531160524377
INFO:root:current train perplexity4.04758882522583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.77s/it]
INFO:root:final mean train loss: 3542.7103820923835
INFO:root:final train perplexity: 4.045890808105469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.24s/it]
INFO:root:eval mean loss: 4015.7506337267287
INFO:root:eval perplexity: 5.072591304779053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [5:28:38<7:31:01, 231.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3533.1854306175596
INFO:root:current train perplexity3.9980063438415527
INFO:root:current mean train loss 3535.753698056461
INFO:root:current train perplexity4.020963191986084
INFO:root:current mean train loss 3525.816383971008
INFO:root:current train perplexity4.025954246520996
INFO:root:current mean train loss 3527.001592630854
INFO:root:current train perplexity4.0292558670043945
INFO:root:current mean train loss 3529.8882020493047
INFO:root:current train perplexity4.026825904846191
INFO:root:current mean train loss 3531.854087165575
INFO:root:current train perplexity4.02982759475708
INFO:root:current mean train loss 3536.573257653422
INFO:root:current train perplexity4.03427791595459
INFO:root:current mean train loss 3539.350478426032
INFO:root:current train perplexity4.037229061126709
INFO:root:current mean train loss 3539.118044679715
INFO:root:current train perplexity4.036288738250732
INFO:root:current mean train loss 3539.230963876314
INFO:root:current train perplexity4.036740779876709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it]
INFO:root:final mean train loss: 3537.081632491081
INFO:root:final train perplexity: 4.036916255950928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.76s/it]
INFO:root:eval mean loss: 4019.3499660627217
INFO:root:eval perplexity: 5.079979419708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [5:32:30<7:28:02, 231.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3506.927617462588
INFO:root:current train perplexity4.007819652557373
INFO:root:current mean train loss 3518.096863863761
INFO:root:current train perplexity4.00773286819458
INFO:root:current mean train loss 3516.1326025931157
INFO:root:current train perplexity4.009505271911621
INFO:root:current mean train loss 3519.052238197018
INFO:root:current train perplexity4.0158233642578125
INFO:root:current mean train loss 3521.6783724580346
INFO:root:current train perplexity4.015509128570557
INFO:root:current mean train loss 3526.9179238554893
INFO:root:current train perplexity4.018939971923828
INFO:root:current mean train loss 3531.472852726807
INFO:root:current train perplexity4.02380895614624
INFO:root:current mean train loss 3535.5532217062864
INFO:root:current train perplexity4.026024341583252
INFO:root:current mean train loss 3536.000798572492
INFO:root:current train perplexity4.0282416343688965
INFO:root:current mean train loss 3534.787291663314
INFO:root:current train perplexity4.028956890106201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.88s/it]
INFO:root:final mean train loss: 3531.9143570315455
INFO:root:final train perplexity: 4.028694152832031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.13s/it]
INFO:root:eval mean loss: 4022.667622451241
INFO:root:eval perplexity: 5.086798667907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [5:36:17<7:21:26, 230.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.4466691801817
INFO:root:current train perplexity4.008448600769043
INFO:root:current mean train loss 3510.306782472067
INFO:root:current train perplexity4.0119853019714355
INFO:root:current mean train loss 3523.5868046804994
INFO:root:current train perplexity4.0145134925842285
INFO:root:current mean train loss 3526.943273056151
INFO:root:current train perplexity4.012211322784424
INFO:root:current mean train loss 3526.5670499861367
INFO:root:current train perplexity4.013364315032959
INFO:root:current mean train loss 3525.4218889147505
INFO:root:current train perplexity4.015492916107178
INFO:root:current mean train loss 3523.7516913659792
INFO:root:current train perplexity4.015909194946289
INFO:root:current mean train loss 3526.251634707959
INFO:root:current train perplexity4.016929626464844
INFO:root:current mean train loss 3527.9227279645725
INFO:root:current train perplexity4.017236232757568
INFO:root:current mean train loss 3528.739461803339
INFO:root:current train perplexity4.017869472503662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.82s/it]
INFO:root:final mean train loss: 3525.395022792201
INFO:root:final train perplexity: 4.018345832824707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 4019.8678904864805
INFO:root:eval perplexity: 5.081042766571045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [5:40:09<7:18:09, 230.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3488.827196143139
INFO:root:current train perplexity3.979292869567871
INFO:root:current mean train loss 3496.80684298755
INFO:root:current train perplexity3.9838128089904785
INFO:root:current mean train loss 3501.8791997291487
INFO:root:current train perplexity4.000854015350342
INFO:root:current mean train loss 3506.9267344708896
INFO:root:current train perplexity4.0012006759643555
INFO:root:current mean train loss 3510.0485634304414
INFO:root:current train perplexity4.0004987716674805
INFO:root:current mean train loss 3516.690354407341
INFO:root:current train perplexity4.005127429962158
INFO:root:current mean train loss 3516.189277571188
INFO:root:current train perplexity4.0032172203063965
INFO:root:current mean train loss 3519.718333068615
INFO:root:current train perplexity4.008159637451172
INFO:root:current mean train loss 3520.8785580674853
INFO:root:current train perplexity4.008458137512207
INFO:root:current mean train loss 3522.32031843655
INFO:root:current train perplexity4.008993625640869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.81s/it]
INFO:root:final mean train loss: 3519.6088718906526
INFO:root:final train perplexity: 4.009182929992676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 4020.7452643644724
INFO:root:eval perplexity: 5.082845687866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [5:44:11<7:20:51, 234.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3513.6228541324012
INFO:root:current train perplexity3.982649803161621
INFO:root:current mean train loss 3525.3804174178686
INFO:root:current train perplexity3.9943935871124268
INFO:root:current mean train loss 3520.6866426112288
INFO:root:current train perplexity3.995980978012085
INFO:root:current mean train loss 3511.4287671825555
INFO:root:current train perplexity3.9906907081604004
INFO:root:current mean train loss 3511.4321767479482
INFO:root:current train perplexity3.990947961807251
INFO:root:current mean train loss 3513.1777249376314
INFO:root:current train perplexity3.989132881164551
INFO:root:current mean train loss 3512.604185167491
INFO:root:current train perplexity3.9915568828582764
INFO:root:current mean train loss 3514.1895191504523
INFO:root:current train perplexity3.995836019515991
INFO:root:current mean train loss 3516.2639544780027
INFO:root:current train perplexity3.9996514320373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.90s/it]
INFO:root:final mean train loss: 3514.6726575051584
INFO:root:final train perplexity: 4.0013837814331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.00s/it]
INFO:root:eval mean loss: 4022.3058198969416
INFO:root:eval perplexity: 5.08605432510376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [5:47:56<7:11:49, 231.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3719.48583984375
INFO:root:current train perplexity4.1163649559021
INFO:root:current mean train loss 3523.4974732630462
INFO:root:current train perplexity3.9945573806762695
INFO:root:current mean train loss 3509.707681890779
INFO:root:current train perplexity3.982239246368408
INFO:root:current mean train loss 3502.8108095477514
INFO:root:current train perplexity3.9735357761383057
INFO:root:current mean train loss 3508.7074747014576
INFO:root:current train perplexity3.9849555492401123
INFO:root:current mean train loss 3508.899463084773
INFO:root:current train perplexity3.9879860877990723
INFO:root:current mean train loss 3509.2890734316697
INFO:root:current train perplexity3.9862759113311768
INFO:root:current mean train loss 3506.3455527510446
INFO:root:current train perplexity3.986083507537842
INFO:root:current mean train loss 3509.166683287282
INFO:root:current train perplexity3.9873361587524414
INFO:root:current mean train loss 3510.157100031146
INFO:root:current train perplexity3.9921512603759766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.52s/it]
INFO:root:final mean train loss: 3509.7490586311587
INFO:root:final train perplexity: 3.9936177730560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.15s/it]
INFO:root:eval mean loss: 4024.149507563165
INFO:root:eval perplexity: 5.089848518371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [5:51:46<7:07:35, 231.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3508.517267400568
INFO:root:current train perplexity3.9398696422576904
INFO:root:current mean train loss 3495.424663921734
INFO:root:current train perplexity3.970862627029419
INFO:root:current mean train loss 3494.3735235856043
INFO:root:current train perplexity3.9722304344177246
INFO:root:current mean train loss 3492.6041075286375
INFO:root:current train perplexity3.9729678630828857
INFO:root:current mean train loss 3490.878393614089
INFO:root:current train perplexity3.966348886489868
INFO:root:current mean train loss 3492.9702253546966
INFO:root:current train perplexity3.9677600860595703
INFO:root:current mean train loss 3495.0338971876276
INFO:root:current train perplexity3.974079132080078
INFO:root:current mean train loss 3501.3656004142495
INFO:root:current train perplexity3.976134777069092
INFO:root:current mean train loss 3501.66884296008
INFO:root:current train perplexity3.978306293487549
INFO:root:current mean train loss 3504.3813382765334
INFO:root:current train perplexity3.982051134109497


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.64s/it]
INFO:root:final mean train loss: 3504.433339457358
INFO:root:final train perplexity: 3.985250949859619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.16s/it]
INFO:root:eval mean loss: 4027.115016206782
INFO:root:eval perplexity: 5.095954895019531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [5:55:36<7:02:59, 230.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.7211014597037
INFO:root:current train perplexity4.022462368011475
INFO:root:current mean train loss 3495.621305064995
INFO:root:current train perplexity3.9548635482788086
INFO:root:current mean train loss 3508.8435705176225
INFO:root:current train perplexity3.9619522094726562
INFO:root:current mean train loss 3506.134419695337
INFO:root:current train perplexity3.9694623947143555
INFO:root:current mean train loss 3507.0074459977254
INFO:root:current train perplexity3.96893048286438
INFO:root:current mean train loss 3505.277487223778
INFO:root:current train perplexity3.9700992107391357
INFO:root:current mean train loss 3501.473400109804
INFO:root:current train perplexity3.9702227115631104
INFO:root:current mean train loss 3498.136089892646
INFO:root:current train perplexity3.9733059406280518
INFO:root:current mean train loss 3499.5154541909915
INFO:root:current train perplexity3.974825859069824
INFO:root:current mean train loss 3503.740781898208
INFO:root:current train perplexity3.97880220413208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.58s/it]
INFO:root:final mean train loss: 3500.2740544349917
INFO:root:final train perplexity: 3.9787168502807617
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4025.6298793495125
INFO:root:eval perplexity: 5.092896461486816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [5:59:29<7:00:28, 231.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.191333912037
INFO:root:current train perplexity3.9805634021759033
INFO:root:current mean train loss 3486.507885549951
INFO:root:current train perplexity3.95692777633667
INFO:root:current mean train loss 3485.2702292555755
INFO:root:current train perplexity3.9593393802642822
INFO:root:current mean train loss 3487.3906892082377
INFO:root:current train perplexity3.9591991901397705
INFO:root:current mean train loss 3482.7701041514197
INFO:root:current train perplexity3.958254337310791
INFO:root:current mean train loss 3488.4847771139707
INFO:root:current train perplexity3.9627254009246826
INFO:root:current mean train loss 3490.4528010366826
INFO:root:current train perplexity3.9614596366882324
INFO:root:current mean train loss 3493.662176538858
INFO:root:current train perplexity3.9648818969726562
INFO:root:current mean train loss 3494.419285397143
INFO:root:current train perplexity3.966931104660034
INFO:root:current mean train loss 3494.6336392070357
INFO:root:current train perplexity3.9669346809387207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.36s/it]
INFO:root:final mean train loss: 3492.7025219086677
INFO:root:final train perplexity: 3.9668490886688232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.31s/it]
INFO:root:eval mean loss: 4029.6052124889184
INFO:root:eval perplexity: 5.1010894775390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:03:41<7:07:37, 237.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.187486049107
INFO:root:current train perplexity3.9457480907440186
INFO:root:current mean train loss 3482.6689001012733
INFO:root:current train perplexity3.947188138961792
INFO:root:current mean train loss 3489.7248285821142
INFO:root:current train perplexity3.957857131958008
INFO:root:current mean train loss 3491.3600367304102
INFO:root:current train perplexity3.9574201107025146
INFO:root:current mean train loss 3495.3290257947197
INFO:root:current train perplexity3.962510585784912
INFO:root:current mean train loss 3496.1811861127335
INFO:root:current train perplexity3.9643313884735107
INFO:root:current mean train loss 3491.5771761195865
INFO:root:current train perplexity3.9583582878112793
INFO:root:current mean train loss 3488.532964963329
INFO:root:current train perplexity3.95701265335083
INFO:root:current mean train loss 3489.7300114614522
INFO:root:current train perplexity3.9581565856933594
INFO:root:current mean train loss 3488.9539926783923
INFO:root:current train perplexity3.956961154937744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.57s/it]
INFO:root:final mean train loss: 3488.9100646357383
INFO:root:final train perplexity: 3.960918426513672
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.30s/it]
INFO:root:eval mean loss: 4029.283952861813
INFO:root:eval perplexity: 5.10042667388916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:07:29<6:58:29, 234.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3446.3473666878635
INFO:root:current train perplexity3.934206247329712
INFO:root:current mean train loss 3484.3725859101837
INFO:root:current train perplexity3.929037570953369
INFO:root:current mean train loss 3478.7248575344006
INFO:root:current train perplexity3.945249080657959
INFO:root:current mean train loss 3479.49589231619
INFO:root:current train perplexity3.9452199935913086
INFO:root:current mean train loss 3479.0665159203936
INFO:root:current train perplexity3.945817232131958
INFO:root:current mean train loss 3479.912459624626
INFO:root:current train perplexity3.9469144344329834
INFO:root:current mean train loss 3481.370394361149
INFO:root:current train perplexity3.9506146907806396
INFO:root:current mean train loss 3486.4977531176396
INFO:root:current train perplexity3.9524824619293213
INFO:root:current mean train loss 3486.472132057199
INFO:root:current train perplexity3.9528756141662598
INFO:root:current mean train loss 3486.6264410251524
INFO:root:current train perplexity3.9530556201934814


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.57s/it]
INFO:root:final mean train loss: 3484.2466221470986
INFO:root:final train perplexity: 3.9536380767822266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.28s/it]
INFO:root:eval mean loss: 4031.540634696365
INFO:root:eval perplexity: 5.105082988739014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [6:11:23<6:54:19, 234.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3468.43159754136
INFO:root:current train perplexity3.950108051300049
INFO:root:current mean train loss 3482.402896704263
INFO:root:current train perplexity3.9430651664733887
INFO:root:current mean train loss 3485.5926032199327
INFO:root:current train perplexity3.9493019580841064
INFO:root:current mean train loss 3483.6490843683227
INFO:root:current train perplexity3.9373342990875244
INFO:root:current mean train loss 3480.6923411299545
INFO:root:current train perplexity3.9377975463867188
INFO:root:current mean train loss 3483.7783198694137
INFO:root:current train perplexity3.9448370933532715
INFO:root:current mean train loss 3482.979731077789
INFO:root:current train perplexity3.9472880363464355
INFO:root:current mean train loss 3482.789687317951
INFO:root:current train perplexity3.9457223415374756
INFO:root:current mean train loss 3482.600600568724
INFO:root:current train perplexity3.947068691253662
INFO:root:current mean train loss 3483.461446062122
INFO:root:current train perplexity3.949413537979126


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.13s/it]
INFO:root:final mean train loss: 3479.735512456586
INFO:root:final train perplexity: 3.9466071128845215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 4031.401516095966
INFO:root:eval perplexity: 5.104795932769775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [6:15:23<6:53:20, 236.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.392106395657
INFO:root:current train perplexity3.8822250366210938
INFO:root:current mean train loss 3453.195522860161
INFO:root:current train perplexity3.8932721614837646
INFO:root:current mean train loss 3457.943927779621
INFO:root:current train perplexity3.904041290283203
INFO:root:current mean train loss 3466.877845360376
INFO:root:current train perplexity3.9151690006256104
INFO:root:current mean train loss 3467.8288026365058
INFO:root:current train perplexity3.91858172416687
INFO:root:current mean train loss 3472.519551340284
INFO:root:current train perplexity3.9232141971588135
INFO:root:current mean train loss 3472.382642824118
INFO:root:current train perplexity3.9266045093536377
INFO:root:current mean train loss 3475.833975046834
INFO:root:current train perplexity3.9314968585968018
INFO:root:current mean train loss 3478.130338409033
INFO:root:current train perplexity3.935370922088623
INFO:root:current mean train loss 3478.5137449389827
INFO:root:current train perplexity3.937237501144409


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.04s/it]
INFO:root:final mean train loss: 3473.96655519547
INFO:root:final train perplexity: 3.9376351833343506
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it]
INFO:root:eval mean loss: 4029.0505907856827
INFO:root:eval perplexity: 5.099945068359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [6:19:10<6:44:33, 233.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.679873338386
INFO:root:current train perplexity3.9601290225982666
INFO:root:current mean train loss 3472.8432500233907
INFO:root:current train perplexity3.9337217807769775
INFO:root:current mean train loss 3477.041377721208
INFO:root:current train perplexity3.933183431625366
INFO:root:current mean train loss 3474.279459191928
INFO:root:current train perplexity3.9269216060638428
INFO:root:current mean train loss 3471.6130559296375
INFO:root:current train perplexity3.9260213375091553
INFO:root:current mean train loss 3469.487460558587
INFO:root:current train perplexity3.926348924636841
INFO:root:current mean train loss 3470.7602762339534
INFO:root:current train perplexity3.9267332553863525
INFO:root:current mean train loss 3468.328258688478
INFO:root:current train perplexity3.9281771183013916
INFO:root:current mean train loss 3472.3703427430255
INFO:root:current train perplexity3.930887222290039
INFO:root:current mean train loss 3471.8980666183265
INFO:root:current train perplexity3.9310104846954346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.87s/it]
INFO:root:final mean train loss: 3469.3849696497764
INFO:root:final train perplexity: 3.9305238723754883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 4033.96490781527
INFO:root:eval perplexity: 5.110089302062988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [6:22:57<6:37:13, 231.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3454.81591796875
INFO:root:current train perplexity3.9290707111358643
INFO:root:current mean train loss 3456.7744935825895
INFO:root:current train perplexity3.9177167415618896
INFO:root:current mean train loss 3467.8244389204547
INFO:root:current train perplexity3.915271282196045
INFO:root:current mean train loss 3470.5439361979165
INFO:root:current train perplexity3.9149394035339355
INFO:root:current mean train loss 3467.5707139185856
INFO:root:current train perplexity3.9174551963806152
INFO:root:current mean train loss 3464.0160890794837
INFO:root:current train perplexity3.919881582260132
INFO:root:current mean train loss 3468.3385145399307
INFO:root:current train perplexity3.921440839767456
INFO:root:current mean train loss 3467.025033392137
INFO:root:current train perplexity3.9215047359466553
INFO:root:current mean train loss 3468.033896205357
INFO:root:current train perplexity3.922057867050171
INFO:root:current mean train loss 3466.1576134314905
INFO:root:current train perplexity3.9226157665252686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.51s/it]
INFO:root:final mean train loss: 3464.480208366148
INFO:root:final train perplexity: 3.9229252338409424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it]
INFO:root:eval mean loss: 4035.941480704233
INFO:root:eval perplexity: 5.114176273345947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [6:26:50<6:34:12, 231.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3446.0526284826806
INFO:root:current train perplexity3.8961069583892822
INFO:root:current mean train loss 3446.4387540556695
INFO:root:current train perplexity3.9036574363708496
INFO:root:current mean train loss 3459.683387567635
INFO:root:current train perplexity3.9038031101226807
INFO:root:current mean train loss 3461.322716934563
INFO:root:current train perplexity3.9027929306030273
INFO:root:current mean train loss 3460.900756077737
INFO:root:current train perplexity3.905271053314209
INFO:root:current mean train loss 3460.2421598614387
INFO:root:current train perplexity3.906749963760376
INFO:root:current mean train loss 3461.746487663571
INFO:root:current train perplexity3.9104104042053223
INFO:root:current mean train loss 3459.7745144626037
INFO:root:current train perplexity3.9104528427124023
INFO:root:current mean train loss 3461.3768958915807
INFO:root:current train perplexity3.9117653369903564
INFO:root:current mean train loss 3462.1822374407902
INFO:root:current train perplexity3.9147396087646484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.55s/it]
INFO:root:final mean train loss: 3459.464365620767
INFO:root:final train perplexity: 3.915170431137085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it]
INFO:root:eval mean loss: 4036.58514793883
INFO:root:eval perplexity: 5.11550760269165
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [6:30:37<6:27:59, 230.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3423.999747810783
INFO:root:current train perplexity3.858597993850708
INFO:root:current mean train loss 3437.6276676517505
INFO:root:current train perplexity3.86855411529541
INFO:root:current mean train loss 3445.209957581615
INFO:root:current train perplexity3.8856091499328613
INFO:root:current mean train loss 3450.5088689857735
INFO:root:current train perplexity3.8933560848236084
INFO:root:current mean train loss 3451.3681456649374
INFO:root:current train perplexity3.8956592082977295
INFO:root:current mean train loss 3451.95143997528
INFO:root:current train perplexity3.895885944366455
INFO:root:current mean train loss 3453.7007846418232
INFO:root:current train perplexity3.8989429473876953
INFO:root:current mean train loss 3454.8738965831426
INFO:root:current train perplexity3.901761531829834
INFO:root:current mean train loss 3453.3527029189463
INFO:root:current train perplexity3.902707815170288
INFO:root:current mean train loss 3457.1562842437406
INFO:root:current train perplexity3.9074621200561523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.76s/it]
INFO:root:final mean train loss: 3454.4242358053884
INFO:root:final train perplexity: 3.9073922634124756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.41s/it]
INFO:root:eval mean loss: 4033.6062548481827
INFO:root:eval perplexity: 5.109349250793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [6:34:23<6:21:59, 229.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3428.815427221433
INFO:root:current train perplexity3.8647427558898926
INFO:root:current mean train loss 3436.275516989243
INFO:root:current train perplexity3.8879101276397705
INFO:root:current mean train loss 3438.994738320443
INFO:root:current train perplexity3.8887476921081543
INFO:root:current mean train loss 3436.5413227893955
INFO:root:current train perplexity3.8848636150360107
INFO:root:current mean train loss 3441.3052574876315
INFO:root:current train perplexity3.8862388134002686
INFO:root:current mean train loss 3443.7705481629537
INFO:root:current train perplexity3.8902111053466797
INFO:root:current mean train loss 3449.5093524370754
INFO:root:current train perplexity3.8954920768737793
INFO:root:current mean train loss 3452.628878138689
INFO:root:current train perplexity3.8975586891174316
INFO:root:current mean train loss 3452.4198824974796
INFO:root:current train perplexity3.8992247581481934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.46s/it]
INFO:root:final mean train loss: 3449.3800899751723
INFO:root:final train perplexity: 3.8996243476867676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.19s/it]
INFO:root:eval mean loss: 4038.815447002438
INFO:root:eval perplexity: 5.120122909545898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [6:38:20<6:21:52, 231.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.1648995535716
INFO:root:current train perplexity3.8560574054718018
INFO:root:current mean train loss 3469.6684479044975
INFO:root:current train perplexity3.895751714706421
INFO:root:current mean train loss 3452.351659212711
INFO:root:current train perplexity3.882020950317383
INFO:root:current mean train loss 3444.377075592936
INFO:root:current train perplexity3.88826322555542
INFO:root:current mean train loss 3449.4666121199325
INFO:root:current train perplexity3.890371561050415
INFO:root:current mean train loss 3449.2166918993466
INFO:root:current train perplexity3.893228054046631
INFO:root:current mean train loss 3446.8903989587625
INFO:root:current train perplexity3.8889057636260986
INFO:root:current mean train loss 3445.874549358535
INFO:root:current train perplexity3.889543294906616
INFO:root:current mean train loss 3447.376489348571
INFO:root:current train perplexity3.8921146392822266
INFO:root:current mean train loss 3446.5993356252584
INFO:root:current train perplexity3.893019199371338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.55s/it]
INFO:root:final mean train loss: 3445.2034678920622
INFO:root:final train perplexity: 3.8932042121887207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it]
INFO:root:eval mean loss: 4042.392425753546
INFO:root:eval perplexity: 5.127533435821533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [6:42:20<6:22:12, 234.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3430.301806640625
INFO:root:current train perplexity3.8459181785583496
INFO:root:current mean train loss 3427.708056640625
INFO:root:current train perplexity3.848426580429077
INFO:root:current mean train loss 3425.949843295785
INFO:root:current train perplexity3.85807728767395
INFO:root:current mean train loss 3443.113082062252
INFO:root:current train perplexity3.87626576423645
INFO:root:current mean train loss 3448.484327348456
INFO:root:current train perplexity3.8812777996063232
INFO:root:current mean train loss 3443.337962682039
INFO:root:current train perplexity3.877655029296875
INFO:root:current mean train loss 3444.147168762703
INFO:root:current train perplexity3.879659414291382
INFO:root:current mean train loss 3441.7078066952577
INFO:root:current train perplexity3.8811261653900146
INFO:root:current mean train loss 3441.566692328892
INFO:root:current train perplexity3.88338041305542
INFO:root:current mean train loss 3443.1184805114412
INFO:root:current train perplexity3.8865718841552734


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.92s/it]
INFO:root:final mean train loss: 3442.281550868865
INFO:root:final train perplexity: 3.888719081878662
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 4038.061691392398
INFO:root:eval perplexity: 5.118561744689941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [6:46:19<6:20:30, 235.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3376.2823963994565
INFO:root:current train perplexity3.8286211490631104
INFO:root:current mean train loss 3424.611574250508
INFO:root:current train perplexity3.845491409301758
INFO:root:current mean train loss 3429.1507015484867
INFO:root:current train perplexity3.857764959335327
INFO:root:current mean train loss 3427.4775012698337
INFO:root:current train perplexity3.8606650829315186
INFO:root:current mean train loss 3427.083534763778
INFO:root:current train perplexity3.863827705383301
INFO:root:current mean train loss 3430.9420149677344
INFO:root:current train perplexity3.8712830543518066
INFO:root:current mean train loss 3434.1664235710523
INFO:root:current train perplexity3.875345230102539
INFO:root:current mean train loss 3436.187760011454
INFO:root:current train perplexity3.8790853023529053
INFO:root:current mean train loss 3436.5437041383466
INFO:root:current train perplexity3.878478765487671
INFO:root:current mean train loss 3436.872674712639
INFO:root:current train perplexity3.876591920852661


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.60s/it]
INFO:root:final mean train loss: 3436.0505394474153
INFO:root:final train perplexity: 3.8791704177856445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.88s/it]
INFO:root:eval mean loss: 4039.9986909906916
INFO:root:eval perplexity: 5.122574329376221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [6:50:14<6:16:39, 235.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3374.7697832661293
INFO:root:current train perplexity3.813091993331909
INFO:root:current mean train loss 3405.951395515267
INFO:root:current train perplexity3.841724157333374
INFO:root:current mean train loss 3402.2303355823865
INFO:root:current train perplexity3.848198413848877
INFO:root:current mean train loss 3411.2087520357345
INFO:root:current train perplexity3.8563599586486816
INFO:root:current mean train loss 3412.793548229952
INFO:root:current train perplexity3.8563649654388428
INFO:root:current mean train loss 3418.8614003097045
INFO:root:current train perplexity3.860713481903076
INFO:root:current mean train loss 3425.3306348894366
INFO:root:current train perplexity3.8654143810272217
INFO:root:current mean train loss 3428.0969381893383
INFO:root:current train perplexity3.86818790435791
INFO:root:current mean train loss 3434.401222054565
INFO:root:current train perplexity3.874460220336914
INFO:root:current mean train loss 3434.273802006411
INFO:root:current train perplexity3.8727309703826904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.44s/it]
INFO:root:final mean train loss: 3432.9764350152786
INFO:root:final train perplexity: 3.874469041824341
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.35s/it]
INFO:root:eval mean loss: 4040.967215896498
INFO:root:eval perplexity: 5.124579429626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [6:54:12<6:13:53, 236.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.1398237179487
INFO:root:current train perplexity3.864917278289795
INFO:root:current mean train loss 3433.5392346279227
INFO:root:current train perplexity3.8656721115112305
INFO:root:current mean train loss 3427.474267169521
INFO:root:current train perplexity3.8655991554260254
INFO:root:current mean train loss 3437.173025125599
INFO:root:current train perplexity3.8678524494171143
INFO:root:current mean train loss 3432.3103494492098
INFO:root:current train perplexity3.863027334213257
INFO:root:current mean train loss 3431.34172893234
INFO:root:current train perplexity3.863121747970581
INFO:root:current mean train loss 3434.1815175995207
INFO:root:current train perplexity3.8647522926330566
INFO:root:current mean train loss 3435.3911710953357
INFO:root:current train perplexity3.866912364959717
INFO:root:current mean train loss 3432.575557886062
INFO:root:current train perplexity3.8657236099243164
INFO:root:current mean train loss 3432.0820884501463
INFO:root:current train perplexity3.867377996444702


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.44s/it]
INFO:root:final mean train loss: 3428.5691851339034
INFO:root:final train perplexity: 3.8677375316619873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.04s/it]
INFO:root:eval mean loss: 4044.72090397828
INFO:root:eval perplexity: 5.132363796234131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [6:58:05<6:08:41, 235.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.9857775099736
INFO:root:current train perplexity3.8143577575683594
INFO:root:current mean train loss 3403.812132958652
INFO:root:current train perplexity3.8448359966278076
INFO:root:current mean train loss 3405.1408078583627
INFO:root:current train perplexity3.8405303955078125
INFO:root:current mean train loss 3408.5643053741896
INFO:root:current train perplexity3.8458266258239746
INFO:root:current mean train loss 3414.057123990667
INFO:root:current train perplexity3.8441104888916016
INFO:root:current mean train loss 3421.6260702910763
INFO:root:current train perplexity3.850937604904175
INFO:root:current mean train loss 3423.549600167842
INFO:root:current train perplexity3.852794647216797
INFO:root:current mean train loss 3422.022022334128
INFO:root:current train perplexity3.8529157638549805
INFO:root:current mean train loss 3425.3520608697054
INFO:root:current train perplexity3.858633279800415
INFO:root:current mean train loss 3424.9598493082594
INFO:root:current train perplexity3.8591039180755615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.06s/it]
INFO:root:final mean train loss: 3423.676410490467
INFO:root:final train perplexity: 3.8602781295776367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 4046.2302384613254
INFO:root:eval perplexity: 5.135497570037842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [7:02:14<6:11:03, 239.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3401.527525745739
INFO:root:current train perplexity3.8296337127685547
INFO:root:current mean train loss 3409.2993463331654
INFO:root:current train perplexity3.83128023147583
INFO:root:current mean train loss 3403.2646867340686
INFO:root:current train perplexity3.8341801166534424
INFO:root:current mean train loss 3414.7904668243837
INFO:root:current train perplexity3.843055248260498
INFO:root:current mean train loss 3417.5618260645606
INFO:root:current train perplexity3.8407645225524902
INFO:root:current mean train loss 3416.4402678068695
INFO:root:current train perplexity3.8449134826660156
INFO:root:current mean train loss 3416.6320372137407
INFO:root:current train perplexity3.8475465774536133
INFO:root:current mean train loss 3419.6751005665355
INFO:root:current train perplexity3.8471994400024414
INFO:root:current mean train loss 3418.7341348569994
INFO:root:current train perplexity3.846820116043091
INFO:root:current mean train loss 3421.7900751083935
INFO:root:current train perplexity3.8521175384521484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.41s/it]
INFO:root:final mean train loss: 3417.8639398390246
INFO:root:final train perplexity: 3.851436138153076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.05s/it]
INFO:root:eval mean loss: 4047.436767578125
INFO:root:eval perplexity: 5.138004302978516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [7:07:05<6:30:45, 254.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.1619543650795
INFO:root:current train perplexity3.82948899269104
INFO:root:current mean train loss 3389.121893572661
INFO:root:current train perplexity3.841310739517212
INFO:root:current mean train loss 3395.8488017615255
INFO:root:current train perplexity3.8350181579589844
INFO:root:current mean train loss 3404.1450484514894
INFO:root:current train perplexity3.8418688774108887
INFO:root:current mean train loss 3408.1935386575324
INFO:root:current train perplexity3.8361923694610596
INFO:root:current mean train loss 3412.12538724259
INFO:root:current train perplexity3.8401198387145996
INFO:root:current mean train loss 3414.6827317089696
INFO:root:current train perplexity3.840874195098877
INFO:root:current mean train loss 3415.21762688913
INFO:root:current train perplexity3.8412721157073975
INFO:root:current mean train loss 3415.2677552188948
INFO:root:current train perplexity3.843698501586914
INFO:root:current mean train loss 3417.6686253691264
INFO:root:current train perplexity3.8476357460021973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.72s/it]
INFO:root:final mean train loss: 3415.2625210054457
INFO:root:final train perplexity: 3.8474855422973633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.29s/it]
INFO:root:eval mean loss: 4046.0803465065383
INFO:root:eval perplexity: 5.135187149047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [7:11:14<6:23:44, 253.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.3216879401407
INFO:root:current train perplexity3.812014102935791
INFO:root:current mean train loss 3391.5070914999087
INFO:root:current train perplexity3.823470115661621
INFO:root:current mean train loss 3394.328697964714
INFO:root:current train perplexity3.826164722442627
INFO:root:current mean train loss 3398.744140625
INFO:root:current train perplexity3.8215880393981934
INFO:root:current mean train loss 3402.0725968476313
INFO:root:current train perplexity3.8292031288146973
INFO:root:current mean train loss 3405.81399391829
INFO:root:current train perplexity3.8353769779205322
INFO:root:current mean train loss 3407.3887544680283
INFO:root:current train perplexity3.836921215057373
INFO:root:current mean train loss 3409.1139832730423
INFO:root:current train perplexity3.8375205993652344
INFO:root:current mean train loss 3410.337681521778
INFO:root:current train perplexity3.8383522033691406
INFO:root:current mean train loss 3412.973460078608
INFO:root:current train perplexity3.8416738510131836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.71s/it]
INFO:root:final mean train loss: 3411.061088931176
INFO:root:final train perplexity: 3.841113328933716
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.01s/it]
INFO:root:eval mean loss: 4047.7387712627437
INFO:root:eval perplexity: 5.138630390167236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [7:15:19<6:15:59, 250.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.2385006675236
INFO:root:current train perplexity3.8092129230499268
INFO:root:current mean train loss 3403.236611819134
INFO:root:current train perplexity3.81315016746521
INFO:root:current mean train loss 3411.4972400733645
INFO:root:current train perplexity3.8285346031188965
INFO:root:current mean train loss 3413.2483605860407
INFO:root:current train perplexity3.8330750465393066
INFO:root:current mean train loss 3414.303045284773
INFO:root:current train perplexity3.829709529876709
INFO:root:current mean train loss 3410.964950429755
INFO:root:current train perplexity3.826838493347168
INFO:root:current mean train loss 3411.3324580466447
INFO:root:current train perplexity3.827831745147705
INFO:root:current mean train loss 3408.1501226657774
INFO:root:current train perplexity3.829223155975342
INFO:root:current mean train loss 3407.8581842936755
INFO:root:current train perplexity3.8327419757843018
INFO:root:current mean train loss 3409.9124851869733
INFO:root:current train perplexity3.8359079360961914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.10s/it]
INFO:root:final mean train loss: 3407.323930678829
INFO:root:final train perplexity: 3.835453748703003
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 4047.614373822584
INFO:root:eval perplexity: 5.138372421264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [7:19:47<6:19:31, 255.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.826626481681
INFO:root:current train perplexity3.8192968368530273
INFO:root:current mean train loss 3406.2696644176135
INFO:root:current train perplexity3.817370891571045
INFO:root:current mean train loss 3402.7943340660386
INFO:root:current train perplexity3.81978440284729
INFO:root:current mean train loss 3399.669540838986
INFO:root:current train perplexity3.8153254985809326
INFO:root:current mean train loss 3400.0388499422484
INFO:root:current train perplexity3.8206210136413574
INFO:root:current mean train loss 3400.1050831991324
INFO:root:current train perplexity3.823489189147949
INFO:root:current mean train loss 3404.794020296011
INFO:root:current train perplexity3.8282506465911865
INFO:root:current mean train loss 3402.8158252139256
INFO:root:current train perplexity3.828589677810669
INFO:root:current mean train loss 3404.77180365699
INFO:root:current train perplexity3.8293497562408447
INFO:root:current mean train loss 3405.9602894266086
INFO:root:current train perplexity3.8290936946868896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.50s/it]
INFO:root:final mean train loss: 3403.0194731681577
INFO:root:final train perplexity: 3.828946113586426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.52s/it]
INFO:root:eval mean loss: 4050.733817458998
INFO:root:eval perplexity: 5.144857883453369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [7:24:16<6:21:11, 259.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.3461400082238
INFO:root:current train perplexity3.8012940883636475
INFO:root:current mean train loss 3374.6442695813303
INFO:root:current train perplexity3.8090853691101074
INFO:root:current mean train loss 3381.640563757945
INFO:root:current train perplexity3.808156967163086
INFO:root:current mean train loss 3390.7704126285603
INFO:root:current train perplexity3.8156793117523193
INFO:root:current mean train loss 3391.8705936316287
INFO:root:current train perplexity3.8163466453552246
INFO:root:current mean train loss 3390.6889590992646
INFO:root:current train perplexity3.8150007724761963
INFO:root:current mean train loss 3394.1428401809803
INFO:root:current train perplexity3.817814588546753
INFO:root:current mean train loss 3397.496594315055
INFO:root:current train perplexity3.8204638957977295
INFO:root:current mean train loss 3398.9110327012045
INFO:root:current train perplexity3.822409152984619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.03s/it]
INFO:root:final mean train loss: 3398.722816959504
INFO:root:final train perplexity: 3.822460651397705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.25s/it]
INFO:root:eval mean loss: 4052.334091727615
INFO:root:eval perplexity: 5.148189067840576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [7:28:53<6:24:09, 264.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.7530110677085
INFO:root:current train perplexity3.8408381938934326
INFO:root:current mean train loss 3370.2460392331614
INFO:root:current train perplexity3.784592866897583
INFO:root:current mean train loss 3390.5536736549416
INFO:root:current train perplexity3.808673143386841
INFO:root:current mean train loss 3387.7762696923987
INFO:root:current train perplexity3.8067870140075684
INFO:root:current mean train loss 3387.965898461732
INFO:root:current train perplexity3.808807134628296
INFO:root:current mean train loss 3393.0954793698743
INFO:root:current train perplexity3.8134965896606445
INFO:root:current mean train loss 3394.2093702224556
INFO:root:current train perplexity3.8138630390167236
INFO:root:current mean train loss 3395.4055339004713
INFO:root:current train perplexity3.8153932094573975
INFO:root:current mean train loss 3398.5790486602973
INFO:root:current train perplexity3.8182780742645264
INFO:root:current mean train loss 3397.1798502604165
INFO:root:current train perplexity3.8153581619262695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.30s/it]
INFO:root:final mean train loss: 3394.7787487276137
INFO:root:final train perplexity: 3.8165178298950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.30s/it]
INFO:root:eval mean loss: 4054.063757064495
INFO:root:eval perplexity: 5.151790142059326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [7:33:06<6:14:26, 261.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3355.935147372159
INFO:root:current train perplexity3.792840003967285
INFO:root:current mean train loss 3385.061983125704
INFO:root:current train perplexity3.820347785949707
INFO:root:current mean train loss 3378.549399714899
INFO:root:current train perplexity3.809687614440918
INFO:root:current mean train loss 3385.7980368267686
INFO:root:current train perplexity3.8065543174743652
INFO:root:current mean train loss 3387.455292564819
INFO:root:current train perplexity3.8064815998077393
INFO:root:current mean train loss 3386.7591989894204
INFO:root:current train perplexity3.8067612648010254
INFO:root:current mean train loss 3392.235322793065
INFO:root:current train perplexity3.8058629035949707
INFO:root:current mean train loss 3390.8541735341946
INFO:root:current train perplexity3.8060293197631836
INFO:root:current mean train loss 3389.0724405272235
INFO:root:current train perplexity3.8049731254577637
INFO:root:current mean train loss 3390.9570009669146
INFO:root:current train perplexity3.8068246841430664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.91s/it]
INFO:root:final mean train loss: 3390.3958185872725
INFO:root:final train perplexity: 3.8099236488342285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.00s/it]
INFO:root:eval mean loss: 4052.993806446698
INFO:root:eval perplexity: 5.149562358856201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [7:37:48<6:19:01, 267.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.6360120271383
INFO:root:current train perplexity3.7629969120025635
INFO:root:current mean train loss 3350.529881581539
INFO:root:current train perplexity3.777813196182251
INFO:root:current mean train loss 3369.9567124179507
INFO:root:current train perplexity3.7865054607391357
INFO:root:current mean train loss 3377.9649952855602
INFO:root:current train perplexity3.7922990322113037
INFO:root:current mean train loss 3378.333991949769
INFO:root:current train perplexity3.789634943008423
INFO:root:current mean train loss 3381.5953140993797
INFO:root:current train perplexity3.7906930446624756
INFO:root:current mean train loss 3384.198299771557
INFO:root:current train perplexity3.795804023742676
INFO:root:current mean train loss 3388.2552539469966
INFO:root:current train perplexity3.7987139225006104
INFO:root:current mean train loss 3388.5302081544755
INFO:root:current train perplexity3.7994425296783447
INFO:root:current mean train loss 3386.633667656335
INFO:root:current train perplexity3.801297664642334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.98s/it]
INFO:root:final mean train loss: 3386.1108235389956
INFO:root:final train perplexity: 3.8034884929656982
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.32s/it]
INFO:root:eval mean loss: 4055.7769368489585
INFO:root:eval perplexity: 5.155361175537109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [7:42:25<6:18:34, 270.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.2436613859954
INFO:root:current train perplexity3.80804443359375
INFO:root:current mean train loss 3390.6895338644194
INFO:root:current train perplexity3.7944388389587402
INFO:root:current mean train loss 3388.5017606088245
INFO:root:current train perplexity3.7903084754943848
INFO:root:current mean train loss 3383.6416583046635
INFO:root:current train perplexity3.7911832332611084
INFO:root:current mean train loss 3387.0761158427254
INFO:root:current train perplexity3.796095132827759
INFO:root:current mean train loss 3387.334155783029
INFO:root:current train perplexity3.7960987091064453
INFO:root:current mean train loss 3387.365044358054
INFO:root:current train perplexity3.795849323272705
INFO:root:current mean train loss 3388.017281260746
INFO:root:current train perplexity3.798633337020874
INFO:root:current mean train loss 3387.264768588932
INFO:root:current train perplexity3.7985317707061768
INFO:root:current mean train loss 3387.4554776517834
INFO:root:current train perplexity3.8013880252838135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.60s/it]
INFO:root:final mean train loss: 3383.898593164259
INFO:root:final train perplexity: 3.800170421600342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.86s/it]
INFO:root:eval mean loss: 4055.213908743351
INFO:root:eval perplexity: 5.1541876792907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [7:46:23<6:00:29, 260.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3367.008530970982
INFO:root:current train perplexity3.7542946338653564
INFO:root:current mean train loss 3369.226533564815
INFO:root:current train perplexity3.7611353397369385
INFO:root:current mean train loss 3367.8424409906916
INFO:root:current train perplexity3.7707509994506836
INFO:root:current mean train loss 3376.567383541278
INFO:root:current train perplexity3.7799251079559326
INFO:root:current mean train loss 3378.8839029947917
INFO:root:current train perplexity3.7811782360076904
INFO:root:current mean train loss 3380.1955228716415
INFO:root:current train perplexity3.7845559120178223
INFO:root:current mean train loss 3379.038410433071
INFO:root:current train perplexity3.7868878841400146
INFO:root:current mean train loss 3381.016148490646
INFO:root:current train perplexity3.7878310680389404
INFO:root:current mean train loss 3380.7445034735215
INFO:root:current train perplexity3.789262056350708
INFO:root:current mean train loss 3380.9945753780917
INFO:root:current train perplexity3.791752338409424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.26s/it]
INFO:root:final mean train loss: 3377.9063678249236
INFO:root:final train perplexity: 3.791196823120117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.20s/it]
INFO:root:eval mean loss: 4056.625202584774
INFO:root:eval perplexity: 5.157128810882568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [7:50:40<5:54:44, 259.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3371.7073321675143
INFO:root:current train perplexity3.7721245288848877
INFO:root:current mean train loss 3364.0868713805726
INFO:root:current train perplexity3.764596462249756
INFO:root:current mean train loss 3366.0069333928113
INFO:root:current train perplexity3.773451805114746
INFO:root:current mean train loss 3369.9352322681307
INFO:root:current train perplexity3.7755534648895264
INFO:root:current mean train loss 3377.052787832428
INFO:root:current train perplexity3.7788355350494385
INFO:root:current mean train loss 3377.0226803493324
INFO:root:current train perplexity3.779287338256836
INFO:root:current mean train loss 3378.559869887855
INFO:root:current train perplexity3.783104419708252
INFO:root:current mean train loss 3379.2498771082182
INFO:root:current train perplexity3.7852890491485596
INFO:root:current mean train loss 3377.6104245440392
INFO:root:current train perplexity3.7887070178985596
INFO:root:current mean train loss 3378.6770022120227
INFO:root:current train perplexity3.788801431655884


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.10s/it]
INFO:root:final mean train loss: 3376.553850789224
INFO:root:final train perplexity: 3.7891740798950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.24s/it]
INFO:root:eval mean loss: 4056.8521823747783
INFO:root:eval perplexity: 5.157602310180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [7:54:32<5:39:22, 251.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.664560355392
INFO:root:current train perplexity3.772850751876831
INFO:root:current mean train loss 3361.3710080582573
INFO:root:current train perplexity3.763845205307007
INFO:root:current mean train loss 3360.445241494958
INFO:root:current train perplexity3.770063877105713
INFO:root:current mean train loss 3356.3995615206554
INFO:root:current train perplexity3.7703888416290283
INFO:root:current mean train loss 3359.4545059373268
INFO:root:current train perplexity3.7721152305603027
INFO:root:current mean train loss 3363.371051656789
INFO:root:current train perplexity3.772545099258423
INFO:root:current mean train loss 3368.1336233018915
INFO:root:current train perplexity3.776312828063965
INFO:root:current mean train loss 3372.141576205684
INFO:root:current train perplexity3.779792070388794
INFO:root:current mean train loss 3371.841004780681
INFO:root:current train perplexity3.7806293964385986
INFO:root:current mean train loss 3373.888541461291
INFO:root:current train perplexity3.7818820476531982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.50s/it]
INFO:root:final mean train loss: 3371.689387229181
INFO:root:final train perplexity: 3.781909465789795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.48s/it]
INFO:root:eval mean loss: 4063.1089906083776
INFO:root:eval perplexity: 5.170668601989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [7:58:48<5:37:03, 252.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.2439709679556
INFO:root:current train perplexity3.753154993057251
INFO:root:current mean train loss 3354.1214008451257
INFO:root:current train perplexity3.7553837299346924
INFO:root:current mean train loss 3353.650959029621
INFO:root:current train perplexity3.7502777576446533
INFO:root:current mean train loss 3361.550090991687
INFO:root:current train perplexity3.763416290283203
INFO:root:current mean train loss 3363.5501078686684
INFO:root:current train perplexity3.767768383026123
INFO:root:current mean train loss 3360.6575344679395
INFO:root:current train perplexity3.7691807746887207
INFO:root:current mean train loss 3365.946745112742
INFO:root:current train perplexity3.7727789878845215
INFO:root:current mean train loss 3368.370635061553
INFO:root:current train perplexity3.775334358215332
INFO:root:current mean train loss 3370.536392300731
INFO:root:current train perplexity3.776473045349121
INFO:root:current mean train loss 3369.8590766341895
INFO:root:current train perplexity3.775632858276367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.22s/it]
INFO:root:final mean train loss: 3367.9751913624427
INFO:root:final train perplexity: 3.7763724327087402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it]
INFO:root:eval mean loss: 4061.5389586103724
INFO:root:eval perplexity: 5.167387962341309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [8:03:15<5:38:08, 256.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.6789222831158
INFO:root:current train perplexity3.768068790435791
INFO:root:current mean train loss 3362.6587674260854
INFO:root:current train perplexity3.767132043838501
INFO:root:current mean train loss 3356.2145200579353
INFO:root:current train perplexity3.7567694187164307
INFO:root:current mean train loss 3355.7424023703593
INFO:root:current train perplexity3.7595882415771484
INFO:root:current mean train loss 3360.4600466742504
INFO:root:current train perplexity3.7599003314971924
INFO:root:current mean train loss 3360.092269224675
INFO:root:current train perplexity3.760798692703247
INFO:root:current mean train loss 3363.806386601621
INFO:root:current train perplexity3.763927936553955
INFO:root:current mean train loss 3363.9346422496333
INFO:root:current train perplexity3.7654244899749756
INFO:root:current mean train loss 3365.6822294347426
INFO:root:current train perplexity3.766942024230957
INFO:root:current mean train loss 3368.2808483167173
INFO:root:current train perplexity3.771855592727661


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.29s/it]
INFO:root:final mean train loss: 3365.897110846735
INFO:root:final train perplexity: 3.7732768058776855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.70s/it]
INFO:root:eval mean loss: 4059.456196669991
INFO:root:eval perplexity: 5.163036823272705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [8:07:26<5:31:45, 255.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.5738541666665
INFO:root:current train perplexity3.754364490509033
INFO:root:current mean train loss 3349.720372488839
INFO:root:current train perplexity3.7664153575897217
INFO:root:current mean train loss 3358.724600497159
INFO:root:current train perplexity3.7690207958221436
INFO:root:current mean train loss 3359.4037389322916
INFO:root:current train perplexity3.765259265899658
INFO:root:current mean train loss 3363.9451963404604
INFO:root:current train perplexity3.7691030502319336
INFO:root:current mean train loss 3364.516603685462
INFO:root:current train perplexity3.7662200927734375
INFO:root:current mean train loss 3365.4693645109955
INFO:root:current train perplexity3.767003059387207
INFO:root:current mean train loss 3365.880831653226
INFO:root:current train perplexity3.767585277557373
INFO:root:current mean train loss 3364.528728236607
INFO:root:current train perplexity3.7668962478637695
INFO:root:current mean train loss 3364.396087489984
INFO:root:current train perplexity3.7673566341400146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.08s/it]
INFO:root:final mean train loss: 3362.1479891500167
INFO:root:final train perplexity: 3.767699718475342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 4063.006733779366
INFO:root:eval perplexity: 5.170455455780029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [8:11:57<5:33:45, 260.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.5669739504897
INFO:root:current train perplexity3.749030590057373
INFO:root:current mean train loss 3333.6920332778345
INFO:root:current train perplexity3.7465672492980957
INFO:root:current mean train loss 3340.4458396021973
INFO:root:current train perplexity3.746131181716919
INFO:root:current mean train loss 3350.164179789491
INFO:root:current train perplexity3.75526762008667
INFO:root:current mean train loss 3352.969600701184
INFO:root:current train perplexity3.7605645656585693
INFO:root:current mean train loss 3362.017838178736
INFO:root:current train perplexity3.7625250816345215
INFO:root:current mean train loss 3363.3168233980373
INFO:root:current train perplexity3.7625606060028076
INFO:root:current mean train loss 3361.42256252245
INFO:root:current train perplexity3.7594239711761475
INFO:root:current mean train loss 3361.068265644907
INFO:root:current train perplexity3.760848045349121
INFO:root:current mean train loss 3360.9695323427964
INFO:root:current train perplexity3.761887788772583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.86s/it]
INFO:root:final mean train loss: 3358.2530519423944
INFO:root:final train perplexity: 3.7619142532348633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.28s/it]
INFO:root:eval mean loss: 4065.745425393395
INFO:root:eval perplexity: 5.176184177398682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [8:16:29<5:33:49, 263.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3326.528838105254
INFO:root:current train perplexity3.7030985355377197
INFO:root:current mean train loss 3349.7753867903307
INFO:root:current train perplexity3.739860773086548
INFO:root:current mean train loss 3351.774926673915
INFO:root:current train perplexity3.742017984390259
INFO:root:current mean train loss 3353.0523691006633
INFO:root:current train perplexity3.7414259910583496
INFO:root:current mean train loss 3353.0189156775077
INFO:root:current train perplexity3.744152545928955
INFO:root:current mean train loss 3355.4942005241383
INFO:root:current train perplexity3.7499589920043945
INFO:root:current mean train loss 3357.023034720966
INFO:root:current train perplexity3.7515547275543213
INFO:root:current mean train loss 3359.7395207806576
INFO:root:current train perplexity3.7527854442596436
INFO:root:current mean train loss 3357.8697078203913
INFO:root:current train perplexity3.75539493560791
INFO:root:current mean train loss 3357.22370942979
INFO:root:current train perplexity3.756423234939575


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.39s/it]
INFO:root:final mean train loss: 3354.5187187194824
INFO:root:final train perplexity: 3.756376266479492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it]
INFO:root:eval mean loss: 4063.23775660738
INFO:root:eval perplexity: 5.170938014984131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [8:20:38<5:23:58, 259.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.988989011206
INFO:root:current train perplexity3.750169515609741
INFO:root:current mean train loss 3344.1100534410334
INFO:root:current train perplexity3.7449605464935303
INFO:root:current mean train loss 3347.125267819816
INFO:root:current train perplexity3.7457146644592285
INFO:root:current mean train loss 3346.7271731575033
INFO:root:current train perplexity3.744410514831543
INFO:root:current mean train loss 3347.3935835538264
INFO:root:current train perplexity3.743457794189453
INFO:root:current mean train loss 3349.672896396338
INFO:root:current train perplexity3.7437331676483154
INFO:root:current mean train loss 3349.349632077633
INFO:root:current train perplexity3.7455708980560303
INFO:root:current mean train loss 3352.61503667915
INFO:root:current train perplexity3.7482187747955322
INFO:root:current mean train loss 3353.6738039553497
INFO:root:current train perplexity3.75117826461792


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.75s/it]
INFO:root:final mean train loss: 3350.4606368772447
INFO:root:final train perplexity: 3.750366687774658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.24s/it]
INFO:root:eval mean loss: 4066.9242281000666
INFO:root:eval perplexity: 5.178652763366699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [8:24:50<5:17:04, 257.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.0362374441966
INFO:root:current train perplexity3.7807371616363525
INFO:root:current mean train loss 3336.4339770735983
INFO:root:current train perplexity3.7295525074005127
INFO:root:current mean train loss 3341.57259350468
INFO:root:current train perplexity3.7312533855438232
INFO:root:current mean train loss 3343.3966489909913
INFO:root:current train perplexity3.735802412033081
INFO:root:current mean train loss 3337.9540217819026
INFO:root:current train perplexity3.737955331802368
INFO:root:current mean train loss 3342.8574608797153
INFO:root:current train perplexity3.741718292236328
INFO:root:current mean train loss 3344.4690786044325
INFO:root:current train perplexity3.740391492843628
INFO:root:current mean train loss 3348.5365271669466
INFO:root:current train perplexity3.74473237991333
INFO:root:current mean train loss 3349.8981119791665
INFO:root:current train perplexity3.745995044708252
INFO:root:current mean train loss 3349.9467485421546
INFO:root:current train perplexity3.744535207748413


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.97s/it]
INFO:root:final mean train loss: 3348.0680723497944
INFO:root:final train perplexity: 3.746828556060791
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 4065.7099315021055
INFO:root:eval perplexity: 5.1761088371276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [8:29:22<5:18:13, 261.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.2742513020835
INFO:root:current train perplexity3.7488627433776855
INFO:root:current mean train loss 3321.074558423913
INFO:root:current train perplexity3.7406580448150635
INFO:root:current mean train loss 3329.60174759266
INFO:root:current train perplexity3.741741418838501
INFO:root:current mean train loss 3336.210529823909
INFO:root:current train perplexity3.7359378337860107
INFO:root:current mean train loss 3338.9848897543297
INFO:root:current train perplexity3.73476505279541
INFO:root:current mean train loss 3338.243327613016
INFO:root:current train perplexity3.735565185546875
INFO:root:current mean train loss 3340.292947710239
INFO:root:current train perplexity3.734440803527832
INFO:root:current mean train loss 3341.565276032561
INFO:root:current train perplexity3.735792636871338
INFO:root:current mean train loss 3341.6908176164684
INFO:root:current train perplexity3.7352864742279053
INFO:root:current mean train loss 3344.4103977224213
INFO:root:current train perplexity3.739042043685913


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.43s/it]
INFO:root:final mean train loss: 3343.38653988992
INFO:root:final train perplexity: 3.7399144172668457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it]
INFO:root:eval mean loss: 4070.198900155142
INFO:root:eval perplexity: 5.185514450073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [8:33:31<5:09:14, 257.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.585247537364
INFO:root:current train perplexity3.7185134887695312
INFO:root:current mean train loss 3343.6771786077234
INFO:root:current train perplexity3.729560375213623
INFO:root:current mean train loss 3344.288229356432
INFO:root:current train perplexity3.7331366539001465
INFO:root:current mean train loss 3344.446498433872
INFO:root:current train perplexity3.740067720413208
INFO:root:current mean train loss 3341.6426825917924
INFO:root:current train perplexity3.7328991889953613
INFO:root:current mean train loss 3340.3448376628226
INFO:root:current train perplexity3.7349257469177246
INFO:root:current mean train loss 3341.9779540623745
INFO:root:current train perplexity3.7365806102752686
INFO:root:current mean train loss 3343.5212537414636
INFO:root:current train perplexity3.738023519515991
INFO:root:current mean train loss 3341.8708027391212
INFO:root:current train perplexity3.7360825538635254
INFO:root:current mean train loss 3342.337195234206
INFO:root:current train perplexity3.735292673110962


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.27s/it]
INFO:root:final mean train loss: 3341.2472018580283
INFO:root:final train perplexity: 3.7367591857910156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.11s/it]
INFO:root:eval mean loss: 4070.847647592531
INFO:root:eval perplexity: 5.1868743896484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [8:37:30<4:58:26, 252.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.6109107232865
INFO:root:current train perplexity3.704944133758545
INFO:root:current mean train loss 3334.165456524332
INFO:root:current train perplexity3.72542667388916
INFO:root:current mean train loss 3346.352842388731
INFO:root:current train perplexity3.7371633052825928
INFO:root:current mean train loss 3346.118868456146
INFO:root:current train perplexity3.737435817718506
INFO:root:current mean train loss 3341.6567677367316
INFO:root:current train perplexity3.736326217651367
INFO:root:current mean train loss 3344.1217884703096
INFO:root:current train perplexity3.7402398586273193
INFO:root:current mean train loss 3342.522710881785
INFO:root:current train perplexity3.7352890968322754
INFO:root:current mean train loss 3343.554441355485
INFO:root:current train perplexity3.734900712966919
INFO:root:current mean train loss 3339.9374579878345
INFO:root:current train perplexity3.731839656829834
INFO:root:current mean train loss 3339.3343879544004
INFO:root:current train perplexity3.7306089401245117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.69s/it]
INFO:root:final mean train loss: 3338.051187576786
INFO:root:final train perplexity: 3.732050657272339
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.43s/it]
INFO:root:eval mean loss: 4073.2760174257537
INFO:root:eval perplexity: 5.1919708251953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [8:42:07<5:02:51, 259.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.2635904947915
INFO:root:current train perplexity3.7294483184814453
INFO:root:current mean train loss 3340.924718623539
INFO:root:current train perplexity3.7330431938171387
INFO:root:current mean train loss 3338.1290911431092
INFO:root:current train perplexity3.7253143787384033
INFO:root:current mean train loss 3340.217163446027
INFO:root:current train perplexity3.728334426879883
INFO:root:current mean train loss 3339.708856465333
INFO:root:current train perplexity3.730241537094116
INFO:root:current mean train loss 3333.529588575487
INFO:root:current train perplexity3.7275314331054688
INFO:root:current mean train loss 3333.7269300481707
INFO:root:current train perplexity3.7282681465148926
INFO:root:current mean train loss 3334.354713863223
INFO:root:current train perplexity3.726637840270996
INFO:root:current mean train loss 3338.5728461500858
INFO:root:current train perplexity3.729658603668213
INFO:root:current mean train loss 3338.4984740560935
INFO:root:current train perplexity3.730173110961914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.88s/it]
INFO:root:final mean train loss: 3336.655881943241
INFO:root:final train perplexity: 3.729996681213379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.64s/it]
INFO:root:eval mean loss: 4070.9489763408687
INFO:root:eval perplexity: 5.187087059020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [8:46:56<5:08:45, 268.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.8222864029253
INFO:root:current train perplexity3.7139570713043213
INFO:root:current mean train loss 3332.652941645408
INFO:root:current train perplexity3.7169556617736816
INFO:root:current mean train loss 3332.619657570534
INFO:root:current train perplexity3.726449489593506
INFO:root:current mean train loss 3330.557993600279
INFO:root:current train perplexity3.7181172370910645
INFO:root:current mean train loss 3331.0301926034676
INFO:root:current train perplexity3.7165369987487793
INFO:root:current mean train loss 3331.840711408821
INFO:root:current train perplexity3.717609167098999
INFO:root:current mean train loss 3332.012792666876
INFO:root:current train perplexity3.7200706005096436
INFO:root:current mean train loss 3332.8854542519034
INFO:root:current train perplexity3.7215688228607178
INFO:root:current mean train loss 3332.403959632342
INFO:root:current train perplexity3.7212681770324707
INFO:root:current mean train loss 3333.873916190932
INFO:root:current train perplexity3.7222201824188232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.15s/it]
INFO:root:final mean train loss: 3332.547016697545
INFO:root:final train perplexity: 3.7239551544189453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.94s/it]
INFO:root:eval mean loss: 4072.9692417442375
INFO:root:eval perplexity: 5.191326141357422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [8:51:32<5:06:42, 270.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.207080078125
INFO:root:current train perplexity3.7056920528411865
INFO:root:current mean train loss 3311.1138971144155
INFO:root:current train perplexity3.713977813720703
INFO:root:current mean train loss 3312.3506002987133
INFO:root:current train perplexity3.715756893157959
INFO:root:current mean train loss 3312.2504752145687
INFO:root:current train perplexity3.707383871078491
INFO:root:current mean train loss 3316.985861306662
INFO:root:current train perplexity3.7074170112609863
INFO:root:current mean train loss 3320.0648741026184
INFO:root:current train perplexity3.7089014053344727
INFO:root:current mean train loss 3322.1907856482585
INFO:root:current train perplexity3.712495803833008
INFO:root:current mean train loss 3323.9063098225374
INFO:root:current train perplexity3.713130474090576
INFO:root:current mean train loss 3326.884010930647
INFO:root:current train perplexity3.7142529487609863
INFO:root:current mean train loss 3329.1173278489036
INFO:root:current train perplexity3.7170584201812744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.52s/it]
INFO:root:final mean train loss: 3329.19594493989
INFO:root:final train perplexity: 3.7190346717834473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.17s/it]
INFO:root:eval mean loss: 4076.0867045517507
INFO:root:eval perplexity: 5.197875022888184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [8:56:23<5:08:50, 276.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.5033210875495
INFO:root:current train perplexity3.7155778408050537
INFO:root:current mean train loss 3310.7445105804254
INFO:root:current train perplexity3.701591730117798
INFO:root:current mean train loss 3319.5426197124525
INFO:root:current train perplexity3.7118711471557617
INFO:root:current mean train loss 3323.2821774653494
INFO:root:current train perplexity3.7147927284240723
INFO:root:current mean train loss 3325.2130804535636
INFO:root:current train perplexity3.7133302688598633
INFO:root:current mean train loss 3332.3775662952376
INFO:root:current train perplexity3.7162227630615234
INFO:root:current mean train loss 3328.7142722473604
INFO:root:current train perplexity3.711897134780884
INFO:root:current mean train loss 3326.271321507925
INFO:root:current train perplexity3.70988392829895
INFO:root:current mean train loss 3325.9484272025275
INFO:root:current train perplexity3.710376262664795
INFO:root:current mean train loss 3328.3655768817334
INFO:root:current train perplexity3.7135236263275146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.66s/it]
INFO:root:final mean train loss: 3325.6390251036614
INFO:root:final train perplexity: 3.7138195037841797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.32s/it]
INFO:root:eval mean loss: 4074.7102829953456
INFO:root:eval perplexity: 5.194982051849365
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [9:01:01<5:04:53, 277.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3320.8441454390404
INFO:root:current train perplexity3.704493761062622
INFO:root:current mean train loss 3303.3006327668127
INFO:root:current train perplexity3.6815123558044434
INFO:root:current mean train loss 3306.602558882034
INFO:root:current train perplexity3.6874887943267822
INFO:root:current mean train loss 3312.0645551244525
INFO:root:current train perplexity3.694347381591797
INFO:root:current mean train loss 3316.4869651713443
INFO:root:current train perplexity3.6990463733673096
INFO:root:current mean train loss 3323.61498168304
INFO:root:current train perplexity3.7034754753112793
INFO:root:current mean train loss 3327.553133513995
INFO:root:current train perplexity3.7100002765655518
INFO:root:current mean train loss 3326.3106269885902
INFO:root:current train perplexity3.7098751068115234
INFO:root:current mean train loss 3326.7543126838764
INFO:root:current train perplexity3.7109224796295166
INFO:root:current mean train loss 3325.183286248471
INFO:root:current train perplexity3.7093522548675537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it]
INFO:root:final mean train loss: 3323.26983950215
INFO:root:final train perplexity: 3.7103495597839355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.16s/it]
INFO:root:eval mean loss: 4077.0539620041
INFO:root:eval perplexity: 5.199908256530762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [9:05:40<5:00:45, 277.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.379292548457
INFO:root:current train perplexity3.69645619392395
INFO:root:current mean train loss 3317.602650903457
INFO:root:current train perplexity3.711412191390991
INFO:root:current mean train loss 3315.295361153114
INFO:root:current train perplexity3.7029523849487305
INFO:root:current mean train loss 3319.9013800709104
INFO:root:current train perplexity3.7046306133270264
INFO:root:current mean train loss 3323.529748458703
INFO:root:current train perplexity3.7072958946228027
INFO:root:current mean train loss 3324.432240645914
INFO:root:current train perplexity3.706392765045166
INFO:root:current mean train loss 3327.825427947234
INFO:root:current train perplexity3.7076504230499268
INFO:root:current mean train loss 3327.199830511874
INFO:root:current train perplexity3.7056708335876465
INFO:root:current mean train loss 3325.7691982299666
INFO:root:current train perplexity3.705687999725342
INFO:root:current mean train loss 3322.8620296240583
INFO:root:current train perplexity3.7054030895233154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.62s/it]
INFO:root:final mean train loss: 3320.0399042560207
INFO:root:final train perplexity: 3.70562481880188
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.14s/it]
INFO:root:eval mean loss: 4077.928695354056
INFO:root:eval perplexity: 5.201747894287109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [9:10:13<4:54:38, 276.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.3125897988507
INFO:root:current train perplexity3.695253849029541
INFO:root:current mean train loss 3315.2267700848097
INFO:root:current train perplexity3.699176073074341
INFO:root:current mean train loss 3313.3311508125544
INFO:root:current train perplexity3.6954028606414795
INFO:root:current mean train loss 3320.982604822755
INFO:root:current train perplexity3.7008790969848633
INFO:root:current mean train loss 3324.5973364107417
INFO:root:current train perplexity3.703218936920166
INFO:root:current mean train loss 3323.942426899223
INFO:root:current train perplexity3.701537847518921
INFO:root:current mean train loss 3322.651918724982
INFO:root:current train perplexity3.7007083892822266
INFO:root:current mean train loss 3319.628856615311
INFO:root:current train perplexity3.6988868713378906
INFO:root:current mean train loss 3319.0873577543684
INFO:root:current train perplexity3.6990156173706055
INFO:root:current mean train loss 3319.9142079454787
INFO:root:current train perplexity3.7018842697143555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.48s/it]
INFO:root:final mean train loss: 3317.5818677102366
INFO:root:final train perplexity: 3.702033042907715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.14s/it]
INFO:root:eval mean loss: 4079.108919617132
INFO:root:eval perplexity: 5.204231262207031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [9:14:48<4:49:46, 275.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3296.9055047286183
INFO:root:current train perplexity3.6784069538116455
INFO:root:current mean train loss 3308.697790214343
INFO:root:current train perplexity3.6827633380889893
INFO:root:current mean train loss 3310.5816472457627
INFO:root:current train perplexity3.687786102294922
INFO:root:current mean train loss 3310.9958860759493
INFO:root:current train perplexity3.6916792392730713
INFO:root:current mean train loss 3311.2403739543875
INFO:root:current train perplexity3.6944782733917236
INFO:root:current mean train loss 3313.8270249310663
INFO:root:current train perplexity3.696929931640625
INFO:root:current mean train loss 3312.2189463663444
INFO:root:current train perplexity3.6955199241638184
INFO:root:current mean train loss 3315.9598080041274
INFO:root:current train perplexity3.6988437175750732
INFO:root:current mean train loss 3315.9157382048706
INFO:root:current train perplexity3.697406530380249


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.89s/it]
INFO:root:final mean train loss: 3314.3243905344316
INFO:root:final train perplexity: 3.697277784347534
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.73s/it]
INFO:root:eval mean loss: 4079.8637885776816
INFO:root:eval perplexity: 5.205819129943848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [9:19:29<4:46:46, 277.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.137939453125
INFO:root:current train perplexity3.570884943008423
INFO:root:current mean train loss 3287.371977870904
INFO:root:current train perplexity3.6577141284942627
INFO:root:current mean train loss 3291.8274106180725
INFO:root:current train perplexity3.6657705307006836
INFO:root:current mean train loss 3297.936594343028
INFO:root:current train perplexity3.67553973197937
INFO:root:current mean train loss 3303.1514732039004
INFO:root:current train perplexity3.6742753982543945
INFO:root:current mean train loss 3305.264793077473
INFO:root:current train perplexity3.6762444972991943
INFO:root:current mean train loss 3307.483252681903
INFO:root:current train perplexity3.6791787147521973
INFO:root:current mean train loss 3308.2714972245067
INFO:root:current train perplexity3.6824758052825928
INFO:root:current mean train loss 3311.4023671607447
INFO:root:current train perplexity3.6864662170410156
INFO:root:current mean train loss 3311.911407774865
INFO:root:current train perplexity3.6890475749969482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.89s/it]
INFO:root:final mean train loss: 3311.0070995207757
INFO:root:final train perplexity: 3.6924424171447754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.36s/it]
INFO:root:eval mean loss: 4080.1273271276596
INFO:root:eval perplexity: 5.206373691558838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [9:23:26<4:29:33, 265.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.853093927557
INFO:root:current train perplexity3.6150474548339844
INFO:root:current mean train loss 3304.4643906601914
INFO:root:current train perplexity3.6822948455810547
INFO:root:current mean train loss 3304.6879200144404
INFO:root:current train perplexity3.678157329559326
INFO:root:current mean train loss 3294.813681452221
INFO:root:current train perplexity3.6676924228668213
INFO:root:current mean train loss 3300.272444899065
INFO:root:current train perplexity3.673879623413086
INFO:root:current mean train loss 3301.978132930987
INFO:root:current train perplexity3.681436777114868
INFO:root:current mean train loss 3304.7488803894744
INFO:root:current train perplexity3.682438850402832
INFO:root:current mean train loss 3307.258044965827
INFO:root:current train perplexity3.6828081607818604
INFO:root:current mean train loss 3309.0036630124846
INFO:root:current train perplexity3.6868937015533447
INFO:root:current mean train loss 3311.685238416318
INFO:root:current train perplexity3.6886565685272217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.12s/it]
INFO:root:final mean train loss: 3309.4343688718736
INFO:root:final train perplexity: 3.6901514530181885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.44s/it]
INFO:root:eval mean loss: 4083.947812777039
INFO:root:eval perplexity: 5.214424133300781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [9:27:20<4:15:58, 255.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.9367161800988
INFO:root:current train perplexity3.671631336212158
INFO:root:current mean train loss 3285.8304556197477
INFO:root:current train perplexity3.6667747497558594
INFO:root:current mean train loss 3286.7712145940354
INFO:root:current train perplexity3.678184986114502
INFO:root:current mean train loss 3293.827561716301
INFO:root:current train perplexity3.677734613418579
INFO:root:current mean train loss 3298.1889240565333
INFO:root:current train perplexity3.6798155307769775
INFO:root:current mean train loss 3301.700674656039
INFO:root:current train perplexity3.682034730911255
INFO:root:current mean train loss 3300.1484335558866
INFO:root:current train perplexity3.6806070804595947
INFO:root:current mean train loss 3303.453243844532
INFO:root:current train perplexity3.6823673248291016
INFO:root:current mean train loss 3305.1937793922657
INFO:root:current train perplexity3.683250665664673
INFO:root:current mean train loss 3306.967096804016
INFO:root:current train perplexity3.6835193634033203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.63s/it]
INFO:root:final mean train loss: 3307.3239707946777
INFO:root:final train perplexity: 3.6870806217193604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.83s/it]
INFO:root:eval mean loss: 4082.55424943207
INFO:root:eval perplexity: 5.211486339569092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [9:31:14<4:05:04, 249.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.609284577546
INFO:root:current train perplexity3.681039333343506
INFO:root:current mean train loss 3298.1638222041092
INFO:root:current train perplexity3.6812222003936768
INFO:root:current mean train loss 3298.9596092459387
INFO:root:current train perplexity3.680920362472534
INFO:root:current mean train loss 3300.410787879874
INFO:root:current train perplexity3.6847503185272217
INFO:root:current mean train loss 3304.6958173622293
INFO:root:current train perplexity3.684126615524292
INFO:root:current mean train loss 3304.9233949722784
INFO:root:current train perplexity3.6821391582489014
INFO:root:current mean train loss 3305.067929500598
INFO:root:current train perplexity3.6829090118408203
INFO:root:current mean train loss 3304.4742584438404
INFO:root:current train perplexity3.6821141242980957
INFO:root:current mean train loss 3305.4137271387544
INFO:root:current train perplexity3.6836602687835693
INFO:root:current mean train loss 3305.3839773694544
INFO:root:current train perplexity3.681760311126709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.05s/it]
INFO:root:final mean train loss: 3303.577197105654
INFO:root:final train perplexity: 3.6816344261169434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 4086.3012297068926
INFO:root:eval perplexity: 5.219388961791992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [9:35:06<3:56:06, 244.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.834605189732
INFO:root:current train perplexity3.6782867908477783
INFO:root:current mean train loss 3327.860085720486
INFO:root:current train perplexity3.6673169136047363
INFO:root:current mean train loss 3316.3705057347074
INFO:root:current train perplexity3.668825387954712
INFO:root:current mean train loss 3313.902732917444
INFO:root:current train perplexity3.670320510864258
INFO:root:current mean train loss 3307.9721023033403
INFO:root:current train perplexity3.6737477779388428
INFO:root:current mean train loss 3312.6418333820093
INFO:root:current train perplexity3.6786463260650635
INFO:root:current mean train loss 3308.3559220441684
INFO:root:current train perplexity3.6745059490203857
INFO:root:current mean train loss 3305.1827513818025
INFO:root:current train perplexity3.67478609085083
INFO:root:current mean train loss 3303.379735158589
INFO:root:current train perplexity3.6768009662628174
INFO:root:current mean train loss 3303.821680731952
INFO:root:current train perplexity3.67905330657959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.77s/it]
INFO:root:final mean train loss: 3302.5950442283383
INFO:root:final train perplexity: 3.680208206176758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.13s/it]
INFO:root:eval mean loss: 4086.202191724845
INFO:root:eval perplexity: 5.219179153442383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [9:39:54<4:04:23, 257.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.5153467932414
INFO:root:current train perplexity3.648470163345337
INFO:root:current mean train loss 3284.6038656168053
INFO:root:current train perplexity3.647733449935913
INFO:root:current mean train loss 3284.810003335584
INFO:root:current train perplexity3.6532866954803467
INFO:root:current mean train loss 3290.1111117438045
INFO:root:current train perplexity3.65502667427063
INFO:root:current mean train loss 3291.990220597312
INFO:root:current train perplexity3.659519672393799
INFO:root:current mean train loss 3294.4769977267497
INFO:root:current train perplexity3.6634390354156494
INFO:root:current mean train loss 3297.5779579364307
INFO:root:current train perplexity3.6668968200683594
INFO:root:current mean train loss 3294.884712722388
INFO:root:current train perplexity3.6675302982330322
INFO:root:current mean train loss 3296.877583604408
INFO:root:current train perplexity3.6698219776153564
INFO:root:current mean train loss 3298.2167054840766
INFO:root:current train perplexity3.6730172634124756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.42s/it]
INFO:root:final mean train loss: 3298.0073272335912
INFO:root:final train perplexity: 3.6735527515411377
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it]
INFO:root:eval mean loss: 4088.1516321060503
INFO:root:eval perplexity: 5.223295211791992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [9:44:38<4:07:43, 265.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.413933249081
INFO:root:current train perplexity3.640878915786743
INFO:root:current mean train loss 3289.580399873241
INFO:root:current train perplexity3.6556713581085205
INFO:root:current mean train loss 3290.6029115958045
INFO:root:current train perplexity3.6552021503448486
INFO:root:current mean train loss 3286.3910186854523
INFO:root:current train perplexity3.655837059020996
INFO:root:current mean train loss 3290.2268970430296
INFO:root:current train perplexity3.6578524112701416
INFO:root:current mean train loss 3291.751789626106
INFO:root:current train perplexity3.6623127460479736
INFO:root:current mean train loss 3296.3592868693595
INFO:root:current train perplexity3.665914535522461
INFO:root:current mean train loss 3298.7060748429176
INFO:root:current train perplexity3.6691792011260986
INFO:root:current mean train loss 3297.786857201546
INFO:root:current train perplexity3.6687798500061035
INFO:root:current mean train loss 3296.606004010992
INFO:root:current train perplexity3.6692514419555664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it]
INFO:root:final mean train loss: 3295.569328185051
INFO:root:final train perplexity: 3.6700217723846436
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.76s/it]
INFO:root:eval mean loss: 4089.489837862921
INFO:root:eval perplexity: 5.2261223793029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [9:49:21<4:08:00, 270.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3301.3257498013772
INFO:root:current train perplexity3.656851291656494
INFO:root:current mean train loss 3290.883296174823
INFO:root:current train perplexity3.6533193588256836
INFO:root:current mean train loss 3285.8897700364987
INFO:root:current train perplexity3.655752182006836
INFO:root:current mean train loss 3288.597871148155
INFO:root:current train perplexity3.6610422134399414
INFO:root:current mean train loss 3291.241066261574
INFO:root:current train perplexity3.6620876789093018
INFO:root:current mean train loss 3292.575521124497
INFO:root:current train perplexity3.6638004779815674
INFO:root:current mean train loss 3297.305119840075
INFO:root:current train perplexity3.666098117828369
INFO:root:current mean train loss 3296.7779195230155
INFO:root:current train perplexity3.6674816608428955
INFO:root:current mean train loss 3297.2679424885405
INFO:root:current train perplexity3.6681129932403564
INFO:root:current mean train loss 3296.659768018036
INFO:root:current train perplexity3.668419122695923


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.64s/it]
INFO:root:final mean train loss: 3294.809047268283
INFO:root:final train perplexity: 3.668919801712036
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.80s/it]
INFO:root:eval mean loss: 4091.0282545157356
INFO:root:eval perplexity: 5.229374885559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [9:54:10<4:08:28, 276.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.6926670359144
INFO:root:current train perplexity3.6522860527038574
INFO:root:current mean train loss 3302.5237064932635
INFO:root:current train perplexity3.6527655124664307
INFO:root:current mean train loss 3298.4439390946864
INFO:root:current train perplexity3.6580650806427
INFO:root:current mean train loss 3299.081346724923
INFO:root:current train perplexity3.655270576477051
INFO:root:current mean train loss 3293.5462774566718
INFO:root:current train perplexity3.6535348892211914
INFO:root:current mean train loss 3290.885184151786
INFO:root:current train perplexity3.655475378036499
INFO:root:current mean train loss 3292.295937968516
INFO:root:current train perplexity3.6570653915405273
INFO:root:current mean train loss 3292.409145310463
INFO:root:current train perplexity3.6573805809020996
INFO:root:current mean train loss 3293.5230469313183
INFO:root:current train perplexity3.661071300506592
INFO:root:current mean train loss 3294.6640690642776
INFO:root:current train perplexity3.6636054515838623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.97s/it]
INFO:root:final mean train loss: 3291.6099411133796
INFO:root:final train perplexity: 3.664292812347412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.91s/it]
INFO:root:eval mean loss: 4089.4549967447915
INFO:root:eval perplexity: 5.226048469543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [9:58:04<3:52:45, 263.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.3747005208334
INFO:root:current train perplexity3.633119821548462
INFO:root:current mean train loss 3282.914275948661
INFO:root:current train perplexity3.651561737060547
INFO:root:current mean train loss 3289.922932350852
INFO:root:current train perplexity3.659339666366577
INFO:root:current mean train loss 3284.4944153645833
INFO:root:current train perplexity3.6538991928100586
INFO:root:current mean train loss 3284.405773540296
INFO:root:current train perplexity3.6516551971435547
INFO:root:current mean train loss 3285.632322095788
INFO:root:current train perplexity3.651512861251831
INFO:root:current mean train loss 3288.422412109375
INFO:root:current train perplexity3.6533381938934326
INFO:root:current mean train loss 3289.416949974798
INFO:root:current train perplexity3.653421401977539
INFO:root:current mean train loss 3293.725382533482
INFO:root:current train perplexity3.659212112426758
INFO:root:current mean train loss 3291.6565342047274
INFO:root:current train perplexity3.6595842838287354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.50s/it]
INFO:root:final mean train loss: 3289.058352562689
INFO:root:final train perplexity: 3.6606056690216064
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it]
INFO:root:eval mean loss: 4089.345871079898
INFO:root:eval perplexity: 5.225819110870361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [10:02:06<3:42:40, 256.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3293.9841514495483
INFO:root:current train perplexity3.663461208343506
INFO:root:current mean train loss 3281.1360730447404
INFO:root:current train perplexity3.652672290802002
INFO:root:current mean train loss 3282.0141429024957
INFO:root:current train perplexity3.64896559715271
INFO:root:current mean train loss 3285.519176194313
INFO:root:current train perplexity3.6501102447509766
INFO:root:current mean train loss 3286.235701851223
INFO:root:current train perplexity3.649928331375122
INFO:root:current mean train loss 3284.3127713604204
INFO:root:current train perplexity3.651416778564453
INFO:root:current mean train loss 3285.5322283497667
INFO:root:current train perplexity3.6524505615234375
INFO:root:current mean train loss 3285.2074977051407
INFO:root:current train perplexity3.6521854400634766
INFO:root:current mean train loss 3285.835139550007
INFO:root:current train perplexity3.6532692909240723
INFO:root:current mean train loss 3287.8133633090665
INFO:root:current train perplexity3.6550114154815674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.40s/it]
INFO:root:final mean train loss: 3285.643784246137
INFO:root:final train perplexity: 3.6556780338287354
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it]
INFO:root:eval mean loss: 4092.287379488032
INFO:root:eval perplexity: 5.232037544250488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [10:06:07<3:34:26, 252.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.1057799622254
INFO:root:current train perplexity3.640974760055542
INFO:root:current mean train loss 3275.848574014234
INFO:root:current train perplexity3.6373419761657715
INFO:root:current mean train loss 3278.142867570071
INFO:root:current train perplexity3.6422224044799805
INFO:root:current mean train loss 3278.967479344829
INFO:root:current train perplexity3.641691207885742
INFO:root:current mean train loss 3279.345658871404
INFO:root:current train perplexity3.6433680057525635
INFO:root:current mean train loss 3278.31055183217
INFO:root:current train perplexity3.6436381340026855
INFO:root:current mean train loss 3282.6426173429586
INFO:root:current train perplexity3.6472795009613037
INFO:root:current mean train loss 3282.8871061033306
INFO:root:current train perplexity3.6507790088653564
INFO:root:current mean train loss 3284.236566511469
INFO:root:current train perplexity3.651052951812744
INFO:root:current mean train loss 3285.9797693400765
INFO:root:current train perplexity3.6525068283081055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.22s/it]
INFO:root:final mean train loss: 3283.4692451107885
INFO:root:final train perplexity: 3.652543306350708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it]
INFO:root:eval mean loss: 4094.1290049451463
INFO:root:eval perplexity: 5.235935688018799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [10:10:04<3:26:21, 247.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.005706478851
INFO:root:current train perplexity3.6574106216430664
INFO:root:current mean train loss 3279.464982382616
INFO:root:current train perplexity3.6435723304748535
INFO:root:current mean train loss 3277.287582142297
INFO:root:current train perplexity3.6400930881500244
INFO:root:current mean train loss 3276.36260450932
INFO:root:current train perplexity3.6399147510528564
INFO:root:current mean train loss 3278.95843248998
INFO:root:current train perplexity3.6419689655303955
INFO:root:current mean train loss 3280.520048469454
INFO:root:current train perplexity3.6465561389923096
INFO:root:current mean train loss 3279.768838645051
INFO:root:current train perplexity3.648374080657959
INFO:root:current mean train loss 3277.780264881884
INFO:root:current train perplexity3.647618293762207
INFO:root:current mean train loss 3282.2355840256537
INFO:root:current train perplexity3.649421453475952


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.79s/it]
INFO:root:final mean train loss: 3282.2051367605886
INFO:root:final train perplexity: 3.650722026824951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it]
INFO:root:eval mean loss: 4092.8735888325577
INFO:root:eval perplexity: 5.233278751373291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [10:14:07<3:21:15, 246.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.411202566964
INFO:root:current train perplexity3.640730857849121
INFO:root:current mean train loss 3281.720397378797
INFO:root:current train perplexity3.646273612976074
INFO:root:current mean train loss 3280.1523107261473
INFO:root:current train perplexity3.648831605911255
INFO:root:current mean train loss 3277.5534970162357
INFO:root:current train perplexity3.650876045227051
INFO:root:current mean train loss 3277.5053267045455
INFO:root:current train perplexity3.6491613388061523
INFO:root:current mean train loss 3278.9938324395957
INFO:root:current train perplexity3.6457507610321045
INFO:root:current mean train loss 3279.092950811496
INFO:root:current train perplexity3.646747350692749
INFO:root:current mean train loss 3284.1651540537705
INFO:root:current train perplexity3.6477243900299072
INFO:root:current mean train loss 3284.612351276913
INFO:root:current train perplexity3.648348331451416
INFO:root:current mean train loss 3287.126344523067
INFO:root:current train perplexity3.650336503982544


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.44s/it]
INFO:root:final mean train loss: 3281.2510938336773
INFO:root:final train perplexity: 3.649348020553589
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.21s/it]
INFO:root:eval mean loss: 4094.992937236813
INFO:root:eval perplexity: 5.237764835357666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [10:18:09<3:16:00, 245.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.5214680989584
INFO:root:current train perplexity3.645291805267334
INFO:root:current mean train loss 3273.6145422894024
INFO:root:current train perplexity3.6324305534362793
INFO:root:current mean train loss 3276.026184365916
INFO:root:current train perplexity3.639646530151367
INFO:root:current mean train loss 3269.5537628658235
INFO:root:current train perplexity3.635221004486084
INFO:root:current mean train loss 3273.9828425028236
INFO:root:current train perplexity3.635739803314209
INFO:root:current mean train loss 3276.5374606530645
INFO:root:current train perplexity3.6392247676849365
INFO:root:current mean train loss 3277.578211143928
INFO:root:current train perplexity3.636577606201172
INFO:root:current mean train loss 3279.953917859484
INFO:root:current train perplexity3.6402900218963623
INFO:root:current mean train loss 3278.541843606212
INFO:root:current train perplexity3.6415531635284424
INFO:root:current mean train loss 3278.8279038059254
INFO:root:current train perplexity3.6425771713256836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.36s/it]
INFO:root:final mean train loss: 3276.432706586776
INFO:root:final train perplexity: 3.6424174308776855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.62s/it]
INFO:root:eval mean loss: 4094.6320593001997
INFO:root:eval perplexity: 5.237000942230225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [10:22:03<3:09:20, 241.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.3138480808425
INFO:root:current train perplexity3.589102268218994
INFO:root:current mean train loss 3265.901905090828
INFO:root:current train perplexity3.627918243408203
INFO:root:current mean train loss 3265.303129598164
INFO:root:current train perplexity3.6222665309906006
INFO:root:current mean train loss 3265.6632779242454
INFO:root:current train perplexity3.6219820976257324
INFO:root:current mean train loss 3267.551909606789
INFO:root:current train perplexity3.6267073154449463
INFO:root:current mean train loss 3270.8005128353548
INFO:root:current train perplexity3.6290340423583984
INFO:root:current mean train loss 3271.003243582589
INFO:root:current train perplexity3.632495880126953
INFO:root:current mean train loss 3274.27218471754
INFO:root:current train perplexity3.6358838081359863
INFO:root:current mean train loss 3276.978271484375
INFO:root:current train perplexity3.636742115020752
INFO:root:current mean train loss 3278.1995036248136
INFO:root:current train perplexity3.639737129211426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.35s/it]
INFO:root:final mean train loss: 3275.628136111844
INFO:root:final train perplexity: 3.641261339187622
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it]
INFO:root:eval mean loss: 4094.322856064384
INFO:root:eval perplexity: 5.2363457679748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [10:26:06<3:05:31, 241.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3289.0286589591733
INFO:root:current train perplexity3.652829170227051
INFO:root:current mean train loss 3269.268006768845
INFO:root:current train perplexity3.6366517543792725
INFO:root:current mean train loss 3267.725664147051
INFO:root:current train perplexity3.627509593963623
INFO:root:current mean train loss 3270.3817267749246
INFO:root:current train perplexity3.6325156688690186
INFO:root:current mean train loss 3267.290684817285
INFO:root:current train perplexity3.635277032852173
INFO:root:current mean train loss 3266.7466707678614
INFO:root:current train perplexity3.6346595287323
INFO:root:current mean train loss 3271.6850578199287
INFO:root:current train perplexity3.639190196990967
INFO:root:current mean train loss 3274.458471045122
INFO:root:current train perplexity3.6416525840759277
INFO:root:current mean train loss 3277.034938844389
INFO:root:current train perplexity3.639043092727661
INFO:root:current mean train loss 3275.0454098940154
INFO:root:current train perplexity3.637842893600464


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.24s/it]
INFO:root:final mean train loss: 3273.4304342577534
INFO:root:final train perplexity: 3.6381053924560547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.49s/it]
INFO:root:eval mean loss: 4096.844506662788
INFO:root:eval perplexity: 5.241688251495361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [10:30:05<3:00:59, 241.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.203600761218
INFO:root:current train perplexity3.63852596282959
INFO:root:current mean train loss 3267.410310813849
INFO:root:current train perplexity3.616123676300049
INFO:root:current mean train loss 3274.197696701752
INFO:root:current train perplexity3.6288745403289795
INFO:root:current mean train loss 3272.416660185057
INFO:root:current train perplexity3.633612871170044
INFO:root:current mean train loss 3266.766326278652
INFO:root:current train perplexity3.6335980892181396
INFO:root:current mean train loss 3269.2068573167903
INFO:root:current train perplexity3.6325838565826416
INFO:root:current mean train loss 3269.769616450875
INFO:root:current train perplexity3.6316916942596436
INFO:root:current mean train loss 3271.7599651661876
INFO:root:current train perplexity3.6319644451141357
INFO:root:current mean train loss 3272.5798243817044
INFO:root:current train perplexity3.631141185760498
INFO:root:current mean train loss 3274.1775814946086
INFO:root:current train perplexity3.635436773300171


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.18s/it]
INFO:root:final mean train loss: 3271.7453271189042
INFO:root:final train perplexity: 3.635687828063965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4095.591384779477
INFO:root:eval perplexity: 5.239032745361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [10:34:02<2:55:50, 239.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3262.4981092087764
INFO:root:current train perplexity3.584085464477539
INFO:root:current mean train loss 3272.3738523729803
INFO:root:current train perplexity3.6118836402893066
INFO:root:current mean train loss 3262.1676050101214
INFO:root:current train perplexity3.6122400760650635
INFO:root:current mean train loss 3264.82359608587
INFO:root:current train perplexity3.616673469543457
INFO:root:current mean train loss 3267.423532097665
INFO:root:current train perplexity3.6221487522125244
INFO:root:current mean train loss 3263.182725644853
INFO:root:current train perplexity3.6217267513275146
INFO:root:current mean train loss 3263.8904016132146
INFO:root:current train perplexity3.6240944862365723
INFO:root:current mean train loss 3267.2330477508995
INFO:root:current train perplexity3.626629114151001
INFO:root:current mean train loss 3270.33635862096
INFO:root:current train perplexity3.6285665035247803
INFO:root:current mean train loss 3271.5723581767256
INFO:root:current train perplexity3.6305036544799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.17s/it]
INFO:root:final mean train loss: 3269.423846337103
INFO:root:final train perplexity: 3.632359027862549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.46s/it]
INFO:root:eval mean loss: 4097.274623573249
INFO:root:eval perplexity: 5.2425994873046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [10:38:08<2:53:20, 241.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.657350852273
INFO:root:current train perplexity3.6463210582733154
INFO:root:current mean train loss 3242.967683656754
INFO:root:current train perplexity3.6225996017456055
INFO:root:current mean train loss 3253.9155637254903
INFO:root:current train perplexity3.622065305709839
INFO:root:current mean train loss 3258.7375343860035
INFO:root:current train perplexity3.6248154640197754
INFO:root:current mean train loss 3260.409995814732
INFO:root:current train perplexity3.624812126159668
INFO:root:current mean train loss 3263.987652642877
INFO:root:current train perplexity3.624603033065796
INFO:root:current mean train loss 3267.1279714336833
INFO:root:current train perplexity3.626701831817627
INFO:root:current mean train loss 3267.679227998241
INFO:root:current train perplexity3.6269373893737793
INFO:root:current mean train loss 3269.643465312043
INFO:root:current train perplexity3.6290833950042725
INFO:root:current mean train loss 3268.7047721183735
INFO:root:current train perplexity3.627335786819458


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.57s/it]
INFO:root:final mean train loss: 3266.216218640727
INFO:root:final train perplexity: 3.62776517868042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.43s/it]
INFO:root:eval mean loss: 4098.929355053191
INFO:root:eval perplexity: 5.246108531951904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [10:42:11<2:49:33, 242.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.752464657738
INFO:root:current train perplexity3.6237986087799072
INFO:root:current mean train loss 3274.659289026553
INFO:root:current train perplexity3.6175758838653564
INFO:root:current mean train loss 3268.848274492039
INFO:root:current train perplexity3.6151034832000732
INFO:root:current mean train loss 3260.530236446496
INFO:root:current train perplexity3.616697072982788
INFO:root:current mean train loss 3263.504938706466
INFO:root:current train perplexity3.6232171058654785
INFO:root:current mean train loss 3265.07596416033
INFO:root:current train perplexity3.6230149269104004
INFO:root:current mean train loss 3263.6823347503064
INFO:root:current train perplexity3.625657320022583
INFO:root:current mean train loss 3268.147390223112
INFO:root:current train perplexity3.6260273456573486
INFO:root:current mean train loss 3267.1494233981207
INFO:root:current train perplexity3.6261117458343506
INFO:root:current mean train loss 3267.295050663616
INFO:root:current train perplexity3.625500202178955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.96s/it]
INFO:root:final mean train loss: 3264.746419537452
INFO:root:final train perplexity: 3.6256625652313232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it]
INFO:root:eval mean loss: 4099.689548357159
INFO:root:eval perplexity: 5.247722148895264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [10:46:12<2:45:07, 241.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.5941041758365
INFO:root:current train perplexity3.63081955909729
INFO:root:current mean train loss 3255.3276724118236
INFO:root:current train perplexity3.609041690826416
INFO:root:current mean train loss 3257.241286612085
INFO:root:current train perplexity3.6109588146209717
INFO:root:current mean train loss 3253.184069528091
INFO:root:current train perplexity3.6152031421661377
INFO:root:current mean train loss 3258.986486220309
INFO:root:current train perplexity3.618741273880005
INFO:root:current mean train loss 3258.4347152576347
INFO:root:current train perplexity3.6196377277374268
INFO:root:current mean train loss 3260.5211791082575
INFO:root:current train perplexity3.6175124645233154
INFO:root:current mean train loss 3263.0244599774037
INFO:root:current train perplexity3.619272470474243
INFO:root:current mean train loss 3264.3283834358854
INFO:root:current train perplexity3.6228392124176025
INFO:root:current mean train loss 3264.6934516506017
INFO:root:current train perplexity3.6229610443115234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.02s/it]
INFO:root:final mean train loss: 3262.7448962426956
INFO:root:final train perplexity: 3.622799873352051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 4099.115926972518
INFO:root:eval perplexity: 5.246504306793213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [10:50:16<2:41:36, 242.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.072809533228
INFO:root:current train perplexity3.6021199226379395
INFO:root:current mean train loss 3250.6486366314593
INFO:root:current train perplexity3.614278793334961
INFO:root:current mean train loss 3257.3315053413417
INFO:root:current train perplexity3.617565870285034
INFO:root:current mean train loss 3264.0075090956875
INFO:root:current train perplexity3.6173765659332275
INFO:root:current mean train loss 3263.195085688772
INFO:root:current train perplexity3.617879867553711
INFO:root:current mean train loss 3264.6221567526177
INFO:root:current train perplexity3.6178932189941406
INFO:root:current mean train loss 3260.4847615260264
INFO:root:current train perplexity3.618321180343628
INFO:root:current mean train loss 3262.105603513118
INFO:root:current train perplexity3.6193315982818604
INFO:root:current mean train loss 3261.226341967968
INFO:root:current train perplexity3.62056040763855
INFO:root:current mean train loss 3263.193158376692
INFO:root:current train perplexity3.6209826469421387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.13s/it]
INFO:root:final mean train loss: 3261.2116755823936
INFO:root:final train perplexity: 3.6206092834472656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.60s/it]
INFO:root:eval mean loss: 4102.886644295767
INFO:root:eval perplexity: 5.254510402679443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [10:54:13<2:36:27, 240.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.312398976293
INFO:root:current train perplexity3.595444440841675
INFO:root:current mean train loss 3250.094086835729
INFO:root:current train perplexity3.5982444286346436
INFO:root:current mean train loss 3258.07000455956
INFO:root:current train perplexity3.604674816131592
INFO:root:current mean train loss 3262.3434762092215
INFO:root:current train perplexity3.6119301319122314
INFO:root:current mean train loss 3259.2196107586306
INFO:root:current train perplexity3.6114048957824707
INFO:root:current mean train loss 3261.325617463666
INFO:root:current train perplexity3.6123158931732178
INFO:root:current mean train loss 3259.5417896254094
INFO:root:current train perplexity3.6118106842041016
INFO:root:current mean train loss 3260.237884792924
INFO:root:current train perplexity3.6134450435638428
INFO:root:current mean train loss 3260.090076605658
INFO:root:current train perplexity3.61490535736084
INFO:root:current mean train loss 3262.3696996501394
INFO:root:current train perplexity3.6187360286712646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.11s/it]
INFO:root:final mean train loss: 3259.506903494558
INFO:root:final train perplexity: 3.6181745529174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it]
INFO:root:eval mean loss: 4102.310365068151
INFO:root:eval perplexity: 5.253286361694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [10:58:14<2:32:32, 240.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.026670435855
INFO:root:current train perplexity3.6066536903381348
INFO:root:current mean train loss 3260.8834873297274
INFO:root:current train perplexity3.618975877761841
INFO:root:current mean train loss 3256.8407838983053
INFO:root:current train perplexity3.6087872982025146
INFO:root:current mean train loss 3262.379924841772
INFO:root:current train perplexity3.609419345855713
INFO:root:current mean train loss 3265.0656871448864
INFO:root:current train perplexity3.614140033721924
INFO:root:current mean train loss 3264.221892233456
INFO:root:current train perplexity3.613862991333008
INFO:root:current mean train loss 3262.6675689916815
INFO:root:current train perplexity3.611839532852173
INFO:root:current mean train loss 3260.3812005576847
INFO:root:current train perplexity3.6128222942352295
INFO:root:current mean train loss 3260.510606341655
INFO:root:current train perplexity3.613907814025879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.87s/it]
INFO:root:final mean train loss: 3257.755127752981
INFO:root:final train perplexity: 3.6156749725341797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.17s/it]
INFO:root:eval mean loss: 4103.236386995789
INFO:root:eval perplexity: 5.255252838134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [11:02:17<2:28:56, 241.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.1314290364585
INFO:root:current train perplexity3.578886032104492
INFO:root:current mean train loss 3230.995761908374
INFO:root:current train perplexity3.610898971557617
INFO:root:current mean train loss 3252.9499451585593
INFO:root:current train perplexity3.62043833732605
INFO:root:current mean train loss 3251.7799019892223
INFO:root:current train perplexity3.6179373264312744
INFO:root:current mean train loss 3251.4598712779157
INFO:root:current train perplexity3.6195709705352783
INFO:root:current mean train loss 3252.5926768490617
INFO:root:current train perplexity3.617018699645996
INFO:root:current mean train loss 3255.3202622952945
INFO:root:current train perplexity3.6149661540985107
INFO:root:current mean train loss 3254.898286084193
INFO:root:current train perplexity3.6121487617492676
INFO:root:current mean train loss 3254.4375072968555
INFO:root:current train perplexity3.6116631031036377
INFO:root:current mean train loss 3258.3635129537824
INFO:root:current train perplexity3.612919330596924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.36s/it]
INFO:root:final mean train loss: 3255.826874825262
INFO:root:final train perplexity: 3.6129260063171387
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.09s/it]
INFO:root:eval mean loss: 4104.305529005984
INFO:root:eval perplexity: 5.2575273513793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [11:06:13<2:24:00, 240.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.2466930042615
INFO:root:current train perplexity3.588576555252075
INFO:root:current mean train loss 3253.842287355715
INFO:root:current train perplexity3.5922112464904785
INFO:root:current mean train loss 3257.3814980746447
INFO:root:current train perplexity3.600778102874756
INFO:root:current mean train loss 3258.494655596865
INFO:root:current train perplexity3.6100335121154785
INFO:root:current mean train loss 3263.882891504144
INFO:root:current train perplexity3.6173694133758545
INFO:root:current mean train loss 3260.0728886374754
INFO:root:current train perplexity3.6170458793640137
INFO:root:current mean train loss 3257.6089226805443
INFO:root:current train perplexity3.6139087677001953
INFO:root:current mean train loss 3256.4150850749384
INFO:root:current train perplexity3.6126909255981445
INFO:root:current mean train loss 3257.594337322268
INFO:root:current train perplexity3.612264633178711
INFO:root:current mean train loss 3257.7245718561335
INFO:root:current train perplexity3.612217664718628


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.21s/it]
INFO:root:final mean train loss: 3253.9600303403795
INFO:root:final train perplexity: 3.6102654933929443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it]
INFO:root:eval mean loss: 4105.109568927305
INFO:root:eval perplexity: 5.259235858917236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [11:10:17<2:20:33, 240.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.1417429070725
INFO:root:current train perplexity3.633993625640869
INFO:root:current mean train loss 3256.990033318015
INFO:root:current train perplexity3.6120851039886475
INFO:root:current mean train loss 3260.292824941139
INFO:root:current train perplexity3.618227481842041
INFO:root:current mean train loss 3258.8779358101488
INFO:root:current train perplexity3.611807346343994
INFO:root:current mean train loss 3254.8674700971437
INFO:root:current train perplexity3.6100265979766846
INFO:root:current mean train loss 3253.513614015083
INFO:root:current train perplexity3.6104607582092285
INFO:root:current mean train loss 3256.3673744509792
INFO:root:current train perplexity3.611515760421753
INFO:root:current mean train loss 3258.1982812364176
INFO:root:current train perplexity3.610962152481079
INFO:root:current mean train loss 3258.1040477263623
INFO:root:current train perplexity3.612258195877075
INFO:root:current mean train loss 3256.111502662966
INFO:root:current train perplexity3.6089937686920166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:40<00:00, 220.73s/it]
INFO:root:final mean train loss: 3252.9959599279587
INFO:root:final train perplexity: 3.6088926792144775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it]
INFO:root:eval mean loss: 4107.61996654754
INFO:root:eval perplexity: 5.264577865600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [11:14:19<2:16:46, 241.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3246.5634313512733
INFO:root:current train perplexity3.611588954925537
INFO:root:current mean train loss 3247.195156788263
INFO:root:current train perplexity3.592724561691284
INFO:root:current mean train loss 3251.711809738092
INFO:root:current train perplexity3.6011877059936523
INFO:root:current mean train loss 3248.430787999331
INFO:root:current train perplexity3.600337028503418
INFO:root:current mean train loss 3251.191036894394
INFO:root:current train perplexity3.5998523235321045
INFO:root:current mean train loss 3254.3855082387036
INFO:root:current train perplexity3.599754571914673
INFO:root:current mean train loss 3253.7542395584132
INFO:root:current train perplexity3.600869655609131
INFO:root:current mean train loss 3255.3944825562025
INFO:root:current train perplexity3.6035895347595215
INFO:root:current mean train loss 3252.5893631442714
INFO:root:current train perplexity3.6041622161865234
INFO:root:current mean train loss 3252.7206517685577
INFO:root:current train perplexity3.6047134399414062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.41s/it]
INFO:root:final mean train loss: 3249.8960525758803
INFO:root:final train perplexity: 3.6044819355010986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.50s/it]
INFO:root:eval mean loss: 4105.8004886275485
INFO:root:eval perplexity: 5.260705947875977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [11:18:14<2:11:41, 239.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.047035435268
INFO:root:current train perplexity3.5995233058929443
INFO:root:current mean train loss 3251.1587691695604
INFO:root:current train perplexity3.6026763916015625
INFO:root:current mean train loss 3240.7822857795877
INFO:root:current train perplexity3.5959231853485107
INFO:root:current mean train loss 3246.5873294659514
INFO:root:current train perplexity3.5965735912323
INFO:root:current mean train loss 3248.744244454921
INFO:root:current train perplexity3.598515033721924
INFO:root:current mean train loss 3252.633434944509
INFO:root:current train perplexity3.6002278327941895
INFO:root:current mean train loss 3251.8055087352363
INFO:root:current train perplexity3.6019763946533203
INFO:root:current mean train loss 3253.0061018548045
INFO:root:current train perplexity3.6013550758361816
INFO:root:current mean train loss 3252.8111626356663
INFO:root:current train perplexity3.60134220123291
INFO:root:current mean train loss 3252.178594742229
INFO:root:current train perplexity3.602869987487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:39<00:00, 219.71s/it]
INFO:root:final mean train loss: 3249.201496247322
INFO:root:final train perplexity: 3.603494167327881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.69s/it]
INFO:root:eval mean loss: 4104.964246384641
INFO:root:eval perplexity: 5.258926868438721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [11:22:15<2:08:01, 240.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.0928415697676
INFO:root:current train perplexity3.5781033039093018
INFO:root:current mean train loss 3266.6503820886146
INFO:root:current train perplexity3.609872817993164
INFO:root:current mean train loss 3250.4689820842977
INFO:root:current train perplexity3.6043314933776855
INFO:root:current mean train loss 3245.1920767469933
INFO:root:current train perplexity3.597540855407715
INFO:root:current mean train loss 3246.227639364066
INFO:root:current train perplexity3.5981318950653076
INFO:root:current mean train loss 3243.7932115417816
INFO:root:current train perplexity3.593087911605835
INFO:root:current mean train loss 3249.0620580409213
INFO:root:current train perplexity3.595137596130371
INFO:root:current mean train loss 3251.1900495115874
INFO:root:current train perplexity3.6007416248321533
INFO:root:current mean train loss 3253.091352614361
INFO:root:current train perplexity3.602599859237671
INFO:root:current mean train loss 3251.167237881512
INFO:root:current train perplexity3.6018831729888916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:41<00:00, 221.47s/it]
INFO:root:final mean train loss: 3247.811017436366
INFO:root:final train perplexity: 3.601517915725708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it]
INFO:root:eval mean loss: 4106.223063151042
INFO:root:eval perplexity: 5.2616047859191895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [11:26:18<2:04:27, 240.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3263.032351026348
INFO:root:current train perplexity3.5969038009643555
INFO:root:current mean train loss 3242.978138904698
INFO:root:current train perplexity3.5877997875213623
INFO:root:current mean train loss 3244.387696285172
INFO:root:current train perplexity3.5974440574645996
INFO:root:current mean train loss 3242.4963782329505
INFO:root:current train perplexity3.593770742416382
INFO:root:current mean train loss 3237.0737883912484
INFO:root:current train perplexity3.5889217853546143
INFO:root:current mean train loss 3237.2351614784197
INFO:root:current train perplexity3.589812994003296
INFO:root:current mean train loss 3241.4054009456604
INFO:root:current train perplexity3.5923280715942383
INFO:root:current mean train loss 3244.4721260324777
INFO:root:current train perplexity3.5956308841705322
INFO:root:current mean train loss 3246.0527280634915
INFO:root:current train perplexity3.5952064990997314
INFO:root:current mean train loss 3247.047536053743
INFO:root:current train perplexity3.5967202186584473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.84s/it]
INFO:root:final mean train loss: 3245.226603969451
INFO:root:final train perplexity: 3.5978477001190186
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.58s/it]
INFO:root:eval mean loss: 4107.360950659353
INFO:root:eval perplexity: 5.264026165008545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [11:30:11<1:59:10, 238.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.781022411282
INFO:root:current train perplexity3.5978009700775146
INFO:root:current mean train loss 3228.9505054785773
INFO:root:current train perplexity3.576528787612915
INFO:root:current mean train loss 3227.9565476818893
INFO:root:current train perplexity3.58402943611145
INFO:root:current mean train loss 3238.165414454213
INFO:root:current train perplexity3.5946855545043945
INFO:root:current mean train loss 3237.4602779479847
INFO:root:current train perplexity3.5923635959625244
INFO:root:current mean train loss 3240.481795582234
INFO:root:current train perplexity3.5960874557495117
INFO:root:current mean train loss 3243.797405885456
INFO:root:current train perplexity3.5973639488220215
INFO:root:current mean train loss 3246.5290906903615
INFO:root:current train perplexity3.598815679550171
INFO:root:current mean train loss 3247.0977648201033
INFO:root:current train perplexity3.5990796089172363
INFO:root:current mean train loss 3247.0554415610336
INFO:root:current train perplexity3.5981650352478027


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.20s/it]
INFO:root:final mean train loss: 3245.3291201437673
INFO:root:final train perplexity: 3.5979931354522705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it]
INFO:root:eval mean loss: 4108.719889322917
INFO:root:eval perplexity: 5.26692008972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [11:34:17<1:56:21, 240.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.9238099055506
INFO:root:current train perplexity3.5773863792419434
INFO:root:current mean train loss 3257.9957282700225
INFO:root:current train perplexity3.5994648933410645
INFO:root:current mean train loss 3251.4992739788154
INFO:root:current train perplexity3.6058084964752197
INFO:root:current mean train loss 3249.2097593718067
INFO:root:current train perplexity3.6037209033966064
INFO:root:current mean train loss 3241.248500129651
INFO:root:current train perplexity3.5980465412139893
INFO:root:current mean train loss 3239.808262201003
INFO:root:current train perplexity3.5941104888916016
INFO:root:current mean train loss 3240.6112926202914
INFO:root:current train perplexity3.595060110092163
INFO:root:current mean train loss 3242.9442646369785
INFO:root:current train perplexity3.595498561859131
INFO:root:current mean train loss 3245.7268522585964
INFO:root:current train perplexity3.5958316326141357
INFO:root:current mean train loss 3246.06769613051
INFO:root:current train perplexity3.5960612297058105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.48s/it]
INFO:root:final mean train loss: 3243.855885351858
INFO:root:final train perplexity: 3.59590220451355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.55s/it]
INFO:root:eval mean loss: 4107.971200063719
INFO:root:eval perplexity: 5.265325546264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [11:38:16<1:52:05, 240.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.700703125
INFO:root:current train perplexity3.5972001552581787
INFO:root:current mean train loss 3233.374686104911
INFO:root:current train perplexity3.5860979557037354
INFO:root:current mean train loss 3245.012218572443
INFO:root:current train perplexity3.5922980308532715
INFO:root:current mean train loss 3241.55998828125
INFO:root:current train perplexity3.5898101329803467
INFO:root:current mean train loss 3242.477877775493
INFO:root:current train perplexity3.591202974319458
INFO:root:current mean train loss 3244.192422299592
INFO:root:current train perplexity3.5917487144470215
INFO:root:current mean train loss 3241.7833799913196
INFO:root:current train perplexity3.5918848514556885
INFO:root:current mean train loss 3243.436194871472
INFO:root:current train perplexity3.5927751064300537
INFO:root:current mean train loss 3245.9986007254465
INFO:root:current train perplexity3.5942320823669434
INFO:root:current mean train loss 3245.130655548878
INFO:root:current train perplexity3.5934250354766846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.93s/it]
INFO:root:final mean train loss: 3242.1114311833535
INFO:root:final train perplexity: 3.59342885017395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.56s/it]
INFO:root:eval mean loss: 4109.319955812279
INFO:root:eval perplexity: 5.268198490142822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [11:42:12<1:47:35, 239.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.6452107257155
INFO:root:current train perplexity3.6102564334869385
INFO:root:current mean train loss 3245.342430573344
INFO:root:current train perplexity3.5890848636627197
INFO:root:current mean train loss 3242.780163013472
INFO:root:current train perplexity3.591221332550049
INFO:root:current mean train loss 3243.0710353602317
INFO:root:current train perplexity3.5860936641693115
INFO:root:current mean train loss 3251.103199202575
INFO:root:current train perplexity3.5919435024261475
INFO:root:current mean train loss 3244.845301947095
INFO:root:current train perplexity3.5901618003845215
INFO:root:current mean train loss 3242.6279983185395
INFO:root:current train perplexity3.588606595993042
INFO:root:current mean train loss 3243.774366045059
INFO:root:current train perplexity3.5900604724884033
INFO:root:current mean train loss 3245.397198825028
INFO:root:current train perplexity3.5922112464904785
INFO:root:current mean train loss 3243.5617310687944
INFO:root:current train perplexity3.5918116569519043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.45s/it]
INFO:root:final mean train loss: 3241.0346608315745
INFO:root:final train perplexity: 3.591902494430542
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it]
INFO:root:eval mean loss: 4110.359013117797
INFO:root:eval perplexity: 5.270411968231201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [11:46:23<1:45:04, 242.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.0965857872598
INFO:root:current train perplexity3.574876308441162
INFO:root:current mean train loss 3221.2187231573134
INFO:root:current train perplexity3.5706512928009033
INFO:root:current mean train loss 3231.971813083924
INFO:root:current train perplexity3.57938814163208
INFO:root:current mean train loss 3237.1611040900734
INFO:root:current train perplexity3.5832011699676514
INFO:root:current mean train loss 3233.3562742648933
INFO:root:current train perplexity3.5782291889190674
INFO:root:current mean train loss 3235.343818987283
INFO:root:current train perplexity3.5790998935699463
INFO:root:current mean train loss 3237.222828667692
INFO:root:current train perplexity3.5810749530792236
INFO:root:current mean train loss 3238.0361291087233
INFO:root:current train perplexity3.5827414989471436
INFO:root:current mean train loss 3241.1447318234427
INFO:root:current train perplexity3.58674693107605
INFO:root:current mean train loss 3241.9072879056034
INFO:root:current train perplexity3.589561939239502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.94s/it]
INFO:root:final mean train loss: 3239.3503676999
INFO:root:final train perplexity: 3.5895166397094727
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.07s/it]
INFO:root:eval mean loss: 4109.214061114805
INFO:root:eval perplexity: 5.267971515655518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [11:50:30<1:41:35, 243.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.5065523398043
INFO:root:current train perplexity3.5874297618865967
INFO:root:current mean train loss 3232.98891552489
INFO:root:current train perplexity3.5791163444519043
INFO:root:current mean train loss 3233.323554099603
INFO:root:current train perplexity3.579141139984131
INFO:root:current mean train loss 3234.7195001664318
INFO:root:current train perplexity3.5804150104522705
INFO:root:current mean train loss 3235.689013769727
INFO:root:current train perplexity3.5814669132232666
INFO:root:current mean train loss 3237.2860712678685
INFO:root:current train perplexity3.585192918777466
INFO:root:current mean train loss 3238.873045827186
INFO:root:current train perplexity3.584488868713379
INFO:root:current mean train loss 3237.334309182865
INFO:root:current train perplexity3.583695650100708
INFO:root:current mean train loss 3237.727383453403
INFO:root:current train perplexity3.584482431411743


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.65s/it]
INFO:root:final mean train loss: 3237.8077839882144
INFO:root:final train perplexity: 3.587332248687744
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.77s/it]
INFO:root:eval mean loss: 4109.562333776596
INFO:root:eval perplexity: 5.268713474273682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [11:54:27<1:36:45, 241.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.1898367745534
INFO:root:current train perplexity3.4873576164245605
INFO:root:current mean train loss 3247.158198561624
INFO:root:current train perplexity3.5776405334472656
INFO:root:current mean train loss 3239.0918334371227
INFO:root:current train perplexity3.5736873149871826
INFO:root:current mean train loss 3234.8819886247966
INFO:root:current train perplexity3.5741446018218994
INFO:root:current mean train loss 3235.8411226389744
INFO:root:current train perplexity3.5721890926361084
INFO:root:current mean train loss 3233.2494765663523
INFO:root:current train perplexity3.57289719581604
INFO:root:current mean train loss 3232.0601852894615
INFO:root:current train perplexity3.574683666229248
INFO:root:current mean train loss 3233.951145630746
INFO:root:current train perplexity3.5792503356933594
INFO:root:current mean train loss 3235.2496297049256
INFO:root:current train perplexity3.5807337760925293
INFO:root:current mean train loss 3238.3193849271292
INFO:root:current train perplexity3.585080623626709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.38s/it]
INFO:root:final mean train loss: 3234.94090929339
INFO:root:final train perplexity: 3.5832772254943848
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.70s/it]
INFO:root:eval mean loss: 4110.715884377771
INFO:root:eval perplexity: 5.271172523498535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [11:58:31<1:33:00, 242.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.7975260416665
INFO:root:current train perplexity3.5348825454711914
INFO:root:current mean train loss 3226.665788468071
INFO:root:current train perplexity3.5537261962890625
INFO:root:current mean train loss 3233.261127134811
INFO:root:current train perplexity3.5826449394226074
INFO:root:current mean train loss 3230.8034117683533
INFO:root:current train perplexity3.5833539962768555
INFO:root:current mean train loss 3233.8515948559866
INFO:root:current train perplexity3.580601453781128
INFO:root:current mean train loss 3233.63229767142
INFO:root:current train perplexity3.579165458679199
INFO:root:current mean train loss 3236.312168921494
INFO:root:current train perplexity3.5799784660339355
INFO:root:current mean train loss 3239.3921383304196
INFO:root:current train perplexity3.583329200744629
INFO:root:current mean train loss 3239.9776028685774
INFO:root:current train perplexity3.5841307640075684
INFO:root:current mean train loss 3238.725950947746
INFO:root:current train perplexity3.5854732990264893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.11s/it]
INFO:root:final mean train loss: 3236.6898428393947
INFO:root:final train perplexity: 3.5857503414154053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.56s/it]
INFO:root:eval mean loss: 4110.740073346077
INFO:root:eval perplexity: 5.271224498748779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [12:02:29<1:28:25, 241.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.2209154211955
INFO:root:current train perplexity3.5791335105895996
INFO:root:current mean train loss 3250.1701124237807
INFO:root:current train perplexity3.5774917602539062
INFO:root:current mean train loss 3243.3735471990612
INFO:root:current train perplexity3.572284460067749
INFO:root:current mean train loss 3242.5959132522253
INFO:root:current train perplexity3.574019193649292
INFO:root:current mean train loss 3245.3251710715867
INFO:root:current train perplexity3.5783298015594482
INFO:root:current mean train loss 3239.712925635606
INFO:root:current train perplexity3.578538417816162
INFO:root:current mean train loss 3238.6616689029897
INFO:root:current train perplexity3.578429937362671
INFO:root:current mean train loss 3235.3258007677427
INFO:root:current train perplexity3.578887701034546
INFO:root:current mean train loss 3233.6850965645885
INFO:root:current train perplexity3.577329158782959
INFO:root:current mean train loss 3234.6624558801122
INFO:root:current train perplexity3.581014394760132


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.23s/it]
INFO:root:final mean train loss: 3233.369599250055
INFO:root:final train perplexity: 3.5810561180114746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.40s/it]
INFO:root:eval mean loss: 4111.6303745567375
INFO:root:eval perplexity: 5.2731218338012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [12:06:29<1:24:15, 240.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.509214339718
INFO:root:current train perplexity3.591113805770874
INFO:root:current mean train loss 3230.1295771708014
INFO:root:current train perplexity3.579939126968384
INFO:root:current mean train loss 3228.469683230181
INFO:root:current train perplexity3.5860037803649902
INFO:root:current mean train loss 3227.6644858737727
INFO:root:current train perplexity3.583348512649536
INFO:root:current mean train loss 3230.138010259571
INFO:root:current train perplexity3.5818660259246826
INFO:root:current mean train loss 3231.7577108896835
INFO:root:current train perplexity3.5786638259887695
INFO:root:current mean train loss 3233.2516405011884
INFO:root:current train perplexity3.5809404850006104
INFO:root:current mean train loss 3235.807054762312
INFO:root:current train perplexity3.5829925537109375
INFO:root:current mean train loss 3236.4862734798057
INFO:root:current train perplexity3.5819103717803955
INFO:root:current mean train loss 3234.729055828746
INFO:root:current train perplexity3.5799779891967773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.56s/it]
INFO:root:final mean train loss: 3234.157044379942
INFO:root:final train perplexity: 3.5821692943573
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.79s/it]
INFO:root:eval mean loss: 4112.11527073637
INFO:root:eval perplexity: 5.274156093597412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [12:10:26<1:19:54, 239.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.7051219451123
INFO:root:current train perplexity3.6011486053466797
INFO:root:current mean train loss 3226.4392599201888
INFO:root:current train perplexity3.57778263092041
INFO:root:current mean train loss 3227.301166358852
INFO:root:current train perplexity3.577991485595703
INFO:root:current mean train loss 3233.1398162391683
INFO:root:current train perplexity3.57739520072937
INFO:root:current mean train loss 3231.564846864322
INFO:root:current train perplexity3.5778698921203613
INFO:root:current mean train loss 3231.2371239600243
INFO:root:current train perplexity3.576507568359375
INFO:root:current mean train loss 3229.818668466965
INFO:root:current train perplexity3.57440447807312
INFO:root:current mean train loss 3232.720923479258
INFO:root:current train perplexity3.5765271186828613
INFO:root:current mean train loss 3235.262513443739
INFO:root:current train perplexity3.5806093215942383
INFO:root:current mean train loss 3235.2476831340687
INFO:root:current train perplexity3.5795884132385254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.93s/it]
INFO:root:final mean train loss: 3233.362130072809
INFO:root:final train perplexity: 3.5810458660125732
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 4112.134010693706
INFO:root:eval perplexity: 5.274197101593018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [12:14:12<1:14:32, 235.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.500768783245
INFO:root:current train perplexity3.562626838684082
INFO:root:current mean train loss 3229.3973729140093
INFO:root:current train perplexity3.5790512561798096
INFO:root:current mean train loss 3234.164164307629
INFO:root:current train perplexity3.5785562992095947
INFO:root:current mean train loss 3241.845088200198
INFO:root:current train perplexity3.585245132446289
INFO:root:current mean train loss 3238.258815278943
INFO:root:current train perplexity3.5813827514648438
INFO:root:current mean train loss 3236.173746893567
INFO:root:current train perplexity3.5818772315979004
INFO:root:current mean train loss 3237.9947960689965
INFO:root:current train perplexity3.581430196762085
INFO:root:current mean train loss 3236.156291180346
INFO:root:current train perplexity3.5808422565460205
INFO:root:current mean train loss 3236.2858843482513
INFO:root:current train perplexity3.581101894378662
INFO:root:current mean train loss 3235.636375612543
INFO:root:current train perplexity3.580432176589966


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:18<00:00, 198.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:18<00:00, 198.81s/it]
INFO:root:final mean train loss: 3232.267465160739
INFO:root:final train perplexity: 3.5794997215270996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.13s/it]
INFO:root:eval mean loss: 4113.782049950133
INFO:root:eval perplexity: 5.277711868286133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [12:17:50<1:09:03, 230.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.9583540482954
INFO:root:current train perplexity3.5953235626220703
INFO:root:current mean train loss 3220.46998015373
INFO:root:current train perplexity3.5825536251068115
INFO:root:current mean train loss 3220.8558804381128
INFO:root:current train perplexity3.5700175762176514
INFO:root:current mean train loss 3226.144875110035
INFO:root:current train perplexity3.570218324661255
INFO:root:current mean train loss 3227.7972747467375
INFO:root:current train perplexity3.5679123401641846
INFO:root:current mean train loss 3226.6396563555745
INFO:root:current train perplexity3.572171211242676
INFO:root:current mean train loss 3228.7863240249285
INFO:root:current train perplexity3.5716052055358887
INFO:root:current mean train loss 3230.971528999379
INFO:root:current train perplexity3.5757827758789062
INFO:root:current mean train loss 3232.7189213267543
INFO:root:current train perplexity3.5763258934020996
INFO:root:current mean train loss 3233.4063540473658
INFO:root:current train perplexity3.576443910598755


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.09s/it]
INFO:root:final mean train loss: 3229.8659567063855
INFO:root:final train perplexity: 3.5761096477508545
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.20s/it]
INFO:root:eval mean loss: 4113.261104069703
INFO:root:eval perplexity: 5.276599407196045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [12:21:38<1:05:04, 229.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.2484072730654
INFO:root:current train perplexity3.576261043548584
INFO:root:current mean train loss 3234.5045383195934
INFO:root:current train perplexity3.5708913803100586
INFO:root:current mean train loss 3228.357175877792
INFO:root:current train perplexity3.571190595626831
INFO:root:current mean train loss 3229.2977338638516
INFO:root:current train perplexity3.5745046138763428
INFO:root:current mean train loss 3229.306316334537
INFO:root:current train perplexity3.574045419692993
INFO:root:current mean train loss 3227.7091149013377
INFO:root:current train perplexity3.5728840827941895
INFO:root:current mean train loss 3230.4277549962294
INFO:root:current train perplexity3.5741734504699707
INFO:root:current mean train loss 3231.3973905430867
INFO:root:current train perplexity3.5725061893463135
INFO:root:current mean train loss 3229.1963728001883
INFO:root:current train perplexity3.572496175765991
INFO:root:current mean train loss 3229.431995047216
INFO:root:current train perplexity3.5735182762145996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.27s/it]
INFO:root:final mean train loss: 3228.0496173981696
INFO:root:final train perplexity: 3.5735480785369873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.05s/it]
INFO:root:eval mean loss: 4114.224181696033
INFO:root:eval perplexity: 5.278656005859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [12:25:28<1:01:17, 229.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.6158326914615
INFO:root:current train perplexity3.56927227973938
INFO:root:current mean train loss 3235.9271475808664
INFO:root:current train perplexity3.5678093433380127
INFO:root:current mean train loss 3233.5015567343175
INFO:root:current train perplexity3.567089319229126
INFO:root:current mean train loss 3230.951263345477
INFO:root:current train perplexity3.5670604705810547
INFO:root:current mean train loss 3229.7019768652135
INFO:root:current train perplexity3.5665242671966553
INFO:root:current mean train loss 3229.871748354723
INFO:root:current train perplexity3.5679075717926025
INFO:root:current mean train loss 3229.3922950528595
INFO:root:current train perplexity3.5695254802703857
INFO:root:current mean train loss 3227.4455927392387
INFO:root:current train perplexity3.569293260574341
INFO:root:current mean train loss 3231.307313062841
INFO:root:current train perplexity3.571118116378784
INFO:root:current mean train loss 3230.35772485075
INFO:root:current train perplexity3.572404384613037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.80s/it]
INFO:root:final mean train loss: 3227.0724578980476
INFO:root:final train perplexity: 3.5721707344055176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.01s/it]
INFO:root:eval mean loss: 4113.92475447418
INFO:root:eval perplexity: 5.278016567230225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [12:29:15<57:13, 228.93s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.906577581092
INFO:root:current train perplexity3.559242010116577
INFO:root:current mean train loss 3216.5660884580134
INFO:root:current train perplexity3.568369150161743
INFO:root:current mean train loss 3219.9645479810706
INFO:root:current train perplexity3.576307535171509
INFO:root:current mean train loss 3224.112579104139
INFO:root:current train perplexity3.5723371505737305
INFO:root:current mean train loss 3226.6272915579334
INFO:root:current train perplexity3.5723230838775635
INFO:root:current mean train loss 3229.3435530851953
INFO:root:current train perplexity3.572021245956421
INFO:root:current mean train loss 3230.4506983356728
INFO:root:current train perplexity3.57305645942688
INFO:root:current mean train loss 3230.466852660663
INFO:root:current train perplexity3.5738987922668457
INFO:root:current mean train loss 3231.453635223354
INFO:root:current train perplexity3.5736703872680664
INFO:root:current mean train loss 3230.089539260007
INFO:root:current train perplexity3.572261095046997


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.82s/it]
INFO:root:final mean train loss: 3227.0775994331607
INFO:root:final train perplexity: 3.5721778869628906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 4113.9454492880095
INFO:root:eval perplexity: 5.278061389923096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [12:33:02<53:15, 228.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.7963670752515
INFO:root:current train perplexity3.580294132232666
INFO:root:current mean train loss 3228.503590303309
INFO:root:current train perplexity3.5774190425872803
INFO:root:current mean train loss 3231.008038776677
INFO:root:current train perplexity3.5702052116394043
INFO:root:current mean train loss 3231.6916415586643
INFO:root:current train perplexity3.5688350200653076
INFO:root:current mean train loss 3232.1024633638667
INFO:root:current train perplexity3.568065881729126
INFO:root:current mean train loss 3230.8456756747764
INFO:root:current train perplexity3.570169448852539
INFO:root:current mean train loss 3232.841920899859
INFO:root:current train perplexity3.572143077850342
INFO:root:current mean train loss 3230.9240489993645
INFO:root:current train perplexity3.571892738342285
INFO:root:current mean train loss 3229.6576961272194
INFO:root:current train perplexity3.571547746658325
INFO:root:current mean train loss 3228.9784990521307
INFO:root:current train perplexity3.5713088512420654


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.65s/it]
INFO:root:final mean train loss: 3225.942031921879
INFO:root:final train perplexity: 3.570578098297119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.88s/it]
INFO:root:eval mean loss: 4115.377413702349
INFO:root:eval perplexity: 5.281118869781494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [12:36:48<49:20, 227.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.716470497533
INFO:root:current train perplexity3.5663414001464844
INFO:root:current mean train loss 3231.823265975561
INFO:root:current train perplexity3.572096586227417
INFO:root:current mean train loss 3227.9913731461866
INFO:root:current train perplexity3.56907320022583
INFO:root:current mean train loss 3224.9856636916534
INFO:root:current train perplexity3.566906213760376
INFO:root:current mean train loss 3223.4507467250633
INFO:root:current train perplexity3.5653858184814453
INFO:root:current mean train loss 3227.040708295037
INFO:root:current train perplexity3.570157051086426
INFO:root:current mean train loss 3231.5658445509216
INFO:root:current train perplexity3.57416033744812
INFO:root:current mean train loss 3230.645683470912
INFO:root:current train perplexity3.572864532470703
INFO:root:current mean train loss 3229.4034234244064
INFO:root:current train perplexity3.5725061893463135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.36s/it]
INFO:root:final mean train loss: 3226.4458989174136
INFO:root:final train perplexity: 3.5712876319885254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 4114.002280377327
INFO:root:eval perplexity: 5.278182029724121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [12:40:31<45:16, 226.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.7119140625
INFO:root:current train perplexity3.54166316986084
INFO:root:current mean train loss 3221.782887875455
INFO:root:current train perplexity3.5466508865356445
INFO:root:current mean train loss 3221.8848510140856
INFO:root:current train perplexity3.5584850311279297
INFO:root:current mean train loss 3226.450466042698
INFO:root:current train perplexity3.5664401054382324
INFO:root:current mean train loss 3223.4180880941767
INFO:root:current train perplexity3.5660665035247803
INFO:root:current mean train loss 3224.7261669242357
INFO:root:current train perplexity3.5693252086639404
INFO:root:current mean train loss 3220.8967090815454
INFO:root:current train perplexity3.567667245864868
INFO:root:current mean train loss 3222.984329853085
INFO:root:current train perplexity3.5651848316192627
INFO:root:current mean train loss 3223.023895681721
INFO:root:current train perplexity3.565185785293579
INFO:root:current mean train loss 3227.799157971692
INFO:root:current train perplexity3.567802906036377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.69s/it]
INFO:root:final mean train loss: 3224.4781481219875
INFO:root:final train perplexity: 3.568516731262207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 4114.513824246454
INFO:root:eval perplexity: 5.279273986816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [12:44:17<41:26, 226.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.641424005682
INFO:root:current train perplexity3.5813844203948975
INFO:root:current mean train loss 3209.7785028681024
INFO:root:current train perplexity3.5563735961914062
INFO:root:current mean train loss 3223.7468493131664
INFO:root:current train perplexity3.5622620582580566
INFO:root:current mean train loss 3225.62261197498
INFO:root:current train perplexity3.5648117065429688
INFO:root:current mean train loss 3221.7328572888155
INFO:root:current train perplexity3.5661709308624268
INFO:root:current mean train loss 3220.461668488564
INFO:root:current train perplexity3.565026044845581
INFO:root:current mean train loss 3218.9921775106127
INFO:root:current train perplexity3.5630083084106445
INFO:root:current mean train loss 3221.5676647245295
INFO:root:current train perplexity3.5656561851501465
INFO:root:current mean train loss 3221.447279171644
INFO:root:current train perplexity3.5640244483947754
INFO:root:current mean train loss 3224.886050110198
INFO:root:current train perplexity3.56630277633667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.73s/it]
INFO:root:final mean train loss: 3223.563455397083
INFO:root:final train perplexity: 3.5672285556793213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 4114.790996578568
INFO:root:eval perplexity: 5.279865264892578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [12:47:59<37:29, 224.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.7111302425988
INFO:root:current train perplexity3.5856118202209473
INFO:root:current mean train loss 3243.515575761555
INFO:root:current train perplexity3.575812578201294
INFO:root:current mean train loss 3235.818068412885
INFO:root:current train perplexity3.567054033279419
INFO:root:current mean train loss 3235.817131018564
INFO:root:current train perplexity3.568709373474121
INFO:root:current mean train loss 3228.0833696533787
INFO:root:current train perplexity3.5668113231658936
INFO:root:current mean train loss 3228.557729614493
INFO:root:current train perplexity3.566681146621704
INFO:root:current mean train loss 3225.8641004423716
INFO:root:current train perplexity3.5662219524383545
INFO:root:current mean train loss 3225.2133412155554
INFO:root:current train perplexity3.565735340118408
INFO:root:current mean train loss 3223.2535807291665
INFO:root:current train perplexity3.565502405166626
INFO:root:current mean train loss 3223.9102861572533
INFO:root:current train perplexity3.56510329246521


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.83s/it]
INFO:root:final mean train loss: 3223.369212612029
INFO:root:final train perplexity: 3.566955089569092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 4116.231777759309
INFO:root:eval perplexity: 5.282942771911621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [12:51:47<33:51, 225.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.0795536747687
INFO:root:current train perplexity3.583660840988159
INFO:root:current mean train loss 3246.6147403266486
INFO:root:current train perplexity3.570700168609619
INFO:root:current mean train loss 3236.422378338381
INFO:root:current train perplexity3.5702707767486572
INFO:root:current mean train loss 3234.21164827026
INFO:root:current train perplexity3.5684428215026855
INFO:root:current mean train loss 3231.0416685725263
INFO:root:current train perplexity3.5685932636260986
INFO:root:current mean train loss 3233.145158510733
INFO:root:current train perplexity3.568314790725708
INFO:root:current mean train loss 3229.612783623654
INFO:root:current train perplexity3.5683133602142334
INFO:root:current mean train loss 3226.67838384951
INFO:root:current train perplexity3.56614089012146
INFO:root:current mean train loss 3225.148150553582
INFO:root:current train perplexity3.566279888153076
INFO:root:current mean train loss 3225.1452591946468
INFO:root:current train perplexity3.566342353820801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.78s/it]
INFO:root:final mean train loss: 3223.699397671607
INFO:root:final train perplexity: 3.567420244216919
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 4115.806287400266
INFO:root:eval perplexity: 5.282034873962402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [12:55:32<30:04, 225.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.972426060268
INFO:root:current train perplexity3.572726011276245
INFO:root:current mean train loss 3220.828416160301
INFO:root:current train perplexity3.559710741043091
INFO:root:current mean train loss 3217.80580639129
INFO:root:current train perplexity3.5618081092834473
INFO:root:current mean train loss 3223.1995641907647
INFO:root:current train perplexity3.567378044128418
INFO:root:current mean train loss 3227.7020187904095
INFO:root:current train perplexity3.5677480697631836
INFO:root:current mean train loss 3222.8916522159757
INFO:root:current train perplexity3.5638298988342285
INFO:root:current mean train loss 3224.761782572589
INFO:root:current train perplexity3.5665600299835205
INFO:root:current mean train loss 3223.761479924001
INFO:root:current train perplexity3.5672249794006348
INFO:root:current mean train loss 3223.0472931090944
INFO:root:current train perplexity3.5650417804718018
INFO:root:current mean train loss 3223.976471632687
INFO:root:current train perplexity3.5655133724212646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.48s/it]
INFO:root:final mean train loss: 3223.1231389199534
INFO:root:final train perplexity: 3.5666093826293945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 4115.793412012411
INFO:root:eval perplexity: 5.282005786895752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [12:59:15<26:13, 224.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.3323264898254
INFO:root:current train perplexity3.582390546798706
INFO:root:current mean train loss 3227.437959257539
INFO:root:current train perplexity3.5822269916534424
INFO:root:current mean train loss 3226.0800118152006
INFO:root:current train perplexity3.570723533630371
INFO:root:current mean train loss 3221.880155424335
INFO:root:current train perplexity3.571047067642212
INFO:root:current mean train loss 3225.8159289909
INFO:root:current train perplexity3.5678532123565674
INFO:root:current mean train loss 3225.5695378143705
INFO:root:current train perplexity3.5655908584594727
INFO:root:current mean train loss 3223.9172875862655
INFO:root:current train perplexity3.564863920211792
INFO:root:current mean train loss 3223.076060483786
INFO:root:current train perplexity3.5633280277252197
INFO:root:current mean train loss 3225.4703237368403
INFO:root:current train perplexity3.564340591430664
INFO:root:current mean train loss 3225.0911382389977
INFO:root:current train perplexity3.5638577938079834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.17s/it]
INFO:root:final mean train loss: 3221.526184328141
INFO:root:final train perplexity: 3.5643625259399414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.24s/it]
INFO:root:eval mean loss: 4115.75371924867
INFO:root:eval perplexity: 5.28192138671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [13:03:04<22:35, 225.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.6108206954655
INFO:root:current train perplexity3.53078556060791
INFO:root:current mean train loss 3212.977880212645
INFO:root:current train perplexity3.5536563396453857
INFO:root:current mean train loss 3217.132402032495
INFO:root:current train perplexity3.562774181365967
INFO:root:current mean train loss 3217.139207454149
INFO:root:current train perplexity3.561948299407959
INFO:root:current mean train loss 3220.3916676049753
INFO:root:current train perplexity3.563359022140503
INFO:root:current mean train loss 3221.7154272948333
INFO:root:current train perplexity3.5647432804107666
INFO:root:current mean train loss 3224.1790597098216
INFO:root:current train perplexity3.5658862590789795
INFO:root:current mean train loss 3221.340837867219
INFO:root:current train perplexity3.563321352005005
INFO:root:current mean train loss 3222.269930883244
INFO:root:current train perplexity3.5638272762298584
INFO:root:current mean train loss 3223.154273256769
INFO:root:current train perplexity3.5643417835235596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it]
INFO:root:final mean train loss: 3220.732194777458
INFO:root:final train perplexity: 3.563246250152588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.60s/it]
INFO:root:eval mean loss: 4115.706709192154
INFO:root:eval perplexity: 5.281820774078369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [13:06:51<18:52, 226.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.1502623477227
INFO:root:current train perplexity3.572617769241333
INFO:root:current mean train loss 3231.8522196835693
INFO:root:current train perplexity3.5694148540496826
INFO:root:current mean train loss 3233.4388055396357
INFO:root:current train perplexity3.567319869995117
INFO:root:current mean train loss 3230.067993504091
INFO:root:current train perplexity3.5648231506347656
INFO:root:current mean train loss 3226.7367020484407
INFO:root:current train perplexity3.563816547393799
INFO:root:current mean train loss 3221.564198939233
INFO:root:current train perplexity3.5621886253356934
INFO:root:current mean train loss 3219.8135688098682
INFO:root:current train perplexity3.5616097450256348
INFO:root:current mean train loss 3220.882981050313
INFO:root:current train perplexity3.5625131130218506
INFO:root:current mean train loss 3222.668644328889
INFO:root:current train perplexity3.5621604919433594
INFO:root:current mean train loss 3222.4019947231004
INFO:root:current train perplexity3.562143087387085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.91s/it]
INFO:root:final mean train loss: 3219.8541481264174
INFO:root:final train perplexity: 3.5620124340057373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 4116.032969373337
INFO:root:eval perplexity: 5.282517910003662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [13:10:40<15:08, 227.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.544338852612
INFO:root:current train perplexity3.5763795375823975
INFO:root:current mean train loss 3228.802544325412
INFO:root:current train perplexity3.5738203525543213
INFO:root:current mean train loss 3229.7491231053955
INFO:root:current train perplexity3.568789005279541
INFO:root:current mean train loss 3228.059260313777
INFO:root:current train perplexity3.5652809143066406
INFO:root:current mean train loss 3229.227589249866
INFO:root:current train perplexity3.566850423812866
INFO:root:current mean train loss 3228.502738939181
INFO:root:current train perplexity3.5671310424804688
INFO:root:current mean train loss 3225.6835644677662
INFO:root:current train perplexity3.5655181407928467
INFO:root:current mean train loss 3225.9917090862327
INFO:root:current train perplexity3.5668232440948486
INFO:root:current mean train loss 3224.251571848868
INFO:root:current train perplexity3.5651533603668213
INFO:root:current mean train loss 3223.184916451897
INFO:root:current train perplexity3.5640175342559814


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it]
INFO:root:final mean train loss: 3220.7322765473396
INFO:root:final train perplexity: 3.563246250152588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it]
INFO:root:eval mean loss: 4116.086946960882
INFO:root:eval perplexity: 5.282632827758789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [13:14:29<11:23, 227.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.4844856770833
INFO:root:current train perplexity3.550806760787964
INFO:root:current mean train loss 3221.4198814174106
INFO:root:current train perplexity3.557539701461792
INFO:root:current mean train loss 3220.2653098366477
INFO:root:current train perplexity3.5607786178588867
INFO:root:current mean train loss 3216.3599498697918
INFO:root:current train perplexity3.5581812858581543
INFO:root:current mean train loss 3219.903174342105
INFO:root:current train perplexity3.557328939437866
INFO:root:current mean train loss 3220.8977653702445
INFO:root:current train perplexity3.556680202484131
INFO:root:current mean train loss 3222.8721480758104
INFO:root:current train perplexity3.559736728668213
INFO:root:current mean train loss 3220.9107078503025
INFO:root:current train perplexity3.559225082397461
INFO:root:current mean train loss 3222.9407525111606
INFO:root:current train perplexity3.5601868629455566
INFO:root:current mean train loss 3221.891334385016
INFO:root:current train perplexity3.5616209506988525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it]
INFO:root:final mean train loss: 3219.64663979315
INFO:root:final train perplexity: 3.561720609664917
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.66s/it]
INFO:root:eval mean loss: 4116.162855648825
INFO:root:eval perplexity: 5.282796382904053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [13:18:20<07:37, 228.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.1313417733436
INFO:root:current train perplexity3.5685465335845947
INFO:root:current mean train loss 3229.5892914318647
INFO:root:current train perplexity3.5683066844940186
INFO:root:current mean train loss 3230.476352004196
INFO:root:current train perplexity3.572561740875244
INFO:root:current mean train loss 3226.974031851746
INFO:root:current train perplexity3.5696539878845215
INFO:root:current mean train loss 3219.381126261646
INFO:root:current train perplexity3.566718101501465
INFO:root:current mean train loss 3223.522532965266
INFO:root:current train perplexity3.5702528953552246
INFO:root:current mean train loss 3223.499369809778
INFO:root:current train perplexity3.565430164337158
INFO:root:current mean train loss 3223.1203008386215
INFO:root:current train perplexity3.5628769397735596
INFO:root:current mean train loss 3223.030741534984
INFO:root:current train perplexity3.5608601570129395
INFO:root:current mean train loss 3222.815996948118
INFO:root:current train perplexity3.56203031539917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.40s/it]
INFO:root:final mean train loss: 3219.670954365884
INFO:root:final train perplexity: 3.5617547035217285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.46s/it]
INFO:root:eval mean loss: 4116.290281471631
INFO:root:eval perplexity: 5.2830681800842285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [13:22:11<03:49, 229.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.2347881610576
INFO:root:current train perplexity3.5606563091278076
INFO:root:current mean train loss 3214.598121523233
INFO:root:current train perplexity3.5515048503875732
INFO:root:current mean train loss 3215.1149533196412
INFO:root:current train perplexity3.5581274032592773
INFO:root:current mean train loss 3219.4305972516386
INFO:root:current train perplexity3.559685707092285
INFO:root:current mean train loss 3222.204312885852
INFO:root:current train perplexity3.5626137256622314
INFO:root:current mean train loss 3221.7961239887372
INFO:root:current train perplexity3.564927339553833
INFO:root:current mean train loss 3220.4719630460836
INFO:root:current train perplexity3.562831163406372
INFO:root:current mean train loss 3221.864580349735
INFO:root:current train perplexity3.5622341632843018
INFO:root:current mean train loss 3223.382072405917
INFO:root:current train perplexity3.5637502670288086
INFO:root:current mean train loss 3222.9407467500473
INFO:root:current train perplexity3.5627601146698


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.76s/it]
INFO:root:final mean train loss: 3220.361266166933
INFO:root:final train perplexity: 3.562725067138672
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.69s/it]
INFO:root:eval mean loss: 4116.334690824468
INFO:root:eval perplexity: 5.283162593841553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_180/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:25:57<00:00, 228.40s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:25:57<00:00, 241.79s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
INFO:root:eval mean loss: 4116.334690824468
INFO:root:eval perplexity: 5.283162593841553
INFO:root:evalaution complete
INFO:root:save model final: small_val_180/final
