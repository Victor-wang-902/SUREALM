Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [00:00<00:00, 849kB/s]
INFO:root:in update config, concat_self: False
INFO:root:Output: distilbert_distilroberta_not_concat
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 9.71MB/s]
Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]Downloading:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 381k/456k [00:00<00:00, 3.68MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 4.08MB/s]
Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.05M/1.36M [00:00<00:00, 10.5MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.36M/1.36M [00:00<00:00, 11.2MB/s]
Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]Downloading:   2%|â–         | 7.29M/331M [00:00<00:04, 72.9MB/s]Downloading:   4%|â–         | 14.6M/331M [00:00<00:05, 62.7MB/s]Downloading:   7%|â–‹         | 23.4M/331M [00:00<00:04, 73.3MB/s]Downloading:   9%|â–‰         | 30.9M/331M [00:00<00:04, 65.8MB/s]Downloading:  11%|â–ˆâ–        | 37.6M/331M [00:00<00:04, 61.4MB/s]Downloading:  13%|â–ˆâ–Ž        | 43.9M/331M [00:00<00:04, 60.4MB/s]Downloading:  15%|â–ˆâ–Œ        | 50.3M/331M [00:00<00:05, 51.5MB/s]Downloading:  18%|â–ˆâ–Š        | 58.0M/331M [00:00<00:04, 58.0MB/s]Downloading:  19%|â–ˆâ–‰        | 64.1M/331M [00:01<00:05, 51.7MB/s]Downloading:  21%|â–ˆâ–ˆ        | 69.5M/331M [00:01<00:05, 49.1MB/s]Downloading:  23%|â–ˆâ–ˆâ–Ž       | 75.5M/331M [00:01<00:06, 41.2MB/s]Downloading:  25%|â–ˆâ–ˆâ–Œ       | 83.9M/331M [00:01<00:05, 48.2MB/s]Downloading:  27%|â–ˆâ–ˆâ–‹       | 90.5M/331M [00:01<00:05, 47.3MB/s]Downloading:  29%|â–ˆâ–ˆâ–‰       | 95.5M/331M [00:01<00:05, 46.2MB/s]Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 100M/331M [00:01<00:05, 45.7MB/s] Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 105M/331M [00:02<00:06, 33.8MB/s]Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 109M/331M [00:02<00:06, 34.3MB/s]Downloading:  35%|â–ˆâ–ˆâ–ˆâ–      | 116M/331M [00:02<00:05, 40.2MB/s]Downloading:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 120M/331M [00:02<00:05, 38.9MB/s]Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 126M/331M [00:02<00:05, 34.9MB/s]Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 134M/331M [00:02<00:04, 41.1MB/s]Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 143M/331M [00:03<00:04, 43.4MB/s]Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 151M/331M [00:03<00:03, 49.6MB/s]Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 159M/331M [00:03<00:03, 47.3MB/s]Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 168M/331M [00:03<00:03, 47.9MB/s]Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 176M/331M [00:03<00:03, 48.8MB/s]Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 185M/331M [00:03<00:03, 47.3MB/s]Downloading:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 189M/331M [00:04<00:04, 31.3MB/s]Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 196M/331M [00:04<00:03, 36.8MB/s]Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 202M/331M [00:04<00:03, 40.5MB/s]Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 210M/331M [00:04<00:02, 43.2MB/s]Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 218M/331M [00:04<00:02, 48.7MB/s]Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 226M/331M [00:04<00:01, 55.4MB/s]Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 235M/331M [00:04<00:01, 62.6MB/s]Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 241M/331M [00:05<00:01, 58.9MB/s]Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 248M/331M [00:05<00:01, 60.0MB/s]Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 254M/331M [00:05<00:01, 61.1MB/s]Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 261M/331M [00:05<00:01, 60.2MB/s]Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 268M/331M [00:05<00:00, 63.3MB/s]Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 277M/331M [00:05<00:00, 70.6MB/s]Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 285M/331M [00:05<00:00, 66.9MB/s]Downloading:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 294M/331M [00:05<00:00, 63.6MB/s]Downloading:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 300M/331M [00:06<00:00, 59.8MB/s]Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 306M/331M [00:06<00:00, 45.6MB/s]Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 311M/331M [00:06<00:00, 41.8MB/s]Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 317M/331M [00:06<00:00, 44.2MB/s]Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 322M/331M [00:06<00:00, 42.6MB/s]Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 327M/331M [00:06<00:00, 44.4MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 331M/331M [00:06<00:00, 48.7MB/s]
/scratch/zw2374/public/faiss_db/models_roberta.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModelRoberta were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models_roberta.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10358.23393604009
INFO:root:current train perplexity3555.0302734375
INFO:root:current mean train loss 9236.062487731628
INFO:root:current train perplexity1459.0203857421875
INFO:root:current mean train loss 8624.975793334552
INFO:root:current train perplexity904.1583251953125
INFO:root:current mean train loss 8174.564610990366
INFO:root:current train perplexity637.09130859375
INFO:root:current mean train loss 7804.4947707915835
INFO:root:current train perplexity478.76177978515625
INFO:root:current mean train loss 7484.641739324656
INFO:root:current train perplexity368.8719177246094
INFO:root:current mean train loss 7181.525572944608
INFO:root:current train perplexity289.75146484375
INFO:root:current mean train loss 6908.068930767952
INFO:root:current train perplexity233.9660186767578
INFO:root:current mean train loss 6669.09959416713
INFO:root:current train perplexity193.5360565185547
INFO:root:current mean train loss 6456.038735512857
INFO:root:current train perplexity163.9796600341797
INFO:root:current mean train loss 6269.303606527951
INFO:root:current train perplexity141.1393280029297
INFO:root:current mean train loss 6098.063986834732
INFO:root:current train perplexity123.36176300048828
INFO:root:current mean train loss 5943.307199009755
INFO:root:current train perplexity109.10865020751953
INFO:root:current mean train loss 5806.772008779988
INFO:root:current train perplexity97.75447082519531
INFO:root:current mean train loss 5680.492547766219
INFO:root:current train perplexity88.32682037353516
INFO:root:current mean train loss 5564.94586338141
INFO:root:current train perplexity80.61641693115234
INFO:root:current mean train loss 5457.7291032006415
INFO:root:current train perplexity74.07930755615234
INFO:root:current mean train loss 5357.813047586115
INFO:root:current train perplexity68.50542449951172
INFO:root:current mean train loss 5264.687750954449
INFO:root:current train perplexity63.663700103759766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:13<00:00, 793.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:13<00:00, 793.87s/it]
INFO:root:final mean train loss: 5191.888830018536
INFO:root:final train perplexity: 60.18522644042969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.07s/it]
INFO:root:eval mean loss: 3157.691860767121
INFO:root:eval perplexity: 12.874528884887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.62s/it]
INFO:root:eval mean loss: 3421.2232051335327
INFO:root:eval perplexity: 16.65458869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/1
  0%|          | 1/200 [15:10<50:19:14, 910.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3536.6146392822266
INFO:root:current train perplexity16.100584030151367
INFO:root:current mean train loss 3480.9042695144126
INFO:root:current train perplexity15.654029846191406
INFO:root:current mean train loss 3446.1973571777344
INFO:root:current train perplexity15.257856369018555
INFO:root:current mean train loss 3422.6154646088808
INFO:root:current train perplexity14.9641695022583
INFO:root:current mean train loss 3417.5883172842173
INFO:root:current train perplexity14.818814277648926
INFO:root:current mean train loss 3393.981931228046
INFO:root:current train perplexity14.578822135925293
INFO:root:current mean train loss 3377.4000747482496
INFO:root:current train perplexity14.38023853302002
INFO:root:current mean train loss 3360.704556427854
INFO:root:current train perplexity14.20177936553955
INFO:root:current mean train loss 3344.90256096335
INFO:root:current train perplexity14.013595581054688
INFO:root:current mean train loss 3330.7042636121723
INFO:root:current train perplexity13.848001480102539
INFO:root:current mean train loss 3316.588072769285
INFO:root:current train perplexity13.682693481445312
INFO:root:current mean train loss 3301.320735808342
INFO:root:current train perplexity13.527129173278809
INFO:root:current mean train loss 3285.6070070768656
INFO:root:current train perplexity13.362229347229004
INFO:root:current mean train loss 3270.6036098677337
INFO:root:current train perplexity13.213918685913086
INFO:root:current mean train loss 3256.628193138683
INFO:root:current train perplexity13.059024810791016
INFO:root:current mean train loss 3243.036994551606
INFO:root:current train perplexity12.913623809814453
INFO:root:current mean train loss 3226.6635787510636
INFO:root:current train perplexity12.75910758972168
INFO:root:current mean train loss 3212.484076653327
INFO:root:current train perplexity12.617571830749512
INFO:root:current mean train loss 3199.4865410758534
INFO:root:current train perplexity12.49244499206543
INFO:root:current mean train loss 3186.076681053464
INFO:root:current train perplexity12.363004684448242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.05s/it]
INFO:root:final mean train loss: 3178.7028612222443
INFO:root:final train perplexity: 12.288028717041016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.40s/it]
INFO:root:eval mean loss: 2662.820982155225
INFO:root:eval perplexity: 8.626112937927246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.54s/it]
INFO:root:eval mean loss: 2974.0125598231107
INFO:root:eval perplexity: 11.530790328979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/2
  1%|          | 2/200 [30:05<49:35:31, 901.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2915.778801195549
INFO:root:current train perplexity10.020491600036621
INFO:root:current mean train loss 2915.21005271969
INFO:root:current train perplexity10.0140962600708
INFO:root:current mean train loss 2892.0167985515022
INFO:root:current train perplexity9.879491806030273
INFO:root:current mean train loss 2896.3968208931587
INFO:root:current train perplexity9.882627487182617
INFO:root:current mean train loss 2888.65949430752
INFO:root:current train perplexity9.793320655822754
INFO:root:current mean train loss 2882.3794018600493
INFO:root:current train perplexity9.734325408935547
INFO:root:current mean train loss 2874.9864002486916
INFO:root:current train perplexity9.676804542541504
INFO:root:current mean train loss 2869.712776048772
INFO:root:current train perplexity9.626717567443848
INFO:root:current mean train loss 2860.1101000947256
INFO:root:current train perplexity9.570101737976074
INFO:root:current mean train loss 2852.5866128772273
INFO:root:current train perplexity9.519645690917969
INFO:root:current mean train loss 2847.3042798111537
INFO:root:current train perplexity9.47433090209961
INFO:root:current mean train loss 2838.047627892625
INFO:root:current train perplexity9.410416603088379
INFO:root:current mean train loss 2834.853881142919
INFO:root:current train perplexity9.37527084350586
INFO:root:current mean train loss 2829.591726178615
INFO:root:current train perplexity9.336709976196289
INFO:root:current mean train loss 2824.1679861277694
INFO:root:current train perplexity9.297830581665039
INFO:root:current mean train loss 2819.974548538915
INFO:root:current train perplexity9.26248550415039
INFO:root:current mean train loss 2813.8343805615623
INFO:root:current train perplexity9.222545623779297
INFO:root:current mean train loss 2809.000462359799
INFO:root:current train perplexity9.178268432617188
INFO:root:current mean train loss 2805.8351808372117
INFO:root:current train perplexity9.14671802520752
INFO:root:current mean train loss 2800.1473917243275
INFO:root:current train perplexity9.104042053222656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.07s/it]
INFO:root:final mean train loss: 2795.852396123889
INFO:root:final train perplexity: 9.08369255065918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.80s/it]
INFO:root:eval mean loss: 2456.982365601452
INFO:root:eval perplexity: 7.3025689125061035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.93s/it]
INFO:root:eval mean loss: 2789.4491178904864
INFO:root:eval perplexity: 9.907441139221191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/3
  2%|â–         | 3/200 [44:53<48:58:56, 895.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2643.4235986328126
INFO:root:current train perplexity8.140542984008789
INFO:root:current mean train loss 2659.071953125
INFO:root:current train perplexity8.197681427001953
INFO:root:current mean train loss 2663.389798828125
INFO:root:current train perplexity8.189229965209961
INFO:root:current mean train loss 2663.05822265625
INFO:root:current train perplexity8.156986236572266
INFO:root:current mean train loss 2655.0303255208332
INFO:root:current train perplexity8.120903015136719
INFO:root:current mean train loss 2650.3832253196024
INFO:root:current train perplexity8.104640007019043
INFO:root:current mean train loss 2645.6042677659257
INFO:root:current train perplexity8.071784973144531
INFO:root:current mean train loss 2644.959123860677
INFO:root:current train perplexity8.054780960083008
INFO:root:current mean train loss 2637.9377454331343
INFO:root:current train perplexity8.025147438049316
INFO:root:current mean train loss 2636.4838701428866
INFO:root:current train perplexity8.004443168640137
INFO:root:current mean train loss 2632.590680687314
INFO:root:current train perplexity7.976376056671143
INFO:root:current mean train loss 2629.6898888629416
INFO:root:current train perplexity7.9614577293396
INFO:root:current mean train loss 2624.6183729492186
INFO:root:current train perplexity7.947007179260254
INFO:root:current mean train loss 2624.138516619647
INFO:root:current train perplexity7.922051429748535
INFO:root:current mean train loss 2620.808842689251
INFO:root:current train perplexity7.901712894439697
INFO:root:current mean train loss 2616.5451867282004
INFO:root:current train perplexity7.878711700439453
INFO:root:current mean train loss 2612.700008951823
INFO:root:current train perplexity7.856894016265869
INFO:root:current mean train loss 2608.8120239257814
INFO:root:current train perplexity7.834266185760498
INFO:root:current mean train loss 2604.972230587521
INFO:root:current train perplexity7.812532424926758
INFO:root:current mean train loss 2602.176163549179
INFO:root:current train perplexity7.792881965637207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.19s/it]
INFO:root:final mean train loss: 2600.622502144695
INFO:root:final train perplexity: 7.786610126495361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.68s/it]
INFO:root:eval mean loss: 2325.9643048225566
INFO:root:eval perplexity: 6.567967414855957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it]
INFO:root:eval mean loss: 2665.0874629460327
INFO:root:eval perplexity: 8.94455337524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/4
  2%|â–         | 4/200 [59:38<48:31:07, 891.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2471.544892723881
INFO:root:current train perplexity7.281893253326416
INFO:root:current mean train loss 2498.5763560769087
INFO:root:current train perplexity7.259078025817871
INFO:root:current mean train loss 2498.1936794095272
INFO:root:current train perplexity7.2553935050964355
INFO:root:current mean train loss 2501.962715003406
INFO:root:current train perplexity7.240413188934326
INFO:root:current mean train loss 2503.175745439223
INFO:root:current train perplexity7.235304355621338
INFO:root:current mean train loss 2499.15306992842
INFO:root:current train perplexity7.197692394256592
INFO:root:current mean train loss 2498.370649575115
INFO:root:current train perplexity7.18783712387085
INFO:root:current mean train loss 2492.7698245688866
INFO:root:current train perplexity7.157736301422119
INFO:root:current mean train loss 2491.3184862323837
INFO:root:current train perplexity7.143441200256348
INFO:root:current mean train loss 2490.0066352220947
INFO:root:current train perplexity7.131093978881836
INFO:root:current mean train loss 2487.094068275173
INFO:root:current train perplexity7.111870288848877
INFO:root:current mean train loss 2483.229137168956
INFO:root:current train perplexity7.099447727203369
INFO:root:current mean train loss 2484.3703299193467
INFO:root:current train perplexity7.096416473388672
INFO:root:current mean train loss 2480.791027055139
INFO:root:current train perplexity7.079177379608154
INFO:root:current mean train loss 2477.961359046151
INFO:root:current train perplexity7.061763763427734
INFO:root:current mean train loss 2474.984065500733
INFO:root:current train perplexity7.0474395751953125
INFO:root:current mean train loss 2473.992711735973
INFO:root:current train perplexity7.033594608306885
INFO:root:current mean train loss 2471.791240076865
INFO:root:current train perplexity7.02493953704834
INFO:root:current mean train loss 2469.456088359814
INFO:root:current train perplexity7.014374732971191
INFO:root:current mean train loss 2466.4708788144026
INFO:root:current train perplexity7.000331878662109

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.33s/it]
INFO:root:final mean train loss: 2465.6801606994413
INFO:root:final train perplexity: 6.999993801116943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.91s/it]
INFO:root:eval mean loss: 2240.879371156084
INFO:root:eval perplexity: 6.130967617034912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.24s/it]
INFO:root:eval mean loss: 2589.6308433586823
INFO:root:eval perplexity: 8.406538009643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/5
  2%|â–Ž         | 5/200 [1:14:19<48:04:28, 887.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2376.160660516648
INFO:root:current train perplexity6.497133255004883
INFO:root:current mean train loss 2384.049022508704
INFO:root:current train perplexity6.566810131072998
INFO:root:current mean train loss 2386.2574828241914
INFO:root:current train perplexity6.5669732093811035
INFO:root:current mean train loss 2385.2924105326333
INFO:root:current train perplexity6.57198429107666
INFO:root:current mean train loss 2390.0633080852917
INFO:root:current train perplexity6.591903209686279
INFO:root:current mean train loss 2396.707229614258
INFO:root:current train perplexity6.609903335571289
INFO:root:current mean train loss 2395.1639588116204
INFO:root:current train perplexity6.601195812225342
INFO:root:current mean train loss 2392.811544768664
INFO:root:current train perplexity6.5826826095581055
INFO:root:current mean train loss 2391.6452113363
INFO:root:current train perplexity6.578704357147217
INFO:root:current mean train loss 2389.8623791206173
INFO:root:current train perplexity6.569987773895264
INFO:root:current mean train loss 2386.387113113685
INFO:root:current train perplexity6.556018352508545
INFO:root:current mean train loss 2382.644172565357
INFO:root:current train perplexity6.5427350997924805
INFO:root:current mean train loss 2379.6203994513303
INFO:root:current train perplexity6.526729583740234
INFO:root:current mean train loss 2376.270486908841
INFO:root:current train perplexity6.516600131988525
INFO:root:current mean train loss 2373.5012805866745
INFO:root:current train perplexity6.501781940460205
INFO:root:current mean train loss 2371.0776015772963
INFO:root:current train perplexity6.492142677307129
INFO:root:current mean train loss 2369.9816938024237
INFO:root:current train perplexity6.489739894866943
INFO:root:current mean train loss 2370.0668850201664
INFO:root:current train perplexity6.486774444580078
INFO:root:current mean train loss 2368.2169170015177
INFO:root:current train perplexity6.478395938873291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.94s/it]
INFO:root:final mean train loss: 2366.398180986136
INFO:root:final train perplexity: 6.47245979309082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it]
INFO:root:eval mean loss: 2169.8012197508033
INFO:root:eval perplexity: 5.788279056549072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.10s/it]
INFO:root:eval mean loss: 2530.7939877340978
INFO:root:eval perplexity: 8.009576797485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/6
  3%|â–Ž         | 6/200 [1:28:57<47:39:45, 884.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2170.812744140625
INFO:root:current train perplexity5.960818767547607
INFO:root:current mean train loss 2334.2982455716274
INFO:root:current train perplexity6.29235315322876
INFO:root:current mean train loss 2329.5622953348493
INFO:root:current train perplexity6.290732383728027
INFO:root:current mean train loss 2327.7704129139847
INFO:root:current train perplexity6.264395713806152
INFO:root:current mean train loss 2321.3716395656365
INFO:root:current train perplexity6.239636421203613
INFO:root:current mean train loss 2319.648304221635
INFO:root:current train perplexity6.224440097808838
INFO:root:current mean train loss 2314.3938378256294
INFO:root:current train perplexity6.205571174621582
INFO:root:current mean train loss 2314.6671661507557
INFO:root:current train perplexity6.2039642333984375
INFO:root:current mean train loss 2313.326265904192
INFO:root:current train perplexity6.196362018585205
INFO:root:current mean train loss 2310.5832409789905
INFO:root:current train perplexity6.181947231292725
INFO:root:current mean train loss 2308.8262960184347
INFO:root:current train perplexity6.174145221710205
INFO:root:current mean train loss 2307.1437945041084
INFO:root:current train perplexity6.168145179748535
INFO:root:current mean train loss 2307.4673386191844
INFO:root:current train perplexity6.165998458862305
INFO:root:current mean train loss 2304.6752420201105
INFO:root:current train perplexity6.1521782875061035
INFO:root:current mean train loss 2303.5311518906697
INFO:root:current train perplexity6.149943828582764
INFO:root:current mean train loss 2302.499167221852
INFO:root:current train perplexity6.147459983825684
INFO:root:current mean train loss 2300.0428453835007
INFO:root:current train perplexity6.13364315032959
INFO:root:current mean train loss 2298.1240770450977
INFO:root:current train perplexity6.125438690185547
INFO:root:current mean train loss 2297.172925780708
INFO:root:current train perplexity6.120386600494385
INFO:root:current mean train loss 2294.523242739738
INFO:root:current train perplexity6.112890720367432

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.50s/it]
INFO:root:final mean train loss: 2292.3699839751166
INFO:root:final train perplexity: 6.105153560638428
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.96s/it]
INFO:root:eval mean loss: 2121.709508151873
INFO:root:eval perplexity: 5.567347526550293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.61s/it]
INFO:root:eval mean loss: 2484.3834765278702
INFO:root:eval perplexity: 7.709729194641113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/7
  4%|â–Ž         | 7/200 [1:43:42<47:25:01, 884.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.9327799479165
INFO:root:current train perplexity5.844352722167969
INFO:root:current mean train loss 2277.305255437301
INFO:root:current train perplexity5.961245059967041
INFO:root:current mean train loss 2270.0413040021144
INFO:root:current train perplexity5.953084945678711
INFO:root:current mean train loss 2264.2118683821
INFO:root:current train perplexity5.92527437210083
INFO:root:current mean train loss 2256.7168739720396
INFO:root:current train perplexity5.905506610870361
INFO:root:current mean train loss 2253.768482812123
INFO:root:current train perplexity5.900448322296143
INFO:root:current mean train loss 2251.5247172630334
INFO:root:current train perplexity5.89619779586792
INFO:root:current mean train loss 2246.197324279955
INFO:root:current train perplexity5.8809685707092285
INFO:root:current mean train loss 2248.3843124128493
INFO:root:current train perplexity5.8788933753967285
INFO:root:current mean train loss 2244.2395842641527
INFO:root:current train perplexity5.861571311950684
INFO:root:current mean train loss 2243.277460784013
INFO:root:current train perplexity5.861120700836182
INFO:root:current mean train loss 2240.0452659211132
INFO:root:current train perplexity5.84895658493042
INFO:root:current mean train loss 2238.347591807298
INFO:root:current train perplexity5.840484619140625
INFO:root:current mean train loss 2237.6493086633986
INFO:root:current train perplexity5.840178489685059
INFO:root:current mean train loss 2236.217175654531
INFO:root:current train perplexity5.8338212966918945
INFO:root:current mean train loss 2235.8527488658237
INFO:root:current train perplexity5.835573196411133
INFO:root:current mean train loss 2234.1208280320516
INFO:root:current train perplexity5.829926013946533
INFO:root:current mean train loss 2232.5391314221206
INFO:root:current train perplexity5.824832439422607
INFO:root:current mean train loss 2233.8494410415165
INFO:root:current train perplexity5.8269548416137695
INFO:root:current mean train loss 2233.0271991495047
INFO:root:current train perplexity5.821650981903076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.96s/it]
INFO:root:final mean train loss: 2231.487121181902
INFO:root:final train perplexity: 5.818746089935303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it]
INFO:root:eval mean loss: 2077.0237582592254
INFO:root:eval perplexity: 5.369624614715576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.90s/it]
INFO:root:eval mean loss: 2447.5753628345246
INFO:root:eval perplexity: 7.47991943359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/8
  4%|â–         | 8/200 [1:58:18<47:01:38, 881.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2197.804471261161
INFO:root:current train perplexity5.644223213195801
INFO:root:current mean train loss 2209.247605613426
INFO:root:current train perplexity5.673631191253662
INFO:root:current mean train loss 2200.247209005153
INFO:root:current train perplexity5.6642842292785645
INFO:root:current mean train loss 2205.0963579320196
INFO:root:current train perplexity5.673595905303955
INFO:root:current mean train loss 2205.161532417385
INFO:root:current train perplexity5.666849613189697
INFO:root:current mean train loss 2200.7036899459695
INFO:root:current train perplexity5.663355827331543
INFO:root:current mean train loss 2199.95449161079
INFO:root:current train perplexity5.6641387939453125
INFO:root:current mean train loss 2200.111646006059
INFO:root:current train perplexity5.668418884277344
INFO:root:current mean train loss 2192.7929816148953
INFO:root:current train perplexity5.64892053604126
INFO:root:current mean train loss 2193.563788331384
INFO:root:current train perplexity5.650291919708252
INFO:root:current mean train loss 2194.0145076143567
INFO:root:current train perplexity5.64598274230957
INFO:root:current mean train loss 2192.667129637596
INFO:root:current train perplexity5.6382737159729
INFO:root:current mean train loss 2192.452401671622
INFO:root:current train perplexity5.634446144104004
INFO:root:current mean train loss 2188.223959887787
INFO:root:current train perplexity5.624066352844238
INFO:root:current mean train loss 2187.733244637413
INFO:root:current train perplexity5.621108055114746
INFO:root:current mean train loss 2187.2834200682005
INFO:root:current train perplexity5.615055561065674
INFO:root:current mean train loss 2185.3386243907685
INFO:root:current train perplexity5.607174396514893
INFO:root:current mean train loss 2183.8000307462403
INFO:root:current train perplexity5.6015191078186035
INFO:root:current mean train loss 2182.5350030467685
INFO:root:current train perplexity5.596512794494629
INFO:root:current mean train loss 2181.8814226017444
INFO:root:current train perplexity5.590630531311035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.25s/it]
INFO:root:final mean train loss: 2180.493521501365
INFO:root:final train perplexity: 5.5892252922058105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.78s/it]
INFO:root:eval mean loss: 2042.0964610864085
INFO:root:eval perplexity: 5.2199859619140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.16s/it]
INFO:root:eval mean loss: 2416.4666730731938
INFO:root:eval perplexity: 7.291043281555176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/9
  4%|â–         | 9/200 [2:12:58<46:44:54, 881.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2160.5316279484678
INFO:root:current train perplexity5.460024356842041
INFO:root:current mean train loss 2160.75077578896
INFO:root:current train perplexity5.450003623962402
INFO:root:current mean train loss 2150.780767047216
INFO:root:current train perplexity5.438289642333984
INFO:root:current mean train loss 2147.787871274081
INFO:root:current train perplexity5.443631649017334
INFO:root:current mean train loss 2148.1013753435254
INFO:root:current train perplexity5.431110382080078
INFO:root:current mean train loss 2146.2537897082343
INFO:root:current train perplexity5.424501895904541
INFO:root:current mean train loss 2144.1048158984972
INFO:root:current train perplexity5.424757480621338
INFO:root:current mean train loss 2143.928577991242
INFO:root:current train perplexity5.427826881408691
INFO:root:current mean train loss 2143.975482206389
INFO:root:current train perplexity5.424095153808594
INFO:root:current mean train loss 2142.562545776367
INFO:root:current train perplexity5.420517921447754
INFO:root:current mean train loss 2142.8326751360873
INFO:root:current train perplexity5.419450759887695
INFO:root:current mean train loss 2140.772845692105
INFO:root:current train perplexity5.410518646240234
INFO:root:current mean train loss 2142.9681752360284
INFO:root:current train perplexity5.413998603820801
INFO:root:current mean train loss 2142.7742054956198
INFO:root:current train perplexity5.415111064910889
INFO:root:current mean train loss 2140.2220262259493
INFO:root:current train perplexity5.41246223449707
INFO:root:current mean train loss 2141.0346806319717
INFO:root:current train perplexity5.413245677947998
INFO:root:current mean train loss 2139.773102176103
INFO:root:current train perplexity5.4099884033203125
INFO:root:current mean train loss 2138.2554630645336
INFO:root:current train perplexity5.403075695037842
INFO:root:current mean train loss 2138.0953437030703
INFO:root:current train perplexity5.402608394622803
INFO:root:current mean train loss 2138.28908119827
INFO:root:current train perplexity5.4017229080200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.73s/it]
INFO:root:final mean train loss: 2137.146677576047
INFO:root:final train perplexity: 5.401255130767822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.47s/it]
INFO:root:eval mean loss: 2014.9808630977116
INFO:root:eval perplexity: 5.106693744659424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it]
INFO:root:eval mean loss: 2391.88785720717
INFO:root:eval perplexity: 7.145191669464111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/10
  5%|â–Œ         | 10/200 [2:27:36<46:27:19, 880.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2080.069381935009
INFO:root:current train perplexity5.297450065612793
INFO:root:current mean train loss 2092.5112095217733
INFO:root:current train perplexity5.255861759185791
INFO:root:current mean train loss 2098.862409059886
INFO:root:current train perplexity5.264652729034424
INFO:root:current mean train loss 2096.4692786405403
INFO:root:current train perplexity5.25688362121582
INFO:root:current mean train loss 2097.5955602324593
INFO:root:current train perplexity5.259147644042969
INFO:root:current mean train loss 2095.276429188063
INFO:root:current train perplexity5.245532035827637
INFO:root:current mean train loss 2094.0589287591088
INFO:root:current train perplexity5.230949401855469
INFO:root:current mean train loss 2094.559383476664
INFO:root:current train perplexity5.217650413513184
INFO:root:current mean train loss 2095.703370545347
INFO:root:current train perplexity5.230268478393555
INFO:root:current mean train loss 2099.7818464942516
INFO:root:current train perplexity5.240255832672119
INFO:root:current mean train loss 2098.7494511974537
INFO:root:current train perplexity5.235319137573242
INFO:root:current mean train loss 2098.5157818431217
INFO:root:current train perplexity5.234996318817139
INFO:root:current mean train loss 2095.7900064527003
INFO:root:current train perplexity5.232699394226074
INFO:root:current mean train loss 2095.187611548547
INFO:root:current train perplexity5.23362922668457
INFO:root:current mean train loss 2095.3259607241057
INFO:root:current train perplexity5.237181663513184
INFO:root:current mean train loss 2096.8793382030753
INFO:root:current train perplexity5.240814685821533
INFO:root:current mean train loss 2096.9072541362016
INFO:root:current train perplexity5.238990306854248
INFO:root:current mean train loss 2098.481107393721
INFO:root:current train perplexity5.241221904754639
INFO:root:current mean train loss 2097.911800247772
INFO:root:current train perplexity5.235920429229736
INFO:root:current mean train loss 2099.6029050254533
INFO:root:current train perplexity5.241942405700684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.81s/it]
INFO:root:final mean train loss: 2099.1957634152996
INFO:root:final train perplexity: 5.241882801055908
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.79s/it]
INFO:root:eval mean loss: 1991.5458573145224
INFO:root:eval perplexity: 5.010763168334961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.32s/it]
INFO:root:eval mean loss: 2371.725959507286
INFO:root:eval perplexity: 7.027731895446777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/11
  6%|â–Œ         | 11/200 [2:42:08<46:05:04, 877.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2073.181413517442
INFO:root:current train perplexity5.1149749755859375
INFO:root:current mean train loss 2083.3480309927336
INFO:root:current train perplexity5.138703346252441
INFO:root:current mean train loss 2084.7129021491205
INFO:root:current train perplexity5.150304317474365
INFO:root:current mean train loss 2078.5724095161713
INFO:root:current train perplexity5.150249481201172
INFO:root:current mean train loss 2080.8735258628312
INFO:root:current train perplexity5.139743328094482
INFO:root:current mean train loss 2078.3198969193286
INFO:root:current train perplexity5.134374618530273
INFO:root:current mean train loss 2077.7381104227406
INFO:root:current train perplexity5.136940002441406
INFO:root:current mean train loss 2075.758004923813
INFO:root:current train perplexity5.136776447296143
INFO:root:current mean train loss 2074.0380862130537
INFO:root:current train perplexity5.13666296005249
INFO:root:current mean train loss 2071.7033381897345
INFO:root:current train perplexity5.132503986358643
INFO:root:current mean train loss 2070.430121715117
INFO:root:current train perplexity5.124783039093018
INFO:root:current mean train loss 2068.485423404893
INFO:root:current train perplexity5.119049072265625
INFO:root:current mean train loss 2069.2213050284618
INFO:root:current train perplexity5.115147113800049
INFO:root:current mean train loss 2067.6622484435593
INFO:root:current train perplexity5.114470958709717
INFO:root:current mean train loss 2066.234366538868
INFO:root:current train perplexity5.10773229598999
INFO:root:current mean train loss 2065.692333630325
INFO:root:current train perplexity5.10562801361084
INFO:root:current mean train loss 2064.8012594673273
INFO:root:current train perplexity5.104767799377441
INFO:root:current mean train loss 2064.96060074724
INFO:root:current train perplexity5.102509498596191
INFO:root:current mean train loss 2065.442930122448
INFO:root:current train perplexity5.103928089141846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.04s/it]
INFO:root:final mean train loss: 2066.087183318953
INFO:root:final train perplexity: 5.106690883636475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.53s/it]
INFO:root:eval mean loss: 1963.0714622118794
INFO:root:eval perplexity: 4.896625995635986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.67s/it]
INFO:root:eval mean loss: 2345.130832103973
INFO:root:eval perplexity: 6.875740051269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/12
  6%|â–Œ         | 12/200 [2:56:47<45:51:18, 878.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.9761149088542
INFO:root:current train perplexity5.041319847106934
INFO:root:current mean train loss 2034.6555483919904
INFO:root:current train perplexity4.981344223022461
INFO:root:current mean train loss 2045.3624941069504
INFO:root:current train perplexity4.99036979675293
INFO:root:current mean train loss 2043.34050405773
INFO:root:current train perplexity4.990490913391113
INFO:root:current mean train loss 2046.399154473771
INFO:root:current train perplexity5.00182580947876
INFO:root:current mean train loss 2045.7690436968035
INFO:root:current train perplexity5.001224040985107
INFO:root:current mean train loss 2043.0238964276923
INFO:root:current train perplexity4.9980292320251465
INFO:root:current mean train loss 2042.5653156047185
INFO:root:current train perplexity4.995965957641602
INFO:root:current mean train loss 2038.8953640036386
INFO:root:current train perplexity4.994579792022705
INFO:root:current mean train loss 2037.3629518088576
INFO:root:current train perplexity4.989247798919678
INFO:root:current mean train loss 2038.2863963042514
INFO:root:current train perplexity4.991854190826416
INFO:root:current mean train loss 2040.0783602869305
INFO:root:current train perplexity4.998594760894775
INFO:root:current mean train loss 2039.111944666329
INFO:root:current train perplexity4.996701717376709
INFO:root:current mean train loss 2037.680131281328
INFO:root:current train perplexity4.993247985839844
INFO:root:current mean train loss 2035.3251279693625
INFO:root:current train perplexity4.985339164733887
INFO:root:current mean train loss 2036.2646301635011
INFO:root:current train perplexity4.985990047454834
INFO:root:current mean train loss 2036.216399822842
INFO:root:current train perplexity4.987651824951172
INFO:root:current mean train loss 2034.3155089651075
INFO:root:current train perplexity4.982165336608887
INFO:root:current mean train loss 2034.4745570398077
INFO:root:current train perplexity4.979959487915039
INFO:root:current mean train loss 2034.627031575863
INFO:root:current train perplexity4.980198383331299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.12s/it]
INFO:root:final mean train loss: 2033.9011035020822
INFO:root:final train perplexity: 4.978608131408691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.03s/it]
INFO:root:eval mean loss: 1946.1764695187833
INFO:root:eval perplexity: 4.830136299133301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.34s/it]
INFO:root:eval mean loss: 2329.984558971216
INFO:root:eval perplexity: 6.790652275085449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/13
  6%|â–‹         | 13/200 [3:11:30<45:41:20, 879.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2037.0395935058593
INFO:root:current train perplexity4.847031116485596
INFO:root:current mean train loss 2021.794751993815
INFO:root:current train perplexity4.885901927947998
INFO:root:current mean train loss 2010.4927085182883
INFO:root:current train perplexity4.8636884689331055
INFO:root:current mean train loss 2019.0731143951416
INFO:root:current train perplexity4.886744976043701
INFO:root:current mean train loss 2013.1846798851377
INFO:root:current train perplexity4.877931118011475
INFO:root:current mean train loss 2011.0718634972206
INFO:root:current train perplexity4.869419097900391
INFO:root:current mean train loss 2006.4544943532635
INFO:root:current train perplexity4.8572845458984375
INFO:root:current mean train loss 2007.4284362792969
INFO:root:current train perplexity4.861469268798828
INFO:root:current mean train loss 2007.9983443097371
INFO:root:current train perplexity4.871016025543213
INFO:root:current mean train loss 2006.8259671418564
INFO:root:current train perplexity4.869126796722412
INFO:root:current mean train loss 2007.6533442478553
INFO:root:current train perplexity4.870542526245117
INFO:root:current mean train loss 2010.2934350149972
INFO:root:current train perplexity4.878772735595703
INFO:root:current mean train loss 2012.3278964683657
INFO:root:current train perplexity4.886043071746826
INFO:root:current mean train loss 2012.1858721184008
INFO:root:current train perplexity4.886774063110352
INFO:root:current mean train loss 2011.6624521174901
INFO:root:current train perplexity4.884860992431641
INFO:root:current mean train loss 2010.345676863821
INFO:root:current train perplexity4.881219387054443
INFO:root:current mean train loss 2010.4058164243345
INFO:root:current train perplexity4.880497932434082
INFO:root:current mean train loss 2009.5116733994596
INFO:root:current train perplexity4.879804611206055
INFO:root:current mean train loss 2008.8369401533525
INFO:root:current train perplexity4.878208637237549
INFO:root:current mean train loss 2007.7856424967447
INFO:root:current train perplexity4.875365257263184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.59s/it]
INFO:root:final mean train loss: 2007.480093274523
INFO:root:final train perplexity: 4.875871658325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it]
INFO:root:eval mean loss: 1930.2450925137134
INFO:root:eval perplexity: 4.768266201019287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it]
INFO:root:eval mean loss: 2319.0505574544272
INFO:root:eval perplexity: 6.729884147644043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/14
  7%|â–‹         | 14/200 [3:26:11<45:28:31, 880.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.1443893845017
INFO:root:current train perplexity4.6972575187683105
INFO:root:current mean train loss 1987.0311929744526
INFO:root:current train perplexity4.7761688232421875
INFO:root:current mean train loss 1983.3189192502307
INFO:root:current train perplexity4.788820743560791
INFO:root:current mean train loss 1977.292507273507
INFO:root:current train perplexity4.773591995239258
INFO:root:current mean train loss 1977.1088576676916
INFO:root:current train perplexity4.7770490646362305
INFO:root:current mean train loss 1978.1447322000117
INFO:root:current train perplexity4.7786173820495605
INFO:root:current mean train loss 1980.619496679381
INFO:root:current train perplexity4.777965545654297
INFO:root:current mean train loss 1983.683029112693
INFO:root:current train perplexity4.7869744300842285
INFO:root:current mean train loss 1983.5054838301319
INFO:root:current train perplexity4.7812700271606445
INFO:root:current mean train loss 1986.2743335508105
INFO:root:current train perplexity4.786607265472412
INFO:root:current mean train loss 1986.4762826917715
INFO:root:current train perplexity4.787448883056641
INFO:root:current mean train loss 1986.1284189350058
INFO:root:current train perplexity4.784533500671387
INFO:root:current mean train loss 1985.9974249775794
INFO:root:current train perplexity4.786793231964111
INFO:root:current mean train loss 1986.5185026455567
INFO:root:current train perplexity4.788946151733398
INFO:root:current mean train loss 1986.1104372750576
INFO:root:current train perplexity4.789272785186768
INFO:root:current mean train loss 1986.015389675123
INFO:root:current train perplexity4.787838459014893
INFO:root:current mean train loss 1986.5673853478638
INFO:root:current train perplexity4.788523197174072
INFO:root:current mean train loss 1986.4247275941593
INFO:root:current train perplexity4.790177822113037
INFO:root:current mean train loss 1986.9850028946014
INFO:root:current train perplexity4.791569709777832
INFO:root:current mean train loss 1985.5540504278322
INFO:root:current train perplexity4.7885332107543945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.84s/it]
INFO:root:final mean train loss: 1984.2201519310624
INFO:root:final train perplexity: 4.7871832847595215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 58.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.04s/it]
INFO:root:eval mean loss: 1913.0109045150432
INFO:root:eval perplexity: 4.702228546142578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.19s/it]
INFO:root:eval mean loss: 2300.7864730510305
INFO:root:eval perplexity: 6.629586696624756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/15
  8%|â–Š         | 15/200 [3:40:52<45:14:19, 880.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1971.0700864438656
INFO:root:current train perplexity4.678089618682861
INFO:root:current mean train loss 1960.544424874442
INFO:root:current train perplexity4.682825088500977
INFO:root:current mean train loss 1971.6528243417815
INFO:root:current train perplexity4.736201763153076
INFO:root:current mean train loss 1970.627891756047
INFO:root:current train perplexity4.748090744018555
INFO:root:current mean train loss 1973.1824996881023
INFO:root:current train perplexity4.745839595794678
INFO:root:current mean train loss 1973.4190940443789
INFO:root:current train perplexity4.743441581726074
INFO:root:current mean train loss 1968.5689275432435
INFO:root:current train perplexity4.739816665649414
INFO:root:current mean train loss 1967.8369503274205
INFO:root:current train perplexity4.738983154296875
INFO:root:current mean train loss 1967.7670016500933
INFO:root:current train perplexity4.736804962158203
INFO:root:current mean train loss 1967.3417148550102
INFO:root:current train perplexity4.7373480796813965
INFO:root:current mean train loss 1968.8234015506405
INFO:root:current train perplexity4.742282867431641
INFO:root:current mean train loss 1970.45429810205
INFO:root:current train perplexity4.745443820953369
INFO:root:current mean train loss 1971.3234208151105
INFO:root:current train perplexity4.745762825012207
INFO:root:current mean train loss 1971.5304605999584
INFO:root:current train perplexity4.744921684265137
INFO:root:current mean train loss 1972.5239398856602
INFO:root:current train perplexity4.747679710388184
INFO:root:current mean train loss 1973.954008870757
INFO:root:current train perplexity4.74910306930542
INFO:root:current mean train loss 1974.6612644034112
INFO:root:current train perplexity4.75246000289917
INFO:root:current mean train loss 1975.4718022449802
INFO:root:current train perplexity4.7559638023376465
INFO:root:current mean train loss 1976.9296817717814
INFO:root:current train perplexity4.758384704589844
INFO:root:current mean train loss 1978.3625803140194
INFO:root:current train perplexity4.763229846954346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.72s/it]
INFO:root:final mean train loss: 1978.2021284925775
INFO:root:final train perplexity: 4.764500141143799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it]
INFO:root:eval mean loss: 1927.1748960237976
INFO:root:eval perplexity: 4.756434440612793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.05s/it]
INFO:root:eval mean loss: 2319.570035893866
INFO:root:eval perplexity: 6.73275899887085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/16
  8%|â–Š         | 16/200 [3:55:30<44:57:29, 879.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2001.7911875550176
INFO:root:current train perplexity4.795661926269531
INFO:root:current mean train loss 1984.5666182668585
INFO:root:current train perplexity4.788863658905029
INFO:root:current mean train loss 1998.1593553606435
INFO:root:current train perplexity4.822464942932129
INFO:root:current mean train loss 2005.3194626142395
INFO:root:current train perplexity4.838085174560547
INFO:root:current mean train loss 2004.2720898022824
INFO:root:current train perplexity4.849532604217529
INFO:root:current mean train loss 2007.9558671994719
INFO:root:current train perplexity4.862070560455322
INFO:root:current mean train loss 2013.3271859136316
INFO:root:current train perplexity4.878317356109619
INFO:root:current mean train loss 2008.20511675685
INFO:root:current train perplexity4.880826950073242
INFO:root:current mean train loss 2012.3238392248493
INFO:root:current train perplexity4.891016006469727
INFO:root:current mean train loss 2010.565820538789
INFO:root:current train perplexity4.888360500335693
INFO:root:current mean train loss 2010.7451827247826
INFO:root:current train perplexity4.891668796539307
INFO:root:current mean train loss 2011.3043949899259
INFO:root:current train perplexity4.894019603729248
INFO:root:current mean train loss 2012.0778875823662
INFO:root:current train perplexity4.896015644073486
INFO:root:current mean train loss 2012.581354476517
INFO:root:current train perplexity4.900775909423828
INFO:root:current mean train loss 2013.848310417419
INFO:root:current train perplexity4.905702114105225
INFO:root:current mean train loss 2014.6917127855716
INFO:root:current train perplexity4.909214973449707
INFO:root:current mean train loss 2014.2052245947646
INFO:root:current train perplexity4.907054424285889
INFO:root:current mean train loss 2015.9432168332687
INFO:root:current train perplexity4.91166353225708
INFO:root:current mean train loss 2017.6241266524837
INFO:root:current train perplexity4.914194107055664
INFO:root:current mean train loss 2018.0966696543237
INFO:root:current train perplexity4.91480827331543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.04s/it]
INFO:root:final mean train loss: 2017.9290062331577
INFO:root:final train perplexity: 4.916244983673096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.73s/it]
INFO:root:eval mean loss: 1940.2885720543827
INFO:root:eval perplexity: 4.807177543640137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.10s/it]
INFO:root:eval mean loss: 2336.5057139295213
INFO:root:eval perplexity: 6.827156066894531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/17
  8%|â–Š         | 17/200 [4:10:08<44:41:00, 879.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2008.5758944424715
INFO:root:current train perplexity4.915949821472168
INFO:root:current mean train loss 2001.3428169412816
INFO:root:current train perplexity4.89982271194458
INFO:root:current mean train loss 1999.2755830552842
INFO:root:current train perplexity4.879446983337402
INFO:root:current mean train loss 2003.8794266218993
INFO:root:current train perplexity4.886137008666992
INFO:root:current mean train loss 1999.338065976002
INFO:root:current train perplexity4.880084037780762
INFO:root:current mean train loss 2002.116327402543
INFO:root:current train perplexity4.873997211456299
INFO:root:current mean train loss 2002.4352170367574
INFO:root:current train perplexity4.868443965911865
INFO:root:current mean train loss 2004.4329504022744
INFO:root:current train perplexity4.872547626495361
INFO:root:current mean train loss 2007.8688030071087
INFO:root:current train perplexity4.885097026824951
INFO:root:current mean train loss 2007.7555198514992
INFO:root:current train perplexity4.885889053344727
INFO:root:current mean train loss 2007.6723972769344
INFO:root:current train perplexity4.889017105102539
INFO:root:current mean train loss 2009.4550613762956
INFO:root:current train perplexity4.889531135559082
INFO:root:current mean train loss 2010.1830547640782
INFO:root:current train perplexity4.892200469970703
INFO:root:current mean train loss 2009.6288828561217
INFO:root:current train perplexity4.8894782066345215
INFO:root:current mean train loss 2010.260538901052
INFO:root:current train perplexity4.891188144683838
INFO:root:current mean train loss 2011.3434229930042
INFO:root:current train perplexity4.893311500549316
INFO:root:current mean train loss 2013.0624014325617
INFO:root:current train perplexity4.898447036743164
INFO:root:current mean train loss 2013.5425026571456
INFO:root:current train perplexity4.898897171020508
INFO:root:current mean train loss 2014.1799156059653
INFO:root:current train perplexity4.901332378387451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.22s/it]
INFO:root:final mean train loss: 2014.0749740716008
INFO:root:final train perplexity: 4.901314735412598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.21s/it]
INFO:root:eval mean loss: 1933.2884967344028
INFO:root:eval perplexity: 4.78002405166626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.61s/it]
INFO:root:eval mean loss: 2334.4678193220857
INFO:root:eval perplexity: 6.815728664398193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/18
  9%|â–‰         | 18/200 [4:24:47<44:26:50, 879.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2048.5038330078123
INFO:root:current train perplexity4.924222946166992
INFO:root:current mean train loss 2027.1314615885417
INFO:root:current train perplexity4.901372909545898
INFO:root:current mean train loss 2021.3924352134147
INFO:root:current train perplexity4.901858329772949
INFO:root:current mean train loss 2007.7728039350666
INFO:root:current train perplexity4.861186504364014
INFO:root:current mean train loss 2013.6857828776042
INFO:root:current train perplexity4.868616104125977
INFO:root:current mean train loss 2012.964917233911
INFO:root:current train perplexity4.875192165374756
INFO:root:current mean train loss 2009.079338439437
INFO:root:current train perplexity4.867098808288574
INFO:root:current mean train loss 2004.5595879737366
INFO:root:current train perplexity4.8620991706848145
INFO:root:current mean train loss 2002.6194243437014
INFO:root:current train perplexity4.854421615600586
INFO:root:current mean train loss 2003.2261980425587
INFO:root:current train perplexity4.851319313049316
INFO:root:current mean train loss 2001.887155773865
INFO:root:current train perplexity4.843626022338867
INFO:root:current mean train loss 2002.2453618804793
INFO:root:current train perplexity4.85037899017334
INFO:root:current mean train loss 2001.340730051381
INFO:root:current train perplexity4.848341941833496
INFO:root:current mean train loss 2000.1875998076807
INFO:root:current train perplexity4.851219654083252
INFO:root:current mean train loss 1999.4330059010788
INFO:root:current train perplexity4.846945285797119
INFO:root:current mean train loss 2001.2225394518273
INFO:root:current train perplexity4.851536750793457
INFO:root:current mean train loss 2001.9752449011878
INFO:root:current train perplexity4.854485034942627
INFO:root:current mean train loss 2002.3544185157396
INFO:root:current train perplexity4.856314659118652
INFO:root:current mean train loss 2002.543468257661
INFO:root:current train perplexity4.856884002685547
INFO:root:current mean train loss 2003.9555525011278
INFO:root:current train perplexity4.862166881561279

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.50s/it]
INFO:root:final mean train loss: 2003.3532905367006
INFO:root:final train perplexity: 4.860017776489258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.12s/it]
INFO:root:eval mean loss: 1942.2085943560228
INFO:root:eval perplexity: 4.814651966094971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.05s/it]
INFO:root:eval mean loss: 2344.0755411783853
INFO:root:eval perplexity: 6.869777679443359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/19
 10%|â–‰         | 19/200 [4:39:27<44:12:17, 879.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2064.3605679598722
INFO:root:current train perplexity4.999858856201172
INFO:root:current mean train loss 1993.3540629402537
INFO:root:current train perplexity4.812530517578125
INFO:root:current mean train loss 1991.504370337134
INFO:root:current train perplexity4.81339168548584
INFO:root:current mean train loss 1995.8604478539887
INFO:root:current train perplexity4.802340984344482
INFO:root:current mean train loss 2000.0193785174763
INFO:root:current train perplexity4.819105625152588
INFO:root:current mean train loss 1995.8836777493416
INFO:root:current train perplexity4.815829277038574
INFO:root:current mean train loss 1992.4785048310014
INFO:root:current train perplexity4.818216800689697
INFO:root:current mean train loss 1988.8813466418153
INFO:root:current train perplexity4.81903600692749
INFO:root:current mean train loss 1989.8298828422007
INFO:root:current train perplexity4.822287559509277
INFO:root:current mean train loss 1991.601149155623
INFO:root:current train perplexity4.825917720794678
INFO:root:current mean train loss 1991.8369685283146
INFO:root:current train perplexity4.823829650878906
INFO:root:current mean train loss 1990.3813138203611
INFO:root:current train perplexity4.818161487579346
INFO:root:current mean train loss 1988.4213682383836
INFO:root:current train perplexity4.811337471008301
INFO:root:current mean train loss 1986.896567663519
INFO:root:current train perplexity4.808032035827637
INFO:root:current mean train loss 1987.4494115558523
INFO:root:current train perplexity4.8065667152404785
INFO:root:current mean train loss 1988.7093719201707
INFO:root:current train perplexity4.80980920791626
INFO:root:current mean train loss 1989.8555880357246
INFO:root:current train perplexity4.811193466186523
INFO:root:current mean train loss 1989.3981158780443
INFO:root:current train perplexity4.8101348876953125
INFO:root:current mean train loss 1990.4037389158548
INFO:root:current train perplexity4.812739372253418
INFO:root:current mean train loss 1991.531302524531
INFO:root:current train perplexity4.8144450187683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.03s/it]
INFO:root:final mean train loss: 1991.3796879801555
INFO:root:final train perplexity: 4.8143086433410645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.79s/it]
INFO:root:eval mean loss: 1924.7978818636414
INFO:root:eval perplexity: 4.747293949127197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it]
INFO:root:eval mean loss: 2332.505802235705
INFO:root:eval perplexity: 6.804742813110352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/20
 10%|â–ˆ         | 20/200 [4:54:08<43:59:48, 879.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1955.0796868739983
INFO:root:current train perplexity4.673716068267822
INFO:root:current mean train loss 1974.5947256842962
INFO:root:current train perplexity4.7407755851745605
INFO:root:current mean train loss 1968.1276850361205
INFO:root:current train perplexity4.731069087982178
INFO:root:current mean train loss 1970.9787810109005
INFO:root:current train perplexity4.743535041809082
INFO:root:current mean train loss 1972.674922030716
INFO:root:current train perplexity4.745423793792725
INFO:root:current mean train loss 1973.2685075805891
INFO:root:current train perplexity4.747328758239746
INFO:root:current mean train loss 1969.427103200802
INFO:root:current train perplexity4.7431321144104
INFO:root:current mean train loss 1970.8762567130414
INFO:root:current train perplexity4.745809078216553
INFO:root:current mean train loss 1974.1648422077528
INFO:root:current train perplexity4.7521843910217285
INFO:root:current mean train loss 1973.8923463344065
INFO:root:current train perplexity4.752099514007568
INFO:root:current mean train loss 1973.7960797219005
INFO:root:current train perplexity4.754729747772217
INFO:root:current mean train loss 1976.5096383031992
INFO:root:current train perplexity4.758139610290527
INFO:root:current mean train loss 1976.9735919253494
INFO:root:current train perplexity4.756784915924072
INFO:root:current mean train loss 1977.532304144155
INFO:root:current train perplexity4.761730194091797
INFO:root:current mean train loss 1977.3055973013215
INFO:root:current train perplexity4.759438991546631
INFO:root:current mean train loss 1978.4327922421976
INFO:root:current train perplexity4.763828754425049
INFO:root:current mean train loss 1977.931208426084
INFO:root:current train perplexity4.760975360870361
INFO:root:current mean train loss 1978.5843241221608
INFO:root:current train perplexity4.762483596801758
INFO:root:current mean train loss 1978.8232010327454
INFO:root:current train perplexity4.762121677398682
INFO:root:current mean train loss 1978.4008725477654
INFO:root:current train perplexity4.763185501098633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.74s/it]
INFO:root:final mean train loss: 1977.657216036013
INFO:root:final train perplexity: 4.762452602386475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.67s/it]
INFO:root:eval mean loss: 1909.796168550532
INFO:root:eval perplexity: 4.690011501312256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.88s/it]
INFO:root:eval mean loss: 2316.6579092039283
INFO:root:eval perplexity: 6.7166595458984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/21
 10%|â–ˆ         | 21/200 [5:08:46<43:43:16, 879.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1976.1093444824219
INFO:root:current train perplexity4.670549392700195
INFO:root:current mean train loss 1962.4363325070112
INFO:root:current train perplexity4.673907279968262
INFO:root:current mean train loss 1952.4778900146484
INFO:root:current train perplexity4.678798675537109
INFO:root:current mean train loss 1954.4302570471602
INFO:root:current train perplexity4.692178249359131
INFO:root:current mean train loss 1956.0608480353105
INFO:root:current train perplexity4.697249889373779
INFO:root:current mean train loss 1960.3571810276387
INFO:root:current train perplexity4.699954509735107
INFO:root:current mean train loss 1963.6937453107137
INFO:root:current train perplexity4.706168174743652
INFO:root:current mean train loss 1964.4496199996383
INFO:root:current train perplexity4.706852436065674
INFO:root:current mean train loss 1965.266249612113
INFO:root:current train perplexity4.712057113647461
INFO:root:current mean train loss 1967.7025553811045
INFO:root:current train perplexity4.7154645919799805
INFO:root:current mean train loss 1971.2614117246685
INFO:root:current train perplexity4.726053237915039
INFO:root:current mean train loss 1970.2316940993999
INFO:root:current train perplexity4.723005294799805
INFO:root:current mean train loss 1969.8456057408812
INFO:root:current train perplexity4.723387718200684
INFO:root:current mean train loss 1969.1122895637445
INFO:root:current train perplexity4.724708557128906
INFO:root:current mean train loss 1969.024217207353
INFO:root:current train perplexity4.727019786834717
INFO:root:current mean train loss 1969.9190602437388
INFO:root:current train perplexity4.728939056396484
INFO:root:current mean train loss 1969.833480834961
INFO:root:current train perplexity4.728497505187988
INFO:root:current mean train loss 1969.5366270721365
INFO:root:current train perplexity4.730106353759766
INFO:root:current mean train loss 1969.4602321098591
INFO:root:current train perplexity4.731318473815918
INFO:root:current mean train loss 1968.5713648883843
INFO:root:current train perplexity4.727275848388672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.09s/it]
INFO:root:final mean train loss: 1968.3848977601112
INFO:root:final train perplexity: 4.727729797363281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it]
INFO:root:eval mean loss: 1907.6041636365526
INFO:root:eval perplexity: 4.681700229644775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it]
INFO:root:eval mean loss: 2313.163456477172
INFO:root:eval perplexity: 6.697391510009766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/22
 11%|â–ˆ         | 22/200 [5:23:27<43:30:06, 879.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.0347833502783
INFO:root:current train perplexity4.650708198547363
INFO:root:current mean train loss 1942.2076063211255
INFO:root:current train perplexity4.6520538330078125
INFO:root:current mean train loss 1949.6763137985063
INFO:root:current train perplexity4.66593074798584
INFO:root:current mean train loss 1955.3032727279867
INFO:root:current train perplexity4.679932594299316
INFO:root:current mean train loss 1957.5196115118756
INFO:root:current train perplexity4.686479091644287
INFO:root:current mean train loss 1955.3041220992855
INFO:root:current train perplexity4.68856143951416
INFO:root:current mean train loss 1952.9867433091683
INFO:root:current train perplexity4.684412002563477
INFO:root:current mean train loss 1951.8693996098802
INFO:root:current train perplexity4.683063507080078
INFO:root:current mean train loss 1953.2891016519902
INFO:root:current train perplexity4.678387641906738
INFO:root:current mean train loss 1953.8844301511915
INFO:root:current train perplexity4.681868076324463
INFO:root:current mean train loss 1952.3261900774696
INFO:root:current train perplexity4.680365085601807
INFO:root:current mean train loss 1953.78376019438
INFO:root:current train perplexity4.681435585021973
INFO:root:current mean train loss 1953.841912712343
INFO:root:current train perplexity4.681119918823242
INFO:root:current mean train loss 1956.0457632977514
INFO:root:current train perplexity4.684784412384033
INFO:root:current mean train loss 1956.7361278236115
INFO:root:current train perplexity4.684958457946777
INFO:root:current mean train loss 1959.6701140988805
INFO:root:current train perplexity4.692722797393799
INFO:root:current mean train loss 1959.4330313363905
INFO:root:current train perplexity4.691175937652588
INFO:root:current mean train loss 1959.2538503441378
INFO:root:current train perplexity4.689877986907959
INFO:root:current mean train loss 1959.2915269125608
INFO:root:current train perplexity4.690097808837891
INFO:root:current mean train loss 1959.0568097168216
INFO:root:current train perplexity4.691535472869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.48s/it]
INFO:root:final mean train loss: 1958.7697081072909
INFO:root:final train perplexity: 4.691989421844482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.28s/it]
INFO:root:eval mean loss: 1913.853174953596
INFO:root:eval perplexity: 4.705434799194336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.54s/it]
INFO:root:eval mean loss: 2320.0106664346463
INFO:root:eval perplexity: 6.735199451446533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/23
 12%|â–ˆâ–        | 23/200 [5:38:03<43:11:52, 878.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.9266777886285
INFO:root:current train perplexity4.681593894958496
INFO:root:current mean train loss 1941.6982582493831
INFO:root:current train perplexity4.644277572631836
INFO:root:current mean train loss 1944.257252660291
INFO:root:current train perplexity4.630858898162842
INFO:root:current mean train loss 1943.7381213065905
INFO:root:current train perplexity4.631751537322998
INFO:root:current mean train loss 1945.5340827786192
INFO:root:current train perplexity4.636375427246094
INFO:root:current mean train loss 1942.9912965936176
INFO:root:current train perplexity4.63261079788208
INFO:root:current mean train loss 1941.031711213485
INFO:root:current train perplexity4.627523899078369
INFO:root:current mean train loss 1942.3165984721124
INFO:root:current train perplexity4.631469249725342
INFO:root:current mean train loss 1943.9132904395628
INFO:root:current train perplexity4.639113903045654
INFO:root:current mean train loss 1943.5157870205967
INFO:root:current train perplexity4.644190311431885
INFO:root:current mean train loss 1943.4244770015052
INFO:root:current train perplexity4.644184112548828
INFO:root:current mean train loss 1946.1083001657694
INFO:root:current train perplexity4.647314071655273
INFO:root:current mean train loss 1945.6016340388808
INFO:root:current train perplexity4.6478142738342285
INFO:root:current mean train loss 1946.0899566869941
INFO:root:current train perplexity4.6479315757751465
INFO:root:current mean train loss 1946.8593015120334
INFO:root:current train perplexity4.6490020751953125
INFO:root:current mean train loss 1947.156010465802
INFO:root:current train perplexity4.648820877075195
INFO:root:current mean train loss 1947.9660815718612
INFO:root:current train perplexity4.649715423583984
INFO:root:current mean train loss 1948.9053897793733
INFO:root:current train perplexity4.653661727905273
INFO:root:current mean train loss 1949.9708379836309
INFO:root:current train perplexity4.658075332641602

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.91s/it]
INFO:root:final mean train loss: 1949.4152453447073
INFO:root:final train perplexity: 4.6574788093566895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.31s/it]
INFO:root:eval mean loss: 1900.1076469691932
INFO:root:eval perplexity: 4.653386116027832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.16s/it]
INFO:root:eval mean loss: 2313.0445768748614
INFO:root:eval perplexity: 6.6967363357543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/24
 12%|â–ˆâ–        | 24/200 [5:52:38<42:53:59, 877.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1979.7040318080358
INFO:root:current train perplexity4.594500541687012
INFO:root:current mean train loss 1935.5042028694509
INFO:root:current train perplexity4.621039390563965
INFO:root:current mean train loss 1928.347676889908
INFO:root:current train perplexity4.615148544311523
INFO:root:current mean train loss 1926.3578942513234
INFO:root:current train perplexity4.606523513793945
INFO:root:current mean train loss 1932.5412714627803
INFO:root:current train perplexity4.600078582763672
INFO:root:current mean train loss 1928.7933197924372
INFO:root:current train perplexity4.597491264343262
INFO:root:current mean train loss 1932.4668694736538
INFO:root:current train perplexity4.593078136444092
INFO:root:current mean train loss 1935.3507960641907
INFO:root:current train perplexity4.601138591766357
INFO:root:current mean train loss 1935.8888939310332
INFO:root:current train perplexity4.600386142730713
INFO:root:current mean train loss 1938.2471034208759
INFO:root:current train perplexity4.606949806213379
INFO:root:current mean train loss 1939.2945643920293
INFO:root:current train perplexity4.61625862121582
INFO:root:current mean train loss 1942.1670075152085
INFO:root:current train perplexity4.622358798980713
INFO:root:current mean train loss 1940.5107111389616
INFO:root:current train perplexity4.619111061096191
INFO:root:current mean train loss 1939.7058760184045
INFO:root:current train perplexity4.618716239929199
INFO:root:current mean train loss 1938.60720740605
INFO:root:current train perplexity4.6193318367004395
INFO:root:current mean train loss 1940.4798086630879
INFO:root:current train perplexity4.621759414672852
INFO:root:current mean train loss 1940.3923272237914
INFO:root:current train perplexity4.623950958251953
INFO:root:current mean train loss 1940.7710595960566
INFO:root:current train perplexity4.625612735748291
INFO:root:current mean train loss 1941.8485876863413
INFO:root:current train perplexity4.628314018249512
INFO:root:current mean train loss 1942.5024399979925
INFO:root:current train perplexity4.629985332489014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.07s/it]
INFO:root:final mean train loss: 1942.1280210093903
INFO:root:final train perplexity: 4.630770206451416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it]
INFO:root:eval mean loss: 1911.2809266435338
INFO:root:eval perplexity: 4.695650577545166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.39s/it]
INFO:root:eval mean loss: 2320.57932622382
INFO:root:eval perplexity: 6.738347053527832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/25
 12%|â–ˆâ–Ž        | 25/200 [6:07:13<42:37:26, 876.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.4847310384114
INFO:root:current train perplexity4.556445121765137
INFO:root:current mean train loss 1924.229981453188
INFO:root:current train perplexity4.582151889801025
INFO:root:current mean train loss 1922.6990732465472
INFO:root:current train perplexity4.579476833343506
INFO:root:current mean train loss 1923.984890407986
INFO:root:current train perplexity4.577376365661621
INFO:root:current mean train loss 1930.5592956542969
INFO:root:current train perplexity4.577839374542236
INFO:root:current mean train loss 1930.785308139015
INFO:root:current train perplexity4.59153938293457
INFO:root:current mean train loss 1931.939314035269
INFO:root:current train perplexity4.595548152923584
INFO:root:current mean train loss 1931.6275445927572
INFO:root:current train perplexity4.590930938720703
INFO:root:current mean train loss 1930.540205724031
INFO:root:current train perplexity4.5882744789123535
INFO:root:current mean train loss 1929.795731977983
INFO:root:current train perplexity4.593055725097656
INFO:root:current mean train loss 1931.4653358459473
INFO:root:current train perplexity4.596216678619385
INFO:root:current mean train loss 1934.513911019865
INFO:root:current train perplexity4.604528427124023
INFO:root:current mean train loss 1934.3462217243668
INFO:root:current train perplexity4.602938652038574
INFO:root:current mean train loss 1934.114648824732
INFO:root:current train perplexity4.602925777435303
INFO:root:current mean train loss 1934.8110495578037
INFO:root:current train perplexity4.603782653808594
INFO:root:current mean train loss 1935.0684329055425
INFO:root:current train perplexity4.604458808898926
INFO:root:current mean train loss 1935.0790661591027
INFO:root:current train perplexity4.602692127227783
INFO:root:current mean train loss 1935.7582146098055
INFO:root:current train perplexity4.60436487197876
INFO:root:current mean train loss 1935.6456938626472
INFO:root:current train perplexity4.60335111618042
INFO:root:current mean train loss 1935.8839533244745
INFO:root:current train perplexity4.605223655700684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.23s/it]
INFO:root:final mean train loss: 1934.7434991248858
INFO:root:final train perplexity: 4.603861331939697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.19s/it]
INFO:root:eval mean loss: 1906.4997039145612
INFO:root:eval perplexity: 4.677517890930176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.54s/it]
INFO:root:eval mean loss: 2318.0507024670324
INFO:root:eval perplexity: 6.724353790283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/26
 13%|â–ˆâ–Ž        | 26/200 [6:21:46<42:19:53, 875.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.007997094131
INFO:root:current train perplexity4.532320499420166
INFO:root:current mean train loss 1930.5893667234598
INFO:root:current train perplexity4.583924293518066
INFO:root:current mean train loss 1928.4037001993647
INFO:root:current train perplexity4.582103252410889
INFO:root:current mean train loss 1925.9545955713893
INFO:root:current train perplexity4.574070930480957
INFO:root:current mean train loss 1917.7359231615824
INFO:root:current train perplexity4.5568928718566895
INFO:root:current mean train loss 1917.4581684669593
INFO:root:current train perplexity4.564548969268799
INFO:root:current mean train loss 1917.8892197631264
INFO:root:current train perplexity4.565217971801758
INFO:root:current mean train loss 1921.9672553388052
INFO:root:current train perplexity4.566662788391113
INFO:root:current mean train loss 1923.8826792532143
INFO:root:current train perplexity4.568357467651367
INFO:root:current mean train loss 1923.778851272956
INFO:root:current train perplexity4.569262981414795
INFO:root:current mean train loss 1925.4244914792341
INFO:root:current train perplexity4.57489013671875
INFO:root:current mean train loss 1927.848618262489
INFO:root:current train perplexity4.579981803894043
INFO:root:current mean train loss 1927.5742621287332
INFO:root:current train perplexity4.580996513366699
INFO:root:current mean train loss 1926.8615404053644
INFO:root:current train perplexity4.578158378601074
INFO:root:current mean train loss 1926.8357064050572
INFO:root:current train perplexity4.576955318450928
INFO:root:current mean train loss 1926.8368296985268
INFO:root:current train perplexity4.575623989105225
INFO:root:current mean train loss 1928.7525416809492
INFO:root:current train perplexity4.5782365798950195
INFO:root:current mean train loss 1929.246016062518
INFO:root:current train perplexity4.579047203063965
INFO:root:current mean train loss 1929.4520839212512
INFO:root:current train perplexity4.5796589851379395
INFO:root:current mean train loss 1928.5285254610624
INFO:root:current train perplexity4.579228401184082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.88s/it]
INFO:root:final mean train loss: 1927.6900312815178
INFO:root:final train perplexity: 4.578304290771484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.77s/it]
INFO:root:eval mean loss: 1921.7997549070535
INFO:root:eval perplexity: 4.735790252685547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.46s/it]
INFO:root:eval mean loss: 2336.95182205092
INFO:root:eval perplexity: 6.829661846160889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/27
 14%|â–ˆâ–Ž        | 27/200 [6:36:18<42:01:39, 874.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1910.4524893925109
INFO:root:current train perplexity4.537811756134033
INFO:root:current mean train loss 1909.2466855592365
INFO:root:current train perplexity4.530206680297852
INFO:root:current mean train loss 1909.4272635999575
INFO:root:current train perplexity4.546854019165039
INFO:root:current mean train loss 1912.123298176174
INFO:root:current train perplexity4.541059494018555
INFO:root:current mean train loss 1915.1278849106168
INFO:root:current train perplexity4.5485615730285645
INFO:root:current mean train loss 1919.5854680324542
INFO:root:current train perplexity4.5461835861206055
INFO:root:current mean train loss 1919.7554273054593
INFO:root:current train perplexity4.553242206573486
INFO:root:current mean train loss 1918.1532781193314
INFO:root:current train perplexity4.550108909606934
INFO:root:current mean train loss 1921.1085096950576
INFO:root:current train perplexity4.558603286743164
INFO:root:current mean train loss 1921.346455806979
INFO:root:current train perplexity4.5557427406311035
INFO:root:current mean train loss 1920.9508590842465
INFO:root:current train perplexity4.553220272064209
INFO:root:current mean train loss 1922.8977222607336
INFO:root:current train perplexity4.558536052703857
INFO:root:current mean train loss 1923.3170624992238
INFO:root:current train perplexity4.559803485870361
INFO:root:current mean train loss 1922.8036543069427
INFO:root:current train perplexity4.559652805328369
INFO:root:current mean train loss 1922.8386980640219
INFO:root:current train perplexity4.558743476867676
INFO:root:current mean train loss 1922.942823691607
INFO:root:current train perplexity4.557955741882324
INFO:root:current mean train loss 1922.5911902046894
INFO:root:current train perplexity4.558748245239258
INFO:root:current mean train loss 1922.9547433690407
INFO:root:current train perplexity4.557236194610596
INFO:root:current mean train loss 1923.1266014994283
INFO:root:current train perplexity4.557941913604736
INFO:root:current mean train loss 1922.580786980696
INFO:root:current train perplexity4.55751895904541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.06s/it]
INFO:root:final mean train loss: 1922.2162187492613
INFO:root:final train perplexity: 4.558569431304932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.21s/it]
INFO:root:eval mean loss: 1929.626931048454
INFO:root:eval perplexity: 4.765881061553955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.47s/it]
INFO:root:eval mean loss: 2345.375846267592
INFO:root:eval perplexity: 6.877125263214111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/28
 14%|â–ˆâ–        | 28/200 [6:50:47<41:42:30, 872.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1928.5712223307291
INFO:root:current train perplexity4.5916571617126465
INFO:root:current mean train loss 1933.1224455915178
INFO:root:current train perplexity4.57014799118042
INFO:root:current mean train loss 1922.8357563920454
INFO:root:current train perplexity4.534090995788574
INFO:root:current mean train loss 1921.766687174479
INFO:root:current train perplexity4.532710552215576
INFO:root:current mean train loss 1920.8736397512334
INFO:root:current train perplexity4.520748615264893
INFO:root:current mean train loss 1918.0541871178668
INFO:root:current train perplexity4.519107818603516
INFO:root:current mean train loss 1917.138536783854
INFO:root:current train perplexity4.528119087219238
INFO:root:current mean train loss 1917.8534100932459
INFO:root:current train perplexity4.532062530517578
INFO:root:current mean train loss 1915.7485457589285
INFO:root:current train perplexity4.53115177154541
INFO:root:current mean train loss 1916.6212618940303
INFO:root:current train perplexity4.531910419464111
INFO:root:current mean train loss 1917.792660905705
INFO:root:current train perplexity4.538662433624268
INFO:root:current mean train loss 1917.9039785571808
INFO:root:current train perplexity4.538002014160156
INFO:root:current mean train loss 1917.8405598958334
INFO:root:current train perplexity4.538787841796875
INFO:root:current mean train loss 1918.776293856534
INFO:root:current train perplexity4.540971279144287
INFO:root:current mean train loss 1917.740946189751
INFO:root:current train perplexity4.538949489593506
INFO:root:current mean train loss 1916.8044497922867
INFO:root:current train perplexity4.5387749671936035
INFO:root:current mean train loss 1917.503990861124
INFO:root:current train perplexity4.539526462554932
INFO:root:current mean train loss 1917.13490199989
INFO:root:current train perplexity4.538473606109619
INFO:root:current mean train loss 1916.6758446614583
INFO:root:current train perplexity4.53857421875
INFO:root:current mean train loss 1916.7931006477452
INFO:root:current train perplexity4.537869930267334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.65s/it]
INFO:root:final mean train loss: 1916.4862988847588
INFO:root:final train perplexity: 4.5380024909973145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.27s/it]
INFO:root:eval mean loss: 1909.6246878982436
INFO:root:eval perplexity: 4.689361572265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it]
INFO:root:eval mean loss: 2328.2740162518007
INFO:root:eval perplexity: 6.78110933303833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/29
 14%|â–ˆâ–        | 29/200 [7:05:20<41:27:52, 872.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1890.2211847719939
INFO:root:current train perplexity4.464921474456787
INFO:root:current mean train loss 1891.256498336792
INFO:root:current train perplexity4.468594551086426
INFO:root:current mean train loss 1900.632649460884
INFO:root:current train perplexity4.475391387939453
INFO:root:current mean train loss 1899.1440635214046
INFO:root:current train perplexity4.473642349243164
INFO:root:current mean train loss 1901.5511990678988
INFO:root:current train perplexity4.486283302307129
INFO:root:current mean train loss 1899.173504391232
INFO:root:current train perplexity4.485248565673828
INFO:root:current mean train loss 1902.651991474835
INFO:root:current train perplexity4.494496822357178
INFO:root:current mean train loss 1903.8722592748777
INFO:root:current train perplexity4.497668266296387
INFO:root:current mean train loss 1906.331535441993
INFO:root:current train perplexity4.505748271942139
INFO:root:current mean train loss 1904.564111894177
INFO:root:current train perplexity4.50029182434082
INFO:root:current mean train loss 1904.9932283394503
INFO:root:current train perplexity4.50078010559082
INFO:root:current mean train loss 1904.6883443537974
INFO:root:current train perplexity4.504916667938232
INFO:root:current mean train loss 1907.5326638236504
INFO:root:current train perplexity4.50869083404541
INFO:root:current mean train loss 1909.5970515108656
INFO:root:current train perplexity4.513501167297363
INFO:root:current mean train loss 1911.6965707569275
INFO:root:current train perplexity4.514631748199463
INFO:root:current mean train loss 1911.447988385531
INFO:root:current train perplexity4.513930797576904
INFO:root:current mean train loss 1911.2863092805758
INFO:root:current train perplexity4.513566493988037
INFO:root:current mean train loss 1910.695279461997
INFO:root:current train perplexity4.5147881507873535
INFO:root:current mean train loss 1911.7729970274718
INFO:root:current train perplexity4.516276836395264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.86s/it]
INFO:root:final mean train loss: 1910.7251955956688
INFO:root:final train perplexity: 4.517416000366211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.94s/it]
INFO:root:eval mean loss: 1897.2668539277206
INFO:root:eval perplexity: 4.642700672149658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.23s/it]
INFO:root:eval mean loss: 2317.9500550615026
INFO:root:eval perplexity: 6.723797798156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/30
 15%|â–ˆâ–Œ        | 30/200 [7:19:53<41:12:58, 872.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.3798149956597
INFO:root:current train perplexity4.328857898712158
INFO:root:current mean train loss 1893.1162512543006
INFO:root:current train perplexity4.441430568695068
INFO:root:current mean train loss 1899.6870473469273
INFO:root:current train perplexity4.465848922729492
INFO:root:current mean train loss 1893.1635390593397
INFO:root:current train perplexity4.447143077850342
INFO:root:current mean train loss 1892.4444317432954
INFO:root:current train perplexity4.451757907867432
INFO:root:current mean train loss 1893.5988201148853
INFO:root:current train perplexity4.455609321594238
INFO:root:current mean train loss 1892.8103131574558
INFO:root:current train perplexity4.462089538574219
INFO:root:current mean train loss 1896.6062187334715
INFO:root:current train perplexity4.475889682769775
INFO:root:current mean train loss 1898.112256704361
INFO:root:current train perplexity4.479681968688965
INFO:root:current mean train loss 1900.7712411744103
INFO:root:current train perplexity4.483185768127441
INFO:root:current mean train loss 1902.7714097294274
INFO:root:current train perplexity4.486015319824219
INFO:root:current mean train loss 1902.0459858350005
INFO:root:current train perplexity4.484889984130859
INFO:root:current mean train loss 1903.7620679983133
INFO:root:current train perplexity4.490332126617432
INFO:root:current mean train loss 1904.0285231413234
INFO:root:current train perplexity4.488884449005127
INFO:root:current mean train loss 1903.791430785353
INFO:root:current train perplexity4.4886474609375
INFO:root:current mean train loss 1903.3220784343418
INFO:root:current train perplexity4.487990856170654
INFO:root:current mean train loss 1902.3730857190026
INFO:root:current train perplexity4.490000247955322
INFO:root:current mean train loss 1902.7982744157769
INFO:root:current train perplexity4.49122428894043
INFO:root:current mean train loss 1903.8720607978985
INFO:root:current train perplexity4.494030475616455
INFO:root:current mean train loss 1904.7488856368068
INFO:root:current train perplexity4.495453357696533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.09s/it]
INFO:root:final mean train loss: 1904.2476233839689
INFO:root:final train perplexity: 4.494381904602051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.71s/it]
INFO:root:eval mean loss: 1904.3832535980441
INFO:root:eval perplexity: 4.669513702392578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.23s/it]
INFO:root:eval mean loss: 2325.4122916147217
INFO:root:eval perplexity: 6.765174865722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/31
 16%|â–ˆâ–Œ        | 31/200 [7:34:28<41:00:16, 873.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1895.9010901817908
INFO:root:current train perplexity4.522266387939453
INFO:root:current mean train loss 1897.340087890625
INFO:root:current train perplexity4.484752655029297
INFO:root:current mean train loss 1888.3085289339049
INFO:root:current train perplexity4.45119571685791
INFO:root:current mean train loss 1889.7141266805263
INFO:root:current train perplexity4.45231819152832
INFO:root:current mean train loss 1892.2967532162374
INFO:root:current train perplexity4.457219123840332
INFO:root:current mean train loss 1891.2176184128446
INFO:root:current train perplexity4.455273151397705
INFO:root:current mean train loss 1893.3993543923473
INFO:root:current train perplexity4.4542927742004395
INFO:root:current mean train loss 1896.199704845418
INFO:root:current train perplexity4.460763931274414
INFO:root:current mean train loss 1897.2211593369307
INFO:root:current train perplexity4.466119766235352
INFO:root:current mean train loss 1899.4742320907296
INFO:root:current train perplexity4.471766471862793
INFO:root:current mean train loss 1898.9791914138646
INFO:root:current train perplexity4.473677158355713
INFO:root:current mean train loss 1900.7206037124986
INFO:root:current train perplexity4.476572513580322
INFO:root:current mean train loss 1899.8834579990505
INFO:root:current train perplexity4.475948333740234
INFO:root:current mean train loss 1900.827762747602
INFO:root:current train perplexity4.4769206047058105
INFO:root:current mean train loss 1899.6242362473156
INFO:root:current train perplexity4.4742045402526855
INFO:root:current mean train loss 1898.2931815331135
INFO:root:current train perplexity4.474066734313965
INFO:root:current mean train loss 1899.3291828676342
INFO:root:current train perplexity4.475247383117676
INFO:root:current mean train loss 1898.5286032100955
INFO:root:current train perplexity4.474269390106201
INFO:root:current mean train loss 1899.9398176646573
INFO:root:current train perplexity4.478334426879883
INFO:root:current mean train loss 1901.2508999991887
INFO:root:current train perplexity4.482334136962891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.86s/it]
INFO:root:final mean train loss: 1900.9168109287834
INFO:root:final train perplexity: 4.482583045959473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.57s/it]
INFO:root:eval mean loss: 1909.4646649732658
INFO:root:eval perplexity: 4.688754558563232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 57.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.00s/it]
INFO:root:eval mean loss: 2331.5657041292666
INFO:root:eval perplexity: 6.799485683441162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/32
 16%|â–ˆâ–Œ        | 32/200 [7:49:01<40:45:12, 873.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1922.8083779978197
INFO:root:current train perplexity4.53479528427124
INFO:root:current mean train loss 1899.7112379807693
INFO:root:current train perplexity4.435763835906982
INFO:root:current mean train loss 1901.8498635625642
INFO:root:current train perplexity4.441116809844971
INFO:root:current mean train loss 1893.7727687824572
INFO:root:current train perplexity4.4332780838012695
INFO:root:current mean train loss 1897.197658013544
INFO:root:current train perplexity4.44718074798584
INFO:root:current mean train loss 1894.1693609810227
INFO:root:current train perplexity4.449193954467773
INFO:root:current mean train loss 1892.1590293302877
INFO:root:current train perplexity4.441279411315918
INFO:root:current mean train loss 1893.5534378811617
INFO:root:current train perplexity4.444187641143799
INFO:root:current mean train loss 1892.585734483893
INFO:root:current train perplexity4.449582099914551
INFO:root:current mean train loss 1892.0257853146954
INFO:root:current train perplexity4.447494983673096
INFO:root:current mean train loss 1891.188754058867
INFO:root:current train perplexity4.448019504547119
INFO:root:current mean train loss 1893.543688890085
INFO:root:current train perplexity4.457706451416016
INFO:root:current mean train loss 1894.7526373276285
INFO:root:current train perplexity4.460118770599365
INFO:root:current mean train loss 1894.6822609748756
INFO:root:current train perplexity4.46349573135376
INFO:root:current mean train loss 1894.894677768213
INFO:root:current train perplexity4.465507984161377
INFO:root:current mean train loss 1896.1704616583716
INFO:root:current train perplexity4.466869354248047
INFO:root:current mean train loss 1898.6063998426089
INFO:root:current train perplexity4.47219181060791
INFO:root:current mean train loss 1898.757615072455
INFO:root:current train perplexity4.471276760101318
INFO:root:current mean train loss 1899.6344556472125
INFO:root:current train perplexity4.4735283851623535
INFO:root:current mean train loss 1899.2852470331197
INFO:root:current train perplexity4.473670482635498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.39s/it]
INFO:root:final mean train loss: 1898.3563325682856
INFO:root:final train perplexity: 4.473533630371094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.70s/it]
INFO:root:eval mean loss: 1906.905340100011
INFO:root:eval perplexity: 4.67905330657959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.27s/it]
INFO:root:eval mean loss: 2332.120703731023
INFO:root:eval perplexity: 6.80258846282959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/33
 16%|â–ˆâ–‹        | 33/200 [8:03:35<40:31:57, 873.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.2801737467448
INFO:root:current train perplexity4.505735874176025
INFO:root:current mean train loss 1900.6994262695312
INFO:root:current train perplexity4.483887195587158
INFO:root:current mean train loss 1891.0719778207633
INFO:root:current train perplexity4.468237400054932
INFO:root:current mean train loss 1894.1129774305555
INFO:root:current train perplexity4.470542907714844
INFO:root:current mean train loss 1894.9593720809273
INFO:root:current train perplexity4.46473503112793
INFO:root:current mean train loss 1898.7493554251535
INFO:root:current train perplexity4.468358993530273
INFO:root:current mean train loss 1900.3520724209873
INFO:root:current train perplexity4.474057674407959
INFO:root:current mean train loss 1899.1874458714535
INFO:root:current train perplexity4.475035667419434
INFO:root:current mean train loss 1897.05498813363
INFO:root:current train perplexity4.4685187339782715
INFO:root:current mean train loss 1898.3756441752116
INFO:root:current train perplexity4.4748148918151855
INFO:root:current mean train loss 1898.314189637382
INFO:root:current train perplexity4.472113609313965
INFO:root:current mean train loss 1897.5585815429688
INFO:root:current train perplexity4.469793796539307
INFO:root:current mean train loss 1893.9483926440041
INFO:root:current train perplexity4.465655326843262
INFO:root:current mean train loss 1896.7961521821865
INFO:root:current train perplexity4.467244625091553
INFO:root:current mean train loss 1896.9896383207138
INFO:root:current train perplexity4.467893123626709
INFO:root:current mean train loss 1898.2094235151242
INFO:root:current train perplexity4.466723442077637
INFO:root:current mean train loss 1898.9551960037415
INFO:root:current train perplexity4.46876859664917
INFO:root:current mean train loss 1898.9991722800514
INFO:root:current train perplexity4.468702793121338
INFO:root:current mean train loss 1898.6348507460727
INFO:root:current train perplexity4.469149589538574
INFO:root:current mean train loss 1898.1645953742825
INFO:root:current train perplexity4.469383716583252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.30s/it]
INFO:root:final mean train loss: 1897.3970447719187
INFO:root:final train perplexity: 4.470149040222168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.50s/it]
INFO:root:eval mean loss: 1910.7069853654145
INFO:root:eval perplexity: 4.693470478057861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.57s/it]
INFO:root:eval mean loss: 2336.3573491522607
INFO:root:eval perplexity: 6.826323509216309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/34
 17%|â–ˆâ–‹        | 34/200 [8:18:15<40:22:24, 875.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1869.5195217380276
INFO:root:current train perplexity4.422898292541504
INFO:root:current mean train loss 1880.975123173773
INFO:root:current train perplexity4.427582740783691
INFO:root:current mean train loss 1886.9977247327674
INFO:root:current train perplexity4.4386467933654785
INFO:root:current mean train loss 1887.6923028353988
INFO:root:current train perplexity4.4340691566467285
INFO:root:current mean train loss 1888.0592852258583
INFO:root:current train perplexity4.439934730529785
INFO:root:current mean train loss 1889.5760745572466
INFO:root:current train perplexity4.446135520935059
INFO:root:current mean train loss 1889.5464687600975
INFO:root:current train perplexity4.446907043457031
INFO:root:current mean train loss 1891.8990101464467
INFO:root:current train perplexity4.452104091644287
INFO:root:current mean train loss 1890.955399516507
INFO:root:current train perplexity4.451336860656738
INFO:root:current mean train loss 1892.7008802556454
INFO:root:current train perplexity4.45695161819458
INFO:root:current mean train loss 1894.3401862722696
INFO:root:current train perplexity4.456920623779297
INFO:root:current mean train loss 1896.5764065777335
INFO:root:current train perplexity4.464028358459473
INFO:root:current mean train loss 1897.4509588016042
INFO:root:current train perplexity4.46584939956665
INFO:root:current mean train loss 1897.3273422252291
INFO:root:current train perplexity4.46917200088501
INFO:root:current mean train loss 1898.4815803584652
INFO:root:current train perplexity4.471911907196045
INFO:root:current mean train loss 1900.6148002784164
INFO:root:current train perplexity4.4771246910095215
INFO:root:current mean train loss 1901.7765413032946
INFO:root:current train perplexity4.483245849609375
INFO:root:current mean train loss 1903.1334421547465
INFO:root:current train perplexity4.484749794006348
INFO:root:current mean train loss 1902.8690018407449
INFO:root:current train perplexity4.486591815948486
INFO:root:current mean train loss 1903.0368841284142
INFO:root:current train perplexity4.488440990447998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:29<00:00, 749.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:29<00:00, 749.05s/it]
INFO:root:final mean train loss: 1902.507957716272
INFO:root:final train perplexity: 4.48821496963501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.34s/it]
INFO:root:eval mean loss: 1918.1719035696476
INFO:root:eval perplexity: 4.721908092498779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it]
INFO:root:eval mean loss: 2347.350100686364
INFO:root:eval perplexity: 6.888297080993652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/35
 18%|â–ˆâ–Š        | 35/200 [8:32:43<40:01:14, 873.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1912.0491631690493
INFO:root:current train perplexity4.5196356773376465
INFO:root:current mean train loss 1899.8613602156493
INFO:root:current train perplexity4.497220516204834
INFO:root:current mean train loss 1912.5686828198077
INFO:root:current train perplexity4.526234149932861
INFO:root:current mean train loss 1918.5136133184287
INFO:root:current train perplexity4.538774490356445
INFO:root:current mean train loss 1914.2122988063797
INFO:root:current train perplexity4.533323287963867
INFO:root:current mean train loss 1915.436775798348
INFO:root:current train perplexity4.539642810821533
INFO:root:current mean train loss 1919.930104720146
INFO:root:current train perplexity4.548173427581787
INFO:root:current mean train loss 1917.351700866853
INFO:root:current train perplexity4.540215015411377
INFO:root:current mean train loss 1916.1711603288416
INFO:root:current train perplexity4.539308547973633
INFO:root:current mean train loss 1916.6747941260846
INFO:root:current train perplexity4.54245138168335
INFO:root:current mean train loss 1918.4781580058486
INFO:root:current train perplexity4.543735027313232
INFO:root:current mean train loss 1919.785566013662
INFO:root:current train perplexity4.547008991241455
INFO:root:current mean train loss 1919.1731031556403
INFO:root:current train perplexity4.546511650085449
INFO:root:current mean train loss 1921.579188080053
INFO:root:current train perplexity4.552938938140869
INFO:root:current mean train loss 1922.7784398498943
INFO:root:current train perplexity4.559966087341309
INFO:root:current mean train loss 1924.2870357805393
INFO:root:current train perplexity4.566531658172607
INFO:root:current mean train loss 1925.0888474429512
INFO:root:current train perplexity4.5702433586120605
INFO:root:current mean train loss 1925.5940188404709
INFO:root:current train perplexity4.571599960327148
INFO:root:current mean train loss 1926.7567914662668
INFO:root:current train perplexity4.574233531951904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.74s/it]
INFO:root:final mean train loss: 1927.081785724311
INFO:root:final train perplexity: 4.576107501983643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.51s/it]
INFO:root:eval mean loss: 1933.4886725675974
INFO:root:eval perplexity: 4.780797958374023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.25s/it]
INFO:root:eval mean loss: 2366.2881145071474
INFO:root:eval perplexity: 6.996383190155029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/36
 18%|â–ˆâ–Š        | 36/200 [8:47:17<39:47:19, 873.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.519453568892
INFO:root:current train perplexity4.749729633331299
INFO:root:current mean train loss 1935.7524139129364
INFO:root:current train perplexity4.59506368637085
INFO:root:current mean train loss 1923.0491416894995
INFO:root:current train perplexity4.582943439483643
INFO:root:current mean train loss 1934.0081276847618
INFO:root:current train perplexity4.606240272521973
INFO:root:current mean train loss 1940.0199957706052
INFO:root:current train perplexity4.627399444580078
INFO:root:current mean train loss 1942.9508216693678
INFO:root:current train perplexity4.634962558746338
INFO:root:current mean train loss 1941.8657476297183
INFO:root:current train perplexity4.633708477020264
INFO:root:current mean train loss 1942.2607524887921
INFO:root:current train perplexity4.640248775482178
INFO:root:current mean train loss 1945.0103329283388
INFO:root:current train perplexity4.648634433746338
INFO:root:current mean train loss 1947.8564646079171
INFO:root:current train perplexity4.6543049812316895
INFO:root:current mean train loss 1948.5287198482706
INFO:root:current train perplexity4.656085968017578
INFO:root:current mean train loss 1951.7852877694995
INFO:root:current train perplexity4.667963981628418
INFO:root:current mean train loss 1953.1598543502594
INFO:root:current train perplexity4.675337791442871
INFO:root:current mean train loss 1957.968365632151
INFO:root:current train perplexity4.690203666687012
INFO:root:current mean train loss 1958.7039309582078
INFO:root:current train perplexity4.692941188812256
INFO:root:current mean train loss 1961.5622879321177
INFO:root:current train perplexity4.698343276977539
INFO:root:current mean train loss 1962.9398243369558
INFO:root:current train perplexity4.704830169677734
INFO:root:current mean train loss 1966.6290363822327
INFO:root:current train perplexity4.720510959625244
INFO:root:current mean train loss 1971.4182535357925
INFO:root:current train perplexity4.735312461853027
INFO:root:current mean train loss 1973.454742894754
INFO:root:current train perplexity4.746418476104736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.18s/it]
INFO:root:final mean train loss: 1976.3627813957703
INFO:root:final train perplexity: 4.757589340209961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.14s/it]
INFO:root:eval mean loss: 1945.91080772454
INFO:root:eval perplexity: 4.829097270965576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.40s/it]
INFO:root:eval mean loss: 2373.1796385853004
INFO:root:eval perplexity: 7.036134719848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/37
 18%|â–ˆâ–Š        | 37/200 [9:01:49<39:31:44, 873.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1965.5021798270088
INFO:root:current train perplexity4.840620040893555
INFO:root:current mean train loss 2029.5575675964355
INFO:root:current train perplexity4.97849178314209
INFO:root:current mean train loss 2029.8709036843818
INFO:root:current train perplexity5.000738620758057
INFO:root:current mean train loss 2025.0267404695837
INFO:root:current train perplexity4.976512908935547
INFO:root:current mean train loss 2033.9636099271686
INFO:root:current train perplexity5.010269641876221
INFO:root:current mean train loss 2031.3942015676787
INFO:root:current train perplexity5.00008487701416
INFO:root:current mean train loss 2033.9625724257937
INFO:root:current train perplexity4.998426914215088
INFO:root:current mean train loss 2034.952348813906
INFO:root:current train perplexity4.995054721832275
INFO:root:current mean train loss 2036.6625808494678
INFO:root:current train perplexity5.001608371734619
INFO:root:current mean train loss 2034.2390691822973
INFO:root:current train perplexity4.993087291717529
INFO:root:current mean train loss 2033.7881568285277
INFO:root:current train perplexity4.988990306854248
INFO:root:current mean train loss 2031.6068153110803
INFO:root:current train perplexity4.985044002532959
INFO:root:current mean train loss 2031.2245237866132
INFO:root:current train perplexity4.983110427856445
INFO:root:current mean train loss 2030.579069758036
INFO:root:current train perplexity4.979587554931641
INFO:root:current mean train loss 2031.7919030283012
INFO:root:current train perplexity4.980527400970459
INFO:root:current mean train loss 2031.7280071318462
INFO:root:current train perplexity4.9793620109558105
INFO:root:current mean train loss 2032.7225350794686
INFO:root:current train perplexity4.980413913726807
INFO:root:current mean train loss 2033.324017771968
INFO:root:current train perplexity4.978052616119385
INFO:root:current mean train loss 2033.4737560848178
INFO:root:current train perplexity4.974437713623047
INFO:root:current mean train loss 2032.971322847105
INFO:root:current train perplexity4.9740777015686035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.24s/it]
INFO:root:final mean train loss: 2032.4643188722796
INFO:root:final train perplexity: 4.972965717315674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.47s/it]
INFO:root:eval mean loss: 1956.2449487997285
INFO:root:eval perplexity: 4.869650363922119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.87s/it]
INFO:root:eval mean loss: 2386.9590112131536
INFO:root:eval perplexity: 7.116296768188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/38
 19%|â–ˆâ–‰        | 38/200 [9:16:21<39:16:19, 872.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2012.0088704427083
INFO:root:current train perplexity4.943913459777832
INFO:root:current mean train loss 2020.2180150525323
INFO:root:current train perplexity4.956899642944336
INFO:root:current mean train loss 2016.4543706154336
INFO:root:current train perplexity4.936350345611572
INFO:root:current mean train loss 2018.3350225033967
INFO:root:current train perplexity4.9420881271362305
INFO:root:current mean train loss 2020.157765317767
INFO:root:current train perplexity4.940603733062744
INFO:root:current mean train loss 2024.433284878512
INFO:root:current train perplexity4.954672336578369
INFO:root:current mean train loss 2024.9304984632388
INFO:root:current train perplexity4.948300361633301
INFO:root:current mean train loss 2025.6249365889787
INFO:root:current train perplexity4.950190544128418
INFO:root:current mean train loss 2026.515279880501
INFO:root:current train perplexity4.954397678375244
INFO:root:current mean train loss 2025.6924011553406
INFO:root:current train perplexity4.9547600746154785
INFO:root:current mean train loss 2026.8165880121112
INFO:root:current train perplexity4.95961856842041
INFO:root:current mean train loss 2027.391136415973
INFO:root:current train perplexity4.956573009490967
INFO:root:current mean train loss 2027.632227444936
INFO:root:current train perplexity4.954360485076904
INFO:root:current mean train loss 2028.2926108888535
INFO:root:current train perplexity4.957906723022461
INFO:root:current mean train loss 2028.3953451928796
INFO:root:current train perplexity4.958774566650391
INFO:root:current mean train loss 2028.4746868047127
INFO:root:current train perplexity4.956027984619141
INFO:root:current mean train loss 2028.1260900248149
INFO:root:current train perplexity4.955196857452393
INFO:root:current mean train loss 2029.25442761965
INFO:root:current train perplexity4.956119537353516
INFO:root:current mean train loss 2029.6386168275744
INFO:root:current train perplexity4.958323955535889
INFO:root:current mean train loss 2029.8613479575033
INFO:root:current train perplexity4.959166526794434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.73s/it]
INFO:root:final mean train loss: 2028.3627583729276
INFO:root:final train perplexity: 4.956894874572754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.15s/it]
INFO:root:eval mean loss: 1976.0219886725677
INFO:root:eval perplexity: 4.948210716247559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.11s/it]
INFO:root:eval mean loss: 2405.087821365248
INFO:root:eval perplexity: 7.223153114318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/39
 20%|â–ˆâ–‰        | 39/200 [9:30:47<38:56:50, 870.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2053.0027268932713
INFO:root:current train perplexity5.030357360839844
INFO:root:current mean train loss 2029.492806893808
INFO:root:current train perplexity4.981958389282227
INFO:root:current mean train loss 2025.326413686039
INFO:root:current train perplexity4.98747444152832
INFO:root:current mean train loss 2024.7114547813794
INFO:root:current train perplexity4.961386203765869
INFO:root:current mean train loss 2024.9212749530743
INFO:root:current train perplexity4.947279453277588
INFO:root:current mean train loss 2026.7334640340025
INFO:root:current train perplexity4.958506107330322
INFO:root:current mean train loss 2026.2572486162906
INFO:root:current train perplexity4.965506553649902
INFO:root:current mean train loss 2026.5692704168205
INFO:root:current train perplexity4.962038516998291
INFO:root:current mean train loss 2028.456478959723
INFO:root:current train perplexity4.9658026695251465
INFO:root:current mean train loss 2027.829397855826
INFO:root:current train perplexity4.968873977661133
INFO:root:current mean train loss 2027.8913328239025
INFO:root:current train perplexity4.963583946228027
INFO:root:current mean train loss 2029.0808900711663
INFO:root:current train perplexity4.968109607696533
INFO:root:current mean train loss 2028.8817702594158
INFO:root:current train perplexity4.966699600219727
INFO:root:current mean train loss 2029.1131636609764
INFO:root:current train perplexity4.968416690826416
INFO:root:current mean train loss 2028.42475959997
INFO:root:current train perplexity4.96545934677124
INFO:root:current mean train loss 2028.6842799852202
INFO:root:current train perplexity4.962740898132324
INFO:root:current mean train loss 2028.4525644460741
INFO:root:current train perplexity4.962001323699951
INFO:root:current mean train loss 2030.1675659595364
INFO:root:current train perplexity4.966979026794434
INFO:root:current mean train loss 2031.2569541398489
INFO:root:current train perplexity4.967992782592773
INFO:root:current mean train loss 2031.5358158154347
INFO:root:current train perplexity4.96747350692749

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.62s/it]
INFO:root:final mean train loss: 2030.9748623184767
INFO:root:final train perplexity: 4.967123508453369
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.71s/it]
INFO:root:eval mean loss: 1962.6124730752715
INFO:root:eval perplexity: 4.8948073387146
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.93s/it]
INFO:root:eval mean loss: 2391.4783818671044
INFO:root:eval perplexity: 7.142787456512451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/40
 20%|â–ˆâ–ˆ        | 40/200 [9:45:20<38:44:00, 871.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2035.1024015402493
INFO:root:current train perplexity4.934747219085693
INFO:root:current mean train loss 2036.8205702797661
INFO:root:current train perplexity4.976222991943359
INFO:root:current mean train loss 2041.479769580253
INFO:root:current train perplexity4.9821882247924805
INFO:root:current mean train loss 2037.619173155611
INFO:root:current train perplexity4.976505279541016
INFO:root:current mean train loss 2035.3473547694578
INFO:root:current train perplexity4.969574451446533
INFO:root:current mean train loss 2037.7068646946514
INFO:root:current train perplexity4.974265098571777
INFO:root:current mean train loss 2040.5675570188812
INFO:root:current train perplexity4.985639572143555
INFO:root:current mean train loss 2043.583982807987
INFO:root:current train perplexity4.999327182769775
INFO:root:current mean train loss 2037.9350694259278
INFO:root:current train perplexity4.991306781768799
INFO:root:current mean train loss 2035.2518193339424
INFO:root:current train perplexity4.980114459991455
INFO:root:current mean train loss 2034.8679805610664
INFO:root:current train perplexity4.981589317321777
INFO:root:current mean train loss 2034.1995325711341
INFO:root:current train perplexity4.9761457443237305
INFO:root:current mean train loss 2033.8030284317888
INFO:root:current train perplexity4.9773101806640625
INFO:root:current mean train loss 2036.0708903643945
INFO:root:current train perplexity4.981767177581787
INFO:root:current mean train loss 2036.7408305304207
INFO:root:current train perplexity4.983128547668457
INFO:root:current mean train loss 2036.5919763083093
INFO:root:current train perplexity4.984474182128906
INFO:root:current mean train loss 2037.3162965393976
INFO:root:current train perplexity4.989675521850586
INFO:root:current mean train loss 2037.288469371399
INFO:root:current train perplexity4.990381240844727
INFO:root:current mean train loss 2037.935792964592
INFO:root:current train perplexity4.993162631988525
INFO:root:current mean train loss 2038.3469520788592
INFO:root:current train perplexity4.993879318237305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.95s/it]
INFO:root:final mean train loss: 2037.827103807658
INFO:root:final train perplexity: 4.994057655334473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 57.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.01s/it]
INFO:root:eval mean loss: 1966.4710922782303
INFO:root:eval perplexity: 4.9101152420043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.05s/it]
INFO:root:eval mean loss: 2397.9462306245846
INFO:root:eval perplexity: 7.180868148803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/41
 20%|â–ˆâ–ˆ        | 41/200 [9:59:52<38:29:26, 871.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2067.846420288086
INFO:root:current train perplexity5.075517177581787
INFO:root:current mean train loss 2063.4253845214844
INFO:root:current train perplexity5.0513529777526855
INFO:root:current mean train loss 2076.9425547831765
INFO:root:current train perplexity5.085302352905273
INFO:root:current mean train loss 2077.119525023181
INFO:root:current train perplexity5.098495960235596
INFO:root:current mean train loss 2079.4269903859786
INFO:root:current train perplexity5.107876777648926
INFO:root:current mean train loss 2076.4560112665163
INFO:root:current train perplexity5.1044230461120605
INFO:root:current mean train loss 2069.2325521885664
INFO:root:current train perplexity5.090014457702637
INFO:root:current mean train loss 2069.8073636922404
INFO:root:current train perplexity5.094306945800781
INFO:root:current mean train loss 2066.335525103978
INFO:root:current train perplexity5.093159198760986
INFO:root:current mean train loss 2067.48368351335
INFO:root:current train perplexity5.087236404418945
INFO:root:current mean train loss 2066.248027272468
INFO:root:current train perplexity5.084756851196289
INFO:root:current mean train loss 2065.3910407126946
INFO:root:current train perplexity5.081801891326904
INFO:root:current mean train loss 2064.4381508532865
INFO:root:current train perplexity5.080259323120117
INFO:root:current mean train loss 2063.8091110622986
INFO:root:current train perplexity5.081413745880127
INFO:root:current mean train loss 2063.4985180207113
INFO:root:current train perplexity5.082486629486084
INFO:root:current mean train loss 2065.6962560973966
INFO:root:current train perplexity5.093746662139893
INFO:root:current mean train loss 2066.1383540315446
INFO:root:current train perplexity5.098829746246338
INFO:root:current mean train loss 2065.8962343211692
INFO:root:current train perplexity5.102545261383057
INFO:root:current mean train loss 2065.9697300391863
INFO:root:current train perplexity5.105401515960693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.45s/it]
INFO:root:final mean train loss: 2065.7130468294467
INFO:root:final train perplexity: 5.105183124542236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.46s/it]
INFO:root:eval mean loss: 1977.1725888083167
INFO:root:eval perplexity: 4.952820777893066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.40s/it]
INFO:root:eval mean loss: 2408.1223564418497
INFO:root:eval perplexity: 7.241196155548096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/42
 21%|â–ˆâ–ˆ        | 42/200 [10:14:24<38:15:12, 871.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2049.2854285606973
INFO:root:current train perplexity5.022871494293213
INFO:root:current mean train loss 2061.4226398299224
INFO:root:current train perplexity5.068605422973633
INFO:root:current mean train loss 2046.119161829702
INFO:root:current train perplexity5.028780937194824
INFO:root:current mean train loss 2050.271288204498
INFO:root:current train perplexity5.035401344299316
INFO:root:current mean train loss 2047.50845093069
INFO:root:current train perplexity5.0315399169921875
INFO:root:current mean train loss 2051.506965860289
INFO:root:current train perplexity5.03525447845459
INFO:root:current mean train loss 2053.8593295970127
INFO:root:current train perplexity5.035006523132324
INFO:root:current mean train loss 2051.654253730934
INFO:root:current train perplexity5.034538745880127
INFO:root:current mean train loss 2057.3271535425315
INFO:root:current train perplexity5.049267292022705
INFO:root:current mean train loss 2055.5081418090685
INFO:root:current train perplexity5.047738075256348
INFO:root:current mean train loss 2057.6988795319057
INFO:root:current train perplexity5.064218044281006
INFO:root:current mean train loss 2055.8147254525707
INFO:root:current train perplexity5.058236598968506
INFO:root:current mean train loss 2054.5611731269
INFO:root:current train perplexity5.056697845458984
INFO:root:current mean train loss 2055.329726138554
INFO:root:current train perplexity5.058487892150879
INFO:root:current mean train loss 2054.4087827214094
INFO:root:current train perplexity5.060201644897461
INFO:root:current mean train loss 2055.1725688563697
INFO:root:current train perplexity5.065505027770996
INFO:root:current mean train loss 2058.2287877668746
INFO:root:current train perplexity5.070449352264404
INFO:root:current mean train loss 2058.5007032048125
INFO:root:current train perplexity5.071562767028809
INFO:root:current mean train loss 2058.446215874177
INFO:root:current train perplexity5.071367263793945
INFO:root:current mean train loss 2058.7226991947573
INFO:root:current train perplexity5.0718793869018555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.71s/it]
INFO:root:final mean train loss: 2057.242947746273
INFO:root:final train perplexity: 5.071170806884766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.52s/it]
INFO:root:eval mean loss: 1970.3821012889239
INFO:root:eval perplexity: 4.925680160522461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.23s/it]
INFO:root:eval mean loss: 2402.67796033494
INFO:root:eval perplexity: 7.208858966827393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/43
 22%|â–ˆâ–ˆâ–       | 43/200 [10:28:54<37:59:24, 871.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2049.8266723632814
INFO:root:current train perplexity5.054547309875488
INFO:root:current mean train loss 2045.0305926983174
INFO:root:current train perplexity5.0204267501831055
INFO:root:current mean train loss 2043.4040070906929
INFO:root:current train perplexity5.01179313659668
INFO:root:current mean train loss 2041.4422100645122
INFO:root:current train perplexity5.006071090698242
INFO:root:current mean train loss 2042.8851201966752
INFO:root:current train perplexity5.014537811279297
INFO:root:current mean train loss 2045.909326171875
INFO:root:current train perplexity5.028274059295654
INFO:root:current mean train loss 2045.306453062996
INFO:root:current train perplexity5.0266923904418945
INFO:root:current mean train loss 2045.4688441446383
INFO:root:current train perplexity5.0239152908325195
INFO:root:current mean train loss 2047.9005481398249
INFO:root:current train perplexity5.034551620483398
INFO:root:current mean train loss 2049.9831351331486
INFO:root:current train perplexity5.044676303863525
INFO:root:current mean train loss 2048.817905818606
INFO:root:current train perplexity5.04426908493042
INFO:root:current mean train loss 2047.8791812862971
INFO:root:current train perplexity5.0449042320251465
INFO:root:current mean train loss 2049.6399721719386
INFO:root:current train perplexity5.045460224151611
INFO:root:current mean train loss 2051.1225071039416
INFO:root:current train perplexity5.050084590911865
INFO:root:current mean train loss 2050.264414881993
INFO:root:current train perplexity5.04878568649292
INFO:root:current mean train loss 2051.045712060866
INFO:root:current train perplexity5.049909591674805
INFO:root:current mean train loss 2051.245746935511
INFO:root:current train perplexity5.05142068862915
INFO:root:current mean train loss 2052.210233090792
INFO:root:current train perplexity5.052922248840332
INFO:root:current mean train loss 2051.987453306438
INFO:root:current train perplexity5.054877758026123
INFO:root:current mean train loss 2053.552121366985
INFO:root:current train perplexity5.056247234344482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.11s/it]
INFO:root:final mean train loss: 2053.8754293698585
INFO:root:final train perplexity: 5.057710647583008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.30s/it]
INFO:root:eval mean loss: 1973.554223459663
INFO:root:eval perplexity: 4.938338756561279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.98s/it]
INFO:root:eval mean loss: 2405.9990437825522
INFO:root:eval perplexity: 7.228567123413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/44
 22%|â–ˆâ–ˆâ–       | 44/200 [10:43:28<37:47:03, 871.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2048.128168633644
INFO:root:current train perplexity5.031429290771484
INFO:root:current mean train loss 2044.4353816233524
INFO:root:current train perplexity5.061029434204102
INFO:root:current mean train loss 2050.506798377404
INFO:root:current train perplexity5.070174217224121
INFO:root:current mean train loss 2062.057783583056
INFO:root:current train perplexity5.078430652618408
INFO:root:current mean train loss 2068.0366445793134
INFO:root:current train perplexity5.1189775466918945
INFO:root:current mean train loss 2067.699224552245
INFO:root:current train perplexity5.113321781158447
INFO:root:current mean train loss 2070.5645338763043
INFO:root:current train perplexity5.118307590484619
INFO:root:current mean train loss 2070.1078513271837
INFO:root:current train perplexity5.118474960327148
INFO:root:current mean train loss 2070.2404901894092
INFO:root:current train perplexity5.117580890655518
INFO:root:current mean train loss 2071.652524212975
INFO:root:current train perplexity5.125144004821777
INFO:root:current mean train loss 2075.0904488549872
INFO:root:current train perplexity5.134496688842773
INFO:root:current mean train loss 2074.670841393309
INFO:root:current train perplexity5.135487079620361
INFO:root:current mean train loss 2073.5638729239236
INFO:root:current train perplexity5.134734630584717
INFO:root:current mean train loss 2074.940838763514
INFO:root:current train perplexity5.1408820152282715
INFO:root:current mean train loss 2074.605735668085
INFO:root:current train perplexity5.141441822052002
INFO:root:current mean train loss 2076.5362358660414
INFO:root:current train perplexity5.147510051727295
INFO:root:current mean train loss 2078.298127499217
INFO:root:current train perplexity5.151721000671387
INFO:root:current mean train loss 2078.263171226008
INFO:root:current train perplexity5.150664329528809
INFO:root:current mean train loss 2078.334934633231
INFO:root:current train perplexity5.152810096740723
INFO:root:current mean train loss 2078.7279489102825
INFO:root:current train perplexity5.1549763679504395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.32s/it]
INFO:root:final mean train loss: 2077.977849870875
INFO:root:final train perplexity: 5.154837608337402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.94s/it]
INFO:root:eval mean loss: 1990.69016736619
INFO:root:eval perplexity: 5.007294654846191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.64s/it]
INFO:root:eval mean loss: 2424.4345642522717
INFO:root:eval perplexity: 7.338960647583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [10:58:00<37:32:52, 872.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2083.124349594116
INFO:root:current train perplexity5.129587173461914
INFO:root:current mean train loss 2100.1241953780013
INFO:root:current train perplexity5.214178085327148
INFO:root:current mean train loss 2096.136133367365
INFO:root:current train perplexity5.215880393981934
INFO:root:current mean train loss 2090.147686633435
INFO:root:current train perplexity5.192791938781738
INFO:root:current mean train loss 2088.271931615369
INFO:root:current train perplexity5.181680679321289
INFO:root:current mean train loss 2087.9692839493987
INFO:root:current train perplexity5.182714939117432
INFO:root:current mean train loss 2086.7229833028405
INFO:root:current train perplexity5.180295467376709
INFO:root:current mean train loss 2089.3349447999326
INFO:root:current train perplexity5.194079875946045
INFO:root:current mean train loss 2090.27881692957
INFO:root:current train perplexity5.195071220397949
INFO:root:current mean train loss 2089.504201548723
INFO:root:current train perplexity5.193596839904785
INFO:root:current mean train loss 2088.7056212461084
INFO:root:current train perplexity5.194851875305176
INFO:root:current mean train loss 2092.2251907820555
INFO:root:current train perplexity5.2039008140563965
INFO:root:current mean train loss 2092.3162160945844
INFO:root:current train perplexity5.205666542053223
INFO:root:current mean train loss 2091.683982424023
INFO:root:current train perplexity5.202261924743652
INFO:root:current mean train loss 2091.990501695643
INFO:root:current train perplexity5.204676628112793
INFO:root:current mean train loss 2092.480658333625
INFO:root:current train perplexity5.209446430206299
INFO:root:current mean train loss 2092.4169475115264
INFO:root:current train perplexity5.2141313552856445
INFO:root:current mean train loss 2092.2103121318514
INFO:root:current train perplexity5.213591575622559
INFO:root:current mean train loss 2092.704585717983
INFO:root:current train perplexity5.213347911834717
INFO:root:current mean train loss 2092.755848373755
INFO:root:current train perplexity5.212057113647461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.67s/it]
INFO:root:final mean train loss: 2092.036629496472
INFO:root:final train perplexity: 5.212349891662598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.10s/it]
INFO:root:eval mean loss: 1991.4193738572142
INFO:root:eval perplexity: 5.010250091552734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.86s/it]
INFO:root:eval mean loss: 2426.0592703312
INFO:root:eval perplexity: 7.348769187927246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [11:12:33<37:19:09, 872.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2095.9236337167245
INFO:root:current train perplexity5.234933376312256
INFO:root:current mean train loss 2103.2504801881905
INFO:root:current train perplexity5.278933525085449
INFO:root:current mean train loss 2090.324580182384
INFO:root:current train perplexity5.217201232910156
INFO:root:current mean train loss 2095.444919375923
INFO:root:current train perplexity5.2245402336120605
INFO:root:current mean train loss 2106.553443956276
INFO:root:current train perplexity5.252610683441162
INFO:root:current mean train loss 2104.1728381158564
INFO:root:current train perplexity5.247031211853027
INFO:root:current mean train loss 2105.9807171926623
INFO:root:current train perplexity5.254602909088135
INFO:root:current mean train loss 2104.517246143766
INFO:root:current train perplexity5.254354953765869
INFO:root:current mean train loss 2108.480686010216
INFO:root:current train perplexity5.2715983390808105
INFO:root:current mean train loss 2111.1121501397647
INFO:root:current train perplexity5.284912586212158
INFO:root:current mean train loss 2112.402445945775
INFO:root:current train perplexity5.289022922515869
INFO:root:current mean train loss 2115.6701717005253
INFO:root:current train perplexity5.301816940307617
INFO:root:current mean train loss 2117.109120663026
INFO:root:current train perplexity5.312633037567139
INFO:root:current mean train loss 2118.14725073967
INFO:root:current train perplexity5.323058128356934
INFO:root:current mean train loss 2118.5616070156884
INFO:root:current train perplexity5.32301139831543
INFO:root:current mean train loss 2117.329085348227
INFO:root:current train perplexity5.318408966064453
INFO:root:current mean train loss 2116.915031655497
INFO:root:current train perplexity5.317722797393799
INFO:root:current mean train loss 2118.810932962631
INFO:root:current train perplexity5.324693202972412
INFO:root:current mean train loss 2119.872607201227
INFO:root:current train perplexity5.328038692474365
INFO:root:current mean train loss 2123.73152129064
INFO:root:current train perplexity5.341714859008789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.07s/it]
INFO:root:final mean train loss: 2123.2490446135907
INFO:root:final train perplexity: 5.342339038848877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.11s/it]
INFO:root:eval mean loss: 2028.3401073699301
INFO:root:eval perplexity: 5.162198543548584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.46s/it]
INFO:root:eval mean loss: 2465.2006831608765
INFO:root:eval perplexity: 7.5890936851501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [11:27:05<37:04:25, 872.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2288.7021247708067
INFO:root:current train perplexity6.07343864440918
INFO:root:current mean train loss 2247.128977149424
INFO:root:current train perplexity5.902606964111328
INFO:root:current mean train loss 2240.1769220749
INFO:root:current train perplexity5.8518195152282715
INFO:root:current mean train loss 2321.5844524134345
INFO:root:current train perplexity6.2493791580200195
INFO:root:current mean train loss 2424.3135672573103
INFO:root:current train perplexity6.777472019195557
INFO:root:current mean train loss 2511.0378952791857
INFO:root:current train perplexity7.271242141723633
INFO:root:current mean train loss 3093.5977370472556
INFO:root:current train perplexity11.52098274230957
INFO:root:current mean train loss 3759.4052027652137
INFO:root:current train perplexity19.47472381591797
INFO:root:current mean train loss 4471.295650762545
INFO:root:current train perplexity34.12874221801758
INFO:root:current mean train loss 5226.142718297924
INFO:root:current train perplexity61.98965072631836
INFO:root:current mean train loss 5831.997589055741
INFO:root:current train perplexity99.94027709960938
INFO:root:current mean train loss 6262.421212478153
INFO:root:current train perplexity140.4319610595703
INFO:root:current mean train loss 6625.939670744956
INFO:root:current train perplexity185.87940979003906
INFO:root:current mean train loss 6920.180382025941
INFO:root:current train perplexity234.30206298828125
INFO:root:current mean train loss 7173.303497273709
INFO:root:current train perplexity286.4551086425781
INFO:root:current mean train loss 7369.14338250572
INFO:root:current train perplexity334.07232666015625
INFO:root:current mean train loss 7467.206338655541
INFO:root:current train perplexity361.7160949707031
INFO:root:current mean train loss 7561.583191800569
INFO:root:current train perplexity390.0406188964844
INFO:root:current mean train loss 7626.288647409486
INFO:root:current train perplexity409.8907165527344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.95s/it]
INFO:root:final mean train loss: 7660.330594723116
INFO:root:final train perplexity: 422.2159729003906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it]
INFO:root:eval mean loss: 8338.942431294327
INFO:root:eval perplexity: 852.3480224609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.36s/it]
INFO:root:eval mean loss: 8473.482702376994
INFO:root:eval perplexity: 1060.2847900390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/48
 24%|â–ˆâ–ˆâ–       | 48/200 [11:41:37<36:49:41, 872.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8530.83828125
INFO:root:current train perplexity969.8301391601562
INFO:root:current mean train loss 8348.25793138587
INFO:root:current train perplexity740.9312133789062
INFO:root:current mean train loss 8258.557973746367
INFO:root:current train perplexity683.5532836914062
INFO:root:current mean train loss 8166.6958984375
INFO:root:current train perplexity632.0237426757812
INFO:root:current mean train loss 8106.515663827184
INFO:root:current train perplexity597.135009765625
INFO:root:current mean train loss 8045.758077973301
INFO:root:current train perplexity578.0603637695312
INFO:root:current mean train loss 8043.33421144563
INFO:root:current train perplexity576.0684204101562
INFO:root:current mean train loss 8046.680603966346
INFO:root:current train perplexity578.3357543945312
INFO:root:current mean train loss 8061.3264630463955
INFO:root:current train perplexity584.1307373046875
INFO:root:current mean train loss 8068.7458765582305
INFO:root:current train perplexity583.2348022460938
INFO:root:current mean train loss 8037.9205602486145
INFO:root:current train perplexity569.8201293945312
INFO:root:current mean train loss 8024.133390554933
INFO:root:current train perplexity564.7269287109375
INFO:root:current mean train loss 8016.074418483153
INFO:root:current train perplexity562.0126342773438
INFO:root:current mean train loss 8018.325819495603
INFO:root:current train perplexity560.2713012695312
INFO:root:current mean train loss 8013.057906015349
INFO:root:current train perplexity556.067626953125
INFO:root:current mean train loss 8001.368659112005
INFO:root:current train perplexity551.2014770507812
INFO:root:current mean train loss 7997.3926612688665
INFO:root:current train perplexity549.6589965820312
INFO:root:current mean train loss 7986.863117825255
INFO:root:current train perplexity545.0053100585938
INFO:root:current mean train loss 7956.469975142046
INFO:root:current train perplexity533.0956420898438
INFO:root:current mean train loss 7935.18720703125
INFO:root:current train perplexity524.33447265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.47s/it]
INFO:root:final mean train loss: 7921.921041622345
INFO:root:final train perplexity: 519.03076171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it]
INFO:root:eval mean loss: 5943.094523977726
INFO:root:eval perplexity: 122.63835906982422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.25s/it]
INFO:root:eval mean loss: 6096.731514572251
INFO:root:eval perplexity: 150.2495574951172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/49
 24%|â–ˆâ–ˆâ–       | 49/200 [11:56:08<36:33:54, 871.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7316.206497192383
INFO:root:current train perplexity312.03887939453125
INFO:root:current mean train loss 7382.464148319129
INFO:root:current train perplexity340.811767578125
INFO:root:current mean train loss 7298.425770726697
INFO:root:current train perplexity322.6768493652344
INFO:root:current mean train loss 7316.823976080102
INFO:root:current train perplexity323.98333740234375
INFO:root:current mean train loss 7403.472869873047
INFO:root:current train perplexity343.58209228515625
INFO:root:current mean train loss 7379.989621269971
INFO:root:current train perplexity335.8841247558594
INFO:root:current mean train loss 7334.002855518196
INFO:root:current train perplexity326.1246337890625
INFO:root:current mean train loss 7297.112927045979
INFO:root:current train perplexity314.9585266113281
INFO:root:current mean train loss 7270.402235764724
INFO:root:current train perplexity310.0608825683594
INFO:root:current mean train loss 7387.492460455505
INFO:root:current train perplexity339.5701599121094
INFO:root:current mean train loss 7592.539874882661
INFO:root:current train perplexity397.9512634277344
INFO:root:current mean train loss 7678.541658758696
INFO:root:current train perplexity424.800048828125
INFO:root:current mean train loss 7713.559105018517
INFO:root:current train perplexity436.9708251953125
INFO:root:current mean train loss 7695.879250466287
INFO:root:current train perplexity430.46112060546875
INFO:root:current mean train loss 7670.0100653451245
INFO:root:current train perplexity422.2373046875
INFO:root:current mean train loss 7625.046367595463
INFO:root:current train perplexity408.11285400390625
INFO:root:current mean train loss 7553.59022881003
INFO:root:current train perplexity386.54498291015625
INFO:root:current mean train loss 7468.91452512675
INFO:root:current train perplexity362.009765625
INFO:root:current mean train loss 7390.983691619474
INFO:root:current train perplexity340.3537902832031
INFO:root:current mean train loss 7318.1859130859375
INFO:root:current train perplexity322.2203674316406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.61s/it]
INFO:root:final mean train loss: 7285.324323768635
INFO:root:final train perplexity: 314.05316162109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.93s/it]
INFO:root:eval mean loss: 4480.66377247479
INFO:root:eval perplexity: 37.55546569824219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.27s/it]
INFO:root:eval mean loss: 4674.2151285807295
INFO:root:eval perplexity: 46.656211853027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [12:10:39<36:19:00, 871.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6112.599738919005
INFO:root:current train perplexity119.07291412353516
INFO:root:current mean train loss 6061.506665530621
INFO:root:current train perplexity117.29082489013672
INFO:root:current mean train loss 6068.556864175452
INFO:root:current train perplexity118.30424499511719
INFO:root:current mean train loss 6094.7638019900605
INFO:root:current train perplexity121.7121810913086
INFO:root:current mean train loss 6102.179647263015
INFO:root:current train perplexity122.20084381103516
INFO:root:current mean train loss 6108.695183536828
INFO:root:current train perplexity122.61689758300781
INFO:root:current mean train loss 6112.180823562692
INFO:root:current train perplexity123.42707061767578
INFO:root:current mean train loss 6120.758553722672
INFO:root:current train perplexity123.89496612548828
INFO:root:current mean train loss 6124.298479024035
INFO:root:current train perplexity124.06842041015625
INFO:root:current mean train loss 6124.151214374506
INFO:root:current train perplexity124.00555419921875
INFO:root:current mean train loss 6127.983546923409
INFO:root:current train perplexity124.64824676513672
INFO:root:current mean train loss 6135.221317619941
INFO:root:current train perplexity125.65666961669922
INFO:root:current mean train loss 6142.423192851156
INFO:root:current train perplexity126.68182373046875
INFO:root:current mean train loss 6156.425239037018
INFO:root:current train perplexity128.00079345703125
INFO:root:current mean train loss 6162.095149806979
INFO:root:current train perplexity129.09222412109375
INFO:root:current mean train loss 6163.25333317362
INFO:root:current train perplexity129.52464294433594
INFO:root:current mean train loss 6165.761659232395
INFO:root:current train perplexity130.02450561523438
INFO:root:current mean train loss 6171.128114502931
INFO:root:current train perplexity130.4902801513672
INFO:root:current mean train loss 6173.426140660915
INFO:root:current train perplexity130.82041931152344
INFO:root:current mean train loss 6175.647699942278
INFO:root:current train perplexity130.85772705078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.09s/it]
INFO:root:final mean train loss: 6176.094470479545
INFO:root:final train perplexity: 130.86415100097656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.73s/it]
INFO:root:eval mean loss: 4812.236483959441
INFO:root:eval perplexity: 49.11342239379883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.60s/it]
INFO:root:eval mean loss: 4939.696071760029
INFO:root:eval perplexity: 58.03615188598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [12:25:10<36:03:56, 871.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6248.924042672822
INFO:root:current train perplexity132.27239990234375
INFO:root:current mean train loss 6174.952527884978
INFO:root:current train perplexity127.83683776855469
INFO:root:current mean train loss 6179.337811692317
INFO:root:current train perplexity128.77357482910156
INFO:root:current mean train loss 6207.228814463798
INFO:root:current train perplexity132.88807678222656
INFO:root:current mean train loss 6312.553366206746
INFO:root:current train perplexity144.0211639404297
INFO:root:current mean train loss 6423.438949315371
INFO:root:current train perplexity158.42501831054688
INFO:root:current mean train loss 6549.455428573105
INFO:root:current train perplexity175.3668670654297
INFO:root:current mean train loss 6671.477451095382
INFO:root:current train perplexity193.87420654296875
INFO:root:current mean train loss 6770.548032553587
INFO:root:current train perplexity209.2682647705078
INFO:root:current mean train loss 6850.5358623875845
INFO:root:current train perplexity223.54690551757812
INFO:root:current mean train loss 6918.847876572027
INFO:root:current train perplexity236.42115783691406
INFO:root:current mean train loss 6969.684321984214
INFO:root:current train perplexity247.6683807373047
INFO:root:current mean train loss 7026.1414341738255
INFO:root:current train perplexity257.6405029296875
INFO:root:current mean train loss 7064.966445498376
INFO:root:current train perplexity265.6283264160156
INFO:root:current mean train loss 7100.816729661387
INFO:root:current train perplexity272.6039123535156
INFO:root:current mean train loss 7131.120837449114
INFO:root:current train perplexity279.5722351074219
INFO:root:current mean train loss 7170.855498644771
INFO:root:current train perplexity287.5646057128906
INFO:root:current mean train loss 7204.089501731933
INFO:root:current train perplexity295.0664367675781
INFO:root:current mean train loss 7231.736460793057
INFO:root:current train perplexity301.3138122558594
INFO:root:current mean train loss 7251.487100036559
INFO:root:current train perplexity305.2442321777344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.63s/it]
INFO:root:final mean train loss: 7250.650098099471
INFO:root:final train perplexity: 305.5755615234375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.49s/it]
INFO:root:eval mean loss: 7212.645642869016
INFO:root:eval perplexity: 342.605224609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.62s/it]
INFO:root:eval mean loss: 7307.13847102172
INFO:root:eval perplexity: 406.4285583496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [12:39:39<35:47:51, 870.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7395.167756965361
INFO:root:current train perplexity349.4876403808594
INFO:root:current mean train loss 7422.436886313183
INFO:root:current train perplexity355.45538330078125
INFO:root:current mean train loss 7411.90216603633
INFO:root:current train perplexity352.0181579589844
INFO:root:current mean train loss 7414.369325483437
INFO:root:current train perplexity352.19158935546875
INFO:root:current mean train loss 7407.171640463251
INFO:root:current train perplexity351.4180908203125
INFO:root:current mean train loss 7411.838529662039
INFO:root:current train perplexity350.6611633300781
INFO:root:current mean train loss 7411.657822794656
INFO:root:current train perplexity349.921875
INFO:root:current mean train loss 7414.291258206617
INFO:root:current train perplexity349.41400146484375
INFO:root:current mean train loss 7408.939047790735
INFO:root:current train perplexity347.7574462890625
INFO:root:current mean train loss 7402.435846400528
INFO:root:current train perplexity346.6442565917969
INFO:root:current mean train loss 7378.518961363112
INFO:root:current train perplexity340.4209899902344
INFO:root:current mean train loss 7378.150453775492
INFO:root:current train perplexity339.59832763671875
INFO:root:current mean train loss 7372.067648836345
INFO:root:current train perplexity337.34075927734375
INFO:root:current mean train loss 7337.4607899211405
INFO:root:current train perplexity327.4366455078125
INFO:root:current mean train loss 7275.79459821993
INFO:root:current train perplexity311.80804443359375
INFO:root:current mean train loss 7218.095601335479
INFO:root:current train perplexity297.91900634765625
INFO:root:current mean train loss 7195.5170910042525
INFO:root:current train perplexity292.4884948730469
INFO:root:current mean train loss 7179.450574326101
INFO:root:current train perplexity288.5074768066406
INFO:root:current mean train loss 7171.385627313048
INFO:root:current train perplexity286.8030700683594
INFO:root:current mean train loss 7150.027429069946
INFO:root:current train perplexity282.24798583984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.17s/it]
INFO:root:final mean train loss: 7150.027429069946
INFO:root:final train perplexity: 282.24798583984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it]
INFO:root:eval mean loss: 6001.182591215093
INFO:root:eval perplexity: 128.5406951904297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.69s/it]
INFO:root:eval mean loss: 6298.177831338652
INFO:root:eval perplexity: 177.31231689453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [12:54:11<35:34:19, 871.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6487.2315625
INFO:root:current train perplexity170.72779846191406
INFO:root:current mean train loss 6488.683706054688
INFO:root:current train perplexity166.6317138671875
INFO:root:current mean train loss 6458.752578125
INFO:root:current train perplexity161.98031616210938
INFO:root:current mean train loss 6416.600874023437
INFO:root:current train perplexity157.5877227783203
INFO:root:current mean train loss 6416.117639648438
INFO:root:current train perplexity157.5989227294922
INFO:root:current mean train loss 6445.894213867187
INFO:root:current train perplexity160.20376586914062
INFO:root:current mean train loss 6499.652823660715
INFO:root:current train perplexity167.32705688476562
INFO:root:current mean train loss 6513.364863891602
INFO:root:current train perplexity169.99887084960938
INFO:root:current mean train loss 6465.307232530382
INFO:root:current train perplexity163.83851623535156
INFO:root:current mean train loss 6472.399933105468
INFO:root:current train perplexity165.08517456054688
INFO:root:current mean train loss 6505.165539328836
INFO:root:current train perplexity169.3893280029297
INFO:root:current mean train loss 6526.050262044271
INFO:root:current train perplexity171.9447784423828
INFO:root:current mean train loss 6546.068584735577
INFO:root:current train perplexity174.63478088378906
INFO:root:current mean train loss 6572.818971819196
INFO:root:current train perplexity178.3015899658203
INFO:root:current mean train loss 6599.727740559896
INFO:root:current train perplexity182.30555725097656
INFO:root:current mean train loss 6619.106727294922
INFO:root:current train perplexity185.65512084960938
INFO:root:current mean train loss 6631.398102309283
INFO:root:current train perplexity187.72206115722656
INFO:root:current mean train loss 6634.115085720486
INFO:root:current train perplexity188.02978515625
INFO:root:current mean train loss 6654.247385639392
INFO:root:current train perplexity191.0493927001953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:22<00:00, 742.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:22<00:00, 742.67s/it]
INFO:root:final mean train loss: 6672.354337306559
INFO:root:final train perplexity: 193.60260009765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.39s/it]
INFO:root:eval mean loss: 6610.302334399934
INFO:root:eval perplexity: 210.4302978515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 54.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.01s/it]
INFO:root:eval mean loss: 6827.992739846521
INFO:root:eval perplexity: 274.09869384765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [13:08:29<35:09:53, 867.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7151.998420266544
INFO:root:current train perplexity242.4041290283203
INFO:root:current mean train loss 7195.112041766827
INFO:root:current train perplexity275.59442138671875
INFO:root:current mean train loss 6970.377841931883
INFO:root:current train perplexity238.52210998535156
INFO:root:current mean train loss 6852.387749223679
INFO:root:current train perplexity219.3201446533203
INFO:root:current mean train loss 6819.253777446793
INFO:root:current train perplexity214.19056701660156
INFO:root:current mean train loss 6781.322842684659
INFO:root:current train perplexity209.9298858642578
INFO:root:current mean train loss 6771.262088324301
INFO:root:current train perplexity208.1209716796875
INFO:root:current mean train loss 6781.12246325292
INFO:root:current train perplexity210.1900177001953
INFO:root:current mean train loss 6818.805419025398
INFO:root:current train perplexity216.79837036132812
INFO:root:current mean train loss 6843.844072680957
INFO:root:current train perplexity221.53517150878906
INFO:root:current mean train loss 6838.833757278608
INFO:root:current train perplexity220.88214111328125
INFO:root:current mean train loss 6855.173448690689
INFO:root:current train perplexity222.8293914794922
INFO:root:current mean train loss 6869.288342315248
INFO:root:current train perplexity225.10186767578125
INFO:root:current mean train loss 6878.9338555013765
INFO:root:current train perplexity226.66677856445312
INFO:root:current mean train loss 6890.772839984342
INFO:root:current train perplexity229.00709533691406
INFO:root:current mean train loss 6888.618941707523
INFO:root:current train perplexity229.3794403076172
INFO:root:current mean train loss 6882.338143069728
INFO:root:current train perplexity228.1484375
INFO:root:current mean train loss 6880.166622492902
INFO:root:current train perplexity228.46023559570312
INFO:root:current mean train loss 6892.573572187156
INFO:root:current train perplexity230.28170776367188
INFO:root:current mean train loss 6900.552081805066
INFO:root:current train perplexity231.2543487548828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.78s/it]
INFO:root:final mean train loss: 6900.596912747613
INFO:root:final train perplexity: 231.81431579589844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.26s/it]
INFO:root:eval mean loss: 6486.087992783134
INFO:root:eval perplexity: 190.3070068359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it]
INFO:root:eval mean loss: 6661.614534851507
INFO:root:eval perplexity: 239.05751037597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [13:23:01<34:58:52, 868.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6973.35555491728
INFO:root:current train perplexity246.29177856445312
INFO:root:current mean train loss 6862.3528743003735
INFO:root:current train perplexity232.0583953857422
INFO:root:current mean train loss 6870.694991152511
INFO:root:current train perplexity225.64187622070312
INFO:root:current mean train loss 6881.941847749813
INFO:root:current train perplexity226.7942352294922
INFO:root:current mean train loss 6904.377967939949
INFO:root:current train perplexity231.7494354248047
INFO:root:current mean train loss 6914.0786690586965
INFO:root:current train perplexity233.58177185058594
INFO:root:current mean train loss 6901.135757590694
INFO:root:current train perplexity231.69651794433594
INFO:root:current mean train loss 6891.799877197931
INFO:root:current train perplexity230.2121124267578
INFO:root:current mean train loss 6876.464772908236
INFO:root:current train perplexity228.69119262695312
INFO:root:current mean train loss 6886.520191004751
INFO:root:current train perplexity230.3509063720703
INFO:root:current mean train loss 6904.827242882616
INFO:root:current train perplexity233.82928466796875
INFO:root:current mean train loss 6915.589421347966
INFO:root:current train perplexity234.86505126953125
INFO:root:current mean train loss 6903.564231143006
INFO:root:current train perplexity232.8944549560547
INFO:root:current mean train loss 6901.034532904446
INFO:root:current train perplexity232.1708526611328
INFO:root:current mean train loss 6901.8631552639035
INFO:root:current train perplexity231.7666778564453
INFO:root:current mean train loss 6898.727328025689
INFO:root:current train perplexity231.38417053222656
INFO:root:current mean train loss 6901.901690218119
INFO:root:current train perplexity231.52191162109375
INFO:root:current mean train loss 6909.82953155412
INFO:root:current train perplexity232.6162109375
INFO:root:current mean train loss 6923.484107430395
INFO:root:current train perplexity235.65390014648438
INFO:root:current mean train loss 6941.705597460332
INFO:root:current train perplexity239.20562744140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.51s/it]
INFO:root:final mean train loss: 6943.652379823224
INFO:root:final train perplexity: 239.8264617919922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.18s/it]
INFO:root:eval mean loss: 6594.126130665448
INFO:root:eval perplexity: 207.69358825683594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.56s/it]
INFO:root:eval mean loss: 6759.000722032913
INFO:root:eval perplexity: 258.98443603515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [13:37:30<34:45:14, 868.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7030.297296262255
INFO:root:current train perplexity268.47100830078125
INFO:root:current mean train loss 7082.055295426325
INFO:root:current train perplexity269.6946716308594
INFO:root:current mean train loss 7070.933961419945
INFO:root:current train perplexity262.5366516113281
INFO:root:current mean train loss 7074.146021133814
INFO:root:current train perplexity263.4482116699219
INFO:root:current mean train loss 7093.188368296147
INFO:root:current train perplexity268.4743347167969
INFO:root:current mean train loss 7082.321857099308
INFO:root:current train perplexity265.8739013671875
INFO:root:current mean train loss 7086.809643067157
INFO:root:current train perplexity266.55023193359375
INFO:root:current mean train loss 7085.059465634363
INFO:root:current train perplexity267.331787109375
INFO:root:current mean train loss 7058.15516212544
INFO:root:current train perplexity262.2870178222656
INFO:root:current mean train loss 7024.166672827944
INFO:root:current train perplexity255.03175354003906
INFO:root:current mean train loss 7002.718901920046
INFO:root:current train perplexity251.43223571777344
INFO:root:current mean train loss 6984.032672845623
INFO:root:current train perplexity247.0140380859375
INFO:root:current mean train loss 6977.196718796838
INFO:root:current train perplexity244.97889709472656
INFO:root:current mean train loss 6978.185155816293
INFO:root:current train perplexity244.79171752929688
INFO:root:current mean train loss 6979.689966308258
INFO:root:current train perplexity244.7395477294922
INFO:root:current mean train loss 6981.500162760417
INFO:root:current train perplexity245.79644775390625
INFO:root:current mean train loss 6985.727381724145
INFO:root:current train perplexity247.33639526367188
INFO:root:current mean train loss 6988.793959255426
INFO:root:current train perplexity248.20204162597656
INFO:root:current mean train loss 7000.564214392136
INFO:root:current train perplexity250.08444213867188
INFO:root:current mean train loss 7002.852283284214
INFO:root:current train perplexity250.52987670898438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.39s/it]
INFO:root:final mean train loss: 6997.665003112393
INFO:root:final train perplexity: 250.27041625976562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.12s/it]
INFO:root:eval mean loss: 6544.870269558954
INFO:root:eval perplexity: 199.57798767089844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 55.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.00s/it]
INFO:root:eval mean loss: 6723.7620182984265
INFO:root:eval perplexity: 251.58921813964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [13:52:01<34:32:17, 869.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7047.443768669577
INFO:root:current train perplexity257.86785888671875
INFO:root:current mean train loss 7013.472223191035
INFO:root:current train perplexity257.6394958496094
INFO:root:current mean train loss 7010.5341013438665
INFO:root:current train perplexity254.9224395751953
INFO:root:current mean train loss 6973.994371497113
INFO:root:current train perplexity248.8542022705078
INFO:root:current mean train loss 7007.256748297275
INFO:root:current train perplexity252.11151123046875
INFO:root:current mean train loss 7042.765779737016
INFO:root:current train perplexity256.6426696777344
INFO:root:current mean train loss 7077.850792068208
INFO:root:current train perplexity264.114990234375
INFO:root:current mean train loss 7085.598434448242
INFO:root:current train perplexity266.2049865722656
INFO:root:current mean train loss 7058.366451702909
INFO:root:current train perplexity261.8439025878906
INFO:root:current mean train loss 7040.468706115218
INFO:root:current train perplexity258.03466796875
INFO:root:current mean train loss 7032.249807979284
INFO:root:current train perplexity256.7381286621094
INFO:root:current mean train loss 7014.598639083235
INFO:root:current train perplexity253.6714324951172
INFO:root:current mean train loss 7005.771747769618
INFO:root:current train perplexity251.13436889648438
INFO:root:current mean train loss 7004.776214421144
INFO:root:current train perplexity250.08908081054688
INFO:root:current mean train loss 7005.08730688277
INFO:root:current train perplexity250.21206665039062
INFO:root:current mean train loss 6996.3041210563815
INFO:root:current train perplexity248.57241821289062
INFO:root:current mean train loss 6988.265395788838
INFO:root:current train perplexity247.31410217285156
INFO:root:current mean train loss 6982.759346664222
INFO:root:current train perplexity246.3693084716797
INFO:root:current mean train loss 6980.206576426994
INFO:root:current train perplexity246.23471069335938
INFO:root:current mean train loss 6973.302126504542
INFO:root:current train perplexity245.08580017089844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:25<00:00, 745.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:25<00:00, 745.74s/it]
INFO:root:final mean train loss: 6969.8442381581335
INFO:root:final train perplexity: 244.8353729248047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 57.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.56s/it]
INFO:root:eval mean loss: 6252.536105108599
INFO:root:eval perplexity: 157.53445434570312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.29s/it]
INFO:root:eval mean loss: 6427.954781173814
INFO:root:eval perplexity: 197.2764434814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [14:06:25<34:13:16, 867.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6805.625063189338
INFO:root:current train perplexity217.46607971191406
INFO:root:current mean train loss 6814.594341216216
INFO:root:current train perplexity218.15664672851562
INFO:root:current mean train loss 6949.311187637061
INFO:root:current train perplexity242.21153259277344
INFO:root:current mean train loss 7044.300348772322
INFO:root:current train perplexity259.50262451171875
INFO:root:current mean train loss 7075.825343307023
INFO:root:current train perplexity263.13671875
INFO:root:current mean train loss 7063.221049512554
INFO:root:current train perplexity262.5630798339844
INFO:root:current mean train loss 7047.531616389142
INFO:root:current train perplexity258.78912353515625
INFO:root:current mean train loss 7039.0968246168395
INFO:root:current train perplexity256.38629150390625
INFO:root:current mean train loss 7030.346794447387
INFO:root:current train perplexity255.05010986328125
INFO:root:current mean train loss 7012.077823108344
INFO:root:current train perplexity251.84788513183594
INFO:root:current mean train loss 7013.187405043923
INFO:root:current train perplexity251.3229217529297
INFO:root:current mean train loss 7002.783598282568
INFO:root:current train perplexity249.47189331054688
INFO:root:current mean train loss 6988.653424048516
INFO:root:current train perplexity247.90576171875
INFO:root:current mean train loss 6989.191911806182
INFO:root:current train perplexity247.9717254638672
INFO:root:current mean train loss 6987.3701790035775
INFO:root:current train perplexity247.11276245117188
INFO:root:current mean train loss 6986.55462403884
INFO:root:current train perplexity247.17828369140625
INFO:root:current mean train loss 6985.434773449091
INFO:root:current train perplexity247.1595458984375
INFO:root:current mean train loss 6985.65080258666
INFO:root:current train perplexity247.30255126953125
INFO:root:current mean train loss 6985.73396779675
INFO:root:current train perplexity247.61228942871094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.01s/it]
INFO:root:final mean train loss: 6982.923821476693
INFO:root:final train perplexity: 247.37579345703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.62s/it]
INFO:root:eval mean loss: 6462.92079801086
INFO:root:eval perplexity: 186.7724151611328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.99s/it]
INFO:root:eval mean loss: 6612.866262016567
INFO:root:eval perplexity: 229.66607666015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [14:20:57<34:02:00, 868.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6431.85302734375
INFO:root:current train perplexity199.5142364501953
INFO:root:current mean train loss 6869.251977060356
INFO:root:current train perplexity231.67750549316406
INFO:root:current mean train loss 6895.617634688274
INFO:root:current train perplexity235.31187438964844
INFO:root:current mean train loss 6876.364157569329
INFO:root:current train perplexity232.10986328125
INFO:root:current mean train loss 6907.480410447762
INFO:root:current train perplexity236.5184783935547
INFO:root:current mean train loss 6925.354430909176
INFO:root:current train perplexity238.67559814453125
INFO:root:current mean train loss 6922.158616785196
INFO:root:current train perplexity238.3869171142578
INFO:root:current mean train loss 6920.3128978587965
INFO:root:current train perplexity236.67213439941406
INFO:root:current mean train loss 6914.747684012625
INFO:root:current train perplexity235.9980010986328
INFO:root:current mean train loss 6923.985614108405
INFO:root:current train perplexity238.27145385742188
INFO:root:current mean train loss 6929.211036423248
INFO:root:current train perplexity239.25787353515625
INFO:root:current mean train loss 6946.320032026288
INFO:root:current train perplexity240.80105590820312
INFO:root:current mean train loss 6958.424093795497
INFO:root:current train perplexity242.9937744140625
INFO:root:current mean train loss 6965.487953854046
INFO:root:current train perplexity244.7947540283203
INFO:root:current mean train loss 6972.080617254369
INFO:root:current train perplexity246.14479064941406
INFO:root:current mean train loss 6972.72260651163
INFO:root:current train perplexity246.28285217285156
INFO:root:current mean train loss 6974.726621934984
INFO:root:current train perplexity246.17037963867188
INFO:root:current mean train loss 6972.836975743151
INFO:root:current train perplexity245.3174285888672
INFO:root:current mean train loss 6979.734745139948
INFO:root:current train perplexity245.85365295410156
INFO:root:current mean train loss 6983.489265000657
INFO:root:current train perplexity246.9650421142578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.22s/it]
INFO:root:final mean train loss: 6984.0628002818885
INFO:root:final train perplexity: 247.59812927246094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.37s/it]
INFO:root:eval mean loss: 6496.399502368684
INFO:root:eval perplexity: 191.90142822265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.09s/it]
INFO:root:eval mean loss: 6641.952841035018
INFO:root:eval perplexity: 235.224365234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [14:35:25<33:47:00, 868.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6879.5617033305925
INFO:root:current train perplexity239.76380920410156
INFO:root:current mean train loss 6998.204950925683
INFO:root:current train perplexity248.18939208984375
INFO:root:current mean train loss 7105.534170769121
INFO:root:current train perplexity267.08203125
INFO:root:current mean train loss 7161.194694112461
INFO:root:current train perplexity280.177978515625
INFO:root:current mean train loss 7189.456461394317
INFO:root:current train perplexity284.4482421875
INFO:root:current mean train loss 7195.636815653601
INFO:root:current train perplexity288.1533203125
INFO:root:current mean train loss 7223.588138315327
INFO:root:current train perplexity293.5813293457031
INFO:root:current mean train loss 7243.054664410205
INFO:root:current train perplexity299.18743896484375
INFO:root:current mean train loss 7263.1815810058
INFO:root:current train perplexity304.2829284667969
INFO:root:current mean train loss 7287.315024291859
INFO:root:current train perplexity310.29443359375
INFO:root:current mean train loss 7302.106473583936
INFO:root:current train perplexity315.1870422363281
INFO:root:current mean train loss 7308.595371495197
INFO:root:current train perplexity317.4189147949219
INFO:root:current mean train loss 7311.624840577574
INFO:root:current train perplexity318.171142578125
INFO:root:current mean train loss 7301.5084177614435
INFO:root:current train perplexity315.8277893066406
INFO:root:current mean train loss 7289.54647412075
INFO:root:current train perplexity313.19281005859375
INFO:root:current mean train loss 7281.749906779748
INFO:root:current train perplexity311.9349060058594
INFO:root:current mean train loss 7275.34116503484
INFO:root:current train perplexity310.89276123046875
INFO:root:current mean train loss 7272.38856052756
INFO:root:current train perplexity310.4075012207031
INFO:root:current mean train loss 7269.696555080487
INFO:root:current train perplexity309.8086242675781
INFO:root:current mean train loss 7266.248565689731
INFO:root:current train perplexity308.7899475097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.43s/it]
INFO:root:final mean train loss: 7261.4249021960095
INFO:root:final train perplexity: 308.1852111816406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.16s/it]
INFO:root:eval mean loss: 6798.2561519974515
INFO:root:eval perplexity: 244.99769592285156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.69s/it]
INFO:root:eval mean loss: 6909.140953118074
INFO:root:eval perplexity: 293.0088806152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [14:49:57<33:34:38, 869.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7115.656521267361
INFO:root:current train perplexity292.6258850097656
INFO:root:current mean train loss 7165.898717543658
INFO:root:current train perplexity290.1251525878906
INFO:root:current mean train loss 7210.8891891220865
INFO:root:current train perplexity296.0388488769531
INFO:root:current mean train loss 7222.867385137649
INFO:root:current train perplexity297.62664794921875
INFO:root:current mean train loss 7194.741508833859
INFO:root:current train perplexity292.0997619628906
INFO:root:current mean train loss 7169.810318220907
INFO:root:current train perplexity289.6540832519531
INFO:root:current mean train loss 7162.049790100482
INFO:root:current train perplexity288.01580810546875
INFO:root:current mean train loss 7163.82573799465
INFO:root:current train perplexity287.3746032714844
INFO:root:current mean train loss 7149.379562742973
INFO:root:current train perplexity285.3922119140625
INFO:root:current mean train loss 7140.7871172000205
INFO:root:current train perplexity284.0437927246094
INFO:root:current mean train loss 7144.173167814159
INFO:root:current train perplexity283.8932189941406
INFO:root:current mean train loss 7137.653737242793
INFO:root:current train perplexity282.0522155761719
INFO:root:current mean train loss 7135.646888905744
INFO:root:current train perplexity281.23394775390625
INFO:root:current mean train loss 7133.957582028326
INFO:root:current train perplexity279.6473083496094
INFO:root:current mean train loss 7136.772102887252
INFO:root:current train perplexity279.8916931152344
INFO:root:current mean train loss 7136.836127916972
INFO:root:current train perplexity280.26617431640625
INFO:root:current mean train loss 7134.845077253495
INFO:root:current train perplexity279.09393310546875
INFO:root:current mean train loss 7137.376045191892
INFO:root:current train perplexity279.7897644042969
INFO:root:current mean train loss 7133.176933870336
INFO:root:current train perplexity279.01129150390625
INFO:root:current mean train loss 7133.391743809723
INFO:root:current train perplexity278.1583251953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.10s/it]
INFO:root:final mean train loss: 7128.675721661466
INFO:root:final train perplexity: 277.53155517578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.29s/it]
INFO:root:eval mean loss: 6488.0693394004875
INFO:root:eval perplexity: 190.6122589111328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it]
INFO:root:eval mean loss: 6637.132716402094
INFO:root:eval perplexity: 234.29412841796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [15:04:25<33:19:04, 869.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6885.601092644458
INFO:root:current train perplexity237.8122100830078
INFO:root:current mean train loss 6943.012842116013
INFO:root:current train perplexity239.35177612304688
INFO:root:current mean train loss 6965.851207386364
INFO:root:current train perplexity243.7666778564453
INFO:root:current mean train loss 6998.541313020096
INFO:root:current train perplexity251.72711181640625
INFO:root:current mean train loss 7048.652948442674
INFO:root:current train perplexity258.41119384765625
INFO:root:current mean train loss 7044.958021939987
INFO:root:current train perplexity259.74169921875
INFO:root:current mean train loss 7033.876481294267
INFO:root:current train perplexity257.5179138183594
INFO:root:current mean train loss 7030.188098517388
INFO:root:current train perplexity256.8272705078125
INFO:root:current mean train loss 7031.595241175447
INFO:root:current train perplexity256.6528015136719
INFO:root:current mean train loss 7037.921633677368
INFO:root:current train perplexity256.9654541015625
INFO:root:current mean train loss 7043.41446545955
INFO:root:current train perplexity257.3006591796875
INFO:root:current mean train loss 7047.25298177648
INFO:root:current train perplexity258.7569274902344
INFO:root:current mean train loss 7049.795360275963
INFO:root:current train perplexity259.9862976074219
INFO:root:current mean train loss 7050.88225565006
INFO:root:current train perplexity260.0303039550781
INFO:root:current mean train loss 7052.588960273464
INFO:root:current train perplexity260.3765869140625
INFO:root:current mean train loss 7056.573847115462
INFO:root:current train perplexity261.6401062011719
INFO:root:current mean train loss 7062.220268309513
INFO:root:current train perplexity262.7110900878906
INFO:root:current mean train loss 7065.5442241313995
INFO:root:current train perplexity263.4890441894531
INFO:root:current mean train loss 7068.155674497437
INFO:root:current train perplexity264.15869140625
INFO:root:current mean train loss 7074.743949862791
INFO:root:current train perplexity265.6820068359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.40s/it]
INFO:root:final mean train loss: 7075.6830940188875
INFO:root:final train perplexity: 266.16424560546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.55s/it]
INFO:root:eval mean loss: 6869.279078706782
INFO:root:eval perplexity: 259.4908752441406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.51s/it]
INFO:root:eval mean loss: 6951.092695520279
INFO:root:eval perplexity: 303.29095458984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [15:18:54<33:04:23, 869.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7235.4522670200895
INFO:root:current train perplexity307.5946044921875
INFO:root:current mean train loss 7231.945726102941
INFO:root:current train perplexity303.35589599609375
INFO:root:current mean train loss 7230.619283492477
INFO:root:current train perplexity303.5215759277344
INFO:root:current mean train loss 7242.276071579392
INFO:root:current train perplexity304.4806213378906
INFO:root:current mean train loss 7232.675632687832
INFO:root:current train perplexity303.3323059082031
INFO:root:current mean train loss 7250.7803745202855
INFO:root:current train perplexity306.30145263671875
INFO:root:current mean train loss 7269.4542604361
INFO:root:current train perplexity311.1592712402344
INFO:root:current mean train loss 7295.172152749594
INFO:root:current train perplexity316.5208435058594
INFO:root:current mean train loss 7315.374524066092
INFO:root:current train perplexity322.0235900878906
INFO:root:current mean train loss 7335.056980911727
INFO:root:current train perplexity326.9816589355469
INFO:root:current mean train loss 7351.939879800671
INFO:root:current train perplexity331.8739318847656
INFO:root:current mean train loss 7369.379388271234
INFO:root:current train perplexity335.51373291015625
INFO:root:current mean train loss 7384.300410233144
INFO:root:current train perplexity338.73553466796875
INFO:root:current mean train loss 7392.977061117131
INFO:root:current train perplexity342.14599609375
INFO:root:current mean train loss 7407.851347921981
INFO:root:current train perplexity345.1445007324219
INFO:root:current mean train loss 7419.969622686107
INFO:root:current train perplexity347.3019104003906
INFO:root:current mean train loss 7424.407135923466
INFO:root:current train perplexity348.8506164550781
INFO:root:current mean train loss 7427.991933428231
INFO:root:current train perplexity350.2275085449219
INFO:root:current mean train loss 7428.453789793616
INFO:root:current train perplexity351.0558166503906
INFO:root:current mean train loss 7430.948736913071
INFO:root:current train perplexity351.5479736328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.64s/it]
INFO:root:final mean train loss: 7428.241984111038
INFO:root:final train perplexity: 351.54998779296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.17s/it]
INFO:root:eval mean loss: 7102.577368337212
INFO:root:eval perplexity: 313.4092712402344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.58s/it]
INFO:root:eval mean loss: 7173.730757043717
INFO:root:eval perplexity: 364.20989990234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [15:33:29<32:54:30, 871.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7476.750841864224
INFO:root:current train perplexity351.2239074707031
INFO:root:current mean train loss 7441.331890248997
INFO:root:current train perplexity352.31536865234375
INFO:root:current mean train loss 7442.876640080575
INFO:root:current train perplexity352.2119140625
INFO:root:current mean train loss 7442.176661922642
INFO:root:current train perplexity352.3241271972656
INFO:root:current mean train loss 7455.075860056789
INFO:root:current train perplexity353.11712646484375
INFO:root:current mean train loss 7439.974878886286
INFO:root:current train perplexity351.48931884765625
INFO:root:current mean train loss 7420.060526974163
INFO:root:current train perplexity348.95660400390625
INFO:root:current mean train loss 7409.358922703899
INFO:root:current train perplexity346.5473937988281
INFO:root:current mean train loss 7407.668573734322
INFO:root:current train perplexity345.53790283203125
INFO:root:current mean train loss 7411.097766570891
INFO:root:current train perplexity346.03533935546875
INFO:root:current mean train loss 7418.033751149954
INFO:root:current train perplexity346.64788818359375
INFO:root:current mean train loss 7425.191609460562
INFO:root:current train perplexity347.6888122558594
INFO:root:current mean train loss 7426.483599516802
INFO:root:current train perplexity348.69097900390625
INFO:root:current mean train loss 7429.701042675852
INFO:root:current train perplexity349.6238098144531
INFO:root:current mean train loss 7429.517876938677
INFO:root:current train perplexity350.1141357421875
INFO:root:current mean train loss 7431.121479267585
INFO:root:current train perplexity350.4430236816406
INFO:root:current mean train loss 7427.335507974585
INFO:root:current train perplexity350.3011779785156
INFO:root:current mean train loss 7423.31134501128
INFO:root:current train perplexity349.6016540527344
INFO:root:current mean train loss 7422.400814992382
INFO:root:current train perplexity349.135009765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.29s/it]
INFO:root:final mean train loss: 7418.412622772078
INFO:root:final train perplexity: 348.8336486816406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.70s/it]
INFO:root:eval mean loss: 7099.967032358156
INFO:root:eval perplexity: 312.7479553222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.90s/it]
INFO:root:eval mean loss: 7165.6359378462985
INFO:root:eval perplexity: 361.79388427734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [15:48:08<32:45:06, 873.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7433.9117431640625
INFO:root:current train perplexity365.01190185546875
INFO:root:current mean train loss 7428.618347167969
INFO:root:current train perplexity346.824462890625
INFO:root:current mean train loss 7442.880926393995
INFO:root:current train perplexity350.9994201660156
INFO:root:current mean train loss 7422.849827816612
INFO:root:current train perplexity351.8162841796875
INFO:root:current mean train loss 7428.26565279819
INFO:root:current train perplexity352.760009765625
INFO:root:current mean train loss 7420.133006262401
INFO:root:current train perplexity351.66986083984375
INFO:root:current mean train loss 7423.302182229149
INFO:root:current train perplexity351.68829345703125
INFO:root:current mean train loss 7429.951273137873
INFO:root:current train perplexity352.5298156738281
INFO:root:current mean train loss 7426.432152591535
INFO:root:current train perplexity351.5820007324219
INFO:root:current mean train loss 7425.554137103325
INFO:root:current train perplexity350.61651611328125
INFO:root:current mean train loss 7421.498282747914
INFO:root:current train perplexity349.9513854980469
INFO:root:current mean train loss 7411.925277488819
INFO:root:current train perplexity347.32061767578125
INFO:root:current mean train loss 7397.906142529459
INFO:root:current train perplexity344.4313049316406
INFO:root:current mean train loss 7384.1767405878545
INFO:root:current train perplexity340.936767578125
INFO:root:current mean train loss 7383.23245317508
INFO:root:current train perplexity339.3056945800781
INFO:root:current mean train loss 7375.852045586768
INFO:root:current train perplexity337.7595520019531
INFO:root:current mean train loss 7374.223541488077
INFO:root:current train perplexity337.0559997558594
INFO:root:current mean train loss 7374.919178850774
INFO:root:current train perplexity336.7502746582031
INFO:root:current mean train loss 7372.370273903045
INFO:root:current train perplexity336.19610595703125
INFO:root:current mean train loss 7372.351621740005
INFO:root:current train perplexity335.8892517089844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.36s/it]
INFO:root:final mean train loss: 7367.392298034268
INFO:root:final train perplexity: 335.0668640136719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.58s/it]
INFO:root:eval mean loss: 6877.436126925421
INFO:root:eval perplexity: 261.20941162109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it]
INFO:root:eval mean loss: 6967.046574585826
INFO:root:eval perplexity: 307.29522705078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [16:02:38<32:28:20, 872.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7175.175944010417
INFO:root:current train perplexity300.08599853515625
INFO:root:current mean train loss 7183.0721808819735
INFO:root:current train perplexity296.685791015625
INFO:root:current mean train loss 7157.2994489712955
INFO:root:current train perplexity289.0088195800781
INFO:root:current mean train loss 7178.464214004089
INFO:root:current train perplexity287.7356262207031
INFO:root:current mean train loss 7153.71330815766
INFO:root:current train perplexity282.9806823730469
INFO:root:current mean train loss 7124.164075620802
INFO:root:current train perplexity277.7927551269531
INFO:root:current mean train loss 7102.155190877868
INFO:root:current train perplexity272.1632080078125
INFO:root:current mean train loss 7062.780714990031
INFO:root:current train perplexity264.26666259765625
INFO:root:current mean train loss 7048.285343592988
INFO:root:current train perplexity260.81500244140625
INFO:root:current mean train loss 7037.303534392813
INFO:root:current train perplexity258.5330810546875
INFO:root:current mean train loss 7035.1339640976985
INFO:root:current train perplexity257.86639404296875
INFO:root:current mean train loss 7034.661111904828
INFO:root:current train perplexity257.65374755859375
INFO:root:current mean train loss 7031.89893018018
INFO:root:current train perplexity256.2110290527344
INFO:root:current mean train loss 7032.32398514383
INFO:root:current train perplexity256.2682189941406
INFO:root:current mean train loss 7041.1364929929405
INFO:root:current train perplexity258.1097106933594
INFO:root:current mean train loss 7045.299292329265
INFO:root:current train perplexity259.7181396484375
INFO:root:current mean train loss 7050.924160674353
INFO:root:current train perplexity261.2477722167969
INFO:root:current mean train loss 7059.070931008498
INFO:root:current train perplexity262.7494201660156
INFO:root:current mean train loss 7071.729543670202
INFO:root:current train perplexity264.875732421875
INFO:root:current mean train loss 7079.369969000114
INFO:root:current train perplexity266.49127197265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:25<00:00, 745.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:25<00:00, 745.60s/it]
INFO:root:final mean train loss: 7080.480153940329
INFO:root:final train perplexity: 267.17376708984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it]
INFO:root:eval mean loss: 6705.130985774047
INFO:root:eval perplexity: 227.21368408203125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.16s/it]
INFO:root:eval mean loss: 6836.932356597684
INFO:root:eval perplexity: 276.1207275390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [16:17:02<32:08:10, 869.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7203.160734477796
INFO:root:current train perplexity281.42791748046875
INFO:root:current mean train loss 7134.328563745471
INFO:root:current train perplexity276.1336364746094
INFO:root:current mean train loss 7092.021400259322
INFO:root:current train perplexity264.3650817871094
INFO:root:current mean train loss 7018.569473176313
INFO:root:current train perplexity251.95587158203125
INFO:root:current mean train loss 6986.966136914954
INFO:root:current train perplexity246.8490753173828
INFO:root:current mean train loss 6976.33452438865
INFO:root:current train perplexity243.79759216308594
INFO:root:current mean train loss 6955.1124057112065
INFO:root:current train perplexity240.18548583984375
INFO:root:current mean train loss 6951.245305089769
INFO:root:current train perplexity238.3115692138672
INFO:root:current mean train loss 6945.886765946636
INFO:root:current train perplexity237.89999389648438
INFO:root:current mean train loss 6943.806864984508
INFO:root:current train perplexity238.3313446044922
INFO:root:current mean train loss 6949.589907254787
INFO:root:current train perplexity239.2476043701172
INFO:root:current mean train loss 6955.639360102702
INFO:root:current train perplexity240.54388427734375
INFO:root:current mean train loss 6960.027642319391
INFO:root:current train perplexity241.2942657470703
INFO:root:current mean train loss 6955.304141194297
INFO:root:current train perplexity241.49847412109375
INFO:root:current mean train loss 6948.749158920267
INFO:root:current train perplexity240.43264770507812
INFO:root:current mean train loss 6947.775715087573
INFO:root:current train perplexity240.38311767578125
INFO:root:current mean train loss 6944.817481482276
INFO:root:current train perplexity240.14161682128906
INFO:root:current mean train loss 6941.359673643826
INFO:root:current train perplexity240.3478240966797
INFO:root:current mean train loss 6948.681073708684
INFO:root:current train perplexity241.32177734375
INFO:root:current mean train loss 6959.021253083882
INFO:root:current train perplexity242.48829650878906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:24<00:00, 744.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:24<00:00, 744.64s/it]
INFO:root:final mean train loss: 6960.021041770085
INFO:root:final train perplexity: 242.94464111328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.20s/it]
INFO:root:eval mean loss: 6591.732446115913
INFO:root:eval perplexity: 207.29168701171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.78s/it]
INFO:root:eval mean loss: 6739.930167123781
INFO:root:eval perplexity: 254.95574951171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [16:31:22<31:47:14, 866.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6963.096422230114
INFO:root:current train perplexity257.6654357910156
INFO:root:current mean train loss 7046.650318170363
INFO:root:current train perplexity271.916748046875
INFO:root:current mean train loss 7120.637132352941
INFO:root:current train perplexity279.9579162597656
INFO:root:current mean train loss 7151.877983329666
INFO:root:current train perplexity283.0540771484375
INFO:root:current mean train loss 7136.861870063531
INFO:root:current train perplexity281.80352783203125
INFO:root:current mean train loss 7131.129495706644
INFO:root:current train perplexity279.5028076171875
INFO:root:current mean train loss 7125.759886390744
INFO:root:current train perplexity278.9543762207031
INFO:root:current mean train loss 7134.434755277318
INFO:root:current train perplexity280.4857177734375
INFO:root:current mean train loss 7132.349641355994
INFO:root:current train perplexity279.9236145019531
INFO:root:current mean train loss 7124.596109599967
INFO:root:current train perplexity279.83740234375
INFO:root:current mean train loss 7132.3530546504735
INFO:root:current train perplexity280.7117004394531
INFO:root:current mean train loss 7132.617659716586
INFO:root:current train perplexity280.3474426269531
INFO:root:current mean train loss 7137.39202564741
INFO:root:current train perplexity280.9319763183594
INFO:root:current mean train loss 7152.867873255881
INFO:root:current train perplexity282.79803466796875
INFO:root:current mean train loss 7158.513277894115
INFO:root:current train perplexity284.1734313964844
INFO:root:current mean train loss 7162.889900271302
INFO:root:current train perplexity284.62774658203125
INFO:root:current mean train loss 7165.539826047961
INFO:root:current train perplexity284.7883605957031
INFO:root:current mean train loss 7162.777778056001
INFO:root:current train perplexity284.02618408203125
INFO:root:current mean train loss 7158.660051486691
INFO:root:current train perplexity283.83758544921875
INFO:root:current mean train loss 7157.606570941895
INFO:root:current train perplexity283.3556213378906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.84s/it]
INFO:root:final mean train loss: 7154.635198503687
INFO:root:final train perplexity: 283.27606201171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.48s/it]
INFO:root:eval mean loss: 6689.822677720523
INFO:root:eval perplexity: 224.4163818359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.46s/it]
INFO:root:eval mean loss: 6814.590364063885
INFO:root:eval perplexity: 271.0953063964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [16:46:06<31:43:29, 871.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7104.152920193143
INFO:root:current train perplexity277.92779541015625
INFO:root:current mean train loss 7148.231666742369
INFO:root:current train perplexity280.7628173828125
INFO:root:current mean train loss 7144.219545252183
INFO:root:current train perplexity282.57574462890625
INFO:root:current mean train loss 7170.997331516717
INFO:root:current train perplexity287.1258850097656
INFO:root:current mean train loss 7177.463244422008
INFO:root:current train perplexity288.6954650878906
INFO:root:current mean train loss 7189.998296137456
INFO:root:current train perplexity290.8140869140625
INFO:root:current mean train loss 7190.4453851609005
INFO:root:current train perplexity292.716064453125
INFO:root:current mean train loss 7199.9000516110755
INFO:root:current train perplexity293.7039794921875
INFO:root:current mean train loss 7201.606760007526
INFO:root:current train perplexity294.2927551269531
INFO:root:current mean train loss 7209.566795066551
INFO:root:current train perplexity295.46966552734375
INFO:root:current mean train loss 7203.4107433717645
INFO:root:current train perplexity295.4718017578125
INFO:root:current mean train loss 7194.303956327992
INFO:root:current train perplexity293.0552978515625
INFO:root:current mean train loss 7187.824455213246
INFO:root:current train perplexity291.4686584472656
INFO:root:current mean train loss 7190.356874515989
INFO:root:current train perplexity291.67193603515625
INFO:root:current mean train loss 7188.674753935441
INFO:root:current train perplexity292.2007751464844
INFO:root:current mean train loss 7190.587285243221
INFO:root:current train perplexity292.9671325683594
INFO:root:current mean train loss 7195.262346623617
INFO:root:current train perplexity293.5495300292969
INFO:root:current mean train loss 7198.618470753827
INFO:root:current train perplexity294.3052673339844
INFO:root:current mean train loss 7208.319277771518
INFO:root:current train perplexity295.2474365234375
INFO:root:current mean train loss 7215.476671447135
INFO:root:current train perplexity296.7313537597656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.99s/it]
INFO:root:final mean train loss: 7213.9264564225605
INFO:root:final train perplexity: 296.8464050292969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.71s/it]
INFO:root:eval mean loss: 7007.888921210107
INFO:root:eval perplexity: 290.2917785644531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.14s/it]
INFO:root:eval mean loss: 7110.63412670379
INFO:root:eval perplexity: 345.79864501953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [17:00:43<31:32:32, 873.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7325.03797072507
INFO:root:current train perplexity323.433837890625
INFO:root:current mean train loss 7350.619158709491
INFO:root:current train perplexity324.059814453125
INFO:root:current mean train loss 7323.257722953612
INFO:root:current train perplexity322.30657958984375
INFO:root:current mean train loss 7311.421119356523
INFO:root:current train perplexity318.5762023925781
INFO:root:current mean train loss 7305.850224469581
INFO:root:current train perplexity316.6867370605469
INFO:root:current mean train loss 7299.948243845501
INFO:root:current train perplexity314.5595703125
INFO:root:current mean train loss 7299.467022235577
INFO:root:current train perplexity313.1859436035156
INFO:root:current mean train loss 7298.166929682549
INFO:root:current train perplexity312.98052978515625
INFO:root:current mean train loss 7286.956026675864
INFO:root:current train perplexity312.301025390625
INFO:root:current mean train loss 7282.210876279702
INFO:root:current train perplexity312.5396728515625
INFO:root:current mean train loss 7284.298867133695
INFO:root:current train perplexity311.9502258300781
INFO:root:current mean train loss 7285.6522747582
INFO:root:current train perplexity311.8095397949219
INFO:root:current mean train loss 7279.2999531795485
INFO:root:current train perplexity311.06671142578125
INFO:root:current mean train loss 7280.668227830836
INFO:root:current train perplexity311.0587158203125
INFO:root:current mean train loss 7278.772239587705
INFO:root:current train perplexity311.3514709472656
INFO:root:current mean train loss 7282.808270482615
INFO:root:current train perplexity312.42388916015625
INFO:root:current mean train loss 7281.950507824064
INFO:root:current train perplexity312.5937805175781
INFO:root:current mean train loss 7280.474529132022
INFO:root:current train perplexity312.4635314941406
INFO:root:current mean train loss 7274.846694938211
INFO:root:current train perplexity311.5249328613281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.14s/it]
INFO:root:final mean train loss: 7271.8897583808075
INFO:root:final train perplexity: 310.7408447265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it]
INFO:root:eval mean loss: 6793.075962364251
INFO:root:eval perplexity: 243.9729766845703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it]
INFO:root:eval mean loss: 6896.59664332613
INFO:root:eval perplexity: 290.00262451171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [17:15:21<31:20:49, 874.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7062.273356119792
INFO:root:current train perplexity290.54241943359375
INFO:root:current mean train loss 7196.694971624411
INFO:root:current train perplexity295.1600036621094
INFO:root:current mean train loss 7224.750118514867
INFO:root:current train perplexity295.53265380859375
INFO:root:current mean train loss 7197.242790670956
INFO:root:current train perplexity293.97650146484375
INFO:root:current mean train loss 7190.732801916564
INFO:root:current train perplexity292.9120788574219
INFO:root:current mean train loss 7179.902994148345
INFO:root:current train perplexity289.4072265625
INFO:root:current mean train loss 7176.696383334623
INFO:root:current train perplexity288.03326416015625
INFO:root:current mean train loss 7173.691188390802
INFO:root:current train perplexity287.1344909667969
INFO:root:current mean train loss 7171.980282766944
INFO:root:current train perplexity287.3594055175781
INFO:root:current mean train loss 7180.7761526886725
INFO:root:current train perplexity287.6478576660156
INFO:root:current mean train loss 7171.939864232573
INFO:root:current train perplexity287.1383361816406
INFO:root:current mean train loss 7174.235219117315
INFO:root:current train perplexity287.92352294921875
INFO:root:current mean train loss 7173.7626483468075
INFO:root:current train perplexity288.0306396484375
INFO:root:current mean train loss 7175.393225677163
INFO:root:current train perplexity288.1799621582031
INFO:root:current mean train loss 7170.2724609375
INFO:root:current train perplexity287.7669372558594
INFO:root:current mean train loss 7164.980525164965
INFO:root:current train perplexity287.298583984375
INFO:root:current mean train loss 7169.945472422751
INFO:root:current train perplexity287.7625427246094
INFO:root:current mean train loss 7174.909824814075
INFO:root:current train perplexity288.45068359375
INFO:root:current mean train loss 7176.399570874862
INFO:root:current train perplexity288.3106689453125
INFO:root:current mean train loss 7177.7035517977765
INFO:root:current train perplexity288.2856750488281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.81s/it]
INFO:root:final mean train loss: 7174.6139095150575
INFO:root:final train perplexity: 287.7780456542969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.92s/it]
INFO:root:eval mean loss: 6771.741557236259
INFO:root:eval perplexity: 239.79696655273438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.92s/it]
INFO:root:eval mean loss: 6875.7531920088095
INFO:root:eval perplexity: 285.075439453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [17:29:59<31:08:27, 875.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7114.588569972826
INFO:root:current train perplexity279.4153747558594
INFO:root:current mean train loss 7141.099144912348
INFO:root:current train perplexity278.1133728027344
INFO:root:current mean train loss 7142.066528867713
INFO:root:current train perplexity271.9459228515625
INFO:root:current mean train loss 7106.34811278541
INFO:root:current train perplexity273.10467529296875
INFO:root:current mean train loss 7132.268711676271
INFO:root:current train perplexity276.4238586425781
INFO:root:current mean train loss 7138.358294806107
INFO:root:current train perplexity278.98004150390625
INFO:root:current mean train loss 7156.852477929374
INFO:root:current train perplexity281.7058410644531
INFO:root:current mean train loss 7166.086932972424
INFO:root:current train perplexity284.1031188964844
INFO:root:current mean train loss 7180.863862085169
INFO:root:current train perplexity286.8908996582031
INFO:root:current mean train loss 7188.182848896262
INFO:root:current train perplexity288.6306457519531
INFO:root:current mean train loss 7197.193396604655
INFO:root:current train perplexity290.5000305175781
INFO:root:current mean train loss 7200.144356894896
INFO:root:current train perplexity292.04266357421875
INFO:root:current mean train loss 7211.169467529896
INFO:root:current train perplexity294.3639221191406
INFO:root:current mean train loss 7218.563246631118
INFO:root:current train perplexity296.0303955078125
INFO:root:current mean train loss 7220.002697041901
INFO:root:current train perplexity297.0661926269531
INFO:root:current mean train loss 7225.017539973018
INFO:root:current train perplexity297.9989929199219
INFO:root:current mean train loss 7222.603678987119
INFO:root:current train perplexity298.25872802734375
INFO:root:current mean train loss 7224.830991208104
INFO:root:current train perplexity298.7284240722656
INFO:root:current mean train loss 7222.14940040241
INFO:root:current train perplexity298.1661682128906
INFO:root:current mean train loss 7219.1866343989695
INFO:root:current train perplexity298.0556945800781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.43s/it]
INFO:root:final mean train loss: 7219.914610739134
INFO:root:final train perplexity: 298.25262451171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.86s/it]
INFO:root:eval mean loss: 6911.110020847185
INFO:root:eval perplexity: 268.425048828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.27s/it]
INFO:root:eval mean loss: 7008.649506697418
INFO:root:eval perplexity: 317.98748779296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [17:44:41<30:57:58, 877.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7226.250695800782
INFO:root:current train perplexity313.744384765625
INFO:root:current mean train loss 7308.7873046875
INFO:root:current train perplexity319.5413513183594
INFO:root:current mean train loss 7281.646166992187
INFO:root:current train perplexity315.97222900390625
INFO:root:current mean train loss 7257.34773236443
INFO:root:current train perplexity311.76611328125
INFO:root:current mean train loss 7254.423686079545
INFO:root:current train perplexity306.7898254394531
INFO:root:current mean train loss 7252.480136899595
INFO:root:current train perplexity306.3401794433594
INFO:root:current mean train loss 7246.145475769043
INFO:root:current train perplexity306.2112121582031
INFO:root:current mean train loss 7239.562476905617
INFO:root:current train perplexity306.0732727050781
INFO:root:current mean train loss 7247.512697637649
INFO:root:current train perplexity306.977294921875
INFO:root:current mean train loss 7253.951708984375
INFO:root:current train perplexity307.86474609375
INFO:root:current mean train loss 7250.46242957482
INFO:root:current train perplexity307.3013916015625
INFO:root:current mean train loss 7253.437599369518
INFO:root:current train perplexity307.3053283691406
INFO:root:current mean train loss 7251.011077290196
INFO:root:current train perplexity306.6665344238281
INFO:root:current mean train loss 7247.719893452659
INFO:root:current train perplexity306.34600830078125
INFO:root:current mean train loss 7249.895073784723
INFO:root:current train perplexity305.91552734375
INFO:root:current mean train loss 7250.5022527521305
INFO:root:current train perplexity305.7144470214844
INFO:root:current mean train loss 7254.49923929354
INFO:root:current train perplexity305.86651611328125
INFO:root:current mean train loss 7252.468047323994
INFO:root:current train perplexity305.436279296875
INFO:root:current mean train loss 7249.597046694548
INFO:root:current train perplexity304.69049072265625
INFO:root:current mean train loss 7250.441988663821
INFO:root:current train perplexity304.6999206542969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.07s/it]
INFO:root:final mean train loss: 7246.729991179912
INFO:root:final train perplexity: 304.6318054199219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.06s/it]
INFO:root:eval mean loss: 6886.744022883422
INFO:root:eval perplexity: 263.1841735839844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it]
INFO:root:eval mean loss: 6971.199302727449
INFO:root:eval perplexity: 308.34619140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [17:59:21<30:44:17, 878.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7248.953690378289
INFO:root:current train perplexity305.0032958984375
INFO:root:current mean train loss 7207.585931279857
INFO:root:current train perplexity301.77593994140625
INFO:root:current mean train loss 7193.37459531554
INFO:root:current train perplexity298.8140563964844
INFO:root:current mean train loss 7221.210170200893
INFO:root:current train perplexity299.90118408203125
INFO:root:current mean train loss 7216.217475340194
INFO:root:current train perplexity299.7034912109375
INFO:root:current mean train loss 7214.911054792695
INFO:root:current train perplexity299.84100341796875
INFO:root:current mean train loss 7218.5654884001615
INFO:root:current train perplexity300.374755859375
INFO:root:current mean train loss 7222.867010119096
INFO:root:current train perplexity301.0382385253906
INFO:root:current mean train loss 7209.105494958795
INFO:root:current train perplexity298.8585205078125
INFO:root:current mean train loss 7203.0854971795
INFO:root:current train perplexity297.8866271972656
INFO:root:current mean train loss 7196.753870679842
INFO:root:current train perplexity296.99749755859375
INFO:root:current mean train loss 7191.9758881063635
INFO:root:current train perplexity295.87359619140625
INFO:root:current mean train loss 7194.050901280952
INFO:root:current train perplexity295.16253662109375
INFO:root:current mean train loss 7194.906421276252
INFO:root:current train perplexity295.0689697265625
INFO:root:current mean train loss 7201.282741989105
INFO:root:current train perplexity295.5642395019531
INFO:root:current mean train loss 7206.442535223989
INFO:root:current train perplexity296.02545166015625
INFO:root:current mean train loss 7207.25618352067
INFO:root:current train perplexity296.10479736328125
INFO:root:current mean train loss 7206.956587711654
INFO:root:current train perplexity295.9623718261719
INFO:root:current mean train loss 7209.301673671413
INFO:root:current train perplexity296.1302185058594
INFO:root:current mean train loss 7214.971240558732
INFO:root:current train perplexity296.6572265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.27s/it]
INFO:root:final mean train loss: 7213.439101380287
INFO:root:final train perplexity: 296.73236083984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.06s/it]
INFO:root:eval mean loss: 6890.194225121897
INFO:root:eval perplexity: 263.92010498046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.39s/it]
INFO:root:eval mean loss: 6974.401504841257
INFO:root:eval perplexity: 309.15899658203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [18:14:03<30:32:04, 879.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7220.313199429898
INFO:root:current train perplexity295.8603515625
INFO:root:current mean train loss 7238.287676230244
INFO:root:current train perplexity300.1297912597656
INFO:root:current mean train loss 7230.314078894845
INFO:root:current train perplexity301.2596435546875
INFO:root:current mean train loss 7229.049082710144
INFO:root:current train perplexity299.8756103515625
INFO:root:current mean train loss 7221.783373096321
INFO:root:current train perplexity298.5959777832031
INFO:root:current mean train loss 7217.825675937772
INFO:root:current train perplexity297.8916015625
INFO:root:current mean train loss 7204.835193486879
INFO:root:current train perplexity295.9102783203125
INFO:root:current mean train loss 7197.505001413114
INFO:root:current train perplexity294.3925476074219
INFO:root:current mean train loss 7186.952156817613
INFO:root:current train perplexity292.7036437988281
INFO:root:current mean train loss 7192.793595394314
INFO:root:current train perplexity293.38580322265625
INFO:root:current mean train loss 7192.576545587465
INFO:root:current train perplexity293.6699523925781
INFO:root:current mean train loss 7191.329141490098
INFO:root:current train perplexity293.8387451171875
INFO:root:current mean train loss 7199.360057213991
INFO:root:current train perplexity294.2484130859375
INFO:root:current mean train loss 7202.034573439774
INFO:root:current train perplexity294.661376953125
INFO:root:current mean train loss 7209.113474707428
INFO:root:current train perplexity295.7194519042969
INFO:root:current mean train loss 7216.360283004587
INFO:root:current train perplexity296.78485107421875
INFO:root:current mean train loss 7219.751400089605
INFO:root:current train perplexity297.462646484375
INFO:root:current mean train loss 7218.250750587919
INFO:root:current train perplexity297.67578125
INFO:root:current mean train loss 7224.985398983625
INFO:root:current train perplexity298.3876037597656
INFO:root:current mean train loss 7226.180693497895
INFO:root:current train perplexity299.2716369628906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.38s/it]
INFO:root:final mean train loss: 7224.582133560065
INFO:root:final train perplexity: 299.3534240722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it]
INFO:root:eval mean loss: 6969.555693497895
INFO:root:eval perplexity: 281.4253845214844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.32s/it]
INFO:root:eval mean loss: 7047.009383830618
INFO:root:eval perplexity: 328.17535400390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [18:28:39<30:15:47, 878.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7246.085969694368
INFO:root:current train perplexity313.2347717285156
INFO:root:current mean train loss 7258.6635460978405
INFO:root:current train perplexity312.91217041015625
INFO:root:current mean train loss 7279.67138000698
INFO:root:current train perplexity313.87530517578125
INFO:root:current mean train loss 7268.511876098945
INFO:root:current train perplexity312.66339111328125
INFO:root:current mean train loss 7274.7238575611
INFO:root:current train perplexity312.1266784667969
INFO:root:current mean train loss 7261.400307179304
INFO:root:current train perplexity311.238525390625
INFO:root:current mean train loss 7255.415812822223
INFO:root:current train perplexity311.162109375
INFO:root:current mean train loss 7254.968084554756
INFO:root:current train perplexity310.33868408203125
INFO:root:current mean train loss 7252.707700924172
INFO:root:current train perplexity309.46697998046875
INFO:root:current mean train loss 7249.176043374748
INFO:root:current train perplexity308.39117431640625
INFO:root:current mean train loss 7247.298452179766
INFO:root:current train perplexity307.9995422363281
INFO:root:current mean train loss 7252.418295090785
INFO:root:current train perplexity308.62432861328125
INFO:root:current mean train loss 7255.598335532049
INFO:root:current train perplexity308.865478515625
INFO:root:current mean train loss 7261.64839467447
INFO:root:current train perplexity308.9532775878906
INFO:root:current mean train loss 7264.533048879212
INFO:root:current train perplexity308.99658203125
INFO:root:current mean train loss 7267.385920497623
INFO:root:current train perplexity309.10430908203125
INFO:root:current mean train loss 7267.316620793447
INFO:root:current train perplexity309.1388244628906
INFO:root:current mean train loss 7268.062746185354
INFO:root:current train perplexity308.9454650878906
INFO:root:current mean train loss 7265.990216558286
INFO:root:current train perplexity308.8257141113281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.48s/it]
INFO:root:final mean train loss: 7265.35315415406
INFO:root:final train perplexity: 309.1420593261719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it]
INFO:root:eval mean loss: 6983.176785516401
INFO:root:eval perplexity: 284.5442810058594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.03s/it]
INFO:root:eval mean loss: 7058.833640673482
INFO:root:eval perplexity: 331.38134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [18:43:18<30:00:55, 878.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7270.460205078125
INFO:root:current train perplexity321.5234069824219
INFO:root:current mean train loss 7304.045496057581
INFO:root:current train perplexity314.9429016113281
INFO:root:current mean train loss 7261.775458702674
INFO:root:current train perplexity311.03363037109375
INFO:root:current mean train loss 7270.363817091112
INFO:root:current train perplexity311.784423828125
INFO:root:current mean train loss 7268.455482632507
INFO:root:current train perplexity310.44952392578125
INFO:root:current mean train loss 7276.5401130736345
INFO:root:current train perplexity310.086181640625
INFO:root:current mean train loss 7264.614890650699
INFO:root:current train perplexity308.8046569824219
INFO:root:current mean train loss 7271.4589436848955
INFO:root:current train perplexity308.34661865234375
INFO:root:current mean train loss 7264.181883557008
INFO:root:current train perplexity307.83038330078125
INFO:root:current mean train loss 7266.102637471607
INFO:root:current train perplexity307.74761962890625
INFO:root:current mean train loss 7254.640394422743
INFO:root:current train perplexity306.5371398925781
INFO:root:current mean train loss 7254.358904346232
INFO:root:current train perplexity305.9698181152344
INFO:root:current mean train loss 7251.763468155008
INFO:root:current train perplexity305.59185791015625
INFO:root:current mean train loss 7257.746683569859
INFO:root:current train perplexity305.9587097167969
INFO:root:current mean train loss 7259.077839591287
INFO:root:current train perplexity306.1812744140625
INFO:root:current mean train loss 7261.468278556034
INFO:root:current train perplexity306.4363098144531
INFO:root:current mean train loss 7263.381762756044
INFO:root:current train perplexity306.81060791015625
INFO:root:current mean train loss 7265.820689288459
INFO:root:current train perplexity307.4143981933594
INFO:root:current mean train loss 7264.027385070261
INFO:root:current train perplexity307.54632568359375
INFO:root:current mean train loss 7262.979769852676
INFO:root:current train perplexity307.9707336425781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.07s/it]
INFO:root:final mean train loss: 7262.416205347997
INFO:root:final train perplexity: 308.42645263671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.39s/it]
INFO:root:eval mean loss: 7011.385783743351
INFO:root:eval perplexity: 291.1144714355469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.93s/it]
INFO:root:eval mean loss: 7084.242332945479
INFO:root:eval perplexity: 338.37615966796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [18:57:52<29:43:24, 877.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7291.6475
INFO:root:current train perplexity318.8999328613281
INFO:root:current mean train loss 7265.4875546875
INFO:root:current train perplexity317.5011291503906
INFO:root:current mean train loss 7263.376310763889
INFO:root:current train perplexity318.78057861328125
INFO:root:current mean train loss 7272.188757512019
INFO:root:current train perplexity319.7669372558594
INFO:root:current mean train loss 7287.351366038603
INFO:root:current train perplexity321.7962646484375
INFO:root:current mean train loss 7289.066969866071
INFO:root:current train perplexity321.876220703125
INFO:root:current mean train loss 7299.4455734375
INFO:root:current train perplexity322.38079833984375
INFO:root:current mean train loss 7311.7970332704745
INFO:root:current train perplexity322.49365234375
INFO:root:current mean train loss 7313.002744436553
INFO:root:current train perplexity322.4218444824219
INFO:root:current mean train loss 7316.085805532095
INFO:root:current train perplexity322.6903991699219
INFO:root:current mean train loss 7312.592207507622
INFO:root:current train perplexity323.1959533691406
INFO:root:current mean train loss 7316.57734765625
INFO:root:current train perplexity323.31988525390625
INFO:root:current mean train loss 7320.702465720663
INFO:root:current train perplexity323.6203308105469
INFO:root:current mean train loss 7319.5253327682785
INFO:root:current train perplexity323.5071105957031
INFO:root:current mean train loss 7315.249403782895
INFO:root:current train perplexity323.20672607421875
INFO:root:current mean train loss 7317.936719070184
INFO:root:current train perplexity323.41192626953125
INFO:root:current mean train loss 7325.109866887019
INFO:root:current train perplexity323.99383544921875
INFO:root:current mean train loss 7331.326631850091
INFO:root:current train perplexity324.50994873046875
INFO:root:current mean train loss 7332.669880136987
INFO:root:current train perplexity324.7579345703125
INFO:root:current mean train loss 7329.1528330458605
INFO:root:current train perplexity324.7838134765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.19s/it]
INFO:root:final mean train loss: 7328.446139968049
INFO:root:final train perplexity: 324.9247741699219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.70s/it]
INFO:root:eval mean loss: 7052.39183877715
INFO:root:eval perplexity: 300.93646240234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.22s/it]
INFO:root:eval mean loss: 7119.914883228059
INFO:root:eval perplexity: 348.44696044921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [19:12:26<29:27:15, 876.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7364.031261625744
INFO:root:current train perplexity327.0429382324219
INFO:root:current mean train loss 7381.547511141065
INFO:root:current train perplexity330.47607421875
INFO:root:current mean train loss 7364.9570272146175
INFO:root:current train perplexity329.15203857421875
INFO:root:current mean train loss 7372.738002844024
INFO:root:current train perplexity329.3729553222656
INFO:root:current mean train loss 7373.102257361779
INFO:root:current train perplexity329.8644104003906
INFO:root:current mean train loss 7366.866970386012
INFO:root:current train perplexity329.3192443847656
INFO:root:current mean train loss 7357.8359215281835
INFO:root:current train perplexity328.8440856933594
INFO:root:current mean train loss 7353.471613223341
INFO:root:current train perplexity328.85443115234375
INFO:root:current mean train loss 7347.8832219139695
INFO:root:current train perplexity328.5509948730469
INFO:root:current mean train loss 7340.8764140459125
INFO:root:current train perplexity327.7793884277344
INFO:root:current mean train loss 7343.204421616333
INFO:root:current train perplexity327.6846618652344
INFO:root:current mean train loss 7335.977235917661
INFO:root:current train perplexity327.5268859863281
INFO:root:current mean train loss 7340.118698341259
INFO:root:current train perplexity327.7096862792969
INFO:root:current mean train loss 7344.442534900102
INFO:root:current train perplexity327.71795654296875
INFO:root:current mean train loss 7341.241965707893
INFO:root:current train perplexity327.4171142578125
INFO:root:current mean train loss 7338.962400443823
INFO:root:current train perplexity327.2062683105469
INFO:root:current mean train loss 7336.927367123268
INFO:root:current train perplexity327.0647888183594
INFO:root:current mean train loss 7334.582058999623
INFO:root:current train perplexity326.46319580078125
INFO:root:current mean train loss 7331.062281837422
INFO:root:current train perplexity325.7308044433594
INFO:root:current mean train loss 7329.5337487327815
INFO:root:current train perplexity324.707763671875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.64s/it]
INFO:root:final mean train loss: 7326.14594869378
INFO:root:final train perplexity: 324.33544921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it]
INFO:root:eval mean loss: 6979.719764655363
INFO:root:eval perplexity: 283.7496337890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.82s/it]
INFO:root:eval mean loss: 7051.912896338929
INFO:root:eval perplexity: 329.5011291503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [19:26:53<29:07:02, 873.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7272.3211152674785
INFO:root:current train perplexity314.1262512207031
INFO:root:current mean train loss 7266.875061419025
INFO:root:current train perplexity313.19384765625
INFO:root:current mean train loss 7255.4976999879345
INFO:root:current train perplexity312.378173828125
INFO:root:current mean train loss 7268.355062075644
INFO:root:current train perplexity312.33154296875
INFO:root:current mean train loss 7258.972374344703
INFO:root:current train perplexity311.29803466796875
INFO:root:current mean train loss 7268.522253920226
INFO:root:current train perplexity311.4552917480469
INFO:root:current mean train loss 7267.43900855937
INFO:root:current train perplexity311.792724609375
INFO:root:current mean train loss 7281.918040802042
INFO:root:current train perplexity312.18682861328125
INFO:root:current mean train loss 7283.824065842367
INFO:root:current train perplexity312.1460266113281
INFO:root:current mean train loss 7280.1060374780045
INFO:root:current train perplexity312.01092529296875
INFO:root:current mean train loss 7277.4486737561965
INFO:root:current train perplexity312.540283203125
INFO:root:current mean train loss 7283.395193104912
INFO:root:current train perplexity313.0724792480469
INFO:root:current mean train loss 7294.319968492479
INFO:root:current train perplexity314.3375244140625
INFO:root:current mean train loss 7298.510270793093
INFO:root:current train perplexity315.0364685058594
INFO:root:current mean train loss 7298.1447678605855
INFO:root:current train perplexity316.00732421875
INFO:root:current mean train loss 7297.955827303159
INFO:root:current train perplexity316.8285827636719
INFO:root:current mean train loss 7302.383983315439
INFO:root:current train perplexity317.7125549316406
INFO:root:current mean train loss 7306.968699478574
INFO:root:current train perplexity318.5625305175781
INFO:root:current mean train loss 7310.664667926725
INFO:root:current train perplexity319.4746398925781
INFO:root:current mean train loss 7309.793456283499
INFO:root:current train perplexity319.831298828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.41s/it]
INFO:root:final mean train loss: 7308.952134648418
INFO:root:final train perplexity: 319.96417236328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.35s/it]
INFO:root:eval mean loss: 7097.78869715481
INFO:root:eval perplexity: 312.1972351074219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.68s/it]
INFO:root:eval mean loss: 7159.22326746731
INFO:root:eval perplexity: 359.89154052734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [19:41:27<28:52:42, 873.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7318.343248869243
INFO:root:current train perplexity331.6924743652344
INFO:root:current mean train loss 7332.316672585227
INFO:root:current train perplexity332.3563232421875
INFO:root:current mean train loss 7338.209554036458
INFO:root:current train perplexity331.6394958496094
INFO:root:current mean train loss 7339.428956376745
INFO:root:current train perplexity332.14434814453125
INFO:root:current mean train loss 7334.338542008601
INFO:root:current train perplexity331.56488037109375
INFO:root:current mean train loss 7349.25616285536
INFO:root:current train perplexity331.943115234375
INFO:root:current mean train loss 7345.307816544933
INFO:root:current train perplexity330.5127868652344
INFO:root:current mean train loss 7345.02054745389
INFO:root:current train perplexity329.82855224609375
INFO:root:current mean train loss 7337.128050643015
INFO:root:current train perplexity328.37493896484375
INFO:root:current mean train loss 7330.757801493661
INFO:root:current train perplexity327.720458984375
INFO:root:current mean train loss 7327.54198764957
INFO:root:current train perplexity327.1341857910156
INFO:root:current mean train loss 7323.254446016688
INFO:root:current train perplexity326.0860595703125
INFO:root:current mean train loss 7319.324964947835
INFO:root:current train perplexity324.97869873046875
INFO:root:current mean train loss 7317.979723198469
INFO:root:current train perplexity324.17510986328125
INFO:root:current mean train loss 7315.856381134612
INFO:root:current train perplexity323.5533752441406
INFO:root:current mean train loss 7315.954259882118
INFO:root:current train perplexity322.91436767578125
INFO:root:current mean train loss 7311.526703099363
INFO:root:current train perplexity322.0300598144531
INFO:root:current mean train loss 7309.424969922315
INFO:root:current train perplexity321.4662170410156
INFO:root:current mean train loss 7311.178337959338
INFO:root:current train perplexity321.03240966796875
INFO:root:current mean train loss 7313.2397804414695
INFO:root:current train perplexity320.6208801269531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.40s/it]
INFO:root:final mean train loss: 7311.523575637056
INFO:root:final train perplexity: 320.6141662597656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.73s/it]
INFO:root:eval mean loss: 7006.155993738918
INFO:root:eval perplexity: 289.8851013183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.30s/it]
INFO:root:eval mean loss: 7069.637330833057
INFO:root:eval perplexity: 334.337646484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [19:55:53<28:33:38, 871.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7260.473522555443
INFO:root:current train perplexity310.5616149902344
INFO:root:current mean train loss 7242.971877023963
INFO:root:current train perplexity308.11029052734375
INFO:root:current mean train loss 7265.115872640252
INFO:root:current train perplexity307.6522521972656
INFO:root:current mean train loss 7272.820911358937
INFO:root:current train perplexity308.43133544921875
INFO:root:current mean train loss 7270.675443513882
INFO:root:current train perplexity308.6309509277344
INFO:root:current mean train loss 7274.3789877674435
INFO:root:current train perplexity309.7044982910156
INFO:root:current mean train loss 7276.789421841179
INFO:root:current train perplexity310.1521301269531
INFO:root:current mean train loss 7274.19801990562
INFO:root:current train perplexity310.0404968261719
INFO:root:current mean train loss 7269.6974723106805
INFO:root:current train perplexity309.7508544921875
INFO:root:current mean train loss 7268.071825040912
INFO:root:current train perplexity309.7604675292969
INFO:root:current mean train loss 7265.753082917572
INFO:root:current train perplexity309.85443115234375
INFO:root:current mean train loss 7269.131224460394
INFO:root:current train perplexity309.9045104980469
INFO:root:current mean train loss 7261.901080563008
INFO:root:current train perplexity309.3272399902344
INFO:root:current mean train loss 7266.431071372487
INFO:root:current train perplexity309.4508972167969
INFO:root:current mean train loss 7270.001931212847
INFO:root:current train perplexity309.55816650390625
INFO:root:current mean train loss 7260.946192203193
INFO:root:current train perplexity309.3186950683594
INFO:root:current mean train loss 7260.041728290664
INFO:root:current train perplexity309.3116149902344
INFO:root:current mean train loss 7262.529283531006
INFO:root:current train perplexity309.267822265625
INFO:root:current mean train loss 7266.514499863807
INFO:root:current train perplexity309.362060546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.84s/it]
INFO:root:final mean train loss: 7266.150389886299
INFO:root:final train perplexity: 309.3365478515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it]
INFO:root:eval mean loss: 6993.431573096742
INFO:root:eval perplexity: 286.9153747558594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.74s/it]
INFO:root:eval mean loss: 7059.186528631982
INFO:root:eval perplexity: 331.477294921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [20:10:31<28:22:56, 873.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7299.704541015625
INFO:root:current train perplexity306.6499938964844
INFO:root:current mean train loss 7305.620423473011
INFO:root:current train perplexity310.12506103515625
INFO:root:current mean train loss 7258.546786644345
INFO:root:current train perplexity307.2276916503906
INFO:root:current mean train loss 7267.806746156754
INFO:root:current train perplexity306.87322998046875
INFO:root:current mean train loss 7269.663430116235
INFO:root:current train perplexity306.194580078125
INFO:root:current mean train loss 7271.643607345281
INFO:root:current train perplexity306.3590087890625
INFO:root:current mean train loss 7262.128037749744
INFO:root:current train perplexity305.7253723144531
INFO:root:current mean train loss 7249.79540602993
INFO:root:current train perplexity305.1615905761719
INFO:root:current mean train loss 7248.940409191744
INFO:root:current train perplexity304.9522705078125
INFO:root:current mean train loss 7256.6552492917235
INFO:root:current train perplexity305.1919860839844
INFO:root:current mean train loss 7256.51318504409
INFO:root:current train perplexity305.480712890625
INFO:root:current mean train loss 7251.654006545608
INFO:root:current train perplexity304.97509765625
INFO:root:current mean train loss 7253.0686297456095
INFO:root:current train perplexity304.88116455078125
INFO:root:current mean train loss 7251.319794772781
INFO:root:current train perplexity305.0428771972656
INFO:root:current mean train loss 7253.154935103613
INFO:root:current train perplexity305.1263732910156
INFO:root:current mean train loss 7251.770715089508
INFO:root:current train perplexity305.3289794921875
INFO:root:current mean train loss 7253.133829398777
INFO:root:current train perplexity305.3956604003906
INFO:root:current mean train loss 7254.312921749361
INFO:root:current train perplexity305.23345947265625
INFO:root:current mean train loss 7254.214500334513
INFO:root:current train perplexity305.314697265625
INFO:root:current mean train loss 7250.460357697972
INFO:root:current train perplexity305.1876220703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.75s/it]
INFO:root:final mean train loss: 7249.717527819474
INFO:root:final train perplexity: 305.35052490234375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.32s/it]
INFO:root:eval mean loss: 6994.741145140736
INFO:root:eval perplexity: 287.2198181152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it]
INFO:root:eval mean loss: 7060.681691704067
INFO:root:eval perplexity: 331.885009765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [20:25:12<28:12:56, 875.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7338.07398365162
INFO:root:current train perplexity310.2419128417969
INFO:root:current mean train loss 7238.297447865403
INFO:root:current train perplexity302.43817138671875
INFO:root:current mean train loss 7237.702258139455
INFO:root:current train perplexity303.72686767578125
INFO:root:current mean train loss 7214.388267213781
INFO:root:current train perplexity301.9971923828125
INFO:root:current mean train loss 7225.241114882172
INFO:root:current train perplexity302.67132568359375
INFO:root:current mean train loss 7239.938890721359
INFO:root:current train perplexity303.25146484375
INFO:root:current mean train loss 7241.580116284141
INFO:root:current train perplexity303.61566162109375
INFO:root:current mean train loss 7238.4134123538515
INFO:root:current train perplexity303.2241516113281
INFO:root:current mean train loss 7248.556703210021
INFO:root:current train perplexity303.5945129394531
INFO:root:current mean train loss 7246.133456167408
INFO:root:current train perplexity303.6913757324219
INFO:root:current mean train loss 7248.369169151655
INFO:root:current train perplexity304.1084289550781
INFO:root:current mean train loss 7253.355575331356
INFO:root:current train perplexity304.5353698730469
INFO:root:current mean train loss 7246.415963493913
INFO:root:current train perplexity304.3682556152344
INFO:root:current mean train loss 7245.588412390495
INFO:root:current train perplexity304.280029296875
INFO:root:current mean train loss 7244.458364014869
INFO:root:current train perplexity304.2978820800781
INFO:root:current mean train loss 7245.3525077255235
INFO:root:current train perplexity304.35650634765625
INFO:root:current mean train loss 7243.49022147021
INFO:root:current train perplexity303.9405517578125
INFO:root:current mean train loss 7241.866455219492
INFO:root:current train perplexity303.5748291015625
INFO:root:current mean train loss 7241.464380591047
INFO:root:current train perplexity303.3068542480469
INFO:root:current mean train loss 7242.062765045245
INFO:root:current train perplexity303.25958251953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.78s/it]
INFO:root:final mean train loss: 7240.749918250442
INFO:root:final train perplexity: 303.1975402832031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 60.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.02s/it]
INFO:root:eval mean loss: 6949.576450645501
INFO:root:eval perplexity: 276.9119873046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.75s/it]
INFO:root:eval mean loss: 7017.909637667609
INFO:root:eval perplexity: 320.4174499511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [20:39:54<28:02:03, 877.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7186.9780606356535
INFO:root:current train perplexity289.4444885253906
INFO:root:current mean train loss 7243.923807779948
INFO:root:current train perplexity298.0534362792969
INFO:root:current mean train loss 7233.854200019211
INFO:root:current train perplexity298.1300354003906
INFO:root:current mean train loss 7232.924657067587
INFO:root:current train perplexity299.17718505859375
INFO:root:current mean train loss 7224.622101105011
INFO:root:current train perplexity299.34027099609375
INFO:root:current mean train loss 7215.421220667222
INFO:root:current train perplexity299.81854248046875
INFO:root:current mean train loss 7211.540108816965
INFO:root:current train perplexity300.128662109375
INFO:root:current mean train loss 7207.21189437374
INFO:root:current train perplexity300.0237731933594
INFO:root:current mean train loss 7213.50389872908
INFO:root:current train perplexity300.24774169921875
INFO:root:current mean train loss 7223.247633077331
INFO:root:current train perplexity300.91351318359375
INFO:root:current mean train loss 7224.048149021192
INFO:root:current train perplexity301.0220031738281
INFO:root:current mean train loss 7227.549055619674
INFO:root:current train perplexity301.2175598144531
INFO:root:current mean train loss 7227.831411478221
INFO:root:current train perplexity301.3067626953125
INFO:root:current mean train loss 7228.3739006405785
INFO:root:current train perplexity301.2300720214844
INFO:root:current mean train loss 7227.843175829943
INFO:root:current train perplexity300.9469299316406
INFO:root:current mean train loss 7231.564511946446
INFO:root:current train perplexity301.2983093261719
INFO:root:current mean train loss 7232.696000370666
INFO:root:current train perplexity301.3026123046875
INFO:root:current mean train loss 7235.9852857677215
INFO:root:current train perplexity301.501220703125
INFO:root:current mean train loss 7239.024176276946
INFO:root:current train perplexity301.6319274902344
INFO:root:current mean train loss 7236.244367937002
INFO:root:current train perplexity301.5857849121094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.70s/it]
INFO:root:final mean train loss: 7233.580951146267
INFO:root:final train perplexity: 301.4868469238281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it]
INFO:root:eval mean loss: 6965.580360358488
INFO:root:eval perplexity: 280.52154541015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.82s/it]
INFO:root:eval mean loss: 7033.146346721243
INFO:root:eval perplexity: 324.4562683105469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [20:54:45<27:54:52, 881.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7249.126737000513
INFO:root:current train perplexity301.7044372558594
INFO:root:current mean train loss 7237.720415008735
INFO:root:current train perplexity301.61639404296875
INFO:root:current mean train loss 7205.158756884579
INFO:root:current train perplexity297.8958740234375
INFO:root:current mean train loss 7210.666792005713
INFO:root:current train perplexity297.4045104980469
INFO:root:current mean train loss 7210.804278657131
INFO:root:current train perplexity296.7094421386719
INFO:root:current mean train loss 7217.708637094753
INFO:root:current train perplexity297.4843444824219
INFO:root:current mean train loss 7212.596169245225
INFO:root:current train perplexity297.1712951660156
INFO:root:current mean train loss 7215.0911359949905
INFO:root:current train perplexity297.38861083984375
INFO:root:current mean train loss 7213.8217024853
INFO:root:current train perplexity297.3199768066406
INFO:root:current mean train loss 7216.911794354839
INFO:root:current train perplexity296.8799743652344
INFO:root:current mean train loss 7212.832546683553
INFO:root:current train perplexity296.19769287109375
INFO:root:current mean train loss 7205.3496711987245
INFO:root:current train perplexity295.9879150390625
INFO:root:current mean train loss 7204.74261576254
INFO:root:current train perplexity295.982666015625
INFO:root:current mean train loss 7203.725049581535
INFO:root:current train perplexity295.5921325683594
INFO:root:current mean train loss 7202.806584477669
INFO:root:current train perplexity295.226318359375
INFO:root:current mean train loss 7200.474448595652
INFO:root:current train perplexity294.7366943359375
INFO:root:current mean train loss 7199.04002730377
INFO:root:current train perplexity294.5036315917969
INFO:root:current mean train loss 7201.657327490595
INFO:root:current train perplexity294.662353515625
INFO:root:current mean train loss 7200.22910492091
INFO:root:current train perplexity294.4393005371094
INFO:root:current mean train loss 7205.114064840563
INFO:root:current train perplexity294.5083923339844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.01s/it]
INFO:root:final mean train loss: 7204.101282901735
INFO:root:final train perplexity: 294.55377197265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it]
INFO:root:eval mean loss: 6916.845968043551
INFO:root:eval perplexity: 269.6738586425781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.73s/it]
INFO:root:eval mean loss: 6990.17524275543
INFO:root:eval perplexity: 313.19415283203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [21:09:31<27:42:56, 882.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7072.427264873798
INFO:root:current train perplexity280.7847900390625
INFO:root:current mean train loss 7173.1946431706465
INFO:root:current train perplexity287.6400146484375
INFO:root:current mean train loss 7163.547294781362
INFO:root:current train perplexity286.1217346191406
INFO:root:current mean train loss 7172.787239841683
INFO:root:current train perplexity287.3817443847656
INFO:root:current mean train loss 7192.085731155204
INFO:root:current train perplexity288.73388671875
INFO:root:current mean train loss 7203.436984685878
INFO:root:current train perplexity288.8233642578125
INFO:root:current mean train loss 7198.805170019819
INFO:root:current train perplexity288.4082946777344
INFO:root:current mean train loss 7198.58985065372
INFO:root:current train perplexity288.2126770019531
INFO:root:current mean train loss 7194.157917274701
INFO:root:current train perplexity287.25830078125
INFO:root:current mean train loss 7183.052440307867
INFO:root:current train perplexity285.8960266113281
INFO:root:current mean train loss 7175.622165432224
INFO:root:current train perplexity285.312744140625
INFO:root:current mean train loss 7168.397301354918
INFO:root:current train perplexity284.4873046875
INFO:root:current mean train loss 7160.423337933416
INFO:root:current train perplexity283.4953918457031
INFO:root:current mean train loss 7156.83098771714
INFO:root:current train perplexity282.9327697753906
INFO:root:current mean train loss 7155.501066752474
INFO:root:current train perplexity282.8042297363281
INFO:root:current mean train loss 7151.928776227325
INFO:root:current train perplexity282.511474609375
INFO:root:current mean train loss 7156.648817241973
INFO:root:current train perplexity282.73870849609375
INFO:root:current mean train loss 7154.210545062482
INFO:root:current train perplexity282.75689697265625
INFO:root:current mean train loss 7154.729973448732
INFO:root:current train perplexity282.6828918457031
INFO:root:current mean train loss 7151.8491712055265
INFO:root:current train perplexity282.2740783691406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.61s/it]
INFO:root:final mean train loss: 7150.171927324643
INFO:root:final train perplexity: 282.2802734375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.51s/it]
INFO:root:eval mean loss: 6811.536631482712
INFO:root:eval perplexity: 247.64476013183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.48s/it]
INFO:root:eval mean loss: 6894.090297401374
INFO:root:eval perplexity: 289.40557861328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [21:24:17<27:29:58, 883.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7094.122034333882
INFO:root:current train perplexity274.6316833496094
INFO:root:current mean train loss 7101.872478465545
INFO:root:current train perplexity276.6286315917969
INFO:root:current mean train loss 7090.413905256885
INFO:root:current train perplexity276.00054931640625
INFO:root:current mean train loss 7111.155322883703
INFO:root:current train perplexity277.72601318359375
INFO:root:current mean train loss 7116.4571269333965
INFO:root:current train perplexity278.5619812011719
INFO:root:current mean train loss 7127.916404608718
INFO:root:current train perplexity279.1804504394531
INFO:root:current mean train loss 7135.579928479092
INFO:root:current train perplexity279.7524108886719
INFO:root:current mean train loss 7133.076769482115
INFO:root:current train perplexity279.30987548828125
INFO:root:current mean train loss 7130.453514533869
INFO:root:current train perplexity278.7975769042969
INFO:root:current mean train loss 7130.920592218907
INFO:root:current train perplexity279.26220703125
INFO:root:current mean train loss 7135.039919556221
INFO:root:current train perplexity279.8922424316406
INFO:root:current mean train loss 7137.298095907427
INFO:root:current train perplexity280.4268798828125
INFO:root:current mean train loss 7137.503505067568
INFO:root:current train perplexity280.3937072753906
INFO:root:current mean train loss 7138.473143831206
INFO:root:current train perplexity280.30615234375
INFO:root:current mean train loss 7134.223704013378
INFO:root:current train perplexity280.0882263183594
INFO:root:current mean train loss 7136.613940353154
INFO:root:current train perplexity280.2037658691406
INFO:root:current mean train loss 7139.459764472714
INFO:root:current train perplexity280.3348693847656
INFO:root:current mean train loss 7141.21736186673
INFO:root:current train perplexity280.4538879394531
INFO:root:current mean train loss 7143.639077702424
INFO:root:current train perplexity280.4770202636719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:30<00:00, 750.35s/it]
INFO:root:final mean train loss: 7141.846135388104
INFO:root:final train perplexity: 280.4315490722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.16s/it]
INFO:root:eval mean loss: 6851.578474761746
INFO:root:eval perplexity: 255.8006134033203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.68s/it]
INFO:root:eval mean loss: 6930.7747430463205
INFO:root:eval perplexity: 298.266845703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [21:38:44<27:05:37, 878.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7087.177734375
INFO:root:current train perplexity275.7625732421875
INFO:root:current mean train loss 7128.257359095982
INFO:root:current train perplexity279.3213195800781
INFO:root:current mean train loss 7131.698258309994
INFO:root:current train perplexity279.5582580566406
INFO:root:current mean train loss 7124.3830488156045
INFO:root:current train perplexity278.3993225097656
INFO:root:current mean train loss 7120.994467726032
INFO:root:current train perplexity277.4794006347656
INFO:root:current mean train loss 7128.887041091919
INFO:root:current train perplexity277.7465515136719
INFO:root:current mean train loss 7120.825289458231
INFO:root:current train perplexity277.5780029296875
INFO:root:current mean train loss 7120.772131073341
INFO:root:current train perplexity277.7980651855469
INFO:root:current mean train loss 7122.637998984952
INFO:root:current train perplexity277.65704345703125
INFO:root:current mean train loss 7120.216394257127
INFO:root:current train perplexity278.1990661621094
INFO:root:current mean train loss 7126.7892289595175
INFO:root:current train perplexity278.8173828125
INFO:root:current mean train loss 7126.854223896274
INFO:root:current train perplexity279.47027587890625
INFO:root:current mean train loss 7141.8352046752525
INFO:root:current train perplexity280.290771484375
INFO:root:current mean train loss 7147.424979977492
INFO:root:current train perplexity280.81787109375
INFO:root:current mean train loss 7153.81854507403
INFO:root:current train perplexity281.2478942871094
INFO:root:current mean train loss 7157.53420746011
INFO:root:current train perplexity281.67413330078125
INFO:root:current mean train loss 7154.967587757347
INFO:root:current train perplexity281.6051025390625
INFO:root:current mean train loss 7154.173964170652
INFO:root:current train perplexity281.5515441894531
INFO:root:current mean train loss 7151.619226586214
INFO:root:current train perplexity281.6582946777344
INFO:root:current mean train loss 7149.5283614282325
INFO:root:current train perplexity281.4875183105469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.08s/it]
INFO:root:final mean train loss: 7146.572667108902
INFO:root:final train perplexity: 281.4795837402344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.43s/it]
INFO:root:eval mean loss: 6889.277090951906
INFO:root:eval perplexity: 263.7244873046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.68s/it]
INFO:root:eval mean loss: 6963.516086443096
INFO:root:eval perplexity: 306.4044494628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [21:53:07<26:42:09, 873.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7068.9281216325435
INFO:root:current train perplexity285.1784973144531
INFO:root:current mean train loss 7195.752138596173
INFO:root:current train perplexity286.2894592285156
INFO:root:current mean train loss 7217.817233556223
INFO:root:current train perplexity287.38983154296875
INFO:root:current mean train loss 7188.807862070194
INFO:root:current train perplexity285.39532470703125
INFO:root:current mean train loss 7174.101501038024
INFO:root:current train perplexity285.3700256347656
INFO:root:current mean train loss 7151.132123921904
INFO:root:current train perplexity284.9582824707031
INFO:root:current mean train loss 7151.284803818065
INFO:root:current train perplexity284.33013916015625
INFO:root:current mean train loss 7144.221587255658
INFO:root:current train perplexity282.7035217285156
INFO:root:current mean train loss 7138.75204972105
INFO:root:current train perplexity281.86749267578125
INFO:root:current mean train loss 7138.854128473156
INFO:root:current train perplexity281.4691162109375
INFO:root:current mean train loss 7146.717454559949
INFO:root:current train perplexity281.2701416015625
INFO:root:current mean train loss 7154.071998346158
INFO:root:current train perplexity281.389404296875
INFO:root:current mean train loss 7147.301243706774
INFO:root:current train perplexity281.0672912597656
INFO:root:current mean train loss 7141.917792395599
INFO:root:current train perplexity280.4645690917969
INFO:root:current mean train loss 7144.5643495916065
INFO:root:current train perplexity280.4693908691406
INFO:root:current mean train loss 7139.932085155739
INFO:root:current train perplexity280.3319396972656
INFO:root:current mean train loss 7142.010094143263
INFO:root:current train perplexity280.3150939941406
INFO:root:current mean train loss 7142.548924990511
INFO:root:current train perplexity280.4429016113281
INFO:root:current mean train loss 7143.876809497164
INFO:root:current train perplexity280.3184509277344
INFO:root:current mean train loss 7140.935099600262
INFO:root:current train perplexity280.1297607421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.59s/it]
INFO:root:final mean train loss: 7140.567426642083
INFO:root:final train perplexity: 280.14874267578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.22s/it]
INFO:root:eval mean loss: 6851.902186184065
INFO:root:eval perplexity: 255.86758422851562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.11s/it]
INFO:root:eval mean loss: 6928.958379217919
INFO:root:eval perplexity: 297.8218688964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [22:07:33<26:23:32, 871.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7113.100883152174
INFO:root:current train perplexity277.6308288574219
INFO:root:current mean train loss 7125.954482823202
INFO:root:current train perplexity279.06878662109375
INFO:root:current mean train loss 7141.665116472942
INFO:root:current train perplexity280.29974365234375
INFO:root:current mean train loss 7150.909830258761
INFO:root:current train perplexity279.71343994140625
INFO:root:current mean train loss 7150.844619272001
INFO:root:current train perplexity280.3975830078125
INFO:root:current mean train loss 7153.948209993132
INFO:root:current train perplexity281.165283203125
INFO:root:current mean train loss 7156.919972517173
INFO:root:current train perplexity281.07293701171875
INFO:root:current mean train loss 7151.888676456728
INFO:root:current train perplexity280.88079833984375
INFO:root:current mean train loss 7146.316172498337
INFO:root:current train perplexity281.0876770019531
INFO:root:current mean train loss 7148.099730154929
INFO:root:current train perplexity281.2275085449219
INFO:root:current mean train loss 7152.193304758455
INFO:root:current train perplexity281.33453369140625
INFO:root:current mean train loss 7153.029221033758
INFO:root:current train perplexity281.5825500488281
INFO:root:current mean train loss 7153.5246362579
INFO:root:current train perplexity282.0410461425781
INFO:root:current mean train loss 7152.394564987115
INFO:root:current train perplexity282.32550048828125
INFO:root:current mean train loss 7148.535593879668
INFO:root:current train perplexity282.4244689941406
INFO:root:current mean train loss 7151.909937692028
INFO:root:current train perplexity282.4472351074219
INFO:root:current mean train loss 7159.468650326549
INFO:root:current train perplexity282.9179382324219
INFO:root:current mean train loss 7156.752516634003
INFO:root:current train perplexity282.838623046875
INFO:root:current mean train loss 7155.626939899614
INFO:root:current train perplexity282.8132629394531
INFO:root:current mean train loss 7156.216947675119
INFO:root:current train perplexity282.9082336425781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.74s/it]
INFO:root:final mean train loss: 7152.785507625363
INFO:root:final train perplexity: 282.8628845214844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.51s/it]
INFO:root:eval mean loss: 6900.877102033466
INFO:root:eval perplexity: 266.21160888671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.04s/it]
INFO:root:eval mean loss: 6974.734606154421
INFO:root:eval perplexity: 309.2436218261719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [22:21:57<26:04:45, 869.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7223.647398933532
INFO:root:current train perplexity289.9883728027344
INFO:root:current mean train loss 7238.40307467408
INFO:root:current train perplexity290.660888671875
INFO:root:current mean train loss 7219.617750044558
INFO:root:current train perplexity290.0552978515625
INFO:root:current mean train loss 7206.097344180441
INFO:root:current train perplexity290.1940612792969
INFO:root:current mean train loss 7194.223141367441
INFO:root:current train perplexity289.2320251464844
INFO:root:current mean train loss 7196.696644649201
INFO:root:current train perplexity289.0121154785156
INFO:root:current mean train loss 7200.562611943816
INFO:root:current train perplexity289.1895446777344
INFO:root:current mean train loss 7200.407201604481
INFO:root:current train perplexity288.842529296875
INFO:root:current mean train loss 7196.640327391729
INFO:root:current train perplexity288.9393615722656
INFO:root:current mean train loss 7198.441960953725
INFO:root:current train perplexity289.17340087890625
INFO:root:current mean train loss 7196.82412045067
INFO:root:current train perplexity289.0216369628906
INFO:root:current mean train loss 7195.419733783857
INFO:root:current train perplexity288.7015075683594
INFO:root:current mean train loss 7190.090084991092
INFO:root:current train perplexity288.51531982421875
INFO:root:current mean train loss 7185.683852757589
INFO:root:current train perplexity288.27618408203125
INFO:root:current mean train loss 7180.687969924812
INFO:root:current train perplexity287.9049987792969
INFO:root:current mean train loss 7177.202978484385
INFO:root:current train perplexity287.8454284667969
INFO:root:current mean train loss 7177.493937443626
INFO:root:current train perplexity288.10455322265625
INFO:root:current mean train loss 7179.538131912933
INFO:root:current train perplexity288.2364501953125
INFO:root:current mean train loss 7179.301763840664
INFO:root:current train perplexity288.03875732421875
INFO:root:current mean train loss 7177.299221386669
INFO:root:current train perplexity287.8355407714844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.50s/it]
INFO:root:final mean train loss: 7174.812995791375
INFO:root:final train perplexity: 287.8234558105469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it]
INFO:root:eval mean loss: 6897.740629155585
INFO:root:eval perplexity: 265.53662109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.67s/it]
INFO:root:eval mean loss: 6970.310671542553
INFO:root:eval perplexity: 308.120849609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [22:36:37<25:56:06, 872.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7143.805212402343
INFO:root:current train perplexity284.1044921875
INFO:root:current mean train loss 7211.47600640191
INFO:root:current train perplexity287.1855773925781
INFO:root:current mean train loss 7199.072286551339
INFO:root:current train perplexity287.53155517578125
INFO:root:current mean train loss 7164.503614566201
INFO:root:current train perplexity286.2183532714844
INFO:root:current mean train loss 7170.968379720052
INFO:root:current train perplexity286.7099609375
INFO:root:current mean train loss 7177.611344120421
INFO:root:current train perplexity287.5378723144531
INFO:root:current mean train loss 7179.337869801241
INFO:root:current train perplexity288.3793029785156
INFO:root:current mean train loss 7172.681719501202
INFO:root:current train perplexity288.257080078125
INFO:root:current mean train loss 7177.729488303445
INFO:root:current train perplexity288.45782470703125
INFO:root:current mean train loss 7185.391514369419
INFO:root:current train perplexity288.78082275390625
INFO:root:current mean train loss 7182.684343804253
INFO:root:current train perplexity288.661865234375
INFO:root:current mean train loss 7189.596330028469
INFO:root:current train perplexity289.0339050292969
INFO:root:current mean train loss 7187.441232299805
INFO:root:current train perplexity289.0726318359375
INFO:root:current mean train loss 7185.439267719656
INFO:root:current train perplexity289.2077331542969
INFO:root:current mean train loss 7184.589580803949
INFO:root:current train perplexity289.14349365234375
INFO:root:current mean train loss 7183.609093465684
INFO:root:current train perplexity289.0894470214844
INFO:root:current mean train loss 7180.279087320963
INFO:root:current train perplexity288.8907470703125
INFO:root:current mean train loss 7182.03548076501
INFO:root:current train perplexity288.89886474609375
INFO:root:current mean train loss 7179.327995917138
INFO:root:current train perplexity288.66998291015625
INFO:root:current mean train loss 7180.20231539023
INFO:root:current train perplexity288.687744140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.02s/it]
INFO:root:final mean train loss: 7178.744968339282
INFO:root:final train perplexity: 288.7178955078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.78s/it]
INFO:root:eval mean loss: 6931.573848210328
INFO:root:eval perplexity: 272.9070739746094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it]
INFO:root:eval mean loss: 7002.040619978668
INFO:root:eval perplexity: 316.2643737792969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [22:51:18<25:45:51, 875.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7286.132309117268
INFO:root:current train perplexity293.1188659667969
INFO:root:current mean train loss 7207.708848052824
INFO:root:current train perplexity289.71014404296875
INFO:root:current mean train loss 7187.091144189289
INFO:root:current train perplexity288.7917175292969
INFO:root:current mean train loss 7198.360288836193
INFO:root:current train perplexity289.6373596191406
INFO:root:current mean train loss 7187.973974707621
INFO:root:current train perplexity288.9410095214844
INFO:root:current mean train loss 7190.488725365107
INFO:root:current train perplexity288.70013427734375
INFO:root:current mean train loss 7183.452766319942
INFO:root:current train perplexity288.1972961425781
INFO:root:current mean train loss 7172.8012033651585
INFO:root:current train perplexity287.45574951171875
INFO:root:current mean train loss 7175.817569524283
INFO:root:current train perplexity287.1709289550781
INFO:root:current mean train loss 7179.678459205742
INFO:root:current train perplexity287.2681579589844
INFO:root:current mean train loss 7175.198152276094
INFO:root:current train perplexity287.21636962890625
INFO:root:current mean train loss 7175.761125633093
INFO:root:current train perplexity287.42120361328125
INFO:root:current mean train loss 7177.736535936296
INFO:root:current train perplexity287.8436279296875
INFO:root:current mean train loss 7182.909933954456
INFO:root:current train perplexity288.1504211425781
INFO:root:current mean train loss 7182.763579894164
INFO:root:current train perplexity288.36444091796875
INFO:root:current mean train loss 7177.373311653687
INFO:root:current train perplexity288.23260498046875
INFO:root:current mean train loss 7180.138042029593
INFO:root:current train perplexity288.2885437011719
INFO:root:current mean train loss 7176.916312343489
INFO:root:current train perplexity288.3902893066406
INFO:root:current mean train loss 7177.060555626483
INFO:root:current train perplexity288.40185546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.56s/it]
INFO:root:final mean train loss: 7177.85231055771
INFO:root:final train perplexity: 288.5146484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it]
INFO:root:eval mean loss: 6917.279263976618
INFO:root:eval perplexity: 269.7685241699219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.91s/it]
INFO:root:eval mean loss: 6987.579035765736
INFO:root:eval perplexity: 312.52642822265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [23:05:54<25:32:05, 875.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7216.227015904018
INFO:root:current train perplexity282.94073486328125
INFO:root:current mean train loss 7191.5586151658445
INFO:root:current train perplexity286.9315185546875
INFO:root:current mean train loss 7151.393712123978
INFO:root:current train perplexity285.7611083984375
INFO:root:current mean train loss 7160.43529340416
INFO:root:current train perplexity286.0293884277344
INFO:root:current mean train loss 7174.796330106431
INFO:root:current train perplexity286.9212646484375
INFO:root:current mean train loss 7181.750092146462
INFO:root:current train perplexity286.8280944824219
INFO:root:current mean train loss 7178.846804541175
INFO:root:current train perplexity287.0054016113281
INFO:root:current mean train loss 7180.565549364277
INFO:root:current train perplexity287.6929626464844
INFO:root:current mean train loss 7183.331779311272
INFO:root:current train perplexity287.97613525390625
INFO:root:current mean train loss 7181.648852058261
INFO:root:current train perplexity288.18408203125
INFO:root:current mean train loss 7175.265478611933
INFO:root:current train perplexity287.6964111328125
INFO:root:current mean train loss 7179.267442247812
INFO:root:current train perplexity287.746337890625
INFO:root:current mean train loss 7170.136961281791
INFO:root:current train perplexity287.4275207519531
INFO:root:current mean train loss 7166.818605002021
INFO:root:current train perplexity287.19091796875
INFO:root:current mean train loss 7170.934994709711
INFO:root:current train perplexity287.5536193847656
INFO:root:current mean train loss 7165.203618763932
INFO:root:current train perplexity287.36639404296875
INFO:root:current mean train loss 7171.171236362008
INFO:root:current train perplexity287.72808837890625
INFO:root:current mean train loss 7175.7691720185785
INFO:root:current train perplexity288.1710510253906
INFO:root:current mean train loss 7181.684357934382
INFO:root:current train perplexity288.6415100097656
INFO:root:current mean train loss 7182.01147843603
INFO:root:current train perplexity289.0093688964844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.39s/it]
INFO:root:final mean train loss: 7180.7609370814025
INFO:root:final train perplexity: 289.1773986816406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.31s/it]
INFO:root:eval mean loss: 6937.580670295878
INFO:root:eval perplexity: 274.23687744140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.20s/it]
INFO:root:eval mean loss: 7005.612244950964
INFO:root:eval perplexity: 317.19439697265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [23:20:35<25:20:04, 876.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7239.9912266885085
INFO:root:current train perplexity295.1944885253906
INFO:root:current mean train loss 7201.4610493201335
INFO:root:current train perplexity289.59967041015625
INFO:root:current mean train loss 7177.723239650974
INFO:root:current train perplexity289.8476257324219
INFO:root:current mean train loss 7176.921582916352
INFO:root:current train perplexity289.4160461425781
INFO:root:current mean train loss 7181.387736097013
INFO:root:current train perplexity289.7539367675781
INFO:root:current mean train loss 7181.360488575506
INFO:root:current train perplexity289.6511535644531
INFO:root:current mean train loss 7189.832346969097
INFO:root:current train perplexity290.4795227050781
INFO:root:current mean train loss 7189.472253468066
INFO:root:current train perplexity290.50640869140625
INFO:root:current mean train loss 7194.1082121737745
INFO:root:current train perplexity290.60546875
INFO:root:current mean train loss 7196.43472345764
INFO:root:current train perplexity291.0499267578125
INFO:root:current mean train loss 7202.952637192349
INFO:root:current train perplexity291.2297058105469
INFO:root:current mean train loss 7200.0314278708
INFO:root:current train perplexity291.1280822753906
INFO:root:current mean train loss 7203.626171716338
INFO:root:current train perplexity291.4300231933594
INFO:root:current mean train loss 7198.169102692407
INFO:root:current train perplexity291.39459228515625
INFO:root:current mean train loss 7194.205302304442
INFO:root:current train perplexity291.22650146484375
INFO:root:current mean train loss 7192.378829706891
INFO:root:current train perplexity291.1468200683594
INFO:root:current mean train loss 7197.958518546904
INFO:root:current train perplexity291.3098449707031
INFO:root:current mean train loss 7195.617190602885
INFO:root:current train perplexity291.2440185546875
INFO:root:current mean train loss 7196.663788625154
INFO:root:current train perplexity291.3787536621094
INFO:root:current mean train loss 7194.242645437516
INFO:root:current train perplexity291.37957763671875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.78s/it]
INFO:root:final mean train loss: 7190.23419734245
INFO:root:final train perplexity: 291.3476257324219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.06s/it]
INFO:root:eval mean loss: 6932.420507119902
INFO:root:eval perplexity: 273.0942687988281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.77s/it]
INFO:root:eval mean loss: 7001.118795191988
INFO:root:eval perplexity: 316.024658203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [23:35:18<25:08:33, 878.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7267.722625732422
INFO:root:current train perplexity294.59124755859375
INFO:root:current mean train loss 7227.612825960727
INFO:root:current train perplexity291.9105529785156
INFO:root:current mean train loss 7190.729799332157
INFO:root:current train perplexity289.1119079589844
INFO:root:current mean train loss 7199.121218626527
INFO:root:current train perplexity289.298095703125
INFO:root:current mean train loss 7197.649011884417
INFO:root:current train perplexity290.191162109375
INFO:root:current mean train loss 7203.692569927578
INFO:root:current train perplexity290.1334533691406
INFO:root:current mean train loss 7204.250785168307
INFO:root:current train perplexity290.0281982421875
INFO:root:current mean train loss 7203.135193850268
INFO:root:current train perplexity290.1780090332031
INFO:root:current mean train loss 7200.8040552679095
INFO:root:current train perplexity290.3611145019531
INFO:root:current mean train loss 7196.334062149756
INFO:root:current train perplexity290.3130798339844
INFO:root:current mean train loss 7196.369814807222
INFO:root:current train perplexity290.78082275390625
INFO:root:current mean train loss 7192.70723583474
INFO:root:current train perplexity290.6453857421875
INFO:root:current mean train loss 7193.997517512395
INFO:root:current train perplexity291.0085754394531
INFO:root:current mean train loss 7197.462405966015
INFO:root:current train perplexity291.0689392089844
INFO:root:current mean train loss 7194.582748834599
INFO:root:current train perplexity291.03009033203125
INFO:root:current mean train loss 7192.5040005627225
INFO:root:current train perplexity290.8845520019531
INFO:root:current mean train loss 7190.605647114874
INFO:root:current train perplexity290.8006286621094
INFO:root:current mean train loss 7189.677831304974
INFO:root:current train perplexity290.6410827636719
INFO:root:current mean train loss 7187.790048310251
INFO:root:current train perplexity290.549072265625
INFO:root:current mean train loss 7189.650905977284
INFO:root:current train perplexity290.63067626953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:27<00:00, 747.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:27<00:00, 747.89s/it]
INFO:root:final mean train loss: 7187.242265186705
INFO:root:final train perplexity: 290.6606140136719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.99s/it]
INFO:root:eval mean loss: 6931.73571171321
INFO:root:eval perplexity: 272.94287109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.41s/it]
INFO:root:eval mean loss: 6999.809237865691
INFO:root:eval perplexity: 315.68475341796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [23:49:41<24:46:16, 874.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7153.482053786058
INFO:root:current train perplexity293.43841552734375
INFO:root:current mean train loss 7228.96679095644
INFO:root:current train perplexity293.3332214355469
INFO:root:current mean train loss 7170.87353515625
INFO:root:current train perplexity289.85137939453125
INFO:root:current mean train loss 7180.130241331336
INFO:root:current train perplexity289.8423767089844
INFO:root:current mean train loss 7189.7504630796375
INFO:root:current train perplexity289.5905456542969
INFO:root:current mean train loss 7184.7294481125555
INFO:root:current train perplexity289.1055603027344
INFO:root:current mean train loss 7185.693345424107
INFO:root:current train perplexity289.308837890625
INFO:root:current mean train loss 7182.652356515523
INFO:root:current train perplexity288.9816589355469
INFO:root:current mean train loss 7185.703636989704
INFO:root:current train perplexity289.1240539550781
INFO:root:current mean train loss 7186.97574886658
INFO:root:current train perplexity289.01544189453125
INFO:root:current mean train loss 7184.313988684712
INFO:root:current train perplexity288.79364013671875
INFO:root:current mean train loss 7179.499834445413
INFO:root:current train perplexity288.36114501953125
INFO:root:current mean train loss 7173.241483448616
INFO:root:current train perplexity288.0413513183594
INFO:root:current mean train loss 7170.4008778331045
INFO:root:current train perplexity287.7836608886719
INFO:root:current mean train loss 7172.7395024530715
INFO:root:current train perplexity287.74688720703125
INFO:root:current mean train loss 7176.392005291534
INFO:root:current train perplexity288.0284423828125
INFO:root:current mean train loss 7177.082671734234
INFO:root:current train perplexity288.0408020019531
INFO:root:current mean train loss 7174.882197791254
INFO:root:current train perplexity287.8719177246094
INFO:root:current mean train loss 7176.313159768767
INFO:root:current train perplexity287.8310241699219
INFO:root:current mean train loss 7175.083011291348
INFO:root:current train perplexity287.59283447265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.79s/it]
INFO:root:final mean train loss: 7173.696909324965
INFO:root:final train perplexity: 287.56982421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.96s/it]
INFO:root:eval mean loss: 6908.683309785018
INFO:root:eval perplexity: 267.89849853515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.04s/it]
INFO:root:eval mean loss: 6979.296563331117
INFO:root:eval perplexity: 310.4057312011719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [24:04:21<24:34:12, 875.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7131.4674697503815
INFO:root:current train perplexity282.9449157714844
INFO:root:current mean train loss 7159.694786658654
INFO:root:current train perplexity283.6370849609375
INFO:root:current mean train loss 7177.498391442265
INFO:root:current train perplexity284.8919677734375
INFO:root:current mean train loss 7172.815437356839
INFO:root:current train perplexity285.2957458496094
INFO:root:current mean train loss 7179.1013882585585
INFO:root:current train perplexity286.1678466796875
INFO:root:current mean train loss 7171.366460950923
INFO:root:current train perplexity286.0694885253906
INFO:root:current mean train loss 7160.608649021719
INFO:root:current train perplexity285.65142822265625
INFO:root:current mean train loss 7157.771953299833
INFO:root:current train perplexity285.5328063964844
INFO:root:current mean train loss 7155.922003436792
INFO:root:current train perplexity285.4693603515625
INFO:root:current mean train loss 7150.33796073463
INFO:root:current train perplexity285.13934326171875
INFO:root:current mean train loss 7151.73889724252
INFO:root:current train perplexity285.06646728515625
INFO:root:current mean train loss 7156.586724037648
INFO:root:current train perplexity285.1001892089844
INFO:root:current mean train loss 7155.356478829465
INFO:root:current train perplexity284.7821044921875
INFO:root:current mean train loss 7156.249043576452
INFO:root:current train perplexity284.5459289550781
INFO:root:current mean train loss 7160.127435146234
INFO:root:current train perplexity284.60467529296875
INFO:root:current mean train loss 7158.267324107636
INFO:root:current train perplexity284.584716796875
INFO:root:current mean train loss 7162.672712800052
INFO:root:current train perplexity284.642822265625
INFO:root:current mean train loss 7160.477652227571
INFO:root:current train perplexity284.550537109375
INFO:root:current mean train loss 7160.573315092405
INFO:root:current train perplexity284.3972473144531
INFO:root:current mean train loss 7161.240289312799
INFO:root:current train perplexity284.2969055175781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.06s/it]
INFO:root:final mean train loss: 7159.177601162617
INFO:root:final train perplexity: 284.29339599609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.54s/it]
INFO:root:eval mean loss: 6871.02498891844
INFO:root:eval perplexity: 259.8577575683594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.12s/it]
INFO:root:eval mean loss: 6945.3263458901265
INFO:root:eval perplexity: 301.85638427734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [24:18:59<24:20:49, 876.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7190.188106652462
INFO:root:current train perplexity281.5476379394531
INFO:root:current mean train loss 7179.466161373272
INFO:root:current train perplexity280.18853759765625
INFO:root:current mean train loss 7182.346496786162
INFO:root:current train perplexity279.54638671875
INFO:root:current mean train loss 7182.583662525454
INFO:root:current train perplexity280.1101379394531
INFO:root:current mean train loss 7168.254865199148
INFO:root:current train perplexity279.6799621582031
INFO:root:current mean train loss 7165.228189560727
INFO:root:current train perplexity280.3620300292969
INFO:root:current mean train loss 7164.319942970986
INFO:root:current train perplexity280.74945068359375
INFO:root:current mean train loss 7153.5946452841445
INFO:root:current train perplexity280.18212890625
INFO:root:current mean train loss 7148.023478778504
INFO:root:current train perplexity279.7804260253906
INFO:root:current mean train loss 7144.776401401401
INFO:root:current train perplexity279.7905578613281
INFO:root:current mean train loss 7144.747092971594
INFO:root:current train perplexity279.8580627441406
INFO:root:current mean train loss 7139.99149030442
INFO:root:current train perplexity279.6219787597656
INFO:root:current mean train loss 7141.56103515625
INFO:root:current train perplexity280.1363220214844
INFO:root:current mean train loss 7138.635045889363
INFO:root:current train perplexity280.1722412109375
INFO:root:current mean train loss 7140.448691705929
INFO:root:current train perplexity280.1888122558594
INFO:root:current mean train loss 7141.255464841307
INFO:root:current train perplexity280.24786376953125
INFO:root:current mean train loss 7140.329407061598
INFO:root:current train perplexity280.36029052734375
INFO:root:current mean train loss 7141.233174517527
INFO:root:current train perplexity280.3851623535156
INFO:root:current mean train loss 7146.014549701323
INFO:root:current train perplexity280.662841796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.35s/it]
INFO:root:final mean train loss: 7141.938830153965
INFO:root:final train perplexity: 280.4519958496094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.08s/it]
INFO:root:eval mean loss: 6869.0643682818045
INFO:root:eval perplexity: 259.4458312988281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.54s/it]
INFO:root:eval mean loss: 6944.613495089484
INFO:root:eval perplexity: 301.6795654296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [24:33:28<24:02:46, 874.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7237.549896240234
INFO:root:current train perplexity282.70782470703125
INFO:root:current mean train loss 7138.3014126481685
INFO:root:current train perplexity276.52813720703125
INFO:root:current mean train loss 7118.47391990379
INFO:root:current train perplexity275.63214111328125
INFO:root:current mean train loss 7123.366305194324
INFO:root:current train perplexity275.2319641113281
INFO:root:current mean train loss 7135.5692138671875
INFO:root:current train perplexity276.06109619140625
INFO:root:current mean train loss 7152.53996903767
INFO:root:current train perplexity277.7705078125
INFO:root:current mean train loss 7151.52328689377
INFO:root:current train perplexity278.47723388671875
INFO:root:current mean train loss 7149.840839407298
INFO:root:current train perplexity279.04217529296875
INFO:root:current mean train loss 7139.936640720742
INFO:root:current train perplexity278.5634460449219
INFO:root:current mean train loss 7143.732161209573
INFO:root:current train perplexity278.69842529296875
INFO:root:current mean train loss 7149.545344795768
INFO:root:current train perplexity279.36846923828125
INFO:root:current mean train loss 7148.892410551775
INFO:root:current train perplexity279.8865051269531
INFO:root:current mean train loss 7153.155118841874
INFO:root:current train perplexity280.5378723144531
INFO:root:current mean train loss 7150.424242941442
INFO:root:current train perplexity280.7885437011719
INFO:root:current mean train loss 7148.980137711865
INFO:root:current train perplexity280.8245544433594
INFO:root:current mean train loss 7149.517482143593
INFO:root:current train perplexity281.05657958984375
INFO:root:current mean train loss 7148.081232656346
INFO:root:current train perplexity281.0179748535156
INFO:root:current mean train loss 7148.260384797494
INFO:root:current train perplexity280.97509765625
INFO:root:current mean train loss 7144.3359200229725
INFO:root:current train perplexity280.67877197265625
INFO:root:current mean train loss 7143.751127685037
INFO:root:current train perplexity280.3951721191406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.93s/it]
INFO:root:final mean train loss: 7141.425930344451
INFO:root:final train perplexity: 280.3383483886719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.53s/it]
INFO:root:eval mean loss: 6875.683801529255
INFO:root:eval perplexity: 260.83935546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.41s/it]
INFO:root:eval mean loss: 6955.4271240234375
INFO:root:eval perplexity: 304.3736267089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [24:47:59<23:46:11, 873.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7142.418856534091
INFO:root:current train perplexity275.61126708984375
INFO:root:current mean train loss 7108.449655633223
INFO:root:current train perplexity274.80352783203125
INFO:root:current mean train loss 7120.153768776824
INFO:root:current train perplexity275.53765869140625
INFO:root:current mean train loss 7108.632104272241
INFO:root:current train perplexity274.76397705078125
INFO:root:current mean train loss 7124.371130963121
INFO:root:current train perplexity274.6227722167969
INFO:root:current mean train loss 7145.432124325751
INFO:root:current train perplexity275.28106689453125
INFO:root:current mean train loss 7145.697719965689
INFO:root:current train perplexity274.8644714355469
INFO:root:current mean train loss 7140.702707329681
INFO:root:current train perplexity274.86761474609375
INFO:root:current mean train loss 7126.309619550945
INFO:root:current train perplexity274.2784423828125
INFO:root:current mean train loss 7124.895055642082
INFO:root:current train perplexity273.9481506347656
INFO:root:current mean train loss 7119.631543819579
INFO:root:current train perplexity273.7597351074219
INFO:root:current mean train loss 7113.804415562252
INFO:root:current train perplexity273.81781005859375
INFO:root:current mean train loss 7110.98568025142
INFO:root:current train perplexity274.15045166015625
INFO:root:current mean train loss 7111.380260104089
INFO:root:current train perplexity274.4718322753906
INFO:root:current mean train loss 7115.1921790496335
INFO:root:current train perplexity275.0069885253906
INFO:root:current mean train loss 7117.544477230104
INFO:root:current train perplexity275.3341064453125
INFO:root:current mean train loss 7116.280785041431
INFO:root:current train perplexity275.72021484375
INFO:root:current mean train loss 7115.370285958688
INFO:root:current train perplexity276.1510009765625
INFO:root:current mean train loss 7121.400648484384
INFO:root:current train perplexity276.604736328125
INFO:root:current mean train loss 7124.953597367273
INFO:root:current train perplexity276.6568603515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.39s/it]
INFO:root:final mean train loss: 7124.525266277026
INFO:root:final train perplexity: 276.624267578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.29s/it]
INFO:root:eval mean loss: 6873.179452016844
INFO:root:eval perplexity: 260.3111572265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.18s/it]
INFO:root:eval mean loss: 6947.835108114473
INFO:root:eval perplexity: 302.4798583984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [25:02:39<23:35:06, 875.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7246.23060546875
INFO:root:current train perplexity277.7314453125
INFO:root:current mean train loss 7179.837526041667
INFO:root:current train perplexity278.56610107421875
INFO:root:current mean train loss 7161.808591796875
INFO:root:current train perplexity276.33660888671875
INFO:root:current mean train loss 7131.322576729911
INFO:root:current train perplexity274.444091796875
INFO:root:current mean train loss 7129.452913411458
INFO:root:current train perplexity273.6358642578125
INFO:root:current mean train loss 7117.362019708807
INFO:root:current train perplexity272.3389892578125
INFO:root:current mean train loss 7102.429260817307
INFO:root:current train perplexity271.087158203125
INFO:root:current mean train loss 7094.580780598958
INFO:root:current train perplexity270.0443115234375
INFO:root:current mean train loss 7089.8509334788605
INFO:root:current train perplexity269.2759094238281
INFO:root:current mean train loss 7092.105279605264
INFO:root:current train perplexity269.1015930175781
INFO:root:current mean train loss 7090.902133556548
INFO:root:current train perplexity268.35198974609375
INFO:root:current mean train loss 7083.820517153533
INFO:root:current train perplexity267.3953857421875
INFO:root:current mean train loss 7085.49923125
INFO:root:current train perplexity267.1197509765625
INFO:root:current mean train loss 7080.677062355324
INFO:root:current train perplexity266.4893493652344
INFO:root:current mean train loss 7077.143797144397
INFO:root:current train perplexity265.9129333496094
INFO:root:current mean train loss 7077.865230279738
INFO:root:current train perplexity265.4583740234375
INFO:root:current mean train loss 7072.058120265152
INFO:root:current train perplexity264.8821716308594
INFO:root:current mean train loss 7069.747537946429
INFO:root:current train perplexity264.3529968261719
INFO:root:current mean train loss 7069.268390783362
INFO:root:current train perplexity264.0824890136719
INFO:root:current mean train loss 7065.944558042868
INFO:root:current train perplexity263.5386962890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.66s/it]
INFO:root:final mean train loss: 7062.820566243736
INFO:root:final train perplexity: 263.4761047363281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it]
INFO:root:eval mean loss: 6747.24763131649
INFO:root:eval perplexity: 235.09092712402344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.68s/it]
INFO:root:eval mean loss: 6834.480779553136
INFO:root:eval perplexity: 275.5647277832031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [25:17:18<23:22:01, 876.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6964.497427413713
INFO:root:current train perplexity251.9950408935547
INFO:root:current mean train loss 7041.885011227545
INFO:root:current train perplexity261.6264953613281
INFO:root:current mean train loss 7091.659265639631
INFO:root:current train perplexity273.10089111328125
INFO:root:current mean train loss 7108.357783761921
INFO:root:current train perplexity275.14404296875
INFO:root:current mean train loss 7122.374978043027
INFO:root:current train perplexity276.3496398925781
INFO:root:current mean train loss 7131.485538435571
INFO:root:current train perplexity277.1785583496094
INFO:root:current mean train loss 7125.470088930144
INFO:root:current train perplexity277.8478698730469
INFO:root:current mean train loss 7126.316676173403
INFO:root:current train perplexity277.69305419921875
INFO:root:current mean train loss 7128.223622111988
INFO:root:current train perplexity277.81634521484375
INFO:root:current mean train loss 7130.181394717069
INFO:root:current train perplexity277.4778137207031
INFO:root:current mean train loss 7130.707556598524
INFO:root:current train perplexity277.02105712890625
INFO:root:current mean train loss 7127.495283713582
INFO:root:current train perplexity276.56121826171875
INFO:root:current mean train loss 7123.755998883928
INFO:root:current train perplexity276.240966796875
INFO:root:current mean train loss 7119.003980545904
INFO:root:current train perplexity275.9014587402344
INFO:root:current mean train loss 7116.802122941696
INFO:root:current train perplexity275.68865966796875
INFO:root:current mean train loss 7116.958300095725
INFO:root:current train perplexity275.61480712890625
INFO:root:current mean train loss 7114.092158911968
INFO:root:current train perplexity275.4764404296875
INFO:root:current mean train loss 7114.147719585632
INFO:root:current train perplexity275.1768493652344
INFO:root:current mean train loss 7114.955277412794
INFO:root:current train perplexity274.9925537109375
INFO:root:current mean train loss 7117.963763672868
INFO:root:current train perplexity274.8787536621094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.54s/it]
INFO:root:final mean train loss: 7116.734924716536
INFO:root:final train perplexity: 274.9287109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.89s/it]
INFO:root:eval mean loss: 6764.706873684065
INFO:root:eval perplexity: 238.4359130859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.54s/it]
INFO:root:eval mean loss: 6853.871161278258
INFO:root:eval perplexity: 279.9928894042969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [25:31:57<23:08:57, 877.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7049.094540550595
INFO:root:current train perplexity270.0745849609375
INFO:root:current mean train loss 7020.679761803668
INFO:root:current train perplexity268.0994873046875
INFO:root:current mean train loss 7047.439093791263
INFO:root:current train perplexity268.9187927246094
INFO:root:current mean train loss 7061.781299591064
INFO:root:current train perplexity269.16217041015625
INFO:root:current mean train loss 7064.979857389592
INFO:root:current train perplexity268.4917297363281
INFO:root:current mean train loss 7064.69130006555
INFO:root:current train perplexity268.2439880371094
INFO:root:current mean train loss 7066.216942502741
INFO:root:current train perplexity267.92596435546875
INFO:root:current mean train loss 7077.776050178372
INFO:root:current train perplexity267.9926452636719
INFO:root:current mean train loss 7079.536849768453
INFO:root:current train perplexity268.5845947265625
INFO:root:current mean train loss 7078.709537164952
INFO:root:current train perplexity268.5908508300781
INFO:root:current mean train loss 7079.49616537059
INFO:root:current train perplexity268.5458984375
INFO:root:current mean train loss 7081.8239873937655
INFO:root:current train perplexity268.4569091796875
INFO:root:current mean train loss 7081.009648498345
INFO:root:current train perplexity268.4931640625
INFO:root:current mean train loss 7085.845138285202
INFO:root:current train perplexity268.621337890625
INFO:root:current mean train loss 7086.160339190954
INFO:root:current train perplexity268.623779296875
INFO:root:current mean train loss 7083.865521980055
INFO:root:current train perplexity268.1823425292969
INFO:root:current mean train loss 7081.830611638955
INFO:root:current train perplexity267.5430908203125
INFO:root:current mean train loss 7081.310304102876
INFO:root:current train perplexity267.404052734375
INFO:root:current mean train loss 7081.290679478088
INFO:root:current train perplexity267.44384765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.22s/it]
INFO:root:final mean train loss: 7081.197717833026
INFO:root:final train perplexity: 267.3252868652344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.11s/it]
INFO:root:eval mean loss: 6754.748041680518
INFO:root:eval perplexity: 236.52207946777344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.14s/it]
INFO:root:eval mean loss: 6842.31526519559
INFO:root:eval perplexity: 277.34539794921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [25:46:37<22:55:36, 878.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6950.36669921875
INFO:root:current train perplexity278.0572814941406
INFO:root:current mean train loss 7079.845239016089
INFO:root:current train perplexity263.8604431152344
INFO:root:current mean train loss 7058.228224113806
INFO:root:current train perplexity262.7009582519531
INFO:root:current mean train loss 7079.309696843854
INFO:root:current train perplexity264.1779479980469
INFO:root:current mean train loss 7095.1529793679865
INFO:root:current train perplexity264.5143737792969
INFO:root:current mean train loss 7087.807862790045
INFO:root:current train perplexity264.3534851074219
INFO:root:current mean train loss 7083.625567901155
INFO:root:current train perplexity264.20819091796875
INFO:root:current mean train loss 7077.701829417796
INFO:root:current train perplexity263.7902526855469
INFO:root:current mean train loss 7075.641174240208
INFO:root:current train perplexity263.3520202636719
INFO:root:current mean train loss 7068.466869493965
INFO:root:current train perplexity263.0732421875
INFO:root:current mean train loss 7064.362991988481
INFO:root:current train perplexity262.47906494140625
INFO:root:current mean train loss 7059.248505442495
INFO:root:current train perplexity261.9579162597656
INFO:root:current mean train loss 7056.826206026228
INFO:root:current train perplexity261.5240783691406
INFO:root:current mean train loss 7054.420910447492
INFO:root:current train perplexity261.4592590332031
INFO:root:current mean train loss 7051.735560328002
INFO:root:current train perplexity261.19195556640625
INFO:root:current mean train loss 7053.000149314519
INFO:root:current train perplexity261.0812683105469
INFO:root:current mean train loss 7048.975190066755
INFO:root:current train perplexity260.5872497558594
INFO:root:current mean train loss 7051.738352726797
INFO:root:current train perplexity260.5965576171875
INFO:root:current mean train loss 7049.100789003939
INFO:root:current train perplexity260.6222839355469
INFO:root:current mean train loss 7052.279625135619
INFO:root:current train perplexity260.6520080566406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.29s/it]
INFO:root:final mean train loss: 7048.339130534347
INFO:root:final train perplexity: 260.4820251464844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.28s/it]
INFO:root:eval mean loss: 6723.368475731383
INFO:root:eval perplexity: 230.591796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.32s/it]
INFO:root:eval mean loss: 6815.004913113641
INFO:root:eval perplexity: 271.1876220703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [26:01:13<22:40:11, 877.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6972.227756076389
INFO:root:current train perplexity257.0880126953125
INFO:root:current mean train loss 7042.8799945378705
INFO:root:current train perplexity256.243896484375
INFO:root:current mean train loss 7086.646874104071
INFO:root:current train perplexity260.20147705078125
INFO:root:current mean train loss 7102.595170314957
INFO:root:current train perplexity263.81341552734375
INFO:root:current mean train loss 7086.103910455293
INFO:root:current train perplexity263.6167297363281
INFO:root:current mean train loss 7073.216786506093
INFO:root:current train perplexity262.5152587890625
INFO:root:current mean train loss 7073.207361511428
INFO:root:current train perplexity262.85205078125
INFO:root:current mean train loss 7064.571202695203
INFO:root:current train perplexity262.7191162109375
INFO:root:current mean train loss 7069.589322638104
INFO:root:current train perplexity263.366943359375
INFO:root:current mean train loss 7074.513237847223
INFO:root:current train perplexity264.53924560546875
INFO:root:current mean train loss 7073.323089659565
INFO:root:current train perplexity265.2182312011719
INFO:root:current mean train loss 7071.48861798063
INFO:root:current train perplexity265.7809753417969
INFO:root:current mean train loss 7073.130644098292
INFO:root:current train perplexity266.178466796875
INFO:root:current mean train loss 7071.395272192716
INFO:root:current train perplexity266.4486999511719
INFO:root:current mean train loss 7073.264159811905
INFO:root:current train perplexity266.7618103027344
INFO:root:current mean train loss 7074.18309839221
INFO:root:current train perplexity266.78228759765625
INFO:root:current mean train loss 7077.027097195129
INFO:root:current train perplexity266.7568359375
INFO:root:current mean train loss 7078.592871207436
INFO:root:current train perplexity266.8699645996094
INFO:root:current mean train loss 7080.675807570991
INFO:root:current train perplexity266.95904541015625
INFO:root:current mean train loss 7079.756761091469
INFO:root:current train perplexity266.85137939453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.98s/it]
INFO:root:final mean train loss: 7078.9708210709
INFO:root:final train perplexity: 266.855712890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.35s/it]
INFO:root:eval mean loss: 6772.577834109043
INFO:root:eval perplexity: 239.9593963623047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.45s/it]
INFO:root:eval mean loss: 6856.328497271165
INFO:root:eval perplexity: 280.55902099609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [26:15:38<22:19:24, 873.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7036.930119977678
INFO:root:current train perplexity269.56097412109375
INFO:root:current mean train loss 7074.905280671296
INFO:root:current train perplexity269.9364318847656
INFO:root:current mean train loss 7109.986188912899
INFO:root:current train perplexity271.56402587890625
INFO:root:current mean train loss 7106.13514896222
INFO:root:current train perplexity271.30517578125
INFO:root:current mean train loss 7096.121285695043
INFO:root:current train perplexity270.46905517578125
INFO:root:current mean train loss 7091.751295998832
INFO:root:current train perplexity271.0163269042969
INFO:root:current mean train loss 7093.902324526329
INFO:root:current train perplexity271.4132080078125
INFO:root:current mean train loss 7094.746998565051
INFO:root:current train perplexity271.6851501464844
INFO:root:current mean train loss 7102.64794629491
INFO:root:current train perplexity272.0740661621094
INFO:root:current mean train loss 7109.601723867814
INFO:root:current train perplexity272.94586181640625
INFO:root:current mean train loss 7114.817720599336
INFO:root:current train perplexity273.7260437011719
INFO:root:current mean train loss 7113.817540697274
INFO:root:current train perplexity273.8303527832031
INFO:root:current mean train loss 7109.387718243927
INFO:root:current train perplexity273.1658935546875
INFO:root:current mean train loss 7107.804226650281
INFO:root:current train perplexity273.14349365234375
INFO:root:current mean train loss 7107.207729134909
INFO:root:current train perplexity273.22894287109375
INFO:root:current mean train loss 7109.237680998066
INFO:root:current train perplexity273.2082214355469
INFO:root:current mean train loss 7111.301225929377
INFO:root:current train perplexity273.2477111816406
INFO:root:current mean train loss 7112.547189076009
INFO:root:current train perplexity273.5937194824219
INFO:root:current mean train loss 7113.6311861376025
INFO:root:current train perplexity273.70111083984375
INFO:root:current mean train loss 7114.082022922723
INFO:root:current train perplexity273.9593811035156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:21<00:00, 741.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:21<00:00, 741.89s/it]
INFO:root:final mean train loss: 7112.409374950753
INFO:root:final train perplexity: 273.9917907714844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.64s/it]
INFO:root:eval mean loss: 6826.606303330009
INFO:root:eval perplexity: 250.68319702148438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.40s/it]
INFO:root:eval mean loss: 6907.106111999945
INFO:root:eval perplexity: 292.5191650390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [26:29:56<21:58:03, 869.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7158.9600172776445
INFO:root:current train perplexity282.75567626953125
INFO:root:current mean train loss 7143.183770430715
INFO:root:current train perplexity282.5649719238281
INFO:root:current mean train loss 7150.694450257316
INFO:root:current train perplexity281.428466796875
INFO:root:current mean train loss 7149.570147427646
INFO:root:current train perplexity280.21514892578125
INFO:root:current mean train loss 7143.661872796253
INFO:root:current train perplexity280.67730712890625
INFO:root:current mean train loss 7141.155666185462
INFO:root:current train perplexity280.67047119140625
INFO:root:current mean train loss 7152.982766367906
INFO:root:current train perplexity281.1368713378906
INFO:root:current mean train loss 7160.422276922997
INFO:root:current train perplexity281.78887939453125
INFO:root:current mean train loss 7164.104162654966
INFO:root:current train perplexity282.39483642578125
INFO:root:current mean train loss 7154.2228624359905
INFO:root:current train perplexity281.7708740234375
INFO:root:current mean train loss 7148.564684269546
INFO:root:current train perplexity281.69000244140625
INFO:root:current mean train loss 7150.025932735867
INFO:root:current train perplexity281.5885925292969
INFO:root:current mean train loss 7150.331724319214
INFO:root:current train perplexity281.7320251464844
INFO:root:current mean train loss 7150.711269040079
INFO:root:current train perplexity282.01092529296875
INFO:root:current mean train loss 7151.158500061876
INFO:root:current train perplexity282.0939025878906
INFO:root:current mean train loss 7150.849155386699
INFO:root:current train perplexity282.2445983886719
INFO:root:current mean train loss 7156.980753974823
INFO:root:current train perplexity282.7459716796875
INFO:root:current mean train loss 7157.603466573915
INFO:root:current train perplexity283.1067199707031
INFO:root:current mean train loss 7159.015420406992
INFO:root:current train perplexity283.2479553222656
INFO:root:current mean train loss 7156.962646234231
INFO:root:current train perplexity283.3248291015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.60s/it]
INFO:root:final mean train loss: 7155.54186537719
INFO:root:final train perplexity: 283.4788818359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.13s/it]
INFO:root:eval mean loss: 6902.156329648715
INFO:root:eval perplexity: 266.4871826171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 55.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.01s/it]
INFO:root:eval mean loss: 6980.0416406942595
INFO:root:eval perplexity: 310.5958251953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [26:44:29<21:45:29, 870.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7269.326235563859
INFO:root:current train perplexity295.48828125
INFO:root:current mean train loss 7234.893262874445
INFO:root:current train perplexity292.4131774902344
INFO:root:current mean train loss 7231.083040485595
INFO:root:current train perplexity290.39422607421875
INFO:root:current mean train loss 7213.830427464431
INFO:root:current train perplexity289.4835510253906
INFO:root:current mean train loss 7197.958328474813
INFO:root:current train perplexity288.76953125
INFO:root:current mean train loss 7190.167747350066
INFO:root:current train perplexity288.5513610839844
INFO:root:current mean train loss 7177.581113076887
INFO:root:current train perplexity287.8411560058594
INFO:root:current mean train loss 7166.431960007924
INFO:root:current train perplexity287.4649353027344
INFO:root:current mean train loss 7172.454675250827
INFO:root:current train perplexity287.8249816894531
INFO:root:current mean train loss 7177.361184008965
INFO:root:current train perplexity288.0943603515625
INFO:root:current mean train loss 7182.756253105998
INFO:root:current train perplexity288.7322082519531
INFO:root:current mean train loss 7181.214736821001
INFO:root:current train perplexity288.71514892578125
INFO:root:current mean train loss 7186.710459992489
INFO:root:current train perplexity289.0088195800781
INFO:root:current mean train loss 7186.974037632966
INFO:root:current train perplexity289.086669921875
INFO:root:current mean train loss 7185.471109305863
INFO:root:current train perplexity289.07525634765625
INFO:root:current mean train loss 7184.725924217754
INFO:root:current train perplexity288.8016052246094
INFO:root:current mean train loss 7184.751969215754
INFO:root:current train perplexity289.0985412597656
INFO:root:current mean train loss 7183.379978591807
INFO:root:current train perplexity289.1141052246094
INFO:root:current mean train loss 7182.662014279026
INFO:root:current train perplexity289.1246032714844
INFO:root:current mean train loss 7183.736872946689
INFO:root:current train perplexity289.4392395019531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.76s/it]
INFO:root:final mean train loss: 7182.105256127277
INFO:root:final train perplexity: 289.484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.68s/it]
INFO:root:eval mean loss: 6918.079241813497
INFO:root:eval perplexity: 269.9432678222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.16s/it]
INFO:root:eval mean loss: 6993.191573339152
INFO:root:eval perplexity: 313.97186279296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [26:58:59<21:30:48, 870.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7143.078511082849
INFO:root:current train perplexity291.4048767089844
INFO:root:current mean train loss 7146.78574953797
INFO:root:current train perplexity288.87200927734375
INFO:root:current mean train loss 7143.889332591237
INFO:root:current train perplexity289.0071716308594
INFO:root:current mean train loss 7162.555333903417
INFO:root:current train perplexity290.57012939453125
INFO:root:current mean train loss 7161.547311037166
INFO:root:current train perplexity290.6164245605469
INFO:root:current mean train loss 7170.491507572526
INFO:root:current train perplexity290.14410400390625
INFO:root:current mean train loss 7180.981322886298
INFO:root:current train perplexity290.4877014160156
INFO:root:current mean train loss 7195.999837860806
INFO:root:current train perplexity291.05352783203125
INFO:root:current mean train loss 7203.563155817932
INFO:root:current train perplexity291.4903259277344
INFO:root:current mean train loss 7207.875776991157
INFO:root:current train perplexity291.92822265625
INFO:root:current mean train loss 7198.108122374252
INFO:root:current train perplexity291.2562255859375
INFO:root:current mean train loss 7204.615737889308
INFO:root:current train perplexity291.53955078125
INFO:root:current mean train loss 7206.020490726453
INFO:root:current train perplexity291.58001708984375
INFO:root:current mean train loss 7198.855177401808
INFO:root:current train perplexity291.4600524902344
INFO:root:current mean train loss 7198.000023329723
INFO:root:current train perplexity291.2004089355469
INFO:root:current mean train loss 7194.972885305013
INFO:root:current train perplexity291.2054138183594
INFO:root:current mean train loss 7192.5397132520575
INFO:root:current train perplexity291.1570739746094
INFO:root:current mean train loss 7192.802118418866
INFO:root:current train perplexity291.1502685546875
INFO:root:current mean train loss 7193.676288430789
INFO:root:current train perplexity291.15972900390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.30s/it]
INFO:root:final mean train loss: 7189.547813150057
INFO:root:final train perplexity: 291.19000244140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.97s/it]
INFO:root:eval mean loss: 6936.2186132119905
INFO:root:eval perplexity: 273.9348449707031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.68s/it]
INFO:root:eval mean loss: 7013.435230011635
INFO:root:eval perplexity: 319.24102783203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [27:13:36<21:19:02, 872.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7235.787109375
INFO:root:current train perplexity302.6156005859375
INFO:root:current mean train loss 7183.716299112561
INFO:root:current train perplexity292.9122314453125
INFO:root:current mean train loss 7225.046504579741
INFO:root:current train perplexity294.71630859375
INFO:root:current mean train loss 7223.533422287541
INFO:root:current train perplexity294.38287353515625
INFO:root:current mean train loss 7234.83686559786
INFO:root:current train perplexity294.6147155761719
INFO:root:current mean train loss 7225.144597260189
INFO:root:current train perplexity294.2992248535156
INFO:root:current mean train loss 7211.531053229944
INFO:root:current train perplexity293.38958740234375
INFO:root:current mean train loss 7204.635219177854
INFO:root:current train perplexity292.70782470703125
INFO:root:current mean train loss 7204.5163188093475
INFO:root:current train perplexity292.2477111816406
INFO:root:current mean train loss 7200.254028455495
INFO:root:current train perplexity292.08807373046875
INFO:root:current mean train loss 7197.204099128396
INFO:root:current train perplexity292.0893249511719
INFO:root:current mean train loss 7202.611256410075
INFO:root:current train perplexity292.0543518066406
INFO:root:current mean train loss 7205.401346487298
INFO:root:current train perplexity291.9112243652344
INFO:root:current mean train loss 7200.011419710524
INFO:root:current train perplexity291.4093322753906
INFO:root:current mean train loss 7206.290478620033
INFO:root:current train perplexity293.5040588378906
INFO:root:current mean train loss 7215.767988437188
INFO:root:current train perplexity295.89520263671875
INFO:root:current mean train loss 7228.7336616159155
INFO:root:current train perplexity298.278076171875
INFO:root:current mean train loss 7233.686247041067
INFO:root:current train perplexity299.8821716308594
INFO:root:current mean train loss 7236.652118972719
INFO:root:current train perplexity301.2386779785156
INFO:root:current mean train loss 7242.1386067024105
INFO:root:current train perplexity302.3611755371094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:27<00:00, 747.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:27<00:00, 747.83s/it]
INFO:root:final mean train loss: 7239.059086955922
INFO:root:final train perplexity: 302.79315185546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.09s/it]
INFO:root:eval mean loss: 7021.261865926973
INFO:root:eval perplexity: 293.4503173828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.47s/it]
INFO:root:eval mean loss: 7105.417290004432
INFO:root:eval perplexity: 344.3184814453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [27:28:00<21:00:54, 869.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7391.229321289063
INFO:root:current train perplexity315.43255615234375
INFO:root:current mean train loss 7241.114733886719
INFO:root:current train perplexity311.23199462890625
INFO:root:current mean train loss 7244.923408647017
INFO:root:current train perplexity312.11492919921875
INFO:root:current mean train loss 7267.644946289062
INFO:root:current train perplexity311.2799377441406
INFO:root:current mean train loss 7247.891552734375
INFO:root:current train perplexity310.1657409667969
INFO:root:current mean train loss 7244.3074566180885
INFO:root:current train perplexity308.9836120605469
INFO:root:current mean train loss 7239.086550214213
INFO:root:current train perplexity308.6661376953125
INFO:root:current mean train loss 7243.365366617839
INFO:root:current train perplexity308.0760498046875
INFO:root:current mean train loss 7252.584037966844
INFO:root:current train perplexity308.36676025390625
INFO:root:current mean train loss 7253.361719811481
INFO:root:current train perplexity308.006591796875
INFO:root:current mean train loss 7270.277922028186
INFO:root:current train perplexity311.6690673828125
INFO:root:current mean train loss 7293.399141584124
INFO:root:current train perplexity316.3848876953125
INFO:root:current mean train loss 7304.584433433658
INFO:root:current train perplexity318.9505615234375
INFO:root:current mean train loss 7313.68681418679
INFO:root:current train perplexity320.979736328125
INFO:root:current mean train loss 7317.2904241857395
INFO:root:current train perplexity321.8796081542969
INFO:root:current mean train loss 7318.5007995605465
INFO:root:current train perplexity322.2572326660156
INFO:root:current mean train loss 7316.365376338253
INFO:root:current train perplexity322.1344909667969
INFO:root:current mean train loss 7316.385402093932
INFO:root:current train perplexity321.53582763671875
INFO:root:current mean train loss 7310.513720703125
INFO:root:current train perplexity320.5569763183594
INFO:root:current mean train loss 7309.8439270019535
INFO:root:current train perplexity319.6358337402344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:23<00:00, 743.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:23<00:00, 743.95s/it]
INFO:root:final mean train loss: 7304.893579557095
INFO:root:final train perplexity: 318.9411315917969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.55s/it]
INFO:root:eval mean loss: 6952.193906527039
INFO:root:eval perplexity: 277.4991149902344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.77s/it]
INFO:root:eval mean loss: 7035.192025259032
INFO:root:eval perplexity: 325.0027160644531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilbert_distilroberta_not_concat/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [27:42:21<20:42:42, 867.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7204.981458509291
INFO:root:current train perplexity294.4384765625
INFO:root:current mean train loss 7220.991050553148
INFO:root:current train perplexity297.1188659667969
INFO:root:current mean train loss 7246.499804275449
INFO:root:current train perplexity296.4933166503906
INFO:root:current mean train loss 7235.717754601725
INFO:root:current train perplexity296.6600646972656
INFO:root:current mean train loss 7226.606255363272
INFO:root:current train perplexity295.883056640625
INFO:root:current mean train loss 7228.763111760941
INFO:root:current train perplexity295.2615051269531
INFO:root:current mean train loss 7222.835596393004
INFO:root:current train perplexity294.5652770996094
INFO:root:current mean train loss 7220.518764708065
INFO:root:current train perplexity294.51751708984375
INFO:root:current mean train loss 7214.525528883849
INFO:root:current train perplexity293.6994934082031
INFO:root:current mean train loss 7221.322909718517
INFO:root:current train perplexity294.6784973144531
INFO:root:current mean train loss 7230.89645000226
INFO:root:current train perplexity295.9533386230469
INFO:root:current mean train loss 7234.112314564782
INFO:root:current train perplexity296.57733154296875
INFO:root:current mean train loss 7229.122306755886
INFO:root:current train perplexity296.35211181640625
slurmstepd: error: *** JOB 30794078 ON gr052 CANCELLED AT 2023-03-07T13:22:21 ***
