INFO:root:Output: small_val_330
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24398.414476799244
INFO:root:current train perplexity15158.953125
INFO:root:current mean train loss 20464.172890821294
INFO:root:current train perplexity3181.69482421875
INFO:root:current mean train loss 17686.319270615593
INFO:root:current train perplexity1067.358154296875
INFO:root:current mean train loss 15804.603221921992
INFO:root:current train perplexity504.0482482910156
INFO:root:current mean train loss 14439.707844399736
INFO:root:current train perplexity294.3136901855469
INFO:root:current mean train loss 13401.135510681866
INFO:root:current train perplexity196.0620880126953
INFO:root:current mean train loss 12594.085750290593
INFO:root:current train perplexity142.62168884277344
INFO:root:current mean train loss 11945.24773765058
INFO:root:current train perplexity110.69793701171875
INFO:root:current mean train loss 11413.734829606681
INFO:root:current train perplexity89.81647491455078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:02<00:00, 182.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:02<00:00, 182.51s/it]
INFO:root:final mean train loss: 10985.09631421489
INFO:root:final train perplexity: 76.24398803710938
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 6390.604914671986
INFO:root:eval perplexity: 13.252324104309082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/1

  0%|          | 1/200 [03:15<10:47:14, 195.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6804.102818080357
INFO:root:current train perplexity14.400020599365234
INFO:root:current mean train loss 6709.489330826519
INFO:root:current train perplexity14.275741577148438
INFO:root:current mean train loss 6681.634914232337
INFO:root:current train perplexity14.043972969055176
INFO:root:current mean train loss 6609.60402776364
INFO:root:current train perplexity13.625873565673828
INFO:root:current mean train loss 6556.133275587377
INFO:root:current train perplexity13.328851699829102
INFO:root:current mean train loss 6505.203601724297
INFO:root:current train perplexity13.056207656860352
INFO:root:current mean train loss 6461.877833961851
INFO:root:current train perplexity12.785002708435059
INFO:root:current mean train loss 6413.525701412217
INFO:root:current train perplexity12.542179107666016
INFO:root:current mean train loss 6369.16677618204
INFO:root:current train perplexity12.317536354064941
INFO:root:current mean train loss 6324.135384186363
INFO:root:current train perplexity12.11275863647461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.26s/it]
INFO:root:final mean train loss: 6286.177743234942
INFO:root:final train perplexity: 11.94221019744873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 5503.822535738032
INFO:root:eval perplexity: 9.258891105651855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/2

  1%|          | 2/200 [06:26<10:37:03, 193.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5957.23486328125
INFO:root:current train perplexity10.51279067993164
INFO:root:current mean train loss 5853.527373471467
INFO:root:current train perplexity10.126936912536621
INFO:root:current mean train loss 5829.748076398982
INFO:root:current train perplexity9.982132911682129
INFO:root:current mean train loss 5808.478698536706
INFO:root:current train perplexity9.866592407226562
INFO:root:current mean train loss 5783.775134130271
INFO:root:current train perplexity9.776542663574219
INFO:root:current mean train loss 5757.079627768508
INFO:root:current train perplexity9.686192512512207
INFO:root:current mean train loss 5731.601418794461
INFO:root:current train perplexity9.604358673095703
INFO:root:current mean train loss 5712.180198317307
INFO:root:current train perplexity9.525259971618652
INFO:root:current mean train loss 5698.664519627109
INFO:root:current train perplexity9.454163551330566
INFO:root:current mean train loss 5679.555717960212
INFO:root:current train perplexity9.370718955993652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it]
INFO:root:final mean train loss: 5655.786790909306
INFO:root:final train perplexity: 9.312630653381348
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 5133.59922152039
INFO:root:eval perplexity: 7.971534252166748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/3

  2%|â–         | 3/200 [09:38<10:32:12, 192.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5526.768830672554
INFO:root:current train perplexity8.690864562988281
INFO:root:current mean train loss 5440.478833206301
INFO:root:current train perplexity8.56421184539795
INFO:root:current mean train loss 5439.902941511351
INFO:root:current train perplexity8.506933212280273
INFO:root:current mean train loss 5413.671599869389
INFO:root:current train perplexity8.429811477661133
INFO:root:current mean train loss 5400.478326315012
INFO:root:current train perplexity8.403091430664062
INFO:root:current mean train loss 5384.549380825765
INFO:root:current train perplexity8.35165023803711
INFO:root:current mean train loss 5375.42535645315
INFO:root:current train perplexity8.321867942810059
INFO:root:current mean train loss 5365.550826498747
INFO:root:current train perplexity8.287437438964844
INFO:root:current mean train loss 5355.116168813601
INFO:root:current train perplexity8.252985000610352
INFO:root:current mean train loss 5344.275175315716
INFO:root:current train perplexity8.218114852905273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.19s/it]
INFO:root:final mean train loss: 5333.171874384726
INFO:root:final train perplexity: 8.1996431350708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.37s/it]
INFO:root:eval mean loss: 4914.881025598404
INFO:root:eval perplexity: 7.296783924102783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/4

  2%|â–         | 4/200 [12:51<10:28:48, 192.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5276.307758946573
INFO:root:current train perplexity7.832710266113281
INFO:root:current mean train loss 5198.884538257395
INFO:root:current train perplexity7.756147384643555
INFO:root:current mean train loss 5199.82155962527
INFO:root:current train perplexity7.7732625007629395
INFO:root:current mean train loss 5189.743929675698
INFO:root:current train perplexity7.729732036590576
INFO:root:current mean train loss 5182.065226897839
INFO:root:current train perplexity7.694827079772949
INFO:root:current mean train loss 5171.58317884887
INFO:root:current train perplexity7.665431022644043
INFO:root:current mean train loss 5163.216676158875
INFO:root:current train perplexity7.6392083168029785
INFO:root:current mean train loss 5155.676290906079
INFO:root:current train perplexity7.624569892883301
INFO:root:current mean train loss 5142.470343524368
INFO:root:current train perplexity7.600429058074951
INFO:root:current mean train loss 5134.658636336936
INFO:root:current train perplexity7.5721354484558105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it]
INFO:root:final mean train loss: 5125.624334766018
INFO:root:final train perplexity: 7.554980754852295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it]
INFO:root:eval mean loss: 4781.638419076906
INFO:root:eval perplexity: 6.9140400886535645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/5

  2%|â–Ž         | 5/200 [16:02<10:24:19, 192.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5027.281350160257
INFO:root:current train perplexity7.1877288818359375
INFO:root:current mean train loss 5029.119484880845
INFO:root:current train perplexity7.274990081787109
INFO:root:current mean train loss 5035.7809639775105
INFO:root:current train perplexity7.282342910766602
INFO:root:current mean train loss 5018.672986956121
INFO:root:current train perplexity7.221321105957031
INFO:root:current mean train loss 5016.046701487756
INFO:root:current train perplexity7.210507392883301
INFO:root:current mean train loss 5003.939137871058
INFO:root:current train perplexity7.187535285949707
INFO:root:current mean train loss 4995.992672724717
INFO:root:current train perplexity7.1673264503479
INFO:root:current mean train loss 4995.8502985189025
INFO:root:current train perplexity7.16231107711792
INFO:root:current mean train loss 4992.425529834624
INFO:root:current train perplexity7.147556304931641
INFO:root:current mean train loss 4984.348901133187
INFO:root:current train perplexity7.132065773010254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.42s/it]
INFO:root:final mean train loss: 4975.880491195187
INFO:root:final train perplexity: 7.121574401855469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.86s/it]
INFO:root:eval mean loss: 4672.220760264295
INFO:root:eval perplexity: 6.614795684814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/6

  3%|â–Ž         | 6/200 [19:14<10:21:07, 192.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4856.189193400931
INFO:root:current train perplexity6.836027145385742
INFO:root:current mean train loss 4904.628461150085
INFO:root:current train perplexity6.897562503814697
INFO:root:current mean train loss 4886.105528055415
INFO:root:current train perplexity6.879599094390869
INFO:root:current mean train loss 4886.675851607529
INFO:root:current train perplexity6.87299108505249
INFO:root:current mean train loss 4883.865626529292
INFO:root:current train perplexity6.862751483917236
INFO:root:current mean train loss 4875.4981682758225
INFO:root:current train perplexity6.842715263366699
INFO:root:current mean train loss 4875.0430525200445
INFO:root:current train perplexity6.839503765106201
INFO:root:current mean train loss 4872.408764615755
INFO:root:current train perplexity6.828854084014893
INFO:root:current mean train loss 4868.9619492279735
INFO:root:current train perplexity6.820662021636963
INFO:root:current mean train loss 4866.658158267061
INFO:root:current train perplexity6.809751033782959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.73s/it]
INFO:root:final mean train loss: 4861.581913117439
INFO:root:final train perplexity: 6.807567119598389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 4589.944962738254
INFO:root:eval perplexity: 6.398341655731201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/7

  4%|â–Ž         | 7/200 [22:26<10:17:52, 192.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4753.021715198864
INFO:root:current train perplexity6.608212947845459
INFO:root:current mean train loss 4805.4123487903225
INFO:root:current train perplexity6.670070648193359
INFO:root:current mean train loss 4799.69416551777
INFO:root:current train perplexity6.630433559417725
INFO:root:current mean train loss 4800.1721308318665
INFO:root:current train perplexity6.626518249511719
INFO:root:current mean train loss 4793.621958168785
INFO:root:current train perplexity6.6078667640686035
INFO:root:current mean train loss 4787.793528733812
INFO:root:current train perplexity6.590811729431152
INFO:root:current mean train loss 4786.254989787094
INFO:root:current train perplexity6.588455677032471
INFO:root:current mean train loss 4787.927501228787
INFO:root:current train perplexity6.583611488342285
INFO:root:current mean train loss 4778.959911538286
INFO:root:current train perplexity6.5673041343688965
INFO:root:current mean train loss 4771.763158284932
INFO:root:current train perplexity6.559397220611572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.06s/it]
INFO:root:final mean train loss: 4767.570980564241
INFO:root:final train perplexity: 6.559699058532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4525.677642605829
INFO:root:eval perplexity: 6.234205722808838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/8

  4%|â–         | 8/200 [25:39<10:15:07, 192.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4713.989056299603
INFO:root:current train perplexity6.36623477935791
INFO:root:current mean train loss 4703.890283502684
INFO:root:current train perplexity6.39011287689209
INFO:root:current mean train loss 4698.586340378446
INFO:root:current train perplexity6.390483379364014
INFO:root:current mean train loss 4709.928634265238
INFO:root:current train perplexity6.392294883728027
INFO:root:current mean train loss 4714.339806838891
INFO:root:current train perplexity6.401971817016602
INFO:root:current mean train loss 4706.202368727798
INFO:root:current train perplexity6.3886237144470215
INFO:root:current mean train loss 4703.219804628582
INFO:root:current train perplexity6.385441303253174
INFO:root:current mean train loss 4701.713634885936
INFO:root:current train perplexity6.379280090332031
INFO:root:current mean train loss 4697.314533185019
INFO:root:current train perplexity6.372128009796143
INFO:root:current mean train loss 4693.872395579812
INFO:root:current train perplexity6.363171577453613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.88s/it]
INFO:root:final mean train loss: 4691.711982603996
INFO:root:final train perplexity: 6.36628532409668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 4475.3312503462985
INFO:root:eval perplexity: 6.1085686683654785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/9

  4%|â–         | 9/200 [28:51<10:11:38, 192.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4612.824149977993
INFO:root:current train perplexity6.143026351928711
INFO:root:current mean train loss 4626.829472770468
INFO:root:current train perplexity6.199809551239014
INFO:root:current mean train loss 4649.517145698801
INFO:root:current train perplexity6.236522674560547
INFO:root:current mean train loss 4644.295547032934
INFO:root:current train perplexity6.226074695587158
INFO:root:current mean train loss 4638.352654135151
INFO:root:current train perplexity6.223617076873779
INFO:root:current mean train loss 4638.992549221486
INFO:root:current train perplexity6.219773769378662
INFO:root:current mean train loss 4640.662004223524
INFO:root:current train perplexity6.225297927856445
INFO:root:current mean train loss 4631.348361439587
INFO:root:current train perplexity6.212559223175049
INFO:root:current mean train loss 4634.223992436406
INFO:root:current train perplexity6.211031913757324
INFO:root:current mean train loss 4630.181757038089
INFO:root:current train perplexity6.2045722007751465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.49s/it]
INFO:root:final mean train loss: 4626.018511864447
INFO:root:final train perplexity: 6.203402996063232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 4432.190879875887
INFO:root:eval perplexity: 6.002931118011475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/10

  5%|â–Œ         | 10/200 [32:03<10:08:11, 192.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4617.520696326147
INFO:root:current train perplexity6.095678806304932
INFO:root:current mean train loss 4576.966264948499
INFO:root:current train perplexity6.055750846862793
INFO:root:current mean train loss 4586.503690986223
INFO:root:current train perplexity6.068319797515869
INFO:root:current mean train loss 4581.0927811675465
INFO:root:current train perplexity6.071774959564209
INFO:root:current mean train loss 4585.113848023226
INFO:root:current train perplexity6.071225643157959
INFO:root:current mean train loss 4577.9962143445055
INFO:root:current train perplexity6.069279193878174
INFO:root:current mean train loss 4577.850357977034
INFO:root:current train perplexity6.067471981048584
INFO:root:current mean train loss 4575.505381749438
INFO:root:current train perplexity6.063257217407227
INFO:root:current mean train loss 4570.5827450627485
INFO:root:current train perplexity6.060547351837158
INFO:root:current mean train loss 4570.081159426072
INFO:root:current train perplexity6.061150074005127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.26s/it]
INFO:root:final mean train loss: 4567.260751478134
INFO:root:final train perplexity: 6.061253547668457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4390.699128712323
INFO:root:eval perplexity: 5.903055191040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/11

  6%|â–Œ         | 11/200 [35:13<10:03:35, 191.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4519.856114179239
INFO:root:current train perplexity5.931210041046143
INFO:root:current mean train loss 4540.344368837734
INFO:root:current train perplexity5.962380409240723
INFO:root:current mean train loss 4527.888097676666
INFO:root:current train perplexity5.937404155731201
INFO:root:current mean train loss 4528.594573264898
INFO:root:current train perplexity5.951451301574707
INFO:root:current mean train loss 4525.4152380847345
INFO:root:current train perplexity5.949028968811035
INFO:root:current mean train loss 4521.540109767621
INFO:root:current train perplexity5.941853046417236
INFO:root:current mean train loss 4520.581164852848
INFO:root:current train perplexity5.9422078132629395
INFO:root:current mean train loss 4517.885042648606
INFO:root:current train perplexity5.936412811279297
INFO:root:current mean train loss 4519.38122489783
INFO:root:current train perplexity5.939150810241699
INFO:root:current mean train loss 4519.308864110388
INFO:root:current train perplexity5.939722061157227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.47s/it]
INFO:root:final mean train loss: 4515.984433758644
INFO:root:final train perplexity: 5.939865589141846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.86s/it]
INFO:root:eval mean loss: 4358.22002784242
INFO:root:eval perplexity: 5.826033115386963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/12

  6%|â–Œ         | 12/200 [38:26<10:01:51, 192.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4487.3552014802635
INFO:root:current train perplexity5.85904598236084
INFO:root:current mean train loss 4470.921441806891
INFO:root:current train perplexity5.8503217697143555
INFO:root:current mean train loss 4473.3243304753705
INFO:root:current train perplexity5.855038642883301
INFO:root:current mean train loss 4467.941695510285
INFO:root:current train perplexity5.842805862426758
INFO:root:current mean train loss 4474.134087456598
INFO:root:current train perplexity5.8445611000061035
INFO:root:current mean train loss 4468.650105452337
INFO:root:current train perplexity5.840688705444336
INFO:root:current mean train loss 4467.0174762533725
INFO:root:current train perplexity5.838726043701172
INFO:root:current mean train loss 4470.656285623035
INFO:root:current train perplexity5.832443714141846
INFO:root:current mean train loss 4472.4205779176855
INFO:root:current train perplexity5.835045337677002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it]
INFO:root:final mean train loss: 4471.585819367439
INFO:root:final train perplexity: 5.836724281311035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4327.671061197917
INFO:root:eval perplexity: 5.754506587982178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/13

  6%|â–‹         | 13/200 [42:20<10:38:18, 204.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4686.58447265625
INFO:root:current train perplexity5.993019104003906
INFO:root:current mean train loss 4449.8302558973
INFO:root:current train perplexity5.742605209350586
INFO:root:current mean train loss 4446.836574911484
INFO:root:current train perplexity5.740253448486328
INFO:root:current mean train loss 4444.843055448123
INFO:root:current train perplexity5.745755195617676
INFO:root:current mean train loss 4446.203447895666
INFO:root:current train perplexity5.74944543838501
INFO:root:current mean train loss 4442.326234972975
INFO:root:current train perplexity5.751531600952148
INFO:root:current mean train loss 4438.339404053949
INFO:root:current train perplexity5.752166748046875
INFO:root:current mean train loss 4435.032270320279
INFO:root:current train perplexity5.745962142944336
INFO:root:current mean train loss 4433.885204956511
INFO:root:current train perplexity5.744080066680908
INFO:root:current mean train loss 4434.270739245916
INFO:root:current train perplexity5.7437520027160645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.46s/it]
INFO:root:final mean train loss: 4430.701869226271
INFO:root:final train perplexity: 5.7433342933654785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]
INFO:root:eval mean loss: 4305.803426972518
INFO:root:eval perplexity: 5.70384407043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/14

  7%|â–‹         | 14/200 [46:10<10:57:52, 212.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4371.010964133523
INFO:root:current train perplexity5.551799297332764
INFO:root:current mean train loss 4385.855079444679
INFO:root:current train perplexity5.662996768951416
INFO:root:current mean train loss 4375.392165052947
INFO:root:current train perplexity5.6554365158081055
INFO:root:current mean train loss 4380.3964137233725
INFO:root:current train perplexity5.654551982879639
INFO:root:current mean train loss 4378.149947488975
INFO:root:current train perplexity5.649986743927002
INFO:root:current mean train loss 4382.066250019111
INFO:root:current train perplexity5.655366897583008
INFO:root:current mean train loss 4389.9037326744065
INFO:root:current train perplexity5.661332607269287
INFO:root:current mean train loss 4391.4022026222965
INFO:root:current train perplexity5.658814430236816
INFO:root:current mean train loss 4393.451707418985
INFO:root:current train perplexity5.662278175354004
INFO:root:current mean train loss 4395.492241098381
INFO:root:current train perplexity5.6581220626831055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.11s/it]
INFO:root:final mean train loss: 4392.133629398962
INFO:root:final train perplexity: 5.6566033363342285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4283.341587364251
INFO:root:eval perplexity: 5.652272701263428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/15

  8%|â–Š         | 15/200 [50:00<11:11:07, 217.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4418.932745682566
INFO:root:current train perplexity5.6583333015441895
INFO:root:current mean train loss 4352.855105616465
INFO:root:current train perplexity5.550053596496582
INFO:root:current mean train loss 4351.185793245219
INFO:root:current train perplexity5.565479278564453
INFO:root:current mean train loss 4350.751275806965
INFO:root:current train perplexity5.568550109863281
INFO:root:current mean train loss 4357.200886364484
INFO:root:current train perplexity5.577500820159912
INFO:root:current mean train loss 4354.835542359104
INFO:root:current train perplexity5.573093891143799
INFO:root:current mean train loss 4354.637111978115
INFO:root:current train perplexity5.574782848358154
INFO:root:current mean train loss 4357.822056798179
INFO:root:current train perplexity5.578409194946289
INFO:root:current mean train loss 4357.680647369124
INFO:root:current train perplexity5.579484462738037
INFO:root:current mean train loss 4357.798309558623
INFO:root:current train perplexity5.577086925506592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.22s/it]
INFO:root:final mean train loss: 4358.190438424387
INFO:root:final train perplexity: 5.581358432769775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it]
INFO:root:eval mean loss: 4262.606069578346
INFO:root:eval perplexity: 5.605077266693115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/16

  8%|â–Š         | 16/200 [53:49<11:17:43, 221.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.392749927662
INFO:root:current train perplexity5.590618133544922
INFO:root:current mean train loss 4305.787874477116
INFO:root:current train perplexity5.514150619506836
INFO:root:current mean train loss 4318.981566845057
INFO:root:current train perplexity5.511761665344238
INFO:root:current mean train loss 4316.281532217603
INFO:root:current train perplexity5.502425670623779
INFO:root:current mean train loss 4321.903763424875
INFO:root:current train perplexity5.5036749839782715
INFO:root:current mean train loss 4321.997399693874
INFO:root:current train perplexity5.498846530914307
INFO:root:current mean train loss 4322.7002552768645
INFO:root:current train perplexity5.497707366943359
INFO:root:current mean train loss 4322.235402942852
INFO:root:current train perplexity5.503941535949707
INFO:root:current mean train loss 4322.165303277566
INFO:root:current train perplexity5.500228404998779
INFO:root:current mean train loss 4325.098047875792
INFO:root:current train perplexity5.506905555725098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.53s/it]
INFO:root:final mean train loss: 4325.686477784187
INFO:root:final train perplexity: 5.510241985321045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4240.827210771276
INFO:root:eval perplexity: 5.55593204498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/17

  8%|â–Š         | 17/200 [57:40<11:23:45, 224.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4260.65908203125
INFO:root:current train perplexity5.418598651885986
INFO:root:current mean train loss 4292.118059172453
INFO:root:current train perplexity5.431948184967041
INFO:root:current mean train loss 4286.010028465758
INFO:root:current train perplexity5.433437347412109
INFO:root:current mean train loss 4290.021818155317
INFO:root:current train perplexity5.434593200683594
INFO:root:current mean train loss 4290.788390692349
INFO:root:current train perplexity5.440305709838867
INFO:root:current mean train loss 4301.671424138434
INFO:root:current train perplexity5.442777633666992
INFO:root:current mean train loss 4297.0424427903545
INFO:root:current train perplexity5.436198711395264
INFO:root:current mean train loss 4295.385046635842
INFO:root:current train perplexity5.432108402252197
INFO:root:current mean train loss 4296.5739816265905
INFO:root:current train perplexity5.4400224685668945
INFO:root:current mean train loss 4295.8232171206555
INFO:root:current train perplexity5.4429097175598145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it]
INFO:root:final mean train loss: 4294.696688375166
INFO:root:final train perplexity: 5.443281173706055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 4227.437430740249
INFO:root:eval perplexity: 5.5259294509887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/18

  9%|â–‰         | 18/200 [1:00:55<10:53:25, 215.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4264.391675372456
INFO:root:current train perplexity5.396481990814209
INFO:root:current mean train loss 4276.183274489183
INFO:root:current train perplexity5.393442630767822
INFO:root:current mean train loss 4269.255144032922
INFO:root:current train perplexity5.383388996124268
INFO:root:current mean train loss 4276.368872283847
INFO:root:current train perplexity5.398745059967041
INFO:root:current mean train loss 4277.439704430022
INFO:root:current train perplexity5.395394802093506
INFO:root:current mean train loss 4278.325522631791
INFO:root:current train perplexity5.394287586212158
INFO:root:current mean train loss 4274.774292182033
INFO:root:current train perplexity5.389378070831299
INFO:root:current mean train loss 4272.145846586369
INFO:root:current train perplexity5.386394023895264
INFO:root:current mean train loss 4268.760802136621
INFO:root:current train perplexity5.384265899658203
INFO:root:current mean train loss 4268.036722063892
INFO:root:current train perplexity5.381943702697754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it]
INFO:root:final mean train loss: 4266.925338499008
INFO:root:final train perplexity: 5.383967399597168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 4210.344002798094
INFO:root:eval perplexity: 5.487866401672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/19

 10%|â–‰         | 19/200 [1:04:25<10:44:31, 213.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4222.063557942708
INFO:root:current train perplexity5.269563674926758
INFO:root:current mean train loss 4212.862121986238
INFO:root:current train perplexity5.265725135803223
INFO:root:current mean train loss 4241.942948907495
INFO:root:current train perplexity5.2935872077941895
INFO:root:current mean train loss 4233.218342403401
INFO:root:current train perplexity5.303094387054443
INFO:root:current mean train loss 4238.445274065445
INFO:root:current train perplexity5.305891036987305
INFO:root:current mean train loss 4237.306285712766
INFO:root:current train perplexity5.31215763092041
INFO:root:current mean train loss 4244.042353710637
INFO:root:current train perplexity5.323271751403809
INFO:root:current mean train loss 4244.629309683443
INFO:root:current train perplexity5.32322359085083
INFO:root:current mean train loss 4244.976007374137
INFO:root:current train perplexity5.327214241027832
INFO:root:current mean train loss 4247.379177602935
INFO:root:current train perplexity5.330562114715576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.71s/it]
INFO:root:final mean train loss: 4240.701374915338
INFO:root:final train perplexity: 5.328550338745117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.63s/it]
INFO:root:eval mean loss: 4198.097280515846
INFO:root:eval perplexity: 5.460755825042725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/20

 10%|â–ˆ         | 20/200 [1:07:43<10:26:54, 208.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4247.064680713718
INFO:root:current train perplexity5.27910852432251
INFO:root:current mean train loss 4236.775645513954
INFO:root:current train perplexity5.271511554718018
INFO:root:current mean train loss 4227.797197378741
INFO:root:current train perplexity5.269859313964844
INFO:root:current mean train loss 4225.9365207172705
INFO:root:current train perplexity5.2794318199157715
INFO:root:current mean train loss 4221.819221579691
INFO:root:current train perplexity5.274401664733887
INFO:root:current mean train loss 4219.304054656054
INFO:root:current train perplexity5.272718906402588
INFO:root:current mean train loss 4221.477694289999
INFO:root:current train perplexity5.274208068847656
INFO:root:current mean train loss 4225.335667626503
INFO:root:current train perplexity5.28383731842041
INFO:root:current mean train loss 4223.094043025593
INFO:root:current train perplexity5.282191753387451
INFO:root:current mean train loss 4220.621468489312
INFO:root:current train perplexity5.278817653656006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.88s/it]
INFO:root:final mean train loss: 4216.1967579011
INFO:root:final train perplexity: 5.277284145355225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 4186.915738585993
INFO:root:eval perplexity: 5.436121463775635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/21

 10%|â–ˆ         | 21/200 [1:10:55<10:08:37, 204.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4168.436392257463
INFO:root:current train perplexity5.214391231536865
INFO:root:current mean train loss 4184.112763730352
INFO:root:current train perplexity5.238862991333008
INFO:root:current mean train loss 4186.646890361657
INFO:root:current train perplexity5.222842216491699
INFO:root:current mean train loss 4184.668843531804
INFO:root:current train perplexity5.2147536277771
INFO:root:current mean train loss 4190.184342378212
INFO:root:current train perplexity5.221972942352295
INFO:root:current mean train loss 4190.00299470555
INFO:root:current train perplexity5.2174835205078125
INFO:root:current mean train loss 4192.2658526693685
INFO:root:current train perplexity5.219543933868408
INFO:root:current mean train loss 4192.997472332851
INFO:root:current train perplexity5.219237327575684
INFO:root:current mean train loss 4194.661969986754
INFO:root:current train perplexity5.220545768737793
INFO:root:current mean train loss 4193.811650683493
INFO:root:current train perplexity5.224181652069092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.46s/it]
INFO:root:final mean train loss: 4192.0577758666
INFO:root:final train perplexity: 5.227264404296875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 4167.3715681793
INFO:root:eval perplexity: 5.3933281898498535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/22

 11%|â–ˆ         | 22/200 [1:14:49<10:32:03, 213.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4183.552744140625
INFO:root:current train perplexity5.178173065185547
INFO:root:current mean train loss 4172.224448939732
INFO:root:current train perplexity5.181445121765137
INFO:root:current mean train loss 4163.922238991478
INFO:root:current train perplexity5.160183906555176
INFO:root:current mean train loss 4162.433241536458
INFO:root:current train perplexity5.163827419281006
INFO:root:current mean train loss 4164.377522615132
INFO:root:current train perplexity5.168998718261719
INFO:root:current mean train loss 4169.943823879076
INFO:root:current train perplexity5.175479412078857
INFO:root:current mean train loss 4167.383057725694
INFO:root:current train perplexity5.176590919494629
INFO:root:current mean train loss 4172.702869833669
INFO:root:current train perplexity5.181278705596924
INFO:root:current mean train loss 4173.369507254464
INFO:root:current train perplexity5.182021617889404
INFO:root:current mean train loss 4175.021552483974
INFO:root:current train perplexity5.182786464691162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.72s/it]
INFO:root:final mean train loss: 4169.909284837784
INFO:root:final train perplexity: 5.181787014007568
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 4159.758631496565
INFO:root:eval perplexity: 5.37675142288208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/23

 12%|â–ˆâ–        | 23/200 [1:18:38<10:42:35, 217.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4157.071683217244
INFO:root:current train perplexity5.104232311248779
INFO:root:current mean train loss 4150.996149782274
INFO:root:current train perplexity5.119387626647949
INFO:root:current mean train loss 4149.656420812169
INFO:root:current train perplexity5.118711948394775
INFO:root:current mean train loss 4155.348053376917
INFO:root:current train perplexity5.128212928771973
INFO:root:current mean train loss 4157.488417220658
INFO:root:current train perplexity5.134328842163086
INFO:root:current mean train loss 4151.05047345693
INFO:root:current train perplexity5.12824821472168
INFO:root:current mean train loss 4146.146553720946
INFO:root:current train perplexity5.122731685638428
INFO:root:current mean train loss 4151.901440772669
INFO:root:current train perplexity5.134714603424072
INFO:root:current mean train loss 4151.13535869594
INFO:root:current train perplexity5.137638568878174
INFO:root:current mean train loss 4151.992613442189
INFO:root:current train perplexity5.138993740081787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.79s/it]
INFO:root:final mean train loss: 4148.859068962835
INFO:root:final train perplexity: 5.138929843902588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4153.164344733488
INFO:root:eval perplexity: 5.362432479858398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/24

 12%|â–ˆâ–        | 24/200 [1:21:51<10:16:56, 210.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4094.7061217591004
INFO:root:current train perplexity5.050432205200195
INFO:root:current mean train loss 4108.903568287795
INFO:root:current train perplexity5.071495056152344
INFO:root:current mean train loss 4107.403891651901
INFO:root:current train perplexity5.0628252029418945
INFO:root:current mean train loss 4117.7010313848705
INFO:root:current train perplexity5.081337928771973
INFO:root:current mean train loss 4118.707800964231
INFO:root:current train perplexity5.085901260375977
INFO:root:current mean train loss 4125.2030027231385
INFO:root:current train perplexity5.090926170349121
INFO:root:current mean train loss 4127.86230327424
INFO:root:current train perplexity5.094461441040039
INFO:root:current mean train loss 4131.751281198147
INFO:root:current train perplexity5.095194339752197
INFO:root:current mean train loss 4130.517580591067
INFO:root:current train perplexity5.0977301597595215
INFO:root:current mean train loss 4129.554876702826
INFO:root:current train perplexity5.093355655670166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it]
INFO:root:final mean train loss: 4126.230130226381
INFO:root:final train perplexity: 5.093254566192627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 4140.842364804965
INFO:root:eval perplexity: 5.335779666900635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/25

 12%|â–ˆâ–Ž        | 25/200 [1:25:03<9:56:53, 204.65s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4081.1268446180557
INFO:root:current train perplexity5.063986778259277
INFO:root:current mean train loss 4092.0764957600504
INFO:root:current train perplexity5.036535263061523
INFO:root:current mean train loss 4105.554951237197
INFO:root:current train perplexity5.047023296356201
INFO:root:current mean train loss 4112.166682575579
INFO:root:current train perplexity5.057429790496826
INFO:root:current mean train loss 4111.756867739385
INFO:root:current train perplexity5.054614067077637
INFO:root:current mean train loss 4110.424138293641
INFO:root:current train perplexity5.049866199493408
INFO:root:current mean train loss 4110.8775451398205
INFO:root:current train perplexity5.05153751373291
INFO:root:current mean train loss 4114.3051794479425
INFO:root:current train perplexity5.05509614944458
INFO:root:current mean train loss 4114.439534052593
INFO:root:current train perplexity5.059976577758789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it]
INFO:root:final mean train loss: 4108.768690909109
INFO:root:final train perplexity: 5.058288097381592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4136.754081130874
INFO:root:eval perplexity: 5.326967239379883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/26

 13%|â–ˆâ–Ž        | 26/200 [1:28:44<10:07:33, 209.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4153.486118861607
INFO:root:current train perplexity5.127811908721924
INFO:root:current mean train loss 4079.7422057535045
INFO:root:current train perplexity5.019932746887207
INFO:root:current mean train loss 4089.064571067331
INFO:root:current train perplexity5.027953147888184
INFO:root:current mean train loss 4090.292582260281
INFO:root:current train perplexity5.02271842956543
INFO:root:current mean train loss 4098.056644823979
INFO:root:current train perplexity5.035330295562744
INFO:root:current mean train loss 4089.517942169009
INFO:root:current train perplexity5.0240278244018555
INFO:root:current mean train loss 4092.507800031533
INFO:root:current train perplexity5.018141269683838
INFO:root:current mean train loss 4093.9692583097594
INFO:root:current train perplexity5.022162437438965
INFO:root:current mean train loss 4091.8769255948923
INFO:root:current train perplexity5.0191779136657715
INFO:root:current mean train loss 4090.1753088500036
INFO:root:current train perplexity5.016970157623291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.84s/it]
INFO:root:final mean train loss: 4088.579912370251
INFO:root:final train perplexity: 5.018158912658691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4122.454240082004
INFO:root:eval perplexity: 5.2962517738342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/27

 14%|â–ˆâ–Ž        | 27/200 [1:32:05<9:57:06, 207.09s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4094.9163899739583
INFO:root:current train perplexity4.93900728225708
INFO:root:current mean train loss 4046.51181640625
INFO:root:current train perplexity4.952679634094238
INFO:root:current mean train loss 4048.117009220567
INFO:root:current train perplexity4.9569807052612305
INFO:root:current mean train loss 4060.6417426215276
INFO:root:current train perplexity4.969349384307861
INFO:root:current mean train loss 4070.7502523766943
INFO:root:current train perplexity4.982255935668945
INFO:root:current mean train loss 4066.207347447664
INFO:root:current train perplexity4.973425388336182
INFO:root:current mean train loss 4069.820796414507
INFO:root:current train perplexity4.976102828979492
INFO:root:current mean train loss 4071.2291889750873
INFO:root:current train perplexity4.9759345054626465
INFO:root:current mean train loss 4075.260260496549
INFO:root:current train perplexity4.980853080749512
INFO:root:current mean train loss 4072.1812577377905
INFO:root:current train perplexity4.979542255401611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.17s/it]
INFO:root:final mean train loss: 4070.5226485959947
INFO:root:final train perplexity: 4.982536315917969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 4117.331575867132
INFO:root:eval perplexity: 5.285292625427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/28

 14%|â–ˆâ–        | 28/200 [1:35:16<9:40:07, 202.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4090.094185207201
INFO:root:current train perplexity4.969824314117432
INFO:root:current mean train loss 4056.607967717861
INFO:root:current train perplexity4.933947563171387
INFO:root:current mean train loss 4062.407841840667
INFO:root:current train perplexity4.952963352203369
INFO:root:current mean train loss 4051.859549602119
INFO:root:current train perplexity4.941843032836914
INFO:root:current mean train loss 4063.4148647587913
INFO:root:current train perplexity4.950660705566406
INFO:root:current mean train loss 4065.1898592480284
INFO:root:current train perplexity4.951839447021484
INFO:root:current mean train loss 4058.7760709269664
INFO:root:current train perplexity4.9489641189575195
INFO:root:current mean train loss 4055.8045760665195
INFO:root:current train perplexity4.9478044509887695
INFO:root:current mean train loss 4059.0286641265757
INFO:root:current train perplexity4.949894905090332
INFO:root:current mean train loss 4057.4470815276272
INFO:root:current train perplexity4.95001745223999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.81s/it]
INFO:root:final mean train loss: 4053.386691493373
INFO:root:final train perplexity: 4.948965072631836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4110.68107962101
INFO:root:eval perplexity: 5.271098613739014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/29

 14%|â–ˆâ–        | 29/200 [1:38:28<9:27:27, 199.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4052.161605342742
INFO:root:current train perplexity4.891488075256348
INFO:root:current mean train loss 4038.837870124642
INFO:root:current train perplexity4.897609233856201
INFO:root:current mean train loss 4056.7495857007575
INFO:root:current train perplexity4.916749477386475
INFO:root:current mean train loss 4059.8305826331193
INFO:root:current train perplexity4.918630123138428
INFO:root:current mean train loss 4056.8488554279656
INFO:root:current train perplexity4.914223670959473
INFO:root:current mean train loss 4052.522323924494
INFO:root:current train perplexity4.91516637802124
INFO:root:current mean train loss 4046.7671118976573
INFO:root:current train perplexity4.9108357429504395
INFO:root:current mean train loss 4046.5373989371365
INFO:root:current train perplexity4.913822650909424
INFO:root:current mean train loss 4043.9655409169113
INFO:root:current train perplexity4.91163969039917
INFO:root:current mean train loss 4039.155669149856
INFO:root:current train perplexity4.91426944732666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it]
INFO:root:final mean train loss: 4036.208252445344
INFO:root:final train perplexity: 4.915537357330322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.51s/it]
INFO:root:eval mean loss: 4102.322888962766
INFO:root:eval perplexity: 5.253313064575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/30

 15%|â–ˆâ–Œ        | 30/200 [1:42:11<9:44:12, 206.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4017.6074969951924
INFO:root:current train perplexity4.898935794830322
INFO:root:current mean train loss 4009.1842541591727
INFO:root:current train perplexity4.877379417419434
INFO:root:current mean train loss 4015.774761375523
INFO:root:current train perplexity4.866903305053711
INFO:root:current mean train loss 4012.79580553443
INFO:root:current train perplexity4.865479469299316
INFO:root:current mean train loss 4019.3965839220887
INFO:root:current train perplexity4.868929386138916
INFO:root:current mean train loss 4018.3076955480346
INFO:root:current train perplexity4.872697353363037
INFO:root:current mean train loss 4018.219329213126
INFO:root:current train perplexity4.875272750854492
INFO:root:current mean train loss 4023.761970819414
INFO:root:current train perplexity4.880891799926758
INFO:root:current mean train loss 4023.2439910561307
INFO:root:current train perplexity4.883450031280518
INFO:root:current mean train loss 4022.4337947305144
INFO:root:current train perplexity4.883292198181152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it]
INFO:root:final mean train loss: 4018.904608203519
INFO:root:final train perplexity: 4.88209342956543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4093.6641352227393
INFO:root:eval perplexity: 5.234952449798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/31

 16%|â–ˆâ–Œ        | 31/200 [1:45:22<9:28:23, 201.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3994.340004778923
INFO:root:current train perplexity4.826225757598877
INFO:root:current mean train loss 3988.502961243091
INFO:root:current train perplexity4.8140740394592285
INFO:root:current mean train loss 3982.9002206161435
INFO:root:current train perplexity4.8050856590271
INFO:root:current mean train loss 3995.102951357619
INFO:root:current train perplexity4.8210906982421875
INFO:root:current mean train loss 3999.7963626870105
INFO:root:current train perplexity4.829953193664551
INFO:root:current mean train loss 4002.707090611432
INFO:root:current train perplexity4.841928005218506
INFO:root:current mean train loss 4006.4304384116595
INFO:root:current train perplexity4.847110271453857
INFO:root:current mean train loss 4002.1362200102494
INFO:root:current train perplexity4.847728252410889
INFO:root:current mean train loss 4004.3352145900976
INFO:root:current train perplexity4.851053237915039
INFO:root:current mean train loss 4004.2318683692747
INFO:root:current train perplexity4.849905014038086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.98s/it]
INFO:root:final mean train loss: 4002.803988856654
INFO:root:final train perplexity: 4.851180076599121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4089.5950053330007
INFO:root:eval perplexity: 5.226345062255859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/32

 16%|â–ˆâ–Œ        | 32/200 [1:48:34<9:17:00, 198.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3969.560178444602
INFO:root:current train perplexity4.727363586425781
INFO:root:current mean train loss 3994.6950148059477
INFO:root:current train perplexity4.7955732345581055
INFO:root:current mean train loss 3976.5331667432597
INFO:root:current train perplexity4.789217948913574
INFO:root:current mean train loss 3974.1025239326586
INFO:root:current train perplexity4.803323268890381
INFO:root:current mean train loss 3983.154180438702
INFO:root:current train perplexity4.813762664794922
INFO:root:current mean train loss 3984.2593868771114
INFO:root:current train perplexity4.81428337097168
INFO:root:current mean train loss 3988.700448026002
INFO:root:current train perplexity4.816719055175781
INFO:root:current mean train loss 3990.401280202297
INFO:root:current train perplexity4.8171820640563965
INFO:root:current mean train loss 3991.2840580455045
INFO:root:current train perplexity4.818173408508301
INFO:root:current mean train loss 3990.957350805792
INFO:root:current train perplexity4.82243537902832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it]
INFO:root:final mean train loss: 3987.0397023847027
INFO:root:final train perplexity: 4.821101665496826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 4082.9565775986257
INFO:root:eval perplexity: 5.212334156036377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/33

 16%|â–ˆâ–‹        | 33/200 [1:51:46<9:07:52, 196.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3924.9503890749006
INFO:root:current train perplexity4.747452735900879
INFO:root:current mean train loss 3951.5762198044476
INFO:root:current train perplexity4.783892631530762
INFO:root:current mean train loss 3950.0897184306677
INFO:root:current train perplexity4.782100200653076
INFO:root:current mean train loss 3959.5783207160384
INFO:root:current train perplexity4.782713413238525
INFO:root:current mean train loss 3969.268243579576
INFO:root:current train perplexity4.785669803619385
INFO:root:current mean train loss 3965.964109593556
INFO:root:current train perplexity4.779740810394287
INFO:root:current mean train loss 3968.70678269054
INFO:root:current train perplexity4.786180019378662
INFO:root:current mean train loss 3967.3368135904734
INFO:root:current train perplexity4.783228397369385
INFO:root:current mean train loss 3969.100536996216
INFO:root:current train perplexity4.784363269805908
INFO:root:current mean train loss 3976.104658497209
INFO:root:current train perplexity4.7944464683532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it]
INFO:root:final mean train loss: 3972.8638308740433
INFO:root:final train perplexity: 4.79421329498291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.69s/it]
INFO:root:eval mean loss: 4079.4001118544993
INFO:root:eval perplexity: 5.204843044281006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/34

 17%|â–ˆâ–‹        | 34/200 [1:54:58<9:00:18, 195.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3991.6348206426055
INFO:root:current train perplexity4.773155212402344
INFO:root:current mean train loss 3955.4884454381395
INFO:root:current train perplexity4.7493977546691895
INFO:root:current mean train loss 3952.3158098622002
INFO:root:current train perplexity4.75387716293335
INFO:root:current mean train loss 3954.4523169011118
INFO:root:current train perplexity4.7490949630737305
INFO:root:current mean train loss 3953.714279271994
INFO:root:current train perplexity4.748631477355957
INFO:root:current mean train loss 3957.634990952687
INFO:root:current train perplexity4.75806188583374
INFO:root:current mean train loss 3960.522996154876
INFO:root:current train perplexity4.762924671173096
INFO:root:current mean train loss 3959.8746523133514
INFO:root:current train perplexity4.763301849365234
INFO:root:current mean train loss 3963.563250080726
INFO:root:current train perplexity4.76739501953125
INFO:root:current mean train loss 3962.2005171456617
INFO:root:current train perplexity4.768730163574219


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.57s/it]
INFO:root:final mean train loss: 3959.4420952950754
INFO:root:final train perplexity: 4.768894672393799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it]
INFO:root:eval mean loss: 4073.8096101368574
INFO:root:eval perplexity: 5.193090915679932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/35

 18%|â–ˆâ–Š        | 35/200 [1:58:10<8:54:28, 194.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3975.4485574070413
INFO:root:current train perplexity4.770238876342773
INFO:root:current mean train loss 3951.671988204871
INFO:root:current train perplexity4.732822418212891
INFO:root:current mean train loss 3953.8941637264784
INFO:root:current train perplexity4.742150783538818
INFO:root:current mean train loss 3949.9783610240765
INFO:root:current train perplexity4.735727787017822
INFO:root:current mean train loss 3948.425918865801
INFO:root:current train perplexity4.738833904266357
INFO:root:current mean train loss 3951.255367298818
INFO:root:current train perplexity4.737200736999512
INFO:root:current mean train loss 3951.1663640377624
INFO:root:current train perplexity4.739680767059326
INFO:root:current mean train loss 3948.882971395118
INFO:root:current train perplexity4.739492416381836
INFO:root:current mean train loss 3946.9262242583013
INFO:root:current train perplexity4.737831115722656
INFO:root:current mean train loss 3946.8789880458376
INFO:root:current train perplexity4.740079402923584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it]
INFO:root:final mean train loss: 3943.928112460721
INFO:root:final train perplexity: 4.73979377746582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it]
INFO:root:eval mean loss: 4071.5703834912456
INFO:root:eval perplexity: 5.188389301300049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/36

 18%|â–ˆâ–Š        | 36/200 [2:01:59<9:19:12, 204.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3893.45347577676
INFO:root:current train perplexity4.678842067718506
INFO:root:current mean train loss 3901.874261050301
INFO:root:current train perplexity4.673069000244141
INFO:root:current mean train loss 3914.457351950403
INFO:root:current train perplexity4.683907985687256
INFO:root:current mean train loss 3921.2718887526244
INFO:root:current train perplexity4.695784568786621
INFO:root:current mean train loss 3917.843493326489
INFO:root:current train perplexity4.699416160583496
INFO:root:current mean train loss 3919.879114622152
INFO:root:current train perplexity4.703615188598633
INFO:root:current mean train loss 3925.098299473481
INFO:root:current train perplexity4.70643424987793
INFO:root:current mean train loss 3928.6663841625636
INFO:root:current train perplexity4.7099385261535645
INFO:root:current mean train loss 3930.0890524261026
INFO:root:current train perplexity4.708563804626465
INFO:root:current mean train loss 3932.163906170846
INFO:root:current train perplexity4.71281099319458


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.23s/it]
INFO:root:final mean train loss: 3929.289600741479
INFO:root:final train perplexity: 4.712499618530273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it]
INFO:root:eval mean loss: 4066.155659560616
INFO:root:eval perplexity: 5.177043914794922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/37

 18%|â–ˆâ–Š        | 37/200 [2:05:58<9:44:19, 215.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3893.1385922080594
INFO:root:current train perplexity4.6449785232543945
INFO:root:current mean train loss 3894.5594676482374
INFO:root:current train perplexity4.65358304977417
INFO:root:current mean train loss 3904.6656730005298
INFO:root:current train perplexity4.671484470367432
INFO:root:current mean train loss 3897.975519803204
INFO:root:current train perplexity4.672828674316406
INFO:root:current mean train loss 3903.3103510692868
INFO:root:current train perplexity4.675817012786865
INFO:root:current mean train loss 3906.59153632156
INFO:root:current train perplexity4.677332401275635
INFO:root:current mean train loss 3908.018441574865
INFO:root:current train perplexity4.678701400756836
INFO:root:current mean train loss 3914.940700238306
INFO:root:current train perplexity4.686139106750488
INFO:root:current mean train loss 3920.6301962399616
INFO:root:current train perplexity4.690499305725098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.88s/it]
INFO:root:final mean train loss: 3917.596856886341
INFO:root:final train perplexity: 4.690810203552246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4061.683089885306
INFO:root:eval perplexity: 5.167687892913818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/38

 19%|â–ˆâ–‰        | 38/200 [2:09:56<9:59:15, 221.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3852.04833984375
INFO:root:current train perplexity4.5276923179626465
INFO:root:current mean train loss 3905.319954585103
INFO:root:current train perplexity4.647554397583008
INFO:root:current mean train loss 3897.9662448526014
INFO:root:current train perplexity4.644443988800049
INFO:root:current mean train loss 3901.9687064897894
INFO:root:current train perplexity4.647261619567871
INFO:root:current mean train loss 3896.889431558235
INFO:root:current train perplexity4.64276123046875
INFO:root:current mean train loss 3899.4290720520626
INFO:root:current train perplexity4.642933368682861
INFO:root:current mean train loss 3904.2852408692215
INFO:root:current train perplexity4.651129245758057
INFO:root:current mean train loss 3902.0548416940787
INFO:root:current train perplexity4.655261516571045
INFO:root:current mean train loss 3904.302819809017
INFO:root:current train perplexity4.656817436218262
INFO:root:current mean train loss 3906.335126131212
INFO:root:current train perplexity4.659928321838379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.96s/it]
INFO:root:final mean train loss: 3902.785748820151
INFO:root:final train perplexity: 4.663479804992676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it]
INFO:root:eval mean loss: 4060.083672706117
INFO:root:eval perplexity: 5.164347171783447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/39

 20%|â–ˆâ–‰        | 39/200 [2:13:49<10:04:20, 225.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3852.3160511363635
INFO:root:current train perplexity4.588396072387695
INFO:root:current mean train loss 3870.0629772839247
INFO:root:current train perplexity4.601943016052246
INFO:root:current mean train loss 3880.9548536544726
INFO:root:current train perplexity4.611200332641602
INFO:root:current mean train loss 3883.278464755828
INFO:root:current train perplexity4.629443645477295
INFO:root:current mean train loss 3886.8830192176097
INFO:root:current train perplexity4.637922763824463
INFO:root:current mean train loss 3890.748512701046
INFO:root:current train perplexity4.638820648193359
INFO:root:current mean train loss 3889.096054751432
INFO:root:current train perplexity4.634744167327881
INFO:root:current mean train loss 3891.31576413612
INFO:root:current train perplexity4.639673709869385
INFO:root:current mean train loss 3893.249343740367
INFO:root:current train perplexity4.641196250915527
INFO:root:current mean train loss 3894.4669139874622
INFO:root:current train perplexity4.643022060394287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.71s/it]
INFO:root:final mean train loss: 3892.2134160687847
INFO:root:final train perplexity: 4.644068241119385
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 4056.242192694481
INFO:root:eval perplexity: 5.156330585479736
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/40

 20%|â–ˆâ–ˆ        | 40/200 [2:17:38<10:03:38, 226.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3891.361083984375
INFO:root:current train perplexity4.637142181396484
INFO:root:current mean train loss 3875.500736525079
INFO:root:current train perplexity4.616814136505127
INFO:root:current mean train loss 3873.0335174978595
INFO:root:current train perplexity4.6131157875061035
INFO:root:current mean train loss 3882.012790213558
INFO:root:current train perplexity4.615079402923584
INFO:root:current mean train loss 3882.3207862143868
INFO:root:current train perplexity4.617077827453613
INFO:root:current mean train loss 3885.54612282108
INFO:root:current train perplexity4.620070934295654
INFO:root:current mean train loss 3884.0979323379443
INFO:root:current train perplexity4.618439674377441
INFO:root:current mean train loss 3889.1030242877478
INFO:root:current train perplexity4.626262187957764
INFO:root:current mean train loss 3885.8303344875612
INFO:root:current train perplexity4.622808933258057
INFO:root:current mean train loss 3882.79649085708
INFO:root:current train perplexity4.6222124099731445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.70s/it]
INFO:root:final mean train loss: 3879.5950389985114
INFO:root:final train perplexity: 4.621005535125732
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4052.398697224069
INFO:root:eval perplexity: 5.1483235359191895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/41

 20%|â–ˆâ–ˆ        | 41/200 [2:21:24<9:59:29, 226.22s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3832.30456995081
INFO:root:current train perplexity4.589537143707275
INFO:root:current mean train loss 3851.2408206969735
INFO:root:current train perplexity4.57313871383667
INFO:root:current mean train loss 3853.61550325234
INFO:root:current train perplexity4.579726696014404
INFO:root:current mean train loss 3855.484913303947
INFO:root:current train perplexity4.575231552124023
INFO:root:current mean train loss 3857.41713398346
INFO:root:current train perplexity4.582820415496826
INFO:root:current mean train loss 3857.822540341111
INFO:root:current train perplexity4.578525543212891
INFO:root:current mean train loss 3861.2218774920257
INFO:root:current train perplexity4.579919338226318
INFO:root:current mean train loss 3866.7702173288126
INFO:root:current train perplexity4.589165210723877
INFO:root:current mean train loss 3871.890333034972
INFO:root:current train perplexity4.596987247467041
INFO:root:current mean train loss 3871.935033837311
INFO:root:current train perplexity4.598465919494629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it]
INFO:root:final mean train loss: 3868.1999747983873
INFO:root:final train perplexity: 4.600278377532959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4046.30694190492
INFO:root:eval perplexity: 5.13565731048584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/42

 21%|â–ˆâ–ˆ        | 42/200 [2:24:36<9:28:31, 215.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3793.7383370535713
INFO:root:current train perplexity4.535560607910156
INFO:root:current mean train loss 3820.192603443287
INFO:root:current train perplexity4.552119731903076
INFO:root:current mean train loss 3837.043039394947
INFO:root:current train perplexity4.553860187530518
INFO:root:current mean train loss 3849.048792414879
INFO:root:current train perplexity4.567047119140625
INFO:root:current mean train loss 3852.435699533046
INFO:root:current train perplexity4.567882061004639
INFO:root:current mean train loss 3855.8941137010806
INFO:root:current train perplexity4.5720319747924805
INFO:root:current mean train loss 3856.0955885519193
INFO:root:current train perplexity4.575354099273682
INFO:root:current mean train loss 3859.8775981877125
INFO:root:current train perplexity4.576303005218506
INFO:root:current mean train loss 3856.3565938435627
INFO:root:current train perplexity4.572707653045654
INFO:root:current mean train loss 3856.3228860294116
INFO:root:current train perplexity4.573180198669434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it]
INFO:root:final mean train loss: 3855.4395332336426
INFO:root:final train perplexity: 4.577177047729492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it]
INFO:root:eval mean loss: 4044.2589864527927
INFO:root:eval perplexity: 5.131406307220459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/43

 22%|â–ˆâ–ˆâ–       | 43/200 [2:27:48<9:06:20, 208.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3884.663454987282
INFO:root:current train perplexity4.561383247375488
INFO:root:current mean train loss 3859.0502793105334
INFO:root:current train perplexity4.5595245361328125
INFO:root:current mean train loss 3851.1248302067256
INFO:root:current train perplexity4.543351650238037
INFO:root:current mean train loss 3847.315941457498
INFO:root:current train perplexity4.542623043060303
INFO:root:current mean train loss 3848.26026713283
INFO:root:current train perplexity4.5424675941467285
INFO:root:current mean train loss 3848.8352068765826
INFO:root:current train perplexity4.547351360321045
INFO:root:current mean train loss 3847.8864024682885
INFO:root:current train perplexity4.548085689544678
INFO:root:current mean train loss 3845.5725150230273
INFO:root:current train perplexity4.5500807762146
INFO:root:current mean train loss 3847.0864055086004
INFO:root:current train perplexity4.555212020874023
INFO:root:current mean train loss 3846.510508143889
INFO:root:current train perplexity4.555610179901123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.13s/it]
INFO:root:final mean train loss: 3843.596930719191
INFO:root:final train perplexity: 4.555840969085693
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
INFO:root:eval mean loss: 4043.060307928856
INFO:root:eval perplexity: 5.128918647766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/44

 22%|â–ˆâ–ˆâ–       | 44/200 [2:31:01<8:50:25, 204.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3778.9236749387255
INFO:root:current train perplexity4.477738380432129
INFO:root:current mean train loss 3817.1776131131
INFO:root:current train perplexity4.498549461364746
INFO:root:current mean train loss 3822.544865460035
INFO:root:current train perplexity4.513460159301758
INFO:root:current mean train loss 3822.3960892984333
INFO:root:current train perplexity4.514217853546143
INFO:root:current mean train loss 3829.390106404171
INFO:root:current train perplexity4.515598297119141
INFO:root:current mean train loss 3834.0292587695667
INFO:root:current train perplexity4.527018070220947
INFO:root:current mean train loss 3829.4222894015215
INFO:root:current train perplexity4.524896621704102
INFO:root:current mean train loss 3832.613126833493
INFO:root:current train perplexity4.529630661010742
INFO:root:current mean train loss 3831.4696648818485
INFO:root:current train perplexity4.5311455726623535
INFO:root:current mean train loss 3834.635555038693
INFO:root:current train perplexity4.5338640213012695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.16s/it]
INFO:root:final mean train loss: 3833.0425754670173
INFO:root:final train perplexity: 4.536910533905029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4038.474578208112
INFO:root:eval perplexity: 5.119416236877441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:34:12<8:37:17, 200.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3811.2933287539727
INFO:root:current train perplexity4.473092079162598
INFO:root:current mean train loss 3821.755863981427
INFO:root:current train perplexity4.507148742675781
INFO:root:current mean train loss 3818.326399990951
INFO:root:current train perplexity4.508701801300049
INFO:root:current mean train loss 3816.720960866774
INFO:root:current train perplexity4.507132053375244
INFO:root:current mean train loss 3817.0210067316857
INFO:root:current train perplexity4.509144306182861
INFO:root:current mean train loss 3818.6344935326756
INFO:root:current train perplexity4.510098934173584
INFO:root:current mean train loss 3823.744912316839
INFO:root:current train perplexity4.512916564941406
INFO:root:current mean train loss 3827.15997804986
INFO:root:current train perplexity4.51234769821167
INFO:root:current mean train loss 3825.097522668983
INFO:root:current train perplexity4.5147809982299805
INFO:root:current mean train loss 3824.4248948082313
INFO:root:current train perplexity4.515127658843994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.74s/it]
INFO:root:final mean train loss: 3820.8834998838365
INFO:root:final train perplexity: 4.515198707580566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4040.3436028230276
INFO:root:eval perplexity: 5.123288154602051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [2:37:25<8:28:23, 198.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3829.582421146222
INFO:root:current train perplexity4.49968147277832
INFO:root:current mean train loss 3816.773588077751
INFO:root:current train perplexity4.475925445556641
INFO:root:current mean train loss 3809.5192212737006
INFO:root:current train perplexity4.479780673980713
INFO:root:current mean train loss 3816.070284560201
INFO:root:current train perplexity4.49004602432251
INFO:root:current mean train loss 3820.7638083219017
INFO:root:current train perplexity4.493503570556641
INFO:root:current mean train loss 3818.1970425829477
INFO:root:current train perplexity4.492738723754883
INFO:root:current mean train loss 3819.385511955936
INFO:root:current train perplexity4.49920654296875
INFO:root:current mean train loss 3815.6720223756315
INFO:root:current train perplexity4.496472358703613
INFO:root:current mean train loss 3815.4978111821474
INFO:root:current train perplexity4.497528076171875
INFO:root:current mean train loss 3814.789156167189
INFO:root:current train perplexity4.497883319854736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.74s/it]
INFO:root:final mean train loss: 3811.13133172066
INFO:root:final train perplexity: 4.497859001159668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it]
INFO:root:eval mean loss: 4038.47016463043
INFO:root:eval perplexity: 5.11940860748291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [2:40:38<8:20:37, 196.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3806.3833235677084
INFO:root:current train perplexity4.436318397521973
INFO:root:current mean train loss 3794.108755580357
INFO:root:current train perplexity4.46454381942749
INFO:root:current mean train loss 3792.4585324928976
INFO:root:current train perplexity4.459942817687988
INFO:root:current mean train loss 3800.6271927083335
INFO:root:current train perplexity4.471836566925049
INFO:root:current mean train loss 3799.946005345395
INFO:root:current train perplexity4.4729838371276855
INFO:root:current mean train loss 3802.413305027174
INFO:root:current train perplexity4.475512504577637
INFO:root:current mean train loss 3801.085130931713
INFO:root:current train perplexity4.475988388061523
INFO:root:current mean train loss 3801.0726905871975
INFO:root:current train perplexity4.479518413543701
INFO:root:current mean train loss 3802.373380580357
INFO:root:current train perplexity4.481276988983154
INFO:root:current mean train loss 3803.3199576822917
INFO:root:current train perplexity4.479865550994873


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it]
INFO:root:final mean train loss: 3800.685552412464
INFO:root:final train perplexity: 4.479361057281494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4033.499982685062
INFO:root:eval perplexity: 5.109129428863525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/48

 24%|â–ˆâ–ˆâ–       | 48/200 [2:43:49<8:13:47, 194.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3795.428355021649
INFO:root:current train perplexity4.438446521759033
INFO:root:current mean train loss 3797.8804391329404
INFO:root:current train perplexity4.437663555145264
INFO:root:current mean train loss 3786.469463442745
INFO:root:current train perplexity4.435258388519287
INFO:root:current mean train loss 3783.9883328828737
INFO:root:current train perplexity4.445261001586914
INFO:root:current mean train loss 3784.978337700569
INFO:root:current train perplexity4.450395584106445
INFO:root:current mean train loss 3788.156680491531
INFO:root:current train perplexity4.443640232086182
INFO:root:current mean train loss 3789.5287499714036
INFO:root:current train perplexity4.447611331939697
INFO:root:current mean train loss 3788.2619045837323
INFO:root:current train perplexity4.450490474700928
INFO:root:current mean train loss 3788.5820923542788
INFO:root:current train perplexity4.451807498931885
INFO:root:current mean train loss 3791.99759858016
INFO:root:current train perplexity4.4599151611328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.88s/it]
INFO:root:final mean train loss: 3789.5967247870663
INFO:root:final train perplexity: 4.459807395935059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.78s/it]
INFO:root:eval mean loss: 4032.9833863170434
INFO:root:eval perplexity: 5.108061790466309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/49

 24%|â–ˆâ–ˆâ–       | 49/200 [2:47:02<8:08:42, 194.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.3313954112296
INFO:root:current train perplexity4.385509490966797
INFO:root:current mean train loss 3776.3501500633997
INFO:root:current train perplexity4.408879280090332
INFO:root:current mean train loss 3767.5711388866516
INFO:root:current train perplexity4.416428089141846
INFO:root:current mean train loss 3771.299841527134
INFO:root:current train perplexity4.4217915534973145
INFO:root:current mean train loss 3772.176608145844
INFO:root:current train perplexity4.425119400024414
INFO:root:current mean train loss 3775.9099534191255
INFO:root:current train perplexity4.4301300048828125
INFO:root:current mean train loss 3774.4060454306486
INFO:root:current train perplexity4.429096221923828
INFO:root:current mean train loss 3777.6460223288364
INFO:root:current train perplexity4.432953834533691
INFO:root:current mean train loss 3777.040188122545
INFO:root:current train perplexity4.434349536895752
INFO:root:current mean train loss 3781.669759032464
INFO:root:current train perplexity4.440740585327148


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.01s/it]
INFO:root:final mean train loss: 3778.772450970065
INFO:root:final train perplexity: 4.440802574157715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it]
INFO:root:eval mean loss: 4033.032808344415
INFO:root:eval perplexity: 5.108164310455322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [2:50:13<8:03:27, 193.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3757.015686651673
INFO:root:current train perplexity4.376587390899658
INFO:root:current mean train loss 3762.2816744857096
INFO:root:current train perplexity4.392938137054443
INFO:root:current mean train loss 3766.659902311089
INFO:root:current train perplexity4.404249668121338
INFO:root:current mean train loss 3768.753399612312
INFO:root:current train perplexity4.406970977783203
INFO:root:current mean train loss 3772.3708295497245
INFO:root:current train perplexity4.417828559875488
INFO:root:current mean train loss 3771.007692263799
INFO:root:current train perplexity4.422233581542969
INFO:root:current mean train loss 3766.175939819161
INFO:root:current train perplexity4.421291351318359
INFO:root:current mean train loss 3766.1334236154566
INFO:root:current train perplexity4.421217441558838
INFO:root:current mean train loss 3767.827392849694
INFO:root:current train perplexity4.422521114349365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.87s/it]
INFO:root:final mean train loss: 3769.4155089470646
INFO:root:final train perplexity: 4.424439430236816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 4033.4260911873894
INFO:root:eval perplexity: 5.108976364135742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [2:53:25<7:58:46, 192.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3706.160330636161
INFO:root:current train perplexity4.371606349945068
INFO:root:current mean train loss 3755.5423024970796
INFO:root:current train perplexity4.382310390472412
INFO:root:current mean train loss 3755.692821557971
INFO:root:current train perplexity4.392542362213135
INFO:root:current mean train loss 3766.0773369108815
INFO:root:current train perplexity4.395007610321045
INFO:root:current mean train loss 3767.6814600689113
INFO:root:current train perplexity4.402163982391357
INFO:root:current mean train loss 3764.5573248929054
INFO:root:current train perplexity4.400706768035889
INFO:root:current mean train loss 3761.457248442648
INFO:root:current train perplexity4.401455879211426
INFO:root:current mean train loss 3758.722005668759
INFO:root:current train perplexity4.40388298034668
INFO:root:current mean train loss 3762.09682822907
INFO:root:current train perplexity4.407848358154297
INFO:root:current mean train loss 3762.520133391762
INFO:root:current train perplexity4.406900405883789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.40s/it]
INFO:root:final mean train loss: 3760.596683932889
INFO:root:final train perplexity: 4.409072399139404
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4029.913994971742
INFO:root:eval perplexity: 5.101726055145264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:56:37<7:55:25, 192.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3759.566064453125
INFO:root:current train perplexity4.448304176330566
INFO:root:current mean train loss 3728.8403065557063
INFO:root:current train perplexity4.359829425811768
INFO:root:current mean train loss 3735.1059854196947
INFO:root:current train perplexity4.369511127471924
INFO:root:current mean train loss 3735.277881634425
INFO:root:current train perplexity4.374988079071045
INFO:root:current mean train loss 3740.3849915286146
INFO:root:current train perplexity4.373583793640137
INFO:root:current mean train loss 3742.706352870904
INFO:root:current train perplexity4.37613582611084
INFO:root:current mean train loss 3742.008196773374
INFO:root:current train perplexity4.38329553604126
INFO:root:current mean train loss 3745.9165175644666
INFO:root:current train perplexity4.38668966293335
INFO:root:current mean train loss 3751.441810055598
INFO:root:current train perplexity4.388528347015381
INFO:root:current mean train loss 3752.670553705601
INFO:root:current train perplexity4.389984130859375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.53s/it]
INFO:root:final mean train loss: 3750.621977836855
INFO:root:final train perplexity: 4.391755104064941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it]
INFO:root:eval mean loss: 4028.251421556405
INFO:root:eval perplexity: 5.098297119140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:59:50<7:52:21, 192.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3739.2975861922555
INFO:root:current train perplexity4.421320915222168
INFO:root:current mean train loss 3742.2901799892024
INFO:root:current train perplexity4.380001068115234
INFO:root:current mean train loss 3733.9337919089826
INFO:root:current train perplexity4.370786666870117
INFO:root:current mean train loss 3742.1244247956174
INFO:root:current train perplexity4.373680114746094
INFO:root:current mean train loss 3736.7060408355496
INFO:root:current train perplexity4.371049404144287
INFO:root:current mean train loss 3743.1966144277308
INFO:root:current train perplexity4.3779401779174805
INFO:root:current mean train loss 3746.3173193281
INFO:root:current train perplexity4.378940105438232
INFO:root:current mean train loss 3742.187592185879
INFO:root:current train perplexity4.373522758483887
INFO:root:current mean train loss 3744.09064707055
INFO:root:current train perplexity4.375722408294678
INFO:root:current mean train loss 3746.398181721035
INFO:root:current train perplexity4.377477169036865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.34s/it]
INFO:root:final mean train loss: 3741.1058661553166
INFO:root:final train perplexity: 4.375297546386719
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]
INFO:root:eval mean loss: 4029.616391012855
INFO:root:eval perplexity: 5.101112365722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:03:03<7:49:23, 192.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.5232878654233
INFO:root:current train perplexity4.359158992767334
INFO:root:current mean train loss 3720.4562317360446
INFO:root:current train perplexity4.3395586013793945
INFO:root:current mean train loss 3730.277730570211
INFO:root:current train perplexity4.3512701988220215
INFO:root:current mean train loss 3721.640965026671
INFO:root:current train perplexity4.343059539794922
INFO:root:current mean train loss 3724.9639317629785
INFO:root:current train perplexity4.349693775177002
INFO:root:current mean train loss 3727.9876058402483
INFO:root:current train perplexity4.356110095977783
INFO:root:current mean train loss 3726.508253191239
INFO:root:current train perplexity4.357816696166992
INFO:root:current mean train loss 3727.824656266031
INFO:root:current train perplexity4.357296466827393
INFO:root:current mean train loss 3729.498378565452
INFO:root:current train perplexity4.35775899887085
INFO:root:current mean train loss 3731.661161658331
INFO:root:current train perplexity4.357054710388184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.29s/it]
INFO:root:final mean train loss: 3730.508343296666
INFO:root:final train perplexity: 4.3570427894592285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4028.8278410350176
INFO:root:eval perplexity: 5.099484920501709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:06:15<7:45:38, 192.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.1317858573716
INFO:root:current train perplexity4.301634311676025
INFO:root:current mean train loss 3722.1802706272483
INFO:root:current train perplexity4.325847625732422
INFO:root:current mean train loss 3723.4489960610617
INFO:root:current train perplexity4.328829288482666
INFO:root:current mean train loss 3718.7426865839325
INFO:root:current train perplexity4.322926044464111
INFO:root:current mean train loss 3715.231900226011
INFO:root:current train perplexity4.323070526123047
INFO:root:current mean train loss 3713.242965669933
INFO:root:current train perplexity4.3290019035339355
INFO:root:current mean train loss 3715.2414646297925
INFO:root:current train perplexity4.332571983337402
INFO:root:current mean train loss 3718.6967737097216
INFO:root:current train perplexity4.339022159576416
INFO:root:current mean train loss 3721.823109205062
INFO:root:current train perplexity4.341862201690674
INFO:root:current mean train loss 3725.3982895596214
INFO:root:current train perplexity4.344132900238037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.68s/it]
INFO:root:final mean train loss: 3723.2131236906976
INFO:root:final train perplexity: 4.344520092010498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it]
INFO:root:eval mean loss: 4025.9347763602614
INFO:root:eval perplexity: 5.093524932861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:09:34<7:46:30, 194.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.668129778923
INFO:root:current train perplexity4.323598384857178
INFO:root:current mean train loss 3700.3265007174746
INFO:root:current train perplexity4.304747104644775
INFO:root:current mean train loss 3706.680684819395
INFO:root:current train perplexity4.30800724029541
INFO:root:current mean train loss 3710.1186340507925
INFO:root:current train perplexity4.31266975402832
INFO:root:current mean train loss 3707.9905134708824
INFO:root:current train perplexity4.31725549697876
INFO:root:current mean train loss 3710.9314522751943
INFO:root:current train perplexity4.319480895996094
INFO:root:current mean train loss 3716.3593848109062
INFO:root:current train perplexity4.324283599853516
INFO:root:current mean train loss 3716.961046660601
INFO:root:current train perplexity4.326792240142822
INFO:root:current mean train loss 3718.3418672059474
INFO:root:current train perplexity4.328493595123291
INFO:root:current mean train loss 3718.276008839592
INFO:root:current train perplexity4.328711032867432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.91s/it]
INFO:root:final mean train loss: 3713.7806726271106
INFO:root:final train perplexity: 4.32838249206543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4027.063029837101
INFO:root:eval perplexity: 5.095848083496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:12:55<7:47:58, 196.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3671.719921875
INFO:root:current train perplexity4.251749515533447
INFO:root:current mean train loss 3681.9972971270163
INFO:root:current train perplexity4.279045104980469
INFO:root:current mean train loss 3689.5651922487746
INFO:root:current train perplexity4.2806291580200195
INFO:root:current mean train loss 3687.9868033395687
INFO:root:current train perplexity4.281203269958496
INFO:root:current mean train loss 3698.186293247768
INFO:root:current train perplexity4.2922163009643555
INFO:root:current mean train loss 3699.1550882425395
INFO:root:current train perplexity4.297858238220215
INFO:root:current mean train loss 3700.37755285365
INFO:root:current train perplexity4.303045749664307
INFO:root:current mean train loss 3701.5291044727855
INFO:root:current train perplexity4.308737277984619
INFO:root:current mean train loss 3703.198308433845
INFO:root:current train perplexity4.308482646942139
INFO:root:current mean train loss 3705.924764806937
INFO:root:current train perplexity4.310539722442627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.20s/it]
INFO:root:final mean train loss: 3703.735375496649
INFO:root:final train perplexity: 4.311262607574463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it]
INFO:root:eval mean loss: 4026.0164717004654
INFO:root:eval perplexity: 5.093691825866699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:16:15<7:47:44, 197.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3688.4664752294148
INFO:root:current train perplexity4.289870738983154
INFO:root:current mean train loss 3672.496626965107
INFO:root:current train perplexity4.253681182861328
INFO:root:current mean train loss 3682.0904053662666
INFO:root:current train perplexity4.262855529785156
INFO:root:current mean train loss 3674.606751328986
INFO:root:current train perplexity4.264275550842285
INFO:root:current mean train loss 3681.5087010031384
INFO:root:current train perplexity4.273783206939697
INFO:root:current mean train loss 3685.374303136795
INFO:root:current train perplexity4.2779059410095215
INFO:root:current mean train loss 3687.9794093343467
INFO:root:current train perplexity4.281665802001953
INFO:root:current mean train loss 3690.1266997051116
INFO:root:current train perplexity4.288480758666992
INFO:root:current mean train loss 3691.673536457579
INFO:root:current train perplexity4.291926860809326
INFO:root:current mean train loss 3696.6217998057014
INFO:root:current train perplexity4.2961201667785645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.09s/it]
INFO:root:final mean train loss: 3695.543868587863
INFO:root:final train perplexity: 4.297351837158203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 4023.6851295849956
INFO:root:eval perplexity: 5.088891506195068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [3:19:27<7:40:14, 195.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.630890322403
INFO:root:current train perplexity4.260645866394043
INFO:root:current mean train loss 3668.8156552677265
INFO:root:current train perplexity4.2435808181762695
INFO:root:current mean train loss 3682.1543013794394
INFO:root:current train perplexity4.257867336273193
INFO:root:current mean train loss 3686.926676870999
INFO:root:current train perplexity4.27034854888916
INFO:root:current mean train loss 3685.430341133393
INFO:root:current train perplexity4.277706623077393
INFO:root:current mean train loss 3686.2275010090575
INFO:root:current train perplexity4.280129909515381
INFO:root:current mean train loss 3686.392822265625
INFO:root:current train perplexity4.280636310577393
INFO:root:current mean train loss 3688.9138766238043
INFO:root:current train perplexity4.280731201171875
INFO:root:current mean train loss 3688.9393477324916
INFO:root:current train perplexity4.281487464904785
INFO:root:current mean train loss 3688.773375899121
INFO:root:current train perplexity4.282161235809326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.76s/it]
INFO:root:final mean train loss: 3687.0430644250687
INFO:root:final train perplexity: 4.282962799072266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it]
INFO:root:eval mean loss: 4025.3669295074246
INFO:root:eval perplexity: 5.0923542976379395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [3:22:39<7:34:28, 194.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.977455622033
INFO:root:current train perplexity4.264410972595215
INFO:root:current mean train loss 3684.176937849162
INFO:root:current train perplexity4.269845485687256
INFO:root:current mean train loss 3679.416941434252
INFO:root:current train perplexity4.269653797149658
INFO:root:current mean train loss 3670.045654296875
INFO:root:current train perplexity4.263404846191406
INFO:root:current mean train loss 3670.8678241005023
INFO:root:current train perplexity4.260014057159424
INFO:root:current mean train loss 3674.6378496397347
INFO:root:current train perplexity4.265179634094238
INFO:root:current mean train loss 3673.4841186343656
INFO:root:current train perplexity4.262417316436768
INFO:root:current mean train loss 3676.4079828029726
INFO:root:current train perplexity4.265455722808838
INFO:root:current mean train loss 3678.0308050474614
INFO:root:current train perplexity4.265205383300781
INFO:root:current mean train loss 3682.5276345242273
INFO:root:current train perplexity4.269687652587891


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.50s/it]
INFO:root:final mean train loss: 3679.3010338198756
INFO:root:final train perplexity: 4.269901275634766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 4025.959562693927
INFO:root:eval perplexity: 5.093574047088623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [3:25:52<7:29:27, 194.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3655.4051527702945
INFO:root:current train perplexity4.209322929382324
INFO:root:current mean train loss 3665.10888671875
INFO:root:current train perplexity4.238949775695801
INFO:root:current mean train loss 3670.5003147457533
INFO:root:current train perplexity4.246143817901611
INFO:root:current mean train loss 3672.5635409096417
INFO:root:current train perplexity4.248921871185303
INFO:root:current mean train loss 3673.196120119193
INFO:root:current train perplexity4.251568794250488
INFO:root:current mean train loss 3673.543286507134
INFO:root:current train perplexity4.250298976898193
INFO:root:current mean train loss 3672.678379375341
INFO:root:current train perplexity4.250412464141846
INFO:root:current mean train loss 3671.311353748908
INFO:root:current train perplexity4.252495288848877
INFO:root:current mean train loss 3670.114229737704
INFO:root:current train perplexity4.251062870025635
INFO:root:current mean train loss 3671.656905988792
INFO:root:current train perplexity4.252223014831543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.42s/it]
INFO:root:final mean train loss: 3668.767720745456
INFO:root:final train perplexity: 4.252193450927734
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4026.9020113031916
INFO:root:eval perplexity: 5.095516204833984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [3:29:04<7:25:21, 193.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.3348709909537
INFO:root:current train perplexity4.202671527862549
INFO:root:current mean train loss 3651.394439853766
INFO:root:current train perplexity4.224740505218506
INFO:root:current mean train loss 3656.3968882415256
INFO:root:current train perplexity4.228254318237305
INFO:root:current mean train loss 3659.184949194027
INFO:root:current train perplexity4.231383323669434
INFO:root:current mean train loss 3662.5759607796717
INFO:root:current train perplexity4.230617046356201
INFO:root:current mean train loss 3664.05872382156
INFO:root:current train perplexity4.2370524406433105
INFO:root:current mean train loss 3664.086463719649
INFO:root:current train perplexity4.2371015548706055
INFO:root:current mean train loss 3665.796647749607
INFO:root:current train perplexity4.242938995361328
INFO:root:current mean train loss 3665.7929106472593
INFO:root:current train perplexity4.24246883392334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it]
INFO:root:final mean train loss: 3663.174815639373
INFO:root:final train perplexity: 4.242821216583252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it]
INFO:root:eval mean loss: 4026.220897052305
INFO:root:eval perplexity: 5.094112873077393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [3:32:16<7:21:01, 193.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3666.8238932291665
INFO:root:current train perplexity4.27253532409668
INFO:root:current mean train loss 3661.252777988471
INFO:root:current train perplexity4.223303318023682
INFO:root:current mean train loss 3648.7035074468904
INFO:root:current train perplexity4.2139129638671875
INFO:root:current mean train loss 3648.449279180848
INFO:root:current train perplexity4.222236633300781
INFO:root:current mean train loss 3656.1092071911835
INFO:root:current train perplexity4.22669792175293
INFO:root:current mean train loss 3660.1503003463595
INFO:root:current train perplexity4.223916530609131
INFO:root:current mean train loss 3660.622998289801
INFO:root:current train perplexity4.223953723907471
INFO:root:current mean train loss 3657.408963329592
INFO:root:current train perplexity4.2218017578125
INFO:root:current mean train loss 3657.994308756713
INFO:root:current train perplexity4.223635673522949
INFO:root:current mean train loss 3657.6551798908154
INFO:root:current train perplexity4.224081516265869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.03s/it]
INFO:root:final mean train loss: 3654.057546677128
INFO:root:final train perplexity: 4.2275872230529785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4025.254564217642
INFO:root:eval perplexity: 5.092122554779053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [3:35:29<7:17:41, 193.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.731867009943
INFO:root:current train perplexity4.208756446838379
INFO:root:current mean train loss 3657.40612463049
INFO:root:current train perplexity4.205564022064209
INFO:root:current mean train loss 3636.2950456809094
INFO:root:current train perplexity4.199540138244629
INFO:root:current mean train loss 3624.9699754132334
INFO:root:current train perplexity4.1924848556518555
INFO:root:current mean train loss 3631.36975899578
INFO:root:current train perplexity4.19329309463501
INFO:root:current mean train loss 3637.8451541669215
INFO:root:current train perplexity4.198964595794678
INFO:root:current mean train loss 3642.277010903616
INFO:root:current train perplexity4.204880237579346
INFO:root:current mean train loss 3644.1908801973455
INFO:root:current train perplexity4.208165168762207
INFO:root:current mean train loss 3648.5707282314465
INFO:root:current train perplexity4.212094306945801
INFO:root:current mean train loss 3646.8239955127437
INFO:root:current train perplexity4.211170673370361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.86s/it]
INFO:root:final mean train loss: 3645.4106380708754
INFO:root:final train perplexity: 4.213189601898193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4022.010667733267
INFO:root:eval perplexity: 5.085447788238525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/65
##################best##########
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [3:38:40<7:13:08, 192.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3581.38623046875
INFO:root:current train perplexity4.177299499511719
INFO:root:current mean train loss 3635.48554646468
INFO:root:current train perplexity4.188214302062988
INFO:root:current mean train loss 3634.700597754352
INFO:root:current train perplexity4.185561656951904
INFO:root:current mean train loss 3637.7685914233934
INFO:root:current train perplexity4.188055992126465
INFO:root:current mean train loss 3640.062667227588
INFO:root:current train perplexity4.1940155029296875
INFO:root:current mean train loss 3635.9857467033958
INFO:root:current train perplexity4.187819957733154
INFO:root:current mean train loss 3640.1428293650292
INFO:root:current train perplexity4.193377494812012
INFO:root:current mean train loss 3638.5867582063847
INFO:root:current train perplexity4.1960649490356445
INFO:root:current mean train loss 3637.380057198661
INFO:root:current train perplexity4.193129539489746
INFO:root:current mean train loss 3638.2724072743813
INFO:root:current train perplexity4.198426246643066


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.10s/it]
INFO:root:final mean train loss: 3637.9843879207488
INFO:root:final train perplexity: 4.200863838195801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 4025.9730146692154
INFO:root:eval perplexity: 5.093603134155273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [3:41:53<7:09:47, 192.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3596.7033781828704
INFO:root:current train perplexity4.095539569854736
INFO:root:current mean train loss 3614.3784429595225
INFO:root:current train perplexity4.153807640075684
INFO:root:current mean train loss 3627.7800841478524
INFO:root:current train perplexity4.180291652679443
INFO:root:current mean train loss 3630.797790340692
INFO:root:current train perplexity4.180185317993164
INFO:root:current mean train loss 3632.833768250512
INFO:root:current train perplexity4.178033351898193
INFO:root:current mean train loss 3626.5700016492233
INFO:root:current train perplexity4.172817707061768
INFO:root:current mean train loss 3626.739931438148
INFO:root:current train perplexity4.176521301269531
INFO:root:current mean train loss 3627.0340859939174
INFO:root:current train perplexity4.180715560913086
INFO:root:current mean train loss 3628.313188435233
INFO:root:current train perplexity4.183578968048096
INFO:root:current mean train loss 3632.2560147611584
INFO:root:current train perplexity4.1873931884765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.43s/it]
INFO:root:final mean train loss: 3630.745283372941
INFO:root:final train perplexity: 4.188882350921631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]
INFO:root:eval mean loss: 4025.3488215453235
INFO:root:eval perplexity: 5.092316627502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [3:45:04<7:06:05, 192.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3597.4093610491072
INFO:root:current train perplexity4.134706497192383
INFO:root:current mean train loss 3596.94486400463
INFO:root:current train perplexity4.144680500030518
INFO:root:current mean train loss 3607.3252119348404
INFO:root:current train perplexity4.155193328857422
INFO:root:current mean train loss 3616.1733646222015
INFO:root:current train perplexity4.160849571228027
INFO:root:current mean train loss 3615.635810097881
INFO:root:current train perplexity4.160696506500244
INFO:root:current mean train loss 3622.7840418735395
INFO:root:current train perplexity4.166184425354004
INFO:root:current mean train loss 3623.3021299827756
INFO:root:current train perplexity4.164134979248047
INFO:root:current mean train loss 3624.1913926312714
INFO:root:current train perplexity4.168724060058594
INFO:root:current mean train loss 3626.03597200131
INFO:root:current train perplexity4.173051834106445
INFO:root:current mean train loss 3627.987525850184
INFO:root:current train perplexity4.175595283508301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:02<00:00, 182.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:02<00:00, 182.03s/it]
INFO:root:final mean train loss: 3623.341110660184
INFO:root:final train perplexity: 4.176663875579834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4027.8283293162676
INFO:root:eval perplexity: 5.0974249839782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [3:48:19<7:04:16, 192.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3607.700564362282
INFO:root:current train perplexity4.141172885894775
INFO:root:current mean train loss 3619.088076718204
INFO:root:current train perplexity4.156450271606445
INFO:root:current mean train loss 3618.353559831533
INFO:root:current train perplexity4.157151699066162
INFO:root:current mean train loss 3615.9682667012116
INFO:root:current train perplexity4.151659965515137
INFO:root:current mean train loss 3610.635554259841
INFO:root:current train perplexity4.148184299468994
INFO:root:current mean train loss 3613.5375751755296
INFO:root:current train perplexity4.151882171630859
INFO:root:current mean train loss 3616.608858621695
INFO:root:current train perplexity4.15406608581543
INFO:root:current mean train loss 3618.232944000778
INFO:root:current train perplexity4.1584153175354
INFO:root:current mean train loss 3620.37814747368
INFO:root:current train perplexity4.162448883056641
INFO:root:current mean train loss 3617.4985794277736
INFO:root:current train perplexity4.160406112670898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.05s/it]
INFO:root:final mean train loss: 3614.557859051612
INFO:root:final train perplexity: 4.162215709686279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4027.7473750554077
INFO:root:eval perplexity: 5.0972580909729
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [3:51:31<7:00:54, 192.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3595.113156786152
INFO:root:current train perplexity4.133088111877441
INFO:root:current mean train loss 3591.187200887314
INFO:root:current train perplexity4.1375322341918945
INFO:root:current mean train loss 3594.764285630914
INFO:root:current train perplexity4.133238315582275
INFO:root:current mean train loss 3604.283188518296
INFO:root:current train perplexity4.145203590393066
INFO:root:current mean train loss 3596.5152720516908
INFO:root:current train perplexity4.141587734222412
INFO:root:current mean train loss 3597.9508639299283
INFO:root:current train perplexity4.145308971405029
INFO:root:current mean train loss 3601.369822793659
INFO:root:current train perplexity4.145758628845215
INFO:root:current mean train loss 3603.445844017872
INFO:root:current train perplexity4.14804220199585
INFO:root:current mean train loss 3606.7429850451676
INFO:root:current train perplexity4.1482086181640625
INFO:root:current mean train loss 3609.735854990224
INFO:root:current train perplexity4.150026321411133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.40s/it]
INFO:root:final mean train loss: 3607.7060468119957
INFO:root:final train perplexity: 4.150979995727539
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4028.802010610594
INFO:root:eval perplexity: 5.099433422088623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [3:54:43<6:56:57, 192.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3568.358712923729
INFO:root:current train perplexity4.132798194885254
INFO:root:current mean train loss 3575.9293711920204
INFO:root:current train perplexity4.124263286590576
INFO:root:current mean train loss 3592.0964393173867
INFO:root:current train perplexity4.133360385894775
INFO:root:current mean train loss 3590.7995415052665
INFO:root:current train perplexity4.1331892013549805
INFO:root:current mean train loss 3592.06128674343
INFO:root:current train perplexity4.127915382385254
INFO:root:current mean train loss 3591.933616897501
INFO:root:current train perplexity4.127788066864014
INFO:root:current mean train loss 3593.8535919420997
INFO:root:current train perplexity4.129549980163574
INFO:root:current mean train loss 3595.098748932086
INFO:root:current train perplexity4.133326053619385
INFO:root:current mean train loss 3597.8158261673275
INFO:root:current train perplexity4.135679721832275
INFO:root:current mean train loss 3603.2923857656087
INFO:root:current train perplexity4.138598442077637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it]
INFO:root:final mean train loss: 3601.0256331659134
INFO:root:final train perplexity: 4.140053749084473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 4028.781546085439
INFO:root:eval perplexity: 5.099390029907227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [3:57:54<6:52:55, 192.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3568.317976766558
INFO:root:current train perplexity4.072225093841553
INFO:root:current mean train loss 3572.3817789226237
INFO:root:current train perplexity4.087145805358887
INFO:root:current mean train loss 3571.8692101182114
INFO:root:current train perplexity4.096238613128662
INFO:root:current mean train loss 3584.8425845112397
INFO:root:current train perplexity4.108635425567627
INFO:root:current mean train loss 3585.488238381625
INFO:root:current train perplexity4.109112739562988
INFO:root:current mean train loss 3581.4321611999835
INFO:root:current train perplexity4.111019134521484
INFO:root:current mean train loss 3588.000215224419
INFO:root:current train perplexity4.115477085113525
INFO:root:current mean train loss 3590.3290843739815
INFO:root:current train perplexity4.1197967529296875
INFO:root:current mean train loss 3590.0998687216156
INFO:root:current train perplexity4.121224880218506
INFO:root:current mean train loss 3596.1100554126
INFO:root:current train perplexity4.128050804138184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.02s/it]
INFO:root:final mean train loss: 3593.5175249038202
INFO:root:final train perplexity: 4.127808570861816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4030.4531371204566
INFO:root:eval perplexity: 5.102838039398193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [4:01:08<6:51:01, 192.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3599.535393880208
INFO:root:current train perplexity4.095371723175049
INFO:root:current mean train loss 3580.394400111607
INFO:root:current train perplexity4.090663433074951
INFO:root:current mean train loss 3582.445769708807
INFO:root:current train perplexity4.093864917755127
INFO:root:current mean train loss 3580.3504609375
INFO:root:current train perplexity4.102189064025879
INFO:root:current mean train loss 3583.815082236842
INFO:root:current train perplexity4.108055591583252
INFO:root:current mean train loss 3585.2632545006795
INFO:root:current train perplexity4.108298301696777
INFO:root:current mean train loss 3585.692109375
INFO:root:current train perplexity4.109788417816162
INFO:root:current mean train loss 3587.7913148941534
INFO:root:current train perplexity4.114574909210205
INFO:root:current mean train loss 3589.0314464285716
INFO:root:current train perplexity4.114725589752197
INFO:root:current mean train loss 3589.1380341045674
INFO:root:current train perplexity4.1158881187438965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.08s/it]
INFO:root:final mean train loss: 3585.986319880332
INFO:root:final train perplexity: 4.1155619621276855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.25s/it]
INFO:root:eval mean loss: 4029.018765929743
INFO:root:eval perplexity: 5.099879264831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [4:04:30<6:53:17, 195.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.0917292215736
INFO:root:current train perplexity4.071368217468262
INFO:root:current mean train loss 3567.79697238943
INFO:root:current train perplexity4.090544700622559
INFO:root:current mean train loss 3576.553952490062
INFO:root:current train perplexity4.0995659828186035
INFO:root:current mean train loss 3575.4335249061683
INFO:root:current train perplexity4.094935417175293
INFO:root:current mean train loss 3576.6030677811204
INFO:root:current train perplexity4.100013256072998
INFO:root:current mean train loss 3577.471326248928
INFO:root:current train perplexity4.103968143463135
INFO:root:current mean train loss 3580.1915613847455
INFO:root:current train perplexity4.1056389808654785
INFO:root:current mean train loss 3579.3159213985673
INFO:root:current train perplexity4.102883815765381
INFO:root:current mean train loss 3580.6613907776223
INFO:root:current train perplexity4.102802753448486
INFO:root:current mean train loss 3581.7972547467098
INFO:root:current train perplexity4.1051249504089355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.76s/it]
INFO:root:final mean train loss: 3579.73987173265
INFO:root:final train perplexity: 4.105432033538818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it]
INFO:root:eval mean loss: 4029.6054912594195
INFO:root:eval perplexity: 5.1010894775390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [4:07:51<6:53:48, 197.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3577.11421756954
INFO:root:current train perplexity4.084646224975586
INFO:root:current mean train loss 3562.995147864856
INFO:root:current train perplexity4.070633888244629
INFO:root:current mean train loss 3568.825134067601
INFO:root:current train perplexity4.0770368576049805
INFO:root:current mean train loss 3565.1328349784208
INFO:root:current train perplexity4.07763671875
INFO:root:current mean train loss 3563.9550368547925
INFO:root:current train perplexity4.075962543487549
INFO:root:current mean train loss 3566.501967583413
INFO:root:current train perplexity4.075684547424316
INFO:root:current mean train loss 3568.2964626814623
INFO:root:current train perplexity4.0823259353637695
INFO:root:current mean train loss 3569.677865859079
INFO:root:current train perplexity4.0863871574401855
INFO:root:current mean train loss 3571.002683628823
INFO:root:current train perplexity4.0886759757995605
INFO:root:current mean train loss 3574.7588410440053
INFO:root:current train perplexity4.092887878417969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.64s/it]
INFO:root:final mean train loss: 3571.9763923768073
INFO:root:final train perplexity: 4.092876434326172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 4029.6331536042776
INFO:root:eval perplexity: 5.101147174835205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [4:11:14<6:54:32, 198.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3551.156427556818
INFO:root:current train perplexity4.061507701873779
INFO:root:current mean train loss 3560.887994660804
INFO:root:current train perplexity4.061344623565674
INFO:root:current mean train loss 3559.602131617109
INFO:root:current train perplexity4.066802501678467
INFO:root:current mean train loss 3559.5876813616073
INFO:root:current train perplexity4.06958532333374
INFO:root:current mean train loss 3563.3168191852455
INFO:root:current train perplexity4.0715813636779785
INFO:root:current mean train loss 3563.361754454038
INFO:root:current train perplexity4.06889533996582
INFO:root:current mean train loss 3566.7718151349027
INFO:root:current train perplexity4.076659202575684
INFO:root:current mean train loss 3565.243012505867
INFO:root:current train perplexity4.077281951904297
INFO:root:current mean train loss 3566.2262444925786
INFO:root:current train perplexity4.080264568328857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it]
INFO:root:final mean train loss: 3564.917338340513
INFO:root:final train perplexity: 4.081493854522705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 4030.205483294548
INFO:root:eval perplexity: 5.102327823638916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [4:15:05<7:10:55, 208.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3550.319161551339
INFO:root:current train perplexity4.060515880584717
INFO:root:current mean train loss 3557.47439489632
INFO:root:current train perplexity4.071601867675781
INFO:root:current mean train loss 3550.7584623622433
INFO:root:current train perplexity4.059780597686768
INFO:root:current mean train loss 3550.0851804254885
INFO:root:current train perplexity4.053866386413574
INFO:root:current mean train loss 3554.3287506478423
INFO:root:current train perplexity4.058984756469727
INFO:root:current mean train loss 3553.6902048084626
INFO:root:current train perplexity4.0585408210754395
INFO:root:current mean train loss 3559.4836952674527
INFO:root:current train perplexity4.0654296875
INFO:root:current mean train loss 3560.154228156493
INFO:root:current train perplexity4.067814826965332
INFO:root:current mean train loss 3560.5874546812074
INFO:root:current train perplexity4.068551063537598
INFO:root:current mean train loss 3559.695922447802
INFO:root:current train perplexity4.068399429321289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.62s/it]
INFO:root:final mean train loss: 3558.606898646201
INFO:root:final train perplexity: 4.071345806121826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4030.9503598044103
INFO:root:eval perplexity: 5.103863716125488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [4:18:59<7:23:22, 216.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.212353515625
INFO:root:current train perplexity3.965048313140869
INFO:root:current mean train loss 3541.6761018172556
INFO:root:current train perplexity4.0282816886901855
INFO:root:current mean train loss 3547.1806720112645
INFO:root:current train perplexity4.035686016082764
INFO:root:current mean train loss 3543.288914465526
INFO:root:current train perplexity4.036540508270264
INFO:root:current mean train loss 3549.040672063253
INFO:root:current train perplexity4.047974109649658
INFO:root:current mean train loss 3549.833131067961
INFO:root:current train perplexity4.050434589385986
INFO:root:current mean train loss 3545.8479150787603
INFO:root:current train perplexity4.046516418457031
INFO:root:current mean train loss 3550.024729908763
INFO:root:current train perplexity4.0527729988098145
INFO:root:current mean train loss 3550.7569389858127
INFO:root:current train perplexity4.054787635803223
INFO:root:current mean train loss 3552.153592469262
INFO:root:current train perplexity4.056286334991455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.66s/it]
INFO:root:final mean train loss: 3551.2366425914147
INFO:root:final train perplexity: 4.059523105621338
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.78s/it]
INFO:root:eval mean loss: 4031.9261968085107
INFO:root:eval perplexity: 5.105878829956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [4:22:37<7:20:19, 216.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.3369989809785
INFO:root:current train perplexity4.043929576873779
INFO:root:current mean train loss 3535.228225832063
INFO:root:current train perplexity4.041022300720215
INFO:root:current mean train loss 3535.2879304757566
INFO:root:current train perplexity4.045307159423828
INFO:root:current mean train loss 3538.94339112084
INFO:root:current train perplexity4.041598320007324
INFO:root:current mean train loss 3537.897730473367
INFO:root:current train perplexity4.040056228637695
INFO:root:current mean train loss 3536.181468372819
INFO:root:current train perplexity4.040464878082275
INFO:root:current mean train loss 3542.0400849123444
INFO:root:current train perplexity4.044335842132568
INFO:root:current mean train loss 3542.4807392294474
INFO:root:current train perplexity4.043502330780029
INFO:root:current mean train loss 3544.2524986591548
INFO:root:current train perplexity4.043570518493652
INFO:root:current mean train loss 3545.3952782197994
INFO:root:current train perplexity4.048136234283447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.81s/it]
INFO:root:final mean train loss: 3544.658441851216
INFO:root:final train perplexity: 4.049001693725586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 4033.3553111840647
INFO:root:eval perplexity: 5.10883092880249
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [4:25:49<7:02:21, 209.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3530.7403288810483
INFO:root:current train perplexity4.011955738067627
INFO:root:current mean train loss 3532.6136931208252
INFO:root:current train perplexity4.022406578063965
INFO:root:current mean train loss 3537.4438191203326
INFO:root:current train perplexity4.0234856605529785
INFO:root:current mean train loss 3542.304784861216
INFO:root:current train perplexity4.0273966789245605
INFO:root:current mean train loss 3541.7808903032555
INFO:root:current train perplexity4.0347208976745605
INFO:root:current mean train loss 3541.4222717859875
INFO:root:current train perplexity4.038026809692383
INFO:root:current mean train loss 3541.4417529219495
INFO:root:current train perplexity4.037991046905518
INFO:root:current mean train loss 3540.821852823615
INFO:root:current train perplexity4.037583827972412
INFO:root:current mean train loss 3544.540693629663
INFO:root:current train perplexity4.042750835418701
INFO:root:current mean train loss 3541.7767088794812
INFO:root:current train perplexity4.041996002197266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it]
INFO:root:final mean train loss: 3539.4403583157446
INFO:root:final train perplexity: 4.040674686431885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4035.732917082225
INFO:root:eval perplexity: 5.113743782043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [4:29:01<6:48:19, 204.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3490.622251852965
INFO:root:current train perplexity4.023323059082031
INFO:root:current mean train loss 3510.7771821605215
INFO:root:current train perplexity4.000129222869873
INFO:root:current mean train loss 3514.1176144907167
INFO:root:current train perplexity4.001401901245117
INFO:root:current mean train loss 3519.3718412956305
INFO:root:current train perplexity4.0014567375183105
INFO:root:current mean train loss 3522.350991355531
INFO:root:current train perplexity4.013705253601074
INFO:root:current mean train loss 3522.7967354910716
INFO:root:current train perplexity4.0160231590271
INFO:root:current mean train loss 3529.618198066437
INFO:root:current train perplexity4.022336006164551
INFO:root:current mean train loss 3531.772273289496
INFO:root:current train perplexity4.026884078979492
INFO:root:current mean train loss 3533.0658245609543
INFO:root:current train perplexity4.0280561447143555
INFO:root:current mean train loss 3533.178774637663
INFO:root:current train perplexity4.027866363525391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.86s/it]
INFO:root:final mean train loss: 3532.4669881020823
INFO:root:final train perplexity: 4.029573440551758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4034.998493600399
INFO:root:eval perplexity: 5.112225532531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [4:32:14<6:38:08, 200.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3532.740042179189
INFO:root:current train perplexity4.053627014160156
INFO:root:current mean train loss 3539.0148211628402
INFO:root:current train perplexity4.026745796203613
INFO:root:current mean train loss 3522.827321411627
INFO:root:current train perplexity4.010495185852051
INFO:root:current mean train loss 3521.2298911146886
INFO:root:current train perplexity4.007943630218506
INFO:root:current mean train loss 3527.767826635032
INFO:root:current train perplexity4.009610652923584
INFO:root:current mean train loss 3523.11553876971
INFO:root:current train perplexity4.01114559173584
INFO:root:current mean train loss 3525.096402718074
INFO:root:current train perplexity4.013150691986084
INFO:root:current mean train loss 3527.8081463222684
INFO:root:current train perplexity4.01276969909668
INFO:root:current mean train loss 3530.4470563616073
INFO:root:current train perplexity4.016204357147217
INFO:root:current mean train loss 3528.2996520673837
INFO:root:current train perplexity4.019101619720459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.16s/it]
INFO:root:final mean train loss: 3525.5828280295095
INFO:root:final train perplexity: 4.018643379211426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it]
INFO:root:eval mean loss: 4035.785308621454
INFO:root:eval perplexity: 5.1138529777526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [4:35:27<6:30:04, 198.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3524.4952503551135
INFO:root:current train perplexity4.0057291984558105
INFO:root:current mean train loss 3517.566203061996
INFO:root:current train perplexity4.002682685852051
INFO:root:current mean train loss 3511.400856885723
INFO:root:current train perplexity3.996858835220337
INFO:root:current mean train loss 3515.263409165933
INFO:root:current train perplexity4.004218578338623
INFO:root:current mean train loss 3512.6944427154876
INFO:root:current train perplexity4.007961750030518
INFO:root:current mean train loss 3516.90980785473
INFO:root:current train perplexity4.010530948638916
INFO:root:current mean train loss 3518.3320319954673
INFO:root:current train perplexity4.010433673858643
INFO:root:current mean train loss 3520.64953661786
INFO:root:current train perplexity4.010290145874023
INFO:root:current mean train loss 3522.2000185603983
INFO:root:current train perplexity4.010310173034668
INFO:root:current mean train loss 3524.8476928071827
INFO:root:current train perplexity4.0120015144348145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it]
INFO:root:final mean train loss: 3520.259950883927
INFO:root:final train perplexity: 4.010212421417236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4037.190043564384
INFO:root:eval perplexity: 5.116758823394775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [4:38:39<6:22:57, 196.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3508.7501588851687
INFO:root:current train perplexity3.959872245788574
INFO:root:current mean train loss 3507.486435966258
INFO:root:current train perplexity3.9764788150787354
INFO:root:current mean train loss 3500.2839652521984
INFO:root:current train perplexity3.985553741455078
INFO:root:current mean train loss 3502.158654415246
INFO:root:current train perplexity3.989898204803467
INFO:root:current mean train loss 3505.803634478773
INFO:root:current train perplexity3.988734483718872
INFO:root:current mean train loss 3507.8892902489456
INFO:root:current train perplexity3.9918978214263916
INFO:root:current mean train loss 3512.7640426888906
INFO:root:current train perplexity3.9965720176696777
INFO:root:current mean train loss 3515.5779861310207
INFO:root:current train perplexity3.9995627403259277
INFO:root:current mean train loss 3515.6401669887928
INFO:root:current train perplexity3.9990997314453125
INFO:root:current mean train loss 3516.227753034138
INFO:root:current train perplexity4.000294208526611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.06s/it]
INFO:root:final mean train loss: 3514.104644344699
INFO:root:final train perplexity: 4.000486373901367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4037.98402350676
INFO:root:eval perplexity: 5.118401527404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [4:41:50<6:16:54, 194.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.172352965449
INFO:root:current train perplexity3.9640262126922607
INFO:root:current mean train loss 3492.4255014163014
INFO:root:current train perplexity3.9673399925231934
INFO:root:current mean train loss 3490.016232198455
INFO:root:current train perplexity3.968362808227539
INFO:root:current mean train loss 3494.219079030492
INFO:root:current train perplexity3.976618766784668
INFO:root:current mean train loss 3497.996824616839
INFO:root:current train perplexity3.97814679145813
INFO:root:current mean train loss 3504.028359221076
INFO:root:current train perplexity3.982821226119995
INFO:root:current mean train loss 3508.2450560613825
INFO:root:current train perplexity3.9871304035186768
INFO:root:current mean train loss 3511.313307785648
INFO:root:current train perplexity3.9877631664276123
INFO:root:current mean train loss 3512.100400099114
INFO:root:current train perplexity3.9904818534851074
INFO:root:current mean train loss 3510.614557771064
INFO:root:current train perplexity3.9907443523406982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.61s/it]
INFO:root:final mean train loss: 3507.877594363305
INFO:root:final train perplexity: 3.9906702041625977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 4038.673620345745
INFO:root:eval perplexity: 5.1198296546936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [4:45:38<6:32:19, 204.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3456.2412047567245
INFO:root:current train perplexity3.9715027809143066
INFO:root:current mean train loss 3484.6015679556563
INFO:root:current train perplexity3.971376895904541
INFO:root:current mean train loss 3497.3670789930557
INFO:root:current train perplexity3.9732065200805664
INFO:root:current mean train loss 3501.191841709268
INFO:root:current train perplexity3.9717166423797607
INFO:root:current mean train loss 3501.4159840243346
INFO:root:current train perplexity3.973785877227783
INFO:root:current mean train loss 3500.309943902472
INFO:root:current train perplexity3.975926637649536
INFO:root:current mean train loss 3498.6106003773934
INFO:root:current train perplexity3.9762721061706543
INFO:root:current mean train loss 3501.555102445042
INFO:root:current train perplexity3.9780004024505615
INFO:root:current mean train loss 3503.239596109748
INFO:root:current train perplexity3.978339910507202
INFO:root:current mean train loss 3504.0767731242818
INFO:root:current train perplexity3.9790053367614746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.43s/it]
INFO:root:final mean train loss: 3500.795721238659
INFO:root:final train perplexity: 3.9795360565185547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4040.2523756094856
INFO:root:eval perplexity: 5.123098373413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [4:49:39<6:49:56, 215.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3463.910543507543
INFO:root:current train perplexity3.940235137939453
INFO:root:current mean train loss 3470.810539041611
INFO:root:current train perplexity3.943084478378296
INFO:root:current mean train loss 3474.6990477664963
INFO:root:current train perplexity3.9580297470092773
INFO:root:current mean train loss 3479.8869237776566
INFO:root:current train perplexity3.958650827407837
INFO:root:current mean train loss 3484.1263279846316
INFO:root:current train perplexity3.9597465991973877
INFO:root:current mean train loss 3490.03897183108
INFO:root:current train perplexity3.963230848312378
INFO:root:current mean train loss 3491.585260871543
INFO:root:current train perplexity3.964550256729126
INFO:root:current mean train loss 3495.076799753812
INFO:root:current train perplexity3.969390392303467
INFO:root:current mean train loss 3496.288390906849
INFO:root:current train perplexity3.9697763919830322
INFO:root:current mean train loss 3498.0308918281407
INFO:root:current train perplexity3.970790386199951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it]
INFO:root:final mean train loss: 3495.4237697970484
INFO:root:final train perplexity: 3.9711103439331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4041.60078679078
INFO:root:eval perplexity: 5.125893592834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [4:53:34<6:57:02, 221.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.45869140625
INFO:root:current train perplexity3.9264018535614014
INFO:root:current mean train loss 3494.8444974459135
INFO:root:current train perplexity3.9467642307281494
INFO:root:current mean train loss 3493.4336020259534
INFO:root:current train perplexity3.953360080718994
INFO:root:current mean train loss 3485.9953829608385
INFO:root:current train perplexity3.9508864879608154
INFO:root:current mean train loss 3485.7081242108584
INFO:root:current train perplexity3.950687885284424
INFO:root:current mean train loss 3487.3341160878413
INFO:root:current train perplexity3.9487380981445312
INFO:root:current mean train loss 3486.5512382671986
INFO:root:current train perplexity3.9507875442504883
INFO:root:current mean train loss 3488.7345322327046
INFO:root:current train perplexity3.955941915512085
INFO:root:current mean train loss 3491.0038486928247
INFO:root:current train perplexity3.960019588470459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.46s/it]
INFO:root:final mean train loss: 3488.8220847960442
INFO:root:final train perplexity: 3.9607810974121094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 4042.750884793329
INFO:root:eval perplexity: 5.12827730178833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [4:57:28<7:00:25, 225.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3692.8443196614585
INFO:root:current train perplexity4.074856758117676
INFO:root:current mean train loss 3497.6226131105886
INFO:root:current train perplexity3.954137086868286
INFO:root:current mean train loss 3483.9588785406404
INFO:root:current train perplexity3.9420721530914307
INFO:root:current mean train loss 3477.384863925846
INFO:root:current train perplexity3.933941125869751
INFO:root:current mean train loss 3482.2357023253335
INFO:root:current train perplexity3.94360613822937
INFO:root:current mean train loss 3483.1077849310386
INFO:root:current train perplexity3.9476428031921387
INFO:root:current mean train loss 3483.9474793998756
INFO:root:current train perplexity3.946667432785034
INFO:root:current mean train loss 3481.1711898087437
INFO:root:current train perplexity3.9467051029205322
INFO:root:current mean train loss 3483.6091089688084
INFO:root:current train perplexity3.9473717212677
INFO:root:current mean train loss 3484.3929866482385
INFO:root:current train perplexity3.9517931938171387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it]
INFO:root:final mean train loss: 3483.928093756399
INFO:root:final train perplexity: 3.9531407356262207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]
INFO:root:eval mean loss: 4044.7244379571143
INFO:root:eval perplexity: 5.132371425628662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [5:01:24<7:02:27, 228.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.200617009943
INFO:root:current train perplexity3.875249147415161
INFO:root:current mean train loss 3467.900117891329
INFO:root:current train perplexity3.9279773235321045
INFO:root:current mean train loss 3466.1471392735484
INFO:root:current train perplexity3.9282188415527344
INFO:root:current mean train loss 3465.307599917102
INFO:root:current train perplexity3.930363178253174
INFO:root:current mean train loss 3464.570287551323
INFO:root:current train perplexity3.9253761768341064
INFO:root:current mean train loss 3467.202146526419
INFO:root:current train perplexity3.927623748779297
INFO:root:current mean train loss 3469.1640996605206
INFO:root:current train perplexity3.9336984157562256
INFO:root:current mean train loss 3475.2107167089707
INFO:root:current train perplexity3.9353482723236084
INFO:root:current mean train loss 3475.5753699136867
INFO:root:current train perplexity3.937580108642578
INFO:root:current mean train loss 3478.4363320912803
INFO:root:current train perplexity3.941521406173706


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it]
INFO:root:final mean train loss: 3478.366506576538
INFO:root:final train perplexity: 3.944476366043091
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it]
INFO:root:eval mean loss: 4046.210322819703
INFO:root:eval perplexity: 5.135456562042236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [5:05:17<7:01:25, 229.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3427.8470908717104
INFO:root:current train perplexity3.9585959911346436
INFO:root:current mean train loss 3465.4558905593485
INFO:root:current train perplexity3.9082155227661133
INFO:root:current mean train loss 3480.1843506974174
INFO:root:current train perplexity3.9176504611968994
INFO:root:current mean train loss 3477.0819937487754
INFO:root:current train perplexity3.9243757724761963
INFO:root:current mean train loss 3478.395669213343
INFO:root:current train perplexity3.924544095993042
INFO:root:current mean train loss 3477.3305819296424
INFO:root:current train perplexity3.9266953468322754
INFO:root:current mean train loss 3474.798219153877
INFO:root:current train perplexity3.928736925125122
INFO:root:current mean train loss 3471.950618738591
INFO:root:current train perplexity3.9324848651885986
INFO:root:current mean train loss 3473.147986778846
INFO:root:current train perplexity3.933711528778076
INFO:root:current mean train loss 3477.053426682365
INFO:root:current train perplexity3.9371700286865234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.34s/it]
INFO:root:final mean train loss: 3473.4843655863115
INFO:root:final train perplexity: 3.9368865489959717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 4044.504579801086
INFO:root:eval perplexity: 5.131916046142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [5:09:02<6:55:04, 228.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.323857060185
INFO:root:current train perplexity3.95713472366333
INFO:root:current mean train loss 3458.760301965428
INFO:root:current train perplexity3.9138479232788086
INFO:root:current mean train loss 3459.8934794018446
INFO:root:current train perplexity3.9198670387268066
INFO:root:current mean train loss 3464.472215751625
INFO:root:current train perplexity3.9235570430755615
INFO:root:current mean train loss 3458.8227870682085
INFO:root:current train perplexity3.9209864139556885
INFO:root:current mean train loss 3464.2118538380573
INFO:root:current train perplexity3.924940824508667
INFO:root:current mean train loss 3466.162408418062
INFO:root:current train perplexity3.9236907958984375
INFO:root:current mean train loss 3468.855233676496
INFO:root:current train perplexity3.9262919425964355
INFO:root:current mean train loss 3468.7806185407535
INFO:root:current train perplexity3.927025318145752
INFO:root:current mean train loss 3468.8832249317356
INFO:root:current train perplexity3.92685866355896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.67s/it]
INFO:root:final mean train loss: 3467.0304302092522
INFO:root:final train perplexity: 3.926875114440918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 4048.3724200742463
INFO:root:eval perplexity: 5.139946937561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [5:12:55<6:53:18, 229.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.0677804129464
INFO:root:current train perplexity3.9098896980285645
INFO:root:current mean train loss 3458.1922164351854
INFO:root:current train perplexity3.9092824459075928
INFO:root:current mean train loss 3461.80218479887
INFO:root:current train perplexity3.914529800415039
INFO:root:current mean train loss 3463.483448723181
INFO:root:current train perplexity3.9141921997070312
INFO:root:current mean train loss 3466.128433683549
INFO:root:current train perplexity3.9171924591064453
INFO:root:current mean train loss 3466.87477593823
INFO:root:current train perplexity3.9188246726989746
INFO:root:current mean train loss 3463.3545990711123
INFO:root:current train perplexity3.914581060409546
INFO:root:current mean train loss 3460.846496665072
INFO:root:current train perplexity3.914050579071045
INFO:root:current mean train loss 3462.9381309646333
INFO:root:current train perplexity3.9165689945220947
INFO:root:current mean train loss 3461.7970060787097
INFO:root:current train perplexity3.914823293685913


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it]
INFO:root:final mean train loss: 3461.4274366440313
INFO:root:final train perplexity: 3.918203353881836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 4047.885238322806
INFO:root:eval perplexity: 5.1389360427856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [5:16:47<6:51:06, 230.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.542355559593
INFO:root:current train perplexity3.8863327503204346
INFO:root:current mean train loss 3455.1927345115823
INFO:root:current train perplexity3.8842694759368896
INFO:root:current mean train loss 3448.4004378456148
INFO:root:current train perplexity3.898327589035034
INFO:root:current mean train loss 3450.6670178115887
INFO:root:current train perplexity3.9006106853485107
INFO:root:current mean train loss 3449.935425080241
INFO:root:current train perplexity3.900724411010742
INFO:root:current mean train loss 3450.6875287753223
INFO:root:current train perplexity3.9016661643981934
INFO:root:current mean train loss 3452.5588576345012
INFO:root:current train perplexity3.9059510231018066
INFO:root:current mean train loss 3457.8333124132528
INFO:root:current train perplexity3.908074378967285
INFO:root:current mean train loss 3458.1131810451884
INFO:root:current train perplexity3.9089300632476807
INFO:root:current mean train loss 3458.9620090779927
INFO:root:current train perplexity3.9101786613464355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.60s/it]
INFO:root:final mean train loss: 3456.5999736170616
INFO:root:final train perplexity: 3.9107489585876465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it]
INFO:root:eval mean loss: 4050.1487543633643
INFO:root:eval perplexity: 5.143641948699951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [5:20:06<6:30:29, 221.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3436.007745481005
INFO:root:current train perplexity3.8997044563293457
INFO:root:current mean train loss 3448.055976109789
INFO:root:current train perplexity3.890068769454956
INFO:root:current mean train loss 3450.905673205615
INFO:root:current train perplexity3.8956871032714844
INFO:root:current mean train loss 3451.229867092904
INFO:root:current train perplexity3.8874359130859375
INFO:root:current mean train loss 3450.2965967554737
INFO:root:current train perplexity3.890946626663208
INFO:root:current mean train loss 3452.6359907589895
INFO:root:current train perplexity3.8967363834381104
INFO:root:current mean train loss 3452.04928265409
INFO:root:current train perplexity3.8994505405426025
INFO:root:current mean train loss 3452.2688670964753
INFO:root:current train perplexity3.8985443115234375
INFO:root:current mean train loss 3452.6884501689187
INFO:root:current train perplexity3.9007956981658936
INFO:root:current mean train loss 3454.186243099369
INFO:root:current train perplexity3.904085636138916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.12s/it]
INFO:root:final mean train loss: 3450.642568403675
INFO:root:final train perplexity: 3.901567220687866
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4051.2949668938386
INFO:root:eval perplexity: 5.146026611328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [5:23:51<6:28:55, 222.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.7787051443324
INFO:root:current train perplexity3.84775710105896
INFO:root:current mean train loss 3425.0179850260415
INFO:root:current train perplexity3.8503289222717285
INFO:root:current mean train loss 3429.1578279590976
INFO:root:current train perplexity3.8600258827209473
INFO:root:current mean train loss 3438.5922212308496
INFO:root:current train perplexity3.871814250946045
INFO:root:current mean train loss 3440.2907151033155
INFO:root:current train perplexity3.8763132095336914
INFO:root:current mean train loss 3443.42378532396
INFO:root:current train perplexity3.87853741645813
INFO:root:current mean train loss 3443.1001498927117
INFO:root:current train perplexity3.8815741539001465
INFO:root:current mean train loss 3446.1914406677165
INFO:root:current train perplexity3.885862112045288
INFO:root:current mean train loss 3448.5051840803258
INFO:root:current train perplexity3.8897154331207275
INFO:root:current mean train loss 3449.084011614882
INFO:root:current train perplexity3.8918492794036865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.52s/it]
INFO:root:final mean train loss: 3444.647732826971
INFO:root:final train perplexity: 3.892350912094116
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.62s/it]
INFO:root:eval mean loss: 4051.9109613946143
INFO:root:eval perplexity: 5.147307872772217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [5:27:45<6:31:28, 225.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3443.607651440065
INFO:root:current train perplexity3.908620834350586
INFO:root:current mean train loss 3443.182516315026
INFO:root:current train perplexity3.8879754543304443
INFO:root:current mean train loss 3448.641222092989
INFO:root:current train perplexity3.8894333839416504
INFO:root:current mean train loss 3446.7540832020604
INFO:root:current train perplexity3.8845953941345215
INFO:root:current mean train loss 3443.9034473492707
INFO:root:current train perplexity3.8833980560302734
INFO:root:current mean train loss 3441.5803928812556
INFO:root:current train perplexity3.8833911418914795
INFO:root:current mean train loss 3442.7329226011993
INFO:root:current train perplexity3.8835995197296143
INFO:root:current mean train loss 3440.9819199065964
INFO:root:current train perplexity3.8860292434692383
INFO:root:current mean train loss 3444.2530490826844
INFO:root:current train perplexity3.887557029724121
INFO:root:current mean train loss 3443.731570286243
INFO:root:current train perplexity3.887596368789673


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.95s/it]
INFO:root:final mean train loss: 3441.346068413027
INFO:root:final train perplexity: 3.8872835636138916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4053.184217087766
INFO:root:eval perplexity: 5.14995813369751
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [5:31:51<6:37:55, 231.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3420.5056315104166
INFO:root:current train perplexity3.8760364055633545
INFO:root:current mean train loss 3425.1911746651786
INFO:root:current train perplexity3.8691422939300537
INFO:root:current mean train loss 3436.1354767400567
INFO:root:current train perplexity3.8667421340942383
INFO:root:current mean train loss 3437.8397805989584
INFO:root:current train perplexity3.8649117946624756
INFO:root:current mean train loss 3436.3760202508224
INFO:root:current train perplexity3.869629383087158
INFO:root:current mean train loss 3432.5136706012227
INFO:root:current train perplexity3.871485948562622
INFO:root:current mean train loss 3437.6169328703704
INFO:root:current train perplexity3.874263048171997
INFO:root:current mean train loss 3436.7040672253024
INFO:root:current train perplexity3.874919891357422
INFO:root:current mean train loss 3437.688273716518
INFO:root:current train perplexity3.8754372596740723
INFO:root:current mean train loss 3436.8298475060096
INFO:root:current train perplexity3.8775148391723633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.17s/it]
INFO:root:final mean train loss: 3435.1563976041734
INFO:root:final train perplexity: 3.8778023719787598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4054.3039516151375
INFO:root:eval perplexity: 5.152291774749756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [5:35:56<6:40:59, 235.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.7160056240587
INFO:root:current train perplexity3.8497393131256104
INFO:root:current mean train loss 3416.209033736766
INFO:root:current train perplexity3.8573033809661865
INFO:root:current mean train loss 3429.8628568076415
INFO:root:current train perplexity3.8582427501678467
INFO:root:current mean train loss 3430.2699519623043
INFO:root:current train perplexity3.8554060459136963
INFO:root:current mean train loss 3431.063063595853
INFO:root:current train perplexity3.8596715927124023
INFO:root:current mean train loss 3430.28221693088
INFO:root:current train perplexity3.8609261512756348
INFO:root:current mean train loss 3432.6323528150165
INFO:root:current train perplexity3.8658194541931152
INFO:root:current mean train loss 3430.505436260277
INFO:root:current train perplexity3.865600109100342
INFO:root:current mean train loss 3432.25813875814
INFO:root:current train perplexity3.867135763168335
INFO:root:current mean train loss 3433.028609655153
INFO:root:current train perplexity3.8700098991394043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:07<00:00, 187.56s/it]
INFO:root:final mean train loss: 3430.3515800968294
INFO:root:final train perplexity: 3.8704588413238525
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 4057.279582571476
INFO:root:eval perplexity: 5.158493995666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [5:40:11<6:46:23, 241.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.3398705786403
INFO:root:current train perplexity3.813728094100952
INFO:root:current mean train loss 3409.6445670402486
INFO:root:current train perplexity3.826183795928955
INFO:root:current mean train loss 3416.221966615657
INFO:root:current train perplexity3.841487407684326
INFO:root:current mean train loss 3421.579041620045
INFO:root:current train perplexity3.8492372035980225
INFO:root:current mean train loss 3422.322872247327
INFO:root:current train perplexity3.8513309955596924
INFO:root:current mean train loss 3422.6769432932792
INFO:root:current train perplexity3.851213216781616
INFO:root:current mean train loss 3424.1141878561416
INFO:root:current train perplexity3.8537583351135254
INFO:root:current mean train loss 3425.2492941218593
INFO:root:current train perplexity3.8564765453338623
INFO:root:current mean train loss 3423.8712595244983
INFO:root:current train perplexity3.857603073120117
INFO:root:current mean train loss 3428.0272464386508
INFO:root:current train perplexity3.8628487586975098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.68s/it]
INFO:root:final mean train loss: 3425.3250032855617
INFO:root:final train perplexity: 3.862790584564209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.96s/it]
INFO:root:eval mean loss: 4056.0320014683066
INFO:root:eval perplexity: 5.155892848968506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [5:44:06<6:39:12, 239.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.6468986742425
INFO:root:current train perplexity3.813026189804077
INFO:root:current mean train loss 3402.2563231195036
INFO:root:current train perplexity3.835995674133301
INFO:root:current mean train loss 3407.823447951505
INFO:root:current train perplexity3.8411715030670166
INFO:root:current mean train loss 3406.4678664434523
INFO:root:current train perplexity3.8389997482299805
INFO:root:current mean train loss 3411.155156504415
INFO:root:current train perplexity3.840294122695923
INFO:root:current mean train loss 3413.62839432909
INFO:root:current train perplexity3.8442296981811523
INFO:root:current mean train loss 3419.4032298512384
INFO:root:current train perplexity3.849534034729004
INFO:root:current mean train loss 3423.5837512344533
INFO:root:current train perplexity3.8532097339630127
INFO:root:current mean train loss 3423.104354230395
INFO:root:current train perplexity3.85442852973938


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.08s/it]
INFO:root:final mean train loss: 3420.2852818889
INFO:root:final train perplexity: 3.855117082595825
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 4060.0995972545434
INFO:root:eval perplexity: 5.1643805503845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [5:48:02<6:33:36, 238.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.9726911272323
INFO:root:current train perplexity3.773852586746216
INFO:root:current mean train loss 3432.920962324766
INFO:root:current train perplexity3.840045213699341
INFO:root:current mean train loss 3420.4778987866093
INFO:root:current train perplexity3.833711624145508
INFO:root:current mean train loss 3412.387453557614
INFO:root:current train perplexity3.8395321369171143
INFO:root:current mean train loss 3418.0435836004685
INFO:root:current train perplexity3.8425233364105225
INFO:root:current mean train loss 3417.756875423755
INFO:root:current train perplexity3.84525990486145
INFO:root:current mean train loss 3416.3172673786294
INFO:root:current train perplexity3.8423402309417725
INFO:root:current mean train loss 3415.574741563163
INFO:root:current train perplexity3.8433644771575928
INFO:root:current mean train loss 3417.225203238751
INFO:root:current train perplexity3.846128225326538
INFO:root:current mean train loss 3416.520993132838
INFO:root:current train perplexity3.8471150398254395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.73s/it]
INFO:root:final mean train loss: 3415.588049980902
INFO:root:final train perplexity: 3.8479793071746826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4062.159725108045
INFO:root:eval perplexity: 5.1686835289001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [5:51:58<6:28:27, 237.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3378.6746419270835
INFO:root:current train perplexity3.76873517036438
INFO:root:current mean train loss 3388.857655400815
INFO:root:current train perplexity3.7900893688201904
INFO:root:current mean train loss 3391.83788040516
INFO:root:current train perplexity3.8065578937530518
INFO:root:current mean train loss 3406.5493799603173
INFO:root:current train perplexity3.8208937644958496
INFO:root:current mean train loss 3411.7072447995106
INFO:root:current train perplexity3.8255457878112793
INFO:root:current mean train loss 3407.7477358919905
INFO:root:current train perplexity3.8237171173095703
INFO:root:current mean train loss 3409.4972640370934
INFO:root:current train perplexity3.8271021842956543
INFO:root:current mean train loss 3408.105495042067
INFO:root:current train perplexity3.830078363418579
INFO:root:current mean train loss 3408.1043720643215
INFO:root:current train perplexity3.8324897289276123
INFO:root:current mean train loss 3409.6286231536033
INFO:root:current train perplexity3.8355906009674072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.84s/it]
INFO:root:final mean train loss: 3409.117545097105
INFO:root:final train perplexity: 3.8381693363189697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4061.396981313719
INFO:root:eval perplexity: 5.16709041595459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [5:56:01<6:27:01, 239.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.5270253057065
INFO:root:current train perplexity3.7865993976593018
INFO:root:current mean train loss 3392.5365079554117
INFO:root:current train perplexity3.7972846031188965
INFO:root:current mean train loss 3397.3397528815162
INFO:root:current train perplexity3.8097503185272217
INFO:root:current mean train loss 3392.9508801156153
INFO:root:current train perplexity3.8084874153137207
INFO:root:current mean train loss 3392.6229603003103
INFO:root:current train perplexity3.8116681575775146
INFO:root:current mean train loss 3397.308714653292
INFO:root:current train perplexity3.820254325866699
INFO:root:current mean train loss 3400.737887411592
INFO:root:current train perplexity3.8245794773101807
INFO:root:current mean train loss 3403.754678180109
INFO:root:current train perplexity3.8297688961029053
INFO:root:current mean train loss 3404.5608387758202
INFO:root:current train perplexity3.8298604488372803
INFO:root:current mean train loss 3405.1902934660243
INFO:root:current train perplexity3.828472852706909


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it]
INFO:root:final mean train loss: 3404.382838956771
INFO:root:final train perplexity: 3.8310067653656006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it]
INFO:root:eval mean loss: 4062.3321351396276
INFO:root:eval perplexity: 5.169045448303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [6:00:02<6:23:39, 239.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3347.191666141633
INFO:root:current train perplexity3.771613836288452
INFO:root:current mean train loss 3370.7512766131917
INFO:root:current train perplexity3.788655996322632
INFO:root:current mean train loss 3369.241680194805
INFO:root:current train perplexity3.7982430458068848
INFO:root:current mean train loss 3377.966210494949
INFO:root:current train perplexity3.805969476699829
INFO:root:current mean train loss 3380.0733764365214
INFO:root:current train perplexity3.8067829608917236
INFO:root:current mean train loss 3387.3401632937557
INFO:root:current train perplexity3.8129284381866455
INFO:root:current mean train loss 3393.2496765426904
INFO:root:current train perplexity3.816775321960449
INFO:root:current mean train loss 3396.5913723842555
INFO:root:current train perplexity3.8203938007354736
INFO:root:current mean train loss 3402.596102975049
INFO:root:current train perplexity3.826167345046997
INFO:root:current mean train loss 3402.323501537745
INFO:root:current train perplexity3.8242549896240234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.44s/it]
INFO:root:final mean train loss: 3400.914179217431
INFO:root:final train perplexity: 3.8257670402526855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4063.4760136164673
INFO:root:eval perplexity: 5.1714348793029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [6:04:01<6:19:15, 239.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3388.4517603165064
INFO:root:current train perplexity3.8243000507354736
INFO:root:current mean train loss 3401.536399786421
INFO:root:current train perplexity3.8172597885131836
INFO:root:current mean train loss 3393.8214167511114
INFO:root:current train perplexity3.814619302749634
INFO:root:current mean train loss 3403.055528668879
INFO:root:current train perplexity3.816265344619751
INFO:root:current mean train loss 3398.8519434483555
INFO:root:current train perplexity3.812469244003296
INFO:root:current mean train loss 3397.453326563225
INFO:root:current train perplexity3.8119022846221924
INFO:root:current mean train loss 3400.5640171868886
INFO:root:current train perplexity3.81394362449646
INFO:root:current mean train loss 3401.5835354073283
INFO:root:current train perplexity3.815786600112915
INFO:root:current mean train loss 3398.7905811769033
INFO:root:current train perplexity3.8146169185638428
INFO:root:current mean train loss 3398.38732429155
INFO:root:current train perplexity3.8163626194000244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it]
INFO:root:final mean train loss: 3395.2948864967593
INFO:root:final train perplexity: 3.8172953128814697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4065.81695859652
INFO:root:eval perplexity: 5.176333427429199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [6:07:45<6:07:55, 234.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.8824281083776
INFO:root:current train perplexity3.7703421115875244
INFO:root:current mean train loss 3372.0492250611182
INFO:root:current train perplexity3.7968201637268066
INFO:root:current mean train loss 3372.0830631642207
INFO:root:current train perplexity3.7906858921051025
INFO:root:current mean train loss 3375.579335853071
INFO:root:current train perplexity3.7960216999053955
INFO:root:current mean train loss 3381.1132692341303
INFO:root:current train perplexity3.7944858074188232
INFO:root:current mean train loss 3387.360226591065
INFO:root:current train perplexity3.7992894649505615
INFO:root:current mean train loss 3389.3496455998843
INFO:root:current train perplexity3.8012311458587646
INFO:root:current mean train loss 3389.156595130522
INFO:root:current train perplexity3.80332612991333
INFO:root:current mean train loss 3391.446084987456
INFO:root:current train perplexity3.807401657104492
INFO:root:current mean train loss 3391.8848953005377
INFO:root:current train perplexity3.809103012084961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.27s/it]
INFO:root:final mean train loss: 3390.637095051427
INFO:root:final train perplexity: 3.810286283493042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4067.0124044215427
INFO:root:eval perplexity: 5.178836822509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [6:11:47<6:07:30, 237.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3367.046444424716
INFO:root:current train perplexity3.777859926223755
INFO:root:current mean train loss 3379.6754914314515
INFO:root:current train perplexity3.78682541847229
INFO:root:current mean train loss 3371.0437567018994
INFO:root:current train perplexity3.7857024669647217
INFO:root:current mean train loss 3380.8118528554137
INFO:root:current train perplexity3.7919161319732666
INFO:root:current mean train loss 3384.055165586367
INFO:root:current train perplexity3.7904250621795654
INFO:root:current mean train loss 3382.7358750351914
INFO:root:current train perplexity3.7941668033599854
INFO:root:current mean train loss 3383.4959800661977
INFO:root:current train perplexity3.797593832015991
INFO:root:current mean train loss 3386.396454948779
INFO:root:current train perplexity3.7970852851867676
INFO:root:current mean train loss 3385.397062031707
INFO:root:current train perplexity3.7966132164001465
INFO:root:current mean train loss 3388.6288080824606
INFO:root:current train perplexity3.8020989894866943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it]
INFO:root:final mean train loss: 3385.421616769606
INFO:root:final train perplexity: 3.8024539947509766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4067.2870972545434
INFO:root:eval perplexity: 5.179410934448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [6:15:44<6:03:33, 237.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3333.6476857018847
INFO:root:current train perplexity3.7816367149353027
INFO:root:current mean train loss 3354.7592024539877
INFO:root:current train perplexity3.789250373840332
INFO:root:current mean train loss 3362.7163438688212
INFO:root:current train perplexity3.785050392150879
INFO:root:current mean train loss 3371.5058829147297
INFO:root:current train perplexity3.792607307434082
INFO:root:current mean train loss 3375.4488870773152
INFO:root:current train perplexity3.786957263946533
INFO:root:current mean train loss 3379.395278849356
INFO:root:current train perplexity3.7908756732940674
INFO:root:current mean train loss 3381.193449224642
INFO:root:current train perplexity3.7905173301696777
INFO:root:current mean train loss 3380.918941792779
INFO:root:current train perplexity3.7897043228149414
INFO:root:current mean train loss 3381.057005562898
INFO:root:current train perplexity3.792205810546875
INFO:root:current mean train loss 3383.367056429696
INFO:root:current train perplexity3.795949935913086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.76s/it]
INFO:root:final mean train loss: 3381.2581298582018
INFO:root:final train perplexity: 3.7962141036987305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4070.0939560477614
INFO:root:eval perplexity: 5.185294151306152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [6:19:44<6:00:45, 237.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.3456309143926
INFO:root:current train perplexity3.7568488121032715
INFO:root:current mean train loss 3355.888916015625
INFO:root:current train perplexity3.769993305206299
INFO:root:current mean train loss 3358.856941701741
INFO:root:current train perplexity3.7728846073150635
INFO:root:current mean train loss 3364.6329908345265
INFO:root:current train perplexity3.7705113887786865
INFO:root:current mean train loss 3367.9607804413813
INFO:root:current train perplexity3.7779972553253174
INFO:root:current mean train loss 3372.3326106029717
INFO:root:current train perplexity3.7850255966186523
INFO:root:current mean train loss 3374.4698022424554
INFO:root:current train perplexity3.7873988151550293
INFO:root:current mean train loss 3376.7875162760415
INFO:root:current train perplexity3.7888944149017334
INFO:root:current mean train loss 3377.2834439020344
INFO:root:current train perplexity3.78863787651062
INFO:root:current mean train loss 3379.5758218814367
INFO:root:current train perplexity3.7914087772369385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.14s/it]
INFO:root:final mean train loss: 3377.75517512906
INFO:root:final train perplexity: 3.79097056388855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it]
INFO:root:eval mean loss: 4072.3299638464096
INFO:root:eval perplexity: 5.189984321594238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [6:23:39<5:55:32, 237.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.5844881081885
INFO:root:current train perplexity3.756134510040283
INFO:root:current mean train loss 3367.2505673882683
INFO:root:current train perplexity3.7595632076263428
INFO:root:current mean train loss 3376.0424830939182
INFO:root:current train perplexity3.775489568710327
INFO:root:current mean train loss 3379.001369506514
INFO:root:current train perplexity3.781745433807373
INFO:root:current mean train loss 3380.392996069285
INFO:root:current train perplexity3.7789742946624756
INFO:root:current mean train loss 3376.8768915627697
INFO:root:current train perplexity3.7758564949035645
INFO:root:current mean train loss 3378.0946679543677
INFO:root:current train perplexity3.7780959606170654
INFO:root:current mean train loss 3375.162414629132
INFO:root:current train perplexity3.7797818183898926
INFO:root:current mean train loss 3375.0693262163145
INFO:root:current train perplexity3.7835135459899902
INFO:root:current mean train loss 3376.941238668284
INFO:root:current train perplexity3.7863664627075195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.79s/it]
INFO:root:final mean train loss: 3374.42261363614
INFO:root:final train perplexity: 3.785989999771118
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.62s/it]
INFO:root:eval mean loss: 4071.1776876246677
INFO:root:eval perplexity: 5.187566757202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [6:27:35<5:51:17, 236.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.000246946839
INFO:root:current train perplexity3.7585763931274414
INFO:root:current mean train loss 3368.6668342141543
INFO:root:current train perplexity3.761336088180542
INFO:root:current mean train loss 3367.4110868766334
INFO:root:current train perplexity3.7669215202331543
INFO:root:current mean train loss 3365.0321735707366
INFO:root:current train perplexity3.7636284828186035
INFO:root:current mean train loss 3364.8233625032085
INFO:root:current train perplexity3.7679452896118164
INFO:root:current mean train loss 3365.661516283805
INFO:root:current train perplexity3.7718935012817383
INFO:root:current mean train loss 3369.936023428971
INFO:root:current train perplexity3.7759969234466553
INFO:root:current mean train loss 3368.223594345616
INFO:root:current train perplexity3.776693820953369
INFO:root:current mean train loss 3370.6279131729143
INFO:root:current train perplexity3.7781333923339844
INFO:root:current mean train loss 3372.0198330246326
INFO:root:current train perplexity3.7782037258148193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.18s/it]
INFO:root:final mean train loss: 3369.159598504343
INFO:root:final train perplexity: 3.7781364917755127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4074.495934452571
INFO:root:eval perplexity: 5.19453239440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [6:31:31<5:46:58, 236.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.359572882401
INFO:root:current train perplexity3.7491796016693115
INFO:root:current mean train loss 3339.198118239183
INFO:root:current train perplexity3.755951404571533
INFO:root:current mean train loss 3347.100947596663
INFO:root:current train perplexity3.756500244140625
INFO:root:current mean train loss 3356.570717340783
INFO:root:current train perplexity3.76448917388916
INFO:root:current mean train loss 3357.108961193971
INFO:root:current train perplexity3.764322280883789
INFO:root:current mean train loss 3356.3153205422796
INFO:root:current train perplexity3.763566732406616
INFO:root:current mean train loss 3360.3754960094425
INFO:root:current train perplexity3.7672677040100098
INFO:root:current mean train loss 3363.6414946933965
INFO:root:current train perplexity3.769774913787842
INFO:root:current mean train loss 3365.0352705460023
INFO:root:current train perplexity3.7716658115386963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.30s/it]
INFO:root:final mean train loss: 3364.753570618168
INFO:root:final train perplexity: 3.7715747356414795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 4074.342716298205
INFO:root:eval perplexity: 5.194209575653076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [6:35:35<5:46:07, 238.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.4283854166665
INFO:root:current train perplexity3.777130603790283
INFO:root:current mean train loss 3338.3215497952065
INFO:root:current train perplexity3.7371792793273926
INFO:root:current mean train loss 3354.6281834494303
INFO:root:current train perplexity3.7550864219665527
INFO:root:current mean train loss 3350.6765418729374
INFO:root:current train perplexity3.751464605331421
INFO:root:current mean train loss 3350.4532401035203
INFO:root:current train perplexity3.7528247833251953
INFO:root:current mean train loss 3356.688979404821
INFO:root:current train perplexity3.7591183185577393
INFO:root:current mean train loss 3358.636373795087
INFO:root:current train perplexity3.7607295513153076
INFO:root:current mean train loss 3359.3458687794496
INFO:root:current train perplexity3.761519193649292
INFO:root:current mean train loss 3363.1991156819154
INFO:root:current train perplexity3.7653918266296387
INFO:root:current mean train loss 3362.483262172965
INFO:root:current train perplexity3.7635343074798584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.55s/it]
INFO:root:final mean train loss: 3360.269054966588
INFO:root:final train perplexity: 3.7649075984954834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 4075.9373961103724
INFO:root:eval perplexity: 5.197560787200928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [6:39:36<5:43:13, 239.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3320.932683771307
INFO:root:current train perplexity3.7404673099517822
INFO:root:current mean train loss 3348.854690139358
INFO:root:current train perplexity3.76596736907959
INFO:root:current mean train loss 3345.5024367779915
INFO:root:current train perplexity3.7601704597473145
INFO:root:current mean train loss 3353.7267838751004
INFO:root:current train perplexity3.758659839630127
INFO:root:current mean train loss 3354.671705705406
INFO:root:current train perplexity3.7575559616088867
INFO:root:current mean train loss 3353.332546286387
INFO:root:current train perplexity3.756866216659546
INFO:root:current mean train loss 3358.826517907375
INFO:root:current train perplexity3.7560946941375732
INFO:root:current mean train loss 3357.971134749143
INFO:root:current train perplexity3.7570152282714844
INFO:root:current mean train loss 3355.547258520538
INFO:root:current train perplexity3.755006790161133
INFO:root:current mean train loss 3357.3029206293736
INFO:root:current train perplexity3.7566521167755127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:04<00:00, 184.47s/it]
INFO:root:final mean train loss: 3356.8547490027645
INFO:root:final train perplexity: 3.7598392963409424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4075.8349003352173
INFO:root:eval perplexity: 5.197345733642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [6:43:47<5:44:08, 242.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.6876670435854
INFO:root:current train perplexity3.7141478061676025
INFO:root:current mean train loss 3319.628243582589
INFO:root:current train perplexity3.731785774230957
INFO:root:current mean train loss 3337.188176682006
INFO:root:current train perplexity3.7377994060516357
INFO:root:current mean train loss 3342.7882589023316
INFO:root:current train perplexity3.7400214672088623
INFO:root:current mean train loss 3343.8442534307874
INFO:root:current train perplexity3.7384402751922607
INFO:root:current mean train loss 3346.063710824603
INFO:root:current train perplexity3.7379865646362305
INFO:root:current mean train loss 3347.949719652413
INFO:root:current train perplexity3.741957187652588
INFO:root:current mean train loss 3352.1179175449843
INFO:root:current train perplexity3.745023488998413
INFO:root:current mean train loss 3353.0871137868207
INFO:root:current train perplexity3.746762275695801
INFO:root:current mean train loss 3351.4280013622993
INFO:root:current train perplexity3.748894453048706


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:05<00:00, 185.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:05<00:00, 185.16s/it]
INFO:root:final mean train loss: 3350.890370153612
INFO:root:final train perplexity: 3.751002550125122
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 4078.539517882868
INFO:root:eval perplexity: 5.20303201675415
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [6:47:50<5:40:06, 242.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.887107566551
INFO:root:current train perplexity3.765742778778076
INFO:root:current mean train loss 3353.6339543860727
INFO:root:current train perplexity3.7395403385162354
INFO:root:current mean train loss 3353.018557914028
INFO:root:current train perplexity3.737790107727051
INFO:root:current mean train loss 3346.8033525659403
INFO:root:current train perplexity3.7365739345550537
INFO:root:current mean train loss 3350.054198646992
INFO:root:current train perplexity3.74114727973938
INFO:root:current mean train loss 3349.5048073003145
INFO:root:current train perplexity3.739964723587036
INFO:root:current mean train loss 3350.3160585345645
INFO:root:current train perplexity3.7408711910247803
INFO:root:current mean train loss 3351.190475358924
INFO:root:current train perplexity3.7439236640930176
INFO:root:current mean train loss 3350.607371688898
INFO:root:current train perplexity3.744062900543213
INFO:root:current mean train loss 3350.8542117023158
INFO:root:current train perplexity3.746933937072754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.12s/it]
INFO:root:final mean train loss: 3347.96543681237
INFO:root:final train perplexity: 3.7466766834259033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4080.154589497451
INFO:root:eval perplexity: 5.206430912017822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [6:51:47<5:33:33, 241.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.1876534598214
INFO:root:current train perplexity3.720783233642578
INFO:root:current mean train loss 3336.739087818287
INFO:root:current train perplexity3.7133989334106445
INFO:root:current mean train loss 3334.975611909907
INFO:root:current train perplexity3.7222232818603516
INFO:root:current mean train loss 3343.167675052472
INFO:root:current train perplexity3.7305338382720947
INFO:root:current mean train loss 3346.700722319504
INFO:root:current train perplexity3.7335798740386963
INFO:root:current mean train loss 3346.23443432389
INFO:root:current train perplexity3.734286308288574
INFO:root:current mean train loss 3346.3548643577756
INFO:root:current train perplexity3.7384278774261475
INFO:root:current mean train loss 3347.5900682929423
INFO:root:current train perplexity3.7382848262786865
INFO:root:current mean train loss 3346.8645525355537
INFO:root:current train perplexity3.739010810852051
INFO:root:current mean train loss 3347.0231168532755
INFO:root:current train perplexity3.74131178855896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.01s/it]
INFO:root:final mean train loss: 3343.701330615628
INFO:root:final train perplexity: 3.7403793334960938
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 4082.523494639295
INFO:root:eval perplexity: 5.211421489715576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [6:55:42<5:27:03, 239.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3334.859874636628
INFO:root:current train perplexity3.717789649963379
INFO:root:current mean train loss 3327.6166582440997
INFO:root:current train perplexity3.7108817100524902
INFO:root:current mean train loss 3327.984621150013
INFO:root:current train perplexity3.717268943786621
INFO:root:current mean train loss 3332.6590003188776
INFO:root:current train perplexity3.720475912094116
INFO:root:current mean train loss 3339.8996422210075
INFO:root:current train perplexity3.7239696979522705
INFO:root:current mean train loss 3339.7187571938307
INFO:root:current train perplexity3.7241883277893066
INFO:root:current mean train loss 3341.0314690810897
INFO:root:current train perplexity3.7276034355163574
INFO:root:current mean train loss 3342.106007305161
INFO:root:current train perplexity3.730308771133423
INFO:root:current mean train loss 3340.7244358990397
INFO:root:current train perplexity3.7339930534362793
INFO:root:current mean train loss 3341.472890034713
INFO:root:current train perplexity3.733633279800415


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.33s/it]
INFO:root:final mean train loss: 3339.371888929798
INFO:root:final train perplexity: 3.7339956760406494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4083.0145341589096
INFO:root:eval perplexity: 5.212456703186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [6:59:12<5:10:55, 230.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.2238913143383
INFO:root:current train perplexity3.729372262954712
INFO:root:current mean train loss 3328.50275992084
INFO:root:current train perplexity3.715378522872925
INFO:root:current mean train loss 3327.1487516729953
INFO:root:current train perplexity3.7208139896392822
INFO:root:current mean train loss 3322.4716108273237
INFO:root:current train perplexity3.720144271850586
INFO:root:current mean train loss 3324.5637142071437
INFO:root:current train perplexity3.720459461212158
INFO:root:current mean train loss 3328.301672296818
INFO:root:current train perplexity3.720676898956299
INFO:root:current mean train loss 3332.4808842765938
INFO:root:current train perplexity3.7235708236694336
INFO:root:current mean train loss 3336.622485449089
INFO:root:current train perplexity3.7272229194641113
INFO:root:current mean train loss 3335.3819598725763
INFO:root:current train perplexity3.7266526222229004
INFO:root:current mean train loss 3336.9215733541173
INFO:root:current train perplexity3.727160930633545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it]
INFO:root:final mean train loss: 3334.826127144598
INFO:root:final train perplexity: 3.727304220199585
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4085.8685865469856
INFO:root:eval perplexity: 5.218475818634033
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [7:03:07<5:09:13, 231.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3316.657470703125
INFO:root:current train perplexity3.69362211227417
INFO:root:current mean train loss 3312.0568463787345
INFO:root:current train perplexity3.693579912185669
INFO:root:current mean train loss 3314.898832461088
INFO:root:current train perplexity3.6934316158294678
INFO:root:current mean train loss 3323.203257611203
INFO:root:current train perplexity3.70694637298584
INFO:root:current mean train loss 3325.783295675041
INFO:root:current train perplexity3.712066650390625
INFO:root:current mean train loss 3323.7094359696443
INFO:root:current train perplexity3.714595079421997
INFO:root:current mean train loss 3329.695431421306
INFO:root:current train perplexity3.719210386276245
INFO:root:current mean train loss 3332.204543202919
INFO:root:current train perplexity3.721865177154541
INFO:root:current mean train loss 3333.9224226821702
INFO:root:current train perplexity3.7223525047302246
INFO:root:current mean train loss 3333.8687977079803
INFO:root:current train perplexity3.722437620162964


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.82s/it]
INFO:root:final mean train loss: 3332.000982776765
INFO:root:final train perplexity: 3.7231526374816895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4085.491018741689
INFO:root:eval perplexity: 5.217679023742676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [7:07:02<5:06:16, 232.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.433047166511
INFO:root:current train perplexity3.7203264236450195
INFO:root:current mean train loss 3325.83593165232
INFO:root:current train perplexity3.7128145694732666
INFO:root:current mean train loss 3318.1105207236074
INFO:root:current train perplexity3.700739622116089
INFO:root:current mean train loss 3317.711565480245
INFO:root:current train perplexity3.7035837173461914
INFO:root:current mean train loss 3321.9749878713865
INFO:root:current train perplexity3.7033028602600098
INFO:root:current mean train loss 3322.611691106564
INFO:root:current train perplexity3.705638885498047
INFO:root:current mean train loss 3326.402000781836
INFO:root:current train perplexity3.7088584899902344
INFO:root:current mean train loss 3326.3631020437783
INFO:root:current train perplexity3.7100749015808105
INFO:root:current mean train loss 3327.9218361402463
INFO:root:current train perplexity3.711306571960449
INFO:root:current mean train loss 3330.6311686534546
INFO:root:current train perplexity3.7162981033325195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.57s/it]
INFO:root:final mean train loss: 3328.433227416008
INFO:root:final train perplexity: 3.7179155349731445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4085.5616359845967
INFO:root:eval perplexity: 5.217827320098877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [7:11:02<5:05:30, 235.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3325.8667415364584
INFO:root:current train perplexity3.7063064575195312
INFO:root:current mean train loss 3310.7897628348214
INFO:root:current train perplexity3.7088119983673096
INFO:root:current mean train loss 3319.833957741477
INFO:root:current train perplexity3.711559534072876
INFO:root:current mean train loss 3321.60713671875
INFO:root:current train perplexity3.709510326385498
INFO:root:current mean train loss 3326.585983758224
INFO:root:current train perplexity3.713970422744751
INFO:root:current mean train loss 3326.9210899286686
INFO:root:current train perplexity3.710825204849243
INFO:root:current mean train loss 3328.9872898582175
INFO:root:current train perplexity3.7132322788238525
INFO:root:current mean train loss 3328.950394405242
INFO:root:current train perplexity3.7131500244140625
INFO:root:current mean train loss 3328.1462963169643
INFO:root:current train perplexity3.7132599353790283
INFO:root:current mean train loss 3328.0547283153046
INFO:root:current train perplexity3.713765859603882


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.27s/it]
INFO:root:final mean train loss: 3326.008718552128
INFO:root:final train perplexity: 3.7143616676330566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.51s/it]
INFO:root:eval mean loss: 4087.0546736480496
INFO:root:eval perplexity: 5.220979690551758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [7:14:56<5:01:02, 234.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.1148108057228
INFO:root:current train perplexity3.6938788890838623
INFO:root:current mean train loss 3294.292184298156
INFO:root:current train perplexity3.688534736633301
INFO:root:current mean train loss 3301.465382067138
INFO:root:current train perplexity3.688838243484497
INFO:root:current mean train loss 3311.076909396418
INFO:root:current train perplexity3.6977405548095703
INFO:root:current mean train loss 3314.984211228649
INFO:root:current train perplexity3.704555034637451
INFO:root:current mean train loss 3323.402174149737
INFO:root:current train perplexity3.7056941986083984
INFO:root:current mean train loss 3325.4276957700404
INFO:root:current train perplexity3.7068114280700684
INFO:root:current mean train loss 3323.9477935050486
INFO:root:current train perplexity3.704329013824463
INFO:root:current mean train loss 3324.1563395827434
INFO:root:current train perplexity3.706533193588257
INFO:root:current mean train loss 3324.067128240638
INFO:root:current train perplexity3.7075583934783936


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:01<00:00, 181.72s/it]
INFO:root:final mean train loss: 3321.3183430702456
INFO:root:final train perplexity: 3.7074942588806152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.61s/it]
INFO:root:eval mean loss: 4090.067711796321
INFO:root:eval perplexity: 5.227344512939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [7:18:59<5:00:23, 237.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.3402891054257
INFO:root:current train perplexity3.647860050201416
INFO:root:current mean train loss 3312.2390558532397
INFO:root:current train perplexity3.6849894523620605
INFO:root:current mean train loss 3315.3767870086986
INFO:root:current train perplexity3.6887757778167725
INFO:root:current mean train loss 3316.256001738331
INFO:root:current train perplexity3.6876418590545654
INFO:root:current mean train loss 3315.3231327965887
INFO:root:current train perplexity3.6889913082122803
INFO:root:current mean train loss 3317.702622260337
INFO:root:current train perplexity3.694549083709717
INFO:root:current mean train loss 3319.1613907324077
INFO:root:current train perplexity3.6960270404815674
INFO:root:current mean train loss 3321.8074532953738
INFO:root:current train perplexity3.6971683502197266
INFO:root:current mean train loss 3320.531593331317
INFO:root:current train perplexity3.7005443572998047
INFO:root:current mean train loss 3319.5210687693143
INFO:root:current train perplexity3.70100474357605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:08<00:00, 188.33s/it]
INFO:root:final mean train loss: 3316.8415721154984
INFO:root:final train perplexity: 3.7009518146514893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4087.7948924396055
INFO:root:eval perplexity: 5.222541809082031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [7:23:02<4:58:31, 238.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3319.5450254498105
INFO:root:current train perplexity3.693847179412842
INFO:root:current mean train loss 3309.5779262523556
INFO:root:current train perplexity3.694244384765625
INFO:root:current mean train loss 3314.816483819764
INFO:root:current train perplexity3.6982691287994385
INFO:root:current mean train loss 3314.254218921327
INFO:root:current train perplexity3.696748971939087
INFO:root:current mean train loss 3313.5951292232903
INFO:root:current train perplexity3.693895101547241
INFO:root:current mean train loss 3315.271093913032
INFO:root:current train perplexity3.6933202743530273
INFO:root:current mean train loss 3314.0163406568536
INFO:root:current train perplexity3.6937525272369385
INFO:root:current mean train loss 3317.3247580593907
INFO:root:current train perplexity3.6964492797851562
INFO:root:current mean train loss 3318.612249830541
INFO:root:current train perplexity3.699686288833618


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it]
INFO:root:final mean train loss: 3315.554744535877
INFO:root:final train perplexity: 3.69907283782959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 4092.554576684397
INFO:root:eval perplexity: 5.232603073120117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [7:26:50<4:50:39, 235.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.0209612165177
INFO:root:current train perplexity3.761211633682251
INFO:root:current mean train loss 3301.4554295049647
INFO:root:current train perplexity3.6784393787384033
INFO:root:current mean train loss 3304.54931286798
INFO:root:current train perplexity3.677213430404663
INFO:root:current mean train loss 3304.755588991246
INFO:root:current train perplexity3.6793291568756104
INFO:root:current mean train loss 3299.037966566531
INFO:root:current train perplexity3.680933952331543
INFO:root:current mean train loss 3303.929275302022
INFO:root:current train perplexity3.6846609115600586
INFO:root:current mean train loss 3305.9032004543346
INFO:root:current train perplexity3.6839234828948975
INFO:root:current mean train loss 3309.8565982888745
INFO:root:current train perplexity3.688051223754883
INFO:root:current mean train loss 3310.840351998141
INFO:root:current train perplexity3.6887550354003906
INFO:root:current mean train loss 3311.5148645840513
INFO:root:current train perplexity3.6882436275482178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it]
INFO:root:final mean train loss: 3309.459897933468
INFO:root:final train perplexity: 3.6901888847351074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4093.4510472074467
INFO:root:eval perplexity: 5.234500885009766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [7:30:47<4:47:04, 235.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.63935546875
INFO:root:current train perplexity3.712132215499878
INFO:root:current mean train loss 3287.5757218070653
INFO:root:current train perplexity3.6912105083465576
INFO:root:current mean train loss 3294.772803869913
INFO:root:current train perplexity3.6904489994049072
INFO:root:current mean train loss 3301.9046278211804
INFO:root:current train perplexity3.6856465339660645
INFO:root:current mean train loss 3303.851400720068
INFO:root:current train perplexity3.683339834213257
INFO:root:current mean train loss 3302.2110185641686
INFO:root:current train perplexity3.6828019618988037
INFO:root:current mean train loss 3304.030573551829
INFO:root:current train perplexity3.681403398513794
INFO:root:current mean train loss 3305.5009997814686
INFO:root:current train perplexity3.683030605316162
INFO:root:current mean train loss 3305.660094241277
INFO:root:current train perplexity3.682586908340454
INFO:root:current mean train loss 3307.3877612171277
INFO:root:current train perplexity3.6848509311676025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.58s/it]
INFO:root:final mean train loss: 3306.6544164842176
INFO:root:final train perplexity: 3.6861066818237305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4093.470857227948
INFO:root:eval perplexity: 5.234542369842529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [7:34:40<4:42:12, 235.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.88428795856
INFO:root:current train perplexity3.6630966663360596
INFO:root:current mean train loss 3305.3680489392787
INFO:root:current train perplexity3.673736810684204
INFO:root:current mean train loss 3306.0552480381166
INFO:root:current train perplexity3.677340507507324
INFO:root:current mean train loss 3306.6226938914956
INFO:root:current train perplexity3.684685468673706
INFO:root:current mean train loss 3304.9667518561614
INFO:root:current train perplexity3.6793222427368164
INFO:root:current mean train loss 3302.933878969736
INFO:root:current train perplexity3.6802096366882324
INFO:root:current mean train loss 3304.4838737867426
INFO:root:current train perplexity3.681727886199951
INFO:root:current mean train loss 3306.010196838801
INFO:root:current train perplexity3.6831343173980713
INFO:root:current mean train loss 3304.5311082026506
INFO:root:current train perplexity3.681464910507202
INFO:root:current mean train loss 3304.9484421553357
INFO:root:current train perplexity3.6806321144104004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.94s/it]
INFO:root:final mean train loss: 3303.9277877192344
INFO:root:final train perplexity: 3.6821439266204834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it]
INFO:root:eval mean loss: 4095.0694831144724
INFO:root:eval perplexity: 5.237926483154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [7:38:35<4:38:26, 235.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.561263545867
INFO:root:current train perplexity3.640122175216675
INFO:root:current mean train loss 3289.9974952290077
INFO:root:current train perplexity3.661083221435547
INFO:root:current mean train loss 3302.599382144548
INFO:root:current train perplexity3.67329740524292
INFO:root:current mean train loss 3302.4917375731684
INFO:root:current train perplexity3.6737406253814697
INFO:root:current mean train loss 3298.8807749737166
INFO:root:current train perplexity3.6738128662109375
INFO:root:current mean train loss 3301.705390312353
INFO:root:current train perplexity3.6781792640686035
INFO:root:current mean train loss 3301.3909047364054
INFO:root:current train perplexity3.675204038619995
INFO:root:current mean train loss 3302.5521058214345
INFO:root:current train perplexity3.675031900405884
INFO:root:current mean train loss 3299.05770326837
INFO:root:current train perplexity3.672170639038086
INFO:root:current mean train loss 3298.6837846569547
INFO:root:current train perplexity3.671295166015625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.17s/it]
INFO:root:final mean train loss: 3297.9913207023374
INFO:root:final train perplexity: 3.673530101776123
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4095.5312257590867
INFO:root:eval perplexity: 5.238905429840088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [7:42:32<4:35:03, 235.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.3443697415864
INFO:root:current train perplexity3.671241283416748
INFO:root:current mean train loss 3300.8974591810925
INFO:root:current train perplexity3.6745922565460205
INFO:root:current mean train loss 3299.063770757061
INFO:root:current train perplexity3.668417453765869
INFO:root:current mean train loss 3299.4618067558536
INFO:root:current train perplexity3.66894793510437
INFO:root:current mean train loss 3299.2228036241813
INFO:root:current train perplexity3.671182155609131
INFO:root:current mean train loss 3293.293437554354
INFO:root:current train perplexity3.6688013076782227
INFO:root:current mean train loss 3292.870599737749
INFO:root:current train perplexity3.668623447418213
INFO:root:current mean train loss 3293.9828625835166
INFO:root:current train perplexity3.667750120162964
INFO:root:current mean train loss 3297.695930853788
INFO:root:current train perplexity3.6700305938720703
INFO:root:current mean train loss 3297.645320612021
INFO:root:current train perplexity3.6705639362335205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it]
INFO:root:final mean train loss: 3296.135271133915
INFO:root:final train perplexity: 3.6708409786224365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4097.049493018617
INFO:root:eval perplexity: 5.242122650146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [7:46:28<4:31:07, 235.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.984104886968
INFO:root:current train perplexity3.661344528198242
INFO:root:current mean train loss 3291.8099141023595
INFO:root:current train perplexity3.657627820968628
INFO:root:current mean train loss 3292.3758263221152
INFO:root:current train perplexity3.667722225189209
INFO:root:current mean train loss 3288.73029848478
INFO:root:current train perplexity3.6572999954223633
INFO:root:current mean train loss 3292.412437080537
INFO:root:current train perplexity3.6604011058807373
INFO:root:current mean train loss 3293.014106150737
INFO:root:current train perplexity3.6611568927764893
INFO:root:current mean train loss 3293.849141470247
INFO:root:current train perplexity3.664513349533081
INFO:root:current mean train loss 3294.731090703962
INFO:root:current train perplexity3.6660003662109375
INFO:root:current mean train loss 3293.792952031988
INFO:root:current train perplexity3.6650390625
INFO:root:current mean train loss 3294.730893095796
INFO:root:current train perplexity3.6652212142944336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it]
INFO:root:final mean train loss: 3293.2088890690957
INFO:root:final train perplexity: 3.666605234146118
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it]
INFO:root:eval mean loss: 4098.506957142065
INFO:root:eval perplexity: 5.245213508605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [7:50:26<4:27:56, 236.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.400324041193
INFO:root:current train perplexity3.64770770072937
INFO:root:current mean train loss 3268.398862777218
INFO:root:current train perplexity3.6516404151916504
INFO:root:current mean train loss 3269.66961071538
INFO:root:current train perplexity3.653439998626709
INFO:root:current mean train loss 3271.1997826804577
INFO:root:current train perplexity3.6476633548736572
INFO:root:current mean train loss 3276.404042539492
INFO:root:current train perplexity3.6484553813934326
INFO:root:current mean train loss 3280.008447705518
INFO:root:current train perplexity3.650709390640259
INFO:root:current mean train loss 3282.46889499344
INFO:root:current train perplexity3.6547250747680664
INFO:root:current mean train loss 3284.4721062060225
INFO:root:current train perplexity3.655787467956543
INFO:root:current mean train loss 3287.566399968019
INFO:root:current train perplexity3.6570985317230225
INFO:root:current mean train loss 3289.51348704393
INFO:root:current train perplexity3.6594529151916504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it]
INFO:root:final mean train loss: 3289.5363408365556
INFO:root:final train perplexity: 3.6612961292266846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it]
INFO:root:eval mean loss: 4099.192554230385
INFO:root:eval perplexity: 5.246668338775635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [7:54:13<4:20:53, 233.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.6544053819443
INFO:root:current train perplexity3.6560113430023193
INFO:root:current mean train loss 3271.389410288056
INFO:root:current train perplexity3.6444497108459473
INFO:root:current mean train loss 3278.452447347315
INFO:root:current train perplexity3.652096748352051
INFO:root:current mean train loss 3282.8483832913653
INFO:root:current train perplexity3.6559503078460693
INFO:root:current mean train loss 3285.567017392515
INFO:root:current train perplexity3.655698537826538
INFO:root:current mean train loss 3291.8941062805284
INFO:root:current train perplexity3.6574289798736572
INFO:root:current mean train loss 3289.098021540347
INFO:root:current train perplexity3.654407501220703
INFO:root:current mean train loss 3287.790594858392
INFO:root:current train perplexity3.6540420055389404
INFO:root:current mean train loss 3287.9450083850847
INFO:root:current train perplexity3.6552038192749023
INFO:root:current mean train loss 3290.1374425521644
INFO:root:current train perplexity3.657984495162964


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.57s/it]
INFO:root:final mean train loss: 3287.4301002871607
INFO:root:final train perplexity: 3.6582553386688232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4101.864401526485
INFO:root:eval perplexity: 5.2523393630981445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [7:58:11<4:18:31, 235.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.4102937940143
INFO:root:current train perplexity3.6473326683044434
INFO:root:current mean train loss 3263.7950203878836
INFO:root:current train perplexity3.6245737075805664
INFO:root:current mean train loss 3265.583996987431
INFO:root:current train perplexity3.628276824951172
INFO:root:current mean train loss 3271.0422587021985
INFO:root:current train perplexity3.635032892227173
INFO:root:current mean train loss 3276.423503122512
INFO:root:current train perplexity3.641055107116699
INFO:root:current mean train loss 3283.0369789671354
INFO:root:current train perplexity3.6447465419769287
INFO:root:current mean train loss 3287.458387303814
INFO:root:current train perplexity3.651853322982788
INFO:root:current mean train loss 3285.7367286929516
INFO:root:current train perplexity3.6510214805603027
INFO:root:current mean train loss 3286.1181635019016
INFO:root:current train perplexity3.6519570350646973
INFO:root:current mean train loss 3284.5281186639095
INFO:root:current train perplexity3.650376081466675


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.94s/it]
INFO:root:final mean train loss: 3282.719788520567
INFO:root:final train perplexity: 3.6514627933502197
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it]
INFO:root:eval mean loss: 4101.671720897052
INFO:root:eval perplexity: 5.251928806304932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [8:02:04<4:13:57, 234.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.3727780112736
INFO:root:current train perplexity3.6358749866485596
INFO:root:current mean train loss 3278.093913669693
INFO:root:current train perplexity3.653900384902954
INFO:root:current mean train loss 3275.9863184993837
INFO:root:current train perplexity3.645918130874634
INFO:root:current mean train loss 3280.2723836370383
INFO:root:current train perplexity3.6471691131591797
INFO:root:current mean train loss 3283.303560579495
INFO:root:current train perplexity3.6489651203155518
INFO:root:current mean train loss 3284.665530717023
INFO:root:current train perplexity3.6487629413604736
INFO:root:current mean train loss 3287.5436864299522
INFO:root:current train perplexity3.6493053436279297
INFO:root:current mean train loss 3287.118598438503
INFO:root:current train perplexity3.6476569175720215
INFO:root:current mean train loss 3285.837436784521
INFO:root:current train perplexity3.6478633880615234
INFO:root:current mean train loss 3282.7657135290315
INFO:root:current train perplexity3.6472995281219482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.66s/it]
INFO:root:final mean train loss: 3280.1988087315713
INFO:root:final train perplexity: 3.6478331089019775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 4103.900265957447
INFO:root:eval perplexity: 5.256664276123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [8:06:02<4:11:09, 235.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.9016870959053
INFO:root:current train perplexity3.6294305324554443
INFO:root:current mean train loss 3272.46366221382
INFO:root:current train perplexity3.637282133102417
INFO:root:current mean train loss 3270.579535401241
INFO:root:current train perplexity3.6336019039154053
INFO:root:current mean train loss 3278.1431515715844
INFO:root:current train perplexity3.638932466506958
INFO:root:current mean train loss 3282.1017695432815
INFO:root:current train perplexity3.641763687133789
INFO:root:current mean train loss 3281.5256855069474
INFO:root:current train perplexity3.6402323246002197
INFO:root:current mean train loss 3280.777559105486
INFO:root:current train perplexity3.640181064605713
INFO:root:current mean train loss 3278.9238712451356
INFO:root:current train perplexity3.640033483505249
INFO:root:current mean train loss 3279.0732520962515
INFO:root:current train perplexity3.641141176223755
INFO:root:current mean train loss 3279.9507033822506
INFO:root:current train perplexity3.644016981124878


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.56s/it]
INFO:root:final mean train loss: 3277.7082090685444
INFO:root:final train perplexity: 3.6442503929138184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4104.554161125887
INFO:root:eval perplexity: 5.258055210113525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [8:09:59<4:07:39, 235.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.3527138157897
INFO:root:current train perplexity3.618515729904175
INFO:root:current mean train loss 3266.2253342848558
INFO:root:current train perplexity3.6216466426849365
INFO:root:current mean train loss 3267.719680217161
INFO:root:current train perplexity3.625999689102173
INFO:root:current mean train loss 3269.4653851859175
INFO:root:current train perplexity3.631693124771118
INFO:root:current mean train loss 3268.862121212121
INFO:root:current train perplexity3.6332004070281982
INFO:root:current mean train loss 3271.8466977415965
INFO:root:current train perplexity3.6361987590789795
INFO:root:current mean train loss 3270.6550675865556
INFO:root:current train perplexity3.6353986263275146
INFO:root:current mean train loss 3274.4939035475627
INFO:root:current train perplexity3.6388347148895264
INFO:root:current mean train loss 3274.363913287797
INFO:root:current train perplexity3.637314796447754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.92s/it]
INFO:root:final mean train loss: 3273.1735921059885
INFO:root:final train perplexity: 3.6377365589141846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 4105.529281291556
INFO:root:eval perplexity: 5.260128974914551
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [8:13:54<4:03:25, 235.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.8935546875
INFO:root:current train perplexity3.501382350921631
INFO:root:current mean train loss 3247.1558446791564
INFO:root:current train perplexity3.600142478942871
INFO:root:current mean train loss 3252.781290890548
INFO:root:current train perplexity3.6097187995910645
INFO:root:current mean train loss 3257.3112567360254
INFO:root:current train perplexity3.6170730590820312
INFO:root:current mean train loss 3265.963102657801
INFO:root:current train perplexity3.6208345890045166
INFO:root:current mean train loss 3267.6990284853377
INFO:root:current train perplexity3.622248888015747
INFO:root:current mean train loss 3269.885197223518
INFO:root:current train perplexity3.6250967979431152
INFO:root:current mean train loss 3269.647778355041
INFO:root:current train perplexity3.6268560886383057
INFO:root:current mean train loss 3272.02637205207
INFO:root:current train perplexity3.629715919494629
INFO:root:current mean train loss 3272.704207546027
INFO:root:current train perplexity3.632477283477783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.38s/it]
INFO:root:final mean train loss: 3271.5589549772203
INFO:root:final train perplexity: 3.6354198455810547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it]
INFO:root:eval mean loss: 4106.156965106937
INFO:root:eval perplexity: 5.2614641189575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [8:17:50<3:59:44, 235.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.1525656960225
INFO:root:current train perplexity3.544074773788452
INFO:root:current mean train loss 3266.9671949781814
INFO:root:current train perplexity3.6282286643981934
INFO:root:current mean train loss 3264.8864190702757
INFO:root:current train perplexity3.620910882949829
INFO:root:current mean train loss 3256.4985846123895
INFO:root:current train perplexity3.6126811504364014
INFO:root:current mean train loss 3261.2441376549195
INFO:root:current train perplexity3.6177775859832764
INFO:root:current mean train loss 3262.7937097717404
INFO:root:current train perplexity3.624936103820801
INFO:root:current mean train loss 3264.4608491938166
INFO:root:current train perplexity3.624380350112915
INFO:root:current mean train loss 3266.4688914710796
INFO:root:current train perplexity3.624067783355713
INFO:root:current mean train loss 3269.078690647638
INFO:root:current train perplexity3.629305362701416
INFO:root:current mean train loss 3270.9288529732094
INFO:root:current train perplexity3.629876136779785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.71s/it]
INFO:root:final mean train loss: 3269.058360622775
INFO:root:final train perplexity: 3.631835460662842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4107.263529892509
INFO:root:eval perplexity: 5.263819217681885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [8:21:46<3:55:53, 235.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.6820903577304
INFO:root:current train perplexity3.6023147106170654
INFO:root:current mean train loss 3241.758862920168
INFO:root:current train perplexity3.6034271717071533
INFO:root:current mean train loss 3244.539006760131
INFO:root:current train perplexity3.617142915725708
INFO:root:current mean train loss 3253.4697502877643
INFO:root:current train perplexity3.619516611099243
INFO:root:current mean train loss 3258.1583365574656
INFO:root:current train perplexity3.622083902359009
INFO:root:current mean train loss 3261.870594649416
INFO:root:current train perplexity3.624589681625366
INFO:root:current mean train loss 3259.545579358719
INFO:root:current train perplexity3.6220693588256836
INFO:root:current mean train loss 3262.3022909151164
INFO:root:current train perplexity3.6230547428131104
INFO:root:current mean train loss 3263.816644428705
INFO:root:current train perplexity3.6236205101013184
INFO:root:current mean train loss 3265.2168946375136
INFO:root:current train perplexity3.623380422592163


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.34s/it]
INFO:root:final mean train loss: 3265.393456674391
INFO:root:final train perplexity: 3.6265881061553955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4107.858433067376
INFO:root:eval perplexity: 5.265085220336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [8:25:44<3:52:23, 236.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.3889612268517
INFO:root:current train perplexity3.623683214187622
INFO:root:current mean train loss 3256.5810662217027
INFO:root:current train perplexity3.621229887008667
INFO:root:current mean train loss 3256.3543061243804
INFO:root:current train perplexity3.6194889545440674
INFO:root:current mean train loss 3257.467695790329
INFO:root:current train perplexity3.6227498054504395
INFO:root:current mean train loss 3261.048436470836
INFO:root:current train perplexity3.6212170124053955
INFO:root:current mean train loss 3261.668792898334
INFO:root:current train perplexity3.6198549270629883
INFO:root:current mean train loss 3263.0758097525418
INFO:root:current train perplexity3.6224074363708496
INFO:root:current mean train loss 3263.3613009236374
INFO:root:current train perplexity3.6228811740875244
INFO:root:current mean train loss 3264.066273109224
INFO:root:current train perplexity3.6240646839141846
INFO:root:current mean train loss 3263.159503101402
INFO:root:current train perplexity3.6209657192230225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.63s/it]
INFO:root:final mean train loss: 3261.9148921966553
INFO:root:final train perplexity: 3.621614694595337
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 4111.623001856161
INFO:root:eval perplexity: 5.273106098175049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [8:29:19<3:42:23, 230.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.1333077566965
INFO:root:current train perplexity3.605321168899536
INFO:root:current mean train loss 3283.71845703125
INFO:root:current train perplexity3.604647397994995
INFO:root:current mean train loss 3273.885517785904
INFO:root:current train perplexity3.6082372665405273
INFO:root:current mean train loss 3272.3758373659048
INFO:root:current train perplexity3.6110010147094727
INFO:root:current mean train loss 3264.7586801813936
INFO:root:current train perplexity3.6118288040161133
INFO:root:current mean train loss 3268.8942136390187
INFO:root:current train perplexity3.615908145904541
INFO:root:current mean train loss 3264.371031465305
INFO:root:current train perplexity3.6114749908447266
INFO:root:current mean train loss 3262.5328347549957
INFO:root:current train perplexity3.6135854721069336
INFO:root:current mean train loss 3260.344468387444
INFO:root:current train perplexity3.6149582862854004
INFO:root:current mean train loss 3261.068252579796
INFO:root:current train perplexity3.6175546646118164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.32s/it]
INFO:root:final mean train loss: 3259.7174579251196
INFO:root:final train perplexity: 3.6184756755828857
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it]
INFO:root:eval mean loss: 4110.583205202793
INFO:root:eval perplexity: 5.270890235900879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [8:33:13<3:39:32, 231.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.391732149346
INFO:root:current train perplexity3.5927700996398926
INFO:root:current mean train loss 3246.5807012811406
INFO:root:current train perplexity3.5934948921203613
INFO:root:current mean train loss 3245.3055304382074
INFO:root:current train perplexity3.596803903579712
INFO:root:current mean train loss 3249.8262971483236
INFO:root:current train perplexity3.5974795818328857
INFO:root:current mean train loss 3250.5911129505853
INFO:root:current train perplexity3.6003000736236572
INFO:root:current mean train loss 3252.7437184370683
INFO:root:current train perplexity3.6036767959594727
INFO:root:current mean train loss 3256.2033231981436
INFO:root:current train perplexity3.607600688934326
INFO:root:current mean train loss 3253.3699601226026
INFO:root:current train perplexity3.607968807220459
INFO:root:current mean train loss 3255.8382572703513
INFO:root:current train perplexity3.6109070777893066
INFO:root:current mean train loss 3257.343755436854
INFO:root:current train perplexity3.6142728328704834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.85s/it]
INFO:root:final mean train loss: 3257.0771873843287
INFO:root:final train perplexity: 3.614708662033081
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it]
INFO:root:eval mean loss: 4114.322885499779
INFO:root:eval perplexity: 5.278865814208984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [8:37:09<3:36:59, 232.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.1778875612745
INFO:root:current train perplexity3.576846122741699
INFO:root:current mean train loss 3247.704166235513
INFO:root:current train perplexity3.595842123031616
INFO:root:current mean train loss 3247.8260395916336
INFO:root:current train perplexity3.5941293239593506
INFO:root:current mean train loss 3243.4129941239316
INFO:root:current train perplexity3.5943830013275146
INFO:root:current mean train loss 3248.965703926171
INFO:root:current train perplexity3.598844528198242
INFO:root:current mean train loss 3250.1660497426556
INFO:root:current train perplexity3.60274338722229
INFO:root:current mean train loss 3254.3159438454063
INFO:root:current train perplexity3.6056740283966064
INFO:root:current mean train loss 3256.4832397948567
INFO:root:current train perplexity3.6086320877075195
INFO:root:current mean train loss 3255.871307480629
INFO:root:current train perplexity3.60866379737854
INFO:root:current mean train loss 3254.9978579291537
INFO:root:current train perplexity3.6095380783081055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.37s/it]
INFO:root:final mean train loss: 3253.91916096595
INFO:root:final train perplexity: 3.6102073192596436
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.69s/it]
INFO:root:eval mean loss: 4113.727824758976
INFO:root:eval perplexity: 5.277596473693848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [8:41:06<3:34:26, 233.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.3036074880824
INFO:root:current train perplexity3.592757225036621
INFO:root:current mean train loss 3248.872414259041
INFO:root:current train perplexity3.593391180038452
INFO:root:current mean train loss 3243.0547657381153
INFO:root:current train perplexity3.5944933891296387
INFO:root:current mean train loss 3244.488387338962
INFO:root:current train perplexity3.597867727279663
INFO:root:current mean train loss 3247.0914091222426
INFO:root:current train perplexity3.598874092102051
INFO:root:current mean train loss 3249.902752106859
INFO:root:current train perplexity3.602658271789551
INFO:root:current mean train loss 3254.190213332227
INFO:root:current train perplexity3.6043474674224854
INFO:root:current mean train loss 3253.2137066787095
INFO:root:current train perplexity3.605041742324829
INFO:root:current mean train loss 3254.6128839175276
INFO:root:current train perplexity3.6069560050964355
INFO:root:current mean train loss 3254.15051154971
INFO:root:current train perplexity3.6074488162994385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.99s/it]
INFO:root:final mean train loss: 3252.3314919010286
INFO:root:final train perplexity: 3.60794734954834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4115.542892564273
INFO:root:eval perplexity: 5.281471252441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [8:45:07<3:32:34, 236.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.469394968517
INFO:root:current train perplexity3.5891618728637695
INFO:root:current mean train loss 3257.147513566617
INFO:root:current train perplexity3.588322401046753
INFO:root:current mean train loss 3253.2688811227176
INFO:root:current train perplexity3.5936615467071533
INFO:root:current mean train loss 3254.75927734375
INFO:root:current train perplexity3.592170000076294
INFO:root:current mean train loss 3249.813086042057
INFO:root:current train perplexity3.5912134647369385
INFO:root:current mean train loss 3248.0044040040784
INFO:root:current train perplexity3.5942530632019043
INFO:root:current mean train loss 3249.574228632754
INFO:root:current train perplexity3.5960466861724854
INFO:root:current mean train loss 3249.303593482623
INFO:root:current train perplexity3.5958118438720703
INFO:root:current mean train loss 3250.504669083856
INFO:root:current train perplexity3.599536657333374
INFO:root:current mean train loss 3251.353542639526
INFO:root:current train perplexity3.601602077484131


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.07s/it]
INFO:root:final mean train loss: 3248.3268037611438
INFO:root:final train perplexity: 3.602250814437866
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4116.551553496232
INFO:root:eval perplexity: 5.283625602722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [8:49:03<3:28:37, 236.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.850823567708
INFO:root:current train perplexity3.569788932800293
INFO:root:current mean train loss 3241.237557198661
INFO:root:current train perplexity3.592013359069824
INFO:root:current mean train loss 3247.2471235795456
INFO:root:current train perplexity3.5982751846313477
INFO:root:current mean train loss 3243.479782552083
INFO:root:current train perplexity3.5952508449554443
INFO:root:current mean train loss 3242.402007606908
INFO:root:current train perplexity3.591667413711548
INFO:root:current mean train loss 3243.90981360394
INFO:root:current train perplexity3.591949939727783
INFO:root:current mean train loss 3246.5882338686342
INFO:root:current train perplexity3.5936152935028076
INFO:root:current mean train loss 3247.707242628528
INFO:root:current train perplexity3.5938897132873535
INFO:root:current mean train loss 3251.20723828125
INFO:root:current train perplexity3.598445177078247
INFO:root:current mean train loss 3249.5865034054486
INFO:root:current train perplexity3.5994043350219727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.21s/it]
INFO:root:final mean train loss: 3246.854387467907
INFO:root:final train perplexity: 3.600158929824829
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 4116.768857698914
INFO:root:eval perplexity: 5.284090042114258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [8:53:00<3:24:49, 236.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3245.07279802805
INFO:root:current train perplexity3.593508005142212
INFO:root:current mean train loss 3236.7623884690915
INFO:root:current train perplexity3.589236259460449
INFO:root:current mean train loss 3239.1161419224823
INFO:root:current train perplexity3.5877480506896973
INFO:root:current mean train loss 3241.972223426281
INFO:root:current train perplexity3.5880045890808105
INFO:root:current mean train loss 3242.6438402764297
INFO:root:current train perplexity3.5877788066864014
INFO:root:current mean train loss 3242.0710411529803
INFO:root:current train perplexity3.5910983085632324
INFO:root:current mean train loss 3243.419593375389
INFO:root:current train perplexity3.59230637550354
INFO:root:current mean train loss 3242.852370066052
INFO:root:current train perplexity3.5916998386383057
INFO:root:current mean train loss 3243.785199658922
INFO:root:current train perplexity3.593196153640747
INFO:root:current mean train loss 3245.966619047241
INFO:root:current train perplexity3.5952107906341553


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.69s/it]
INFO:root:final mean train loss: 3243.719324050411
INFO:root:final train perplexity: 3.5957086086273193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it]
INFO:root:eval mean loss: 4116.679316960328
INFO:root:eval perplexity: 5.283899784088135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [8:56:56<3:20:44, 236.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.502465552026
INFO:root:current train perplexity3.5705559253692627
INFO:root:current mean train loss 3232.155021627536
INFO:root:current train perplexity3.5752334594726562
INFO:root:current mean train loss 3234.3469028538443
INFO:root:current train perplexity3.5798652172088623
INFO:root:current mean train loss 3235.7411890834796
INFO:root:current train perplexity3.580169200897217
INFO:root:current mean train loss 3235.44238629312
INFO:root:current train perplexity3.58084774017334
INFO:root:current mean train loss 3234.6565610624207
INFO:root:current train perplexity3.581441640853882
INFO:root:current mean train loss 3238.752131902361
INFO:root:current train perplexity3.5847208499908447
INFO:root:current mean train loss 3239.1903491303533
INFO:root:current train perplexity3.5883922576904297
INFO:root:current mean train loss 3241.3961506339438
INFO:root:current train perplexity3.589895725250244
INFO:root:current mean train loss 3242.7583256633925
INFO:root:current train perplexity3.59079909324646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.97s/it]
INFO:root:final mean train loss: 3240.2624686456497
INFO:root:final train perplexity: 3.590808153152466
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 4119.845761995789
INFO:root:eval perplexity: 5.290668964385986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [9:00:49<3:15:58, 235.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.885927142519
INFO:root:current train perplexity3.5941109657287598
INFO:root:current mean train loss 3236.603432200063
INFO:root:current train perplexity3.5825181007385254
INFO:root:current mean train loss 3234.037422103627
INFO:root:current train perplexity3.5785536766052246
INFO:root:current mean train loss 3231.9078005071274
INFO:root:current train perplexity3.5766639709472656
INFO:root:current mean train loss 3234.4514047626503
INFO:root:current train perplexity3.5786304473876953
INFO:root:current mean train loss 3236.776400201508
INFO:root:current train perplexity3.584185838699341
INFO:root:current mean train loss 3236.6007158664165
INFO:root:current train perplexity3.5867490768432617
INFO:root:current mean train loss 3234.4790011562304
INFO:root:current train perplexity3.5857901573181152
INFO:root:current mean train loss 3238.616746471774
INFO:root:current train perplexity3.5871741771698


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.15s/it]
INFO:root:final mean train loss: 3239.3075224968693
INFO:root:final train perplexity: 3.5894558429718018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4120.284396124224
INFO:root:eval perplexity: 5.291606903076172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [9:04:45<3:12:12, 235.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.267892020089
INFO:root:current train perplexity3.5876739025115967
INFO:root:current mean train loss 3235.539094443633
INFO:root:current train perplexity3.5804927349090576
INFO:root:current mean train loss 3233.910439311594
INFO:root:current train perplexity3.5828521251678467
INFO:root:current mean train loss 3232.103074263284
INFO:root:current train perplexity3.58590030670166
INFO:root:current mean train loss 3231.82237059947
INFO:root:current train perplexity3.583909273147583
INFO:root:current mean train loss 3233.848952554857
INFO:root:current train perplexity3.5813956260681152
INFO:root:current mean train loss 3233.2126392446203
INFO:root:current train perplexity3.5813233852386475
INFO:root:current mean train loss 3238.0342974413234
INFO:root:current train perplexity3.5820164680480957
INFO:root:current mean train loss 3238.865833986795
INFO:root:current train perplexity3.583172559738159
INFO:root:current mean train loss 3242.3752497932746
INFO:root:current train perplexity3.586552858352661


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.22s/it]
INFO:root:final mean train loss: 3236.86136891765
INFO:root:final train perplexity: 3.5859932899475098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 4121.414732588099
INFO:root:eval perplexity: 5.294027328491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [9:08:41<3:08:38, 235.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.5677571614583
INFO:root:current train perplexity3.5830020904541016
INFO:root:current mean train loss 3230.1523649796195
INFO:root:current train perplexity3.570753812789917
INFO:root:current mean train loss 3231.487601062863
INFO:root:current train perplexity3.576279878616333
INFO:root:current mean train loss 3226.3796115451387
INFO:root:current train perplexity3.5737900733947754
INFO:root:current mean train loss 3232.10217491058
INFO:root:current train perplexity3.5761992931365967
INFO:root:current mean train loss 3235.410865442961
INFO:root:current train perplexity3.580693244934082
INFO:root:current mean train loss 3236.4405098767784
INFO:root:current train perplexity3.578124523162842
INFO:root:current mean train loss 3238.7139358200393
INFO:root:current train perplexity3.5816285610198975
INFO:root:current mean train loss 3237.2674292441525
INFO:root:current train perplexity3.582782506942749
INFO:root:current mean train loss 3237.4521156185965
INFO:root:current train perplexity3.58363938331604


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.56s/it]
INFO:root:final mean train loss: 3234.680141202865
INFO:root:final train perplexity: 3.5829083919525146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 4122.058901955896
INFO:root:eval perplexity: 5.295405864715576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [9:12:43<3:06:06, 237.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3183.0711722995925
INFO:root:current train perplexity3.5281522274017334
INFO:root:current mean train loss 3223.031416730183
INFO:root:current train perplexity3.5670647621154785
INFO:root:current mean train loss 3221.911014573991
INFO:root:current train perplexity3.5608372688293457
INFO:root:current mean train loss 3222.8233034116197
INFO:root:current train perplexity3.561343193054199
INFO:root:current mean train loss 3225.4205013482565
INFO:root:current train perplexity3.5669593811035156
INFO:root:current mean train loss 3227.906916135128
INFO:root:current train perplexity3.5682053565979004
INFO:root:current mean train loss 3228.4337579473063
INFO:root:current train perplexity3.5720255374908447
INFO:root:current mean train loss 3231.771688669714
INFO:root:current train perplexity3.575470447540283
INFO:root:current mean train loss 3234.523043552552
INFO:root:current train perplexity3.5764172077178955
INFO:root:current mean train loss 3235.1299230176733
INFO:root:current train perplexity3.578479528427124


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.96s/it]
INFO:root:final mean train loss: 3231.978995846164
INFO:root:final train perplexity: 3.579092502593994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4122.983628726175
INFO:root:eval perplexity: 5.297386169433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [9:16:45<3:03:03, 238.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.527131111391
INFO:root:current train perplexity3.6063640117645264
INFO:root:current mean train loss 3224.9210288943227
INFO:root:current train perplexity3.573517084121704
INFO:root:current mean train loss 3223.6747338761497
INFO:root:current train perplexity3.5650417804718018
INFO:root:current mean train loss 3225.565239390578
INFO:root:current train perplexity3.568868637084961
INFO:root:current mean train loss 3223.0346334152046
INFO:root:current train perplexity3.5722758769989014
INFO:root:current mean train loss 3222.3203598568443
INFO:root:current train perplexity3.5714263916015625
INFO:root:current mean train loss 3226.2907351147733
INFO:root:current train perplexity3.5745458602905273
INFO:root:current mean train loss 3229.0579317982642
INFO:root:current train perplexity3.5769765377044678
INFO:root:current mean train loss 3231.9792339448895
INFO:root:current train perplexity3.5749852657318115
INFO:root:current mean train loss 3230.801527308086
INFO:root:current train perplexity3.5749285221099854


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.54s/it]
INFO:root:final mean train loss: 3229.255838394165
INFO:root:final train perplexity: 3.575249195098877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 4124.286742298315
INFO:root:eval perplexity: 5.300179481506348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [9:20:40<2:58:11, 237.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.4378255208335
INFO:root:current train perplexity3.5741679668426514
INFO:root:current mean train loss 3221.8828950511465
INFO:root:current train perplexity3.5519332885742188
INFO:root:current mean train loss 3228.823619124281
INFO:root:current train perplexity3.564631223678589
INFO:root:current mean train loss 3226.101872897078
INFO:root:current train perplexity3.5678629875183105
INFO:root:current mean train loss 3222.704805621797
INFO:root:current train perplexity3.5709125995635986
INFO:root:current mean train loss 3224.205572747565
INFO:root:current train perplexity3.5686521530151367
INFO:root:current mean train loss 3224.1509136743202
INFO:root:current train perplexity3.566930055618286
INFO:root:current mean train loss 3226.4033956359945
INFO:root:current train perplexity3.5676023960113525
INFO:root:current mean train loss 3226.814190652004
INFO:root:current train perplexity3.5662450790405273
INFO:root:current mean train loss 3228.961946042582
INFO:root:current train perplexity3.5712101459503174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it]
INFO:root:final mean train loss: 3226.941418001729
INFO:root:final train perplexity: 3.571986436843872
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4124.321295988475
INFO:root:eval perplexity: 5.300252914428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [9:24:35<2:53:51, 237.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.3848799035904
INFO:root:current train perplexity3.5117456912994385
INFO:root:current mean train loss 3226.0516249468537
INFO:root:current train perplexity3.54681658744812
INFO:root:current mean train loss 3217.90837412228
INFO:root:current train perplexity3.549842357635498
INFO:root:current mean train loss 3220.8673155507026
INFO:root:current train perplexity3.554614305496216
INFO:root:current mean train loss 3223.7512747745386
INFO:root:current train perplexity3.5603699684143066
INFO:root:current mean train loss 3220.1132125157105
INFO:root:current train perplexity3.56072735786438
INFO:root:current mean train loss 3220.813358831627
INFO:root:current train perplexity3.5630273818969727
INFO:root:current mean train loss 3223.9696236116342
INFO:root:current train perplexity3.56528639793396
INFO:root:current mean train loss 3226.649153203863
INFO:root:current train perplexity3.566627264022827
INFO:root:current mean train loss 3227.5499330740167
INFO:root:current train perplexity3.5680582523345947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.15s/it]
INFO:root:final mean train loss: 3225.1179583149574
INFO:root:final train perplexity: 3.5694169998168945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it]
INFO:root:eval mean loss: 4125.912135347407
INFO:root:eval perplexity: 5.30366325378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [9:28:28<2:48:53, 235.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3196.2174360795457
INFO:root:current train perplexity3.5723631381988525
INFO:root:current mean train loss 3195.4544874621974
INFO:root:current train perplexity3.5549213886260986
INFO:root:current mean train loss 3208.59691138174
INFO:root:current train perplexity3.5577173233032227
INFO:root:current mean train loss 3213.9261863171214
INFO:root:current train perplexity3.561189651489258
INFO:root:current mean train loss 3216.0505167196084
INFO:root:current train perplexity3.5618538856506348
INFO:root:current mean train loss 3220.0658392278997
INFO:root:current train perplexity3.5623350143432617
INFO:root:current mean train loss 3223.5085844316554
INFO:root:current train perplexity3.564854621887207
INFO:root:current mean train loss 3224.1073905085887
INFO:root:current train perplexity3.565159797668457
INFO:root:current mean train loss 3226.0690561038014
INFO:root:current train perplexity3.567274808883667
INFO:root:current mean train loss 3225.360405247873
INFO:root:current train perplexity3.5658857822418213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.36s/it]
INFO:root:final mean train loss: 3222.9717234949912
INFO:root:final train perplexity: 3.566396474838257
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4125.835052706671
INFO:root:eval perplexity: 5.303497791290283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [9:32:09<2:41:54, 231.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.8318839905755
INFO:root:current train perplexity3.5618908405303955
INFO:root:current mean train loss 3233.190443167657
INFO:root:current train perplexity3.5591485500335693
INFO:root:current mean train loss 3228.235150123277
INFO:root:current train perplexity3.5578408241271973
INFO:root:current mean train loss 3217.733066863593
INFO:root:current train perplexity3.556180715560913
INFO:root:current mean train loss 3220.1257108025106
INFO:root:current train perplexity3.5617434978485107
INFO:root:current mean train loss 3222.373432816663
INFO:root:current train perplexity3.562528371810913
INFO:root:current mean train loss 3220.975607295202
INFO:root:current train perplexity3.565061330795288
INFO:root:current mean train loss 3224.4289336398265
INFO:root:current train perplexity3.5640814304351807
INFO:root:current mean train loss 3223.2935099331003
INFO:root:current train perplexity3.563950538635254
INFO:root:current mean train loss 3223.5228163737993
INFO:root:current train perplexity3.5634777545928955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it]
INFO:root:final mean train loss: 3220.76645365069
INFO:root:final train perplexity: 3.5632948875427246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4128.261465951906
INFO:root:eval perplexity: 5.308703899383545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [9:35:21<2:30:00, 219.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.3094155754843
INFO:root:current train perplexity3.5665512084960938
INFO:root:current mean train loss 3211.7705549273574
INFO:root:current train perplexity3.547593832015991
INFO:root:current mean train loss 3211.7328939402673
INFO:root:current train perplexity3.5467593669891357
INFO:root:current mean train loss 3209.1458085463696
INFO:root:current train perplexity3.5528531074523926
INFO:root:current mean train loss 3214.2498284277135
INFO:root:current train perplexity3.5554134845733643
INFO:root:current mean train loss 3214.1746114273205
INFO:root:current train perplexity3.556940793991089
INFO:root:current mean train loss 3216.4612671444206
INFO:root:current train perplexity3.5552010536193848
INFO:root:current mean train loss 3218.2411507731435
INFO:root:current train perplexity3.555940866470337
INFO:root:current mean train loss 3220.51087589023
INFO:root:current train perplexity3.5607786178588867
INFO:root:current mean train loss 3220.857308730529
INFO:root:current train perplexity3.5608766078948975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.13s/it]
INFO:root:final mean train loss: 3219.115812855382
INFO:root:final train perplexity: 3.5609750747680664
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4128.690109361148
INFO:root:eval perplexity: 5.309624195098877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [9:38:33<2:20:48, 211.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.8119869956486
INFO:root:current train perplexity3.549679756164551
INFO:root:current mean train loss 3213.199525630674
INFO:root:current train perplexity3.5611724853515625
INFO:root:current mean train loss 3216.886938389057
INFO:root:current train perplexity3.560269832611084
INFO:root:current mean train loss 3222.550534532693
INFO:root:current train perplexity3.558781623840332
INFO:root:current mean train loss 3220.521279990051
INFO:root:current train perplexity3.5575501918792725
INFO:root:current mean train loss 3222.4616791983754
INFO:root:current train perplexity3.5583090782165527
INFO:root:current mean train loss 3217.758067786957
INFO:root:current train perplexity3.5578551292419434
INFO:root:current mean train loss 3219.117326650754
INFO:root:current train perplexity3.558497428894043
INFO:root:current mean train loss 3217.8152558171573
INFO:root:current train perplexity3.559079885482788
INFO:root:current mean train loss 3220.597180687005
INFO:root:current train perplexity3.560671329498291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.58s/it]
INFO:root:final mean train loss: 3218.6047899799964
INFO:root:final train perplexity: 3.5602574348449707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4128.35195035461
INFO:root:eval perplexity: 5.308898448944092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [9:41:45<2:13:30, 205.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3205.32373046875
INFO:root:current train perplexity3.526846408843994
INFO:root:current mean train loss 3204.7376271620155
INFO:root:current train perplexity3.534517526626587
INFO:root:current mean train loss 3210.7474794819796
INFO:root:current train perplexity3.5381624698638916
INFO:root:current mean train loss 3215.5087783379763
INFO:root:current train perplexity3.545947790145874
INFO:root:current mean train loss 3213.9070150073794
INFO:root:current train perplexity3.5475032329559326
INFO:root:current mean train loss 3215.8532174157526
INFO:root:current train perplexity3.548204183578491
INFO:root:current mean train loss 3214.4617068805724
INFO:root:current train perplexity3.5482282638549805
INFO:root:current mean train loss 3215.2917983019975
INFO:root:current train perplexity3.5500123500823975
INFO:root:current mean train loss 3215.465102203266
INFO:root:current train perplexity3.5518741607666016
INFO:root:current mean train loss 3217.782650531123
INFO:root:current train perplexity3.5556833744049072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.17s/it]
INFO:root:final mean train loss: 3214.9702601894255
INFO:root:final train perplexity: 3.5551552772521973
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 4128.358301473848
INFO:root:eval perplexity: 5.3089118003845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [9:44:57<2:07:37, 201.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.170921566612
INFO:root:current train perplexity3.5559561252593994
INFO:root:current mean train loss 3219.8288799579327
INFO:root:current train perplexity3.560844898223877
INFO:root:current mean train loss 3215.5423960540256
INFO:root:current train perplexity3.5505332946777344
INFO:root:current mean train loss 3219.152315936511
INFO:root:current train perplexity3.5485517978668213
INFO:root:current mean train loss 3220.3131505484535
INFO:root:current train perplexity3.55104923248291
INFO:root:current mean train loss 3219.848100216649
INFO:root:current train perplexity3.5512940883636475
INFO:root:current mean train loss 3218.914040017986
INFO:root:current train perplexity3.5501701831817627
INFO:root:current mean train loss 3216.460969130798
INFO:root:current train perplexity3.550846576690674
INFO:root:current mean train loss 3216.3411130084673
INFO:root:current train perplexity3.5515527725219727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.10s/it]
INFO:root:final mean train loss: 3213.4824650672176
INFO:root:final train perplexity: 3.5530691146850586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 4129.231526692708
INFO:root:eval perplexity: 5.310786724090576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [9:48:09<2:02:35, 198.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.0039876302085
INFO:root:current train perplexity3.5395753383636475
INFO:root:current mean train loss 3183.189697265625
INFO:root:current train perplexity3.5429482460021973
INFO:root:current mean train loss 3207.761760843211
INFO:root:current train perplexity3.556307077407837
INFO:root:current mean train loss 3205.1448801374277
INFO:root:current train perplexity3.551828384399414
INFO:root:current mean train loss 3205.1537698220377
INFO:root:current train perplexity3.5538651943206787
INFO:root:current mean train loss 3206.5442345924453
INFO:root:current train perplexity3.551779270172119
INFO:root:current mean train loss 3209.480947719087
INFO:root:current train perplexity3.550138473510742
INFO:root:current mean train loss 3209.0806952485996
INFO:root:current train perplexity3.5474331378936768
INFO:root:current mean train loss 3209.181349662885
INFO:root:current train perplexity3.5477397441864014
INFO:root:current mean train loss 3213.438553346484
INFO:root:current train perplexity3.5494961738586426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.64s/it]
INFO:root:final mean train loss: 3211.1191534842214
INFO:root:final train perplexity: 3.549757957458496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it]
INFO:root:eval mean loss: 4131.032056876108
INFO:root:eval perplexity: 5.314655780792236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [9:51:22<1:58:08, 196.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.201238458807
INFO:root:current train perplexity3.5258748531341553
INFO:root:current mean train loss 3210.3850361592063
INFO:root:current train perplexity3.531381607055664
INFO:root:current mean train loss 3214.9447466954234
INFO:root:current train perplexity3.541177749633789
INFO:root:current mean train loss 3214.525636335661
INFO:root:current train perplexity3.5480387210845947
INFO:root:current mean train loss 3218.971724832725
INFO:root:current train perplexity3.553933620452881
INFO:root:current mean train loss 3214.1216880962575
INFO:root:current train perplexity3.5520896911621094
INFO:root:current mean train loss 3211.6945037592063
INFO:root:current train perplexity3.5490548610687256
INFO:root:current mean train loss 3210.9286213162577
INFO:root:current train perplexity3.5484514236450195
INFO:root:current mean train loss 3211.6306459401007
INFO:root:current train perplexity3.547393798828125
INFO:root:current mean train loss 3211.847738255523
INFO:root:current train perplexity3.547473192214966


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.06s/it]
INFO:root:final mean train loss: 3208.598594296363
INFO:root:final train perplexity: 3.546229839324951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4131.085598127216
INFO:root:eval perplexity: 5.314770698547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [9:54:33<1:53:53, 195.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.3266473067433
INFO:root:current train perplexity3.5564494132995605
INFO:root:current mean train loss 3207.483511275604
INFO:root:current train perplexity3.5422556400299072
INFO:root:current mean train loss 3212.2047615225456
INFO:root:current train perplexity3.5502443313598633
INFO:root:current mean train loss 3212.4466242775275
INFO:root:current train perplexity3.54632306098938
INFO:root:current mean train loss 3210.5190744331744
INFO:root:current train perplexity3.5474331378936768
INFO:root:current mean train loss 3208.5040393748495
INFO:root:current train perplexity3.546902894973755
INFO:root:current mean train loss 3211.1832916309068
INFO:root:current train perplexity3.5477359294891357
INFO:root:current mean train loss 3212.8714197235745
INFO:root:current train perplexity3.5470352172851562
INFO:root:current mean train loss 3212.7420202681433
INFO:root:current train perplexity3.5482397079467773
INFO:root:current mean train loss 3211.1665174548593
INFO:root:current train perplexity3.5456228256225586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.20s/it]
INFO:root:final mean train loss: 3208.1283118340275
INFO:root:final train perplexity: 3.5455715656280518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4132.833639807735
INFO:root:eval perplexity: 5.318528652191162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [9:57:45<1:49:58, 194.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.6720106336807
INFO:root:current train perplexity3.536816358566284
INFO:root:current mean train loss 3200.8377272237944
INFO:root:current train perplexity3.527724504470825
INFO:root:current mean train loss 3207.234083536963
INFO:root:current train perplexity3.538625478744507
INFO:root:current mean train loss 3203.2704697355216
INFO:root:current train perplexity3.5367860794067383
INFO:root:current mean train loss 3206.0914481026784
INFO:root:current train perplexity3.536454677581787
INFO:root:current mean train loss 3209.676698977852
INFO:root:current train perplexity3.5369651317596436
INFO:root:current mean train loss 3209.960148618172
INFO:root:current train perplexity3.539308547973633
INFO:root:current mean train loss 3211.222977293243
INFO:root:current train perplexity3.5414505004882812
INFO:root:current mean train loss 3208.7563878051315
INFO:root:current train perplexity3.5424249172210693
INFO:root:current mean train loss 3209.0757849898023
INFO:root:current train perplexity3.5432240962982178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.42s/it]
INFO:root:final mean train loss: 3206.1403594478484
INFO:root:final train perplexity: 3.5427920818328857
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.61s/it]
INFO:root:eval mean loss: 4132.975892411901
INFO:root:eval perplexity: 5.31883430480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [10:00:57<1:46:22, 193.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.4743233816966
INFO:root:current train perplexity3.5346744060516357
INFO:root:current mean train loss 3204.9752839265047
INFO:root:current train perplexity3.53767728805542
INFO:root:current mean train loss 3194.1951265375665
INFO:root:current train perplexity3.530371904373169
INFO:root:current mean train loss 3200.7143416219683
INFO:root:current train perplexity3.532111644744873
INFO:root:current mean train loss 3203.17691327676
INFO:root:current train perplexity3.5344603061676025
INFO:root:current mean train loss 3207.3393417786215
INFO:root:current train perplexity3.5365750789642334
INFO:root:current mean train loss 3206.550197234867
INFO:root:current train perplexity3.538306713104248
INFO:root:current mean train loss 3207.960326318027
INFO:root:current train perplexity3.538020610809326
INFO:root:current mean train loss 3207.726835294255
INFO:root:current train perplexity3.5379507541656494
INFO:root:current mean train loss 3207.1193808489306
INFO:root:current train perplexity3.5394527912139893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.96s/it]
INFO:root:final mean train loss: 3204.548221095916
INFO:root:final train perplexity: 3.540567398071289
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4133.02001953125
INFO:root:eval perplexity: 5.318930149078369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [10:04:09<1:42:57, 193.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.2785360646803
INFO:root:current train perplexity3.5172278881073
INFO:root:current mean train loss 3221.7775144777097
INFO:root:current train perplexity3.546776294708252
INFO:root:current mean train loss 3205.229544431584
INFO:root:current train perplexity3.5405843257904053
INFO:root:current mean train loss 3199.7127568103133
INFO:root:current train perplexity3.5335693359375
INFO:root:current mean train loss 3200.979925909107
INFO:root:current train perplexity3.5344860553741455
INFO:root:current mean train loss 3199.274169022646
INFO:root:current train perplexity3.5305662155151367
INFO:root:current mean train loss 3204.281067369144
INFO:root:current train perplexity3.5322885513305664
INFO:root:current mean train loss 3205.857776092488
INFO:root:current train perplexity3.536991834640503
INFO:root:current mean train loss 3207.4591149887865
INFO:root:current train perplexity3.5384092330932617
INFO:root:current mean train loss 3205.7639789277905
INFO:root:current train perplexity3.5379979610443115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.52s/it]
INFO:root:final mean train loss: 3202.425515451739
INFO:root:final train perplexity: 3.5376031398773193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.83s/it]
INFO:root:eval mean loss: 4133.546668952238
INFO:root:eval perplexity: 5.320061206817627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [10:07:21<1:39:36, 192.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.9425359987745
INFO:root:current train perplexity3.520003080368042
INFO:root:current mean train loss 3195.31208447589
INFO:root:current train perplexity3.5210585594177246
INFO:root:current mean train loss 3199.418661292331
INFO:root:current train perplexity3.5341720581054688
INFO:root:current mean train loss 3198.2186880953973
INFO:root:current train perplexity3.5315394401550293
INFO:root:current mean train loss 3193.332136268362
INFO:root:current train perplexity3.5274834632873535
INFO:root:current mean train loss 3194.609440576792
INFO:root:current train perplexity3.529905080795288
INFO:root:current mean train loss 3197.8519180227536
INFO:root:current train perplexity3.5311293601989746
INFO:root:current mean train loss 3199.7417209996047
INFO:root:current train perplexity3.5327491760253906
INFO:root:current mean train loss 3201.612669894334
INFO:root:current train perplexity3.53277325630188
INFO:root:current mean train loss 3202.370319996221
INFO:root:current train perplexity3.5339276790618896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.96s/it]
INFO:root:final mean train loss: 3200.8336491123323
INFO:root:final train perplexity: 3.5353822708129883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4134.469795822251
INFO:root:eval perplexity: 5.322048187255859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [10:10:33<1:36:18, 192.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.616914393538
INFO:root:current train perplexity3.5257859230041504
INFO:root:current mean train loss 3184.336032699489
INFO:root:current train perplexity3.5141031742095947
INFO:root:current mean train loss 3184.5627507390204
INFO:root:current train perplexity3.523052453994751
INFO:root:current mean train loss 3193.792658643802
INFO:root:current train perplexity3.5322110652923584
INFO:root:current mean train loss 3192.323251761642
INFO:root:current train perplexity3.5288822650909424
INFO:root:current mean train loss 3194.483329868487
INFO:root:current train perplexity3.531345844268799
INFO:root:current mean train loss 3198.2377118355225
INFO:root:current train perplexity3.533259153366089
INFO:root:current mean train loss 3199.8381894479785
INFO:root:current train perplexity3.533141613006592
INFO:root:current mean train loss 3200.9086561635986
INFO:root:current train perplexity3.5341081619262695
INFO:root:current mean train loss 3201.276476656185
INFO:root:current train perplexity3.5337936878204346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.48s/it]
INFO:root:final mean train loss: 3199.580035609584
INFO:root:final train perplexity: 3.5336341857910156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4134.648210674313
INFO:root:eval perplexity: 5.322432518005371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [10:13:45<1:33:00, 192.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.410859520756
INFO:root:current train perplexity3.5267534255981445
INFO:root:current mean train loss 3213.0032498479604
INFO:root:current train perplexity3.5363597869873047
INFO:root:current mean train loss 3205.147421618972
INFO:root:current train perplexity3.5404813289642334
INFO:root:current mean train loss 3204.894505971134
INFO:root:current train perplexity3.541259765625
INFO:root:current mean train loss 3197.474765164949
INFO:root:current train perplexity3.5363643169403076
INFO:root:current mean train loss 3195.240417372823
INFO:root:current train perplexity3.5314128398895264
INFO:root:current mean train loss 3195.708349316553
INFO:root:current train perplexity3.531881809234619
INFO:root:current mean train loss 3197.8882259284346
INFO:root:current train perplexity3.532137393951416
INFO:root:current mean train loss 3200.9957003653944
INFO:root:current train perplexity3.5329666137695312
INFO:root:current mean train loss 3200.9661427195097
INFO:root:current train perplexity3.532679319381714


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.03s/it]
INFO:root:final mean train loss: 3198.601255724507
INFO:root:final train perplexity: 3.5322694778442383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4136.469988018063
INFO:root:eval perplexity: 5.326354503631592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [10:16:57<1:29:46, 192.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.805426432292
INFO:root:current train perplexity3.5324132442474365
INFO:root:current mean train loss 3189.202709263393
INFO:root:current train perplexity3.524076461791992
INFO:root:current mean train loss 3199.342520419034
INFO:root:current train perplexity3.5282249450683594
INFO:root:current mean train loss 3195.225619140625
INFO:root:current train perplexity3.5248239040374756
INFO:root:current mean train loss 3195.603230879934
INFO:root:current train perplexity3.5254387855529785
INFO:root:current mean train loss 3197.155792289402
INFO:root:current train perplexity3.5257761478424072
INFO:root:current mean train loss 3195.851771556713
INFO:root:current train perplexity3.527395486831665
INFO:root:current mean train loss 3197.6343381426414
INFO:root:current train perplexity3.5284717082977295
INFO:root:current mean train loss 3199.6915220424107
INFO:root:current train perplexity3.5292294025421143
INFO:root:current mean train loss 3198.7561653645835
INFO:root:current train perplexity3.528336763381958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.81s/it]
INFO:root:final mean train loss: 3195.7827708336613
INFO:root:final train perplexity: 3.5283443927764893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4135.931136760306
INFO:root:eval perplexity: 5.325194358825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [10:20:10<1:26:31, 192.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.263513036521
INFO:root:current train perplexity3.5459909439086914
INFO:root:current mean train loss 3198.0328655972507
INFO:root:current train perplexity3.522844076156616
INFO:root:current mean train loss 3194.9020582003645
INFO:root:current train perplexity3.5240671634674072
INFO:root:current mean train loss 3195.3392184185295
INFO:root:current train perplexity3.519319534301758
INFO:root:current mean train loss 3203.444534080616
INFO:root:current train perplexity3.525240659713745
INFO:root:current mean train loss 3197.296952890491
INFO:root:current train perplexity3.5235438346862793
INFO:root:current mean train loss 3196.520198615369
INFO:root:current train perplexity3.523994207382202
INFO:root:current mean train loss 3198.0580515270794
INFO:root:current train perplexity3.5259687900543213
INFO:root:current mean train loss 3199.22547893589
INFO:root:current train perplexity3.527449369430542
INFO:root:current mean train loss 3197.3848545388796
INFO:root:current train perplexity3.5270192623138428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.10s/it]
INFO:root:final mean train loss: 3194.9328412702007
INFO:root:final train perplexity: 3.5271613597869873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it]
INFO:root:eval mean loss: 4137.160322473404
INFO:root:eval perplexity: 5.327841758728027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [10:23:21<1:23:16, 192.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.0840729095125
INFO:root:current train perplexity3.5159316062927246
INFO:root:current mean train loss 3176.174995142752
INFO:root:current train perplexity3.5076656341552734
INFO:root:current mean train loss 3184.4857777598795
INFO:root:current train perplexity3.5129499435424805
INFO:root:current mean train loss 3189.7768236243205
INFO:root:current train perplexity3.516883611679077
INFO:root:current mean train loss 3186.138887176203
INFO:root:current train perplexity3.5122289657592773
INFO:root:current mean train loss 3187.5431360544894
INFO:root:current train perplexity3.5123038291931152
INFO:root:current mean train loss 3190.319976850805
INFO:root:current train perplexity3.5154953002929688
INFO:root:current mean train loss 3190.807777067201
INFO:root:current train perplexity3.5166730880737305
INFO:root:current mean train loss 3193.6364472086316
INFO:root:current train perplexity3.520221710205078
INFO:root:current mean train loss 3194.5229805061963
INFO:root:current train perplexity3.5231313705444336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.86s/it]
INFO:root:final mean train loss: 3191.994614816481
INFO:root:final train perplexity: 3.5230751037597656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4138.108703180408
INFO:root:eval perplexity: 5.3298845291137695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [10:26:34<1:20:03, 192.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3184.2816100457703
INFO:root:current train perplexity3.519709348678589
INFO:root:current mean train loss 3185.226415279523
INFO:root:current train perplexity3.5123238563537598
INFO:root:current mean train loss 3186.927357140991
INFO:root:current train perplexity3.5142481327056885
INFO:root:current mean train loss 3189.6702957344532
INFO:root:current train perplexity3.517376661300659
INFO:root:current mean train loss 3191.1302027883894
INFO:root:current train perplexity3.519094705581665
INFO:root:current mean train loss 3192.6061648972245
INFO:root:current train perplexity3.5225677490234375
INFO:root:current mean train loss 3193.268133815607
INFO:root:current train perplexity3.520632028579712
INFO:root:current mean train loss 3191.880257731833
INFO:root:current train perplexity3.520043134689331
INFO:root:current mean train loss 3192.416807520509
INFO:root:current train perplexity3.5210113525390625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.76s/it]
INFO:root:final mean train loss: 3192.2065363237934
INFO:root:final train perplexity: 3.523369550704956
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it]
INFO:root:eval mean loss: 4139.083904726285
INFO:root:eval perplexity: 5.331986904144287
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [10:29:45<1:16:45, 191.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3169.6103515625
INFO:root:current train perplexity3.424834728240967
INFO:root:current mean train loss 3201.308383834696
INFO:root:current train perplexity3.5138237476348877
INFO:root:current mean train loss 3191.6859714673915
INFO:root:current train perplexity3.5076916217803955
INFO:root:current mean train loss 3188.061158419432
INFO:root:current train perplexity3.508856773376465
INFO:root:current mean train loss 3188.8644203729655
INFO:root:current train perplexity3.5067684650421143
INFO:root:current mean train loss 3186.9562473033775
INFO:root:current train perplexity3.5083460807800293
INFO:root:current mean train loss 3187.029740913303
INFO:root:current train perplexity3.511798620223999
INFO:root:current mean train loss 3188.156668526786
INFO:root:current train perplexity3.5151994228363037
INFO:root:current mean train loss 3189.7749616393667
INFO:root:current train perplexity3.517106294631958
INFO:root:current mean train loss 3193.092696184623
INFO:root:current train perplexity3.5217196941375732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.15s/it]
INFO:root:final mean train loss: 3190.1376168650963
INFO:root:final train perplexity: 3.5204946994781494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it]
INFO:root:eval mean loss: 4138.767422290559
INFO:root:eval perplexity: 5.331305027008057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [10:32:57<1:13:37, 192.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.186669921875
INFO:root:current train perplexity3.492870330810547
INFO:root:current mean train loss 3179.8442064368205
INFO:root:current train perplexity3.488936424255371
INFO:root:current mean train loss 3186.3216671965843
INFO:root:current train perplexity3.516883611679077
INFO:root:current mean train loss 3185.1198071676586
INFO:root:current train perplexity3.5192654132843018
INFO:root:current mean train loss 3187.205163427146
INFO:root:current train perplexity3.515324831008911
INFO:root:current mean train loss 3186.558219717081
INFO:root:current train perplexity3.513338565826416
INFO:root:current mean train loss 3189.17900509718
INFO:root:current train perplexity3.514097213745117
INFO:root:current mean train loss 3192.091058989838
INFO:root:current train perplexity3.517167806625366
INFO:root:current mean train loss 3192.3041842407974
INFO:root:current train perplexity3.517439126968384
INFO:root:current mean train loss 3190.946884071892
INFO:root:current train perplexity3.5185647010803223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.99s/it]
INFO:root:final mean train loss: 3188.6021625149633
INFO:root:final train perplexity: 3.5183629989624023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4139.1413020140735
INFO:root:eval perplexity: 5.332111358642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [10:36:10<1:10:26, 192.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.847942849864
INFO:root:current train perplexity3.518800973892212
INFO:root:current mean train loss 3202.704605722815
INFO:root:current train perplexity3.511512279510498
INFO:root:current mean train loss 3196.3507786224777
INFO:root:current train perplexity3.506948709487915
INFO:root:current mean train loss 3196.491910857682
INFO:root:current train perplexity3.5098774433135986
INFO:root:current mean train loss 3198.655060463763
INFO:root:current train perplexity3.5133228302001953
INFO:root:current mean train loss 3194.5003827826245
INFO:root:current train perplexity3.5154287815093994
INFO:root:current mean train loss 3192.8366522873193
INFO:root:current train perplexity3.5144567489624023
INFO:root:current mean train loss 3189.389929047264
INFO:root:current train perplexity3.514680862426758
INFO:root:current mean train loss 3188.068389336365
INFO:root:current train perplexity3.5135815143585205
INFO:root:current mean train loss 3188.435823021059
INFO:root:current train perplexity3.5163228511810303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.03s/it]
INFO:root:final mean train loss: 3187.3351116795693
INFO:root:final train perplexity: 3.5166049003601074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]
INFO:root:eval mean loss: 4139.749338569371
INFO:root:eval perplexity: 5.333423137664795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [10:39:21<1:07:11, 191.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3165.523878528226
INFO:root:current train perplexity3.5053763389587402
INFO:root:current mean train loss 3181.2971750506917
INFO:root:current train perplexity3.5115771293640137
INFO:root:current mean train loss 3179.118056260146
INFO:root:current train perplexity3.5166800022125244
INFO:root:current mean train loss 3179.9660733041446
INFO:root:current train perplexity3.5163960456848145
INFO:root:current mean train loss 3181.652241788718
INFO:root:current train perplexity3.513920307159424
INFO:root:current mean train loss 3183.9761726106403
INFO:root:current train perplexity3.511835813522339
INFO:root:current mean train loss 3186.1316784648625
INFO:root:current train perplexity3.514984607696533
INFO:root:current mean train loss 3188.303629111983
INFO:root:current train perplexity3.516489267349243
INFO:root:current mean train loss 3188.9048207050055
INFO:root:current train perplexity3.515347957611084
INFO:root:current mean train loss 3188.0470666936594
INFO:root:current train perplexity3.5146899223327637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.72s/it]
INFO:root:final mean train loss: 3186.7976955290765
INFO:root:final train perplexity: 3.5158591270446777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4140.906714040337
INFO:root:eval perplexity: 5.3359198570251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [10:42:34<1:04:01, 192.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.8924341446314
INFO:root:current train perplexity3.533776044845581
INFO:root:current mean train loss 3180.86586316884
INFO:root:current train perplexity3.5139384269714355
INFO:root:current mean train loss 3179.214100091527
INFO:root:current train perplexity3.510669708251953
INFO:root:current mean train loss 3185.114633025673
INFO:root:current train perplexity3.5102996826171875
INFO:root:current mean train loss 3183.386399531962
INFO:root:current train perplexity3.5105135440826416
INFO:root:current mean train loss 3182.9486326313195
INFO:root:current train perplexity3.509037971496582
INFO:root:current mean train loss 3182.7241505128864
INFO:root:current train perplexity3.5086278915405273
INFO:root:current mean train loss 3185.9959100663905
INFO:root:current train perplexity3.511251449584961
INFO:root:current mean train loss 3187.3315359849894
INFO:root:current train perplexity3.513580799102783
INFO:root:current mean train loss 3187.0411635653786
INFO:root:current train perplexity3.512211799621582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.19s/it]
INFO:root:final mean train loss: 3184.9103314799645
INFO:root:final train perplexity: 3.513241767883301
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4141.725856050532
INFO:root:eval perplexity: 5.337687015533447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [10:45:46<1:00:52, 192.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.0531239611037
INFO:root:current train perplexity3.487426996231079
INFO:root:current mean train loss 3182.7186071694305
INFO:root:current train perplexity3.51369047164917
INFO:root:current mean train loss 3184.9059801603617
INFO:root:current train perplexity3.5097365379333496
INFO:root:current mean train loss 3191.2140662993065
INFO:root:current train perplexity3.514458417892456
INFO:root:current mean train loss 3187.7265439300195
INFO:root:current train perplexity3.5107905864715576
INFO:root:current mean train loss 3186.8092743979946
INFO:root:current train perplexity3.51283860206604
INFO:root:current mean train loss 3189.661536946363
INFO:root:current train perplexity3.51387357711792
INFO:root:current mean train loss 3188.1170387931934
INFO:root:current train perplexity3.51367449760437
INFO:root:current mean train loss 3188.4345524415216
INFO:root:current train perplexity3.5141890048980713
INFO:root:current mean train loss 3188.5945334671164
INFO:root:current train perplexity3.514648914337158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.40s/it]
INFO:root:final mean train loss: 3185.288357334752
INFO:root:final train perplexity: 3.513765811920166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it]
INFO:root:eval mean loss: 4141.068063289561
INFO:root:eval perplexity: 5.33626651763916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [10:48:58<57:38, 192.13s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3181.1744895241477
INFO:root:current train perplexity3.529258966445923
INFO:root:current mean train loss 3175.8468686995966
INFO:root:current train perplexity3.519765853881836
INFO:root:current mean train loss 3175.0917710248164
INFO:root:current train perplexity3.5060465335845947
INFO:root:current mean train loss 3181.4890184859155
INFO:root:current train perplexity3.507878065109253
INFO:root:current mean train loss 3184.171502618475
INFO:root:current train perplexity3.5070979595184326
INFO:root:current mean train loss 3181.902219260276
INFO:root:current train perplexity3.509666681289673
INFO:root:current mean train loss 3183.5604548097567
INFO:root:current train perplexity3.508483648300171
INFO:root:current mean train loss 3185.0635823028765
INFO:root:current train perplexity3.511627674102783
INFO:root:current mean train loss 3186.0684384708516
INFO:root:current train perplexity3.5111594200134277
INFO:root:current mean train loss 3187.076784910831
INFO:root:current train perplexity3.5117316246032715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.52s/it]
INFO:root:final mean train loss: 3183.963716199321
INFO:root:final train perplexity: 3.511930465698242
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4141.511725675975
INFO:root:eval perplexity: 5.337224006652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [10:52:11<54:29, 192.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3176.4113963293653
INFO:root:current train perplexity3.5188803672790527
INFO:root:current mean train loss 3192.375281585506
INFO:root:current train perplexity3.5121798515319824
INFO:root:current mean train loss 3185.20073836294
INFO:root:current train perplexity3.510936975479126
INFO:root:current mean train loss 3185.1668993737085
INFO:root:current train perplexity3.5128185749053955
INFO:root:current mean train loss 3184.259044276458
INFO:root:current train perplexity3.5111048221588135
INFO:root:current mean train loss 3181.9519654404417
INFO:root:current train perplexity3.5089659690856934
INFO:root:current mean train loss 3184.140726264965
INFO:root:current train perplexity3.5095343589782715
INFO:root:current mean train loss 3185.5237184377047
INFO:root:current train perplexity3.5085108280181885
INFO:root:current mean train loss 3183.374294170499
INFO:root:current train perplexity3.508528709411621
INFO:root:current mean train loss 3183.6061981296243
INFO:root:current train perplexity3.50951886177063


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it]
INFO:root:final mean train loss: 3182.5275497436523
INFO:root:final train perplexity: 3.5099406242370605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 4142.088458554965
INFO:root:eval perplexity: 5.338469505310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [10:55:23<51:15, 192.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.4754655864876
INFO:root:current train perplexity3.5119051933288574
INFO:root:current mean train loss 3192.2351873743605
INFO:root:current train perplexity3.507058620452881
INFO:root:current mean train loss 3190.4360603811115
INFO:root:current train perplexity3.507179021835327
INFO:root:current mean train loss 3186.6197835505814
INFO:root:current train perplexity3.5053577423095703
INFO:root:current mean train loss 3185.1959236290804
INFO:root:current train perplexity3.504572629928589
INFO:root:current mean train loss 3184.499963229258
INFO:root:current train perplexity3.5047218799591064
INFO:root:current mean train loss 3184.3431056288423
INFO:root:current train perplexity3.5067245960235596
INFO:root:current mean train loss 3183.159834212366
INFO:root:current train perplexity3.5075185298919678
INFO:root:current mean train loss 3186.248387999157
INFO:root:current train perplexity3.508291244506836
INFO:root:current mean train loss 3185.1501630788975
INFO:root:current train perplexity3.5093131065368652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.84s/it]
INFO:root:final mean train loss: 3181.790600130635
INFO:root:final train perplexity: 3.508920431137085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.48s/it]
INFO:root:eval mean loss: 4143.184501052749
INFO:root:eval perplexity: 5.3408355712890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [10:58:34<47:58, 191.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3171.7433093107197
INFO:root:current train perplexity3.4909346103668213
INFO:root:current mean train loss 3168.2873821578214
INFO:root:current train perplexity3.500882863998413
INFO:root:current mean train loss 3171.085756363407
INFO:root:current train perplexity3.507791042327881
INFO:root:current mean train loss 3175.9539289248023
INFO:root:current train perplexity3.505040168762207
INFO:root:current mean train loss 3178.655428382698
INFO:root:current train perplexity3.5053374767303467
INFO:root:current mean train loss 3180.8851349983806
INFO:root:current train perplexity3.5044286251068115
INFO:root:current mean train loss 3182.681782291283
INFO:root:current train perplexity3.5064048767089844
INFO:root:current mean train loss 3182.9747018287667
INFO:root:current train perplexity3.5076024532318115
INFO:root:current mean train loss 3184.652723709471
INFO:root:current train perplexity3.508356809616089
INFO:root:current mean train loss 3183.2468443764365
INFO:root:current train perplexity3.506908893585205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.39s/it]
INFO:root:final mean train loss: 3180.237612262849
INFO:root:final train perplexity: 3.5067708492279053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 4143.632893880208
INFO:root:eval perplexity: 5.3418049812316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [11:01:45<44:45, 191.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.364083827227
INFO:root:current train perplexity3.5221738815307617
INFO:root:current mean train loss 3182.683131580047
INFO:root:current train perplexity3.513284206390381
INFO:root:current mean train loss 3184.775112457807
INFO:root:current train perplexity3.505779504776001
INFO:root:current mean train loss 3185.9130310531737
INFO:root:current train perplexity3.505094051361084
INFO:root:current mean train loss 3187.289405399769
INFO:root:current train perplexity3.5056889057159424
INFO:root:current mean train loss 3184.924131325197
INFO:root:current train perplexity3.506171464920044
INFO:root:current mean train loss 3186.838726460153
INFO:root:current train perplexity3.508009433746338
INFO:root:current mean train loss 3184.991382177176
INFO:root:current train perplexity3.507826328277588
INFO:root:current mean train loss 3183.0776758032694
INFO:root:current train perplexity3.50657320022583
INFO:root:current mean train loss 3182.47744655126
INFO:root:current train perplexity3.506436586380005


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it]
INFO:root:final mean train loss: 3179.5475957932013
INFO:root:final train perplexity: 3.5058162212371826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it]
INFO:root:eval mean loss: 4143.432205091977
INFO:root:eval perplexity: 5.341371059417725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [11:04:58<41:35, 191.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3185.0194798519738
INFO:root:current train perplexity3.4932925701141357
INFO:root:current mean train loss 3180.5927734375
INFO:root:current train perplexity3.500727891921997
INFO:root:current mean train loss 3178.8125811043433
INFO:root:current train perplexity3.5005576610565186
INFO:root:current mean train loss 3177.1912535848496
INFO:root:current train perplexity3.5003116130828857
INFO:root:current mean train loss 3175.2657029277148
INFO:root:current train perplexity3.4982712268829346
INFO:root:current mean train loss 3179.5805270154938
INFO:root:current train perplexity3.5039587020874023
INFO:root:current mean train loss 3182.7984171256744
INFO:root:current train perplexity3.5061159133911133
INFO:root:current mean train loss 3181.8852821590017
INFO:root:current train perplexity3.504852771759033
INFO:root:current mean train loss 3180.724563547486
INFO:root:current train perplexity3.504594564437866


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it]
INFO:root:final mean train loss: 3178.1406314603746
INFO:root:final train perplexity: 3.503870964050293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4143.279764378324
INFO:root:eval perplexity: 5.341041564941406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [11:08:10<38:24, 192.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3144.6539713541665
INFO:root:current train perplexity3.442741632461548
INFO:root:current mean train loss 3172.5663209192962
INFO:root:current train perplexity3.4787182807922363
INFO:root:current mean train loss 3169.14596963516
INFO:root:current train perplexity3.485311269760132
INFO:root:current mean train loss 3173.773439111489
INFO:root:current train perplexity3.4931626319885254
INFO:root:current mean train loss 3171.826680753722
INFO:root:current train perplexity3.4942305088043213
INFO:root:current mean train loss 3174.0139373718625
INFO:root:current train perplexity3.498615264892578
INFO:root:current mean train loss 3172.1073963677704
INFO:root:current train perplexity3.4995884895324707
INFO:root:current mean train loss 3174.4293916140646
INFO:root:current train perplexity3.4975574016571045
INFO:root:current mean train loss 3174.8294168474667
INFO:root:current train perplexity3.498056411743164
INFO:root:current mean train loss 3179.556222098214
INFO:root:current train perplexity3.500617742538452


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.04s/it]
INFO:root:final mean train loss: 3175.9691872135286
INFO:root:final train perplexity: 3.500870704650879
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it]
INFO:root:eval mean loss: 4143.741995304189
INFO:root:eval perplexity: 5.342040538787842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [11:11:22<35:11, 191.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3153.794500177557
INFO:root:current train perplexity3.5000290870666504
INFO:root:current mean train loss 3160.876909135698
INFO:root:current train perplexity3.488290548324585
INFO:root:current mean train loss 3176.471617206013
INFO:root:current train perplexity3.496511936187744
INFO:root:current mean train loss 3178.460630557928
INFO:root:current train perplexity3.4991722106933594
INFO:root:current mean train loss 3175.686638082611
INFO:root:current train perplexity3.5019495487213135
INFO:root:current mean train loss 3174.4062476111485
INFO:root:current train perplexity3.5008034706115723
INFO:root:current mean train loss 3172.0235078252863
INFO:root:current train perplexity3.497560739517212
INFO:root:current mean train loss 3174.2741105177565
INFO:root:current train perplexity3.499725341796875
INFO:root:current mean train loss 3174.1088114596178
INFO:root:current train perplexity3.4980831146240234
INFO:root:current mean train loss 3177.6312337596905
INFO:root:current train perplexity3.5004703998565674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.25s/it]
INFO:root:final mean train loss: 3176.6114402278777
INFO:root:final train perplexity: 3.501758098602295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it]
INFO:root:eval mean loss: 4144.60602975399
INFO:root:eval perplexity: 5.343906402587891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [11:14:33<31:58, 191.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3167.2513234991775
INFO:root:current train perplexity3.5172743797302246
INFO:root:current mean train loss 3196.860893185399
INFO:root:current train perplexity3.5108718872070312
INFO:root:current mean train loss 3190.7009143568066
INFO:root:current train perplexity3.504361391067505
INFO:root:current mean train loss 3190.384702867849
INFO:root:current train perplexity3.5055298805236816
INFO:root:current mean train loss 3182.237078027111
INFO:root:current train perplexity3.5029704570770264
INFO:root:current mean train loss 3181.3252075430514
INFO:root:current train perplexity3.500941753387451
INFO:root:current mean train loss 3178.4460816021306
INFO:root:current train perplexity3.500187635421753
INFO:root:current mean train loss 3177.952239778012
INFO:root:current train perplexity3.4999191761016846
INFO:root:current mean train loss 3176.1053760421437
INFO:root:current train perplexity3.4998111724853516
INFO:root:current mean train loss 3177.1157582545566
INFO:root:current train perplexity3.4999263286590576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.82s/it]
INFO:root:final mean train loss: 3175.957934656451
INFO:root:final train perplexity: 3.5008552074432373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4144.5384893755545
INFO:root:eval perplexity: 5.343761444091797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [11:17:46<28:47, 191.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.372612847222
INFO:root:current train perplexity3.506788969039917
INFO:root:current mean train loss 3193.0236604945867
INFO:root:current train perplexity3.4964654445648193
INFO:root:current mean train loss 3185.28028957014
INFO:root:current train perplexity3.4991884231567383
INFO:root:current mean train loss 3184.1567950234135
INFO:root:current train perplexity3.498872995376587
INFO:root:current mean train loss 3181.1894365440207
INFO:root:current train perplexity3.499230146408081
INFO:root:current mean train loss 3183.0555834543998
INFO:root:current train perplexity3.4986796379089355
INFO:root:current mean train loss 3178.9902176317037
INFO:root:current train perplexity3.497868061065674
INFO:root:current mean train loss 3176.804477948762
INFO:root:current train perplexity3.496739387512207
INFO:root:current mean train loss 3175.183795084832
INFO:root:current train perplexity3.4967164993286133
INFO:root:current mean train loss 3175.8958846897754
INFO:root:current train perplexity3.4977633953094482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:00<00:00, 180.09s/it]
INFO:root:final mean train loss: 3174.9995147951186
INFO:root:final train perplexity: 3.4995317459106445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.55s/it]
INFO:root:eval mean loss: 4144.143407510527
INFO:root:eval perplexity: 5.342907905578613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [11:20:58<25:36, 192.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3170.508705357143
INFO:root:current train perplexity3.5131044387817383
INFO:root:current mean train loss 3176.025681785301
INFO:root:current train perplexity3.497392177581787
INFO:root:current mean train loss 3172.958541805186
INFO:root:current train perplexity3.49930477142334
INFO:root:current mean train loss 3177.1650667560634
INFO:root:current train perplexity3.5031633377075195
INFO:root:current mean train loss 3180.0928043058548
INFO:root:current train perplexity3.5014357566833496
INFO:root:current mean train loss 3174.7190758250586
INFO:root:current train perplexity3.4967727661132812
INFO:root:current mean train loss 3175.8765736497294
INFO:root:current train perplexity3.4984676837921143
INFO:root:current mean train loss 3173.945122169962
INFO:root:current train perplexity3.4978036880493164
INFO:root:current mean train loss 3173.9241947745136
INFO:root:current train perplexity3.4966368675231934
INFO:root:current mean train loss 3174.7699983810994
INFO:root:current train perplexity3.496997117996216


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.41s/it]
INFO:root:final mean train loss: 3173.8169391385973
INFO:root:final train perplexity: 3.4978997707366943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 4144.47399815769
INFO:root:eval perplexity: 5.34362268447876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [11:24:10<22:23, 191.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.9272688045057
INFO:root:current train perplexity3.5339138507843018
INFO:root:current mean train loss 3182.872906878278
INFO:root:current train perplexity3.5196642875671387
INFO:root:current mean train loss 3180.130929703575
INFO:root:current train perplexity3.5065765380859375
INFO:root:current mean train loss 3175.836413680986
INFO:root:current train perplexity3.5066752433776855
INFO:root:current mean train loss 3179.4307461775184
INFO:root:current train perplexity3.503190279006958
INFO:root:current mean train loss 3178.700708772157
INFO:root:current train perplexity3.500328540802002
INFO:root:current mean train loss 3177.6488152914803
INFO:root:current train perplexity3.5004208087921143
INFO:root:current mean train loss 3176.4202573629923
INFO:root:current train perplexity3.4983835220336914
INFO:root:current mean train loss 3178.7427707730944
INFO:root:current train perplexity3.499311923980713
INFO:root:current mean train loss 3178.5172560561373
INFO:root:current train perplexity3.499048948287964


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:58<00:00, 178.83s/it]
INFO:root:final mean train loss: 3174.827474286479
INFO:root:final train perplexity: 3.4992942810058594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 4144.391430144615
INFO:root:eval perplexity: 5.343442916870117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [11:27:21<19:10, 191.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3147.505007276348
INFO:root:current train perplexity3.4684131145477295
INFO:root:current mean train loss 3163.1811588110513
INFO:root:current train perplexity3.484501600265503
INFO:root:current mean train loss 3167.2747797871016
INFO:root:current train perplexity3.4933083057403564
INFO:root:current mean train loss 3166.8500635739406
INFO:root:current train perplexity3.4919164180755615
INFO:root:current mean train loss 3170.147186482296
INFO:root:current train perplexity3.493410110473633
INFO:root:current mean train loss 3173.121661343722
INFO:root:current train perplexity3.4970507621765137
INFO:root:current mean train loss 3176.9173285840293
INFO:root:current train perplexity3.500044107437134
INFO:root:current mean train loss 3175.0702289525425
INFO:root:current train perplexity3.4988739490509033
INFO:root:current mean train loss 3175.9475748889176
INFO:root:current train perplexity3.499310255050659
INFO:root:current mean train loss 3176.608847440605
INFO:root:current train perplexity3.4995179176330566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.07s/it]
INFO:root:final mean train loss: 3174.0248402626285
INFO:root:final train perplexity: 3.4981861114501953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 4144.603700894836
INFO:root:eval perplexity: 5.343902111053467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [11:30:32<15:58, 191.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.9980096332097
INFO:root:current train perplexity3.5178871154785156
INFO:root:current mean train loss 3187.8717939268868
INFO:root:current train perplexity3.508141040802002
INFO:root:current mean train loss 3186.936333969293
INFO:root:current train perplexity3.5026636123657227
INFO:root:current mean train loss 3182.5658506430623
INFO:root:current train perplexity3.4988038539886475
INFO:root:current mean train loss 3178.9119631033836
INFO:root:current train perplexity3.4973185062408447
INFO:root:current mean train loss 3173.492270918353
INFO:root:current train perplexity3.495297908782959
INFO:root:current mean train loss 3172.2400417298936
INFO:root:current train perplexity3.495389938354492
INFO:root:current mean train loss 3173.3156593533845
INFO:root:current train perplexity3.496293306350708
INFO:root:current mean train loss 3174.9482313873327
INFO:root:current train perplexity3.4957778453826904
INFO:root:current mean train loss 3175.092497729161
INFO:root:current train perplexity3.4963226318359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.68s/it]
INFO:root:final mean train loss: 3172.990935848605
INFO:root:final train perplexity: 3.4967598915100098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it]
INFO:root:eval mean loss: 4144.440687680075
INFO:root:eval perplexity: 5.343550682067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [11:33:44<12:47, 191.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3185.638577133862
INFO:root:current train perplexity3.5026957988739014
INFO:root:current mean train loss 3175.470073037519
INFO:root:current train perplexity3.4994215965270996
INFO:root:current mean train loss 3178.312925188729
INFO:root:current train perplexity3.497208833694458
INFO:root:current mean train loss 3177.2442663540955
INFO:root:current train perplexity3.494642972946167
INFO:root:current mean train loss 3179.084585577824
INFO:root:current train perplexity3.497107982635498
INFO:root:current mean train loss 3179.077759004354
INFO:root:current train perplexity3.4983534812927246
INFO:root:current mean train loss 3176.367423221983
INFO:root:current train perplexity3.4968864917755127
INFO:root:current mean train loss 3176.9051317913745
INFO:root:current train perplexity3.4984700679779053
INFO:root:current mean train loss 3175.877728630515
INFO:root:current train perplexity3.497802495956421
INFO:root:current mean train loss 3174.742608876115
INFO:root:current train perplexity3.496589422225952


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.35s/it]
INFO:root:final mean train loss: 3172.546140609249
INFO:root:final train perplexity: 3.4961462020874023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it]
INFO:root:eval mean loss: 4145.199423066268
INFO:root:eval perplexity: 5.345189094543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [11:36:56<09:35, 191.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3174.1034602864584
INFO:root:current train perplexity3.4947304725646973
INFO:root:current mean train loss 3173.6198604910714
INFO:root:current train perplexity3.491175651550293
INFO:root:current mean train loss 3172.083994140625
INFO:root:current train perplexity3.493757724761963
INFO:root:current mean train loss 3169.3737154947917
INFO:root:current train perplexity3.492814540863037
INFO:root:current mean train loss 3173.1751336348684
INFO:root:current train perplexity3.4924163818359375
INFO:root:current mean train loss 3174.9153664232335
INFO:root:current train perplexity3.4928340911865234
INFO:root:current mean train loss 3176.6994741030094
INFO:root:current train perplexity3.4955687522888184
INFO:root:current mean train loss 3174.0298210685482
INFO:root:current train perplexity3.4940600395202637
INFO:root:current mean train loss 3175.9812555803574
INFO:root:current train perplexity3.4949228763580322
INFO:root:current mean train loss 3175.0438048377405
INFO:root:current train perplexity3.496443510055542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.75s/it]
INFO:root:final mean train loss: 3172.774123714816
INFO:root:final train perplexity: 3.496460437774658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]
INFO:root:eval mean loss: 4144.977843805408
INFO:root:eval perplexity: 5.344710826873779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [11:40:08<06:23, 191.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3164.0106039391944
INFO:root:current train perplexity3.4930098056793213
INFO:root:current mean train loss 3178.4767159217045
INFO:root:current train perplexity3.4971861839294434
INFO:root:current mean train loss 3180.6472590685735
INFO:root:current train perplexity3.5030815601348877
INFO:root:current mean train loss 3176.5949439305236
INFO:root:current train perplexity3.4994406700134277
INFO:root:current mean train loss 3170.629893932777
INFO:root:current train perplexity3.498692750930786
INFO:root:current mean train loss 3174.8138593146978
INFO:root:current train perplexity3.5022523403167725
INFO:root:current mean train loss 3175.1631903138727
INFO:root:current train perplexity3.4981064796447754
INFO:root:current mean train loss 3174.7419673680956
INFO:root:current train perplexity3.4955732822418213
INFO:root:current mean train loss 3174.4313843188174
INFO:root:current train perplexity3.4933180809020996
INFO:root:current mean train loss 3174.3277007963507
INFO:root:current train perplexity3.4945969581604004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.10s/it]
INFO:root:final mean train loss: 3171.2958079922582
INFO:root:final train perplexity: 3.4944217205047607
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4145.09750561004
INFO:root:eval perplexity: 5.344969272613525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [11:43:20<03:11, 191.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3167.853274167239
INFO:root:current train perplexity3.498725414276123
INFO:root:current mean train loss 3167.7135105632365
INFO:root:current train perplexity3.4864606857299805
INFO:root:current mean train loss 3167.032455601643
INFO:root:current train perplexity3.4912259578704834
INFO:root:current mean train loss 3170.177045036765
INFO:root:current train perplexity3.4912068843841553
INFO:root:current mean train loss 3172.5595628540286
INFO:root:current train perplexity3.4935548305511475
INFO:root:current mean train loss 3172.649953154743
INFO:root:current train perplexity3.4964675903320312
INFO:root:current mean train loss 3172.0865939591627
INFO:root:current train perplexity3.4954640865325928
INFO:root:current mean train loss 3173.7929243046774
INFO:root:current train perplexity3.495349168777466
INFO:root:current mean train loss 3174.8293706378017
INFO:root:current train perplexity3.4961822032928467
INFO:root:current mean train loss 3174.4601582701343
INFO:root:current train perplexity3.4953153133392334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:59<00:00, 179.44s/it]
INFO:root:final mean train loss: 3171.9060197645617
INFO:root:final train perplexity: 3.4952635765075684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4145.071993780474
INFO:root:eval perplexity: 5.344913482666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_330/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [11:46:31<00:00, 191.72s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [11:46:31<00:00, 211.96s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
INFO:root:eval mean loss: 4145.071993780474
INFO:root:eval perplexity: 5.344913482666016
INFO:root:evalaution complete
INFO:root:save model final: small_val_330/final
