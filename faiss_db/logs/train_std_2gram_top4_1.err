INFO:root:Output: std_24_1
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12227.37767321654
INFO:root:current train perplexity16558.01171875
INFO:root:current mean train loss 10547.102168557632
INFO:root:current train perplexity4121.7763671875
INFO:root:current mean train loss 9177.722386797137
INFO:root:current train perplexity1388.58837890625
INFO:root:current mean train loss 8229.565684230107
INFO:root:current train perplexity656.728271484375
INFO:root:current mean train loss 7537.813632147107
INFO:root:current train perplexity381.364501953125
INFO:root:current mean train loss 7012.68486866131
INFO:root:current train perplexity252.0005645751953
INFO:root:current mean train loss 6603.272932803
INFO:root:current train perplexity181.88661193847656
INFO:root:current mean train loss 6277.908619600184
INFO:root:current train perplexity140.26820373535156
INFO:root:current mean train loss 6001.317190270005
INFO:root:current train perplexity113.34630584716797
INFO:root:current mean train loss 5777.388198256851
INFO:root:current train perplexity94.50521850585938
INFO:root:current mean train loss 5578.406362184727
INFO:root:current train perplexity80.96930694580078
INFO:root:current mean train loss 5409.02201256581
INFO:root:current train perplexity70.88780212402344
INFO:root:current mean train loss 5262.645720002466
INFO:root:current train perplexity62.98704528808594
INFO:root:current mean train loss 5126.918933445765
INFO:root:current train perplexity56.739532470703125
INFO:root:current mean train loss 5008.313678520055
INFO:root:current train perplexity51.74722671508789
INFO:root:current mean train loss 4901.782760954112
INFO:root:current train perplexity47.604087829589844
INFO:root:current mean train loss 4806.0645603227085
INFO:root:current train perplexity44.11207962036133
INFO:root:current mean train loss 4717.502770772174
INFO:root:current train perplexity41.18381118774414
INFO:root:current mean train loss 4634.940275026535
INFO:root:current train perplexity38.647518157958984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.95s/it]
INFO:root:final mean train loss: 4570.790003112393
INFO:root:final train perplexity: 36.77433776855469
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.04s/it]
INFO:root:eval mean loss: 3472.72338793872
INFO:root:eval perplexity: 17.281269073486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/1
  1%|          | 1/100 [05:50<9:38:10, 350.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3100.466812133789
INFO:root:current train perplexity11.449579238891602
INFO:root:current mean train loss 3096.4633010338093
INFO:root:current train perplexity11.518830299377441
INFO:root:current mean train loss 3076.8614908854165
INFO:root:current train perplexity11.44012451171875
INFO:root:current mean train loss 3075.982315256626
INFO:root:current train perplexity11.423757553100586
INFO:root:current mean train loss 3069.2821103609526
INFO:root:current train perplexity11.331568717956543
INFO:root:current mean train loss 3059.7786373168
INFO:root:current train perplexity11.196649551391602
INFO:root:current mean train loss 3042.1005692915483
INFO:root:current train perplexity11.068471908569336
INFO:root:current mean train loss 3031.230546493104
INFO:root:current train perplexity10.968140602111816
INFO:root:current mean train loss 3022.5010773901845
INFO:root:current train perplexity10.891852378845215
INFO:root:current mean train loss 3016.8472420638304
INFO:root:current train perplexity10.818292617797852
INFO:root:current mean train loss 3004.4136650505966
INFO:root:current train perplexity10.732852935791016
INFO:root:current mean train loss 2996.0804318663895
INFO:root:current train perplexity10.641265869140625
INFO:root:current mean train loss 2988.937491768285
INFO:root:current train perplexity10.565943717956543
INFO:root:current mean train loss 2980.198746052194
INFO:root:current train perplexity10.485603332519531
INFO:root:current mean train loss 2971.252764858095
INFO:root:current train perplexity10.414422035217285
INFO:root:current mean train loss 2963.4713542203476
INFO:root:current train perplexity10.343887329101562
INFO:root:current mean train loss 2954.4115697275292
INFO:root:current train perplexity10.272710800170898
INFO:root:current mean train loss 2947.01127969524
INFO:root:current train perplexity10.210824966430664
INFO:root:current mean train loss 2936.979658488135
INFO:root:current train perplexity10.141373634338379
INFO:root:current mean train loss 2929.2770480034496
INFO:root:current train perplexity10.073079109191895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.60s/it]
INFO:root:final mean train loss: 2923.735260456064
INFO:root:final train perplexity: 10.032537460327148
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.22s/it]
INFO:root:eval mean loss: 3221.5373865076012
INFO:root:eval perplexity: 14.062424659729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/2
  2%|â–         | 2/100 [11:40<9:32:26, 350.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2805.072576349432
INFO:root:current train perplexity9.111245155334473
INFO:root:current mean train loss 2750.7187940554513
INFO:root:current train perplexity8.826478004455566
INFO:root:current mean train loss 2749.0882898420737
INFO:root:current train perplexity8.794914245605469
INFO:root:current mean train loss 2737.463887715841
INFO:root:current train perplexity8.7286958694458
INFO:root:current mean train loss 2740.2540720175375
INFO:root:current train perplexity8.696283340454102
INFO:root:current mean train loss 2736.2487183762314
INFO:root:current train perplexity8.6536865234375
INFO:root:current mean train loss 2731.9844914778337
INFO:root:current train perplexity8.614745140075684
INFO:root:current mean train loss 2726.9625915277543
INFO:root:current train perplexity8.584660530090332
INFO:root:current mean train loss 2722.7705620334073
INFO:root:current train perplexity8.555670738220215
INFO:root:current mean train loss 2716.463726930935
INFO:root:current train perplexity8.522526741027832
INFO:root:current mean train loss 2711.7685617777406
INFO:root:current train perplexity8.491796493530273
INFO:root:current mean train loss 2706.9109550402004
INFO:root:current train perplexity8.468666076660156
INFO:root:current mean train loss 2701.8601511810625
INFO:root:current train perplexity8.43913459777832
INFO:root:current mean train loss 2695.72903449251
INFO:root:current train perplexity8.402352333068848
INFO:root:current mean train loss 2694.760092054475
INFO:root:current train perplexity8.385069847106934
INFO:root:current mean train loss 2693.710280565833
INFO:root:current train perplexity8.362383842468262
INFO:root:current mean train loss 2689.66687019194
INFO:root:current train perplexity8.33582592010498
INFO:root:current mean train loss 2686.135840238207
INFO:root:current train perplexity8.307251930236816
INFO:root:current mean train loss 2682.057944573019
INFO:root:current train perplexity8.276249885559082
INFO:root:current mean train loss 2677.5487657321037
INFO:root:current train perplexity8.251792907714844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.68s/it]
INFO:root:final mean train loss: 2673.721262075296
INFO:root:final train perplexity: 8.237174034118652
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it]
INFO:root:eval mean loss: 3104.686452321462
INFO:root:eval perplexity: 12.776683807373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/3
  3%|â–Ž         | 3/100 [17:33<9:27:59, 351.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2605.2368359375
INFO:root:current train perplexity7.758729457855225
INFO:root:current mean train loss 2591.6669580078124
INFO:root:current train perplexity7.713956356048584
INFO:root:current mean train loss 2584.184357421875
INFO:root:current train perplexity7.687206745147705
INFO:root:current mean train loss 2577.1543568638394
INFO:root:current train perplexity7.632774353027344
INFO:root:current mean train loss 2581.0484830729165
INFO:root:current train perplexity7.623515605926514
INFO:root:current mean train loss 2572.9742817826705
INFO:root:current train perplexity7.583549976348877
INFO:root:current mean train loss 2569.392605919471
INFO:root:current train perplexity7.56889009475708
INFO:root:current mean train loss 2566.3658046875
INFO:root:current train perplexity7.553869247436523
INFO:root:current mean train loss 2564.6022087545957
INFO:root:current train perplexity7.552862644195557
INFO:root:current mean train loss 2561.535341282895
INFO:root:current train perplexity7.532331466674805
INFO:root:current mean train loss 2557.9098918805803
INFO:root:current train perplexity7.512411594390869
INFO:root:current mean train loss 2557.344923148777
INFO:root:current train perplexity7.504745960235596
INFO:root:current mean train loss 2554.1688484375
INFO:root:current train perplexity7.490782737731934
INFO:root:current mean train loss 2552.025340802228
INFO:root:current train perplexity7.476888656616211
INFO:root:current mean train loss 2551.3882171841324
INFO:root:current train perplexity7.471163272857666
INFO:root:current mean train loss 2548.4673918693297
INFO:root:current train perplexity7.456917762756348
INFO:root:current mean train loss 2547.1400212328363
INFO:root:current train perplexity7.447052001953125
INFO:root:current mean train loss 2544.634428920201
INFO:root:current train perplexity7.431484222412109
INFO:root:current mean train loss 2543.4412895243877
INFO:root:current train perplexity7.42441463470459
INFO:root:current mean train loss 2541.212080015525
INFO:root:current train perplexity7.414017200469971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.10s/it]
INFO:root:final mean train loss: 2539.59956659191
INFO:root:final train perplexity: 7.410375118255615
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it]
INFO:root:eval mean loss: 3037.4491483671172
INFO:root:eval perplexity: 12.090845108032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/4
  4%|â–         | 4/100 [23:23<9:21:39, 351.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2519.4194445254197
INFO:root:current train perplexity7.14339017868042
INFO:root:current mean train loss 2481.6879517332522
INFO:root:current train perplexity7.047458171844482
INFO:root:current mean train loss 2479.272750797343
INFO:root:current train perplexity7.055545330047607
INFO:root:current mean train loss 2479.6863790818716
INFO:root:current train perplexity7.0651984214782715
INFO:root:current mean train loss 2480.6577258222364
INFO:root:current train perplexity7.076019287109375
INFO:root:current mean train loss 2475.4605990616733
INFO:root:current train perplexity7.041197776794434
INFO:root:current mean train loss 2476.251813302333
INFO:root:current train perplexity7.037957668304443
INFO:root:current mean train loss 2473.3459262574356
INFO:root:current train perplexity7.024033546447754
INFO:root:current mean train loss 2473.673509784773
INFO:root:current train perplexity7.013658046722412
INFO:root:current mean train loss 2470.017519930156
INFO:root:current train perplexity6.997512340545654
INFO:root:current mean train loss 2469.431277617407
INFO:root:current train perplexity6.992745876312256
INFO:root:current mean train loss 2468.688671644876
INFO:root:current train perplexity6.984892845153809
INFO:root:current mean train loss 2465.5082829572502
INFO:root:current train perplexity6.972592830657959
INFO:root:current mean train loss 2465.075181649912
INFO:root:current train perplexity6.9676432609558105
INFO:root:current mean train loss 2462.6667554526402
INFO:root:current train perplexity6.963344573974609
INFO:root:current mean train loss 2460.3319196183743
INFO:root:current train perplexity6.958110332489014
INFO:root:current mean train loss 2456.783145568152
INFO:root:current train perplexity6.942498683929443
INFO:root:current mean train loss 2455.412520075627
INFO:root:current train perplexity6.9313201904296875
INFO:root:current mean train loss 2453.408879251996
INFO:root:current train perplexity6.921135425567627
INFO:root:current mean train loss 2451.4858467943727
INFO:root:current train perplexity6.908736705780029

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.92s/it]
INFO:root:final mean train loss: 2450.5119768951618
INFO:root:final train perplexity: 6.907591342926025
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 3000.8405908349755
INFO:root:eval perplexity: 11.733036994934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/5
  5%|â–Œ         | 5/100 [29:20<9:18:52, 352.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2407.726831345331
INFO:root:current train perplexity6.619027614593506
INFO:root:current mean train loss 2404.6561073634934
INFO:root:current train perplexity6.645503997802734
INFO:root:current mean train loss 2403.116628297618
INFO:root:current train perplexity6.670466899871826
INFO:root:current mean train loss 2404.816813468933
INFO:root:current train perplexity6.676033020019531
INFO:root:current mean train loss 2410.9156698431852
INFO:root:current train perplexity6.68959903717041
INFO:root:current mean train loss 2404.2033672594043
INFO:root:current train perplexity6.654811859130859
INFO:root:current mean train loss 2402.3177293922467
INFO:root:current train perplexity6.6341986656188965
INFO:root:current mean train loss 2402.457703882334
INFO:root:current train perplexity6.641185760498047
INFO:root:current mean train loss 2400.45189987804
INFO:root:current train perplexity6.627570152282715
INFO:root:current mean train loss 2396.2257655694234
INFO:root:current train perplexity6.60954475402832
INFO:root:current mean train loss 2395.511240828961
INFO:root:current train perplexity6.609026908874512
INFO:root:current mean train loss 2393.7908686045052
INFO:root:current train perplexity6.601210594177246
INFO:root:current mean train loss 2392.4847105032186
INFO:root:current train perplexity6.595301628112793
INFO:root:current mean train loss 2392.4788076588184
INFO:root:current train perplexity6.592119216918945
INFO:root:current mean train loss 2392.8451228797276
INFO:root:current train perplexity6.593982696533203
INFO:root:current mean train loss 2392.050087206291
INFO:root:current train perplexity6.585628986358643
INFO:root:current mean train loss 2391.3539665747708
INFO:root:current train perplexity6.580714702606201
INFO:root:current mean train loss 2388.1296282712656
INFO:root:current train perplexity6.57356071472168
INFO:root:current mean train loss 2387.6198775823964
INFO:root:current train perplexity6.567345142364502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:17<00:00, 317.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:17<00:00, 317.13s/it]
INFO:root:final mean train loss: 2385.196317440924
INFO:root:final train perplexity: 6.560779094696045
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 2967.421526018206
INFO:root:eval perplexity: 11.415657043457031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/6
  6%|â–Œ         | 6/100 [35:13<9:13:18, 353.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2485.617919921875
INFO:root:current train perplexity6.186073303222656
INFO:root:current mean train loss 2326.518362517404
INFO:root:current train perplexity6.281932830810547
INFO:root:current mean train loss 2338.086920742965
INFO:root:current train perplexity6.337989330291748
INFO:root:current mean train loss 2347.7652782554246
INFO:root:current train perplexity6.354703426361084
INFO:root:current mean train loss 2345.361747304103
INFO:root:current train perplexity6.354039192199707
INFO:root:current mean train loss 2342.5473584081838
INFO:root:current train perplexity6.354170799255371
INFO:root:current mean train loss 2340.1722148063773
INFO:root:current train perplexity6.346534729003906
INFO:root:current mean train loss 2342.353872780793
INFO:root:current train perplexity6.349367141723633
INFO:root:current mean train loss 2342.605548453837
INFO:root:current train perplexity6.348540306091309
INFO:root:current mean train loss 2341.9232582828977
INFO:root:current train perplexity6.342085361480713
INFO:root:current mean train loss 2339.0265524270653
INFO:root:current train perplexity6.331918239593506
INFO:root:current mean train loss 2337.9722860476627
INFO:root:current train perplexity6.3239545822143555
INFO:root:current mean train loss 2337.8984626052184
INFO:root:current train perplexity6.322171211242676
INFO:root:current mean train loss 2337.715549806189
INFO:root:current train perplexity6.322424411773682
INFO:root:current mean train loss 2337.371159098133
INFO:root:current train perplexity6.321396350860596
INFO:root:current mean train loss 2337.8574553813082
INFO:root:current train perplexity6.318080902099609
INFO:root:current mean train loss 2336.805682132871
INFO:root:current train perplexity6.312970161437988
INFO:root:current mean train loss 2336.732914964428
INFO:root:current train perplexity6.313490390777588
INFO:root:current mean train loss 2336.5911718831335
INFO:root:current train perplexity6.309730052947998
INFO:root:current mean train loss 2336.1092371331083
INFO:root:current train perplexity6.30717134475708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.64s/it]
INFO:root:final mean train loss: 2334.718957636492
INFO:root:final train perplexity: 6.3047285079956055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2946.5040066922393
INFO:root:eval perplexity: 11.221388816833496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/7
  7%|â–‹         | 7/100 [41:10<9:09:06, 354.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2293.616902669271
INFO:root:current train perplexity6.087001800537109
INFO:root:current mean train loss 2283.761071156647
INFO:root:current train perplexity6.12811279296875
INFO:root:current mean train loss 2300.1259552841884
INFO:root:current train perplexity6.173064708709717
INFO:root:current mean train loss 2303.704659324022
INFO:root:current train perplexity6.173070430755615
INFO:root:current mean train loss 2303.045592385616
INFO:root:current train perplexity6.149163722991943
INFO:root:current mean train loss 2303.6204633675948
INFO:root:current train perplexity6.148850917816162
INFO:root:current mean train loss 2303.102039917387
INFO:root:current train perplexity6.14097261428833
INFO:root:current mean train loss 2304.426772433735
INFO:root:current train perplexity6.146001815795898
INFO:root:current mean train loss 2303.3015559040246
INFO:root:current train perplexity6.136054992675781
INFO:root:current mean train loss 2301.6659883652896
INFO:root:current train perplexity6.131694316864014
INFO:root:current mean train loss 2299.0635893995964
INFO:root:current train perplexity6.123592376708984
INFO:root:current mean train loss 2299.641087950022
INFO:root:current train perplexity6.119395732879639
INFO:root:current mean train loss 2299.2972618566555
INFO:root:current train perplexity6.115004539489746
INFO:root:current mean train loss 2300.119265844319
INFO:root:current train perplexity6.122593402862549
INFO:root:current mean train loss 2300.3512342531017
INFO:root:current train perplexity6.12037992477417
INFO:root:current mean train loss 2300.6215306459208
INFO:root:current train perplexity6.1175737380981445
INFO:root:current mean train loss 2298.8634875925864
INFO:root:current train perplexity6.1122026443481445
INFO:root:current mean train loss 2296.9691891831208
INFO:root:current train perplexity6.105142116546631
INFO:root:current mean train loss 2296.113361555882
INFO:root:current train perplexity6.105344295501709
INFO:root:current mean train loss 2294.0362913511594
INFO:root:current train perplexity6.1025190353393555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.51s/it]
INFO:root:final mean train loss: 2293.5568628508336
INFO:root:final train perplexity: 6.1033453941345215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 2923.191306540916
INFO:root:eval perplexity: 11.008766174316406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/8
  8%|â–Š         | 8/100 [47:05<9:03:26, 354.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2262.5022216796874
INFO:root:current train perplexity5.926395416259766
INFO:root:current mean train loss 2268.0654360170715
INFO:root:current train perplexity5.934290885925293
INFO:root:current mean train loss 2260.7740249958442
INFO:root:current train perplexity5.941833972930908
INFO:root:current mean train loss 2261.531484666511
INFO:root:current train perplexity5.950847625732422
INFO:root:current mean train loss 2258.705029296875
INFO:root:current train perplexity5.955325603485107
INFO:root:current mean train loss 2257.6305408513435
INFO:root:current train perplexity5.942992687225342
INFO:root:current mean train loss 2261.009983044722
INFO:root:current train perplexity5.942239761352539
INFO:root:current mean train loss 2263.2991230867347
INFO:root:current train perplexity5.946082592010498
INFO:root:current mean train loss 2263.797841767637
INFO:root:current train perplexity5.950428485870361
INFO:root:current mean train loss 2265.5023433583306
INFO:root:current train perplexity5.953246116638184
INFO:root:current mean train loss 2264.310320897494
INFO:root:current train perplexity5.952891826629639
INFO:root:current mean train loss 2261.701433223775
INFO:root:current train perplexity5.9464192390441895
INFO:root:current mean train loss 2259.6431452824518
INFO:root:current train perplexity5.941900730133057
INFO:root:current mean train loss 2260.626653024052
INFO:root:current train perplexity5.944843769073486
INFO:root:current mean train loss 2260.095150618603
INFO:root:current train perplexity5.942793846130371
INFO:root:current mean train loss 2260.9543757634365
INFO:root:current train perplexity5.942136287689209
INFO:root:current mean train loss 2260.2043595153623
INFO:root:current train perplexity5.94143533706665
INFO:root:current mean train loss 2259.0726839708664
INFO:root:current train perplexity5.937346458435059
INFO:root:current mean train loss 2257.694150071313
INFO:root:current train perplexity5.932094573974609
INFO:root:current mean train loss 2257.6857090045623
INFO:root:current train perplexity5.931599140167236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.32s/it]
INFO:root:final mean train loss: 2257.9562290824547
INFO:root:final train perplexity: 5.934366703033447
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2910.4279843808654
INFO:root:eval perplexity: 10.894067764282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/9
  9%|â–‰         | 9/100 [53:02<8:59:08, 355.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2210.3214017427886
INFO:root:current train perplexity5.756002426147461
INFO:root:current mean train loss 2220.527378283049
INFO:root:current train perplexity5.725503444671631
INFO:root:current mean train loss 2231.1727992466517
INFO:root:current train perplexity5.779317378997803
INFO:root:current mean train loss 2227.0673935630107
INFO:root:current train perplexity5.7889404296875
INFO:root:current mean train loss 2233.743833018615
INFO:root:current train perplexity5.8068976402282715
INFO:root:current mean train loss 2235.467047428739
INFO:root:current train perplexity5.812565326690674
INFO:root:current mean train loss 2238.432961493182
INFO:root:current train perplexity5.821008682250977
INFO:root:current mean train loss 2234.803741455078
INFO:root:current train perplexity5.81098747253418
INFO:root:current mean train loss 2234.260665392092
INFO:root:current train perplexity5.812741756439209
INFO:root:current mean train loss 2231.00265310592
INFO:root:current train perplexity5.805407524108887
INFO:root:current mean train loss 2232.095317303908
INFO:root:current train perplexity5.808623313903809
INFO:root:current mean train loss 2231.6767193476358
INFO:root:current train perplexity5.802134037017822
INFO:root:current mean train loss 2231.2639811457916
INFO:root:current train perplexity5.80172872543335
INFO:root:current mean train loss 2231.999681280915
INFO:root:current train perplexity5.80836296081543
INFO:root:current mean train loss 2230.7871255165287
INFO:root:current train perplexity5.8043532371521
INFO:root:current mean train loss 2228.16848825671
INFO:root:current train perplexity5.79636287689209
INFO:root:current mean train loss 2228.135575633938
INFO:root:current train perplexity5.79302453994751
INFO:root:current mean train loss 2229.685977047437
INFO:root:current train perplexity5.796976566314697
INFO:root:current mean train loss 2227.94401685414
INFO:root:current train perplexity5.79215145111084
INFO:root:current mean train loss 2228.1225626585915
INFO:root:current train perplexity5.792641639709473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.66s/it]
INFO:root:final mean train loss: 2227.275512202845
INFO:root:final train perplexity: 5.792496204376221
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it]
INFO:root:eval mean loss: 2896.53942981067
INFO:root:eval perplexity: 10.77061939239502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/10
 10%|â–ˆ         | 10/100 [59:00<8:54:08, 356.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2221.5634004896965
INFO:root:current train perplexity5.709805011749268
INFO:root:current mean train loss 2221.3110611593934
INFO:root:current train perplexity5.686980724334717
INFO:root:current mean train loss 2203.92298996936
INFO:root:current train perplexity5.652866840362549
INFO:root:current mean train loss 2203.3304850260415
INFO:root:current train perplexity5.6597208976745605
INFO:root:current mean train loss 2204.243957389392
INFO:root:current train perplexity5.66063117980957
INFO:root:current mean train loss 2207.6914352122008
INFO:root:current train perplexity5.671999454498291
INFO:root:current mean train loss 2203.726741682432
INFO:root:current train perplexity5.664898872375488
INFO:root:current mean train loss 2205.2601610439187
INFO:root:current train perplexity5.676861763000488
INFO:root:current mean train loss 2206.739103152645
INFO:root:current train perplexity5.673375606536865
INFO:root:current mean train loss 2205.7056469046292
INFO:root:current train perplexity5.674151420593262
INFO:root:current mean train loss 2204.196967471973
INFO:root:current train perplexity5.675709247589111
INFO:root:current mean train loss 2203.75369709103
INFO:root:current train perplexity5.674235820770264
INFO:root:current mean train loss 2202.9773965990385
INFO:root:current train perplexity5.670376777648926
INFO:root:current mean train loss 2203.7374957734605
INFO:root:current train perplexity5.673761367797852
INFO:root:current mean train loss 2204.4590639824605
INFO:root:current train perplexity5.674975395202637
INFO:root:current mean train loss 2202.903239865908
INFO:root:current train perplexity5.672957897186279
INFO:root:current mean train loss 2202.0540501598543
INFO:root:current train perplexity5.671971321105957
INFO:root:current mean train loss 2201.0223237550344
INFO:root:current train perplexity5.671136856079102
INFO:root:current mean train loss 2200.2358807297937
INFO:root:current train perplexity5.670677661895752
INFO:root:current mean train loss 2201.609426704744
INFO:root:current train perplexity5.674275875091553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.49s/it]
INFO:root:final mean train loss: 2201.169523899927
INFO:root:final train perplexity: 5.674455642700195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.94s/it]
INFO:root:eval mean loss: 2882.418870530687
INFO:root:eval perplexity: 10.646538734436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/11
 11%|â–ˆ         | 11/100 [1:04:56<8:48:17, 356.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2206.0953667219296
INFO:root:current train perplexity5.615961074829102
INFO:root:current mean train loss 2174.968495358703
INFO:root:current train perplexity5.555818557739258
INFO:root:current mean train loss 2176.5974799736396
INFO:root:current train perplexity5.556985855102539
INFO:root:current mean train loss 2186.076113053554
INFO:root:current train perplexity5.587038516998291
INFO:root:current mean train loss 2181.443604017972
INFO:root:current train perplexity5.568228244781494
INFO:root:current mean train loss 2180.7580299768024
INFO:root:current train perplexity5.562236309051514
INFO:root:current mean train loss 2182.0254093092317
INFO:root:current train perplexity5.566917896270752
INFO:root:current mean train loss 2181.8931662678415
INFO:root:current train perplexity5.574072360992432
INFO:root:current mean train loss 2179.7465993911364
INFO:root:current train perplexity5.571540832519531
INFO:root:current mean train loss 2179.644504756038
INFO:root:current train perplexity5.574514865875244
INFO:root:current mean train loss 2176.4200962129876
INFO:root:current train perplexity5.56638765335083
INFO:root:current mean train loss 2179.5647093079747
INFO:root:current train perplexity5.571865081787109
INFO:root:current mean train loss 2178.336283112759
INFO:root:current train perplexity5.570051193237305
INFO:root:current mean train loss 2178.177453331445
INFO:root:current train perplexity5.570245742797852
INFO:root:current mean train loss 2177.828397070575
INFO:root:current train perplexity5.568783760070801
INFO:root:current mean train loss 2177.4319063165
INFO:root:current train perplexity5.566065311431885
INFO:root:current mean train loss 2177.531709754736
INFO:root:current train perplexity5.566292762756348
INFO:root:current mean train loss 2177.71964686822
INFO:root:current train perplexity5.568072319030762
INFO:root:current mean train loss 2177.870340875199
INFO:root:current train perplexity5.568538188934326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.92s/it]
INFO:root:final mean train loss: 2177.658249293802
INFO:root:final train perplexity: 5.5702080726623535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it]
INFO:root:eval mean loss: 2874.9164122618713
INFO:root:eval perplexity: 10.58120059967041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/12
 12%|â–ˆâ–        | 12/100 [1:10:51<8:41:51, 355.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2048.0064290364585
INFO:root:current train perplexity5.1112518310546875
INFO:root:current mean train loss 2154.8268770384557
INFO:root:current train perplexity5.460381984710693
INFO:root:current mean train loss 2159.9090504012083
INFO:root:current train perplexity5.483075141906738
INFO:root:current mean train loss 2155.924503741878
INFO:root:current train perplexity5.4787187576293945
INFO:root:current mean train loss 2151.6494782781483
INFO:root:current train perplexity5.475399017333984
INFO:root:current mean train loss 2155.441891376351
INFO:root:current train perplexity5.487821578979492
INFO:root:current mean train loss 2153.5046236914386
INFO:root:current train perplexity5.485715389251709
INFO:root:current mean train loss 2151.9399193537183
INFO:root:current train perplexity5.481114864349365
INFO:root:current mean train loss 2151.886089700245
INFO:root:current train perplexity5.476803302764893
INFO:root:current mean train loss 2155.2975976886937
INFO:root:current train perplexity5.481863498687744
INFO:root:current mean train loss 2154.7540031273365
INFO:root:current train perplexity5.478335857391357
INFO:root:current mean train loss 2153.5506079389306
INFO:root:current train perplexity5.474641799926758
INFO:root:current mean train loss 2152.296316398944
INFO:root:current train perplexity5.475929260253906
INFO:root:current mean train loss 2151.4981206043444
INFO:root:current train perplexity5.47405481338501
INFO:root:current mean train loss 2151.7157749820417
INFO:root:current train perplexity5.472927093505859
INFO:root:current mean train loss 2152.1832304629024
INFO:root:current train perplexity5.468515872955322
INFO:root:current mean train loss 2154.274756438124
INFO:root:current train perplexity5.470219135284424
INFO:root:current mean train loss 2153.320142834451
INFO:root:current train perplexity5.469189643859863
INFO:root:current mean train loss 2154.5243473063556
INFO:root:current train perplexity5.472462177276611
INFO:root:current mean train loss 2155.416054754212
INFO:root:current train perplexity5.47390079498291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.69s/it]
INFO:root:final mean train loss: 2155.913361165118
INFO:root:final train perplexity: 5.475496292114258
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2871.656492674315
INFO:root:eval perplexity: 10.552932739257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/13
 13%|â–ˆâ–Ž        | 13/100 [1:16:49<8:36:38, 356.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2203.063623046875
INFO:root:current train perplexity5.459411144256592
INFO:root:current mean train loss 2141.3815775553385
INFO:root:current train perplexity5.370205879211426
INFO:root:current mean train loss 2145.0844565651632
INFO:root:current train perplexity5.387827396392822
INFO:root:current mean train loss 2135.588690185547
INFO:root:current train perplexity5.370786666870117
INFO:root:current mean train loss 2138.9410071963357
INFO:root:current train perplexity5.3724141120910645
INFO:root:current mean train loss 2140.304442185622
INFO:root:current train perplexity5.390378952026367
INFO:root:current mean train loss 2140.1923591859877
INFO:root:current train perplexity5.389546871185303
INFO:root:current mean train loss 2141.390798272027
INFO:root:current train perplexity5.392565727233887
INFO:root:current mean train loss 2142.006114978325
INFO:root:current train perplexity5.395351409912109
INFO:root:current mean train loss 2142.608979863706
INFO:root:current train perplexity5.396429061889648
INFO:root:current mean train loss 2140.4613118489583
INFO:root:current train perplexity5.396138668060303
INFO:root:current mean train loss 2141.1242991856166
INFO:root:current train perplexity5.39924955368042
INFO:root:current mean train loss 2138.7910787613664
INFO:root:current train perplexity5.399737358093262
INFO:root:current mean train loss 2137.628375706528
INFO:root:current train perplexity5.398804664611816
INFO:root:current mean train loss 2137.030389920087
INFO:root:current train perplexity5.392580509185791
INFO:root:current mean train loss 2136.0596238788808
INFO:root:current train perplexity5.391053199768066
INFO:root:current mean train loss 2135.9233907063804
INFO:root:current train perplexity5.388607978820801
INFO:root:current mean train loss 2135.7180546960167
INFO:root:current train perplexity5.387347221374512
INFO:root:current mean train loss 2136.265701998197
INFO:root:current train perplexity5.390224933624268
INFO:root:current mean train loss 2137.2835557937624
INFO:root:current train perplexity5.391558647155762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.11s/it]
INFO:root:final mean train loss: 2136.1869096549185
INFO:root:final train perplexity: 5.390971660614014
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it]
INFO:root:eval mean loss: 2864.110695412209
INFO:root:eval perplexity: 10.487793922424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/14
 14%|â–ˆâ–        | 14/100 [1:22:47<8:31:35, 356.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2101.751022751267
INFO:root:current train perplexity5.277318954467773
INFO:root:current mean train loss 2095.878591718465
INFO:root:current train perplexity5.28147554397583
INFO:root:current mean train loss 2111.2429353738135
INFO:root:current train perplexity5.304791450500488
INFO:root:current mean train loss 2108.8445403781066
INFO:root:current train perplexity5.303786754608154
INFO:root:current mean train loss 2107.8099197632114
INFO:root:current train perplexity5.31232213973999
INFO:root:current mean train loss 2111.7529499188927
INFO:root:current train perplexity5.317238807678223
INFO:root:current mean train loss 2110.665989179626
INFO:root:current train perplexity5.306064128875732
INFO:root:current mean train loss 2108.6502695484755
INFO:root:current train perplexity5.306568145751953
INFO:root:current mean train loss 2110.336498556741
INFO:root:current train perplexity5.309649467468262
INFO:root:current mean train loss 2111.4885459745196
INFO:root:current train perplexity5.313421726226807
INFO:root:current mean train loss 2112.162276294675
INFO:root:current train perplexity5.315642833709717
INFO:root:current mean train loss 2114.4080567909314
INFO:root:current train perplexity5.316510200500488
INFO:root:current mean train loss 2116.495679085931
INFO:root:current train perplexity5.321593761444092
INFO:root:current mean train loss 2116.5095174671023
INFO:root:current train perplexity5.321036338806152
INFO:root:current mean train loss 2116.967656209225
INFO:root:current train perplexity5.317224502563477
INFO:root:current mean train loss 2118.2820885285355
INFO:root:current train perplexity5.323842525482178
INFO:root:current mean train loss 2118.384958461792
INFO:root:current train perplexity5.322935104370117
INFO:root:current mean train loss 2119.2020510342454
INFO:root:current train perplexity5.320044040679932
INFO:root:current mean train loss 2119.080746820457
INFO:root:current train perplexity5.317505359649658
INFO:root:current mean train loss 2120.032583257373
INFO:root:current train perplexity5.318727016448975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.69s/it]
INFO:root:final mean train loss: 2118.8215825114057
INFO:root:final train perplexity: 5.3176422119140625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it]
INFO:root:eval mean loss: 2860.557689769848
INFO:root:eval perplexity: 10.457260131835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/15
 15%|â–ˆâ–Œ        | 15/100 [1:28:45<8:26:14, 357.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2109.8955507631654
INFO:root:current train perplexity5.221724033355713
INFO:root:current mean train loss 2102.1924382990055
INFO:root:current train perplexity5.1923394203186035
INFO:root:current mean train loss 2099.3370366134045
INFO:root:current train perplexity5.225225925445557
INFO:root:current mean train loss 2095.683506507658
INFO:root:current train perplexity5.2334465980529785
INFO:root:current mean train loss 2096.40823646579
INFO:root:current train perplexity5.232661247253418
INFO:root:current mean train loss 2095.3041027082863
INFO:root:current train perplexity5.233088970184326
INFO:root:current mean train loss 2097.2628955899395
INFO:root:current train perplexity5.233940124511719
INFO:root:current mean train loss 2098.791551827752
INFO:root:current train perplexity5.241478443145752
INFO:root:current mean train loss 2099.873642646736
INFO:root:current train perplexity5.240654945373535
INFO:root:current mean train loss 2098.789928252342
INFO:root:current train perplexity5.240451335906982
INFO:root:current mean train loss 2099.081313536787
INFO:root:current train perplexity5.239409923553467
INFO:root:current mean train loss 2098.4889515789173
INFO:root:current train perplexity5.241347789764404
INFO:root:current mean train loss 2100.353788677015
INFO:root:current train perplexity5.2456583976745605
INFO:root:current mean train loss 2102.6075104976862
INFO:root:current train perplexity5.251871585845947
INFO:root:current mean train loss 2102.058192110127
INFO:root:current train perplexity5.247921943664551
INFO:root:current mean train loss 2102.3296533140283
INFO:root:current train perplexity5.249847888946533
INFO:root:current mean train loss 2101.698644635755
INFO:root:current train perplexity5.248433589935303
INFO:root:current mean train loss 2101.7625381661114
INFO:root:current train perplexity5.247792720794678
INFO:root:current mean train loss 2101.637053883706
INFO:root:current train perplexity5.248064994812012
INFO:root:current mean train loss 2103.2703351398573
INFO:root:current train perplexity5.2505574226379395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.66s/it]
INFO:root:final mean train loss: 2102.9929903446878
INFO:root:final train perplexity: 5.251672744750977
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 2850.8049587673613
INFO:root:eval perplexity: 10.37390422821045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/16
 16%|â–ˆâ–Œ        | 16/100 [1:34:41<8:19:44, 356.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2103.329950896787
INFO:root:current train perplexity5.263555526733398
INFO:root:current mean train loss 2079.8659575166757
INFO:root:current train perplexity5.189100742340088
INFO:root:current mean train loss 2078.0636125965752
INFO:root:current train perplexity5.193605899810791
INFO:root:current mean train loss 2080.1705937552647
INFO:root:current train perplexity5.189269542694092
INFO:root:current mean train loss 2081.7552881585057
INFO:root:current train perplexity5.1850128173828125
INFO:root:current mean train loss 2082.0275284588442
INFO:root:current train perplexity5.17617654800415
INFO:root:current mean train loss 2081.0938302280297
INFO:root:current train perplexity5.1751627922058105
INFO:root:current mean train loss 2083.4094800343
INFO:root:current train perplexity5.173954963684082
INFO:root:current mean train loss 2082.510371772074
INFO:root:current train perplexity5.176002502441406
INFO:root:current mean train loss 2083.432223319025
INFO:root:current train perplexity5.175070285797119
INFO:root:current mean train loss 2083.053312242866
INFO:root:current train perplexity5.171350002288818
INFO:root:current mean train loss 2084.0210974194065
INFO:root:current train perplexity5.170806407928467
INFO:root:current mean train loss 2083.185882064135
INFO:root:current train perplexity5.171755790710449
INFO:root:current mean train loss 2083.497368587881
INFO:root:current train perplexity5.175479412078857
INFO:root:current mean train loss 2083.4505397814783
INFO:root:current train perplexity5.176807403564453
INFO:root:current mean train loss 2084.4367375850375
INFO:root:current train perplexity5.1802215576171875
INFO:root:current mean train loss 2084.2360316059107
INFO:root:current train perplexity5.175783157348633
INFO:root:current mean train loss 2085.4365833353554
INFO:root:current train perplexity5.180479526519775
INFO:root:current mean train loss 2085.4581533704195
INFO:root:current train perplexity5.181883811950684
INFO:root:current mean train loss 2087.0656806407756
INFO:root:current train perplexity5.184671878814697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.20s/it]
INFO:root:final mean train loss: 2086.90504259349
INFO:root:final train perplexity: 5.185461044311523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2847.7608272334833
INFO:root:eval perplexity: 10.348023414611816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/17
 17%|â–ˆâ–‹        | 17/100 [1:40:38<8:13:44, 356.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2052.186104514382
INFO:root:current train perplexity5.063746929168701
INFO:root:current mean train loss 2060.8822281208445
INFO:root:current train perplexity5.085671901702881
INFO:root:current mean train loss 2069.266635047065
INFO:root:current train perplexity5.1007080078125
INFO:root:current mean train loss 2062.062301163821
INFO:root:current train perplexity5.094280242919922
INFO:root:current mean train loss 2066.207666866115
INFO:root:current train perplexity5.112952709197998
INFO:root:current mean train loss 2068.5985333708677
INFO:root:current train perplexity5.115760803222656
INFO:root:current mean train loss 2069.47840615206
INFO:root:current train perplexity5.120781898498535
INFO:root:current mean train loss 2067.6868492165195
INFO:root:current train perplexity5.1194353103637695
INFO:root:current mean train loss 2068.836742504223
INFO:root:current train perplexity5.120950222015381
INFO:root:current mean train loss 2072.6044102718956
INFO:root:current train perplexity5.12489652633667
INFO:root:current mean train loss 2073.8732268389535
INFO:root:current train perplexity5.123688220977783
INFO:root:current mean train loss 2073.592624343204
INFO:root:current train perplexity5.11905574798584
INFO:root:current mean train loss 2071.4811398523934
INFO:root:current train perplexity5.117103099822998
INFO:root:current mean train loss 2070.7701417774565
INFO:root:current train perplexity5.115025520324707
INFO:root:current mean train loss 2070.9485589304277
INFO:root:current train perplexity5.11473274230957
INFO:root:current mean train loss 2071.266663904454
INFO:root:current train perplexity5.119086742401123
INFO:root:current mean train loss 2072.507592368465
INFO:root:current train perplexity5.12384557723999
INFO:root:current mean train loss 2072.59740678416
INFO:root:current train perplexity5.1266655921936035
INFO:root:current mean train loss 2072.8971116664047
INFO:root:current train perplexity5.12840461730957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.95s/it]
INFO:root:final mean train loss: 2072.9911354668984
INFO:root:final train perplexity: 5.128869533538818
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2850.0455186631943
INFO:root:eval perplexity: 10.367444038391113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/18
 18%|â–ˆâ–Š        | 18/100 [1:46:35<8:07:47, 356.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2090.504443359375
INFO:root:current train perplexity5.19057559967041
INFO:root:current mean train loss 2056.597894577753
INFO:root:current train perplexity5.073262691497803
INFO:root:current mean train loss 2059.955203172637
INFO:root:current train perplexity5.071262359619141
INFO:root:current mean train loss 2064.108979972464
INFO:root:current train perplexity5.085745334625244
INFO:root:current mean train loss 2060.0687370394485
INFO:root:current train perplexity5.0804057121276855
INFO:root:current mean train loss 2058.3972503964264
INFO:root:current train perplexity5.075112342834473
INFO:root:current mean train loss 2062.389297561015
INFO:root:current train perplexity5.083136081695557
INFO:root:current mean train loss 2062.0091656624004
INFO:root:current train perplexity5.086771488189697
INFO:root:current mean train loss 2062.191692698224
INFO:root:current train perplexity5.081523895263672
INFO:root:current mean train loss 2063.413322659487
INFO:root:current train perplexity5.085644245147705
INFO:root:current mean train loss 2065.775595776003
INFO:root:current train perplexity5.090677738189697
INFO:root:current mean train loss 2063.7691007450157
INFO:root:current train perplexity5.083529472351074
INFO:root:current mean train loss 2063.0194482827087
INFO:root:current train perplexity5.080315113067627
INFO:root:current mean train loss 2061.932126567738
INFO:root:current train perplexity5.078938007354736
INFO:root:current mean train loss 2061.3318848525078
INFO:root:current train perplexity5.075944900512695
INFO:root:current mean train loss 2059.7825419175665
INFO:root:current train perplexity5.074452877044678
INFO:root:current mean train loss 2058.7305013781397
INFO:root:current train perplexity5.072546482086182
INFO:root:current mean train loss 2059.396489816257
INFO:root:current train perplexity5.073788166046143
INFO:root:current mean train loss 2058.6202363497664
INFO:root:current train perplexity5.071910381317139
INFO:root:current mean train loss 2059.091614378281
INFO:root:current train perplexity5.073869705200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.42s/it]
INFO:root:final mean train loss: 2059.9075191188085
INFO:root:final train perplexity: 5.0762200355529785
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it]
INFO:root:eval mean loss: 2844.280950872748
INFO:root:eval perplexity: 10.318516731262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/19
 19%|â–ˆâ–‰        | 19/100 [1:52:32<8:01:39, 356.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2009.615556196733
INFO:root:current train perplexity4.942221641540527
INFO:root:current mean train loss 2033.3592049020235
INFO:root:current train perplexity4.9506635665893555
INFO:root:current mean train loss 2031.2647545616906
INFO:root:current train perplexity4.963884353637695
INFO:root:current mean train loss 2032.4645002850834
INFO:root:current train perplexity4.967172145843506
INFO:root:current mean train loss 2041.6487290802725
INFO:root:current train perplexity4.975767135620117
INFO:root:current mean train loss 2043.3274772322497
INFO:root:current train perplexity4.987955570220947
INFO:root:current mean train loss 2043.0448182526125
INFO:root:current train perplexity4.994739055633545
INFO:root:current mean train loss 2041.8631186022983
INFO:root:current train perplexity4.999415874481201
INFO:root:current mean train loss 2044.320975718997
INFO:root:current train perplexity5.001010417938232
INFO:root:current mean train loss 2045.2852853373695
INFO:root:current train perplexity5.00259256362915
INFO:root:current mean train loss 2044.1119094520166
INFO:root:current train perplexity5.004958152770996
INFO:root:current mean train loss 2044.221329687326
INFO:root:current train perplexity5.0081915855407715
INFO:root:current mean train loss 2045.2468050942678
INFO:root:current train perplexity5.011212348937988
INFO:root:current mean train loss 2047.3416065671981
INFO:root:current train perplexity5.018321514129639
INFO:root:current mean train loss 2047.4023694173864
INFO:root:current train perplexity5.01713228225708
INFO:root:current mean train loss 2048.0144136005256
INFO:root:current train perplexity5.019745349884033
INFO:root:current mean train loss 2047.4687563970263
INFO:root:current train perplexity5.018069744110107
INFO:root:current mean train loss 2047.6851437310586
INFO:root:current train perplexity5.022294998168945
INFO:root:current mean train loss 2048.3253007673143
INFO:root:current train perplexity5.025125026702881
INFO:root:current mean train loss 2048.7214657786485
INFO:root:current train perplexity5.0264058113098145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.72s/it]
INFO:root:final mean train loss: 2046.8228874879837
INFO:root:final train perplexity: 5.024107456207275
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it]
INFO:root:eval mean loss: 2840.4609111064187
INFO:root:eval perplexity: 10.286224365234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/20
 20%|â–ˆâ–ˆ        | 20/100 [1:58:27<7:55:17, 356.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2018.0682091346155
INFO:root:current train perplexity4.948753833770752
INFO:root:current mean train loss 2045.439049151304
INFO:root:current train perplexity4.960829257965088
INFO:root:current mean train loss 2041.6761898535565
INFO:root:current train perplexity4.959053039550781
INFO:root:current mean train loss 2040.5859403807153
INFO:root:current train perplexity4.959882736206055
INFO:root:current mean train loss 2038.0303715942662
INFO:root:current train perplexity4.959868907928467
INFO:root:current mean train loss 2037.7163350913875
INFO:root:current train perplexity4.966146945953369
INFO:root:current mean train loss 2035.521759845095
INFO:root:current train perplexity4.970202445983887
INFO:root:current mean train loss 2037.0669163354196
INFO:root:current train perplexity4.972365856170654
INFO:root:current mean train loss 2036.0126096159397
INFO:root:current train perplexity4.974410057067871
INFO:root:current mean train loss 2036.2962459283897
INFO:root:current train perplexity4.972684383392334
INFO:root:current mean train loss 2035.7046221530243
INFO:root:current train perplexity4.971505165100098
INFO:root:current mean train loss 2036.690341805449
INFO:root:current train perplexity4.97452449798584
INFO:root:current mean train loss 2035.3654037364747
INFO:root:current train perplexity4.971531867980957
INFO:root:current mean train loss 2036.843522633787
INFO:root:current train perplexity4.975153923034668
INFO:root:current mean train loss 2037.455095006162
INFO:root:current train perplexity4.979902267456055
INFO:root:current mean train loss 2038.4815389869893
INFO:root:current train perplexity4.983618259429932
INFO:root:current mean train loss 2037.1888441885296
INFO:root:current train perplexity4.981311321258545
INFO:root:current mean train loss 2037.4880331784161
INFO:root:current train perplexity4.983429431915283
INFO:root:current mean train loss 2037.432584861104
INFO:root:current train perplexity4.982377052307129
INFO:root:current mean train loss 2036.6021235575683
INFO:root:current train perplexity4.981900215148926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.52s/it]
INFO:root:final mean train loss: 2035.5087540665481
INFO:root:final train perplexity: 4.979475975036621
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2845.5451293578735
INFO:root:eval perplexity: 10.329228401184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/21
 21%|â–ˆâ–ˆ        | 21/100 [2:04:25<7:49:48, 356.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2000.4249267578125
INFO:root:current train perplexity4.928033351898193
INFO:root:current mean train loss 2008.1832424066006
INFO:root:current train perplexity4.918452739715576
INFO:root:current mean train loss 2014.5726699829102
INFO:root:current train perplexity4.932467937469482
INFO:root:current mean train loss 2019.7444698033707
INFO:root:current train perplexity4.941531658172607
INFO:root:current mean train loss 2020.9495817485608
INFO:root:current train perplexity4.940952777862549
INFO:root:current mean train loss 2020.525175025995
INFO:root:current train perplexity4.927241802215576
INFO:root:current mean train loss 2019.1222191787347
INFO:root:current train perplexity4.926429748535156
INFO:root:current mean train loss 2020.1647547161767
INFO:root:current train perplexity4.924278259277344
INFO:root:current mean train loss 2020.6615693279516
INFO:root:current train perplexity4.927552700042725
INFO:root:current mean train loss 2022.612983224781
INFO:root:current train perplexity4.929079055786133
INFO:root:current mean train loss 2022.3385936852658
INFO:root:current train perplexity4.929043292999268
INFO:root:current mean train loss 2022.5758982727684
INFO:root:current train perplexity4.9281840324401855
INFO:root:current mean train loss 2022.242124909808
INFO:root:current train perplexity4.925474643707275
INFO:root:current mean train loss 2023.3626902532437
INFO:root:current train perplexity4.9294610023498535
INFO:root:current mean train loss 2023.892947437999
INFO:root:current train perplexity4.928976058959961
INFO:root:current mean train loss 2024.318482857437
INFO:root:current train perplexity4.930340766906738
INFO:root:current mean train loss 2025.0758552735554
INFO:root:current train perplexity4.930434226989746
INFO:root:current mean train loss 2025.1948972106795
INFO:root:current train perplexity4.9318671226501465
INFO:root:current mean train loss 2025.6129808754756
INFO:root:current train perplexity4.933847904205322
INFO:root:current mean train loss 2025.1101181560743
INFO:root:current train perplexity4.935869216918945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.01s/it]
INFO:root:final mean train loss: 2024.761082944038
INFO:root:final train perplexity: 4.9374470710754395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2835.4136768604544
INFO:root:eval perplexity: 10.243711471557617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:10:22<7:43:48, 356.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.9331121575342
INFO:root:current train perplexity4.885310173034668
INFO:root:current mean train loss 2011.3948861711976
INFO:root:current train perplexity4.876483917236328
INFO:root:current mean train loss 2011.0050616701008
INFO:root:current train perplexity4.878890037536621
INFO:root:current mean train loss 2009.6519817935239
INFO:root:current train perplexity4.8850202560424805
INFO:root:current mean train loss 2007.6484346611555
INFO:root:current train perplexity4.868667125701904
INFO:root:current mean train loss 2009.7670549056502
INFO:root:current train perplexity4.876476764678955
INFO:root:current mean train loss 2009.866426419716
INFO:root:current train perplexity4.879161357879639
INFO:root:current mean train loss 2008.0047604263523
INFO:root:current train perplexity4.877651691436768
INFO:root:current mean train loss 2008.9463746375645
INFO:root:current train perplexity4.88139533996582
INFO:root:current mean train loss 2011.3850653433726
INFO:root:current train perplexity4.885307788848877
INFO:root:current mean train loss 2013.4244953592804
INFO:root:current train perplexity4.890682220458984
INFO:root:current mean train loss 2013.1662384319386
INFO:root:current train perplexity4.88981294631958
INFO:root:current mean train loss 2012.8322178555209
INFO:root:current train perplexity4.890964031219482
INFO:root:current mean train loss 2012.137927272766
INFO:root:current train perplexity4.8904500007629395
INFO:root:current mean train loss 2012.8768886506598
INFO:root:current train perplexity4.888979434967041
INFO:root:current mean train loss 2014.3147914762794
INFO:root:current train perplexity4.895427227020264
INFO:root:current mean train loss 2014.7489410601045
INFO:root:current train perplexity4.894772529602051
INFO:root:current mean train loss 2013.7937313968423
INFO:root:current train perplexity4.891879081726074
INFO:root:current mean train loss 2013.970104895743
INFO:root:current train perplexity4.8924055099487305
INFO:root:current mean train loss 2014.523220706095
INFO:root:current train perplexity4.8949761390686035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.32s/it]
INFO:root:final mean train loss: 2013.627464675326
INFO:root:final train perplexity: 4.894282817840576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it]
INFO:root:eval mean loss: 2840.2552105327986
INFO:root:eval perplexity: 10.2844877243042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:16:19<7:38:12, 357.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.3571804470487
INFO:root:current train perplexity4.833800315856934
INFO:root:current mean train loss 1999.8915565892269
INFO:root:current train perplexity4.8079609870910645
INFO:root:current mean train loss 2001.008120622306
INFO:root:current train perplexity4.822386264801025
INFO:root:current mean train loss 2005.3016861353165
INFO:root:current train perplexity4.8340678215026855
INFO:root:current mean train loss 1998.1674323879943
INFO:root:current train perplexity4.825364112854004
INFO:root:current mean train loss 2000.635367907508
INFO:root:current train perplexity4.83247184753418
INFO:root:current mean train loss 2002.6950327997622
INFO:root:current train perplexity4.83986759185791
INFO:root:current mean train loss 2004.0810234745848
INFO:root:current train perplexity4.839422702789307
INFO:root:current mean train loss 2003.4346061106478
INFO:root:current train perplexity4.840749263763428
INFO:root:current mean train loss 2005.2677011817393
INFO:root:current train perplexity4.848488807678223
INFO:root:current mean train loss 2003.2251446925172
INFO:root:current train perplexity4.847944736480713
INFO:root:current mean train loss 2001.8986928218553
INFO:root:current train perplexity4.840738296508789
INFO:root:current mean train loss 2000.9137388717297
INFO:root:current train perplexity4.8364577293396
INFO:root:current mean train loss 2000.7281174474483
INFO:root:current train perplexity4.83913516998291
INFO:root:current mean train loss 2001.280444008232
INFO:root:current train perplexity4.842872142791748
INFO:root:current mean train loss 2003.0161269469831
INFO:root:current train perplexity4.848505020141602
INFO:root:current mean train loss 2002.597161395733
INFO:root:current train perplexity4.850797176361084
INFO:root:current mean train loss 2003.0862949136915
INFO:root:current train perplexity4.852896213531494
INFO:root:current mean train loss 2003.7092715954655
INFO:root:current train perplexity4.85480260848999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.40s/it]
INFO:root:final mean train loss: 2003.3829298303156
INFO:root:final train perplexity: 4.8548994064331055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2836.622436890015
INFO:root:eval perplexity: 10.253873825073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:22:14<7:31:17, 356.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.224853515625
INFO:root:current train perplexity4.7085862159729
INFO:root:current mean train loss 1966.607833719699
INFO:root:current train perplexity4.752508163452148
INFO:root:current mean train loss 1976.3621077238074
INFO:root:current train perplexity4.772711753845215
INFO:root:current mean train loss 1981.7964117690096
INFO:root:current train perplexity4.7902421951293945
INFO:root:current mean train loss 1982.7766428204661
INFO:root:current train perplexity4.789037227630615
INFO:root:current mean train loss 1982.40330442169
INFO:root:current train perplexity4.784758567810059
INFO:root:current mean train loss 1984.1963304899866
INFO:root:current train perplexity4.7936577796936035
INFO:root:current mean train loss 1987.4250937196118
INFO:root:current train perplexity4.802867412567139
INFO:root:current mean train loss 1986.394904116568
INFO:root:current train perplexity4.799721717834473
INFO:root:current mean train loss 1987.775070577367
INFO:root:current train perplexity4.802831172943115
INFO:root:current mean train loss 1988.32300665362
INFO:root:current train perplexity4.807583332061768
INFO:root:current mean train loss 1989.2982821718679
INFO:root:current train perplexity4.806977272033691
INFO:root:current mean train loss 1992.2902309161725
INFO:root:current train perplexity4.816229820251465
INFO:root:current mean train loss 1991.676779200489
INFO:root:current train perplexity4.813459873199463
INFO:root:current mean train loss 1991.9675755395733
INFO:root:current train perplexity4.814615726470947
INFO:root:current mean train loss 1993.07901570017
INFO:root:current train perplexity4.815466403961182
INFO:root:current mean train loss 1994.9964120291595
INFO:root:current train perplexity4.81841516494751
INFO:root:current mean train loss 1994.2785562292902
INFO:root:current train perplexity4.8185834884643555
INFO:root:current mean train loss 1994.3922821028034
INFO:root:current train perplexity4.8193583488464355
INFO:root:current mean train loss 1993.9386230212704
INFO:root:current train perplexity4.8182902336120605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.64s/it]
INFO:root:final mean train loss: 1993.4732619231238
INFO:root:final train perplexity: 4.817104339599609
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 2837.994841521209
INFO:root:eval perplexity: 10.265429496765137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:28:11<7:25:30, 356.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.5130004882812
INFO:root:current train perplexity4.71336030960083
INFO:root:current mean train loss 1960.2126592820691
INFO:root:current train perplexity4.773584842681885
INFO:root:current mean train loss 1971.5073547363281
INFO:root:current train perplexity4.783280849456787
INFO:root:current mean train loss 1976.2659497673128
INFO:root:current train perplexity4.765092372894287
INFO:root:current mean train loss 1975.4745540978774
INFO:root:current train perplexity4.761960506439209
INFO:root:current mean train loss 1977.3652942453632
INFO:root:current train perplexity4.762030601501465
INFO:root:current mean train loss 1981.5420907827524
INFO:root:current train perplexity4.773784160614014
INFO:root:current mean train loss 1983.6732115350376
INFO:root:current train perplexity4.780485153198242
INFO:root:current mean train loss 1984.5314665859185
INFO:root:current train perplexity4.779745101928711
INFO:root:current mean train loss 1983.3062145679028
INFO:root:current train perplexity4.773562908172607
INFO:root:current mean train loss 1983.9545571804047
INFO:root:current train perplexity4.779842853546143
INFO:root:current mean train loss 1984.6015389330446
INFO:root:current train perplexity4.77676248550415
INFO:root:current mean train loss 1983.3668415343839
INFO:root:current train perplexity4.771938800811768
INFO:root:current mean train loss 1983.38300731463
INFO:root:current train perplexity4.7744951248168945
INFO:root:current mean train loss 1984.2038823674234
INFO:root:current train perplexity4.775876045227051
INFO:root:current mean train loss 1984.6019215821593
INFO:root:current train perplexity4.77702522277832
INFO:root:current mean train loss 1985.4635493837554
INFO:root:current train perplexity4.778294086456299
INFO:root:current mean train loss 1986.5141475527028
INFO:root:current train perplexity4.78143310546875
INFO:root:current mean train loss 1985.6824994003564
INFO:root:current train perplexity4.783284664154053
INFO:root:current mean train loss 1985.7908971076695
INFO:root:current train perplexity4.782759189605713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.22s/it]
INFO:root:final mean train loss: 1984.3091553473075
INFO:root:final train perplexity: 4.782413959503174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it]
INFO:root:eval mean loss: 2835.1691967846755
INFO:root:eval perplexity: 10.241655349731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:34:07<7:19:25, 356.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1982.1452845131478
INFO:root:current train perplexity4.730351448059082
INFO:root:current mean train loss 1967.6925481701574
INFO:root:current train perplexity4.734922409057617
INFO:root:current mean train loss 1968.5574145811722
INFO:root:current train perplexity4.741946220397949
INFO:root:current mean train loss 1978.6745741500183
INFO:root:current train perplexity4.754687786102295
INFO:root:current mean train loss 1972.5499660638995
INFO:root:current train perplexity4.751110076904297
INFO:root:current mean train loss 1974.419895926597
INFO:root:current train perplexity4.751544952392578
INFO:root:current mean train loss 1974.7145841839533
INFO:root:current train perplexity4.753860950469971
INFO:root:current mean train loss 1974.5374535111441
INFO:root:current train perplexity4.755762577056885
INFO:root:current mean train loss 1978.4596263690455
INFO:root:current train perplexity4.762490749359131
INFO:root:current mean train loss 1976.8467193830534
INFO:root:current train perplexity4.756475925445557
INFO:root:current mean train loss 1974.8485384161488
INFO:root:current train perplexity4.752025127410889
INFO:root:current mean train loss 1976.0137309309268
INFO:root:current train perplexity4.749706268310547
INFO:root:current mean train loss 1975.857422071729
INFO:root:current train perplexity4.747112274169922
INFO:root:current mean train loss 1976.0299812333963
INFO:root:current train perplexity4.748535633087158
INFO:root:current mean train loss 1976.3056976932523
INFO:root:current train perplexity4.750575065612793
INFO:root:current mean train loss 1975.9386412504816
INFO:root:current train perplexity4.750260829925537
INFO:root:current mean train loss 1975.2702401653432
INFO:root:current train perplexity4.748589992523193
INFO:root:current mean train loss 1975.1801013891757
INFO:root:current train perplexity4.747950553894043
INFO:root:current mean train loss 1975.2119413144817
INFO:root:current train perplexity4.746856689453125
INFO:root:current mean train loss 1975.364850428963
INFO:root:current train perplexity4.747287273406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.65s/it]
INFO:root:final mean train loss: 1975.0264607562722
INFO:root:final train perplexity: 4.747530937194824
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2835.5922983530404
INFO:root:eval perplexity: 10.245210647583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:40:06<7:14:38, 357.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.682133115571
INFO:root:current train perplexity4.684730529785156
INFO:root:current mean train loss 1957.1578454126286
INFO:root:current train perplexity4.6635637283325195
INFO:root:current mean train loss 1948.3980523634327
INFO:root:current train perplexity4.678345680236816
INFO:root:current mean train loss 1948.5376286852959
INFO:root:current train perplexity4.6744890213012695
INFO:root:current mean train loss 1952.9797501876365
INFO:root:current train perplexity4.688079357147217
INFO:root:current mean train loss 1959.168233235677
INFO:root:current train perplexity4.699232578277588
INFO:root:current mean train loss 1961.4934992920664
INFO:root:current train perplexity4.704094886779785
INFO:root:current mean train loss 1963.1906496717306
INFO:root:current train perplexity4.70775032043457
INFO:root:current mean train loss 1964.0473904554106
INFO:root:current train perplexity4.7112507820129395
INFO:root:current mean train loss 1963.5243924007534
INFO:root:current train perplexity4.707976341247559
INFO:root:current mean train loss 1962.6923998884984
INFO:root:current train perplexity4.706014633178711
INFO:root:current mean train loss 1964.010572469708
INFO:root:current train perplexity4.707015037536621
INFO:root:current mean train loss 1965.6075126999701
INFO:root:current train perplexity4.709949493408203
INFO:root:current mean train loss 1965.2729208135815
INFO:root:current train perplexity4.707498073577881
INFO:root:current mean train loss 1965.6093451103557
INFO:root:current train perplexity4.7090020179748535
INFO:root:current mean train loss 1966.5816011832828
INFO:root:current train perplexity4.711654186248779
INFO:root:current mean train loss 1966.5758455688328
INFO:root:current train perplexity4.711907386779785
INFO:root:current mean train loss 1965.9012101209205
INFO:root:current train perplexity4.709929943084717
INFO:root:current mean train loss 1966.5053414631197
INFO:root:current train perplexity4.713987350463867
INFO:root:current mean train loss 1966.7712034511858
INFO:root:current train perplexity4.714591979980469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.34s/it]
INFO:root:final mean train loss: 1966.5260377884872
INFO:root:final train perplexity: 4.715810298919678
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it]
INFO:root:eval mean loss: 2836.7543813344596
INFO:root:eval perplexity: 10.254985809326172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:46:01<7:07:59, 356.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1975.0137679036459
INFO:root:current train perplexity4.710720062255859
INFO:root:current mean train loss 1965.1834674944196
INFO:root:current train perplexity4.674046516418457
INFO:root:current mean train loss 1960.2757199928976
INFO:root:current train perplexity4.673871994018555
INFO:root:current mean train loss 1961.6990843098959
INFO:root:current train perplexity4.68489408493042
INFO:root:current mean train loss 1962.030863229852
INFO:root:current train perplexity4.689573287963867
INFO:root:current mean train loss 1957.5570987601902
INFO:root:current train perplexity4.678239345550537
INFO:root:current mean train loss 1956.9585523365163
INFO:root:current train perplexity4.677973747253418
INFO:root:current mean train loss 1960.5904057459677
INFO:root:current train perplexity4.685827255249023
INFO:root:current mean train loss 1960.66409765625
INFO:root:current train perplexity4.684024810791016
INFO:root:current mean train loss 1961.6636298076924
INFO:root:current train perplexity4.683349609375
INFO:root:current mean train loss 1962.3727306277253
INFO:root:current train perplexity4.684488773345947
INFO:root:current mean train loss 1960.6179019489693
INFO:root:current train perplexity4.684650897979736
INFO:root:current mean train loss 1958.9096414483763
INFO:root:current train perplexity4.682168483734131
INFO:root:current mean train loss 1958.0699820667614
INFO:root:current train perplexity4.684237480163574
INFO:root:current mean train loss 1957.9031084480932
INFO:root:current train perplexity4.6820197105407715
INFO:root:current mean train loss 1959.5098851376488
INFO:root:current train perplexity4.684253215789795
INFO:root:current mean train loss 1959.993783961054
INFO:root:current train perplexity4.686252117156982
INFO:root:current mean train loss 1959.2232408808318
INFO:root:current train perplexity4.6854658126831055
INFO:root:current mean train loss 1959.4844552734376
INFO:root:current train perplexity4.687173843383789
INFO:root:current mean train loss 1958.9914226290546
INFO:root:current train perplexity4.6865034103393555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.30s/it]
INFO:root:final mean train loss: 1958.6408992426839
INFO:root:final train perplexity: 4.686574459075928
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2837.3908119545326
INFO:root:eval perplexity: 10.26034164428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:52:06<7:04:48, 358.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1943.4091876486073
INFO:root:current train perplexity4.623904228210449
INFO:root:current mean train loss 1942.654094696045
INFO:root:current train perplexity4.6344451904296875
INFO:root:current mean train loss 1949.6751537584278
INFO:root:current train perplexity4.634878158569336
INFO:root:current mean train loss 1951.4764918113242
INFO:root:current train perplexity4.640031814575195
INFO:root:current mean train loss 1959.2456064611915
INFO:root:current train perplexity4.65220832824707
INFO:root:current mean train loss 1958.4704268171981
INFO:root:current train perplexity4.656263828277588
INFO:root:current mean train loss 1957.7179951750475
INFO:root:current train perplexity4.6497087478637695
INFO:root:current mean train loss 1955.4893729469993
INFO:root:current train perplexity4.648477077484131
INFO:root:current mean train loss 1956.8442900105977
INFO:root:current train perplexity4.6499457359313965
INFO:root:current mean train loss 1956.2875072110085
INFO:root:current train perplexity4.651458740234375
INFO:root:current mean train loss 1954.9912492800981
INFO:root:current train perplexity4.647899627685547
INFO:root:current mean train loss 1954.7114086791173
INFO:root:current train perplexity4.650360584259033
INFO:root:current mean train loss 1954.0855591954094
INFO:root:current train perplexity4.649814605712891
INFO:root:current mean train loss 1953.6924297288917
INFO:root:current train perplexity4.652455806732178
INFO:root:current mean train loss 1954.8950878480805
INFO:root:current train perplexity4.655569553375244
INFO:root:current mean train loss 1954.1850445617983
INFO:root:current train perplexity4.65506649017334
INFO:root:current mean train loss 1953.272169830106
INFO:root:current train perplexity4.654898643493652
INFO:root:current mean train loss 1951.486293588366
INFO:root:current train perplexity4.655970096588135
INFO:root:current mean train loss 1951.4698402453175
INFO:root:current train perplexity4.658121109008789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.10s/it]
INFO:root:final mean train loss: 1951.0749078963179
INFO:root:final train perplexity: 4.658693313598633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it]
INFO:root:eval mean loss: 2835.0935454497467
INFO:root:eval perplexity: 10.241022109985352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:58:04<6:58:35, 358.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1897.3568657769097
INFO:root:current train perplexity4.671370506286621
INFO:root:current mean train loss 1929.2049392560207
INFO:root:current train perplexity4.623226165771484
INFO:root:current mean train loss 1938.3848993766821
INFO:root:current train perplexity4.6229567527771
INFO:root:current mean train loss 1940.5884353983363
INFO:root:current train perplexity4.636500835418701
INFO:root:current mean train loss 1944.8984557060858
INFO:root:current train perplexity4.631687164306641
INFO:root:current mean train loss 1939.583456043176
INFO:root:current train perplexity4.6137590408325195
INFO:root:current mean train loss 1940.0409679193606
INFO:root:current train perplexity4.613454818725586
INFO:root:current mean train loss 1939.2887937387054
INFO:root:current train perplexity4.614546775817871
INFO:root:current mean train loss 1940.9965034173651
INFO:root:current train perplexity4.615993976593018
INFO:root:current mean train loss 1941.3433576023617
INFO:root:current train perplexity4.618253231048584
INFO:root:current mean train loss 1942.7032807031637
INFO:root:current train perplexity4.621446132659912
INFO:root:current mean train loss 1942.6440506738193
INFO:root:current train perplexity4.62274169921875
INFO:root:current mean train loss 1943.1114528204805
INFO:root:current train perplexity4.6267218589782715
INFO:root:current mean train loss 1943.7200737494927
INFO:root:current train perplexity4.627659797668457
INFO:root:current mean train loss 1944.2296227481536
INFO:root:current train perplexity4.626978874206543
INFO:root:current mean train loss 1944.024344492938
INFO:root:current train perplexity4.627983570098877
INFO:root:current mean train loss 1944.0480301538707
INFO:root:current train perplexity4.627967834472656
INFO:root:current mean train loss 1944.1869529335731
INFO:root:current train perplexity4.630582809448242
INFO:root:current mean train loss 1944.060504700348
INFO:root:current train perplexity4.631357669830322
INFO:root:current mean train loss 1943.8358878789616
INFO:root:current train perplexity4.631045818328857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.13s/it]
INFO:root:final mean train loss: 1943.5471896865545
INFO:root:final train perplexity: 4.631117343902588
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2838.614010739255
INFO:root:eval perplexity: 10.270646095275879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:04:04<6:52:57, 359.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1926.1529634915864
INFO:root:current train perplexity4.586058616638184
INFO:root:current mean train loss 1927.6747988746279
INFO:root:current train perplexity4.5696210861206055
INFO:root:current mean train loss 1930.0698382622372
INFO:root:current train perplexity4.569875240325928
INFO:root:current mean train loss 1922.994559258771
INFO:root:current train perplexity4.553103923797607
INFO:root:current mean train loss 1922.719571825484
INFO:root:current train perplexity4.55386209487915
INFO:root:current mean train loss 1925.1748148987049
INFO:root:current train perplexity4.560356616973877
INFO:root:current mean train loss 1926.997830424446
INFO:root:current train perplexity4.567099571228027
INFO:root:current mean train loss 1930.2557914460658
INFO:root:current train perplexity4.571676254272461
INFO:root:current mean train loss 1934.1928050339077
INFO:root:current train perplexity4.579891204833984
INFO:root:current mean train loss 1932.4961562352355
INFO:root:current train perplexity4.579309940338135
INFO:root:current mean train loss 1932.559431347466
INFO:root:current train perplexity4.5842790603637695
INFO:root:current mean train loss 1934.8910092070937
INFO:root:current train perplexity4.593292236328125
INFO:root:current mean train loss 1935.15134966354
INFO:root:current train perplexity4.5963454246521
INFO:root:current mean train loss 1936.0700260122078
INFO:root:current train perplexity4.596700191497803
INFO:root:current mean train loss 1935.1611512172105
INFO:root:current train perplexity4.5982255935668945
INFO:root:current mean train loss 1933.9919645576927
INFO:root:current train perplexity4.598645210266113
INFO:root:current mean train loss 1935.1146737224208
INFO:root:current train perplexity4.600964546203613
INFO:root:current mean train loss 1935.9611469856695
INFO:root:current train perplexity4.6033034324646
INFO:root:current mean train loss 1935.6690367649576
INFO:root:current train perplexity4.601912498474121
INFO:root:current mean train loss 1935.8877207913504
INFO:root:current train perplexity4.603933811187744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.56s/it]
INFO:root:final mean train loss: 1936.0172748575292
INFO:root:final train perplexity: 4.603697299957275
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.12s/it]
INFO:root:eval mean loss: 2836.4467502170137
INFO:root:eval perplexity: 10.252397537231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:09:58<6:45:23, 357.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1907.303955078125
INFO:root:current train perplexity4.4710283279418945
INFO:root:current mean train loss 1924.0555326021636
INFO:root:current train perplexity4.5205464363098145
INFO:root:current mean train loss 1930.626594951614
INFO:root:current train perplexity4.548995018005371
INFO:root:current mean train loss 1930.3699456484603
INFO:root:current train perplexity4.557953357696533
INFO:root:current mean train loss 1925.557536725804
INFO:root:current train perplexity4.5535478591918945
INFO:root:current mean train loss 1922.4506368338514
INFO:root:current train perplexity4.55171012878418
INFO:root:current mean train loss 1920.1897935170223
INFO:root:current train perplexity4.554956912994385
INFO:root:current mean train loss 1922.135882494427
INFO:root:current train perplexity4.5607008934021
INFO:root:current mean train loss 1922.6907601316911
INFO:root:current train perplexity4.563806056976318
INFO:root:current mean train loss 1925.9340772416408
INFO:root:current train perplexity4.568803787231445
INFO:root:current mean train loss 1926.6253037128101
INFO:root:current train perplexity4.571682453155518
INFO:root:current mean train loss 1926.6439013543718
INFO:root:current train perplexity4.571728229522705
INFO:root:current mean train loss 1928.3361203599532
INFO:root:current train perplexity4.573831558227539
INFO:root:current mean train loss 1928.7639024724556
INFO:root:current train perplexity4.573413848876953
INFO:root:current mean train loss 1928.7854491172363
INFO:root:current train perplexity4.573817253112793
INFO:root:current mean train loss 1930.039347225246
INFO:root:current train perplexity4.575029373168945
INFO:root:current mean train loss 1930.643021382142
INFO:root:current train perplexity4.575526714324951
INFO:root:current mean train loss 1929.9813569288315
INFO:root:current train perplexity4.576208114624023
INFO:root:current mean train loss 1929.6057345493293
INFO:root:current train perplexity4.57854700088501
INFO:root:current mean train loss 1929.8653103312572
INFO:root:current train perplexity4.579231262207031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.91s/it]
INFO:root:final mean train loss: 1928.941564947562
INFO:root:final train perplexity: 4.578078269958496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it]
INFO:root:eval mean loss: 2839.6003777214714
INFO:root:eval perplexity: 10.278960227966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:15:54<6:38:50, 357.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.4450256347657
INFO:root:current train perplexity4.470584869384766
INFO:root:current mean train loss 1900.7064849853516
INFO:root:current train perplexity4.518649101257324
INFO:root:current mean train loss 1904.6290240948017
INFO:root:current train perplexity4.529951095581055
INFO:root:current mean train loss 1907.3302707248263
INFO:root:current train perplexity4.5346503257751465
INFO:root:current mean train loss 1906.5912855065387
INFO:root:current train perplexity4.536911964416504
INFO:root:current mean train loss 1908.7135674612862
INFO:root:current train perplexity4.533756256103516
INFO:root:current mean train loss 1911.3047971783262
INFO:root:current train perplexity4.53961706161499
INFO:root:current mean train loss 1914.3417421039783
INFO:root:current train perplexity4.539975643157959
INFO:root:current mean train loss 1917.83905483512
INFO:root:current train perplexity4.543841361999512
INFO:root:current mean train loss 1918.4788356781005
INFO:root:current train perplexity4.5395402908325195
INFO:root:current mean train loss 1918.4459624668336
INFO:root:current train perplexity4.539785861968994
INFO:root:current mean train loss 1917.6916443923424
INFO:root:current train perplexity4.539361953735352
INFO:root:current mean train loss 1918.4696851942274
INFO:root:current train perplexity4.5421857833862305
INFO:root:current mean train loss 1917.9255906946519
INFO:root:current train perplexity4.54184627532959
INFO:root:current mean train loss 1917.7760901882225
INFO:root:current train perplexity4.540754318237305
INFO:root:current mean train loss 1917.3291408441005
INFO:root:current train perplexity4.541347503662109
INFO:root:current mean train loss 1917.768816035627
INFO:root:current train perplexity4.542210578918457
INFO:root:current mean train loss 1919.891926644065
INFO:root:current train perplexity4.545680999755859
INFO:root:current mean train loss 1921.2325875231015
INFO:root:current train perplexity4.549438953399658
INFO:root:current mean train loss 1922.6957429846939
INFO:root:current train perplexity4.553884506225586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.91s/it]
INFO:root:final mean train loss: 1921.8626990614068
INFO:root:final train perplexity: 4.552591323852539
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2837.222506686374
INFO:root:eval perplexity: 10.258925437927246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:21:50<6:32:22, 356.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.8860735212054
INFO:root:current train perplexity4.502224445343018
INFO:root:current mean train loss 1925.4560967569298
INFO:root:current train perplexity4.515261650085449
INFO:root:current mean train loss 1916.3221356223207
INFO:root:current train perplexity4.50993013381958
INFO:root:current mean train loss 1913.7893095547704
INFO:root:current train perplexity4.510641098022461
INFO:root:current mean train loss 1911.0231995012775
INFO:root:current train perplexity4.5152363777160645
INFO:root:current mean train loss 1912.8747093161016
INFO:root:current train perplexity4.519609451293945
INFO:root:current mean train loss 1911.943646790182
INFO:root:current train perplexity4.516266345977783
INFO:root:current mean train loss 1912.7599612202885
INFO:root:current train perplexity4.512703895568848
INFO:root:current mean train loss 1911.8682940666868
INFO:root:current train perplexity4.511512279510498
INFO:root:current mean train loss 1912.5276516120778
INFO:root:current train perplexity4.514530658721924
INFO:root:current mean train loss 1913.1886327490279
INFO:root:current train perplexity4.518130302429199
INFO:root:current mean train loss 1914.3717311706803
INFO:root:current train perplexity4.520988464355469
INFO:root:current mean train loss 1915.7787776221123
INFO:root:current train perplexity4.526462078094482
INFO:root:current mean train loss 1916.0037958814169
INFO:root:current train perplexity4.527255535125732
INFO:root:current mean train loss 1915.38454875804
INFO:root:current train perplexity4.52721643447876
INFO:root:current mean train loss 1915.1070523355759
INFO:root:current train perplexity4.525763988494873
INFO:root:current mean train loss 1916.0582252097543
INFO:root:current train perplexity4.528204917907715
INFO:root:current mean train loss 1916.4886170292277
INFO:root:current train perplexity4.5300140380859375
INFO:root:current mean train loss 1916.8603008353589
INFO:root:current train perplexity4.531956195831299
INFO:root:current mean train loss 1916.401372065373
INFO:root:current train perplexity4.531440258026123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.89s/it]
INFO:root:final mean train loss: 1915.8575474541415
INFO:root:final train perplexity: 4.531080722808838
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2835.3798879445853
INFO:root:eval perplexity: 10.243428230285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:27:46<6:26:05, 356.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.273467368268
INFO:root:current train perplexity4.551448345184326
INFO:root:current mean train loss 1916.6793496043413
INFO:root:current train perplexity4.513366222381592
INFO:root:current mean train loss 1913.7496632686277
INFO:root:current train perplexity4.497361660003662
INFO:root:current mean train loss 1910.484230312599
INFO:root:current train perplexity4.491001605987549
INFO:root:current mean train loss 1908.7453467488772
INFO:root:current train perplexity4.498276710510254
INFO:root:current mean train loss 1909.5187591655488
INFO:root:current train perplexity4.497340679168701
INFO:root:current mean train loss 1908.7034440713933
INFO:root:current train perplexity4.500226020812988
INFO:root:current mean train loss 1909.0737852005275
INFO:root:current train perplexity4.496563911437988
INFO:root:current mean train loss 1909.1102094202233
INFO:root:current train perplexity4.499929428100586
INFO:root:current mean train loss 1907.3839154310629
INFO:root:current train perplexity4.497243404388428
INFO:root:current mean train loss 1909.3764483296675
INFO:root:current train perplexity4.500725269317627
INFO:root:current mean train loss 1910.4002483118718
INFO:root:current train perplexity4.500416278839111
INFO:root:current mean train loss 1910.0470542377077
INFO:root:current train perplexity4.504189968109131
INFO:root:current mean train loss 1910.380763224926
INFO:root:current train perplexity4.504526138305664
INFO:root:current mean train loss 1910.4658708891557
INFO:root:current train perplexity4.5041656494140625
INFO:root:current mean train loss 1909.1410686344543
INFO:root:current train perplexity4.502302646636963
INFO:root:current mean train loss 1908.768844370296
INFO:root:current train perplexity4.502339839935303
INFO:root:current mean train loss 1909.630152401451
INFO:root:current train perplexity4.504883289337158
INFO:root:current mean train loss 1909.633612788844
INFO:root:current train perplexity4.506351947784424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.41s/it]
INFO:root:final mean train loss: 1908.9016434308319
INFO:root:final train perplexity: 4.506292819976807
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it]
INFO:root:eval mean loss: 2844.773163300019
INFO:root:eval perplexity: 10.322687149047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:33:41<6:19:46, 356.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.2458163174715
INFO:root:current train perplexity4.5626220703125
INFO:root:current mean train loss 1888.1585759343327
INFO:root:current train perplexity4.475480079650879
INFO:root:current mean train loss 1882.6431404583827
INFO:root:current train perplexity4.445558071136475
INFO:root:current mean train loss 1888.8559719465936
INFO:root:current train perplexity4.458532810211182
INFO:root:current mean train loss 1891.4209652643135
INFO:root:current train perplexity4.449370861053467
INFO:root:current mean train loss 1894.346640032565
INFO:root:current train perplexity4.460419178009033
INFO:root:current mean train loss 1898.1305465073906
INFO:root:current train perplexity4.470106601715088
INFO:root:current mean train loss 1898.6806003661766
INFO:root:current train perplexity4.470165729522705
INFO:root:current mean train loss 1896.5963327429004
INFO:root:current train perplexity4.469712734222412
INFO:root:current mean train loss 1895.800399495532
INFO:root:current train perplexity4.471566677093506
INFO:root:current mean train loss 1896.4100306781652
INFO:root:current train perplexity4.473226547241211
INFO:root:current mean train loss 1896.2073904289844
INFO:root:current train perplexity4.473672389984131
INFO:root:current mean train loss 1897.7580617814888
INFO:root:current train perplexity4.474625110626221
INFO:root:current mean train loss 1897.1253813882533
INFO:root:current train perplexity4.474350929260254
INFO:root:current mean train loss 1900.2422869903326
INFO:root:current train perplexity4.476395606994629
INFO:root:current mean train loss 1900.376762950602
INFO:root:current train perplexity4.478656768798828
INFO:root:current mean train loss 1901.3130108616058
INFO:root:current train perplexity4.480465888977051
INFO:root:current mean train loss 1902.2567291348946
INFO:root:current train perplexity4.480365753173828
INFO:root:current mean train loss 1902.4016955842767
INFO:root:current train perplexity4.48160982131958
INFO:root:current mean train loss 1902.2735476890575
INFO:root:current train perplexity4.481710433959961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.24s/it]
INFO:root:final mean train loss: 1902.7787839088305
INFO:root:final train perplexity: 4.484583854675293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2839.882305156719
INFO:root:eval perplexity: 10.281339645385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:39:37<6:13:50, 356.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1886.6659981863838
INFO:root:current train perplexity4.41819429397583
INFO:root:current mean train loss 1887.897047996521
INFO:root:current train perplexity4.4322004318237305
INFO:root:current mean train loss 1887.7389628092449
INFO:root:current train perplexity4.424391746520996
INFO:root:current mean train loss 1882.6228447890862
INFO:root:current train perplexity4.4232940673828125
INFO:root:current mean train loss 1882.2399845301547
INFO:root:current train perplexity4.4281206130981445
INFO:root:current mean train loss 1885.109963388154
INFO:root:current train perplexity4.4374823570251465
INFO:root:current mean train loss 1885.9360232991019
INFO:root:current train perplexity4.437999725341797
INFO:root:current mean train loss 1885.250734098665
INFO:root:current train perplexity4.439535617828369
INFO:root:current mean train loss 1886.2332657523777
INFO:root:current train perplexity4.445596218109131
INFO:root:current mean train loss 1886.831738570641
INFO:root:current train perplexity4.44813346862793
INFO:root:current mean train loss 1889.0829259968916
INFO:root:current train perplexity4.4496989250183105
INFO:root:current mean train loss 1890.3716377637065
INFO:root:current train perplexity4.449685096740723
INFO:root:current mean train loss 1890.1102003662904
INFO:root:current train perplexity4.4519243240356445
INFO:root:current mean train loss 1891.0875279989586
INFO:root:current train perplexity4.452479362487793
INFO:root:current mean train loss 1890.3818169601825
INFO:root:current train perplexity4.451490879058838
INFO:root:current mean train loss 1892.6197596045688
INFO:root:current train perplexity4.455870628356934
INFO:root:current mean train loss 1895.233628931444
INFO:root:current train perplexity4.459958553314209
INFO:root:current mean train loss 1896.687369523225
INFO:root:current train perplexity4.461121082305908
INFO:root:current mean train loss 1897.4092013903728
INFO:root:current train perplexity4.463115692138672
INFO:root:current mean train loss 1897.1795722043366
INFO:root:current train perplexity4.462514877319336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.75s/it]
INFO:root:final mean train loss: 1896.6658261482366
INFO:root:final train perplexity: 4.463015556335449
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 2846.531240468985
INFO:root:eval perplexity: 10.3375883102417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:45:34<6:08:11, 356.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.0493923611111
INFO:root:current train perplexity4.410286903381348
INFO:root:current mean train loss 1889.4412084119074
INFO:root:current train perplexity4.416845798492432
INFO:root:current mean train loss 1892.6567706672513
INFO:root:current train perplexity4.4261794090271
INFO:root:current mean train loss 1885.599956125453
INFO:root:current train perplexity4.419095039367676
INFO:root:current mean train loss 1887.6575332470154
INFO:root:current train perplexity4.422999858856201
INFO:root:current mean train loss 1886.0262265266629
INFO:root:current train perplexity4.421008586883545
INFO:root:current mean train loss 1886.8991920648618
INFO:root:current train perplexity4.420535087585449
INFO:root:current mean train loss 1885.253632288171
INFO:root:current train perplexity4.416870594024658
INFO:root:current mean train loss 1886.5816835301869
INFO:root:current train perplexity4.417748928070068
INFO:root:current mean train loss 1886.9246051122273
INFO:root:current train perplexity4.4188151359558105
INFO:root:current mean train loss 1887.5301792856608
INFO:root:current train perplexity4.422834396362305
INFO:root:current mean train loss 1888.9349026209402
INFO:root:current train perplexity4.42700719833374
INFO:root:current mean train loss 1889.5156691217996
INFO:root:current train perplexity4.42980432510376
INFO:root:current mean train loss 1887.8763786230832
INFO:root:current train perplexity4.431134223937988
INFO:root:current mean train loss 1889.423894777925
INFO:root:current train perplexity4.432424068450928
INFO:root:current mean train loss 1889.6088630157767
INFO:root:current train perplexity4.432931423187256
INFO:root:current mean train loss 1890.1286854103344
INFO:root:current train perplexity4.4345011711120605
INFO:root:current mean train loss 1890.8952037210108
INFO:root:current train perplexity4.436715126037598
INFO:root:current mean train loss 1891.2378672695418
INFO:root:current train perplexity4.438951015472412
INFO:root:current mean train loss 1891.0786401429948
INFO:root:current train perplexity4.439885139465332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.47s/it]
INFO:root:final mean train loss: 1890.6563949084798
INFO:root:final train perplexity: 4.441913604736328
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it]
INFO:root:eval mean loss: 2842.6837257179054
INFO:root:eval perplexity: 10.305000305175781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:51:30<6:02:14, 356.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.5965536794354
INFO:root:current train perplexity4.378965854644775
INFO:root:current mean train loss 1873.502749596113
INFO:root:current train perplexity4.385750770568848
INFO:root:current mean train loss 1880.1442046420266
INFO:root:current train perplexity4.388835906982422
INFO:root:current mean train loss 1880.4763345454937
INFO:root:current train perplexity4.392329216003418
INFO:root:current mean train loss 1876.5532533059388
INFO:root:current train perplexity4.394232749938965
INFO:root:current mean train loss 1879.2669877564779
INFO:root:current train perplexity4.407382488250732
INFO:root:current mean train loss 1879.1002567902071
INFO:root:current train perplexity4.4086480140686035
INFO:root:current mean train loss 1879.248497670091
INFO:root:current train perplexity4.4086809158325195
INFO:root:current mean train loss 1881.8927705769197
INFO:root:current train perplexity4.415853977203369
INFO:root:current mean train loss 1881.1134286987558
INFO:root:current train perplexity4.415438652038574
INFO:root:current mean train loss 1882.5831309173066
INFO:root:current train perplexity4.414255619049072
INFO:root:current mean train loss 1882.6074967770076
INFO:root:current train perplexity4.411468029022217
INFO:root:current mean train loss 1881.757658896469
INFO:root:current train perplexity4.410690784454346
INFO:root:current mean train loss 1882.7870649206131
INFO:root:current train perplexity4.413975238800049
INFO:root:current mean train loss 1882.6958658241867
INFO:root:current train perplexity4.41723108291626
INFO:root:current mean train loss 1883.6451734867658
INFO:root:current train perplexity4.4184956550598145
INFO:root:current mean train loss 1884.6300711327656
INFO:root:current train perplexity4.419510841369629
INFO:root:current mean train loss 1884.9035032101306
INFO:root:current train perplexity4.420844078063965
INFO:root:current mean train loss 1885.4827948384843
INFO:root:current train perplexity4.421383380889893
INFO:root:current mean train loss 1885.7619057129405
INFO:root:current train perplexity4.42171573638916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.95s/it]
INFO:root:final mean train loss: 1885.1848091591023
INFO:root:final train perplexity: 4.422787189483643
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2844.42175256311
INFO:root:eval perplexity: 10.319709777832031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:57:29<5:57:03, 357.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.9206712940072
INFO:root:current train perplexity4.406230449676514
INFO:root:current mean train loss 1880.84439103963
INFO:root:current train perplexity4.394218444824219
INFO:root:current mean train loss 1876.4192997101813
INFO:root:current train perplexity4.389225482940674
INFO:root:current mean train loss 1876.711196778632
INFO:root:current train perplexity4.395670413970947
INFO:root:current mean train loss 1875.4989072286012
INFO:root:current train perplexity4.396115779876709
INFO:root:current mean train loss 1878.3989240946134
INFO:root:current train perplexity4.392319202423096
INFO:root:current mean train loss 1878.8705080282355
INFO:root:current train perplexity4.39273738861084
INFO:root:current mean train loss 1880.934329776005
INFO:root:current train perplexity4.398787975311279
INFO:root:current mean train loss 1880.054997883559
INFO:root:current train perplexity4.398784637451172
INFO:root:current mean train loss 1880.7758918738828
INFO:root:current train perplexity4.40017557144165
INFO:root:current mean train loss 1880.620912284957
INFO:root:current train perplexity4.398241996765137
INFO:root:current mean train loss 1880.6349719745613
INFO:root:current train perplexity4.401978492736816
INFO:root:current mean train loss 1881.3053930072322
INFO:root:current train perplexity4.400124549865723
INFO:root:current mean train loss 1882.4721034370184
INFO:root:current train perplexity4.405255317687988
INFO:root:current mean train loss 1882.7499542752175
INFO:root:current train perplexity4.405683994293213
INFO:root:current mean train loss 1881.5832695794907
INFO:root:current train perplexity4.405440330505371
INFO:root:current mean train loss 1880.7953329444144
INFO:root:current train perplexity4.402247428894043
INFO:root:current mean train loss 1879.7528649126969
INFO:root:current train perplexity4.401663780212402
INFO:root:current mean train loss 1879.4057915379483
INFO:root:current train perplexity4.40209436416626
INFO:root:current mean train loss 1879.6614077328552
INFO:root:current train perplexity4.401758670806885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.90s/it]
INFO:root:final mean train loss: 1879.1239041373155
INFO:root:final train perplexity: 4.401696681976318
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 2846.567652613551
INFO:root:eval perplexity: 10.337896347045898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:03:25<5:50:50, 356.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1856.9222221374512
INFO:root:current train perplexity4.337116718292236
INFO:root:current mean train loss 1856.8369807029258
INFO:root:current train perplexity4.336863040924072
INFO:root:current mean train loss 1864.079546541781
INFO:root:current train perplexity4.358011245727539
INFO:root:current mean train loss 1865.8834687820588
INFO:root:current train perplexity4.360131740570068
INFO:root:current mean train loss 1865.1292343139648
INFO:root:current train perplexity4.365853786468506
INFO:root:current mean train loss 1867.9218428438942
INFO:root:current train perplexity4.360703468322754
INFO:root:current mean train loss 1865.1141999343347
INFO:root:current train perplexity4.358150482177734
INFO:root:current mean train loss 1866.533923125147
INFO:root:current train perplexity4.362604141235352
INFO:root:current mean train loss 1867.7523815972465
INFO:root:current train perplexity4.3644914627075195
INFO:root:current mean train loss 1867.947883820438
INFO:root:current train perplexity4.3670573234558105
INFO:root:current mean train loss 1868.4497764197579
INFO:root:current train perplexity4.363894462585449
INFO:root:current mean train loss 1869.5299257004142
INFO:root:current train perplexity4.365877628326416
INFO:root:current mean train loss 1871.235434072989
INFO:root:current train perplexity4.368938446044922
INFO:root:current mean train loss 1871.221466239339
INFO:root:current train perplexity4.371582508087158
INFO:root:current mean train loss 1872.2063427277428
INFO:root:current train perplexity4.375388145446777
INFO:root:current mean train loss 1874.4784907673236
INFO:root:current train perplexity4.378838062286377
INFO:root:current mean train loss 1874.5914794633973
INFO:root:current train perplexity4.380228519439697
INFO:root:current mean train loss 1874.4339740302887
INFO:root:current train perplexity4.381138324737549
INFO:root:current mean train loss 1874.856554313048
INFO:root:current train perplexity4.38282585144043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.21s/it]
INFO:root:final mean train loss: 1874.0473270849093
INFO:root:final train perplexity: 4.384108543395996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it]
INFO:root:eval mean loss: 2847.242821679101
INFO:root:eval perplexity: 10.343626022338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:09:21<5:44:43, 356.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.9692758413462
INFO:root:current train perplexity4.431873798370361
INFO:root:current mean train loss 1853.1093037022954
INFO:root:current train perplexity4.371127128601074
INFO:root:current mean train loss 1853.0055705325703
INFO:root:current train perplexity4.359328269958496
INFO:root:current mean train loss 1856.8249016417483
INFO:root:current train perplexity4.3432416915893555
INFO:root:current mean train loss 1856.6414324965951
INFO:root:current train perplexity4.344630241394043
INFO:root:current mean train loss 1859.691062406722
INFO:root:current train perplexity4.341932773590088
INFO:root:current mean train loss 1861.3281899183064
INFO:root:current train perplexity4.350648880004883
INFO:root:current mean train loss 1864.5079311461802
INFO:root:current train perplexity4.350973606109619
INFO:root:current mean train loss 1864.324122054697
INFO:root:current train perplexity4.355237007141113
INFO:root:current mean train loss 1866.215626711391
INFO:root:current train perplexity4.354692459106445
INFO:root:current mean train loss 1867.4360904674775
INFO:root:current train perplexity4.3562703132629395
INFO:root:current mean train loss 1867.630399609726
INFO:root:current train perplexity4.359068393707275
INFO:root:current mean train loss 1867.703662189883
INFO:root:current train perplexity4.361087799072266
INFO:root:current mean train loss 1867.7236480596678
INFO:root:current train perplexity4.360628604888916
INFO:root:current mean train loss 1869.39092857755
INFO:root:current train perplexity4.363821029663086
INFO:root:current mean train loss 1869.3677979322435
INFO:root:current train perplexity4.365066051483154
INFO:root:current mean train loss 1867.878911774571
INFO:root:current train perplexity4.360427379608154
INFO:root:current mean train loss 1868.288521984343
INFO:root:current train perplexity4.362266540527344
INFO:root:current mean train loss 1867.6026155500206
INFO:root:current train perplexity4.360816478729248
INFO:root:current mean train loss 1868.689847731802
INFO:root:current train perplexity4.363656997680664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.27s/it]
INFO:root:final mean train loss: 1868.7252168333175
INFO:root:final train perplexity: 4.36574649810791
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2848.2562046910193
INFO:root:eval perplexity: 10.3522310256958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:15:20<5:39:27, 357.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.347900390625
INFO:root:current train perplexity4.386693954467773
INFO:root:current mean train loss 1867.448981182392
INFO:root:current train perplexity4.346547603607178
INFO:root:current mean train loss 1873.7900247325067
INFO:root:current train perplexity4.357409477233887
INFO:root:current mean train loss 1869.8314412434895
INFO:root:current train perplexity4.339634418487549
INFO:root:current mean train loss 1865.141723348928
INFO:root:current train perplexity4.337364196777344
INFO:root:current mean train loss 1865.3710794700767
INFO:root:current train perplexity4.332718849182129
INFO:root:current mean train loss 1863.0397073412698
INFO:root:current train perplexity4.332611083984375
INFO:root:current mean train loss 1864.2071479692852
INFO:root:current train perplexity4.336926460266113
INFO:root:current mean train loss 1865.6968699995293
INFO:root:current train perplexity4.336845397949219
INFO:root:current mean train loss 1865.5779418945312
INFO:root:current train perplexity4.338037490844727
INFO:root:current mean train loss 1864.8520191377806
INFO:root:current train perplexity4.340088367462158
INFO:root:current mean train loss 1864.6435439928443
INFO:root:current train perplexity4.339902877807617
INFO:root:current mean train loss 1865.269387842194
INFO:root:current train perplexity4.343592643737793
INFO:root:current mean train loss 1864.7320536448544
INFO:root:current train perplexity4.342273712158203
INFO:root:current mean train loss 1865.125054718231
INFO:root:current train perplexity4.345396518707275
INFO:root:current mean train loss 1863.4514875025532
INFO:root:current train perplexity4.3433074951171875
INFO:root:current mean train loss 1863.5059269255655
INFO:root:current train perplexity4.346630573272705
INFO:root:current mean train loss 1864.4087500423366
INFO:root:current train perplexity4.3471479415893555
INFO:root:current mean train loss 1864.3102405652323
INFO:root:current train perplexity4.348598957061768
INFO:root:current mean train loss 1863.4542604436529
INFO:root:current train perplexity4.34602165222168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.93s/it]
INFO:root:final mean train loss: 1863.2836846348257
INFO:root:final train perplexity: 4.347050666809082
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it]
INFO:root:eval mean loss: 2848.3541358741554
INFO:root:eval perplexity: 10.353062629699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:21:20<5:34:13, 358.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1845.1138682263963
INFO:root:current train perplexity4.303157329559326
INFO:root:current mean train loss 1830.9008025085034
INFO:root:current train perplexity4.27398681640625
INFO:root:current mean train loss 1844.0540692410489
INFO:root:current train perplexity4.280179500579834
INFO:root:current mean train loss 1851.5833483429394
INFO:root:current train perplexity4.3068461418151855
INFO:root:current mean train loss 1853.2093571400483
INFO:root:current train perplexity4.310904026031494
INFO:root:current mean train loss 1853.9356187335752
INFO:root:current train perplexity4.3141961097717285
INFO:root:current mean train loss 1853.5516768725247
INFO:root:current train perplexity4.315018653869629
INFO:root:current mean train loss 1853.69551872856
INFO:root:current train perplexity4.306820392608643
INFO:root:current mean train loss 1856.5873347510976
INFO:root:current train perplexity4.31461238861084
INFO:root:current mean train loss 1856.7553603948736
INFO:root:current train perplexity4.312536239624023
INFO:root:current mean train loss 1856.6039290551128
INFO:root:current train perplexity4.318020343780518
INFO:root:current mean train loss 1858.264122375116
INFO:root:current train perplexity4.320781230926514
INFO:root:current mean train loss 1856.5212165447074
INFO:root:current train perplexity4.319408416748047
INFO:root:current mean train loss 1855.4566528954679
INFO:root:current train perplexity4.318756580352783
INFO:root:current mean train loss 1856.5290629420515
INFO:root:current train perplexity4.320697784423828
INFO:root:current mean train loss 1858.0013048188025
INFO:root:current train perplexity4.327561378479004
INFO:root:current mean train loss 1857.3011605054883
INFO:root:current train perplexity4.326746463775635
INFO:root:current mean train loss 1857.1376923079074
INFO:root:current train perplexity4.325328350067139
INFO:root:current mean train loss 1857.6038152160809
INFO:root:current train perplexity4.326919078826904
INFO:root:current mean train loss 1858.8349257020016
INFO:root:current train perplexity4.329838275909424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.56s/it]
INFO:root:final mean train loss: 1858.216340234769
INFO:root:final train perplexity: 4.329712867736816
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it]
INFO:root:eval mean loss: 2852.550219653247
INFO:root:eval perplexity: 10.388772964477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:27:17<5:27:54, 357.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1846.4421825408936
INFO:root:current train perplexity4.287792682647705
INFO:root:current mean train loss 1853.5983521996475
INFO:root:current train perplexity4.296546459197998
INFO:root:current mean train loss 1853.8711150198271
INFO:root:current train perplexity4.3070197105407715
INFO:root:current mean train loss 1854.546831738818
INFO:root:current train perplexity4.322904109954834
INFO:root:current mean train loss 1853.8663372171336
INFO:root:current train perplexity4.315234184265137
INFO:root:current mean train loss 1852.786767188539
INFO:root:current train perplexity4.31246280670166
INFO:root:current mean train loss 1850.3986733677875
INFO:root:current train perplexity4.307642459869385
INFO:root:current mean train loss 1849.733045168572
INFO:root:current train perplexity4.30826997756958
INFO:root:current mean train loss 1851.8800694500958
INFO:root:current train perplexity4.311326026916504
INFO:root:current mean train loss 1852.7787027319437
INFO:root:current train perplexity4.312572479248047
INFO:root:current mean train loss 1851.2100036162183
INFO:root:current train perplexity4.311256408691406
INFO:root:current mean train loss 1852.4380952500806
INFO:root:current train perplexity4.310546398162842
INFO:root:current mean train loss 1853.4400483143481
INFO:root:current train perplexity4.31104850769043
INFO:root:current mean train loss 1854.6755965336326
INFO:root:current train perplexity4.311509609222412
INFO:root:current mean train loss 1855.3067881266277
INFO:root:current train perplexity4.3106489181518555
INFO:root:current mean train loss 1855.137415268842
INFO:root:current train perplexity4.310807228088379
INFO:root:current mean train loss 1853.9427423477173
INFO:root:current train perplexity4.311949253082275
INFO:root:current mean train loss 1854.0121999727626
INFO:root:current train perplexity4.3118486404418945
INFO:root:current mean train loss 1853.7398839467585
INFO:root:current train perplexity4.3128461837768555
INFO:root:current mean train loss 1853.839298597907
INFO:root:current train perplexity4.312570571899414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.82s/it]
INFO:root:final mean train loss: 1853.1691799115727
INFO:root:final train perplexity: 4.312511920928955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 2850.6667751736113
INFO:root:eval perplexity: 10.372727394104004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:33:13<5:21:33, 357.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1853.6220793547454
INFO:root:current train perplexity4.292980670928955
INFO:root:current mean train loss 1853.1850558960634
INFO:root:current train perplexity4.281664848327637
INFO:root:current mean train loss 1853.1876542169427
INFO:root:current train perplexity4.282443523406982
INFO:root:current mean train loss 1853.255761013882
INFO:root:current train perplexity4.282192230224609
INFO:root:current mean train loss 1848.8967526251463
INFO:root:current train perplexity4.281660556793213
INFO:root:current mean train loss 1849.7838031814758
INFO:root:current train perplexity4.285397052764893
INFO:root:current mean train loss 1850.500197714471
INFO:root:current train perplexity4.292942047119141
INFO:root:current mean train loss 1852.0741763926956
INFO:root:current train perplexity4.294490814208984
INFO:root:current mean train loss 1854.496969857362
INFO:root:current train perplexity4.296088695526123
INFO:root:current mean train loss 1851.6811002056654
INFO:root:current train perplexity4.294146537780762
INFO:root:current mean train loss 1851.2983452640783
INFO:root:current train perplexity4.293598175048828
INFO:root:current mean train loss 1851.5481414924125
INFO:root:current train perplexity4.294489860534668
INFO:root:current mean train loss 1852.0248323034068
INFO:root:current train perplexity4.298586845397949
INFO:root:current mean train loss 1851.6581394822592
INFO:root:current train perplexity4.299147129058838
INFO:root:current mean train loss 1850.9898955289132
INFO:root:current train perplexity4.29945182800293
INFO:root:current mean train loss 1849.815689193079
INFO:root:current train perplexity4.297505855560303
INFO:root:current mean train loss 1850.2247361654613
INFO:root:current train perplexity4.296901226043701
INFO:root:current mean train loss 1850.1127079787514
INFO:root:current train perplexity4.297857761383057
INFO:root:current mean train loss 1848.9953094758232
INFO:root:current train perplexity4.297025680541992
INFO:root:current mean train loss 1849.4896934081785
INFO:root:current train perplexity4.298094749450684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.09s/it]
INFO:root:final mean train loss: 1848.882164782487
INFO:root:final train perplexity: 4.297956466674805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2855.518021683793
INFO:root:eval perplexity: 10.414102554321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:39:10<5:15:24, 357.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1843.2697280572386
INFO:root:current train perplexity4.243503093719482
INFO:root:current mean train loss 1840.155188974708
INFO:root:current train perplexity4.243354797363281
INFO:root:current mean train loss 1839.2504657514944
INFO:root:current train perplexity4.2635016441345215
INFO:root:current mean train loss 1837.081108054923
INFO:root:current train perplexity4.2629804611206055
INFO:root:current mean train loss 1838.4442361732085
INFO:root:current train perplexity4.262327194213867
INFO:root:current mean train loss 1839.0453491210938
INFO:root:current train perplexity4.26425313949585
INFO:root:current mean train loss 1842.3311291888656
INFO:root:current train perplexity4.2721991539001465
INFO:root:current mean train loss 1842.5359250788104
INFO:root:current train perplexity4.2756428718566895
INFO:root:current mean train loss 1843.2433082903415
INFO:root:current train perplexity4.278169631958008
INFO:root:current mean train loss 1841.7303255192026
INFO:root:current train perplexity4.275173187255859
INFO:root:current mean train loss 1843.8841186968139
INFO:root:current train perplexity4.2755279541015625
INFO:root:current mean train loss 1844.4659201696838
INFO:root:current train perplexity4.278081893920898
INFO:root:current mean train loss 1842.6902247636087
INFO:root:current train perplexity4.275824069976807
INFO:root:current mean train loss 1843.3080107289152
INFO:root:current train perplexity4.278698921203613
INFO:root:current mean train loss 1843.19816998837
INFO:root:current train perplexity4.2798895835876465
INFO:root:current mean train loss 1843.7739553439603
INFO:root:current train perplexity4.2828593254089355
INFO:root:current mean train loss 1844.0375683967582
INFO:root:current train perplexity4.283176898956299
INFO:root:current mean train loss 1844.0127646984063
INFO:root:current train perplexity4.2821526527404785
INFO:root:current mean train loss 1844.134832641473
INFO:root:current train perplexity4.28162956237793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.40s/it]
INFO:root:final mean train loss: 1844.2076496041548
INFO:root:final train perplexity: 4.28214168548584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2856.899876683324
INFO:root:eval perplexity: 10.425917625427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:45:08<5:09:44, 357.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.0425211588542
INFO:root:current train perplexity4.0570783615112305
INFO:root:current mean train loss 1835.6335746433424
INFO:root:current train perplexity4.2480926513671875
INFO:root:current mean train loss 1839.4615472837936
INFO:root:current train perplexity4.23832893371582
INFO:root:current mean train loss 1838.1036768353174
INFO:root:current train perplexity4.236123561859131
INFO:root:current mean train loss 1841.575545051299
INFO:root:current train perplexity4.24678897857666
INFO:root:current mean train loss 1837.4238696052032
INFO:root:current train perplexity4.238378047943115
INFO:root:current mean train loss 1834.3075909870427
INFO:root:current train perplexity4.2382402420043945
INFO:root:current mean train loss 1835.7892591783216
INFO:root:current train perplexity4.245758533477783
INFO:root:current mean train loss 1835.328194947038
INFO:root:current train perplexity4.249575614929199
INFO:root:current mean train loss 1834.360955643784
INFO:root:current train perplexity4.251017093658447
INFO:root:current mean train loss 1836.5569630589978
INFO:root:current train perplexity4.255495071411133
INFO:root:current mean train loss 1837.7099218531039
INFO:root:current train perplexity4.253418922424316
INFO:root:current mean train loss 1838.6736595373586
INFO:root:current train perplexity4.253286361694336
INFO:root:current mean train loss 1838.8798717658328
INFO:root:current train perplexity4.25488805770874
INFO:root:current mean train loss 1838.2298439052838
INFO:root:current train perplexity4.256647109985352
INFO:root:current mean train loss 1837.7512192527847
INFO:root:current train perplexity4.259085655212402
INFO:root:current mean train loss 1838.6816128851829
INFO:root:current train perplexity4.260608196258545
INFO:root:current mean train loss 1838.5687120621128
INFO:root:current train perplexity4.26227331161499
INFO:root:current mean train loss 1839.5954744533403
INFO:root:current train perplexity4.264167785644531
INFO:root:current mean train loss 1839.790299967873
INFO:root:current train perplexity4.2670063972473145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.55s/it]
INFO:root:final mean train loss: 1840.2743432703369
INFO:root:final train perplexity: 4.268877983093262
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2855.87866137622
INFO:root:eval perplexity: 10.417183876037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:51:04<5:03:29, 357.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.7294540405273
INFO:root:current train perplexity4.29095458984375
INFO:root:current mean train loss 1833.5381312514796
INFO:root:current train perplexity4.206876277923584
INFO:root:current mean train loss 1829.207004941743
INFO:root:current train perplexity4.203938961029053
INFO:root:current mean train loss 1830.5565395125423
INFO:root:current train perplexity4.214800834655762
INFO:root:current mean train loss 1832.5582897044994
INFO:root:current train perplexity4.22418737411499
INFO:root:current mean train loss 1829.7234226312853
INFO:root:current train perplexity4.228094100952148
INFO:root:current mean train loss 1830.3510145356383
INFO:root:current train perplexity4.233206748962402
INFO:root:current mean train loss 1831.7760081473596
INFO:root:current train perplexity4.237318515777588
INFO:root:current mean train loss 1831.6789274949294
INFO:root:current train perplexity4.238788604736328
INFO:root:current mean train loss 1831.946985465774
INFO:root:current train perplexity4.24057149887085
INFO:root:current mean train loss 1831.00449282624
INFO:root:current train perplexity4.238659858703613
INFO:root:current mean train loss 1833.0458586460288
INFO:root:current train perplexity4.241577625274658
INFO:root:current mean train loss 1833.671715377213
INFO:root:current train perplexity4.2425923347473145
INFO:root:current mean train loss 1832.7654606816288
INFO:root:current train perplexity4.241278648376465
INFO:root:current mean train loss 1832.3144544036695
INFO:root:current train perplexity4.241392612457275
INFO:root:current mean train loss 1832.7199854439916
INFO:root:current train perplexity4.242160797119141
INFO:root:current mean train loss 1833.8833547105976
INFO:root:current train perplexity4.244450092315674
INFO:root:current mean train loss 1833.4322880487243
INFO:root:current train perplexity4.245481967926025
INFO:root:current mean train loss 1834.794222902523
INFO:root:current train perplexity4.248123645782471
INFO:root:current mean train loss 1834.8094937342294
INFO:root:current train perplexity4.250097751617432

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.18s/it]
INFO:root:final mean train loss: 1835.2252828239252
INFO:root:final train perplexity: 4.251913547515869
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it]
INFO:root:eval mean loss: 2857.7223197318413
INFO:root:eval perplexity: 10.432954788208008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:57:00<4:57:20, 356.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.357516541773
INFO:root:current train perplexity4.195353031158447
INFO:root:current mean train loss 1818.2127153025378
INFO:root:current train perplexity4.169392108917236
INFO:root:current mean train loss 1819.9158538450677
INFO:root:current train perplexity4.192926406860352
INFO:root:current mean train loss 1821.8985662159741
INFO:root:current train perplexity4.203359603881836
INFO:root:current mean train loss 1827.0390464595803
INFO:root:current train perplexity4.206805229187012
INFO:root:current mean train loss 1827.1619706284152
INFO:root:current train perplexity4.20912504196167
INFO:root:current mean train loss 1825.6044649144717
INFO:root:current train perplexity4.2120361328125
INFO:root:current mean train loss 1827.5950857653954
INFO:root:current train perplexity4.2168660163879395
INFO:root:current mean train loss 1827.3738982039993
INFO:root:current train perplexity4.216730117797852
INFO:root:current mean train loss 1829.6614368949222
INFO:root:current train perplexity4.223721504211426
INFO:root:current mean train loss 1830.8501985475377
INFO:root:current train perplexity4.2305006980896
INFO:root:current mean train loss 1830.4231165262593
INFO:root:current train perplexity4.2330322265625
INFO:root:current mean train loss 1830.515505763986
INFO:root:current train perplexity4.235881328582764
INFO:root:current mean train loss 1829.0574351226603
INFO:root:current train perplexity4.2338337898254395
INFO:root:current mean train loss 1828.8255414732412
INFO:root:current train perplexity4.233932018280029
INFO:root:current mean train loss 1828.6883012194107
INFO:root:current train perplexity4.233767032623291
INFO:root:current mean train loss 1829.0886759020618
INFO:root:current train perplexity4.234776973724365
INFO:root:current mean train loss 1829.307889106275
INFO:root:current train perplexity4.235505104064941
INFO:root:current mean train loss 1829.8843225672026
INFO:root:current train perplexity4.235491752624512
INFO:root:current mean train loss 1831.4684749816613
INFO:root:current train perplexity4.237763404846191

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.73s/it]
INFO:root:final mean train loss: 1830.699841105451
INFO:root:final train perplexity: 4.236764907836914
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 2856.7208380255256
INFO:root:eval perplexity: 10.424386978149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:02:58<4:51:39, 357.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.916846073035
INFO:root:current train perplexity4.194880485534668
INFO:root:current mean train loss 1821.7740213784828
INFO:root:current train perplexity4.210252285003662
INFO:root:current mean train loss 1823.9179696678218
INFO:root:current train perplexity4.195445537567139
INFO:root:current mean train loss 1822.8515488254568
INFO:root:current train perplexity4.208225727081299
INFO:root:current mean train loss 1822.7101673568268
INFO:root:current train perplexity4.205411911010742
INFO:root:current mean train loss 1828.4545169466376
INFO:root:current train perplexity4.208821773529053
INFO:root:current mean train loss 1829.043639220275
INFO:root:current train perplexity4.21003532409668
INFO:root:current mean train loss 1826.0171089670366
INFO:root:current train perplexity4.2075395584106445
INFO:root:current mean train loss 1828.0385209363271
INFO:root:current train perplexity4.2130279541015625
INFO:root:current mean train loss 1826.5282861934686
INFO:root:current train perplexity4.210911750793457
INFO:root:current mean train loss 1826.2169113874884
INFO:root:current train perplexity4.215980529785156
INFO:root:current mean train loss 1824.9903131030233
INFO:root:current train perplexity4.213386535644531
INFO:root:current mean train loss 1825.8027390032582
INFO:root:current train perplexity4.2148823738098145
INFO:root:current mean train loss 1825.1096761544313
INFO:root:current train perplexity4.217041969299316
INFO:root:current mean train loss 1824.4825712570878
INFO:root:current train perplexity4.2170796394348145
INFO:root:current mean train loss 1825.7905263303949
INFO:root:current train perplexity4.219950199127197
INFO:root:current mean train loss 1825.613553600151
INFO:root:current train perplexity4.21964693069458
INFO:root:current mean train loss 1826.504915438314
INFO:root:current train perplexity4.220357418060303
INFO:root:current mean train loss 1826.2766838114617
INFO:root:current train perplexity4.220647811889648
INFO:root:current mean train loss 1826.5179574991655
INFO:root:current train perplexity4.221201419830322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.50s/it]
INFO:root:final mean train loss: 1826.2939682122258
INFO:root:final train perplexity: 4.222068786621094
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2861.617816547016
INFO:root:eval perplexity: 10.46635913848877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:08:57<4:46:05, 357.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1819.3328298545746
INFO:root:current train perplexity4.209391117095947
INFO:root:current mean train loss 1814.9707137978141
INFO:root:current train perplexity4.194813251495361
INFO:root:current mean train loss 1810.2152211758778
INFO:root:current train perplexity4.179039478302002
INFO:root:current mean train loss 1812.6380780969525
INFO:root:current train perplexity4.188794136047363
INFO:root:current mean train loss 1812.5521214961018
INFO:root:current train perplexity4.186884880065918
INFO:root:current mean train loss 1812.783156223199
INFO:root:current train perplexity4.193116664886475
INFO:root:current mean train loss 1815.8467365225797
INFO:root:current train perplexity4.1965742111206055
INFO:root:current mean train loss 1815.8299831814236
INFO:root:current train perplexity4.192681312561035
INFO:root:current mean train loss 1817.7891588567472
INFO:root:current train perplexity4.19460916519165
INFO:root:current mean train loss 1818.4248035698674
INFO:root:current train perplexity4.197864055633545
INFO:root:current mean train loss 1818.2911617036011
INFO:root:current train perplexity4.197443008422852
INFO:root:current mean train loss 1819.388766600737
INFO:root:current train perplexity4.203677177429199
INFO:root:current mean train loss 1818.360248996797
INFO:root:current train perplexity4.204702854156494
INFO:root:current mean train loss 1819.6748417587446
INFO:root:current train perplexity4.207351207733154
INFO:root:current mean train loss 1821.2196486120038
INFO:root:current train perplexity4.208332061767578
INFO:root:current mean train loss 1822.558013935294
INFO:root:current train perplexity4.209643840789795
INFO:root:current mean train loss 1822.6977824110822
INFO:root:current train perplexity4.208683013916016
INFO:root:current mean train loss 1823.4506705856966
INFO:root:current train perplexity4.210333824157715
INFO:root:current mean train loss 1823.577064356143
INFO:root:current train perplexity4.211277961730957
INFO:root:current mean train loss 1823.1612643628066
INFO:root:current train perplexity4.211650848388672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.67s/it]
INFO:root:final mean train loss: 1823.1612643628066
INFO:root:final train perplexity: 4.211650848388672
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2862.754788968656
INFO:root:eval perplexity: 10.476128578186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:14:53<4:39:41, 357.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.3789599609374
INFO:root:current train perplexity4.255600452423096
INFO:root:current mean train loss 1827.1297802734375
INFO:root:current train perplexity4.22606897354126
INFO:root:current mean train loss 1814.6792036946615
INFO:root:current train perplexity4.202561378479004
INFO:root:current mean train loss 1814.286658630371
INFO:root:current train perplexity4.195306301116943
INFO:root:current mean train loss 1813.4851362304687
INFO:root:current train perplexity4.191256046295166
INFO:root:current mean train loss 1818.2696122233074
INFO:root:current train perplexity4.197673320770264
INFO:root:current mean train loss 1816.0622848074777
INFO:root:current train perplexity4.189443111419678
INFO:root:current mean train loss 1816.0023281860351
INFO:root:current train perplexity4.192341327667236
INFO:root:current mean train loss 1817.0803671603733
INFO:root:current train perplexity4.193770885467529
INFO:root:current mean train loss 1816.6455281982421
INFO:root:current train perplexity4.193614482879639
INFO:root:current mean train loss 1819.2310860928621
INFO:root:current train perplexity4.197112083435059
INFO:root:current mean train loss 1819.7746787516276
INFO:root:current train perplexity4.198012828826904
INFO:root:current mean train loss 1820.5433328951322
INFO:root:current train perplexity4.198015213012695
INFO:root:current mean train loss 1818.4178444126674
INFO:root:current train perplexity4.195723056793213
INFO:root:current mean train loss 1818.3770762532552
INFO:root:current train perplexity4.195789813995361
INFO:root:current mean train loss 1818.81016746521
INFO:root:current train perplexity4.196547508239746
INFO:root:current mean train loss 1819.4743018296185
INFO:root:current train perplexity4.196343421936035
INFO:root:current mean train loss 1820.9024243842232
INFO:root:current train perplexity4.199011325836182
INFO:root:current mean train loss 1819.6174669767681
INFO:root:current train perplexity4.197772026062012

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.99s/it]
INFO:root:final mean train loss: 1818.4773359813296
INFO:root:final train perplexity: 4.1961212158203125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 2864.7361411704674
INFO:root:eval perplexity: 10.493173599243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:20:49<4:33:28, 356.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.4817899816176
INFO:root:current train perplexity4.250225067138672
INFO:root:current mean train loss 1806.989248422476
INFO:root:current train perplexity4.180218696594238
INFO:root:current mean train loss 1810.4031734906034
INFO:root:current train perplexity4.16769552230835
INFO:root:current mean train loss 1807.226215157975
INFO:root:current train perplexity4.166406154632568
INFO:root:current mean train loss 1814.388028444432
INFO:root:current train perplexity4.183684349060059
INFO:root:current mean train loss 1812.8228714904194
INFO:root:current train perplexity4.177215099334717
INFO:root:current mean train loss 1811.1792120786695
INFO:root:current train perplexity4.173590183258057
INFO:root:current mean train loss 1810.8791360895004
INFO:root:current train perplexity4.1779375076293945
INFO:root:current mean train loss 1811.6031256574165
INFO:root:current train perplexity4.179985046386719
INFO:root:current mean train loss 1812.6285488249302
INFO:root:current train perplexity4.182764053344727
INFO:root:current mean train loss 1812.8221435546875
INFO:root:current train perplexity4.183589935302734
INFO:root:current mean train loss 1813.2619148056317
INFO:root:current train perplexity4.186175346374512
INFO:root:current mean train loss 1813.3963580919076
INFO:root:current train perplexity4.187308311462402
INFO:root:current mean train loss 1812.507051900923
INFO:root:current train perplexity4.187060356140137
INFO:root:current mean train loss 1813.2039967215894
INFO:root:current train perplexity4.186654090881348
INFO:root:current mean train loss 1813.0721344617768
INFO:root:current train perplexity4.183920383453369
INFO:root:current mean train loss 1813.718662580444
INFO:root:current train perplexity4.185712814331055
INFO:root:current mean train loss 1813.7827169766035
INFO:root:current train perplexity4.185301780700684
INFO:root:current mean train loss 1814.360838097009
INFO:root:current train perplexity4.185147762298584
INFO:root:current mean train loss 1814.7043904049297
INFO:root:current train perplexity4.18339204788208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.59s/it]
INFO:root:final mean train loss: 1814.7629683855744
INFO:root:final train perplexity: 4.183847427368164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2865.0673138959273
INFO:root:eval perplexity: 10.496026039123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:26:44<4:27:10, 356.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1789.2512242934283
INFO:root:current train perplexity4.1338629722595215
INFO:root:current mean train loss 1802.0438104885727
INFO:root:current train perplexity4.142484188079834
INFO:root:current mean train loss 1811.9517071063701
INFO:root:current train perplexity4.1543869972229
INFO:root:current mean train loss 1813.192136844475
INFO:root:current train perplexity4.1583991050720215
INFO:root:current mean train loss 1813.302497266075
INFO:root:current train perplexity4.162896156311035
INFO:root:current mean train loss 1812.1917020533415
INFO:root:current train perplexity4.159987449645996
INFO:root:current mean train loss 1809.744251142917
INFO:root:current train perplexity4.154281139373779
INFO:root:current mean train loss 1809.550712730969
INFO:root:current train perplexity4.154837131500244
INFO:root:current mean train loss 1808.6201271404752
INFO:root:current train perplexity4.155093193054199
INFO:root:current mean train loss 1806.5464311554804
INFO:root:current train perplexity4.155359268188477
INFO:root:current mean train loss 1805.637225211935
INFO:root:current train perplexity4.157928943634033
INFO:root:current mean train loss 1805.8452869664213
INFO:root:current train perplexity4.15746545791626
INFO:root:current mean train loss 1807.2929090008356
INFO:root:current train perplexity4.162882328033447
INFO:root:current mean train loss 1807.4734209738392
INFO:root:current train perplexity4.164178371429443
INFO:root:current mean train loss 1807.8594688085666
INFO:root:current train perplexity4.166983127593994
INFO:root:current mean train loss 1809.0342397677387
INFO:root:current train perplexity4.167947292327881
INFO:root:current mean train loss 1809.8218235123259
INFO:root:current train perplexity4.169811725616455
INFO:root:current mean train loss 1810.7895091055723
INFO:root:current train perplexity4.172425746917725
INFO:root:current mean train loss 1810.405287215338
INFO:root:current train perplexity4.170507431030273
INFO:root:current mean train loss 1811.5026502007659
INFO:root:current train perplexity4.171502590179443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.47s/it]
INFO:root:final mean train loss: 1811.0101484567062
INFO:root:final train perplexity: 4.171483039855957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.76s/it]
INFO:root:eval mean loss: 2866.057063655452
INFO:root:eval perplexity: 10.504555702209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:32:39<4:20:56, 355.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1812.0846425972734
INFO:root:current train perplexity4.169090270996094
INFO:root:current mean train loss 1809.6038818359375
INFO:root:current train perplexity4.157904624938965
INFO:root:current mean train loss 1804.913735682271
INFO:root:current train perplexity4.154899597167969
INFO:root:current mean train loss 1803.1904488153268
INFO:root:current train perplexity4.143315315246582
INFO:root:current mean train loss 1803.775721378707
INFO:root:current train perplexity4.1454596519470215
INFO:root:current mean train loss 1805.6619760059834
INFO:root:current train perplexity4.147639274597168
INFO:root:current mean train loss 1807.2182210286458
INFO:root:current train perplexity4.15247917175293
INFO:root:current mean train loss 1804.7391017705559
INFO:root:current train perplexity4.150616645812988
INFO:root:current mean train loss 1804.08968524507
INFO:root:current train perplexity4.150496959686279
INFO:root:current mean train loss 1803.789437696134
INFO:root:current train perplexity4.1516289710998535
INFO:root:current mean train loss 1804.7113238043382
INFO:root:current train perplexity4.154037952423096
INFO:root:current mean train loss 1805.7916849436292
INFO:root:current train perplexity4.153763294219971
INFO:root:current mean train loss 1807.4014347116058
INFO:root:current train perplexity4.155231952667236
INFO:root:current mean train loss 1808.3711157063922
INFO:root:current train perplexity4.157459259033203
INFO:root:current mean train loss 1808.290724456598
INFO:root:current train perplexity4.158234596252441
INFO:root:current mean train loss 1808.4748512332014
INFO:root:current train perplexity4.159876346588135
INFO:root:current mean train loss 1808.0355089304305
INFO:root:current train perplexity4.158997058868408
INFO:root:current mean train loss 1808.187851710295
INFO:root:current train perplexity4.160065174102783
INFO:root:current mean train loss 1808.9693720903608
INFO:root:current train perplexity4.1613640785217285
INFO:root:current mean train loss 1808.290334008401
INFO:root:current train perplexity4.1608147621154785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.53s/it]
INFO:root:final mean train loss: 1807.7647143665492
INFO:root:final train perplexity: 4.160819053649902
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it]
INFO:root:eval mean loss: 2871.060373850413
INFO:root:eval perplexity: 10.547768592834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:38:35<4:15:08, 356.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.5485032025506
INFO:root:current train perplexity4.0787353515625
INFO:root:current mean train loss 1781.7297029041108
INFO:root:current train perplexity4.0934319496154785
INFO:root:current mean train loss 1793.3129828154151
INFO:root:current train perplexity4.108278274536133
INFO:root:current mean train loss 1791.5295466547427
INFO:root:current train perplexity4.110998153686523
INFO:root:current mean train loss 1794.2422401884683
INFO:root:current train perplexity4.114625930786133
INFO:root:current mean train loss 1796.1144858346859
INFO:root:current train perplexity4.1209397315979
INFO:root:current mean train loss 1795.5202455806161
INFO:root:current train perplexity4.11978006362915
INFO:root:current mean train loss 1796.604202111562
INFO:root:current train perplexity4.123244762420654
INFO:root:current mean train loss 1798.7491405856224
INFO:root:current train perplexity4.1266913414001465
INFO:root:current mean train loss 1801.7742608440808
INFO:root:current train perplexity4.134332656860352
INFO:root:current mean train loss 1800.4598178363472
INFO:root:current train perplexity4.134695529937744
INFO:root:current mean train loss 1800.543880305878
INFO:root:current train perplexity4.137401103973389
INFO:root:current mean train loss 1802.1636915718343
INFO:root:current train perplexity4.139706611633301
INFO:root:current mean train loss 1800.7877307021827
INFO:root:current train perplexity4.140555381774902
INFO:root:current mean train loss 1801.4038271371285
INFO:root:current train perplexity4.14408540725708
INFO:root:current mean train loss 1801.832669082953
INFO:root:current train perplexity4.143777847290039
INFO:root:current mean train loss 1802.1055518134322
INFO:root:current train perplexity4.143494129180908
INFO:root:current mean train loss 1802.9506721323971
INFO:root:current train perplexity4.14483118057251
INFO:root:current mean train loss 1803.453705095377
INFO:root:current train perplexity4.145997047424316
INFO:root:current mean train loss 1804.2625555022946
INFO:root:current train perplexity4.14845609664917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.26s/it]
INFO:root:final mean train loss: 1803.8669609035198
INFO:root:final train perplexity: 4.148049354553223
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 2868.913921734234
INFO:root:eval perplexity: 10.529208183288574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:44:31<4:09:05, 355.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.991552734375
INFO:root:current train perplexity4.134195804595947
INFO:root:current mean train loss 1795.8462785050676
INFO:root:current train perplexity4.119978904724121
INFO:root:current mean train loss 1790.9599373800713
INFO:root:current train perplexity4.104071617126465
INFO:root:current mean train loss 1789.6578109146712
INFO:root:current train perplexity4.100469589233398
INFO:root:current mean train loss 1791.47660302231
INFO:root:current train perplexity4.103678226470947
INFO:root:current mean train loss 1792.2164150140225
INFO:root:current train perplexity4.10762357711792
INFO:root:current mean train loss 1789.0911820683166
INFO:root:current train perplexity4.106489658355713
INFO:root:current mean train loss 1790.829506649333
INFO:root:current train perplexity4.1067352294921875
INFO:root:current mean train loss 1792.3269176763329
INFO:root:current train perplexity4.112101078033447
INFO:root:current mean train loss 1792.7335304221526
INFO:root:current train perplexity4.11569881439209
INFO:root:current mean train loss 1793.3689377745175
INFO:root:current train perplexity4.114650726318359
INFO:root:current mean train loss 1794.950292865737
INFO:root:current train perplexity4.118714332580566
INFO:root:current mean train loss 1794.6340491625122
INFO:root:current train perplexity4.121285915374756
INFO:root:current mean train loss 1796.0583664436203
INFO:root:current train perplexity4.122549057006836
INFO:root:current mean train loss 1796.2070873119212
INFO:root:current train perplexity4.124549865722656
INFO:root:current mean train loss 1796.6783275520013
INFO:root:current train perplexity4.128836154937744
INFO:root:current mean train loss 1796.9130430498888
INFO:root:current train perplexity4.130514621734619
INFO:root:current mean train loss 1798.7355968656993
INFO:root:current train perplexity4.13311243057251
INFO:root:current mean train loss 1799.1823279747596
INFO:root:current train perplexity4.133667945861816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.56s/it]
INFO:root:final mean train loss: 1800.031889191674
INFO:root:final train perplexity: 4.13552188873291
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2873.907245624531
INFO:root:eval perplexity: 10.572440147399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:50:26<4:03:03, 355.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1851.5960083007812
INFO:root:current train perplexity4.270208835601807
INFO:root:current mean train loss 1795.6482424268536
INFO:root:current train perplexity4.091247081756592
INFO:root:current mean train loss 1788.4933985341893
INFO:root:current train perplexity4.092575550079346
INFO:root:current mean train loss 1786.2259274918513
INFO:root:current train perplexity4.08540153503418
INFO:root:current mean train loss 1788.5223081977806
INFO:root:current train perplexity4.091432571411133
INFO:root:current mean train loss 1793.7623193748443
INFO:root:current train perplexity4.103098392486572
INFO:root:current mean train loss 1792.7648353956863
INFO:root:current train perplexity4.104856014251709
INFO:root:current mean train loss 1796.780296390892
INFO:root:current train perplexity4.113262176513672
INFO:root:current mean train loss 1796.6525533395516
INFO:root:current train perplexity4.121405601501465
INFO:root:current mean train loss 1795.5248787958183
INFO:root:current train perplexity4.1220879554748535
INFO:root:current mean train loss 1795.1077751723117
INFO:root:current train perplexity4.122995376586914
INFO:root:current mean train loss 1795.7205175825559
INFO:root:current train perplexity4.122317314147949
INFO:root:current mean train loss 1795.2137393284954
INFO:root:current train perplexity4.122540473937988
INFO:root:current mean train loss 1795.581305109777
INFO:root:current train perplexity4.124074935913086
INFO:root:current mean train loss 1795.6746040812232
INFO:root:current train perplexity4.124658107757568
INFO:root:current mean train loss 1797.364506179261
INFO:root:current train perplexity4.124647617340088
INFO:root:current mean train loss 1797.789244310091
INFO:root:current train perplexity4.124342441558838
INFO:root:current mean train loss 1797.768978634396
INFO:root:current train perplexity4.12578010559082
INFO:root:current mean train loss 1797.739041987852
INFO:root:current train perplexity4.125669002532959
INFO:root:current mean train loss 1797.6294521648676
INFO:root:current train perplexity4.1268792152404785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.08s/it]
INFO:root:final mean train loss: 1797.6410006909316
INFO:root:final train perplexity: 4.1277313232421875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 2873.0329927095063
INFO:root:eval perplexity: 10.564858436584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:56:23<3:57:19, 355.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.8088443153783
INFO:root:current train perplexity4.0750298500061035
INFO:root:current mean train loss 1781.4152196034663
INFO:root:current train perplexity4.104520320892334
INFO:root:current mean train loss 1792.54624235249
INFO:root:current train perplexity4.106228828430176
INFO:root:current mean train loss 1793.0712779651988
INFO:root:current train perplexity4.110804557800293
INFO:root:current mean train loss 1793.9853990504737
INFO:root:current train perplexity4.113840579986572
INFO:root:current mean train loss 1792.1643172247561
INFO:root:current train perplexity4.116397380828857
INFO:root:current mean train loss 1791.5652717257547
INFO:root:current train perplexity4.1140336990356445
INFO:root:current mean train loss 1788.5232558376433
INFO:root:current train perplexity4.110002040863037
INFO:root:current mean train loss 1788.1917083702972
INFO:root:current train perplexity4.109089374542236
INFO:root:current mean train loss 1787.9341414060375
INFO:root:current train perplexity4.105813026428223
INFO:root:current mean train loss 1790.6103225722982
INFO:root:current train perplexity4.1083502769470215
INFO:root:current mean train loss 1790.4250588642901
INFO:root:current train perplexity4.109760761260986
INFO:root:current mean train loss 1790.8872510927247
INFO:root:current train perplexity4.10941743850708
INFO:root:current mean train loss 1789.7446573183697
INFO:root:current train perplexity4.107034683227539
INFO:root:current mean train loss 1790.9378623397859
INFO:root:current train perplexity4.110134601593018
INFO:root:current mean train loss 1791.2280122356403
INFO:root:current train perplexity4.110979080200195
INFO:root:current mean train loss 1791.5806399198725
INFO:root:current train perplexity4.110855579376221
INFO:root:current mean train loss 1792.8191027327844
INFO:root:current train perplexity4.111903667449951
INFO:root:current mean train loss 1793.2511625871873
INFO:root:current train perplexity4.113032341003418
INFO:root:current mean train loss 1794.3291313962554
INFO:root:current train perplexity4.114804267883301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.94s/it]
INFO:root:final mean train loss: 1793.9063871521212
INFO:root:final train perplexity: 4.115591049194336
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 2874.2705129445853
INFO:root:eval perplexity: 10.575591087341309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:02:19<3:51:27, 356.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.1214124891494
INFO:root:current train perplexity4.051645755767822
INFO:root:current mean train loss 1776.954491110409
INFO:root:current train perplexity4.046096324920654
INFO:root:current mean train loss 1783.0843945519398
INFO:root:current train perplexity4.069523334503174
INFO:root:current mean train loss 1785.3799293154761
INFO:root:current train perplexity4.089320659637451
INFO:root:current mean train loss 1788.302671659977
INFO:root:current train perplexity4.095732688903809
INFO:root:current mean train loss 1789.7085332158786
INFO:root:current train perplexity4.097238540649414
INFO:root:current mean train loss 1788.5483008810559
INFO:root:current train perplexity4.096366882324219
INFO:root:current mean train loss 1789.8476778113325
INFO:root:current train perplexity4.098931789398193
INFO:root:current mean train loss 1791.8182892867824
INFO:root:current train perplexity4.105506896972656
INFO:root:current mean train loss 1792.4749548496345
INFO:root:current train perplexity4.106868743896484
INFO:root:current mean train loss 1791.2462661330765
INFO:root:current train perplexity4.103305816650391
INFO:root:current mean train loss 1791.3310089111328
INFO:root:current train perplexity4.10205078125
INFO:root:current mean train loss 1791.1434652087758
INFO:root:current train perplexity4.101344108581543
INFO:root:current mean train loss 1791.5440483778536
INFO:root:current train perplexity4.102062702178955
INFO:root:current mean train loss 1791.2879723679057
INFO:root:current train perplexity4.104269504547119
INFO:root:current mean train loss 1791.2406533559163
INFO:root:current train perplexity4.105688095092773
INFO:root:current mean train loss 1790.679905450723
INFO:root:current train perplexity4.105123996734619
INFO:root:current mean train loss 1790.565193141111
INFO:root:current train perplexity4.1041460037231445
INFO:root:current mean train loss 1790.6455310829845
INFO:root:current train perplexity4.103801250457764
INFO:root:current mean train loss 1791.0900694161408
INFO:root:current train perplexity4.104869365692139

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.31s/it]
INFO:root:final mean train loss: 1790.601028973324
INFO:root:final train perplexity: 4.104876518249512
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 2875.6401924385323
INFO:root:eval perplexity: 10.587484359741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:08:14<3:45:21, 355.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.6374949329304
INFO:root:current train perplexity4.045342922210693
INFO:root:current mean train loss 1773.0103544347426
INFO:root:current train perplexity4.060914039611816
INFO:root:current mean train loss 1775.50623716573
INFO:root:current train perplexity4.061836242675781
INFO:root:current mean train loss 1780.051594936814
INFO:root:current train perplexity4.074260234832764
INFO:root:current mean train loss 1779.8216843762934
INFO:root:current train perplexity4.074509143829346
INFO:root:current mean train loss 1781.3083017083663
INFO:root:current train perplexity4.076865196228027
INFO:root:current mean train loss 1782.030402424507
INFO:root:current train perplexity4.076750755310059
INFO:root:current mean train loss 1783.5670360549987
INFO:root:current train perplexity4.080923080444336
INFO:root:current mean train loss 1785.7453805044695
INFO:root:current train perplexity4.083405017852783
INFO:root:current mean train loss 1785.7655409725867
INFO:root:current train perplexity4.0821356773376465
INFO:root:current mean train loss 1786.5755748549532
INFO:root:current train perplexity4.083675861358643
INFO:root:current mean train loss 1786.2382148683123
INFO:root:current train perplexity4.084973335266113
INFO:root:current mean train loss 1785.6637087591344
INFO:root:current train perplexity4.086245059967041
INFO:root:current mean train loss 1785.6979861375762
INFO:root:current train perplexity4.085794448852539
INFO:root:current mean train loss 1786.7955617149862
INFO:root:current train perplexity4.089055061340332
INFO:root:current mean train loss 1787.5235014041623
INFO:root:current train perplexity4.0917463302612305
INFO:root:current mean train loss 1787.3070241901562
INFO:root:current train perplexity4.092462062835693
INFO:root:current mean train loss 1787.1063052763343
INFO:root:current train perplexity4.091907978057861
INFO:root:current mean train loss 1786.8186341484882
INFO:root:current train perplexity4.091737747192383
INFO:root:current mean train loss 1787.039300015201
INFO:root:current train perplexity4.091487407684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.77s/it]
INFO:root:final mean train loss: 1786.3266289461399
INFO:root:final train perplexity: 4.091061592102051
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 2879.2105797203453
INFO:root:eval perplexity: 10.618550300598145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:14:10<3:39:28, 355.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.6777465820312
INFO:root:current train perplexity4.098337650299072
INFO:root:current mean train loss 1785.794236127068
INFO:root:current train perplexity4.091068267822266
INFO:root:current mean train loss 1784.5953830295139
INFO:root:current train perplexity4.079591751098633
INFO:root:current mean train loss 1780.2845597550677
INFO:root:current train perplexity4.067416667938232
INFO:root:current mean train loss 1781.9915623441655
INFO:root:current train perplexity4.078017234802246
INFO:root:current mean train loss 1781.078673673931
INFO:root:current train perplexity4.082537651062012
INFO:root:current mean train loss 1782.4280767184584
INFO:root:current train perplexity4.077444553375244
INFO:root:current mean train loss 1784.1440434443487
INFO:root:current train perplexity4.081258773803711
INFO:root:current mean train loss 1785.84022441294
INFO:root:current train perplexity4.0831756591796875
INFO:root:current mean train loss 1787.0698300076515
INFO:root:current train perplexity4.08392858505249
INFO:root:current mean train loss 1786.600080999927
INFO:root:current train perplexity4.08207368850708
INFO:root:current mean train loss 1786.2431710528513
INFO:root:current train perplexity4.079097747802734
INFO:root:current mean train loss 1786.0935994786541
INFO:root:current train perplexity4.077291011810303
INFO:root:current mean train loss 1785.5670986648893
INFO:root:current train perplexity4.078017711639404
INFO:root:current mean train loss 1785.3177665450946
INFO:root:current train perplexity4.079306602478027
INFO:root:current mean train loss 1784.7132391862808
INFO:root:current train perplexity4.078921318054199
INFO:root:current mean train loss 1784.953386902952
INFO:root:current train perplexity4.080928325653076
INFO:root:current mean train loss 1784.959692520745
INFO:root:current train perplexity4.080364227294922
INFO:root:current mean train loss 1784.5177039814505
INFO:root:current train perplexity4.081006050109863
INFO:root:current mean train loss 1784.5748541352712
INFO:root:current train perplexity4.0834455490112305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.59s/it]
INFO:root:final mean train loss: 1784.1061615282638
INFO:root:final train perplexity: 4.083903789520264
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it]
INFO:root:eval mean loss: 2878.9043137375656
INFO:root:eval perplexity: 10.61588191986084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:20:05<3:33:24, 355.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.0929642600574
INFO:root:current train perplexity4.056192398071289
INFO:root:current mean train loss 1785.6556455234793
INFO:root:current train perplexity4.0763654708862305
INFO:root:current mean train loss 1783.7235090408592
INFO:root:current train perplexity4.064655303955078
INFO:root:current mean train loss 1775.527169003351
INFO:root:current train perplexity4.060824394226074
INFO:root:current mean train loss 1774.325951546859
INFO:root:current train perplexity4.0619001388549805
INFO:root:current mean train loss 1772.986229969655
INFO:root:current train perplexity4.060284614562988
INFO:root:current mean train loss 1773.405138040734
INFO:root:current train perplexity4.059755325317383
INFO:root:current mean train loss 1773.0076437420585
INFO:root:current train perplexity4.05757474899292
INFO:root:current mean train loss 1776.469197820515
INFO:root:current train perplexity4.061173439025879
INFO:root:current mean train loss 1778.521155267501
INFO:root:current train perplexity4.065339088439941
INFO:root:current mean train loss 1778.0610973705584
INFO:root:current train perplexity4.064219951629639
INFO:root:current mean train loss 1779.4394950834562
INFO:root:current train perplexity4.069265842437744
INFO:root:current mean train loss 1779.0003940964634
INFO:root:current train perplexity4.068047046661377
INFO:root:current mean train loss 1779.9234092838917
INFO:root:current train perplexity4.070392608642578
INFO:root:current mean train loss 1780.974617830442
INFO:root:current train perplexity4.071454048156738
INFO:root:current mean train loss 1781.9068681203726
INFO:root:current train perplexity4.074415683746338
INFO:root:current mean train loss 1781.3589385280825
INFO:root:current train perplexity4.075293064117432
INFO:root:current mean train loss 1780.882315338425
INFO:root:current train perplexity4.073155879974365
INFO:root:current mean train loss 1780.9527851826435
INFO:root:current train perplexity4.073309898376465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.81s/it]
INFO:root:final mean train loss: 1781.350674889392
INFO:root:final train perplexity: 4.075039386749268
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it]
INFO:root:eval mean loss: 2879.553889827327
INFO:root:eval perplexity: 10.621540069580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [6:26:00<3:27:18, 355.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.335693359375
INFO:root:current train perplexity4.0273003578186035
INFO:root:current mean train loss 1765.1111508882964
INFO:root:current train perplexity4.035210609436035
INFO:root:current mean train loss 1779.5959759880516
INFO:root:current train perplexity4.063860893249512
INFO:root:current mean train loss 1776.2999829744037
INFO:root:current train perplexity4.051815986633301
INFO:root:current mean train loss 1775.3600750913715
INFO:root:current train perplexity4.051648139953613
INFO:root:current mean train loss 1776.5323718843006
INFO:root:current train perplexity4.053068161010742
INFO:root:current mean train loss 1776.242734189065
INFO:root:current train perplexity4.050552845001221
INFO:root:current mean train loss 1776.090392372825
INFO:root:current train perplexity4.053070068359375
INFO:root:current mean train loss 1778.1043941061296
INFO:root:current train perplexity4.0580596923828125
INFO:root:current mean train loss 1778.6051418338202
INFO:root:current train perplexity4.0574445724487305
INFO:root:current mean train loss 1778.2307378153403
INFO:root:current train perplexity4.055380344390869
INFO:root:current mean train loss 1777.0484069603076
INFO:root:current train perplexity4.055344104766846
INFO:root:current mean train loss 1777.7139493112152
INFO:root:current train perplexity4.057882785797119
INFO:root:current mean train loss 1778.1044722481008
INFO:root:current train perplexity4.059625625610352
INFO:root:current mean train loss 1777.8480015942175
INFO:root:current train perplexity4.060725688934326
INFO:root:current mean train loss 1777.5718823696704
INFO:root:current train perplexity4.0606255531311035
INFO:root:current mean train loss 1777.7824617989938
INFO:root:current train perplexity4.059902191162109
INFO:root:current mean train loss 1776.950356138704
INFO:root:current train perplexity4.060909271240234
INFO:root:current mean train loss 1777.361755844759
INFO:root:current train perplexity4.062841415405273
INFO:root:current mean train loss 1778.108844404461
INFO:root:current train perplexity4.064072132110596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.98s/it]
INFO:root:final mean train loss: 1778.5377150481238
INFO:root:final train perplexity: 4.066009044647217
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 2876.953297291432
INFO:root:eval perplexity: 10.598899841308594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:31:55<3:21:18, 355.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.3916422526042
INFO:root:current train perplexity3.9559481143951416
INFO:root:current mean train loss 1772.8285386266787
INFO:root:current train perplexity4.0086188316345215
INFO:root:current mean train loss 1766.3304211370546
INFO:root:current train perplexity4.025872707366943
INFO:root:current mean train loss 1772.3134290273315
INFO:root:current train perplexity4.043479919433594
INFO:root:current mean train loss 1776.0330537990833
INFO:root:current train perplexity4.0536112785339355
INFO:root:current mean train loss 1776.0981428911498
INFO:root:current train perplexity4.056654453277588
INFO:root:current mean train loss 1775.704406639996
INFO:root:current train perplexity4.054211616516113
INFO:root:current mean train loss 1774.4910812483747
INFO:root:current train perplexity4.045449733734131
INFO:root:current mean train loss 1775.4994138840782
INFO:root:current train perplexity4.047478199005127
INFO:root:current mean train loss 1776.2441777364957
INFO:root:current train perplexity4.048837184906006
INFO:root:current mean train loss 1774.6796590448243
INFO:root:current train perplexity4.0480852127075195
INFO:root:current mean train loss 1774.549060940636
INFO:root:current train perplexity4.048523902893066
INFO:root:current mean train loss 1774.6926480479947
INFO:root:current train perplexity4.048597812652588
INFO:root:current mean train loss 1773.0796662647556
INFO:root:current train perplexity4.050278186798096
INFO:root:current mean train loss 1773.9683571586636
INFO:root:current train perplexity4.052445888519287
INFO:root:current mean train loss 1773.6459553233892
INFO:root:current train perplexity4.053211688995361
INFO:root:current mean train loss 1774.6376894386663
INFO:root:current train perplexity4.0539960861206055
INFO:root:current mean train loss 1774.716255892854
INFO:root:current train perplexity4.055521011352539
INFO:root:current mean train loss 1775.6699511691936
INFO:root:current train perplexity4.05544900894165
INFO:root:current mean train loss 1775.1109021180375
INFO:root:current train perplexity4.054624080657959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.20s/it]
INFO:root:final mean train loss: 1775.688419251627
INFO:root:final train perplexity: 4.056881904602051
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 2881.8188315268394
INFO:root:eval perplexity: 10.641301155090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:37:50<3:15:21, 355.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1761.1336862664473
INFO:root:current train perplexity4.026960849761963
INFO:root:current mean train loss 1756.6800926319067
INFO:root:current train perplexity4.0100321769714355
INFO:root:current mean train loss 1760.5702781356683
INFO:root:current train perplexity4.016631126403809
INFO:root:current mean train loss 1761.0685049203726
INFO:root:current train perplexity4.023959159851074
INFO:root:current mean train loss 1763.3188161632243
INFO:root:current train perplexity4.026974201202393
INFO:root:current mean train loss 1768.1618030647362
INFO:root:current train perplexity4.032514572143555
INFO:root:current mean train loss 1771.3597084930325
INFO:root:current train perplexity4.0348029136657715
INFO:root:current mean train loss 1768.0513484303544
INFO:root:current train perplexity4.032041549682617
INFO:root:current mean train loss 1769.6482149183323
INFO:root:current train perplexity4.034389495849609
INFO:root:current mean train loss 1771.682014774412
INFO:root:current train perplexity4.036579608917236
INFO:root:current mean train loss 1772.0496408686702
INFO:root:current train perplexity4.040050983428955
INFO:root:current mean train loss 1773.146812720542
INFO:root:current train perplexity4.039280414581299
INFO:root:current mean train loss 1773.1858149761144
INFO:root:current train perplexity4.040093898773193
INFO:root:current mean train loss 1772.2874890884832
INFO:root:current train perplexity4.040541172027588
INFO:root:current mean train loss 1772.5874000517483
INFO:root:current train perplexity4.042104244232178
INFO:root:current mean train loss 1773.767723133102
INFO:root:current train perplexity4.044519901275635
INFO:root:current mean train loss 1773.4666802449394
INFO:root:current train perplexity4.044767379760742
INFO:root:current mean train loss 1773.9503267242117
INFO:root:current train perplexity4.046998500823975
INFO:root:current mean train loss 1774.3898535262513
INFO:root:current train perplexity4.0479536056518555
INFO:root:current mean train loss 1773.1679225169714
INFO:root:current train perplexity4.047395706176758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.92s/it]
INFO:root:final mean train loss: 1772.857222364217
INFO:root:final train perplexity: 4.047834396362305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 2882.0225452503287
INFO:root:eval perplexity: 10.64307975769043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:43:46<3:09:36, 355.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.6663108132102
INFO:root:current train perplexity4.01161003112793
INFO:root:current mean train loss 1773.6225656817037
INFO:root:current train perplexity4.020702838897705
INFO:root:current mean train loss 1771.2027616613052
INFO:root:current train perplexity4.028852939605713
INFO:root:current mean train loss 1774.8037535761443
INFO:root:current train perplexity4.0405497550964355
INFO:root:current mean train loss 1773.172793344351
INFO:root:current train perplexity4.042189121246338
INFO:root:current mean train loss 1770.849366114161
INFO:root:current train perplexity4.036144733428955
INFO:root:current mean train loss 1770.4047965246302
INFO:root:current train perplexity4.035518646240234
INFO:root:current mean train loss 1770.163132340387
INFO:root:current train perplexity4.029837131500244
INFO:root:current mean train loss 1768.9547975774396
INFO:root:current train perplexity4.029098987579346
INFO:root:current mean train loss 1769.5523707205089
INFO:root:current train perplexity4.030584812164307
INFO:root:current mean train loss 1769.0727751962381
INFO:root:current train perplexity4.0307512283325195
INFO:root:current mean train loss 1770.8959160874933
INFO:root:current train perplexity4.034451007843018
INFO:root:current mean train loss 1771.2797274768116
INFO:root:current train perplexity4.035398006439209
INFO:root:current mean train loss 1771.0482013772773
INFO:root:current train perplexity4.036275863647461
INFO:root:current mean train loss 1771.774916102878
INFO:root:current train perplexity4.038036346435547
INFO:root:current mean train loss 1772.3958487458551
INFO:root:current train perplexity4.039120674133301
INFO:root:current mean train loss 1773.3876017867258
INFO:root:current train perplexity4.041865348815918
INFO:root:current mean train loss 1772.3277619190706
INFO:root:current train perplexity4.040780067443848
INFO:root:current mean train loss 1771.8531536914588
INFO:root:current train perplexity4.040699005126953
INFO:root:current mean train loss 1771.1738555986253
INFO:root:current train perplexity4.040195465087891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.48s/it]
INFO:root:final mean train loss: 1770.657626630559
INFO:root:final train perplexity: 4.0408172607421875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2883.325543561139
INFO:root:eval perplexity: 10.65446662902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:49:42<3:03:45, 355.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.88282945421
INFO:root:current train perplexity4.017175197601318
INFO:root:current mean train loss 1757.91573032113
INFO:root:current train perplexity4.021875858306885
INFO:root:current mean train loss 1757.9477238374598
INFO:root:current train perplexity4.022512912750244
INFO:root:current mean train loss 1757.449688655074
INFO:root:current train perplexity4.017582416534424
INFO:root:current mean train loss 1761.6391291214247
INFO:root:current train perplexity4.017696380615234
INFO:root:current mean train loss 1763.775011182665
INFO:root:current train perplexity4.02481746673584
INFO:root:current mean train loss 1764.7158560979933
INFO:root:current train perplexity4.028034210205078
INFO:root:current mean train loss 1763.3776480719216
INFO:root:current train perplexity4.024487018585205
INFO:root:current mean train loss 1761.8114397241434
INFO:root:current train perplexity4.024596214294434
INFO:root:current mean train loss 1762.137143861119
INFO:root:current train perplexity4.024667739868164
INFO:root:current mean train loss 1762.197158699605
INFO:root:current train perplexity4.025040626525879
INFO:root:current mean train loss 1763.6720793532024
INFO:root:current train perplexity4.026787281036377
INFO:root:current mean train loss 1763.8780842907024
INFO:root:current train perplexity4.026071548461914
INFO:root:current mean train loss 1763.4419182869158
INFO:root:current train perplexity4.027153015136719
INFO:root:current mean train loss 1764.294989876125
INFO:root:current train perplexity4.028399467468262
INFO:root:current mean train loss 1764.261733115781
INFO:root:current train perplexity4.028197288513184
INFO:root:current mean train loss 1765.7282243938537
INFO:root:current train perplexity4.028697490692139
INFO:root:current mean train loss 1766.3896710329077
INFO:root:current train perplexity4.028922080993652
INFO:root:current mean train loss 1767.4000626262437
INFO:root:current train perplexity4.029446125030518
INFO:root:current mean train loss 1767.6841181199884
INFO:root:current train perplexity4.030182838439941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.82s/it]
INFO:root:final mean train loss: 1767.495275885062
INFO:root:final train perplexity: 4.030753135681152
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it]
INFO:root:eval mean loss: 2886.5673219606324
INFO:root:eval perplexity: 10.682845115661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:55:38<2:57:52, 355.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.3174623639395
INFO:root:current train perplexity4.038558483123779
INFO:root:current mean train loss 1746.4315450355489
INFO:root:current train perplexity4.006772041320801
INFO:root:current mean train loss 1753.8894363984105
INFO:root:current train perplexity4.010992527008057
INFO:root:current mean train loss 1752.5966749804186
INFO:root:current train perplexity4.006711006164551
INFO:root:current mean train loss 1758.2476921471593
INFO:root:current train perplexity4.015527248382568
INFO:root:current mean train loss 1757.867216929515
INFO:root:current train perplexity4.015595436096191
INFO:root:current mean train loss 1758.8807373046875
INFO:root:current train perplexity4.014364242553711
INFO:root:current mean train loss 1758.4003910891456
INFO:root:current train perplexity4.010520935058594
INFO:root:current mean train loss 1760.367055543228
INFO:root:current train perplexity4.013611316680908
INFO:root:current mean train loss 1762.6410848928053
INFO:root:current train perplexity4.013730049133301
INFO:root:current mean train loss 1760.5645456025095
INFO:root:current train perplexity4.011963844299316
INFO:root:current mean train loss 1760.2573240134172
INFO:root:current train perplexity4.014114856719971
INFO:root:current mean train loss 1760.729683674057
INFO:root:current train perplexity4.015193939208984
INFO:root:current mean train loss 1760.8146806556256
INFO:root:current train perplexity4.016289710998535
INFO:root:current mean train loss 1761.566458062248
INFO:root:current train perplexity4.018481254577637
INFO:root:current mean train loss 1761.4870186020098
INFO:root:current train perplexity4.019090175628662
INFO:root:current mean train loss 1762.692385125259
INFO:root:current train perplexity4.019252777099609
INFO:root:current mean train loss 1763.6261405966147
INFO:root:current train perplexity4.018996715545654
INFO:root:current mean train loss 1764.8304504103735
INFO:root:current train perplexity4.020292282104492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.03s/it]
INFO:root:final mean train loss: 1765.0869428718324
INFO:root:final train perplexity: 4.023103713989258
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.13s/it]
INFO:root:eval mean loss: 2884.726346952421
INFO:root:eval perplexity: 10.666717529296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:01:34<2:51:57, 355.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.7222086588542
INFO:root:current train perplexity4.042041301727295
INFO:root:current mean train loss 1758.997509074661
INFO:root:current train perplexity3.9824864864349365
INFO:root:current mean train loss 1751.0075073242188
INFO:root:current train perplexity3.977637529373169
INFO:root:current mean train loss 1751.514750561683
INFO:root:current train perplexity3.97672963142395
INFO:root:current mean train loss 1753.6058009857027
INFO:root:current train perplexity3.987185001373291
INFO:root:current mean train loss 1752.7699191730485
INFO:root:current train perplexity3.9870097637176514
INFO:root:current mean train loss 1755.0874470625774
INFO:root:current train perplexity3.993241310119629
INFO:root:current mean train loss 1757.5019951407025
INFO:root:current train perplexity3.9986464977264404
INFO:root:current mean train loss 1758.8043526396266
INFO:root:current train perplexity3.9994659423828125
INFO:root:current mean train loss 1759.1669877412303
INFO:root:current train perplexity4.000629425048828
INFO:root:current mean train loss 1760.3241703344386
INFO:root:current train perplexity4.005954742431641
INFO:root:current mean train loss 1756.0298426595346
INFO:root:current train perplexity4.001155376434326
INFO:root:current mean train loss 1758.0293673235385
INFO:root:current train perplexity4.002935886383057
INFO:root:current mean train loss 1759.8120966819308
INFO:root:current train perplexity4.004901885986328
INFO:root:current mean train loss 1760.1275954266869
INFO:root:current train perplexity4.00742244720459
INFO:root:current mean train loss 1760.3968597452638
INFO:root:current train perplexity4.006322860717773
INFO:root:current mean train loss 1760.235250698674
INFO:root:current train perplexity4.008562088012695
INFO:root:current mean train loss 1759.2386440263683
INFO:root:current train perplexity4.007442951202393
INFO:root:current mean train loss 1760.2179086205704
INFO:root:current train perplexity4.010086536407471
INFO:root:current mean train loss 1762.450523416493
INFO:root:current train perplexity4.012664318084717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.13s/it]
INFO:root:final mean train loss: 1762.3531065078557
INFO:root:final train perplexity: 4.014439105987549
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it]
INFO:root:eval mean loss: 2888.599802927928
INFO:root:eval perplexity: 10.700674057006836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:07:29<2:45:55, 355.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.0302469004755
INFO:root:current train perplexity4.003877639770508
INFO:root:current mean train loss 1766.4330062245936
INFO:root:current train perplexity3.9987294673919678
INFO:root:current mean train loss 1759.211054643708
INFO:root:current train perplexity3.99137282371521
INFO:root:current mean train loss 1757.9778334673713
INFO:root:current train perplexity3.988996982574463
INFO:root:current mean train loss 1758.4064433501403
INFO:root:current train perplexity3.993363618850708
INFO:root:current mean train loss 1759.8913625567639
INFO:root:current train perplexity3.995929002761841
INFO:root:current mean train loss 1758.4024244770767
INFO:root:current train perplexity3.9921817779541016
INFO:root:current mean train loss 1758.1421465735218
INFO:root:current train perplexity4.000026702880859
INFO:root:current mean train loss 1758.326961104809
INFO:root:current train perplexity4.00111198425293
INFO:root:current mean train loss 1759.3593818772008
INFO:root:current train perplexity4.003891468048096
INFO:root:current mean train loss 1760.697851276118
INFO:root:current train perplexity4.004833221435547
INFO:root:current mean train loss 1760.7204625714812
INFO:root:current train perplexity4.005656719207764
INFO:root:current mean train loss 1760.4237634466988
INFO:root:current train perplexity4.006407260894775
INFO:root:current mean train loss 1759.8187764255008
INFO:root:current train perplexity4.005649566650391
INFO:root:current mean train loss 1759.5951114743007
INFO:root:current train perplexity4.005886554718018
INFO:root:current mean train loss 1760.420507620137
INFO:root:current train perplexity4.0078125
INFO:root:current mean train loss 1761.174902313665
INFO:root:current train perplexity4.008459091186523
INFO:root:current mean train loss 1761.1762202213617
INFO:root:current train perplexity4.008334636688232
INFO:root:current mean train loss 1761.2337371943354
INFO:root:current train perplexity4.006731033325195
INFO:root:current mean train loss 1760.8218524395272
INFO:root:current train perplexity4.0073041915893555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.02s/it]
INFO:root:final mean train loss: 1760.4313493614177
INFO:root:final train perplexity: 4.008359432220459
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 2887.72082556189
INFO:root:eval perplexity: 10.692961692810059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:13:25<2:40:02, 355.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.508984375
INFO:root:current train perplexity4.014532089233398
INFO:root:current mean train loss 1749.0501499720983
INFO:root:current train perplexity3.983452320098877
INFO:root:current mean train loss 1746.8101918538412
INFO:root:current train perplexity3.9822685718536377
INFO:root:current mean train loss 1751.6721525304458
INFO:root:current train perplexity3.992182731628418
INFO:root:current mean train loss 1756.215664950284
INFO:root:current train perplexity3.996049404144287
INFO:root:current mean train loss 1756.6678432888455
INFO:root:current train perplexity4.001619338989258
INFO:root:current mean train loss 1756.8614377975464
INFO:root:current train perplexity3.995547294616699
INFO:root:current mean train loss 1756.3823304872255
INFO:root:current train perplexity3.9952392578125
INFO:root:current mean train loss 1756.6655832926433
INFO:root:current train perplexity3.9954254627227783
INFO:root:current mean train loss 1756.4302153891706
INFO:root:current train perplexity3.997560739517212
INFO:root:current mean train loss 1757.157679279034
INFO:root:current train perplexity3.999849319458008
INFO:root:current mean train loss 1757.0576445997808
INFO:root:current train perplexity4.002338886260986
INFO:root:current mean train loss 1757.5686707527407
INFO:root:current train perplexity4.0022454261779785
INFO:root:current mean train loss 1757.927371625758
INFO:root:current train perplexity4.001954078674316
INFO:root:current mean train loss 1757.1210928175185
INFO:root:current train perplexity3.999217987060547
INFO:root:current mean train loss 1757.0517973664519
INFO:root:current train perplexity3.9999265670776367
INFO:root:current mean train loss 1757.851580810547
INFO:root:current train perplexity4.000639915466309
INFO:root:current mean train loss 1758.0017012672863
INFO:root:current train perplexity4.000338554382324
INFO:root:current mean train loss 1758.4456207938815
INFO:root:current train perplexity4.001579761505127
INFO:root:current mean train loss 1758.7221285161284
INFO:root:current train perplexity4.001299858093262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.73s/it]
INFO:root:final mean train loss: 1758.1168524991726
INFO:root:final train perplexity: 4.001049518585205
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it]
INFO:root:eval mean loss: 2890.1030354084555
INFO:root:eval perplexity: 10.713882446289062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:19:20<2:33:59, 355.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.4494371916119
INFO:root:current train perplexity3.9549946784973145
INFO:root:current mean train loss 1761.1548978963476
INFO:root:current train perplexity3.995933771133423
INFO:root:current mean train loss 1758.1864650147434
INFO:root:current train perplexity3.980546712875366
INFO:root:current mean train loss 1753.326160249256
INFO:root:current train perplexity3.97648549079895
INFO:root:current mean train loss 1749.3651708022771
INFO:root:current train perplexity3.9720520973205566
INFO:root:current mean train loss 1752.2983624168958
INFO:root:current train perplexity3.981945037841797
INFO:root:current mean train loss 1753.1669635743674
INFO:root:current train perplexity3.979159116744995
INFO:root:current mean train loss 1751.8312712534573
INFO:root:current train perplexity3.9788811206817627
INFO:root:current mean train loss 1752.2046770164818
INFO:root:current train perplexity3.982412576675415
INFO:root:current mean train loss 1751.397030311194
INFO:root:current train perplexity3.9803285598754883
INFO:root:current mean train loss 1750.8120101019247
INFO:root:current train perplexity3.9779212474823
INFO:root:current mean train loss 1753.0603952630388
INFO:root:current train perplexity3.979708433151245
INFO:root:current mean train loss 1751.634327259534
INFO:root:current train perplexity3.9787449836730957
INFO:root:current mean train loss 1752.912043976977
INFO:root:current train perplexity3.983829975128174
INFO:root:current mean train loss 1753.4258076413166
INFO:root:current train perplexity3.985856771469116
INFO:root:current mean train loss 1753.593448391463
INFO:root:current train perplexity3.9872801303863525
INFO:root:current mean train loss 1754.2149415830568
INFO:root:current train perplexity3.9888551235198975
INFO:root:current mean train loss 1754.2206562283234
INFO:root:current train perplexity3.9886724948883057
INFO:root:current mean train loss 1755.9657084311473
INFO:root:current train perplexity3.9941577911376953
INFO:root:current mean train loss 1755.6509337349698
INFO:root:current train perplexity3.9928877353668213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.60s/it]
INFO:root:final mean train loss: 1755.539474510389
INFO:root:final train perplexity: 3.992924690246582
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 2890.605198948949
INFO:root:eval perplexity: 10.718299865722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [7:25:16<2:28:08, 355.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.416729901288
INFO:root:current train perplexity4.002094268798828
INFO:root:current mean train loss 1744.9464370902926
INFO:root:current train perplexity3.9730825424194336
INFO:root:current mean train loss 1750.035948816007
INFO:root:current train perplexity3.970391273498535
INFO:root:current mean train loss 1750.1476903905207
INFO:root:current train perplexity3.9671645164489746
INFO:root:current mean train loss 1752.2811052668446
INFO:root:current train perplexity3.9746055603027344
INFO:root:current mean train loss 1751.035854007309
INFO:root:current train perplexity3.9789540767669678
INFO:root:current mean train loss 1750.2553991662996
INFO:root:current train perplexity3.976698398590088
INFO:root:current mean train loss 1752.0758812088684
INFO:root:current train perplexity3.9810707569122314
INFO:root:current mean train loss 1752.0751316236413
INFO:root:current train perplexity3.9795925617218018
INFO:root:current mean train loss 1753.616832693989
INFO:root:current train perplexity3.9822652339935303
INFO:root:current mean train loss 1753.3441132557903
INFO:root:current train perplexity3.9798216819763184
INFO:root:current mean train loss 1753.735272539129
INFO:root:current train perplexity3.979433298110962
INFO:root:current mean train loss 1752.5007795636284
INFO:root:current train perplexity3.979156255722046
INFO:root:current mean train loss 1754.5127336038427
INFO:root:current train perplexity3.984638214111328
INFO:root:current mean train loss 1753.6260236018063
INFO:root:current train perplexity3.984095811843872
INFO:root:current mean train loss 1753.0722784214431
INFO:root:current train perplexity3.98398756980896
INFO:root:current mean train loss 1753.4358368831438
INFO:root:current train perplexity3.9852445125579834
INFO:root:current mean train loss 1753.0019712910444
INFO:root:current train perplexity3.9843361377716064
INFO:root:current mean train loss 1753.6236982640742
INFO:root:current train perplexity3.985560894012451
INFO:root:current mean train loss 1753.6873441037194
INFO:root:current train perplexity3.9859721660614014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.25s/it]
INFO:root:final mean train loss: 1753.413732146832
INFO:root:final train perplexity: 3.986236572265625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it]
INFO:root:eval mean loss: 2892.589206638279
INFO:root:eval perplexity: 10.73576545715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [7:31:15<2:22:40, 356.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.197057703039
INFO:root:current train perplexity3.9980316162109375
INFO:root:current mean train loss 1755.330524863997
INFO:root:current train perplexity4.002474308013916
INFO:root:current mean train loss 1750.209951289331
INFO:root:current train perplexity3.984815835952759
INFO:root:current mean train loss 1749.812408837516
INFO:root:current train perplexity3.9792909622192383
INFO:root:current mean train loss 1750.5593818617936
INFO:root:current train perplexity3.9808740615844727
INFO:root:current mean train loss 1748.4775946241143
INFO:root:current train perplexity3.970486879348755
INFO:root:current mean train loss 1749.0192187429336
INFO:root:current train perplexity3.9724607467651367
INFO:root:current mean train loss 1751.3397832549779
INFO:root:current train perplexity3.9746813774108887
INFO:root:current mean train loss 1750.9272362294823
INFO:root:current train perplexity3.9755570888519287
INFO:root:current mean train loss 1750.9642757719869
INFO:root:current train perplexity3.9772872924804688
INFO:root:current mean train loss 1751.6996820801228
INFO:root:current train perplexity3.97702693939209
INFO:root:current mean train loss 1752.725589012319
INFO:root:current train perplexity3.9793365001678467
INFO:root:current mean train loss 1751.7007104473278
INFO:root:current train perplexity3.978301525115967
INFO:root:current mean train loss 1752.173866738183
INFO:root:current train perplexity3.980319023132324
INFO:root:current mean train loss 1752.2213955936138
INFO:root:current train perplexity3.979189872741699
INFO:root:current mean train loss 1752.6738717818246
INFO:root:current train perplexity3.980386734008789
INFO:root:current mean train loss 1752.0442017251257
INFO:root:current train perplexity3.9784717559814453
INFO:root:current mean train loss 1752.5815077994137
INFO:root:current train perplexity3.980668306350708
INFO:root:current mean train loss 1752.0656740863383
INFO:root:current train perplexity3.9803895950317383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.34s/it]
INFO:root:final mean train loss: 1752.079103717044
INFO:root:final train perplexity: 3.9820427894592285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.22s/it]
INFO:root:eval mean loss: 2893.2931549713776
INFO:root:eval perplexity: 10.741966247558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [7:37:10<2:16:33, 356.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1693.7601165771484
INFO:root:current train perplexity3.830728054046631
INFO:root:current mean train loss 1733.9930261682582
INFO:root:current train perplexity3.939471483230591
INFO:root:current mean train loss 1743.3869446974534
INFO:root:current train perplexity3.9460270404815674
INFO:root:current mean train loss 1745.5892131854962
INFO:root:current train perplexity3.9550631046295166
INFO:root:current mean train loss 1746.8150314630248
INFO:root:current train perplexity3.95359468460083
INFO:root:current mean train loss 1745.906925471749
INFO:root:current train perplexity3.9552218914031982
INFO:root:current mean train loss 1746.4962822763543
INFO:root:current train perplexity3.959243059158325
INFO:root:current mean train loss 1745.630088504425
INFO:root:current train perplexity3.9615375995635986
INFO:root:current mean train loss 1748.8435963545696
INFO:root:current train perplexity3.966094970703125
INFO:root:current mean train loss 1749.631522426521
INFO:root:current train perplexity3.96928334236145
INFO:root:current mean train loss 1750.2870850335985
INFO:root:current train perplexity3.968869924545288
INFO:root:current mean train loss 1748.419390516591
INFO:root:current train perplexity3.9673633575439453
INFO:root:current mean train loss 1747.5114701631053
INFO:root:current train perplexity3.9653122425079346
INFO:root:current mean train loss 1747.9361662791773
INFO:root:current train perplexity3.9666500091552734
INFO:root:current mean train loss 1748.7681127028031
INFO:root:current train perplexity3.9701106548309326
INFO:root:current mean train loss 1748.8862258546865
INFO:root:current train perplexity3.970254898071289
INFO:root:current mean train loss 1748.490405106426
INFO:root:current train perplexity3.9708211421966553
INFO:root:current mean train loss 1750.0913319643544
INFO:root:current train perplexity3.9728190898895264
INFO:root:current mean train loss 1750.097761171054
INFO:root:current train perplexity3.973700523376465
INFO:root:current mean train loss 1749.4508954254086
INFO:root:current train perplexity3.973090887069702

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.30s/it]
INFO:root:final mean train loss: 1749.7996426042257
INFO:root:final train perplexity: 3.974891185760498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2896.5656459682336
INFO:root:eval perplexity: 10.77085018157959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [7:43:07<2:10:40, 356.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1746.9700830078125
INFO:root:current train perplexity3.983941078186035
INFO:root:current mean train loss 1736.000705078125
INFO:root:current train perplexity3.9454994201660156
INFO:root:current mean train loss 1745.7666693793403
INFO:root:current train perplexity3.9757280349731445
INFO:root:current mean train loss 1740.9414584585336
INFO:root:current train perplexity3.9689762592315674
INFO:root:current mean train loss 1744.4989260684742
INFO:root:current train perplexity3.968096971511841
INFO:root:current mean train loss 1744.1343198939733
INFO:root:current train perplexity3.9660255908966064
INFO:root:current mean train loss 1745.680896875
INFO:root:current train perplexity3.965219497680664
INFO:root:current mean train loss 1746.1045027949892
INFO:root:current train perplexity3.9636127948760986
INFO:root:current mean train loss 1745.480691583807
INFO:root:current train perplexity3.9650487899780273
INFO:root:current mean train loss 1743.678095835093
INFO:root:current train perplexity3.9626545906066895
INFO:root:current mean train loss 1743.3705695026676
INFO:root:current train perplexity3.9633140563964844
INFO:root:current mean train loss 1745.3275210503473
INFO:root:current train perplexity3.965435028076172
INFO:root:current mean train loss 1745.911977738361
INFO:root:current train perplexity3.9667153358459473
INFO:root:current mean train loss 1746.8516680793043
INFO:root:current train perplexity3.9668691158294678
INFO:root:current mean train loss 1745.9338988829495
INFO:root:current train perplexity3.964176893234253
INFO:root:current mean train loss 1746.2994149430072
INFO:root:current train perplexity3.965013027191162
INFO:root:current mean train loss 1746.430430438702
INFO:root:current train perplexity3.9636378288269043
INFO:root:current mean train loss 1747.5891604393116
INFO:root:current train perplexity3.9649646282196045
INFO:root:current mean train loss 1747.4871719820205
INFO:root:current train perplexity3.968412399291992
INFO:root:current mean train loss 1748.0187408685065
INFO:root:current train perplexity3.9686944484710693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.32s/it]
INFO:root:final mean train loss: 1747.7278612591797
INFO:root:final train perplexity: 3.9684009552001953
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 2896.235321503144
INFO:root:eval perplexity: 10.76793098449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:49:04<2:04:46, 356.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.9832560221355
INFO:root:current train perplexity3.9532501697540283
INFO:root:current mean train loss 1741.803085112236
INFO:root:current train perplexity3.950601100921631
INFO:root:current mean train loss 1741.2736720565922
INFO:root:current train perplexity3.9498183727264404
INFO:root:current mean train loss 1748.1849265293768
INFO:root:current train perplexity3.9611196517944336
INFO:root:current mean train loss 1746.128217464119
INFO:root:current train perplexity3.9513490200042725
INFO:root:current mean train loss 1747.754405567127
INFO:root:current train perplexity3.9546661376953125
INFO:root:current mean train loss 1747.7763721311576
INFO:root:current train perplexity3.953310012817383
INFO:root:current mean train loss 1746.9868091675792
INFO:root:current train perplexity3.956442356109619
INFO:root:current mean train loss 1747.9709923533533
INFO:root:current train perplexity3.9627504348754883
INFO:root:current mean train loss 1749.230040596802
INFO:root:current train perplexity3.9667344093322754
INFO:root:current mean train loss 1747.7191834550445
INFO:root:current train perplexity3.9653098583221436
INFO:root:current mean train loss 1746.6500234520372
INFO:root:current train perplexity3.963477611541748
INFO:root:current mean train loss 1747.155772726701
INFO:root:current train perplexity3.9631643295288086
INFO:root:current mean train loss 1746.8520559660546
INFO:root:current train perplexity3.9639387130737305
INFO:root:current mean train loss 1746.8794791000726
INFO:root:current train perplexity3.9629063606262207
INFO:root:current mean train loss 1746.9410273728822
INFO:root:current train perplexity3.9630768299102783
INFO:root:current mean train loss 1748.0897697792564
INFO:root:current train perplexity3.9658217430114746
INFO:root:current mean train loss 1747.641677103141
INFO:root:current train perplexity3.9660000801086426
INFO:root:current mean train loss 1746.3685373643839
INFO:root:current train perplexity3.965210437774658
INFO:root:current mean train loss 1746.766459566189
INFO:root:current train perplexity3.965653419494629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.99s/it]
INFO:root:final mean train loss: 1746.4339298588786
INFO:root:final train perplexity: 3.9643540382385254
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it]
INFO:root:eval mean loss: 2896.1577214421454
INFO:root:eval perplexity: 10.767245292663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:54:59<1:58:45, 356.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.2105526681673
INFO:root:current train perplexity3.974588394165039
INFO:root:current mean train loss 1747.0329144555817
INFO:root:current train perplexity3.9716780185699463
INFO:root:current mean train loss 1738.5080608824505
INFO:root:current train perplexity3.9480631351470947
INFO:root:current mean train loss 1736.2559698843359
INFO:root:current train perplexity3.945897340774536
INFO:root:current mean train loss 1737.1907626548884
INFO:root:current train perplexity3.9433679580688477
INFO:root:current mean train loss 1737.7786111848725
INFO:root:current train perplexity3.9395408630371094
INFO:root:current mean train loss 1738.6263236941625
INFO:root:current train perplexity3.9377074241638184
INFO:root:current mean train loss 1739.989489086689
INFO:root:current train perplexity3.942450761795044
INFO:root:current mean train loss 1740.3971576801696
INFO:root:current train perplexity3.945510149002075
INFO:root:current mean train loss 1739.721594403757
INFO:root:current train perplexity3.946323871612549
INFO:root:current mean train loss 1739.5931244328744
INFO:root:current train perplexity3.946911096572876
INFO:root:current mean train loss 1741.3760338586605
INFO:root:current train perplexity3.9485936164855957
INFO:root:current mean train loss 1742.719477283093
INFO:root:current train perplexity3.9518935680389404
INFO:root:current mean train loss 1742.640139143988
INFO:root:current train perplexity3.9534108638763428
INFO:root:current mean train loss 1743.1210528367835
INFO:root:current train perplexity3.955211639404297
INFO:root:current mean train loss 1743.4782878491571
INFO:root:current train perplexity3.955049753189087
INFO:root:current mean train loss 1743.7928068725512
INFO:root:current train perplexity3.9566500186920166
INFO:root:current mean train loss 1743.697127454453
INFO:root:current train perplexity3.9562137126922607
INFO:root:current mean train loss 1743.6478916966446
INFO:root:current train perplexity3.955268144607544
INFO:root:current mean train loss 1743.9122424123236
INFO:root:current train perplexity3.956051826477051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.16s/it]
INFO:root:final mean train loss: 1743.9104400342362
INFO:root:final train perplexity: 3.956472158432007
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it]
INFO:root:eval mean loss: 2897.3705996035096
INFO:root:eval perplexity: 10.777966499328613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:00:56<1:52:51, 356.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.4601119192023
INFO:root:current train perplexity3.989103317260742
INFO:root:current mean train loss 1750.9396771517668
INFO:root:current train perplexity3.977538585662842
INFO:root:current mean train loss 1750.0267404749773
INFO:root:current train perplexity3.9650635719299316
INFO:root:current mean train loss 1743.254890604222
INFO:root:current train perplexity3.9498491287231445
INFO:root:current mean train loss 1742.1506570767956
INFO:root:current train perplexity3.9497737884521484
INFO:root:current mean train loss 1742.220780690511
INFO:root:current train perplexity3.9482884407043457
INFO:root:current mean train loss 1742.250202427249
INFO:root:current train perplexity3.948237657546997
INFO:root:current mean train loss 1741.240865176486
INFO:root:current train perplexity3.9493207931518555
INFO:root:current mean train loss 1743.0851655028182
INFO:root:current train perplexity3.946192741394043
INFO:root:current mean train loss 1743.6919764534373
INFO:root:current train perplexity3.9482645988464355
INFO:root:current mean train loss 1741.3584781916168
INFO:root:current train perplexity3.9461145401000977
INFO:root:current mean train loss 1741.0942463777503
INFO:root:current train perplexity3.948110580444336
INFO:root:current mean train loss 1742.7920390640306
INFO:root:current train perplexity3.950617551803589
INFO:root:current mean train loss 1743.475198346515
INFO:root:current train perplexity3.950735330581665
INFO:root:current mean train loss 1743.8338134269404
INFO:root:current train perplexity3.949582099914551
INFO:root:current mean train loss 1744.1352569270255
INFO:root:current train perplexity3.95064640045166
INFO:root:current mean train loss 1744.8452677942973
INFO:root:current train perplexity3.9516148567199707
INFO:root:current mean train loss 1743.7870554881054
INFO:root:current train perplexity3.951275110244751
INFO:root:current mean train loss 1743.374605744124
INFO:root:current train perplexity3.952786922454834
INFO:root:current mean train loss 1743.345263091176
INFO:root:current train perplexity3.9530022144317627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.89s/it]
INFO:root:final mean train loss: 1742.6234793227788
INFO:root:final train perplexity: 3.952458620071411
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2897.6087276241083
INFO:root:eval perplexity: 10.780076026916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:06:52<1:46:54, 356.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.3397295551915
INFO:root:current train perplexity3.9465408325195312
INFO:root:current mean train loss 1750.706930684302
INFO:root:current train perplexity3.9502508640289307
INFO:root:current mean train loss 1737.9748326845136
INFO:root:current train perplexity3.9407596588134766
INFO:root:current mean train loss 1738.86514212339
INFO:root:current train perplexity3.9436419010162354
INFO:root:current mean train loss 1738.3447996066018
INFO:root:current train perplexity3.940429449081421
INFO:root:current mean train loss 1737.100003581827
INFO:root:current train perplexity3.9422566890716553
INFO:root:current mean train loss 1737.4062137135868
INFO:root:current train perplexity3.9443109035491943
INFO:root:current mean train loss 1736.8067308308048
INFO:root:current train perplexity3.9444050788879395
INFO:root:current mean train loss 1737.6419394771835
INFO:root:current train perplexity3.9486825466156006
INFO:root:current mean train loss 1739.7378996727089
INFO:root:current train perplexity3.9515535831451416
INFO:root:current mean train loss 1739.5037899872414
INFO:root:current train perplexity3.950287103652954
INFO:root:current mean train loss 1738.9446103654784
INFO:root:current train perplexity3.948751211166382
INFO:root:current mean train loss 1739.1214831854518
INFO:root:current train perplexity3.9486169815063477
INFO:root:current mean train loss 1740.0176407813342
INFO:root:current train perplexity3.9479727745056152
INFO:root:current mean train loss 1740.1620163301134
INFO:root:current train perplexity3.9475834369659424
INFO:root:current mean train loss 1741.1062489118654
INFO:root:current train perplexity3.9486989974975586
INFO:root:current mean train loss 1741.438234152346
INFO:root:current train perplexity3.9483091831207275
INFO:root:current mean train loss 1741.2713103584251
INFO:root:current train perplexity3.949187994003296
INFO:root:current mean train loss 1741.8323002173922
INFO:root:current train perplexity3.94826078414917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.47s/it]
INFO:root:final mean train loss: 1740.8853873033086
INFO:root:final train perplexity: 3.9470436573028564
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.59s/it]
INFO:root:eval mean loss: 2897.3555391328828
INFO:root:eval perplexity: 10.77783489227295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:13:00<1:41:56, 359.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.4796997070312
INFO:root:current train perplexity3.9325454235076904
INFO:root:current mean train loss 1741.9560391512784
INFO:root:current train perplexity3.930427074432373
INFO:root:current mean train loss 1744.2701009114583
INFO:root:current train perplexity3.9326279163360596
INFO:root:current mean train loss 1741.807619156376
INFO:root:current train perplexity3.9350452423095703
INFO:root:current mean train loss 1736.5584136218558
INFO:root:current train perplexity3.932023525238037
INFO:root:current mean train loss 1735.741692277497
INFO:root:current train perplexity3.938992738723755
INFO:root:current mean train loss 1736.6670848408683
INFO:root:current train perplexity3.943070411682129
INFO:root:current mean train loss 1735.8203166263204
INFO:root:current train perplexity3.9421236515045166
INFO:root:current mean train loss 1736.917744954427
INFO:root:current train perplexity3.942373752593994
INFO:root:current mean train loss 1737.8588254153074
INFO:root:current train perplexity3.941946029663086
INFO:root:current mean train loss 1737.5200899936185
INFO:root:current train perplexity3.9394450187683105
INFO:root:current mean train loss 1738.4599232166738
INFO:root:current train perplexity3.9435136318206787
INFO:root:current mean train loss 1739.1653117534543
INFO:root:current train perplexity3.944802761077881
INFO:root:current mean train loss 1740.2306803696029
INFO:root:current train perplexity3.9455347061157227
INFO:root:current mean train loss 1739.701319484846
INFO:root:current train perplexity3.9458534717559814
INFO:root:current mean train loss 1740.6602092010296
INFO:root:current train perplexity3.9465200901031494
INFO:root:current mean train loss 1740.6188337811773
INFO:root:current train perplexity3.945296049118042
INFO:root:current mean train loss 1740.4237982142042
INFO:root:current train perplexity3.9446020126342773
INFO:root:current mean train loss 1739.2786196208133
INFO:root:current train perplexity3.9444496631622314
INFO:root:current mean train loss 1740.0026328201693
INFO:root:current train perplexity3.9438586235046387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.14s/it]
INFO:root:final mean train loss: 1739.757437640107
INFO:root:final train perplexity: 3.9435343742370605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it]
INFO:root:eval mean loss: 2899.437179611252
INFO:root:eval perplexity: 10.796259880065918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [8:19:18<1:37:25, 365.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.3673276548031
INFO:root:current train perplexity3.926753044128418
INFO:root:current mean train loss 1723.8016376645546
INFO:root:current train perplexity3.924680233001709
INFO:root:current mean train loss 1731.8489850418157
INFO:root:current train perplexity3.9376251697540283
INFO:root:current mean train loss 1735.1194482272554
INFO:root:current train perplexity3.934751272201538
INFO:root:current mean train loss 1734.6369477390406
INFO:root:current train perplexity3.9279448986053467
INFO:root:current mean train loss 1733.2374121649668
INFO:root:current train perplexity3.930668354034424
INFO:root:current mean train loss 1733.7079069633423
INFO:root:current train perplexity3.934964179992676
INFO:root:current mean train loss 1733.5871085018698
INFO:root:current train perplexity3.933927536010742
INFO:root:current mean train loss 1733.0679990683097
INFO:root:current train perplexity3.9316341876983643
INFO:root:current mean train loss 1734.8849617012625
INFO:root:current train perplexity3.933256149291992
INFO:root:current mean train loss 1735.1359207168177
INFO:root:current train perplexity3.9326653480529785
INFO:root:current mean train loss 1736.581572755206
INFO:root:current train perplexity3.9346537590026855
INFO:root:current mean train loss 1737.3416718200833
INFO:root:current train perplexity3.9351871013641357
INFO:root:current mean train loss 1737.8982986875646
INFO:root:current train perplexity3.936959743499756
INFO:root:current mean train loss 1739.0706480864303
INFO:root:current train perplexity3.9382622241973877
INFO:root:current mean train loss 1739.3953653571648
INFO:root:current train perplexity3.9377288818359375
INFO:root:current mean train loss 1739.4522886645523
INFO:root:current train perplexity3.9377496242523193
INFO:root:current mean train loss 1739.4088893905844
INFO:root:current train perplexity3.9389665126800537
INFO:root:current mean train loss 1738.5737328072616
INFO:root:current train perplexity3.9380486011505127
INFO:root:current mean train loss 1738.0591007820608
INFO:root:current train perplexity3.93717885017395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.78s/it]
INFO:root:final mean train loss: 1737.887003857742
INFO:root:final train perplexity: 3.9377214908599854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it]
INFO:root:eval mean loss: 2899.3149472714904
INFO:root:eval perplexity: 10.795175552368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [8:25:39<1:32:27, 369.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1711.5800892223012
INFO:root:current train perplexity3.928739547729492
INFO:root:current mean train loss 1712.488878885905
INFO:root:current train perplexity3.930859088897705
INFO:root:current mean train loss 1728.626588414927
INFO:root:current train perplexity3.9440462589263916
INFO:root:current mean train loss 1730.8195488508356
INFO:root:current train perplexity3.934816837310791
INFO:root:current mean train loss 1733.9056957347973
INFO:root:current train perplexity3.9384937286376953
INFO:root:current mean train loss 1736.9025084551643
INFO:root:current train perplexity3.9381027221679688
INFO:root:current mean train loss 1740.1926773734715
INFO:root:current train perplexity3.937326669692993
INFO:root:current mean train loss 1737.7899184688445
INFO:root:current train perplexity3.932800054550171
INFO:root:current mean train loss 1739.3359231813258
INFO:root:current train perplexity3.934809923171997
INFO:root:current mean train loss 1737.8360794843254
INFO:root:current train perplexity3.932979106903076
INFO:root:current mean train loss 1736.5264547647644
INFO:root:current train perplexity3.935469388961792
INFO:root:current mean train loss 1736.5470582121736
INFO:root:current train perplexity3.9338464736938477
INFO:root:current mean train loss 1736.2797383495465
INFO:root:current train perplexity3.9332993030548096
INFO:root:current mean train loss 1735.4628482091994
INFO:root:current train perplexity3.9334869384765625
INFO:root:current mean train loss 1736.3520647297275
INFO:root:current train perplexity3.934480667114258
INFO:root:current mean train loss 1736.6266602827477
INFO:root:current train perplexity3.934342622756958
INFO:root:current mean train loss 1737.111297384666
INFO:root:current train perplexity3.93440842628479
INFO:root:current mean train loss 1737.054734956234
INFO:root:current train perplexity3.9329142570495605
INFO:root:current mean train loss 1737.342527046121
INFO:root:current train perplexity3.934326648712158
INFO:root:current mean train loss 1737.3842674223974
INFO:root:current train perplexity3.9330718517303467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.58s/it]
INFO:root:final mean train loss: 1736.38400063873
INFO:root:final train perplexity: 3.933056354522705
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.30s/it]
INFO:root:eval mean loss: 2900.1859728380723
INFO:root:eval perplexity: 10.802894592285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [8:31:59<1:27:02, 373.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.6527379770748
INFO:root:current train perplexity3.923509359359741
INFO:root:current mean train loss 1718.3742986643535
INFO:root:current train perplexity3.9114575386047363
INFO:root:current mean train loss 1723.0637871168583
INFO:root:current train perplexity3.9110238552093506
INFO:root:current mean train loss 1726.555570058215
INFO:root:current train perplexity3.916018009185791
INFO:root:current mean train loss 1727.3831900971054
INFO:root:current train perplexity3.923661470413208
INFO:root:current mean train loss 1728.4849514068767
INFO:root:current train perplexity3.9294557571411133
INFO:root:current mean train loss 1729.0820308806497
INFO:root:current train perplexity3.92779803276062
INFO:root:current mean train loss 1729.7934759593668
INFO:root:current train perplexity3.9276208877563477
INFO:root:current mean train loss 1731.7370497717952
INFO:root:current train perplexity3.929584264755249
INFO:root:current mean train loss 1732.181583591108
INFO:root:current train perplexity3.9277234077453613
INFO:root:current mean train loss 1732.9546969572853
INFO:root:current train perplexity3.9301815032958984
INFO:root:current mean train loss 1733.9223707463595
INFO:root:current train perplexity3.9294848442077637
INFO:root:current mean train loss 1733.4090906274782
INFO:root:current train perplexity3.9264562129974365
INFO:root:current mean train loss 1733.8126636872303
INFO:root:current train perplexity3.927546501159668
INFO:root:current mean train loss 1734.632073978787
INFO:root:current train perplexity3.931121826171875
INFO:root:current mean train loss 1734.9482203696798
INFO:root:current train perplexity3.930361747741699
INFO:root:current mean train loss 1734.4738290363016
INFO:root:current train perplexity3.9278957843780518
INFO:root:current mean train loss 1734.6316880112952
INFO:root:current train perplexity3.9280972480773926
INFO:root:current mean train loss 1735.3925463775356
INFO:root:current train perplexity3.928941488265991
INFO:root:current mean train loss 1735.7796673811192
INFO:root:current train perplexity3.929781913757324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.11s/it]
INFO:root:final mean train loss: 1735.2363483469353
INFO:root:final train perplexity: 3.9294984340667725
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 2900.8051574523743
INFO:root:eval perplexity: 10.808384895324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [8:38:18<1:21:12, 374.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.0271543845151
INFO:root:current train perplexity3.9266738891601562
INFO:root:current mean train loss 1735.6304808198736
INFO:root:current train perplexity3.9092023372650146
INFO:root:current mean train loss 1738.3811895795864
INFO:root:current train perplexity3.9143340587615967
INFO:root:current mean train loss 1739.7997720708292
INFO:root:current train perplexity3.9240174293518066
INFO:root:current mean train loss 1740.0597695067338
INFO:root:current train perplexity3.9253807067871094
INFO:root:current mean train loss 1739.0971533963425
INFO:root:current train perplexity3.928072690963745
INFO:root:current mean train loss 1737.4785215664754
INFO:root:current train perplexity3.925945997238159
INFO:root:current mean train loss 1734.5176358651993
INFO:root:current train perplexity3.9233129024505615
INFO:root:current mean train loss 1732.9083755249858
INFO:root:current train perplexity3.919348955154419
INFO:root:current mean train loss 1731.7560454760592
INFO:root:current train perplexity3.9179723262786865
INFO:root:current mean train loss 1732.515938102425
INFO:root:current train perplexity3.918238401412964
INFO:root:current mean train loss 1733.1665414185193
INFO:root:current train perplexity3.9167847633361816
INFO:root:current mean train loss 1733.3031583735267
INFO:root:current train perplexity3.9165070056915283
INFO:root:current mean train loss 1732.0506556362823
INFO:root:current train perplexity3.9163691997528076
INFO:root:current mean train loss 1732.820015748557
INFO:root:current train perplexity3.920334815979004
INFO:root:current mean train loss 1733.1301267210522
INFO:root:current train perplexity3.9206278324127197
INFO:root:current mean train loss 1734.3509814656818
INFO:root:current train perplexity3.9236395359039307
INFO:root:current mean train loss 1733.82178620037
INFO:root:current train perplexity3.924140453338623
INFO:root:current mean train loss 1733.8846850247937
INFO:root:current train perplexity3.9243690967559814
INFO:root:current mean train loss 1733.9087523179783
INFO:root:current train perplexity3.9241390228271484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.82s/it]
INFO:root:final mean train loss: 1733.4682677514734
INFO:root:final train perplexity: 3.924022912979126
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it]
INFO:root:eval mean loss: 2902.826386689424
INFO:root:eval perplexity: 10.826324462890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [8:44:34<1:15:02, 375.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.7878019634047
INFO:root:current train perplexity3.956141471862793
INFO:root:current mean train loss 1744.7169633914264
INFO:root:current train perplexity3.9344089031219482
INFO:root:current mean train loss 1741.4261586334746
INFO:root:current train perplexity3.9353742599487305
INFO:root:current mean train loss 1735.7080047221123
INFO:root:current train perplexity3.924135684967041
INFO:root:current mean train loss 1734.212480764678
INFO:root:current train perplexity3.917724370956421
INFO:root:current mean train loss 1731.6763598017333
INFO:root:current train perplexity3.9119482040405273
INFO:root:current mean train loss 1732.8224084209196
INFO:root:current train perplexity3.9196746349334717
INFO:root:current mean train loss 1735.1267817659198
INFO:root:current train perplexity3.9234018325805664
INFO:root:current mean train loss 1734.8239742002008
INFO:root:current train perplexity3.9262473583221436
INFO:root:current mean train loss 1733.934021425487
INFO:root:current train perplexity3.923123598098755
INFO:root:current mean train loss 1734.3941307033033
INFO:root:current train perplexity3.9233133792877197
INFO:root:current mean train loss 1733.3602461427824
INFO:root:current train perplexity3.9203438758850098
INFO:root:current mean train loss 1733.2128376493122
INFO:root:current train perplexity3.9196970462799072
INFO:root:current mean train loss 1731.7792504970319
INFO:root:current train perplexity3.9201910495758057
INFO:root:current mean train loss 1732.3965196488293
INFO:root:current train perplexity3.917952299118042
INFO:root:current mean train loss 1732.3396063442888
INFO:root:current train perplexity3.9185075759887695
INFO:root:current mean train loss 1732.5610435103245
INFO:root:current train perplexity3.9196903705596924
INFO:root:current mean train loss 1733.2851332640582
INFO:root:current train perplexity3.923143148422241
INFO:root:current mean train loss 1733.5761684608963
INFO:root:current train perplexity3.9234936237335205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it]
INFO:root:final mean train loss: 1733.1883254058423
INFO:root:final train perplexity: 3.92315673828125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it]
INFO:root:eval mean loss: 2902.8280106278153
INFO:root:eval perplexity: 10.826342582702637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [8:50:52<1:08:56, 376.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.9091491699219
INFO:root:current train perplexity3.887890100479126
INFO:root:current mean train loss 1736.661061968122
INFO:root:current train perplexity3.921783447265625
INFO:root:current mean train loss 1730.1525994066922
INFO:root:current train perplexity3.91758131980896
INFO:root:current mean train loss 1728.0716830522585
INFO:root:current train perplexity3.9150168895721436
INFO:root:current mean train loss 1730.2895261894153
INFO:root:current train perplexity3.920405864715576
INFO:root:current mean train loss 1729.2251906394958
INFO:root:current train perplexity3.916917324066162
INFO:root:current mean train loss 1726.8057284884983
INFO:root:current train perplexity3.912745714187622
INFO:root:current mean train loss 1726.3111620270804
INFO:root:current train perplexity3.910928726196289
INFO:root:current mean train loss 1726.138224634631
INFO:root:current train perplexity3.9075660705566406
INFO:root:current mean train loss 1725.8083165486653
INFO:root:current train perplexity3.906038999557495
INFO:root:current mean train loss 1727.2996828584332
INFO:root:current train perplexity3.907198429107666
INFO:root:current mean train loss 1727.288888396119
INFO:root:current train perplexity3.9098174571990967
INFO:root:current mean train loss 1727.666353332721
INFO:root:current train perplexity3.911921977996826
INFO:root:current mean train loss 1729.2315600325421
INFO:root:current train perplexity3.91207218170166
INFO:root:current mean train loss 1730.5551298752048
INFO:root:current train perplexity3.9131155014038086
INFO:root:current mean train loss 1730.5866452979033
INFO:root:current train perplexity3.9134817123413086
INFO:root:current mean train loss 1729.7912009265228
INFO:root:current train perplexity3.913221836090088
INFO:root:current mean train loss 1730.403350901381
INFO:root:current train perplexity3.9152660369873047
INFO:root:current mean train loss 1730.6231864609204
INFO:root:current train perplexity3.915452718734741
INFO:root:current mean train loss 1731.8358282623929
INFO:root:current train perplexity3.9179012775421143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.85s/it]
INFO:root:final mean train loss: 1731.657501112976
INFO:root:final train perplexity: 3.9184229373931885
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.30s/it]
INFO:root:eval mean loss: 2902.8840185400245
INFO:root:eval perplexity: 10.826841354370117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:57:11<1:02:49, 376.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1706.5640237742457
INFO:root:current train perplexity3.9264721870422363
INFO:root:current mean train loss 1719.1133200475413
INFO:root:current train perplexity3.8855693340301514
INFO:root:current mean train loss 1730.1030332073894
INFO:root:current train perplexity3.9005613327026367
INFO:root:current mean train loss 1733.5338769234422
INFO:root:current train perplexity3.9083986282348633
INFO:root:current mean train loss 1736.7212138853984
INFO:root:current train perplexity3.908099889755249
INFO:root:current mean train loss 1734.4416393143017
INFO:root:current train perplexity3.90940260887146
INFO:root:current mean train loss 1735.1208597010384
INFO:root:current train perplexity3.913724422454834
INFO:root:current mean train loss 1734.8415328079454
INFO:root:current train perplexity3.909090042114258
INFO:root:current mean train loss 1734.858363244732
INFO:root:current train perplexity3.911015510559082
INFO:root:current mean train loss 1733.2232514905982
INFO:root:current train perplexity3.910320520401001
INFO:root:current mean train loss 1733.4536228902834
INFO:root:current train perplexity3.911357879638672
INFO:root:current mean train loss 1730.9942113371208
INFO:root:current train perplexity3.908686876296997
INFO:root:current mean train loss 1731.1361157484807
INFO:root:current train perplexity3.9095001220703125
INFO:root:current mean train loss 1730.372861702878
INFO:root:current train perplexity3.9108057022094727
INFO:root:current mean train loss 1730.0522441290075
INFO:root:current train perplexity3.913193464279175
INFO:root:current mean train loss 1730.3714207611183
INFO:root:current train perplexity3.914635181427002
INFO:root:current mean train loss 1729.9863933190895
INFO:root:current train perplexity3.913217306137085
INFO:root:current mean train loss 1730.3009543653304
INFO:root:current train perplexity3.914064407348633
INFO:root:current mean train loss 1731.0420632005194
INFO:root:current train perplexity3.9144415855407715
INFO:root:current mean train loss 1730.6622682119541
INFO:root:current train perplexity3.913377285003662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it]
INFO:root:final mean train loss: 1730.0227039085153
INFO:root:final train perplexity: 3.9133739471435547
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it]
INFO:root:eval mean loss: 2903.0313379786035
INFO:root:eval perplexity: 10.828146934509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:03:28<56:32, 376.91s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1731.044696310292
INFO:root:current train perplexity3.9317986965179443
INFO:root:current mean train loss 1729.0369413192957
INFO:root:current train perplexity3.918189525604248
INFO:root:current mean train loss 1730.9186604817708
INFO:root:current train perplexity3.9193387031555176
INFO:root:current mean train loss 1728.522873013006
INFO:root:current train perplexity3.912100076675415
INFO:root:current mean train loss 1730.4655329272352
INFO:root:current train perplexity3.9211504459381104
INFO:root:current mean train loss 1730.488966051039
INFO:root:current train perplexity3.9200265407562256
INFO:root:current mean train loss 1730.3025576942846
INFO:root:current train perplexity3.918513059616089
INFO:root:current mean train loss 1728.1123874858622
INFO:root:current train perplexity3.913874626159668
INFO:root:current mean train loss 1726.8336529382295
INFO:root:current train perplexity3.914048671722412
INFO:root:current mean train loss 1728.0073100245277
INFO:root:current train perplexity3.915034055709839
INFO:root:current mean train loss 1730.019382338223
INFO:root:current train perplexity3.918848991394043
INFO:root:current mean train loss 1730.0726195862987
INFO:root:current train perplexity3.9179747104644775
INFO:root:current mean train loss 1729.958442112416
INFO:root:current train perplexity3.914158821105957
INFO:root:current mean train loss 1730.3431164314984
INFO:root:current train perplexity3.9169700145721436
INFO:root:current mean train loss 1730.637008814726
INFO:root:current train perplexity3.9151201248168945
INFO:root:current mean train loss 1730.6471245729908
INFO:root:current train perplexity3.915034055709839
INFO:root:current mean train loss 1730.0199074727796
INFO:root:current train perplexity3.91418719291687
INFO:root:current mean train loss 1730.1595437310953
INFO:root:current train perplexity3.9145236015319824
INFO:root:current mean train loss 1730.2495092059266
INFO:root:current train perplexity3.914013624191284
INFO:root:current mean train loss 1730.065837048553
INFO:root:current train perplexity3.9129292964935303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.93s/it]
INFO:root:final mean train loss: 1729.8977664826316
INFO:root:final train perplexity: 3.9129886627197266
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.85s/it]
INFO:root:eval mean loss: 2904.394873633399
INFO:root:eval perplexity: 10.840270042419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:09:42<50:06, 375.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.1886528862847
INFO:root:current train perplexity3.896977424621582
INFO:root:current mean train loss 1724.3895061469516
INFO:root:current train perplexity3.87733793258667
INFO:root:current mean train loss 1725.0126038758021
INFO:root:current train perplexity3.8982114791870117
INFO:root:current mean train loss 1723.1640621637182
INFO:root:current train perplexity3.901348114013672
INFO:root:current mean train loss 1729.3519795955385
INFO:root:current train perplexity3.9097938537597656
INFO:root:current mean train loss 1730.2108418818689
INFO:root:current train perplexity3.9120922088623047
INFO:root:current mean train loss 1730.3048058879501
INFO:root:current train perplexity3.9113199710845947
INFO:root:current mean train loss 1731.8028658845633
INFO:root:current train perplexity3.909261465072632
INFO:root:current mean train loss 1732.4687321774516
INFO:root:current train perplexity3.915134906768799
INFO:root:current mean train loss 1732.6516963843865
INFO:root:current train perplexity3.916003704071045
INFO:root:current mean train loss 1733.001347022357
INFO:root:current train perplexity3.9174458980560303
INFO:root:current mean train loss 1731.2401239554224
INFO:root:current train perplexity3.913625955581665
INFO:root:current mean train loss 1730.089422834552
INFO:root:current train perplexity3.910383462905884
INFO:root:current mean train loss 1729.4727510940652
INFO:root:current train perplexity3.907236337661743
INFO:root:current mean train loss 1728.599575749343
INFO:root:current train perplexity3.907625675201416
INFO:root:current mean train loss 1728.7118213577905
INFO:root:current train perplexity3.908191204071045
INFO:root:current mean train loss 1728.3787595894562
INFO:root:current train perplexity3.906681537628174
INFO:root:current mean train loss 1727.984411074097
INFO:root:current train perplexity3.905952215194702
INFO:root:current mean train loss 1727.761520475837
INFO:root:current train perplexity3.904893159866333
INFO:root:current mean train loss 1728.6392222174684
INFO:root:current train perplexity3.9071178436279297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.40s/it]
INFO:root:final mean train loss: 1728.104408714306
INFO:root:final train perplexity: 3.9074580669403076
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 2903.3093093093094
INFO:root:eval perplexity: 10.830617904663086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:15:55<43:45, 375.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1715.573518371582
INFO:root:current train perplexity3.8954107761383057
INFO:root:current mean train loss 1723.20135023329
INFO:root:current train perplexity3.8855137825012207
INFO:root:current mean train loss 1727.6677987234932
INFO:root:current train perplexity3.890042304992676
INFO:root:current mean train loss 1726.7822416606703
INFO:root:current train perplexity3.903019905090332
INFO:root:current mean train loss 1726.6103235880535
INFO:root:current train perplexity3.9032251834869385
INFO:root:current mean train loss 1727.434592832368
INFO:root:current train perplexity3.9068169593811035
INFO:root:current mean train loss 1727.1752012365005
INFO:root:current train perplexity3.9058353900909424
INFO:root:current mean train loss 1726.823137488732
INFO:root:current train perplexity3.907036781311035
INFO:root:current mean train loss 1726.3094031594017
INFO:root:current train perplexity3.904529571533203
INFO:root:current mean train loss 1726.1115538305166
INFO:root:current train perplexity3.904534339904785
INFO:root:current mean train loss 1726.0491129557292
INFO:root:current train perplexity3.9041619300842285
INFO:root:current mean train loss 1725.3528892387778
INFO:root:current train perplexity3.9039223194122314
INFO:root:current mean train loss 1726.5100347518921
INFO:root:current train perplexity3.9063658714294434
INFO:root:current mean train loss 1726.850278638757
INFO:root:current train perplexity3.9045045375823975
INFO:root:current mean train loss 1728.6521432412637
INFO:root:current train perplexity3.9066874980926514
INFO:root:current mean train loss 1728.6408685998072
INFO:root:current train perplexity3.9058163166046143
INFO:root:current mean train loss 1728.1571906680153
INFO:root:current train perplexity3.9061968326568604
INFO:root:current mean train loss 1728.3964634584577
INFO:root:current train perplexity3.9057977199554443
INFO:root:current mean train loss 1727.8937113660447
INFO:root:current train perplexity3.9053261280059814
INFO:root:current mean train loss 1727.9553717102667
INFO:root:current train perplexity3.905669689178467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.98s/it]
INFO:root:final mean train loss: 1727.534141459732
INFO:root:final train perplexity: 3.905700922012329
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it]
INFO:root:eval mean loss: 2904.6670031848253
INFO:root:eval perplexity: 10.842691421508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [9:21:55<37:02, 370.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.4945294881604
INFO:root:current train perplexity3.9252235889434814
INFO:root:current mean train loss 1728.9121031785373
INFO:root:current train perplexity3.9165942668914795
INFO:root:current mean train loss 1729.4647003071075
INFO:root:current train perplexity3.903979539871216
INFO:root:current mean train loss 1729.1388210037194
INFO:root:current train perplexity3.910365581512451
INFO:root:current mean train loss 1729.2055479851767
INFO:root:current train perplexity3.908524751663208
INFO:root:current mean train loss 1730.3276113641123
INFO:root:current train perplexity3.902000665664673
INFO:root:current mean train loss 1728.8920322237602
INFO:root:current train perplexity3.897510290145874
INFO:root:current mean train loss 1726.9772367202204
INFO:root:current train perplexity3.8979299068450928
INFO:root:current mean train loss 1727.2481636379075
INFO:root:current train perplexity3.897169351577759
INFO:root:current mean train loss 1727.8998689182783
INFO:root:current train perplexity3.900613307952881
INFO:root:current mean train loss 1728.448735921298
INFO:root:current train perplexity3.903989791870117
INFO:root:current mean train loss 1727.8700856756147
INFO:root:current train perplexity3.903414487838745
INFO:root:current mean train loss 1728.2699422608364
INFO:root:current train perplexity3.905667781829834
INFO:root:current mean train loss 1728.0125101535937
INFO:root:current train perplexity3.9033875465393066
INFO:root:current mean train loss 1728.1728667295529
INFO:root:current train perplexity3.904804229736328
INFO:root:current mean train loss 1728.4757054089455
INFO:root:current train perplexity3.9055490493774414
INFO:root:current mean train loss 1728.140732108247
INFO:root:current train perplexity3.9057810306549072
INFO:root:current mean train loss 1727.8744202848932
INFO:root:current train perplexity3.9059858322143555
INFO:root:current mean train loss 1728.2656828498739
INFO:root:current train perplexity3.907590627670288

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.69s/it]
INFO:root:final mean train loss: 1726.9879977735557
INFO:root:final train perplexity: 3.904019594192505
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 2904.6262610266517
INFO:root:eval perplexity: 10.842329978942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [9:27:50<30:29, 366.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.824009486607
INFO:root:current train perplexity3.848057746887207
INFO:root:current mean train loss 1713.785669159471
INFO:root:current train perplexity3.8598272800445557
INFO:root:current mean train loss 1720.139703198014
INFO:root:current train perplexity3.8648526668548584
INFO:root:current mean train loss 1719.7693722475865
INFO:root:current train perplexity3.870335578918457
INFO:root:current mean train loss 1719.729891717146
INFO:root:current train perplexity3.873173236846924
INFO:root:current mean train loss 1721.807690572182
INFO:root:current train perplexity3.8806612491607666
INFO:root:current mean train loss 1723.0707667844692
INFO:root:current train perplexity3.8899378776550293
INFO:root:current mean train loss 1724.77400169052
INFO:root:current train perplexity3.8888449668884277
INFO:root:current mean train loss 1724.6462840237255
INFO:root:current train perplexity3.890948534011841
INFO:root:current mean train loss 1725.1381367155448
INFO:root:current train perplexity3.8914577960968018
INFO:root:current mean train loss 1725.1379566681692
INFO:root:current train perplexity3.8894872665405273
INFO:root:current mean train loss 1726.1064429017756
INFO:root:current train perplexity3.89159893989563
INFO:root:current mean train loss 1725.9663473063285
INFO:root:current train perplexity3.892712354660034
INFO:root:current mean train loss 1725.334627613085
INFO:root:current train perplexity3.8930108547210693
INFO:root:current mean train loss 1725.5321747646306
INFO:root:current train perplexity3.8959217071533203
INFO:root:current mean train loss 1726.496033924259
INFO:root:current train perplexity3.8961143493652344
INFO:root:current mean train loss 1726.5180466662553
INFO:root:current train perplexity3.8982343673706055
INFO:root:current mean train loss 1727.1517644501623
INFO:root:current train perplexity3.8992080688476562
INFO:root:current mean train loss 1727.3797584542103
INFO:root:current train perplexity3.8990750312805176
INFO:root:current mean train loss 1727.2882094746972
INFO:root:current train perplexity3.899862051010132

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.77s/it]
INFO:root:final mean train loss: 1725.7616217955158
INFO:root:final train perplexity: 3.900245189666748
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it]
INFO:root:eval mean loss: 2903.979280305696
INFO:root:eval perplexity: 10.83657455444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [9:33:46<24:11, 362.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.8990636025705
INFO:root:current train perplexity3.968611478805542
INFO:root:current mean train loss 1735.57958984375
INFO:root:current train perplexity3.9515748023986816
INFO:root:current mean train loss 1733.5883461427895
INFO:root:current train perplexity3.9352352619171143
INFO:root:current mean train loss 1732.2714729424329
INFO:root:current train perplexity3.9212419986724854
INFO:root:current mean train loss 1734.7243689163101
INFO:root:current train perplexity3.9207541942596436
INFO:root:current mean train loss 1732.9959390356491
INFO:root:current train perplexity3.915480852127075
INFO:root:current mean train loss 1731.5770110842166
INFO:root:current train perplexity3.90985107421875
INFO:root:current mean train loss 1730.7280744351701
INFO:root:current train perplexity3.906980514526367
INFO:root:current mean train loss 1729.9030062495299
INFO:root:current train perplexity3.9064362049102783
INFO:root:current mean train loss 1728.0412756308322
INFO:root:current train perplexity3.903043270111084
INFO:root:current mean train loss 1726.9571368627244
INFO:root:current train perplexity3.9020397663116455
INFO:root:current mean train loss 1726.7651896050922
INFO:root:current train perplexity3.901369571685791
INFO:root:current mean train loss 1727.3372854299414
INFO:root:current train perplexity3.902101516723633
INFO:root:current mean train loss 1727.0562566216954
INFO:root:current train perplexity3.900627374649048
INFO:root:current mean train loss 1725.639243924976
INFO:root:current train perplexity3.90061092376709
INFO:root:current mean train loss 1725.3361341998439
INFO:root:current train perplexity3.9013192653656006
INFO:root:current mean train loss 1726.9033439631553
INFO:root:current train perplexity3.904050588607788
INFO:root:current mean train loss 1726.6903514101766
INFO:root:current train perplexity3.9017419815063477
INFO:root:current mean train loss 1726.207516997841
INFO:root:current train perplexity3.901562452316284
INFO:root:current mean train loss 1726.2446400955018
INFO:root:current train perplexity3.900925397872925

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.53s/it]
INFO:root:final mean train loss: 1725.6406862506108
INFO:root:final train perplexity: 3.8998732566833496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 2904.9320673212274
INFO:root:eval perplexity: 10.845046997070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [9:39:42<18:02, 360.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.481938680013
INFO:root:current train perplexity3.908541202545166
INFO:root:current mean train loss 1722.4792323756863
INFO:root:current train perplexity3.9171156883239746
INFO:root:current mean train loss 1727.509254701676
INFO:root:current train perplexity3.924628257751465
INFO:root:current mean train loss 1726.6684149380387
INFO:root:current train perplexity3.9124913215637207
INFO:root:current mean train loss 1729.2790500095912
INFO:root:current train perplexity3.9114086627960205
INFO:root:current mean train loss 1729.1076740348426
INFO:root:current train perplexity3.899754047393799
INFO:root:current mean train loss 1730.9514022638768
INFO:root:current train perplexity3.9023244380950928
INFO:root:current mean train loss 1730.556121010194
INFO:root:current train perplexity3.9001224040985107
INFO:root:current mean train loss 1728.501442243468
INFO:root:current train perplexity3.9013118743896484
INFO:root:current mean train loss 1728.2565517506016
INFO:root:current train perplexity3.9008822441101074
INFO:root:current mean train loss 1727.7514934976593
INFO:root:current train perplexity3.9010202884674072
INFO:root:current mean train loss 1725.8236440200008
INFO:root:current train perplexity3.9008491039276123
INFO:root:current mean train loss 1726.5024754450872
INFO:root:current train perplexity3.900120973587036
INFO:root:current mean train loss 1727.5821295944802
INFO:root:current train perplexity3.9012291431427
INFO:root:current mean train loss 1727.2718825366615
INFO:root:current train perplexity3.901257038116455
INFO:root:current mean train loss 1726.1779450803456
INFO:root:current train perplexity3.8985726833343506
INFO:root:current mean train loss 1726.3084840496767
INFO:root:current train perplexity3.8979313373565674
INFO:root:current mean train loss 1726.1195877738621
INFO:root:current train perplexity3.897754192352295
INFO:root:current mean train loss 1725.3661344453885
INFO:root:current train perplexity3.8981428146362305
INFO:root:current mean train loss 1724.946724893621
INFO:root:current train perplexity3.8976924419403076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.71s/it]
INFO:root:final mean train loss: 1724.8959987099822
INFO:root:final train perplexity: 3.897583246231079
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.02s/it]
INFO:root:eval mean loss: 2904.8825954861113
INFO:root:eval perplexity: 10.844610214233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [9:45:37<11:58, 359.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1726.3378699669472
INFO:root:current train perplexity3.8691210746765137
INFO:root:current mean train loss 1720.615507368608
INFO:root:current train perplexity3.8883731365203857
INFO:root:current mean train loss 1721.1499327461675
INFO:root:current train perplexity3.895310401916504
INFO:root:current mean train loss 1720.75032273384
INFO:root:current train perplexity3.896514892578125
INFO:root:current mean train loss 1724.538602045531
INFO:root:current train perplexity3.8993961811065674
INFO:root:current mean train loss 1727.6476305396156
INFO:root:current train perplexity3.89715313911438
INFO:root:current mean train loss 1727.2444385499882
INFO:root:current train perplexity3.893871784210205
INFO:root:current mean train loss 1727.9440542981515
INFO:root:current train perplexity3.89455509185791
INFO:root:current mean train loss 1728.0851458069906
INFO:root:current train perplexity3.896568775177002
INFO:root:current mean train loss 1728.2744712394754
INFO:root:current train perplexity3.8981101512908936
INFO:root:current mean train loss 1727.1119479900235
INFO:root:current train perplexity3.893766403198242
INFO:root:current mean train loss 1726.7184343984711
INFO:root:current train perplexity3.896467924118042
INFO:root:current mean train loss 1726.5999489524147
INFO:root:current train perplexity3.896667957305908
INFO:root:current mean train loss 1726.9392616579385
INFO:root:current train perplexity3.8983356952667236
INFO:root:current mean train loss 1725.790417355482
INFO:root:current train perplexity3.8967766761779785
INFO:root:current mean train loss 1725.4938688723043
INFO:root:current train perplexity3.8967766761779785
INFO:root:current mean train loss 1724.9668966573995
INFO:root:current train perplexity3.8949570655822754
INFO:root:current mean train loss 1725.2648106215695
INFO:root:current train perplexity3.895164728164673
INFO:root:current mean train loss 1725.0102683714183
INFO:root:current train perplexity3.8952083587646484
INFO:root:current mean train loss 1725.2153563831903
INFO:root:current train perplexity3.896542549133301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.80s/it]
INFO:root:final mean train loss: 1724.7162828623377
INFO:root:final train perplexity: 3.897030830383301
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.92s/it]
INFO:root:eval mean loss: 2905.0126806493995
INFO:root:eval perplexity: 10.845766067504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [9:51:34<05:58, 358.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.5093651748284
INFO:root:current train perplexity3.8555338382720947
INFO:root:current mean train loss 1713.987571632469
INFO:root:current train perplexity3.864652395248413
INFO:root:current mean train loss 1718.5808681190438
INFO:root:current train perplexity3.8741891384124756
INFO:root:current mean train loss 1720.8820366185373
INFO:root:current train perplexity3.8748559951782227
INFO:root:current mean train loss 1721.58706551073
INFO:root:current train perplexity3.8760337829589844
INFO:root:current mean train loss 1721.4255117304956
INFO:root:current train perplexity3.8819997310638428
INFO:root:current mean train loss 1723.0353742582706
INFO:root:current train perplexity3.8865792751312256
INFO:root:current mean train loss 1723.7762833617228
INFO:root:current train perplexity3.888824224472046
INFO:root:current mean train loss 1723.035779472922
INFO:root:current train perplexity3.887927770614624
INFO:root:current mean train loss 1723.5528231308076
INFO:root:current train perplexity3.889122247695923
INFO:root:current mean train loss 1723.0548162266418
INFO:root:current train perplexity3.8877010345458984
INFO:root:current mean train loss 1723.030034770417
INFO:root:current train perplexity3.8868539333343506
INFO:root:current mean train loss 1723.102538776844
INFO:root:current train perplexity3.8872103691101074
INFO:root:current mean train loss 1723.2156235160771
INFO:root:current train perplexity3.887791872024536
INFO:root:current mean train loss 1725.234151451533
INFO:root:current train perplexity3.891754150390625
INFO:root:current mean train loss 1723.4560871727097
INFO:root:current train perplexity3.8895387649536133
INFO:root:current mean train loss 1722.5754597739856
INFO:root:current train perplexity3.889711618423462
INFO:root:current mean train loss 1722.4009932358524
INFO:root:current train perplexity3.8895716667175293
INFO:root:current mean train loss 1723.4948930892376
INFO:root:current train perplexity3.8925867080688477
INFO:root:current mean train loss 1724.2806611431595
INFO:root:current train perplexity3.894244909286499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.55s/it]
INFO:root:final mean train loss: 1723.772819576754
INFO:root:final train perplexity: 3.894132137298584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it]
INFO:root:eval mean loss: 2905.037259671781
INFO:root:eval perplexity: 10.845983505249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24_1/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:57:30<00:00, 357.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:57:30<00:00, 358.50s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 35.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 35.00s/it]
INFO:root:eval mean loss: 2905.037259671781
INFO:root:eval perplexity: 10.845983505249023
INFO:root:evalaution complete
INFO:root:save model final: std_24_1/final
