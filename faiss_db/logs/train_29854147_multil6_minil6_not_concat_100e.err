INFO:root:Output: multiqal6_minilml6_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11894.42297979798
INFO:root:current train perplexity12709.3623046875
INFO:root:current mean train loss 10128.577069919913
INFO:root:current train perplexity2962.3232421875
INFO:root:current mean train loss 8841.611479998432
INFO:root:current train perplexity1065.3319091796875
INFO:root:current mean train loss 7962.877530740915
INFO:root:current train perplexity532.2122802734375
INFO:root:current mean train loss 7322.198531829284
INFO:root:current train perplexity321.7378234863281
INFO:root:current mean train loss 6833.359727149415
INFO:root:current train perplexity218.77304077148438
INFO:root:current mean train loss 6452.1090232838205
INFO:root:current train perplexity161.46148681640625
INFO:root:current mean train loss 6147.402387444755
INFO:root:current train perplexity126.5692138671875
INFO:root:current mean train loss 5886.538509856872
INFO:root:current train perplexity103.54176330566406
INFO:root:current mean train loss 5675.871398498108
INFO:root:current train perplexity87.24568176269531
INFO:root:current mean train loss 5487.127735752318
INFO:root:current train perplexity75.35205841064453
INFO:root:current mean train loss 5326.226206979123
INFO:root:current train perplexity66.41173553466797
INFO:root:current mean train loss 5187.422315543206
INFO:root:current train perplexity59.36537551879883
INFO:root:current mean train loss 5058.020304158384
INFO:root:current train perplexity53.742305755615234
INFO:root:current mean train loss 4944.533596290757
INFO:root:current train perplexity49.21088409423828
INFO:root:current mean train loss 4842.417375575311
INFO:root:current train perplexity45.42828369140625
INFO:root:current mean train loss 4750.757560312362
INFO:root:current train perplexity42.2310905456543
INFO:root:current mean train loss 4665.685995936327
INFO:root:current train perplexity39.535770416259766
INFO:root:current mean train loss 4586.327676830322
INFO:root:current train perplexity37.1942253112793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.98s/it]
INFO:root:final mean train loss: 4524.362468001942
INFO:root:final train perplexity: 35.45217514038086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.94s/it]
INFO:root:eval mean loss: 2934.5084479582224
INFO:root:eval perplexity: 10.73230266571045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.35s/it]
INFO:root:eval mean loss: 3218.4518229166665
INFO:root:eval perplexity: 13.903470993041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/1
  1%|          | 1/100 [06:13<10:15:42, 373.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3123.0486450195312
INFO:root:current train perplexity11.82573127746582
INFO:root:current mean train loss 3137.4198818864493
INFO:root:current train perplexity11.556361198425293
INFO:root:current mean train loss 3119.92301997432
INFO:root:current train perplexity11.464017868041992
INFO:root:current mean train loss 3090.355936171133
INFO:root:current train perplexity11.366952896118164
INFO:root:current mean train loss 3079.0906184269834
INFO:root:current train perplexity11.252506256103516
INFO:root:current mean train loss 3058.202025420906
INFO:root:current train perplexity11.120540618896484
INFO:root:current mean train loss 3042.999474859857
INFO:root:current train perplexity11.001655578613281
INFO:root:current mean train loss 3029.7242114530595
INFO:root:current train perplexity10.906559944152832
INFO:root:current mean train loss 3015.980066935221
INFO:root:current train perplexity10.804314613342285
INFO:root:current mean train loss 3005.6179031305437
INFO:root:current train perplexity10.69597339630127
INFO:root:current mean train loss 2995.1991053303395
INFO:root:current train perplexity10.5980224609375
INFO:root:current mean train loss 2984.084073849476
INFO:root:current train perplexity10.497953414916992
INFO:root:current mean train loss 2972.6780795047157
INFO:root:current train perplexity10.409713745117188
INFO:root:current mean train loss 2964.0858848131174
INFO:root:current train perplexity10.332120895385742
INFO:root:current mean train loss 2955.5095445880784
INFO:root:current train perplexity10.263442039489746
INFO:root:current mean train loss 2947.037714573198
INFO:root:current train perplexity10.194670677185059
INFO:root:current mean train loss 2935.9516684654914
INFO:root:current train perplexity10.120135307312012
INFO:root:current mean train loss 2927.2267012162642
INFO:root:current train perplexity10.051017761230469
INFO:root:current mean train loss 2917.1937809746696
INFO:root:current train perplexity9.981775283813477
INFO:root:current mean train loss 2910.826676848537
INFO:root:current train perplexity9.925212860107422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.34s/it]
INFO:root:final mean train loss: 2904.9472716577234
INFO:root:final train perplexity: 9.884976387023926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2573.5425618489585
INFO:root:eval perplexity: 8.015122413635254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it]
INFO:root:eval mean loss: 2901.820656201518
INFO:root:eval perplexity: 10.731560707092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/2
  2%|â–         | 2/100 [12:39<10:22:08, 380.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2751.966249408144
INFO:root:current train perplexity8.791635513305664
INFO:root:current mean train loss 2709.1608023966164
INFO:root:current train perplexity8.55313777923584
INFO:root:current mean train loss 2693.571083690987
INFO:root:current train perplexity8.494913101196289
INFO:root:current mean train loss 2696.593464069538
INFO:root:current train perplexity8.481879234313965
INFO:root:current mean train loss 2696.718020961136
INFO:root:current train perplexity8.442584037780762
INFO:root:current mean train loss 2692.7935985686854
INFO:root:current train perplexity8.410970687866211
INFO:root:current mean train loss 2690.916921992249
INFO:root:current train perplexity8.38707447052002
INFO:root:current mean train loss 2689.7672523821198
INFO:root:current train perplexity8.359025001525879
INFO:root:current mean train loss 2684.820675340449
INFO:root:current train perplexity8.32601547241211
INFO:root:current mean train loss 2682.874474561227
INFO:root:current train perplexity8.299910545349121
INFO:root:current mean train loss 2681.080447526546
INFO:root:current train perplexity8.27725601196289
INFO:root:current mean train loss 2675.1670844136142
INFO:root:current train perplexity8.2400484085083
INFO:root:current mean train loss 2668.948705520073
INFO:root:current train perplexity8.202982902526855
INFO:root:current mean train loss 2664.5263027182577
INFO:root:current train perplexity8.171098709106445
INFO:root:current mean train loss 2657.5348323760795
INFO:root:current train perplexity8.139148712158203
INFO:root:current mean train loss 2655.405360550952
INFO:root:current train perplexity8.121695518493652
INFO:root:current mean train loss 2652.2409649280703
INFO:root:current train perplexity8.095637321472168
INFO:root:current mean train loss 2648.9564358314474
INFO:root:current train perplexity8.069558143615723
INFO:root:current mean train loss 2643.696052979981
INFO:root:current train perplexity8.03600788116455
INFO:root:current mean train loss 2639.866375508237
INFO:root:current train perplexity8.01390552520752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.87s/it]
INFO:root:final mean train loss: 2636.1778553372615
INFO:root:final train perplexity: 7.996857166290283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.23s/it]
INFO:root:eval mean loss: 2405.8678026131706
INFO:root:eval perplexity: 6.9987006187438965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it]
INFO:root:eval mean loss: 2760.5082401789673
INFO:root:eval perplexity: 9.560304641723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/3
  3%|â–Ž         | 3/100 [19:00<10:15:37, 380.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2579.42501953125
INFO:root:current train perplexity7.458364963531494
INFO:root:current mean train loss 2542.1998225911457
INFO:root:current train perplexity7.384019374847412
INFO:root:current mean train loss 2539.38288671875
INFO:root:current train perplexity7.397719860076904
INFO:root:current mean train loss 2536.290242047991
INFO:root:current train perplexity7.379837512969971
INFO:root:current mean train loss 2534.668626844618
INFO:root:current train perplexity7.380422592163086
INFO:root:current mean train loss 2528.3373086825286
INFO:root:current train perplexity7.347289562225342
INFO:root:current mean train loss 2526.440096529447
INFO:root:current train perplexity7.327127933502197
INFO:root:current mean train loss 2523.160267578125
INFO:root:current train perplexity7.30328893661499
INFO:root:current mean train loss 2522.3438114659925
INFO:root:current train perplexity7.286489486694336
INFO:root:current mean train loss 2517.9531098375824
INFO:root:current train perplexity7.259982585906982
INFO:root:current mean train loss 2513.86853515625
INFO:root:current train perplexity7.245401859283447
INFO:root:current mean train loss 2512.648288786515
INFO:root:current train perplexity7.2335710525512695
INFO:root:current mean train loss 2509.111566503906
INFO:root:current train perplexity7.214104652404785
INFO:root:current mean train loss 2505.6075659179687
INFO:root:current train perplexity7.197868347167969
INFO:root:current mean train loss 2503.3173438341864
INFO:root:current train perplexity7.1867756843566895
INFO:root:current mean train loss 2500.1022939768145
INFO:root:current train perplexity7.1773576736450195
INFO:root:current mean train loss 2495.5032072679924
INFO:root:current train perplexity7.159599304199219
INFO:root:current mean train loss 2492.4432788085937
INFO:root:current train perplexity7.13913631439209
INFO:root:current mean train loss 2489.795334010769
INFO:root:current train perplexity7.122898578643799
INFO:root:current mean train loss 2486.8711008238183
INFO:root:current train perplexity7.104487419128418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.46s/it]
INFO:root:final mean train loss: 2485.3287532342783
INFO:root:final train perplexity: 7.099893569946289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2303.6732130118294
INFO:root:eval perplexity: 6.443523406982422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.69s/it]
INFO:root:eval mean loss: 2674.8769643797095
INFO:root:eval perplexity: 8.913686752319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/4
  4%|â–         | 4/100 [25:17<10:06:49, 379.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2396.3320913741836
INFO:root:current train perplexity6.686079978942871
INFO:root:current mean train loss 2419.6143915781718
INFO:root:current train perplexity6.719841003417969
INFO:root:current mean train loss 2404.664755603347
INFO:root:current train perplexity6.684942722320557
INFO:root:current mean train loss 2404.1918689197673
INFO:root:current train perplexity6.692264556884766
INFO:root:current mean train loss 2405.092332729691
INFO:root:current train perplexity6.687297821044922
INFO:root:current mean train loss 2406.273800050981
INFO:root:current train perplexity6.6851115226745605
INFO:root:current mean train loss 2406.1662773349653
INFO:root:current train perplexity6.675713539123535
INFO:root:current mean train loss 2407.049553862451
INFO:root:current train perplexity6.6753458976745605
INFO:root:current mean train loss 2407.60575541108
INFO:root:current train perplexity6.669522762298584
INFO:root:current mean train loss 2402.320250896781
INFO:root:current train perplexity6.648195743560791
INFO:root:current mean train loss 2399.510954180273
INFO:root:current train perplexity6.638919353485107
INFO:root:current mean train loss 2398.7317377791614
INFO:root:current train perplexity6.634426593780518
INFO:root:current mean train loss 2397.4138837782716
INFO:root:current train perplexity6.62817907333374
INFO:root:current mean train loss 2399.0216250192884
INFO:root:current train perplexity6.627450466156006
INFO:root:current mean train loss 2397.8914801578744
INFO:root:current train perplexity6.621947765350342
INFO:root:current mean train loss 2394.5201882640495
INFO:root:current train perplexity6.607882499694824
INFO:root:current mean train loss 2392.719601489858
INFO:root:current train perplexity6.599270343780518
INFO:root:current mean train loss 2390.672040247418
INFO:root:current train perplexity6.58838415145874
INFO:root:current mean train loss 2390.1855126142373
INFO:root:current train perplexity6.587242603302002
INFO:root:current mean train loss 2390.024612527604
INFO:root:current train perplexity6.583502292633057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.35s/it]
INFO:root:final mean train loss: 2389.928337185658
INFO:root:final train perplexity: 6.5853095054626465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it]
INFO:root:eval mean loss: 2228.0806114250886
INFO:root:eval perplexity: 6.061399936676025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it]
INFO:root:eval mean loss: 2607.752898520612
INFO:root:eval perplexity: 8.43755054473877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/5
  5%|â–Œ         | 5/100 [31:39<10:02:06, 380.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2382.365949358259
INFO:root:current train perplexity6.478150367736816
INFO:root:current mean train loss 2361.1607971191406
INFO:root:current train perplexity6.397463798522949
INFO:root:current mean train loss 2353.6207352759134
INFO:root:current train perplexity6.388104438781738
INFO:root:current mean train loss 2358.1564947764077
INFO:root:current train perplexity6.397373676300049
INFO:root:current mean train loss 2355.651275382554
INFO:root:current train perplexity6.3826093673706055
INFO:root:current mean train loss 2352.738395168357
INFO:root:current train perplexity6.383488178253174
INFO:root:current mean train loss 2350.848060830992
INFO:root:current train perplexity6.377391338348389
INFO:root:current mean train loss 2349.8409378674564
INFO:root:current train perplexity6.377706050872803
INFO:root:current mean train loss 2349.60636604965
INFO:root:current train perplexity6.3792572021484375
INFO:root:current mean train loss 2350.248811799336
INFO:root:current train perplexity6.374927997589111
INFO:root:current mean train loss 2348.7878982149805
INFO:root:current train perplexity6.367984771728516
INFO:root:current mean train loss 2347.924420949575
INFO:root:current train perplexity6.369156360626221
INFO:root:current mean train loss 2345.7289507619316
INFO:root:current train perplexity6.359195709228516
INFO:root:current mean train loss 2343.9793016731396
INFO:root:current train perplexity6.35049295425415
INFO:root:current mean train loss 2342.8936671336705
INFO:root:current train perplexity6.347777843475342
INFO:root:current mean train loss 2341.0573846836282
INFO:root:current train perplexity6.339396953582764
INFO:root:current mean train loss 2340.8363604692836
INFO:root:current train perplexity6.337564468383789
INFO:root:current mean train loss 2340.3031990496033
INFO:root:current train perplexity6.332696437835693
INFO:root:current mean train loss 2337.2868544787107
INFO:root:current train perplexity6.319653511047363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.98s/it]
INFO:root:final mean train loss: 2337.9084924494928
INFO:root:final train perplexity: 6.320606708526611
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.77s/it]
INFO:root:eval mean loss: 2178.541609960245
INFO:root:eval perplexity: 5.823355197906494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it]
INFO:root:eval mean loss: 2567.3632682637967
INFO:root:eval perplexity: 8.163394927978516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/6
  6%|â–Œ         | 6/100 [37:53<9:52:33, 378.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2362.492431640625
INFO:root:current train perplexity6.619328498840332
INFO:root:current mean train loss 2311.296928179146
INFO:root:current train perplexity6.133859634399414
INFO:root:current mean train loss 2297.6125148184856
INFO:root:current train perplexity6.100461959838867
INFO:root:current mean train loss 2285.575000648879
INFO:root:current train perplexity6.076955318450928
INFO:root:current mean train loss 2293.3573235490376
INFO:root:current train perplexity6.1110429763793945
INFO:root:current mean train loss 2289.2392748682323
INFO:root:current train perplexity6.092494487762451
INFO:root:current mean train loss 2292.706738565607
INFO:root:current train perplexity6.095479488372803
INFO:root:current mean train loss 2294.6814179032745
INFO:root:current train perplexity6.093331336975098
INFO:root:current mean train loss 2294.9302877933346
INFO:root:current train perplexity6.094481468200684
INFO:root:current mean train loss 2296.4570587530784
INFO:root:current train perplexity6.101245880126953
INFO:root:current mean train loss 2293.0506866180694
INFO:root:current train perplexity6.089804172515869
INFO:root:current mean train loss 2290.921165528674
INFO:root:current train perplexity6.082338809967041
INFO:root:current mean train loss 2289.786053532863
INFO:root:current train perplexity6.076314449310303
INFO:root:current mean train loss 2286.7645062879815
INFO:root:current train perplexity6.075169086456299
INFO:root:current mean train loss 2286.7879761526365
INFO:root:current train perplexity6.071038246154785
INFO:root:current mean train loss 2286.575676355737
INFO:root:current train perplexity6.065499305725098
INFO:root:current mean train loss 2285.7054775793204
INFO:root:current train perplexity6.06463098526001
INFO:root:current mean train loss 2285.0289427203898
INFO:root:current train perplexity6.058559417724609
INFO:root:current mean train loss 2282.2321831567097
INFO:root:current train perplexity6.047984600067139
INFO:root:current mean train loss 2281.598770165682
INFO:root:current train perplexity6.044173717498779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.24s/it]
INFO:root:final mean train loss: 2281.412926224224
INFO:root:final train perplexity: 6.045169830322266
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it]
INFO:root:eval mean loss: 2137.6196834483044
INFO:root:eval perplexity: 5.633784294128418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.71s/it]
INFO:root:eval mean loss: 2532.417446704621
INFO:root:eval perplexity: 7.933390140533447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/7
  7%|â–‹         | 7/100 [44:04<9:42:37, 375.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2265.5052829318574
INFO:root:current train perplexity5.899432182312012
INFO:root:current mean train loss 2240.1141119488216
INFO:root:current train perplexity5.842604160308838
INFO:root:current mean train loss 2240.2994446360735
INFO:root:current train perplexity5.8707733154296875
INFO:root:current mean train loss 2238.8517667182587
INFO:root:current train perplexity5.867300510406494
INFO:root:current mean train loss 2240.1684625799007
INFO:root:current train perplexity5.872859954833984
INFO:root:current mean train loss 2237.6888243921935
INFO:root:current train perplexity5.8622612953186035
INFO:root:current mean train loss 2236.541063623521
INFO:root:current train perplexity5.86224365234375
INFO:root:current mean train loss 2238.0942250201297
INFO:root:current train perplexity5.864339828491211
INFO:root:current mean train loss 2239.82248499341
INFO:root:current train perplexity5.8699798583984375
INFO:root:current mean train loss 2237.2733363066363
INFO:root:current train perplexity5.853681564331055
INFO:root:current mean train loss 2237.682217521143
INFO:root:current train perplexity5.850567817687988
INFO:root:current mean train loss 2235.8157858532954
INFO:root:current train perplexity5.846685886383057
INFO:root:current mean train loss 2236.6991346637997
INFO:root:current train perplexity5.843011856079102
INFO:root:current mean train loss 2234.7498647779544
INFO:root:current train perplexity5.841072082519531
INFO:root:current mean train loss 2235.206266545779
INFO:root:current train perplexity5.8356218338012695
INFO:root:current mean train loss 2234.411350576931
INFO:root:current train perplexity5.8334527015686035
INFO:root:current mean train loss 2236.0915340239685
INFO:root:current train perplexity5.834906101226807
INFO:root:current mean train loss 2235.839784206972
INFO:root:current train perplexity5.833377361297607
INFO:root:current mean train loss 2234.6730630033217
INFO:root:current train perplexity5.827523708343506
INFO:root:current mean train loss 2234.0784443048788
INFO:root:current train perplexity5.823537826538086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.73s/it]
INFO:root:final mean train loss: 2234.1474572439956
INFO:root:final train perplexity: 5.823976516723633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2109.7371371654754
INFO:root:eval perplexity: 5.50816535949707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it]
INFO:root:eval mean loss: 2507.2545070783467
INFO:root:eval perplexity: 7.771798133850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/8
  8%|â–Š         | 8/100 [50:26<9:39:13, 377.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2187.1244384765623
INFO:root:current train perplexity5.618077278137207
INFO:root:current mean train loss 2192.4015887225114
INFO:root:current train perplexity5.618296146392822
INFO:root:current mean train loss 2199.865448907081
INFO:root:current train perplexity5.645087718963623
INFO:root:current mean train loss 2205.4652744577893
INFO:root:current train perplexity5.660305976867676
INFO:root:current mean train loss 2205.6289272966055
INFO:root:current train perplexity5.668327808380127
INFO:root:current mean train loss 2206.2839631553006
INFO:root:current train perplexity5.666209697723389
INFO:root:current mean train loss 2208.0355995478594
INFO:root:current train perplexity5.681729793548584
INFO:root:current mean train loss 2207.110549200149
INFO:root:current train perplexity5.676666736602783
INFO:root:current mean train loss 2207.722558886134
INFO:root:current train perplexity5.679354667663574
INFO:root:current mean train loss 2205.559964984751
INFO:root:current train perplexity5.669127464294434
INFO:root:current mean train loss 2201.216196312651
INFO:root:current train perplexity5.656675338745117
INFO:root:current mean train loss 2200.7311914922907
INFO:root:current train perplexity5.660888195037842
INFO:root:current mean train loss 2199.4606022267208
INFO:root:current train perplexity5.6598358154296875
INFO:root:current mean train loss 2199.8808280116164
INFO:root:current train perplexity5.663441181182861
INFO:root:current mean train loss 2198.182861583324
INFO:root:current train perplexity5.656825065612793
INFO:root:current mean train loss 2198.422884962846
INFO:root:current train perplexity5.658483028411865
INFO:root:current mean train loss 2198.176068693855
INFO:root:current train perplexity5.656479835510254
INFO:root:current mean train loss 2196.6415245913636
INFO:root:current train perplexity5.653380393981934
INFO:root:current mean train loss 2195.4874920172
INFO:root:current train perplexity5.649765968322754
INFO:root:current mean train loss 2195.805206251514
INFO:root:current train perplexity5.648643493652344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.06s/it]
INFO:root:final mean train loss: 2195.1369111200083
INFO:root:final train perplexity: 5.647522926330566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it]
INFO:root:eval mean loss: 2081.2408784906916
INFO:root:eval perplexity: 5.3826751708984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it]
INFO:root:eval mean loss: 2485.1554859783632
INFO:root:eval perplexity: 7.632597923278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/9
  9%|â–‰         | 9/100 [56:34<9:28:37, 374.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2147.021202674279
INFO:root:current train perplexity5.491520881652832
INFO:root:current mean train loss 2171.661496614155
INFO:root:current train perplexity5.534872531890869
INFO:root:current mean train loss 2168.435973152282
INFO:root:current train perplexity5.532365798950195
INFO:root:current mean train loss 2165.9965334805574
INFO:root:current train perplexity5.52455472946167
INFO:root:current mean train loss 2162.8866471822284
INFO:root:current train perplexity5.528388977050781
INFO:root:current mean train loss 2165.088307698568
INFO:root:current train perplexity5.533682823181152
INFO:root:current mean train loss 2162.660608584164
INFO:root:current train perplexity5.527877330780029
INFO:root:current mean train loss 2161.622893800127
INFO:root:current train perplexity5.520902156829834
INFO:root:current mean train loss 2163.3949563469687
INFO:root:current train perplexity5.518379211425781
INFO:root:current mean train loss 2165.1844114415785
INFO:root:current train perplexity5.51928186416626
INFO:root:current mean train loss 2164.173586769249
INFO:root:current train perplexity5.517078876495361
INFO:root:current mean train loss 2160.2363279130723
INFO:root:current train perplexity5.510618209838867
INFO:root:current mean train loss 2160.9972490304576
INFO:root:current train perplexity5.51178503036499
INFO:root:current mean train loss 2160.1791166045964
INFO:root:current train perplexity5.5106940269470215
INFO:root:current mean train loss 2160.615483812064
INFO:root:current train perplexity5.50717830657959
INFO:root:current mean train loss 2160.5591191557264
INFO:root:current train perplexity5.500099182128906
INFO:root:current mean train loss 2161.185596013473
INFO:root:current train perplexity5.502111434936523
INFO:root:current mean train loss 2161.06352338399
INFO:root:current train perplexity5.503525733947754
INFO:root:current mean train loss 2161.6481062887037
INFO:root:current train perplexity5.504366874694824
INFO:root:current mean train loss 2162.8660526588314
INFO:root:current train perplexity5.504513740539551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.58s/it]
INFO:root:final mean train loss: 2162.994527519561
INFO:root:final train perplexity: 5.506160259246826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 2069.2171955514464
INFO:root:eval perplexity: 5.330587387084961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it]
INFO:root:eval mean loss: 2476.1108441724846
INFO:root:eval perplexity: 7.576350212097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:02:56<9:25:41, 377.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2154.810734403306
INFO:root:current train perplexity5.405308246612549
INFO:root:current mean train loss 2139.9102320925017
INFO:root:current train perplexity5.374945163726807
INFO:root:current mean train loss 2136.5594545952895
INFO:root:current train perplexity5.361445903778076
INFO:root:current mean train loss 2137.9978222523923
INFO:root:current train perplexity5.382177829742432
INFO:root:current mean train loss 2137.566258672458
INFO:root:current train perplexity5.384956359863281
INFO:root:current mean train loss 2135.5323477746733
INFO:root:current train perplexity5.3877081871032715
INFO:root:current mean train loss 2136.564832108616
INFO:root:current train perplexity5.384707927703857
INFO:root:current mean train loss 2136.194284506055
INFO:root:current train perplexity5.380188465118408
INFO:root:current mean train loss 2137.8918594693973
INFO:root:current train perplexity5.386521339416504
INFO:root:current mean train loss 2137.1964304070725
INFO:root:current train perplexity5.385949611663818
INFO:root:current mean train loss 2136.2981507432473
INFO:root:current train perplexity5.385128498077393
INFO:root:current mean train loss 2137.0532768517096
INFO:root:current train perplexity5.384341239929199
INFO:root:current mean train loss 2136.603427799787
INFO:root:current train perplexity5.385067462921143
INFO:root:current mean train loss 2136.781899406929
INFO:root:current train perplexity5.387243747711182
INFO:root:current mean train loss 2137.2611091463154
INFO:root:current train perplexity5.387535095214844
INFO:root:current mean train loss 2136.0799105409
INFO:root:current train perplexity5.386238098144531
INFO:root:current mean train loss 2135.970670797212
INFO:root:current train perplexity5.384481430053711
INFO:root:current mean train loss 2135.6439350445166
INFO:root:current train perplexity5.385980129241943
INFO:root:current mean train loss 2135.0727808152756
INFO:root:current train perplexity5.383841514587402
INFO:root:current mean train loss 2135.141664240553
INFO:root:current train perplexity5.383164405822754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.11s/it]
INFO:root:final mean train loss: 2134.5948932626543
INFO:root:final train perplexity: 5.384207725524902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 2036.9391860420822
INFO:root:eval perplexity: 5.193235397338867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 2446.0701441122287
INFO:root:eval perplexity: 7.39247989654541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:09:12<9:18:28, 376.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2113.6406633244005
INFO:root:current train perplexity5.32370138168335
INFO:root:current mean train loss 2114.4172671738493
INFO:root:current train perplexity5.326145648956299
INFO:root:current mean train loss 2115.0231434215198
INFO:root:current train perplexity5.305088520050049
INFO:root:current mean train loss 2113.5615234375
INFO:root:current train perplexity5.310203552246094
INFO:root:current mean train loss 2115.925136236497
INFO:root:current train perplexity5.316915512084961
INFO:root:current mean train loss 2112.5271410632868
INFO:root:current train perplexity5.302768230438232
INFO:root:current mean train loss 2109.857244285828
INFO:root:current train perplexity5.292938232421875
INFO:root:current mean train loss 2108.5451139882016
INFO:root:current train perplexity5.290455341339111
INFO:root:current mean train loss 2110.7936134080046
INFO:root:current train perplexity5.288950443267822
INFO:root:current mean train loss 2108.789708630792
INFO:root:current train perplexity5.284762859344482
INFO:root:current mean train loss 2110.4963230533494
INFO:root:current train perplexity5.28244686126709
INFO:root:current mean train loss 2110.5349022284727
INFO:root:current train perplexity5.281811714172363
INFO:root:current mean train loss 2109.699530950045
INFO:root:current train perplexity5.280879497528076
INFO:root:current mean train loss 2110.9470161999457
INFO:root:current train perplexity5.285671710968018
INFO:root:current mean train loss 2111.9485837543634
INFO:root:current train perplexity5.2871270179748535
INFO:root:current mean train loss 2112.0791466654023
INFO:root:current train perplexity5.289619445800781
INFO:root:current mean train loss 2111.0917808016848
INFO:root:current train perplexity5.2862420082092285
INFO:root:current mean train loss 2110.552414641001
INFO:root:current train perplexity5.281838893890381
INFO:root:current mean train loss 2110.101884504138
INFO:root:current train perplexity5.280651092529297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.83s/it]
INFO:root:final mean train loss: 2109.208679414673
INFO:root:final train perplexity: 5.277480602264404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.39s/it]
INFO:root:eval mean loss: 2030.3947026678857
INFO:root:eval perplexity: 5.165820121765137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it]
INFO:root:eval mean loss: 2444.456414838209
INFO:root:eval perplexity: 7.382730960845947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:15:34<9:14:39, 378.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2108.5179036458335
INFO:root:current train perplexity5.24919319152832
INFO:root:current mean train loss 2096.9801712776853
INFO:root:current train perplexity5.2718119621276855
INFO:root:current mean train loss 2082.6870640345983
INFO:root:current train perplexity5.197397232055664
INFO:root:current mean train loss 2086.569720680564
INFO:root:current train perplexity5.216327667236328
INFO:root:current mean train loss 2081.7608263948123
INFO:root:current train perplexity5.188169479370117
INFO:root:current mean train loss 2082.786178679874
INFO:root:current train perplexity5.186074733734131
INFO:root:current mean train loss 2084.287809609181
INFO:root:current train perplexity5.186232566833496
INFO:root:current mean train loss 2081.6044588482396
INFO:root:current train perplexity5.178945064544678
INFO:root:current mean train loss 2087.5443746108344
INFO:root:current train perplexity5.1903815269470215
INFO:root:current mean train loss 2084.399454482238
INFO:root:current train perplexity5.179908752441406
INFO:root:current mean train loss 2084.267613906328
INFO:root:current train perplexity5.17994499206543
INFO:root:current mean train loss 2085.674642000864
INFO:root:current train perplexity5.178675651550293
INFO:root:current mean train loss 2086.9207756568862
INFO:root:current train perplexity5.182410717010498
INFO:root:current mean train loss 2083.777110008304
INFO:root:current train perplexity5.178017616271973
INFO:root:current mean train loss 2084.608784224931
INFO:root:current train perplexity5.1808552742004395
INFO:root:current mean train loss 2084.854932875135
INFO:root:current train perplexity5.1813530921936035
INFO:root:current mean train loss 2084.2937357445026
INFO:root:current train perplexity5.178537845611572
INFO:root:current mean train loss 2085.1775087277047
INFO:root:current train perplexity5.180293560028076
INFO:root:current mean train loss 2085.23971156471
INFO:root:current train perplexity5.181178569793701
INFO:root:current mean train loss 2085.78538217309
INFO:root:current train perplexity5.182584285736084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.39s/it]
INFO:root:final mean train loss: 2086.975907641712
INFO:root:final train perplexity: 5.185750961303711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 2023.2690827931074
INFO:root:eval perplexity: 5.136137008666992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 2438.2765857885915
INFO:root:eval perplexity: 7.345510959625244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:22:13<9:17:31, 384.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2113.6658569335937
INFO:root:current train perplexity5.208386421203613
INFO:root:current mean train loss 2074.0003712972007
INFO:root:current train perplexity5.139352798461914
INFO:root:current mean train loss 2080.580696799538
INFO:root:current train perplexity5.130141735076904
INFO:root:current mean train loss 2075.533144760132
INFO:root:current train perplexity5.112725257873535
INFO:root:current mean train loss 2070.0497105189734
INFO:root:current train perplexity5.107481479644775
INFO:root:current mean train loss 2068.2881450946516
INFO:root:current train perplexity5.112945079803467
INFO:root:current mean train loss 2065.1165436775455
INFO:root:current train perplexity5.102480888366699
INFO:root:current mean train loss 2064.9694686889648
INFO:root:current train perplexity5.100855350494385
INFO:root:current mean train loss 2068.4779171827363
INFO:root:current train perplexity5.109405994415283
INFO:root:current mean train loss 2069.4835010030997
INFO:root:current train perplexity5.114440441131592
INFO:root:current mean train loss 2070.1779231052774
INFO:root:current train perplexity5.119292259216309
INFO:root:current mean train loss 2069.9973300388883
INFO:root:current train perplexity5.120189666748047
INFO:root:current mean train loss 2069.0724616379034
INFO:root:current train perplexity5.116608619689941
INFO:root:current mean train loss 2067.9561248779296
INFO:root:current train perplexity5.116097927093506
INFO:root:current mean train loss 2067.6368719396455
INFO:root:current train perplexity5.114148139953613
INFO:root:current mean train loss 2067.008302387438
INFO:root:current train perplexity5.113640785217285
INFO:root:current mean train loss 2067.9313385386527
INFO:root:current train perplexity5.111041069030762
INFO:root:current mean train loss 2067.398647361578
INFO:root:current train perplexity5.107705116271973
INFO:root:current mean train loss 2067.7419907789963
INFO:root:current train perplexity5.106680393218994
INFO:root:current mean train loss 2067.531406466166
INFO:root:current train perplexity5.103784084320068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.21s/it]
INFO:root:final mean train loss: 2067.0032810628622
INFO:root:final train perplexity: 5.104707717895508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.08s/it]
INFO:root:eval mean loss: 2001.6214829032303
INFO:root:eval perplexity: 5.046999931335449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it]
INFO:root:eval mean loss: 2421.0763844158632
INFO:root:eval perplexity: 7.2429070472717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [1:28:42<9:13:21, 386.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2060.2228838946367
INFO:root:current train perplexity5.023616790771484
INFO:root:current mean train loss 2055.061925289405
INFO:root:current train perplexity5.03925085067749
INFO:root:current mean train loss 2050.7331269984506
INFO:root:current train perplexity5.041432857513428
INFO:root:current mean train loss 2046.1575029412788
INFO:root:current train perplexity5.029602527618408
INFO:root:current mean train loss 2054.198182409361
INFO:root:current train perplexity5.051485061645508
INFO:root:current mean train loss 2051.9560096783343
INFO:root:current train perplexity5.0454535484313965
INFO:root:current mean train loss 2053.685510464703
INFO:root:current train perplexity5.047839164733887
INFO:root:current mean train loss 2049.705812700083
INFO:root:current train perplexity5.04286527633667
INFO:root:current mean train loss 2045.9457303392417
INFO:root:current train perplexity5.028873920440674
INFO:root:current mean train loss 2047.6325709649313
INFO:root:current train perplexity5.031097412109375
INFO:root:current mean train loss 2048.975920129995
INFO:root:current train perplexity5.0326032638549805
INFO:root:current mean train loss 2049.714435667979
INFO:root:current train perplexity5.03278112411499
INFO:root:current mean train loss 2049.1296787369897
INFO:root:current train perplexity5.033810138702393
INFO:root:current mean train loss 2049.4499126425767
INFO:root:current train perplexity5.0316596031188965
INFO:root:current mean train loss 2051.0163852848273
INFO:root:current train perplexity5.036864280700684
INFO:root:current mean train loss 2052.6148873839816
INFO:root:current train perplexity5.039688587188721
INFO:root:current mean train loss 2050.9904839592004
INFO:root:current train perplexity5.0361199378967285
INFO:root:current mean train loss 2052.782342307926
INFO:root:current train perplexity5.044393062591553
INFO:root:current mean train loss 2052.7428158597577
INFO:root:current train perplexity5.043642520904541
INFO:root:current mean train loss 2052.4745178695307
INFO:root:current train perplexity5.044167518615723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.49s/it]
INFO:root:final mean train loss: 2051.232396605276
INFO:root:final train perplexity: 5.041609287261963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it]
INFO:root:eval mean loss: 1986.9617244639296
INFO:root:eval perplexity: 4.987515449523926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it]
INFO:root:eval mean loss: 2408.4540119576964
INFO:root:eval perplexity: 7.168523788452148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [1:35:20<9:11:44, 389.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2024.6773613823784
INFO:root:current train perplexity4.931894779205322
INFO:root:current mean train loss 2045.2678214729606
INFO:root:current train perplexity4.957103729248047
INFO:root:current mean train loss 2043.95844755398
INFO:root:current train perplexity4.966737270355225
INFO:root:current mean train loss 2045.891005693856
INFO:root:current train perplexity4.984833717346191
INFO:root:current mean train loss 2043.186302958081
INFO:root:current train perplexity4.983839988708496
INFO:root:current mean train loss 2041.2431336550937
INFO:root:current train perplexity4.979987621307373
INFO:root:current mean train loss 2039.7896291750287
INFO:root:current train perplexity4.987787246704102
INFO:root:current mean train loss 2041.386393822789
INFO:root:current train perplexity4.990596294403076
INFO:root:current mean train loss 2040.4812291880123
INFO:root:current train perplexity4.988207817077637
INFO:root:current mean train loss 2039.4034358570411
INFO:root:current train perplexity4.984434127807617
INFO:root:current mean train loss 2037.1691920010821
INFO:root:current train perplexity4.980330467224121
INFO:root:current mean train loss 2038.3238032455047
INFO:root:current train perplexity4.981789588928223
INFO:root:current mean train loss 2037.7693903921513
INFO:root:current train perplexity4.9814982414245605
INFO:root:current mean train loss 2038.8840262611648
INFO:root:current train perplexity4.983810901641846
INFO:root:current mean train loss 2039.9563494528832
INFO:root:current train perplexity4.989355564117432
INFO:root:current mean train loss 2040.7416176028846
INFO:root:current train perplexity4.992486000061035
INFO:root:current mean train loss 2038.9102175065655
INFO:root:current train perplexity4.98915958404541
INFO:root:current mean train loss 2038.9710235421715
INFO:root:current train perplexity4.989520072937012
INFO:root:current mean train loss 2039.0090201664898
INFO:root:current train perplexity4.988468647003174
INFO:root:current mean train loss 2037.6311221947567
INFO:root:current train perplexity4.985340595245361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.75s/it]
INFO:root:final mean train loss: 2036.656469548043
INFO:root:final train perplexity: 4.98398494720459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it]
INFO:root:eval mean loss: 1986.2044959102116
INFO:root:eval perplexity: 4.984462738037109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 2408.0612277849345
INFO:root:eval perplexity: 7.166222095489502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [1:41:58<9:09:10, 392.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2012.0884476782571
INFO:root:current train perplexity4.850009441375732
INFO:root:current mean train loss 2034.3972217939054
INFO:root:current train perplexity4.937857151031494
INFO:root:current mean train loss 2024.14068986393
INFO:root:current train perplexity4.904744625091553
INFO:root:current mean train loss 2032.8908326182404
INFO:root:current train perplexity4.941221714019775
INFO:root:current mean train loss 2031.1496727167928
INFO:root:current train perplexity4.933157444000244
INFO:root:current mean train loss 2025.2407592132088
INFO:root:current train perplexity4.922142028808594
INFO:root:current mean train loss 2022.5179910901406
INFO:root:current train perplexity4.917595386505127
INFO:root:current mean train loss 2021.341291177752
INFO:root:current train perplexity4.91635274887085
INFO:root:current mean train loss 2017.9309545926467
INFO:root:current train perplexity4.916078090667725
INFO:root:current mean train loss 2017.2764077937934
INFO:root:current train perplexity4.910539150238037
INFO:root:current mean train loss 2016.4632103329614
INFO:root:current train perplexity4.910908222198486
INFO:root:current mean train loss 2017.0113800596112
INFO:root:current train perplexity4.910632610321045
INFO:root:current mean train loss 2016.5249563197654
INFO:root:current train perplexity4.909942626953125
INFO:root:current mean train loss 2016.8217467148752
INFO:root:current train perplexity4.911362171173096
INFO:root:current mean train loss 2015.3795610812956
INFO:root:current train perplexity4.9089274406433105
INFO:root:current mean train loss 2016.2291123786601
INFO:root:current train perplexity4.912598609924316
INFO:root:current mean train loss 2019.1280430645945
INFO:root:current train perplexity4.918312072753906
INFO:root:current mean train loss 2019.8600269147462
INFO:root:current train perplexity4.919479846954346
INFO:root:current mean train loss 2020.4660153248806
INFO:root:current train perplexity4.920839786529541
INFO:root:current mean train loss 2022.0374964574216
INFO:root:current train perplexity4.92519998550415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.30s/it]
INFO:root:final mean train loss: 2021.7877242203258
INFO:root:final train perplexity: 4.925882339477539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 1970.8732092025432
INFO:root:eval perplexity: 4.923041820526123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it]
INFO:root:eval mean loss: 2394.014551040974
INFO:root:eval perplexity: 7.084368705749512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [1:48:24<9:00:01, 390.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2009.1894350918856
INFO:root:current train perplexity4.912137985229492
INFO:root:current mean train loss 1998.754901642495
INFO:root:current train perplexity4.848885536193848
INFO:root:current mean train loss 2003.8282788594563
INFO:root:current train perplexity4.847759246826172
INFO:root:current mean train loss 2006.126866606093
INFO:root:current train perplexity4.851172924041748
INFO:root:current mean train loss 2010.1674106785508
INFO:root:current train perplexity4.867195129394531
INFO:root:current mean train loss 2007.6572118227173
INFO:root:current train perplexity4.864076614379883
INFO:root:current mean train loss 2008.4234698983125
INFO:root:current train perplexity4.867032051086426
INFO:root:current mean train loss 2012.1018603949378
INFO:root:current train perplexity4.876389026641846
INFO:root:current mean train loss 2012.2480210312851
INFO:root:current train perplexity4.883003234863281
INFO:root:current mean train loss 2009.378239928952
INFO:root:current train perplexity4.877930641174316
INFO:root:current mean train loss 2011.1267410727107
INFO:root:current train perplexity4.887387275695801
INFO:root:current mean train loss 2011.607803396103
INFO:root:current train perplexity4.883938789367676
INFO:root:current mean train loss 2014.1923212086933
INFO:root:current train perplexity4.885781764984131
INFO:root:current mean train loss 2012.9334303446394
INFO:root:current train perplexity4.88632869720459
INFO:root:current mean train loss 2012.3619150141235
INFO:root:current train perplexity4.885295391082764
INFO:root:current mean train loss 2010.6098721213546
INFO:root:current train perplexity4.881213665008545
INFO:root:current mean train loss 2011.964519193387
INFO:root:current train perplexity4.88425874710083
INFO:root:current mean train loss 2011.199312487438
INFO:root:current train perplexity4.883840560913086
INFO:root:current mean train loss 2009.7528998811367
INFO:root:current train perplexity4.878834247589111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it]
INFO:root:final mean train loss: 2010.1511276329759
INFO:root:final train perplexity: 4.880882740020752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it]
INFO:root:eval mean loss: 1969.5578647911125
INFO:root:eval perplexity: 4.917806625366211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 2396.446181709885
INFO:root:eval perplexity: 7.098471641540527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [1:54:55<8:53:37, 390.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1952.9140869140624
INFO:root:current train perplexity4.863796234130859
INFO:root:current mean train loss 1968.472265625
INFO:root:current train perplexity4.757159233093262
INFO:root:current mean train loss 1978.6925358469894
INFO:root:current train perplexity4.78532600402832
INFO:root:current mean train loss 1989.0594610495646
INFO:root:current train perplexity4.81591796875
INFO:root:current mean train loss 1988.6665180724344
INFO:root:current train perplexity4.812480926513672
INFO:root:current mean train loss 1988.3160721882734
INFO:root:current train perplexity4.807555675506592
INFO:root:current mean train loss 1989.591489177105
INFO:root:current train perplexity4.813665390014648
INFO:root:current mean train loss 1993.9482259114584
INFO:root:current train perplexity4.8277788162231445
INFO:root:current mean train loss 1992.2832599900523
INFO:root:current train perplexity4.822464466094971
INFO:root:current mean train loss 1992.4834866518474
INFO:root:current train perplexity4.821030139923096
INFO:root:current mean train loss 1992.7108795621502
INFO:root:current train perplexity4.823700428009033
INFO:root:current mean train loss 1993.4963314833144
INFO:root:current train perplexity4.823007583618164
INFO:root:current mean train loss 1996.706061474812
INFO:root:current train perplexity4.833295822143555
INFO:root:current mean train loss 1997.1919143618295
INFO:root:current train perplexity4.8344831466674805
INFO:root:current mean train loss 1997.0446518433052
INFO:root:current train perplexity4.833589553833008
INFO:root:current mean train loss 1997.8974550975913
INFO:root:current train perplexity4.833713531494141
INFO:root:current mean train loss 1999.555675014603
INFO:root:current train perplexity4.835568904876709
INFO:root:current mean train loss 1998.8297401942816
INFO:root:current train perplexity4.836175918579102
INFO:root:current mean train loss 1999.1456932511687
INFO:root:current train perplexity4.836958885192871
INFO:root:current mean train loss 1998.610880085302
INFO:root:current train perplexity4.836093425750732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.29s/it]
INFO:root:final mean train loss: 1997.7692648560123
INFO:root:final train perplexity: 4.8334527015686035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 1955.1178714400487
INFO:root:eval perplexity: 4.860710620880127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2382.2924393457724
INFO:root:eval perplexity: 7.016778945922852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:01:33<8:50:00, 392.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2034.1238625266335
INFO:root:current train perplexity4.940375328063965
INFO:root:current mean train loss 1989.8202934890496
INFO:root:current train perplexity4.803136825561523
INFO:root:current mean train loss 1986.001857998135
INFO:root:current train perplexity4.78888463973999
INFO:root:current mean train loss 1987.2074539468895
INFO:root:current train perplexity4.78790807723999
INFO:root:current mean train loss 1992.9127555955642
INFO:root:current train perplexity4.7994279861450195
INFO:root:current mean train loss 1992.2256663823036
INFO:root:current train perplexity4.800087928771973
INFO:root:current mean train loss 1989.472609148915
INFO:root:current train perplexity4.794000148773193
INFO:root:current mean train loss 1986.226985012065
INFO:root:current train perplexity4.784887313842773
INFO:root:current mean train loss 1985.6434719707554
INFO:root:current train perplexity4.780986309051514
INFO:root:current mean train loss 1987.3635754368051
INFO:root:current train perplexity4.786386489868164
INFO:root:current mean train loss 1986.6642172975783
INFO:root:current train perplexity4.7871198654174805
INFO:root:current mean train loss 1986.8993039598652
INFO:root:current train perplexity4.791433811187744
INFO:root:current mean train loss 1986.3838146353314
INFO:root:current train perplexity4.789526462554932
INFO:root:current mean train loss 1985.915899279619
INFO:root:current train perplexity4.789425849914551
INFO:root:current mean train loss 1986.9811170446553
INFO:root:current train perplexity4.794874668121338
INFO:root:current mean train loss 1987.5583119135492
INFO:root:current train perplexity4.7983317375183105
INFO:root:current mean train loss 1988.81970974961
INFO:root:current train perplexity4.798288822174072
INFO:root:current mean train loss 1989.559088765675
INFO:root:current train perplexity4.797816753387451
INFO:root:current mean train loss 1988.092111095508
INFO:root:current train perplexity4.795800685882568
INFO:root:current mean train loss 1986.981293518511
INFO:root:current train perplexity4.792847633361816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.33s/it]
INFO:root:final mean train loss: 1987.592918807668
INFO:root:final train perplexity: 4.794815540313721
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it]
INFO:root:eval mean loss: 1957.611159304355
INFO:root:eval perplexity: 4.870521068572998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2387.306868316434
INFO:root:eval perplexity: 7.045615196228027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:08:02<8:42:02, 391.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1956.3792349008413
INFO:root:current train perplexity4.742565155029297
INFO:root:current mean train loss 1967.1897780603642
INFO:root:current train perplexity4.729368686676025
INFO:root:current mean train loss 1971.9836512609506
INFO:root:current train perplexity4.756659507751465
INFO:root:current mean train loss 1977.3570967142562
INFO:root:current train perplexity4.75521183013916
INFO:root:current mean train loss 1981.3112495439743
INFO:root:current train perplexity4.764932632446289
INFO:root:current mean train loss 1980.428303734491
INFO:root:current train perplexity4.7574262619018555
INFO:root:current mean train loss 1975.4930593762226
INFO:root:current train perplexity4.751306056976318
INFO:root:current mean train loss 1978.2102338199848
INFO:root:current train perplexity4.753359317779541
INFO:root:current mean train loss 1979.3239554040338
INFO:root:current train perplexity4.757518291473389
INFO:root:current mean train loss 1980.1202224877695
INFO:root:current train perplexity4.759382247924805
INFO:root:current mean train loss 1980.4861708082065
INFO:root:current train perplexity4.760930061340332
INFO:root:current mean train loss 1980.6403796804693
INFO:root:current train perplexity4.760944843292236
INFO:root:current mean train loss 1980.5664002400815
INFO:root:current train perplexity4.761619567871094
INFO:root:current mean train loss 1978.9011193090985
INFO:root:current train perplexity4.756819248199463
INFO:root:current mean train loss 1978.632061245874
INFO:root:current train perplexity4.758406639099121
INFO:root:current mean train loss 1977.5231040473725
INFO:root:current train perplexity4.756272315979004
INFO:root:current mean train loss 1976.889900696285
INFO:root:current train perplexity4.755516529083252
INFO:root:current mean train loss 1977.3853605335098
INFO:root:current train perplexity4.75886344909668
INFO:root:current mean train loss 1978.0936785102085
INFO:root:current train perplexity4.758493423461914
INFO:root:current mean train loss 1979.0638377999694
INFO:root:current train perplexity4.759119510650635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.94s/it]
INFO:root:final mean train loss: 1978.1145557859481
INFO:root:final train perplexity: 4.75910758972168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 1958.5031972032912
INFO:root:eval perplexity: 4.874035835266113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 2388.7918644898327
INFO:root:eval perplexity: 7.054174900054932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [2:14:50<8:42:07, 396.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.911597115653
INFO:root:current train perplexity4.764438629150391
INFO:root:current mean train loss 1988.643316806891
INFO:root:current train perplexity4.76096248626709
INFO:root:current mean train loss 1973.7994475364685
INFO:root:current train perplexity4.729091644287109
INFO:root:current mean train loss 1977.0335837374912
INFO:root:current train perplexity4.74462366104126
INFO:root:current mean train loss 1976.3994871440686
INFO:root:current train perplexity4.744897365570068
INFO:root:current mean train loss 1973.255539489307
INFO:root:current train perplexity4.736327171325684
INFO:root:current mean train loss 1972.1897994250785
INFO:root:current train perplexity4.733272075653076
INFO:root:current mean train loss 1973.4393047352946
INFO:root:current train perplexity4.733676910400391
INFO:root:current mean train loss 1976.9883271689728
INFO:root:current train perplexity4.741374492645264
INFO:root:current mean train loss 1974.9593555657934
INFO:root:current train perplexity4.735876560211182
INFO:root:current mean train loss 1976.6134413516884
INFO:root:current train perplexity4.738773822784424
INFO:root:current mean train loss 1973.5629398121553
INFO:root:current train perplexity4.733703136444092
INFO:root:current mean train loss 1972.6061697795892
INFO:root:current train perplexity4.731788158416748
INFO:root:current mean train loss 1971.7472339731403
INFO:root:current train perplexity4.733906269073486
INFO:root:current mean train loss 1971.6151990785704
INFO:root:current train perplexity4.7328267097473145
INFO:root:current mean train loss 1971.9543311896239
INFO:root:current train perplexity4.730973243713379
INFO:root:current mean train loss 1972.7120925977035
INFO:root:current train perplexity4.734302520751953
INFO:root:current mean train loss 1971.3396890766257
INFO:root:current train perplexity4.730306148529053
INFO:root:current mean train loss 1971.5694099294728
INFO:root:current train perplexity4.732048511505127
INFO:root:current mean train loss 1970.8423126782377
INFO:root:current train perplexity4.729092597961426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it]
INFO:root:final mean train loss: 1970.1523017979487
INFO:root:final train perplexity: 4.729316234588623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it]
INFO:root:eval mean loss: 1939.8730087821366
INFO:root:eval perplexity: 4.801150321960449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it]
INFO:root:eval mean loss: 2372.2613573006706
INFO:root:eval perplexity: 6.959449768066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:21:17<8:32:00, 393.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1966.4517437660531
INFO:root:current train perplexity4.686666011810303
INFO:root:current mean train loss 1963.870753646586
INFO:root:current train perplexity4.678006172180176
INFO:root:current mean train loss 1961.5570654118017
INFO:root:current train perplexity4.666131019592285
INFO:root:current mean train loss 1958.5251091760222
INFO:root:current train perplexity4.6604766845703125
INFO:root:current mean train loss 1963.8471486129922
INFO:root:current train perplexity4.6713738441467285
INFO:root:current mean train loss 1965.0738853467906
INFO:root:current train perplexity4.690162658691406
INFO:root:current mean train loss 1959.5735897160569
INFO:root:current train perplexity4.679467678070068
INFO:root:current mean train loss 1957.1109391739267
INFO:root:current train perplexity4.675824165344238
INFO:root:current mean train loss 1958.6956545206006
INFO:root:current train perplexity4.680043697357178
INFO:root:current mean train loss 1962.0092536322504
INFO:root:current train perplexity4.684342384338379
INFO:root:current mean train loss 1964.3266508274842
INFO:root:current train perplexity4.6905412673950195
INFO:root:current mean train loss 2102.8067849655995
INFO:root:current train perplexity5.231739521026611
INFO:root:current mean train loss 2113.3025224540334
INFO:root:current train perplexity5.278599262237549
INFO:root:current mean train loss 2117.5720610483145
INFO:root:current train perplexity5.29895544052124
INFO:root:current mean train loss 2118.1323745219947
INFO:root:current train perplexity5.305936813354492
INFO:root:current mean train loss 2117.859865764562
INFO:root:current train perplexity5.30437707901001
INFO:root:current mean train loss 2117.532303175667
INFO:root:current train perplexity5.303715229034424
INFO:root:current mean train loss 2115.310403874414
INFO:root:current train perplexity5.297924995422363
INFO:root:current mean train loss 2114.2950571755705
INFO:root:current train perplexity5.293394088745117
INFO:root:current mean train loss 2112.44857684453
INFO:root:current train perplexity5.288662910461426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.37s/it]
INFO:root:final mean train loss: 2111.9083111292175
INFO:root:final train perplexity: 5.288729190826416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it]
INFO:root:eval mean loss: 1992.8937057603337
INFO:root:eval perplexity: 5.011500358581543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it]
INFO:root:eval mean loss: 2423.093648707613
INFO:root:eval perplexity: 7.254866600036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:27:47<8:23:40, 392.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2074.6249891493057
INFO:root:current train perplexity5.162038326263428
INFO:root:current mean train loss 2085.5605751439143
INFO:root:current train perplexity5.169941425323486
INFO:root:current mean train loss 2078.1841944201237
INFO:root:current train perplexity5.144903659820557
INFO:root:current mean train loss 2075.8062744140625
INFO:root:current train perplexity5.144725799560547
INFO:root:current mean train loss 2084.052107830437
INFO:root:current train perplexity5.158880233764648
INFO:root:current mean train loss 2079.7075211864408
INFO:root:current train perplexity5.145003795623779
INFO:root:current mean train loss 2082.7588499207427
INFO:root:current train perplexity5.147220134735107
INFO:root:current mean train loss 2082.127163889438
INFO:root:current train perplexity5.147224426269531
INFO:root:current mean train loss 2078.7773017797576
INFO:root:current train perplexity5.139514446258545
INFO:root:current mean train loss 2076.080186878551
INFO:root:current train perplexity5.129852294921875
INFO:root:current mean train loss 2073.6635327820386
INFO:root:current train perplexity5.120855331420898
INFO:root:current mean train loss 2072.712926220293
INFO:root:current train perplexity5.115878582000732
INFO:root:current mean train loss 2072.170481695131
INFO:root:current train perplexity5.112707138061523
INFO:root:current mean train loss 2072.0629859979204
INFO:root:current train perplexity5.1108245849609375
INFO:root:current mean train loss 2070.684390320234
INFO:root:current train perplexity5.107443332672119
INFO:root:current mean train loss 2069.60323401877
INFO:root:current train perplexity5.106156826019287
INFO:root:current mean train loss 2069.209771403476
INFO:root:current train perplexity5.1064863204956055
INFO:root:current mean train loss 2067.572174515538
INFO:root:current train perplexity5.103823184967041
INFO:root:current mean train loss 2067.2943217928446
INFO:root:current train perplexity5.103158473968506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.62s/it]
INFO:root:final mean train loss: 2065.697292279788
INFO:root:final train perplexity: 5.099452018737793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 1982.252432748781
INFO:root:eval perplexity: 4.968556880950928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.37s/it]
INFO:root:eval mean loss: 2415.62461084677
INFO:root:eval perplexity: 7.210686206817627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:34:13<8:14:47, 390.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1986.5849434988838
INFO:root:current train perplexity4.9207282066345215
INFO:root:current mean train loss 2050.560840071919
INFO:root:current train perplexity4.9738922119140625
INFO:root:current mean train loss 2059.667297658137
INFO:root:current train perplexity5.026796817779541
INFO:root:current mean train loss 2058.581424477046
INFO:root:current train perplexity5.029666423797607
INFO:root:current mean train loss 2051.570895258273
INFO:root:current train perplexity5.024784564971924
INFO:root:current mean train loss 2045.2856279181306
INFO:root:current train perplexity5.008224964141846
INFO:root:current mean train loss 2041.6332871061572
INFO:root:current train perplexity5.012330055236816
INFO:root:current mean train loss 2041.428559342402
INFO:root:current train perplexity5.012476444244385
INFO:root:current mean train loss 2041.2803183630053
INFO:root:current train perplexity5.014792442321777
INFO:root:current mean train loss 2044.9935707840925
INFO:root:current train perplexity5.020699501037598
INFO:root:current mean train loss 2045.6459871233396
INFO:root:current train perplexity5.021907806396484
INFO:root:current mean train loss 2045.061713765738
INFO:root:current train perplexity5.0200324058532715
INFO:root:current mean train loss 2045.4232748137492
INFO:root:current train perplexity5.019075870513916
INFO:root:current mean train loss 2046.0383572567484
INFO:root:current train perplexity5.016726493835449
INFO:root:current mean train loss 2045.6526336995269
INFO:root:current train perplexity5.014232635498047
INFO:root:current mean train loss 2045.8585343591883
INFO:root:current train perplexity5.013589382171631
INFO:root:current mean train loss 2046.143193869837
INFO:root:current train perplexity5.0115814208984375
INFO:root:current mean train loss 2045.59362893085
INFO:root:current train perplexity5.011195659637451
INFO:root:current mean train loss 2044.67602383688
INFO:root:current train perplexity5.010807514190674
INFO:root:current mean train loss 2044.6980866390682
INFO:root:current train perplexity5.013933181762695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it]
INFO:root:final mean train loss: 2043.5969168720255
INFO:root:final train perplexity: 5.011340141296387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 1978.6987529781693
INFO:root:eval perplexity: 4.9542975425720215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 2413.944967932735
INFO:root:eval perplexity: 7.200788974761963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:40:47<8:09:36, 391.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2035.6090189615886
INFO:root:current train perplexity4.988387107849121
INFO:root:current mean train loss 2039.143033919796
INFO:root:current train perplexity4.996001243591309
INFO:root:current mean train loss 2037.5741010393415
INFO:root:current train perplexity4.972716331481934
INFO:root:current mean train loss 2033.5031323845003
INFO:root:current train perplexity4.966205596923828
INFO:root:current mean train loss 2035.1110888787036
INFO:root:current train perplexity4.967679023742676
INFO:root:current mean train loss 2039.0795416213175
INFO:root:current train perplexity4.970684051513672
INFO:root:current mean train loss 2039.361808189979
INFO:root:current train perplexity4.971494674682617
INFO:root:current mean train loss 2037.5551658335312
INFO:root:current train perplexity4.967111110687256
INFO:root:current mean train loss 2033.8879231573308
INFO:root:current train perplexity4.964686870574951
INFO:root:current mean train loss 2033.011476062593
INFO:root:current train perplexity4.966404914855957
INFO:root:current mean train loss 2031.9106622934341
INFO:root:current train perplexity4.962497711181641
INFO:root:current mean train loss 2032.34085962696
INFO:root:current train perplexity4.961699485778809
INFO:root:current mean train loss 2033.3822689679714
INFO:root:current train perplexity4.962535381317139
INFO:root:current mean train loss 2031.3897889474367
INFO:root:current train perplexity4.9592790603637695
INFO:root:current mean train loss 2031.433508026466
INFO:root:current train perplexity4.9609880447387695
INFO:root:current mean train loss 2031.7205341168901
INFO:root:current train perplexity4.960521697998047
INFO:root:current mean train loss 2031.4183271436268
INFO:root:current train perplexity4.958514213562012
INFO:root:current mean train loss 2030.8577354767483
INFO:root:current train perplexity4.958860874176025
INFO:root:current mean train loss 2030.5338253222014
INFO:root:current train perplexity4.960716724395752
INFO:root:current mean train loss 2032.308142457831
INFO:root:current train perplexity4.965253829956055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.78s/it]
INFO:root:final mean train loss: 2031.4555204221233
INFO:root:final train perplexity: 4.9635844230651855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 1978.3853824696641
INFO:root:eval perplexity: 4.953042030334473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it]
INFO:root:eval mean loss: 2412.975499795684
INFO:root:eval perplexity: 7.1950812339782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:47:15<8:01:35, 390.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2001.4602259193978
INFO:root:current train perplexity4.877915382385254
INFO:root:current mean train loss 2023.420939993351
INFO:root:current train perplexity4.907290458679199
INFO:root:current mean train loss 2018.0521265560167
INFO:root:current train perplexity4.894537925720215
INFO:root:current mean train loss 2016.9935907716276
INFO:root:current train perplexity4.905828952789307
INFO:root:current mean train loss 2013.6569887883538
INFO:root:current train perplexity4.903594017028809
INFO:root:current mean train loss 2017.8179324673638
INFO:root:current train perplexity4.90794038772583
INFO:root:current mean train loss 2018.6987243747562
INFO:root:current train perplexity4.900384902954102
INFO:root:current mean train loss 2018.8978676738045
INFO:root:current train perplexity4.9004082679748535
INFO:root:current mean train loss 2019.4728765861882
INFO:root:current train perplexity4.904971599578857
INFO:root:current mean train loss 2020.1325540897317
INFO:root:current train perplexity4.9120917320251465
INFO:root:current mean train loss 2019.215395822076
INFO:root:current train perplexity4.908771514892578
INFO:root:current mean train loss 2020.1600108568757
INFO:root:current train perplexity4.9112653732299805
INFO:root:current mean train loss 2018.43860473141
INFO:root:current train perplexity4.910488605499268
INFO:root:current mean train loss 2020.0924428190249
INFO:root:current train perplexity4.914988040924072
INFO:root:current mean train loss 2020.5849695781467
INFO:root:current train perplexity4.916874885559082
INFO:root:current mean train loss 2021.3027633676893
INFO:root:current train perplexity4.920557975769043
INFO:root:current mean train loss 2021.2595414202945
INFO:root:current train perplexity4.921306133270264
INFO:root:current mean train loss 2020.9727633858056
INFO:root:current train perplexity4.92293643951416
INFO:root:current mean train loss 2021.7560822312305
INFO:root:current train perplexity4.927724838256836
INFO:root:current mean train loss 2022.1766204598146
INFO:root:current train perplexity4.9268479347229

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.74s/it]
INFO:root:final mean train loss: 2022.2054312239977
INFO:root:final train perplexity: 4.927505016326904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 1977.5569877895057
INFO:root:eval perplexity: 4.9497246742248535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.80s/it]
INFO:root:eval mean loss: 2412.406415790531
INFO:root:eval perplexity: 7.191734313964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:53:43<7:54:04, 389.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2025.0184978616649
INFO:root:current train perplexity4.929294109344482
INFO:root:current mean train loss 1999.9954764450654
INFO:root:current train perplexity4.894693851470947
INFO:root:current mean train loss 1996.1230071311772
INFO:root:current train perplexity4.861654758453369
INFO:root:current mean train loss 2002.8901060306825
INFO:root:current train perplexity4.872323989868164
INFO:root:current mean train loss 2005.6165960720011
INFO:root:current train perplexity4.877289772033691
INFO:root:current mean train loss 2008.4051211777553
INFO:root:current train perplexity4.8767876625061035
INFO:root:current mean train loss 2010.9721182501426
INFO:root:current train perplexity4.884576797485352
INFO:root:current mean train loss 2011.8095248984787
INFO:root:current train perplexity4.88856840133667
INFO:root:current mean train loss 2008.3084095063466
INFO:root:current train perplexity4.885341644287109
INFO:root:current mean train loss 2009.518173440762
INFO:root:current train perplexity4.890403747558594
INFO:root:current mean train loss 2010.0755995982986
INFO:root:current train perplexity4.892422676086426
INFO:root:current mean train loss 2010.9635873112654
INFO:root:current train perplexity4.896539688110352
INFO:root:current mean train loss 2010.8999536753838
INFO:root:current train perplexity4.89445686340332
INFO:root:current mean train loss 2012.859849438225
INFO:root:current train perplexity4.898034572601318
INFO:root:current mean train loss 2014.7563646523224
INFO:root:current train perplexity4.900305271148682
INFO:root:current mean train loss 2014.679548114194
INFO:root:current train perplexity4.901678562164307
INFO:root:current mean train loss 2016.3254308389955
INFO:root:current train perplexity4.902496337890625
INFO:root:current mean train loss 2015.8917257159237
INFO:root:current train perplexity4.901244163513184
INFO:root:current mean train loss 2015.504690443353
INFO:root:current train perplexity4.900305271148682
INFO:root:current mean train loss 2016.339401541253
INFO:root:current train perplexity4.902968406677246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.04s/it]
INFO:root:final mean train loss: 2015.9118687124248
INFO:root:final train perplexity: 4.903108596801758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it]
INFO:root:eval mean loss: 1976.223699475011
INFO:root:eval perplexity: 4.944389820098877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it]
INFO:root:eval mean loss: 2412.234959812029
INFO:root:eval perplexity: 7.190726280212402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [3:00:23<7:51:37, 393.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2017.3853955078125
INFO:root:current train perplexity4.896605968475342
INFO:root:current mean train loss 2003.5296909877231
INFO:root:current train perplexity4.86746883392334
INFO:root:current mean train loss 2002.387139559659
INFO:root:current train perplexity4.867510795593262
INFO:root:current mean train loss 2004.1280003255208
INFO:root:current train perplexity4.861469745635986
INFO:root:current mean train loss 2010.0706471011513
INFO:root:current train perplexity4.8764190673828125
INFO:root:current mean train loss 2017.179969641644
INFO:root:current train perplexity4.884576797485352
INFO:root:current mean train loss 2017.0248012514467
INFO:root:current train perplexity4.89287805557251
INFO:root:current mean train loss 2018.4891615738406
INFO:root:current train perplexity4.898988723754883
INFO:root:current mean train loss 2018.0946092354911
INFO:root:current train perplexity4.893667221069336
INFO:root:current mean train loss 2015.9249684495192
INFO:root:current train perplexity4.890521049499512
INFO:root:current mean train loss 2015.7578327125727
INFO:root:current train perplexity4.889988899230957
INFO:root:current mean train loss 2014.6177132854057
INFO:root:current train perplexity4.891788959503174
INFO:root:current mean train loss 2016.0578208295037
INFO:root:current train perplexity4.8954176902771
INFO:root:current mean train loss 2015.4352613636363
INFO:root:current train perplexity4.8928022384643555
INFO:root:current mean train loss 2014.6141927635063
INFO:root:current train perplexity4.890887260437012
INFO:root:current mean train loss 2014.9308232576884
INFO:root:current train perplexity4.891366004943848
INFO:root:current mean train loss 2015.5430178696363
INFO:root:current train perplexity4.895602226257324
INFO:root:current mean train loss 2015.7522845373019
INFO:root:current train perplexity4.898918628692627
INFO:root:current mean train loss 2015.7351869140625
INFO:root:current train perplexity4.898723602294922
INFO:root:current mean train loss 2016.9745428698575
INFO:root:current train perplexity4.904244899749756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.58s/it]
INFO:root:final mean train loss: 2016.1552563858224
INFO:root:final train perplexity: 4.904049396514893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 1983.3088279345357
INFO:root:eval perplexity: 4.972803115844727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2422.1018447334886
INFO:root:eval perplexity: 7.248983860015869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:07:08<7:49:02, 396.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1988.5230009659476
INFO:root:current train perplexity4.858696937561035
INFO:root:current mean train loss 2008.5333582560222
INFO:root:current train perplexity4.893866539001465
INFO:root:current mean train loss 2015.3161190503265
INFO:root:current train perplexity4.907805442810059
INFO:root:current mean train loss 2013.848872593471
INFO:root:current train perplexity4.9032158851623535
INFO:root:current mean train loss 2017.2906501583936
INFO:root:current train perplexity4.90816593170166
INFO:root:current mean train loss 2018.3815926216744
INFO:root:current train perplexity4.915107727050781
INFO:root:current mean train loss 2018.806217083352
INFO:root:current train perplexity4.91605806350708
INFO:root:current mean train loss 2016.9295774517636
INFO:root:current train perplexity4.90493106842041
INFO:root:current mean train loss 2016.8119499993431
INFO:root:current train perplexity4.9055562019348145
INFO:root:current mean train loss 2019.3497607323432
INFO:root:current train perplexity4.909407138824463
INFO:root:current mean train loss 2020.119891826923
INFO:root:current train perplexity4.909196853637695
INFO:root:current mean train loss 2020.9322336696139
INFO:root:current train perplexity4.910969257354736
INFO:root:current mean train loss 2020.6411133757317
INFO:root:current train perplexity4.912322521209717
INFO:root:current mean train loss 2020.894863961757
INFO:root:current train perplexity4.915650367736816
INFO:root:current mean train loss 2020.381311493329
INFO:root:current train perplexity4.915091037750244
INFO:root:current mean train loss 2021.3824018928874
INFO:root:current train perplexity4.916619300842285
INFO:root:current mean train loss 2019.6824608480395
INFO:root:current train perplexity4.916961669921875
INFO:root:current mean train loss 2021.8435307911463
INFO:root:current train perplexity4.920695781707764
INFO:root:current mean train loss 2021.750327241345
INFO:root:current train perplexity4.922369003295898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.08s/it]
INFO:root:final mean train loss: 2021.0185196299897
INFO:root:final train perplexity: 4.9228949546813965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it]
INFO:root:eval mean loss: 1972.4374147239307
INFO:root:eval perplexity: 4.92927360534668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it]
INFO:root:eval mean loss: 2410.5527153285684
INFO:root:eval perplexity: 7.180838108062744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:13:48<7:43:46, 397.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2032.7922770182292
INFO:root:current train perplexity5.042453289031982
INFO:root:current mean train loss 2035.4059577031967
INFO:root:current train perplexity4.937316417694092
INFO:root:current mean train loss 2026.7234897157223
INFO:root:current train perplexity4.936890125274658
INFO:root:current mean train loss 2022.848995863041
INFO:root:current train perplexity4.933035373687744
INFO:root:current mean train loss 2024.1051034344437
INFO:root:current train perplexity4.9360032081604
INFO:root:current mean train loss 2023.4011391150693
INFO:root:current train perplexity4.93423318862915
INFO:root:current mean train loss 2026.3626618784638
INFO:root:current train perplexity4.935739040374756
INFO:root:current mean train loss 2025.98864694442
INFO:root:current train perplexity4.933682441711426
INFO:root:current mean train loss 2028.1679343469948
INFO:root:current train perplexity4.94378137588501
INFO:root:current mean train loss 2027.0591013691212
INFO:root:current train perplexity4.941405773162842
INFO:root:current mean train loss 2030.0733938982748
INFO:root:current train perplexity4.949179172515869
INFO:root:current mean train loss 2029.5548444632693
INFO:root:current train perplexity4.946036338806152
INFO:root:current mean train loss 2029.8367290891233
INFO:root:current train perplexity4.948909282684326
INFO:root:current mean train loss 2031.2386256393538
INFO:root:current train perplexity4.952364921569824
INFO:root:current mean train loss 2032.2820702709146
INFO:root:current train perplexity4.956819534301758
INFO:root:current mean train loss 2032.1974122873437
INFO:root:current train perplexity4.956376075744629
INFO:root:current mean train loss 2030.6575700132798
INFO:root:current train perplexity4.954286575317383
INFO:root:current mean train loss 2028.8226719069996
INFO:root:current train perplexity4.948475360870361
INFO:root:current mean train loss 2028.767134920018
INFO:root:current train perplexity4.951081275939941
INFO:root:current mean train loss 2028.438920977729
INFO:root:current train perplexity4.951200008392334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.01s/it]
INFO:root:final mean train loss: 2028.133306136831
INFO:root:final train perplexity: 4.950595855712891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 1981.6347426827072
INFO:root:eval perplexity: 4.966075420379639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it]
INFO:root:eval mean loss: 2419.8496803662456
INFO:root:eval perplexity: 7.235644340515137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:20:26<7:37:14, 397.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2038.5375507061299
INFO:root:current train perplexity5.02951192855835
INFO:root:current mean train loss 2021.6948842850943
INFO:root:current train perplexity4.933135509490967
INFO:root:current mean train loss 2025.8635102668695
INFO:root:current train perplexity4.955560207366943
INFO:root:current mean train loss 2028.8074003816382
INFO:root:current train perplexity4.955976963043213
INFO:root:current mean train loss 2030.7650696660432
INFO:root:current train perplexity4.963980674743652
INFO:root:current mean train loss 2030.1597055645498
INFO:root:current train perplexity4.960763931274414
INFO:root:current mean train loss 2031.1733960038937
INFO:root:current train perplexity4.959019660949707
INFO:root:current mean train loss 2033.6542265920928
INFO:root:current train perplexity4.9653706550598145
INFO:root:current mean train loss 2036.3297224067892
INFO:root:current train perplexity4.967616558074951
INFO:root:current mean train loss 2037.2737461032414
INFO:root:current train perplexity4.968045711517334
INFO:root:current mean train loss 2035.4508998937774
INFO:root:current train perplexity4.9630537033081055
INFO:root:current mean train loss 2034.2696999368616
INFO:root:current train perplexity4.965241432189941
INFO:root:current mean train loss 2034.8871658101168
INFO:root:current train perplexity4.967245101928711
INFO:root:current mean train loss 2035.7130502554087
INFO:root:current train perplexity4.967212677001953
INFO:root:current mean train loss 2034.0285297837866
INFO:root:current train perplexity4.965170383453369
INFO:root:current mean train loss 2032.4522673080664
INFO:root:current train perplexity4.961795330047607
INFO:root:current mean train loss 2031.7844085130305
INFO:root:current train perplexity4.9614176750183105
INFO:root:current mean train loss 2032.6183594032898
INFO:root:current train perplexity4.963596820831299
INFO:root:current mean train loss 2032.3858966137989
INFO:root:current train perplexity4.9640936851501465
INFO:root:current mean train loss 2033.4597139447649
INFO:root:current train perplexity4.967268466949463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.74s/it]
INFO:root:final mean train loss: 2032.3703167290623
INFO:root:final train perplexity: 4.967166900634766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 1970.5090219484152
INFO:root:eval perplexity: 4.9215922355651855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 2413.136534345911
INFO:root:eval perplexity: 7.196029186248779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:26:52<7:26:48, 394.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2029.0506307912428
INFO:root:current train perplexity4.904700756072998
INFO:root:current mean train loss 2010.4981296779392
INFO:root:current train perplexity4.910719871520996
INFO:root:current mean train loss 2018.3125120563273
INFO:root:current train perplexity4.922638893127441
INFO:root:current mean train loss 2020.9140689060223
INFO:root:current train perplexity4.931380271911621
INFO:root:current mean train loss 2024.5392303122355
INFO:root:current train perplexity4.936052322387695
INFO:root:current mean train loss 2029.1022137664738
INFO:root:current train perplexity4.947223663330078
INFO:root:current mean train loss 2028.6778479022892
INFO:root:current train perplexity4.948739528656006
INFO:root:current mean train loss 2029.752594035214
INFO:root:current train perplexity4.951800346374512
INFO:root:current mean train loss 2028.408968272724
INFO:root:current train perplexity4.949786186218262
INFO:root:current mean train loss 2026.019032612838
INFO:root:current train perplexity4.937682151794434
INFO:root:current mean train loss 2026.4048471862266
INFO:root:current train perplexity4.944240570068359
INFO:root:current mean train loss 2028.2587210320635
INFO:root:current train perplexity4.950442314147949
INFO:root:current mean train loss 2030.0190668328578
INFO:root:current train perplexity4.952525615692139
INFO:root:current mean train loss 2030.9240799915942
INFO:root:current train perplexity4.956236839294434
INFO:root:current mean train loss 2029.6684056821996
INFO:root:current train perplexity4.953591823577881
INFO:root:current mean train loss 2031.0901299783802
INFO:root:current train perplexity4.958856105804443
INFO:root:current mean train loss 2031.301161948893
INFO:root:current train perplexity4.95843505859375
INFO:root:current mean train loss 2030.135724048538
INFO:root:current train perplexity4.956216812133789
INFO:root:current mean train loss 2031.2553538065272
INFO:root:current train perplexity4.9588494300842285
INFO:root:current mean train loss 2030.6607942448654
INFO:root:current train perplexity4.959989547729492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.63s/it]
INFO:root:final mean train loss: 2031.1264596728442
INFO:root:final train perplexity: 4.962295055389404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 1972.9259422789228
INFO:root:eval perplexity: 4.931221008300781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2414.126512026956
INFO:root:eval perplexity: 7.201857089996338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:33:27<7:20:29, 394.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2001.8966512044271
INFO:root:current train perplexity4.903158187866211
INFO:root:current mean train loss 2004.3396507263183
INFO:root:current train perplexity4.89639949798584
INFO:root:current mean train loss 2014.2916067270132
INFO:root:current train perplexity4.8955979347229
INFO:root:current mean train loss 2020.8978817409939
INFO:root:current train perplexity4.927577972412109
INFO:root:current mean train loss 2024.4351222826087
INFO:root:current train perplexity4.934566974639893
INFO:root:current mean train loss 2026.495765032087
INFO:root:current train perplexity4.942004680633545
INFO:root:current mean train loss 2024.758954412287
INFO:root:current train perplexity4.93627405166626
INFO:root:current mean train loss 2025.9480645430715
INFO:root:current train perplexity4.931972503662109
INFO:root:current mean train loss 2028.031927774119
INFO:root:current train perplexity4.939733028411865
INFO:root:current mean train loss 2028.253574371338
INFO:root:current train perplexity4.9363603591918945
INFO:root:current mean train loss 2027.9548616229363
INFO:root:current train perplexity4.942230224609375
INFO:root:current mean train loss 2029.3195294610384
INFO:root:current train perplexity4.945609092712402
INFO:root:current mean train loss 2028.467964390346
INFO:root:current train perplexity4.946739196777344
INFO:root:current mean train loss 2026.918119991527
INFO:root:current train perplexity4.942465782165527
INFO:root:current mean train loss 2027.0337158203124
INFO:root:current train perplexity4.943896293640137
INFO:root:current mean train loss 2028.9471661689954
INFO:root:current train perplexity4.952165126800537
INFO:root:current mean train loss 2027.9534182628954
INFO:root:current train perplexity4.951405048370361
INFO:root:current mean train loss 2028.008779144287
INFO:root:current train perplexity4.948687553405762
INFO:root:current mean train loss 2028.2167353148102
INFO:root:current train perplexity4.950294017791748
INFO:root:current mean train loss 2029.4037468735053
INFO:root:current train perplexity4.953438758850098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.33s/it]
INFO:root:final mean train loss: 2028.6860863112827
INFO:root:final train perplexity: 4.952754974365234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 1977.9973547103557
INFO:root:eval perplexity: 4.951488018035889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it]
INFO:root:eval mean loss: 2420.259172155502
INFO:root:eval perplexity: 7.238068580627441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:39:59<7:13:14, 393.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1998.036472072849
INFO:root:current train perplexity4.864957332611084
INFO:root:current mean train loss 2001.6556513727048
INFO:root:current train perplexity4.8902788162231445
INFO:root:current mean train loss 2006.3447578512805
INFO:root:current train perplexity4.899381160736084
INFO:root:current mean train loss 2014.6561761749833
INFO:root:current train perplexity4.905919551849365
INFO:root:current mean train loss 2021.2832402323277
INFO:root:current train perplexity4.9201788902282715
INFO:root:current mean train loss 2023.0252962690913
INFO:root:current train perplexity4.924503803253174
INFO:root:current mean train loss 2027.7354556017472
INFO:root:current train perplexity4.936822414398193
INFO:root:current mean train loss 2025.5130516258446
INFO:root:current train perplexity4.935777187347412
INFO:root:current mean train loss 2027.0839957886437
INFO:root:current train perplexity4.9383769035339355
INFO:root:current mean train loss 2028.0032299279922
INFO:root:current train perplexity4.943113327026367
INFO:root:current mean train loss 2026.3488568914302
INFO:root:current train perplexity4.9452080726623535
INFO:root:current mean train loss 2025.476090812845
INFO:root:current train perplexity4.937608242034912
INFO:root:current mean train loss 2026.5315450908806
INFO:root:current train perplexity4.942429065704346
INFO:root:current mean train loss 2024.6585208446804
INFO:root:current train perplexity4.940598964691162
INFO:root:current mean train loss 2025.504526188669
INFO:root:current train perplexity4.937952995300293
INFO:root:current mean train loss 2024.888263787056
INFO:root:current train perplexity4.938710689544678
INFO:root:current mean train loss 2025.066696176091
INFO:root:current train perplexity4.940329551696777
INFO:root:current mean train loss 2025.6991588483047
INFO:root:current train perplexity4.939979076385498
INFO:root:current mean train loss 2025.9883971420068
INFO:root:current train perplexity4.936944961547852
INFO:root:current mean train loss 2025.9203101289834
INFO:root:current train perplexity4.939483165740967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it]
INFO:root:final mean train loss: 2025.2296874507533
INFO:root:final train perplexity: 4.939272403717041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 1974.1892527045934
INFO:root:eval perplexity: 4.936262130737305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it]
INFO:root:eval mean loss: 2415.3633782136526
INFO:root:eval perplexity: 7.209146976470947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:46:32<7:06:21, 393.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2043.3627760866855
INFO:root:current train perplexity5.023426055908203
INFO:root:current mean train loss 2026.2195786938225
INFO:root:current train perplexity4.963480472564697
INFO:root:current mean train loss 2021.892638329746
INFO:root:current train perplexity4.9444260597229
INFO:root:current mean train loss 2026.3827926713197
INFO:root:current train perplexity4.945291996002197
INFO:root:current mean train loss 2023.8698050927537
INFO:root:current train perplexity4.946735858917236
INFO:root:current mean train loss 2024.428314928254
INFO:root:current train perplexity4.943636894226074
INFO:root:current mean train loss 2024.2027596685316
INFO:root:current train perplexity4.944204330444336
INFO:root:current mean train loss 2023.6289346920753
INFO:root:current train perplexity4.937782287597656
INFO:root:current mean train loss 2024.7837181688687
INFO:root:current train perplexity4.933679580688477
INFO:root:current mean train loss 2023.5038443551937
INFO:root:current train perplexity4.930334091186523
INFO:root:current mean train loss 2021.4754949984647
INFO:root:current train perplexity4.926083564758301
INFO:root:current mean train loss 2020.882798186898
INFO:root:current train perplexity4.9206223487854
INFO:root:current mean train loss 2021.2024670089415
INFO:root:current train perplexity4.922730445861816
INFO:root:current mean train loss 2019.8016085084234
INFO:root:current train perplexity4.918747425079346
INFO:root:current mean train loss 2020.7173646571964
INFO:root:current train perplexity4.917006492614746
INFO:root:current mean train loss 2021.184176149452
INFO:root:current train perplexity4.917951583862305
INFO:root:current mean train loss 2021.6224902084332
INFO:root:current train perplexity4.9217071533203125
INFO:root:current mean train loss 2021.6580324715196
INFO:root:current train perplexity4.922618389129639
INFO:root:current mean train loss 2022.3859985738268
INFO:root:current train perplexity4.924862861633301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.71s/it]
INFO:root:final mean train loss: 2020.380139172468
INFO:root:final train perplexity: 4.920416831970215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 1968.836189432347
INFO:root:eval perplexity: 4.914938926696777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 2412.7094886725677
INFO:root:eval perplexity: 7.193515777587891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:53:17<7:03:20, 396.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1945.4336159446023
INFO:root:current train perplexity4.672854423522949
INFO:root:current mean train loss 2016.2908165734093
INFO:root:current train perplexity4.913293361663818
INFO:root:current mean train loss 2023.2753900464677
INFO:root:current train perplexity4.895012378692627
INFO:root:current mean train loss 2021.806531899995
INFO:root:current train perplexity4.892917156219482
INFO:root:current mean train loss 2024.37019678566
INFO:root:current train perplexity4.905008792877197
INFO:root:current mean train loss 2018.1680179603413
INFO:root:current train perplexity4.884054660797119
INFO:root:current mean train loss 2012.439604564111
INFO:root:current train perplexity4.87662410736084
INFO:root:current mean train loss 2013.1088484322806
INFO:root:current train perplexity4.882593631744385
INFO:root:current mean train loss 2012.303505028514
INFO:root:current train perplexity4.8863654136657715
INFO:root:current mean train loss 2010.4916424044663
INFO:root:current train perplexity4.884779453277588
INFO:root:current mean train loss 2012.9928822503246
INFO:root:current train perplexity4.890876770019531
INFO:root:current mean train loss 2013.5350101172226
INFO:root:current train perplexity4.885311126708984
INFO:root:current mean train loss 2013.5250305629386
INFO:root:current train perplexity4.881335735321045
INFO:root:current mean train loss 2014.321278633915
INFO:root:current train perplexity4.88542366027832
INFO:root:current mean train loss 2014.0386423912562
INFO:root:current train perplexity4.888927936553955
INFO:root:current mean train loss 2012.3861350583998
INFO:root:current train perplexity4.888471603393555
INFO:root:current mean train loss 2013.655337693009
INFO:root:current train perplexity4.890984058380127
INFO:root:current mean train loss 2013.402687772821
INFO:root:current train perplexity4.892467498779297
INFO:root:current mean train loss 2014.0759974984685
INFO:root:current train perplexity4.892788410186768
INFO:root:current mean train loss 2014.3563020347863
INFO:root:current train perplexity4.896500587463379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.74s/it]
INFO:root:final mean train loss: 2014.6735722267201
INFO:root:final train perplexity: 4.898322582244873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it]
INFO:root:eval mean loss: 1966.910190879876
INFO:root:eval perplexity: 4.907288074493408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 2408.606020663647
INFO:root:eval perplexity: 7.169416904449463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:59:58<6:57:53, 398.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2050.215083530971
INFO:root:current train perplexity4.970053672790527
INFO:root:current mean train loss 1993.0659646987915
INFO:root:current train perplexity4.84479284286499
INFO:root:current mean train loss 2005.8568270499245
INFO:root:current train perplexity4.86653470993042
INFO:root:current mean train loss 2007.7467174995236
INFO:root:current train perplexity4.8553619384765625
INFO:root:current mean train loss 2010.5400245167384
INFO:root:current train perplexity4.869700908660889
INFO:root:current mean train loss 2010.8378166429925
INFO:root:current train perplexity4.87456750869751
INFO:root:current mean train loss 2010.719102604374
INFO:root:current train perplexity4.878380298614502
INFO:root:current mean train loss 2010.3911875630472
INFO:root:current train perplexity4.881165981292725
INFO:root:current mean train loss 2009.187162095222
INFO:root:current train perplexity4.876141548156738
INFO:root:current mean train loss 2010.4532742993586
INFO:root:current train perplexity4.874777317047119
INFO:root:current mean train loss 2009.0515868190662
INFO:root:current train perplexity4.869866847991943
INFO:root:current mean train loss 2009.9793423050685
INFO:root:current train perplexity4.871464729309082
INFO:root:current mean train loss 2009.4389135503613
INFO:root:current train perplexity4.87161922454834
INFO:root:current mean train loss 2010.393271204937
INFO:root:current train perplexity4.8719706535339355
INFO:root:current mean train loss 2008.828575326615
INFO:root:current train perplexity4.866011619567871
INFO:root:current mean train loss 2007.7698358665587
INFO:root:current train perplexity4.866698741912842
INFO:root:current mean train loss 2008.7776975889465
INFO:root:current train perplexity4.872407913208008
INFO:root:current mean train loss 2008.2298995830395
INFO:root:current train perplexity4.8740386962890625
INFO:root:current mean train loss 2008.8575082190448
INFO:root:current train perplexity4.87379789352417
INFO:root:current mean train loss 2009.724255826958
INFO:root:current train perplexity4.876712799072266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.38s/it]
INFO:root:final mean train loss: 2008.8788731008
INFO:root:final train perplexity: 4.875988483428955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.70s/it]
INFO:root:eval mean loss: 1967.8338822168662
INFO:root:eval perplexity: 4.910955905914307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 2408.6317311821253
INFO:root:eval perplexity: 7.169567108154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:06:22<6:46:53, 393.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2016.3468831380208
INFO:root:current train perplexity4.867628574371338
INFO:root:current mean train loss 2016.151821794181
INFO:root:current train perplexity4.870792388916016
INFO:root:current mean train loss 2008.2577910754146
INFO:root:current train perplexity4.8595685958862305
INFO:root:current mean train loss 2003.7588623046875
INFO:root:current train perplexity4.855474948883057
INFO:root:current mean train loss 2001.2283315594277
INFO:root:current train perplexity4.8474578857421875
INFO:root:current mean train loss 2002.6792471509461
INFO:root:current train perplexity4.852476119995117
INFO:root:current mean train loss 2004.3214974336845
INFO:root:current train perplexity4.852292537689209
INFO:root:current mean train loss 2005.0051633284395
INFO:root:current train perplexity4.857261657714844
INFO:root:current mean train loss 2006.7001018456453
INFO:root:current train perplexity4.865427494049072
INFO:root:current mean train loss 2007.109251896288
INFO:root:current train perplexity4.859738349914551
INFO:root:current mean train loss 2007.3443122243198
INFO:root:current train perplexity4.8610334396362305
INFO:root:current mean train loss 2009.5881758111013
INFO:root:current train perplexity4.867526054382324
INFO:root:current mean train loss 2008.7261675608684
INFO:root:current train perplexity4.862632751464844
INFO:root:current mean train loss 2007.3982281199176
INFO:root:current train perplexity4.859321117401123
INFO:root:current mean train loss 2006.541253936662
INFO:root:current train perplexity4.8566460609436035
INFO:root:current mean train loss 2005.0211758412975
INFO:root:current train perplexity4.853661060333252
INFO:root:current mean train loss 2004.7496082618968
INFO:root:current train perplexity4.853256702423096
INFO:root:current mean train loss 2003.420300537809
INFO:root:current train perplexity4.851811408996582
INFO:root:current mean train loss 2004.2263511761093
INFO:root:current train perplexity4.85402250289917
INFO:root:current mean train loss 2003.3812532008153
INFO:root:current train perplexity4.85326623916626

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.35s/it]
INFO:root:final mean train loss: 2002.8691627552457
INFO:root:final train perplexity: 4.852931499481201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 1964.0699696642287
INFO:root:eval perplexity: 4.896029472351074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.77s/it]
INFO:root:eval mean loss: 2406.620377777316
INFO:root:eval perplexity: 7.157782554626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:12:51<6:39:05, 392.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1995.709222608997
INFO:root:current train perplexity4.827186107635498
INFO:root:current mean train loss 1996.6780011212384
INFO:root:current train perplexity4.834843158721924
INFO:root:current mean train loss 1986.7385552093274
INFO:root:current train perplexity4.814490795135498
INFO:root:current mean train loss 1989.4870011977728
INFO:root:current train perplexity4.822657585144043
INFO:root:current mean train loss 1992.3451955555838
INFO:root:current train perplexity4.8190083503723145
INFO:root:current mean train loss 1990.3022936620746
INFO:root:current train perplexity4.822481632232666
INFO:root:current mean train loss 1991.4620842602317
INFO:root:current train perplexity4.823230743408203
INFO:root:current mean train loss 1994.071209124067
INFO:root:current train perplexity4.826712608337402
INFO:root:current mean train loss 1995.7542577331967
INFO:root:current train perplexity4.826284408569336
INFO:root:current mean train loss 1995.779775258657
INFO:root:current train perplexity4.8280134201049805
INFO:root:current mean train loss 1995.1067086487392
INFO:root:current train perplexity4.8253703117370605
INFO:root:current mean train loss 1995.1809304741287
INFO:root:current train perplexity4.830132484436035
INFO:root:current mean train loss 1993.1681462452643
INFO:root:current train perplexity4.828658580780029
INFO:root:current mean train loss 1994.3555911788155
INFO:root:current train perplexity4.829814910888672
INFO:root:current mean train loss 1996.6205326607387
INFO:root:current train perplexity4.83425760269165
INFO:root:current mean train loss 1998.414609081156
INFO:root:current train perplexity4.835155010223389
INFO:root:current mean train loss 1997.651987968656
INFO:root:current train perplexity4.8323211669921875
INFO:root:current mean train loss 1998.6794365007138
INFO:root:current train perplexity4.834245681762695
INFO:root:current mean train loss 1998.3837187180075
INFO:root:current train perplexity4.833663463592529
INFO:root:current mean train loss 1999.1914313235657
INFO:root:current train perplexity4.834784984588623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.91s/it]
INFO:root:final mean train loss: 1998.3290541009715
INFO:root:final train perplexity: 4.8355865478515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 1972.371539609652
INFO:root:eval perplexity: 4.929010391235352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.68s/it]
INFO:root:eval mean loss: 2415.8071916729
INFO:root:eval perplexity: 7.211763381958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:19:20<6:31:19, 391.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.2721225400514
INFO:root:current train perplexity4.81424617767334
INFO:root:current mean train loss 2001.5254349522083
INFO:root:current train perplexity4.851545333862305
INFO:root:current mean train loss 1993.4488722278227
INFO:root:current train perplexity4.820644378662109
INFO:root:current mean train loss 2000.2502164412929
INFO:root:current train perplexity4.828167915344238
INFO:root:current mean train loss 1998.5277359550332
INFO:root:current train perplexity4.825793266296387
INFO:root:current mean train loss 1997.6764251234617
INFO:root:current train perplexity4.82277774810791
INFO:root:current mean train loss 2003.430528688501
INFO:root:current train perplexity4.836193561553955
INFO:root:current mean train loss 2002.083650757933
INFO:root:current train perplexity4.832931995391846
INFO:root:current mean train loss 2000.163001640936
INFO:root:current train perplexity4.827230453491211
INFO:root:current mean train loss 1999.1671092702613
INFO:root:current train perplexity4.82167387008667
INFO:root:current mean train loss 2000.0232508308475
INFO:root:current train perplexity4.826761722564697
INFO:root:current mean train loss 1998.2051838364412
INFO:root:current train perplexity4.821728706359863
INFO:root:current mean train loss 1996.7226279037272
INFO:root:current train perplexity4.8202128410339355
INFO:root:current mean train loss 1995.4091337451562
INFO:root:current train perplexity4.817395210266113
INFO:root:current mean train loss 1995.4763689537642
INFO:root:current train perplexity4.818083763122559
INFO:root:current mean train loss 1993.0812655081093
INFO:root:current train perplexity4.814938068389893
INFO:root:current mean train loss 1994.4848436511222
INFO:root:current train perplexity4.81709098815918
INFO:root:current mean train loss 1994.0545435407444
INFO:root:current train perplexity4.815725803375244
INFO:root:current mean train loss 1992.5349089910276
INFO:root:current train perplexity4.813714504241943
INFO:root:current mean train loss 1992.9875446953756
INFO:root:current train perplexity4.813371658325195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.78s/it]
INFO:root:final mean train loss: 1992.5582377885366
INFO:root:final train perplexity: 4.813629150390625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 1959.4434065582059
INFO:root:eval perplexity: 4.877743244171143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 2403.6052743898217
INFO:root:eval perplexity: 7.140154838562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:25:54<6:25:36, 392.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1997.4298706054688
INFO:root:current train perplexity4.855387210845947
INFO:root:current mean train loss 1993.6074100416533
INFO:root:current train perplexity4.8279032707214355
INFO:root:current mean train loss 1989.3157307392842
INFO:root:current train perplexity4.818142890930176
INFO:root:current mean train loss 1990.0959814823036
INFO:root:current train perplexity4.8056488037109375
INFO:root:current mean train loss 1988.8064939437375
INFO:root:current train perplexity4.801499843597412
INFO:root:current mean train loss 1992.5654823252019
INFO:root:current train perplexity4.805973529815674
INFO:root:current mean train loss 1988.5279528738438
INFO:root:current train perplexity4.801872253417969
INFO:root:current mean train loss 1986.3184662632007
INFO:root:current train perplexity4.7909932136535645
INFO:root:current mean train loss 1984.4436255863734
INFO:root:current train perplexity4.785493850708008
INFO:root:current mean train loss 1985.8468172004425
INFO:root:current train perplexity4.788213729858398
INFO:root:current mean train loss 1985.4746653981451
INFO:root:current train perplexity4.788850784301758
INFO:root:current mean train loss 1987.4921641270055
INFO:root:current train perplexity4.792572021484375
INFO:root:current mean train loss 1987.689651866018
INFO:root:current train perplexity4.796656608581543
INFO:root:current mean train loss 1987.5692511178702
INFO:root:current train perplexity4.794325828552246
INFO:root:current mean train loss 1987.1582253196023
INFO:root:current train perplexity4.787193298339844
INFO:root:current mean train loss 1986.7801354582746
INFO:root:current train perplexity4.790683746337891
INFO:root:current mean train loss 1987.8586005444797
INFO:root:current train perplexity4.792773723602295
INFO:root:current mean train loss 1987.8744748121912
INFO:root:current train perplexity4.794547080993652
INFO:root:current mean train loss 1987.7148985399979
INFO:root:current train perplexity4.794990062713623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.86s/it]
INFO:root:final mean train loss: 1987.052775803805
INFO:root:final train perplexity: 4.792773723602295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it]
INFO:root:eval mean loss: 1956.6843517114085
INFO:root:eval perplexity: 4.866870880126953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it]
INFO:root:eval mean loss: 2399.429606552665
INFO:root:eval perplexity: 7.115812301635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:32:18<6:16:51, 389.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1971.4842998798076
INFO:root:current train perplexity4.777903079986572
INFO:root:current mean train loss 1979.410794688537
INFO:root:current train perplexity4.772763729095459
INFO:root:current mean train loss 1984.5641637094704
INFO:root:current train perplexity4.77133321762085
INFO:root:current mean train loss 1979.6432282566643
INFO:root:current train perplexity4.76171350479126
INFO:root:current mean train loss 1977.531132363234
INFO:root:current train perplexity4.754001617431641
INFO:root:current mean train loss 1983.1603406642148
INFO:root:current train perplexity4.768641471862793
INFO:root:current mean train loss 1981.6298246648144
INFO:root:current train perplexity4.764271259307861
INFO:root:current mean train loss 1981.592436331686
INFO:root:current train perplexity4.764817237854004
INFO:root:current mean train loss 1980.6317757281577
INFO:root:current train perplexity4.76993989944458
INFO:root:current mean train loss 1979.281861153777
INFO:root:current train perplexity4.766696453094482
INFO:root:current mean train loss 1980.5045996286556
INFO:root:current train perplexity4.7713823318481445
INFO:root:current mean train loss 1981.8777290885769
INFO:root:current train perplexity4.77119255065918
INFO:root:current mean train loss 1982.5448332155233
INFO:root:current train perplexity4.771345138549805
INFO:root:current mean train loss 1984.315854005022
INFO:root:current train perplexity4.777159214019775
INFO:root:current mean train loss 1985.0726304536834
INFO:root:current train perplexity4.777807712554932
INFO:root:current mean train loss 1983.9960354176565
INFO:root:current train perplexity4.777943134307861
INFO:root:current mean train loss 1984.2098829880754
INFO:root:current train perplexity4.777066230773926
INFO:root:current mean train loss 1984.113464818666
INFO:root:current train perplexity4.7786993980407715
INFO:root:current mean train loss 1984.0396088875268
INFO:root:current train perplexity4.777706146240234
INFO:root:current mean train loss 1983.6769135111736
INFO:root:current train perplexity4.775266170501709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.14s/it]
INFO:root:final mean train loss: 1982.0422273713775
INFO:root:final train perplexity: 4.773872375488281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 1953.159057184314
INFO:root:eval perplexity: 4.853015422821045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.53s/it]
INFO:root:eval mean loss: 2396.6515208575743
INFO:root:eval perplexity: 7.099664211273193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:38:44<6:09:04, 388.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2003.515995279948
INFO:root:current train perplexity4.7509660720825195
INFO:root:current mean train loss 1984.8004760742188
INFO:root:current train perplexity4.780705451965332
INFO:root:current mean train loss 1968.8805738366168
INFO:root:current train perplexity4.757151126861572
INFO:root:current mean train loss 1969.385820608428
INFO:root:current train perplexity4.748774528503418
INFO:root:current mean train loss 1967.1371763717295
INFO:root:current train perplexity4.736375331878662
INFO:root:current mean train loss 1968.7572337024617
INFO:root:current train perplexity4.739814281463623
INFO:root:current mean train loss 1971.1517246791295
INFO:root:current train perplexity4.737574577331543
INFO:root:current mean train loss 1970.4306038634418
INFO:root:current train perplexity4.7353596687316895
INFO:root:current mean train loss 1973.0806887707079
INFO:root:current train perplexity4.737728118896484
INFO:root:current mean train loss 1971.9855535691784
INFO:root:current train perplexity4.73436164855957
INFO:root:current mean train loss 1973.742771541262
INFO:root:current train perplexity4.737371921539307
INFO:root:current mean train loss 1974.797983139173
INFO:root:current train perplexity4.741047382354736
INFO:root:current mean train loss 1976.5045045930196
INFO:root:current train perplexity4.744837760925293
INFO:root:current mean train loss 1975.957996247944
INFO:root:current train perplexity4.745068073272705
INFO:root:current mean train loss 1975.3618812827797
INFO:root:current train perplexity4.745284557342529
INFO:root:current mean train loss 1974.4546859043096
INFO:root:current train perplexity4.744751453399658
INFO:root:current mean train loss 1974.5281145154333
INFO:root:current train perplexity4.74664306640625
INFO:root:current mean train loss 1975.691818184384
INFO:root:current train perplexity4.751490116119385
INFO:root:current mean train loss 1977.3479895753287
INFO:root:current train perplexity4.755831718444824
INFO:root:current mean train loss 1977.06690066639
INFO:root:current train perplexity4.7551445960998535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.04s/it]
INFO:root:final mean train loss: 1977.311801496805
INFO:root:final train perplexity: 4.756094932556152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 1954.6700880984042
INFO:root:eval perplexity: 4.858950614929199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 2400.6679159394394
INFO:root:eval perplexity: 7.123023509979248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:45:15<6:03:27, 389.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1964.2304791389627
INFO:root:current train perplexity4.778069496154785
INFO:root:current mean train loss 1991.7326834542412
INFO:root:current train perplexity4.809972286224365
INFO:root:current mean train loss 1977.3904935396636
INFO:root:current train perplexity4.755641937255859
INFO:root:current mean train loss 1980.5498694164264
INFO:root:current train perplexity4.750720500946045
INFO:root:current mean train loss 1975.9355711798273
INFO:root:current train perplexity4.740967750549316
INFO:root:current mean train loss 1975.3537510622573
INFO:root:current train perplexity4.739161968231201
INFO:root:current mean train loss 1971.895914587761
INFO:root:current train perplexity4.727614879608154
INFO:root:current mean train loss 1969.4606178620734
INFO:root:current train perplexity4.723143577575684
INFO:root:current mean train loss 1966.9843872502674
INFO:root:current train perplexity4.7221150398254395
INFO:root:current mean train loss 1968.5274606642274
INFO:root:current train perplexity4.722481727600098
INFO:root:current mean train loss 1968.831532708781
INFO:root:current train perplexity4.724287509918213
INFO:root:current mean train loss 1968.2559091822418
INFO:root:current train perplexity4.724145889282227
INFO:root:current mean train loss 1969.612770649559
INFO:root:current train perplexity4.72792911529541
INFO:root:current mean train loss 1969.5885139357715
INFO:root:current train perplexity4.7281599044799805
INFO:root:current mean train loss 1969.9934810909965
INFO:root:current train perplexity4.729245185852051
INFO:root:current mean train loss 1970.430787316429
INFO:root:current train perplexity4.730072975158691
INFO:root:current mean train loss 1971.9435098320337
INFO:root:current train perplexity4.734588623046875
INFO:root:current mean train loss 1972.982459816717
INFO:root:current train perplexity4.7380218505859375
INFO:root:current mean train loss 1972.8701636495625
INFO:root:current train perplexity4.737087249755859
INFO:root:current mean train loss 1973.3115544096286
INFO:root:current train perplexity4.738575458526611

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.58s/it]
INFO:root:final mean train loss: 1972.2316295567991
INFO:root:final train perplexity: 4.7370781898498535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 1952.0146285253213
INFO:root:eval perplexity: 4.848526477813721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it]
INFO:root:eval mean loss: 2395.4681084815493
INFO:root:eval perplexity: 7.0927958488464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:51:34<5:54:09, 386.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.821834564209
INFO:root:current train perplexity4.674637317657471
INFO:root:current mean train loss 1971.008904433832
INFO:root:current train perplexity4.73405647277832
INFO:root:current mean train loss 1977.369897553415
INFO:root:current train perplexity4.74713659286499
INFO:root:current mean train loss 1974.1661199213383
INFO:root:current train perplexity4.737349033355713
INFO:root:current mean train loss 1971.9265689192148
INFO:root:current train perplexity4.735132217407227
INFO:root:current mean train loss 1970.2769580597574
INFO:root:current train perplexity4.735172271728516
INFO:root:current mean train loss 1965.9276683761414
INFO:root:current train perplexity4.726841449737549
INFO:root:current mean train loss 1964.1753971439382
INFO:root:current train perplexity4.7234787940979
INFO:root:current mean train loss 1961.2481542516637
INFO:root:current train perplexity4.714496612548828
INFO:root:current mean train loss 1964.0009010916428
INFO:root:current train perplexity4.71421480178833
INFO:root:current mean train loss 1964.5363530897557
INFO:root:current train perplexity4.716443061828613
INFO:root:current mean train loss 1964.6268086122075
INFO:root:current train perplexity4.715500354766846
INFO:root:current mean train loss 1963.2777592139907
INFO:root:current train perplexity4.7096943855285645
INFO:root:current mean train loss 1963.2959383519863
INFO:root:current train perplexity4.709017276763916
INFO:root:current mean train loss 1964.4819874581092
INFO:root:current train perplexity4.713230609893799
INFO:root:current mean train loss 1964.1567551400656
INFO:root:current train perplexity4.711612701416016
INFO:root:current mean train loss 1964.7528035824116
INFO:root:current train perplexity4.711269378662109
INFO:root:current mean train loss 1965.8802378820994
INFO:root:current train perplexity4.712886333465576
INFO:root:current mean train loss 1966.7307496295978
INFO:root:current train perplexity4.713909149169922
INFO:root:current mean train loss 1967.1163764534074
INFO:root:current train perplexity4.715804576873779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.26s/it]
INFO:root:final mean train loss: 1966.700510091392
INFO:root:final train perplexity: 4.716458797454834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 1949.3111425088653
INFO:root:eval perplexity: 4.837936878204346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.16s/it]
INFO:root:eval mean loss: 2394.307476503629
INFO:root:eval perplexity: 7.086068153381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:57:59<5:47:18, 385.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.0666925877701
INFO:root:current train perplexity4.663105487823486
INFO:root:current mean train loss 1963.169252848757
INFO:root:current train perplexity4.685907363891602
INFO:root:current mean train loss 1962.0070561853593
INFO:root:current train perplexity4.6965556144714355
INFO:root:current mean train loss 1966.584272730069
INFO:root:current train perplexity4.721435546875
INFO:root:current mean train loss 1965.8726139187565
INFO:root:current train perplexity4.711825370788574
INFO:root:current mean train loss 1963.0242558543325
INFO:root:current train perplexity4.708103656768799
INFO:root:current mean train loss 1959.313886152315
INFO:root:current train perplexity4.700827121734619
INFO:root:current mean train loss 1960.5350662211908
INFO:root:current train perplexity4.694344520568848
INFO:root:current mean train loss 1958.2104252480758
INFO:root:current train perplexity4.690350532531738
INFO:root:current mean train loss 1958.5337481484137
INFO:root:current train perplexity4.688652038574219
INFO:root:current mean train loss 1961.312302270937
INFO:root:current train perplexity4.6981401443481445
INFO:root:current mean train loss 1960.135579702715
INFO:root:current train perplexity4.698057174682617
INFO:root:current mean train loss 1959.7210088248926
INFO:root:current train perplexity4.696534633636475
INFO:root:current mean train loss 1961.3851225547044
INFO:root:current train perplexity4.699311256408691
INFO:root:current mean train loss 1961.5336803614007
INFO:root:current train perplexity4.699336528778076
INFO:root:current mean train loss 1962.6714369829963
INFO:root:current train perplexity4.699960231781006
INFO:root:current mean train loss 1962.8299449441831
INFO:root:current train perplexity4.701305866241455
INFO:root:current mean train loss 1962.8092643485052
INFO:root:current train perplexity4.700896263122559
INFO:root:current mean train loss 1962.8362971563913
INFO:root:current train perplexity4.700538158416748
INFO:root:current mean train loss 1962.7448954151353
INFO:root:current train perplexity4.699918270111084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.14s/it]
INFO:root:final mean train loss: 1962.195096645461
INFO:root:final train perplexity: 4.699729919433594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 1948.6503053489307
INFO:root:eval perplexity: 4.835351943969727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 2395.527403486536
INFO:root:eval perplexity: 7.093141078948975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [5:04:41<5:44:57, 390.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1955.762770049426
INFO:root:current train perplexity4.6018900871276855
INFO:root:current mean train loss 1952.1764100970645
INFO:root:current train perplexity4.63699197769165
INFO:root:current mean train loss 1942.3400055546088
INFO:root:current train perplexity4.63754415512085
INFO:root:current mean train loss 1953.1966236823766
INFO:root:current train perplexity4.652674674987793
INFO:root:current mean train loss 1956.3112599323074
INFO:root:current train perplexity4.667195796966553
INFO:root:current mean train loss 1956.4562588184574
INFO:root:current train perplexity4.672584056854248
INFO:root:current mean train loss 1955.256954160324
INFO:root:current train perplexity4.67378568649292
INFO:root:current mean train loss 1954.917968291089
INFO:root:current train perplexity4.673466205596924
INFO:root:current mean train loss 1955.883241377323
INFO:root:current train perplexity4.676558017730713
INFO:root:current mean train loss 1954.1007232971804
INFO:root:current train perplexity4.675013542175293
INFO:root:current mean train loss 1956.6848508073983
INFO:root:current train perplexity4.679375171661377
INFO:root:current mean train loss 1955.828891964309
INFO:root:current train perplexity4.675319194793701
INFO:root:current mean train loss 1956.256486748694
INFO:root:current train perplexity4.675703048706055
INFO:root:current mean train loss 1957.3830166490634
INFO:root:current train perplexity4.678187370300293
INFO:root:current mean train loss 1958.5738476497309
INFO:root:current train perplexity4.683413982391357
INFO:root:current mean train loss 1959.446776961803
INFO:root:current train perplexity4.685332775115967
INFO:root:current mean train loss 1959.3988563348885
INFO:root:current train perplexity4.684347152709961
INFO:root:current mean train loss 1958.6256851009584
INFO:root:current train perplexity4.682363033294678
INFO:root:current mean train loss 1958.2743291663924
INFO:root:current train perplexity4.681763172149658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it]
INFO:root:final mean train loss: 1957.5431536406625
INFO:root:final train perplexity: 4.68251895904541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 1946.7256915586215
INFO:root:eval perplexity: 4.827832221984863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.67s/it]
INFO:root:eval mean loss: 2393.0849072611923
INFO:root:eval perplexity: 7.078985214233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:11:07<5:37:22, 389.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1924.2817464192708
INFO:root:current train perplexity4.616495132446289
INFO:root:current mean train loss 1980.8502271569293
INFO:root:current train perplexity4.70221471786499
INFO:root:current mean train loss 1967.5780188272165
INFO:root:current train perplexity4.689489841461182
INFO:root:current mean train loss 1954.5497670975942
INFO:root:current train perplexity4.6630682945251465
INFO:root:current mean train loss 1952.126038627165
INFO:root:current train perplexity4.666651725769043
INFO:root:current mean train loss 1948.1227923050667
INFO:root:current train perplexity4.6612372398376465
INFO:root:current mean train loss 1943.7067386782267
INFO:root:current train perplexity4.651266098022461
INFO:root:current mean train loss 1948.5762934331294
INFO:root:current train perplexity4.658692836761475
INFO:root:current mean train loss 1947.0204965790356
INFO:root:current train perplexity4.651337623596191
INFO:root:current mean train loss 1950.1082777012894
INFO:root:current train perplexity4.656801223754883
INFO:root:current mean train loss 1950.2829666814193
INFO:root:current train perplexity4.656746864318848
INFO:root:current mean train loss 1949.5000925106854
INFO:root:current train perplexity4.655752182006836
INFO:root:current mean train loss 1951.7125118553884
INFO:root:current train perplexity4.660033702850342
INFO:root:current mean train loss 1950.4325058853672
INFO:root:current train perplexity4.6591362953186035
INFO:root:current mean train loss 1977.9269742608492
INFO:root:current train perplexity4.7575812339782715
INFO:root:current mean train loss 2120.350767149469
INFO:root:current train perplexity5.321343898773193
INFO:root:current mean train loss 2219.2164779804807
INFO:root:current train perplexity5.750317573547363
INFO:root:current mean train loss 2286.2585516837876
INFO:root:current train perplexity6.067818641662598
INFO:root:current mean train loss 2340.1445197491607
INFO:root:current train perplexity6.329983234405518
INFO:root:current mean train loss 2416.5913891027863
INFO:root:current train perplexity6.721157073974609

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.97s/it]
INFO:root:final mean train loss: 2464.2355184473295
INFO:root:final train perplexity: 6.982760906219482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it]
INFO:root:eval mean loss: 3229.961930511691
INFO:root:eval perplexity: 13.629051208496094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.71s/it]
INFO:root:eval mean loss: 3609.5930383560503
INFO:root:eval perplexity: 19.144672393798828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:17:30<5:29:18, 387.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3713.392250061035
INFO:root:current train perplexity18.037857055664062
INFO:root:current mean train loss 3644.3981711647725
INFO:root:current train perplexity17.532726287841797
INFO:root:current mean train loss 3682.872649094154
INFO:root:current train perplexity17.98668098449707
INFO:root:current mean train loss 3703.8008180181664
INFO:root:current train perplexity18.42161750793457
INFO:root:current mean train loss 3773.2418919316046
INFO:root:current train perplexity19.618572235107422
INFO:root:current mean train loss 3833.3201908885985
INFO:root:current train perplexity20.493093490600586
INFO:root:current mean train loss 3862.4922836883156
INFO:root:current train perplexity20.968708038330078
INFO:root:current mean train loss 3875.969099868191
INFO:root:current train perplexity21.13505744934082
INFO:root:current mean train loss 3895.384464263916
INFO:root:current train perplexity21.38265037536621
INFO:root:current mean train loss 3910.916325777897
INFO:root:current train perplexity21.697391510009766
INFO:root:current mean train loss 3927.991512091585
INFO:root:current train perplexity21.969358444213867
INFO:root:current mean train loss 3936.983544447397
INFO:root:current train perplexity22.2233943939209
INFO:root:current mean train loss 3955.67461504255
INFO:root:current train perplexity22.562788009643555
INFO:root:current mean train loss 3973.0851414769263
INFO:root:current train perplexity22.877483367919922
INFO:root:current mean train loss 3994.1561725978745
INFO:root:current train perplexity23.251230239868164
INFO:root:current mean train loss 4010.370306029955
INFO:root:current train perplexity23.579641342163086
INFO:root:current mean train loss 4040.3039353314566
INFO:root:current train perplexity24.164505004882812
INFO:root:current mean train loss 4099.798051442065
INFO:root:current train perplexity25.32781219482422
INFO:root:current mean train loss 4170.875217087925
INFO:root:current train perplexity26.78443145751953
INFO:root:current mean train loss 4263.272866701241
INFO:root:current train perplexity28.83165168762207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.71s/it]
INFO:root:final mean train loss: 4305.719248253711
INFO:root:final train perplexity: 29.83699607849121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.46s/it]
INFO:root:eval mean loss: 5028.58305802582
INFO:root:eval perplexity: 58.37122344970703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it]
INFO:root:eval mean loss: 5272.604727670656
INFO:root:eval perplexity: 74.59558868408203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:24:00<5:23:26, 388.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6007.591916454082
INFO:root:current train perplexity115.64685821533203
INFO:root:current mean train loss 5632.065164246015
INFO:root:current train perplexity84.45712280273438
INFO:root:current mean train loss 5659.704315308108
INFO:root:current train perplexity86.69544982910156
INFO:root:current mean train loss 5606.608534148908
INFO:root:current train perplexity83.67142486572266
INFO:root:current mean train loss 5600.180185568624
INFO:root:current train perplexity82.92359161376953
INFO:root:current mean train loss 5619.955543281819
INFO:root:current train perplexity84.11779022216797
INFO:root:current mean train loss 5643.6958903120185
INFO:root:current train perplexity85.6819839477539
INFO:root:current mean train loss 5657.181102798523
INFO:root:current train perplexity86.70404815673828
INFO:root:current mean train loss 5663.079410979829
INFO:root:current train perplexity87.04422760009766
INFO:root:current mean train loss 5685.304682354781
INFO:root:current train perplexity88.44706726074219
INFO:root:current mean train loss 5716.116739714907
INFO:root:current train perplexity90.52669525146484
INFO:root:current mean train loss 5733.49441685025
INFO:root:current train perplexity91.81922149658203
INFO:root:current mean train loss 5744.755563044186
INFO:root:current train perplexity92.6380386352539
INFO:root:current mean train loss 5748.313240565928
INFO:root:current train perplexity93.0588607788086
INFO:root:current mean train loss 5749.117264667982
INFO:root:current train perplexity92.94852447509766
INFO:root:current mean train loss 5749.426144072285
INFO:root:current train perplexity93.0625
INFO:root:current mean train loss 5740.131262673401
INFO:root:current train perplexity92.32392883300781
INFO:root:current mean train loss 5735.963272260488
INFO:root:current train perplexity92.04326629638672
INFO:root:current mean train loss 5789.528374184525
INFO:root:current train perplexity96.0926513671875
INFO:root:current mean train loss 5869.332211129907
INFO:root:current train perplexity102.25177001953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.12s/it]
INFO:root:final mean train loss: 5875.6873464733435
INFO:root:final train perplexity: 102.9167251586914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 5630.8070734984485
INFO:root:eval perplexity: 94.9990005493164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 5759.518725239639
INFO:root:eval perplexity: 111.08468627929688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:30:23<5:15:40, 386.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6492.154992305871
INFO:root:current train perplexity166.23419189453125
INFO:root:current mean train loss 6680.589490775603
INFO:root:current train perplexity189.87600708007812
INFO:root:current mean train loss 6577.633436618891
INFO:root:current train perplexity177.2024383544922
INFO:root:current mean train loss 6448.882228163422
INFO:root:current train perplexity159.78195190429688
INFO:root:current mean train loss 6400.576639199973
INFO:root:current train perplexity154.91473388671875
INFO:root:current mean train loss 6432.34273547924
INFO:root:current train perplexity158.8140869140625
INFO:root:current mean train loss 6447.801784939236
INFO:root:current train perplexity160.5146026611328
INFO:root:current mean train loss 6492.8173681513135
INFO:root:current train perplexity166.1709442138672
INFO:root:current mean train loss 6530.969478475029
INFO:root:current train perplexity171.48208618164062
INFO:root:current mean train loss 6562.428811525459
INFO:root:current train perplexity175.74758911132812
INFO:root:current mean train loss 6591.223759692337
INFO:root:current train perplexity180.12484741210938
INFO:root:current mean train loss 6623.888530750831
INFO:root:current train perplexity184.5054473876953
INFO:root:current mean train loss 6658.557479882504
INFO:root:current train perplexity189.28289794921875
INFO:root:current mean train loss 6685.6910512988425
INFO:root:current train perplexity193.9552001953125
INFO:root:current mean train loss 6718.519667475805
INFO:root:current train perplexity198.93797302246094
INFO:root:current mean train loss 6740.193711710768
INFO:root:current train perplexity202.11048889160156
INFO:root:current mean train loss 6756.373765521834
INFO:root:current train perplexity204.73252868652344
INFO:root:current mean train loss 6758.639643184191
INFO:root:current train perplexity205.49081420898438
INFO:root:current mean train loss 6752.550073425358
INFO:root:current train perplexity204.87490844726562
INFO:root:current mean train loss 6746.35421377281
INFO:root:current train perplexity204.1841278076172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.01s/it]
INFO:root:final mean train loss: 6743.733333062476
INFO:root:final train perplexity: 204.0803680419922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 5777.5608758588205
INFO:root:eval perplexity: 106.97039794921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 5941.290407870678
INFO:root:eval perplexity: 128.8888702392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:36:47<5:08:40, 385.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6600.53376200113
INFO:root:current train perplexity180.63568115234375
INFO:root:current mean train loss 6544.545097976435
INFO:root:current train perplexity171.3544921875
INFO:root:current mean train loss 6410.028867256515
INFO:root:current train perplexity153.93971252441406
INFO:root:current mean train loss 6305.93765681095
INFO:root:current train perplexity142.4707794189453
INFO:root:current mean train loss 6193.707432590903
INFO:root:current train perplexity130.90809631347656
INFO:root:current mean train loss 6151.28536144538
INFO:root:current train perplexity127.1762466430664
INFO:root:current mean train loss 6174.854047515556
INFO:root:current train perplexity129.1898193359375
INFO:root:current mean train loss 6188.79141223659
INFO:root:current train perplexity130.7183380126953
INFO:root:current mean train loss 6199.935608255769
INFO:root:current train perplexity131.82470703125
INFO:root:current mean train loss 6201.432374785414
INFO:root:current train perplexity131.62811279296875
INFO:root:current mean train loss 6188.461910906481
INFO:root:current train perplexity130.36297607421875
INFO:root:current mean train loss 6173.934533990649
INFO:root:current train perplexity128.8517608642578
INFO:root:current mean train loss 6153.192781277402
INFO:root:current train perplexity127.2686996459961
INFO:root:current mean train loss 6139.91740032425
INFO:root:current train perplexity125.99517822265625
INFO:root:current mean train loss 6125.647870198183
INFO:root:current train perplexity124.75741577148438
INFO:root:current mean train loss 6119.018518290035
INFO:root:current train perplexity124.37869262695312
INFO:root:current mean train loss 6104.444781570299
INFO:root:current train perplexity123.1022720336914
INFO:root:current mean train loss 6088.665169964596
INFO:root:current train perplexity121.55181884765625
INFO:root:current mean train loss 6075.457202654093
INFO:root:current train perplexity120.1485824584961
INFO:root:current mean train loss 6056.180593885921
INFO:root:current train perplexity118.66073608398438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.76s/it]
INFO:root:final mean train loss: 6056.180593885921
INFO:root:final train perplexity: 118.66073608398438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it]
INFO:root:eval mean loss: 4602.21125003463
INFO:root:eval perplexity: 41.34694290161133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it]
INFO:root:eval mean loss: 4795.875555809508
INFO:root:eval perplexity: 50.51138687133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:43:06<5:00:34, 383.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5855.268408203125
INFO:root:current train perplexity97.46650695800781
INFO:root:current mean train loss 5755.600441894531
INFO:root:current train perplexity92.68487548828125
INFO:root:current mean train loss 5677.977814127604
INFO:root:current train perplexity88.5115737915039
INFO:root:current mean train loss 5650.141802978515
INFO:root:current train perplexity85.36784362792969
INFO:root:current mean train loss 5590.8901923828125
INFO:root:current train perplexity81.87008666992188
INFO:root:current mean train loss 5531.909624023438
INFO:root:current train perplexity78.23737335205078
INFO:root:current mean train loss 5485.771242327009
INFO:root:current train perplexity75.40399169921875
INFO:root:current mean train loss 5421.317964477539
INFO:root:current train perplexity71.71977996826172
INFO:root:current mean train loss 5363.971239149306
INFO:root:current train perplexity68.7905044555664
INFO:root:current mean train loss 5318.107978027344
INFO:root:current train perplexity66.20103454589844
INFO:root:current mean train loss 5268.9559494850855
INFO:root:current train perplexity63.6361083984375
INFO:root:current mean train loss 5208.919409383138
INFO:root:current train perplexity60.81898880004883
INFO:root:current mean train loss 5150.612405160758
INFO:root:current train perplexity58.21770095825195
INFO:root:current mean train loss 5109.152651192801
INFO:root:current train perplexity56.20048522949219
INFO:root:current mean train loss 5056.009713216145
INFO:root:current train perplexity53.99565124511719
INFO:root:current mean train loss 4995.029137115478
INFO:root:current train perplexity51.57207107543945
INFO:root:current mean train loss 4934.830041503907
INFO:root:current train perplexity49.10862350463867
INFO:root:current mean train loss 4870.522697618273
INFO:root:current train perplexity46.6121711730957
INFO:root:current mean train loss 4807.5786531147205
INFO:root:current train perplexity44.32795333862305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.97s/it]
INFO:root:final mean train loss: 4750.699092001249
INFO:root:final train perplexity: 42.38043975830078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 2660.370125844969
INFO:root:eval perplexity: 8.598185539245605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it]
INFO:root:eval mean loss: 3050.9429814764794
INFO:root:eval perplexity: 12.123492240905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:49:35<4:55:27, 385.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3406.075252757353
INFO:root:current train perplexity14.35264778137207
INFO:root:current mean train loss 3337.205591446314
INFO:root:current train perplexity13.701960563659668
INFO:root:current mean train loss 3216.9355795020883
INFO:root:current train perplexity12.545221328735352
INFO:root:current mean train loss 3159.7288352412756
INFO:root:current train perplexity12.022761344909668
INFO:root:current mean train loss 3109.743787001649
INFO:root:current train perplexity11.571798324584961
INFO:root:current mean train loss 3070.398742085499
INFO:root:current train perplexity11.205201148986816
INFO:root:current mean train loss 3026.6148406636194
INFO:root:current train perplexity10.833050727844238
INFO:root:current mean train loss 2987.42796761953
INFO:root:current train perplexity10.536330223083496
INFO:root:current mean train loss 2951.0968846819537
INFO:root:current train perplexity10.258231163024902
INFO:root:current mean train loss 2926.60282766494
INFO:root:current train perplexity10.051727294921875
INFO:root:current mean train loss 2904.792800468212
INFO:root:current train perplexity9.868182182312012
INFO:root:current mean train loss 2884.357008562626
INFO:root:current train perplexity9.713041305541992
INFO:root:current mean train loss 2864.975567882729
INFO:root:current train perplexity9.571389198303223
INFO:root:current mean train loss 2849.2627904105566
INFO:root:current train perplexity9.455588340759277
INFO:root:current mean train loss 2833.93760802835
INFO:root:current train perplexity9.345436096191406
INFO:root:current mean train loss 2821.610591196904
INFO:root:current train perplexity9.256014823913574
INFO:root:current mean train loss 2811.4541849054963
INFO:root:current train perplexity9.173057556152344
INFO:root:current mean train loss 2799.7963513133827
INFO:root:current train perplexity9.089996337890625
INFO:root:current mean train loss 2790.5679913501394
INFO:root:current train perplexity9.019524574279785
INFO:root:current mean train loss 2780.4201750578704
INFO:root:current train perplexity8.953313827514648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it]
INFO:root:final mean train loss: 2774.26739738953
INFO:root:final train perplexity: 8.916950225830078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 2281.449034778784
INFO:root:eval perplexity: 6.328744411468506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 2696.639467929272
INFO:root:eval perplexity: 9.073752403259277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:56:04<4:49:49, 386.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2676.022518382353
INFO:root:current train perplexity7.933785438537598
INFO:root:current mean train loss 2650.894933899837
INFO:root:current train perplexity7.9249982833862305
INFO:root:current mean train loss 2629.232864249466
INFO:root:current train perplexity7.885202407836914
INFO:root:current mean train loss 2629.4766224387163
INFO:root:current train perplexity7.862404823303223
INFO:root:current mean train loss 2631.580292451217
INFO:root:current train perplexity7.869486331939697
INFO:root:current mean train loss 2623.2379154962546
INFO:root:current train perplexity7.8463826179504395
INFO:root:current mean train loss 2619.306969868272
INFO:root:current train perplexity7.836802959442139
INFO:root:current mean train loss 2614.706181081829
INFO:root:current train perplexity7.816994667053223
INFO:root:current mean train loss 2614.4466874742393
INFO:root:current train perplexity7.809900760650635
INFO:root:current mean train loss 2610.159318748327
INFO:root:current train perplexity7.787124156951904
INFO:root:current mean train loss 2606.832916672963
INFO:root:current train perplexity7.774470806121826
INFO:root:current mean train loss 2601.737794475791
INFO:root:current train perplexity7.744803428649902
INFO:root:current mean train loss 2598.65724951251
INFO:root:current train perplexity7.729800224304199
INFO:root:current mean train loss 2594.9925395273553
INFO:root:current train perplexity7.715472221374512
INFO:root:current mean train loss 2590.4438060297625
INFO:root:current train perplexity7.695397853851318
INFO:root:current mean train loss 2586.881646465913
INFO:root:current train perplexity7.680930137634277
INFO:root:current mean train loss 2583.5590573034206
INFO:root:current train perplexity7.666876792907715
INFO:root:current mean train loss 2583.710525741489
INFO:root:current train perplexity7.661542892456055
INFO:root:current mean train loss 2581.3338479943727
INFO:root:current train perplexity7.653794765472412
INFO:root:current mean train loss 2578.334099439209
INFO:root:current train perplexity7.63486909866333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.94s/it]
INFO:root:final mean train loss: 2575.9659968004403
INFO:root:final train perplexity: 7.625986099243164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2245.6574568511746
INFO:root:eval perplexity: 6.1481781005859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.96s/it]
INFO:root:eval mean loss: 2668.0686887916945
INFO:root:eval perplexity: 8.864191055297852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [6:02:30<4:43:25, 386.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2540.231636795343
INFO:root:current train perplexity7.36606502532959
INFO:root:current mean train loss 2527.4578703823468
INFO:root:current train perplexity7.314317226409912
INFO:root:current mean train loss 2521.507221115538
INFO:root:current train perplexity7.2783427238464355
INFO:root:current mean train loss 2510.4488967069533
INFO:root:current train perplexity7.245067119598389
INFO:root:current mean train loss 2508.3283788845965
INFO:root:current train perplexity7.254570960998535
INFO:root:current mean train loss 2507.206119378119
INFO:root:current train perplexity7.243223190307617
INFO:root:current mean train loss 2504.7959400651644
INFO:root:current train perplexity7.223874092102051
INFO:root:current mean train loss 2500.220533429386
INFO:root:current train perplexity7.207800388336182
INFO:root:current mean train loss 2496.567815581164
INFO:root:current train perplexity7.185792922973633
INFO:root:current mean train loss 2493.650588941123
INFO:root:current train perplexity7.165559768676758
INFO:root:current mean train loss 2490.107719094724
INFO:root:current train perplexity7.143367290496826
INFO:root:current mean train loss 2487.4872922789627
INFO:root:current train perplexity7.13337516784668
INFO:root:current mean train loss 2485.2878436508604
INFO:root:current train perplexity7.118325233459473
INFO:root:current mean train loss 2483.8907541180433
INFO:root:current train perplexity7.104682445526123
INFO:root:current mean train loss 2480.9285994673664
INFO:root:current train perplexity7.089640140533447
INFO:root:current mean train loss 2480.551009571068
INFO:root:current train perplexity7.081000804901123
INFO:root:current mean train loss 2478.798213780829
INFO:root:current train perplexity7.0693817138671875
INFO:root:current mean train loss 2476.695560753788
INFO:root:current train perplexity7.0587921142578125
INFO:root:current mean train loss 2474.3978625626773
INFO:root:current train perplexity7.045514106750488
INFO:root:current mean train loss 2474.8509469552873
INFO:root:current train perplexity7.039576053619385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.69s/it]
INFO:root:final mean train loss: 2473.6906226730925
INFO:root:final train perplexity: 7.0350260734558105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 2213.129094117077
INFO:root:eval perplexity: 5.9885478019714355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it]
INFO:root:eval mean loss: 2642.7983744736257
INFO:root:eval perplexity: 8.682880401611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [6:08:55<4:36:35, 385.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2452.0696770163145
INFO:root:current train perplexity6.925899505615234
INFO:root:current mean train loss 2441.7957066127233
INFO:root:current train perplexity6.894650459289551
INFO:root:current mean train loss 2435.786255793785
INFO:root:current train perplexity6.843420028686523
INFO:root:current mean train loss 2439.1217916737432
INFO:root:current train perplexity6.850088596343994
INFO:root:current mean train loss 2436.318814008664
INFO:root:current train perplexity6.837267875671387
INFO:root:current mean train loss 2431.882047626334
INFO:root:current train perplexity6.806713581085205
INFO:root:current mean train loss 2430.172571056617
INFO:root:current train perplexity6.794522762298584
INFO:root:current mean train loss 2431.6182408332825
INFO:root:current train perplexity6.790377140045166
INFO:root:current mean train loss 2427.9902004822056
INFO:root:current train perplexity6.785921573638916
INFO:root:current mean train loss 2426.45712292884
INFO:root:current train perplexity6.775504112243652
INFO:root:current mean train loss 2425.9885210472994
INFO:root:current train perplexity6.765618324279785
INFO:root:current mean train loss 2426.3694458007812
INFO:root:current train perplexity6.765511989593506
INFO:root:current mean train loss 2424.622027376097
INFO:root:current train perplexity6.761492729187012
INFO:root:current mean train loss 2422.655214543928
INFO:root:current train perplexity6.752474308013916
INFO:root:current mean train loss 2425.3198020997424
INFO:root:current train perplexity6.762948513031006
INFO:root:current mean train loss 2429.4191889860194
INFO:root:current train perplexity6.785872936248779
INFO:root:current mean train loss 2431.931014319404
INFO:root:current train perplexity6.800497531890869
INFO:root:current mean train loss 2438.2308320610773
INFO:root:current train perplexity6.833758354187012
INFO:root:current mean train loss 2467.9141466683955
INFO:root:current train perplexity6.998631954193115
INFO:root:current mean train loss 2501.8530760974418
INFO:root:current train perplexity7.190532207489014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.09s/it]
INFO:root:final mean train loss: 2504.0455164676114
INFO:root:final train perplexity: 7.205472946166992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 2507.232715363198
INFO:root:eval perplexity: 7.59661340713501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it]
INFO:root:eval mean loss: 2912.4285278320312
INFO:root:eval perplexity: 10.82506275177002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:15:32<4:32:33, 389.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3182.410325712316
INFO:root:current train perplexity12.345131874084473
INFO:root:current mean train loss 3220.002473078547
INFO:root:current train perplexity12.648393630981445
INFO:root:current mean train loss 3089.135179379112
INFO:root:current train perplexity11.352712631225586
INFO:root:current mean train loss 3016.6341644683444
INFO:root:current train perplexity10.743721008300781
INFO:root:current mean train loss 2980.0026482965527
INFO:root:current train perplexity10.438879013061523
INFO:root:current mean train loss 2959.940480184963
INFO:root:current train perplexity10.306144714355469
INFO:root:current mean train loss 2954.4807071880705
INFO:root:current train perplexity10.259553909301758
INFO:root:current mean train loss 2953.6182984175957
INFO:root:current train perplexity10.248279571533203
INFO:root:current mean train loss 2961.933920650159
INFO:root:current train perplexity10.3189058303833
INFO:root:current mean train loss 2975.809893767846
INFO:root:current train perplexity10.445189476013184
INFO:root:current mean train loss 2996.772422235023
INFO:root:current train perplexity10.613880157470703
INFO:root:current mean train loss 3020.5740706174183
INFO:root:current train perplexity10.82254695892334
INFO:root:current mean train loss 3045.6808681146645
INFO:root:current train perplexity11.0465087890625
INFO:root:current mean train loss 3078.000061167362
INFO:root:current train perplexity11.323023796081543
INFO:root:current mean train loss 3110.4109302662036
INFO:root:current train perplexity11.614997863769531
INFO:root:current mean train loss 3145.3425329936417
INFO:root:current train perplexity11.930166244506836
INFO:root:current mean train loss 3178.4417777494436
INFO:root:current train perplexity12.241205215454102
INFO:root:current mean train loss 3208.6559019115457
INFO:root:current train perplexity12.526851654052734
INFO:root:current mean train loss 3237.268149167979
INFO:root:current train perplexity12.821853637695312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.92s/it]
INFO:root:final mean train loss: 3263.3387480104325
INFO:root:final train perplexity: 13.113797187805176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.66s/it]
INFO:root:eval mean loss: 3120.0678503158247
INFO:root:eval perplexity: 12.470023155212402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 3445.333839362395
INFO:root:eval perplexity: 16.73811912536621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:21:56<4:24:50, 387.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3858.3541259765625
INFO:root:current train perplexity17.822172164916992
INFO:root:current mean train loss 3812.652513691023
INFO:root:current train perplexity20.086078643798828
INFO:root:current mean train loss 3798.8767452428838
INFO:root:current train perplexity20.21723175048828
INFO:root:current mean train loss 3798.132979033009
INFO:root:current train perplexity20.135032653808594
INFO:root:current mean train loss 3837.380853909165
INFO:root:current train perplexity20.57756996154785
INFO:root:current mean train loss 3854.972749626494
INFO:root:current train perplexity20.847942352294922
INFO:root:current mean train loss 3874.5162795564265
INFO:root:current train perplexity21.18345069885254
INFO:root:current mean train loss 3881.4572301793983
INFO:root:current train perplexity21.317882537841797
INFO:root:current mean train loss 3880.3701083594724
INFO:root:current train perplexity21.271207809448242
INFO:root:current mean train loss 3868.138709768223
INFO:root:current train perplexity21.07670021057129
INFO:root:current mean train loss 3855.8321808531373
INFO:root:current train perplexity20.88593292236328
INFO:root:current mean train loss 3841.248721252552
INFO:root:current train perplexity20.618885040283203
INFO:root:current mean train loss 3821.3786389546067
INFO:root:current train perplexity20.339027404785156
INFO:root:current mean train loss 3801.2359984789027
INFO:root:current train perplexity19.996253967285156
INFO:root:current mean train loss 3790.8641648231323
INFO:root:current train perplexity19.83329200744629
INFO:root:current mean train loss 3772.6290494509926
INFO:root:current train perplexity19.55672264099121
INFO:root:current mean train loss 3755.9862397345114
INFO:root:current train perplexity19.299421310424805
INFO:root:current mean train loss 3735.0049487964525
INFO:root:current train perplexity19.010234832763672
INFO:root:current mean train loss 3716.998867631885
INFO:root:current train perplexity18.75596046447754
INFO:root:current mean train loss 3700.1939544517286
INFO:root:current train perplexity18.506385803222656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.41s/it]
INFO:root:final mean train loss: 3684.5855556532283
INFO:root:final train perplexity: 18.28142738342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it]
INFO:root:eval mean loss: 2729.9063807277817
INFO:root:eval perplexity: 9.095574378967285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it]
INFO:root:eval mean loss: 3074.2357272966533
INFO:root:eval perplexity: 12.356651306152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:28:35<4:20:48, 391.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.0582596628287
INFO:root:current train perplexity14.210328102111816
INFO:root:current mean train loss 3320.2981203223476
INFO:root:current train perplexity13.928609848022461
INFO:root:current mean train loss 3326.695021537885
INFO:root:current train perplexity13.871237754821777
INFO:root:current mean train loss 3305.936306848795
INFO:root:current train perplexity13.627728462219238
INFO:root:current mean train loss 3289.5395391277593
INFO:root:current train perplexity13.4517240524292
INFO:root:current mean train loss 3273.285469069876
INFO:root:current train perplexity13.234891891479492
INFO:root:current mean train loss 3263.359333586808
INFO:root:current train perplexity13.093936920166016
INFO:root:current mean train loss 3252.416572156967
INFO:root:current train perplexity12.988012313842773
INFO:root:current mean train loss 3246.3482625772663
INFO:root:current train perplexity12.917593002319336
INFO:root:current mean train loss 3235.0778503085894
INFO:root:current train perplexity12.851798057556152
INFO:root:current mean train loss 3224.364925066318
INFO:root:current train perplexity12.738256454467773
INFO:root:current mean train loss 3218.7653492236373
INFO:root:current train perplexity12.675103187561035
INFO:root:current mean train loss 3212.5344560731132
INFO:root:current train perplexity12.595747947692871
INFO:root:current mean train loss 3207.7732102030423
INFO:root:current train perplexity12.545263290405273
INFO:root:current mean train loss 3202.2287774868964
INFO:root:current train perplexity12.501633644104004
INFO:root:current mean train loss 3199.6461235483357
INFO:root:current train perplexity12.472508430480957
INFO:root:current mean train loss 3196.013682129208
INFO:root:current train perplexity12.443866729736328
INFO:root:current mean train loss 3192.8689616737565
INFO:root:current train perplexity12.402999877929688
INFO:root:current mean train loss 3186.318368770186
INFO:root:current train perplexity12.342103004455566
INFO:root:current mean train loss 3181.3706357477854
INFO:root:current train perplexity12.295853614807129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.03s/it]
INFO:root:final mean train loss: 3177.3070057278865
INFO:root:final train perplexity: 12.253547668457031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 2529.681006465398
INFO:root:eval perplexity: 7.735788822174072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it]
INFO:root:eval mean loss: 2900.3571781672485
INFO:root:eval perplexity: 10.718721389770508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:35:08<4:14:30, 391.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3001.032721625434
INFO:root:current train perplexity10.924952507019043
INFO:root:current mean train loss 3057.4177946202894
INFO:root:current train perplexity11.268839836120605
INFO:root:current mean train loss 3041.6184744107522
INFO:root:current train perplexity11.102907180786133
INFO:root:current mean train loss 3033.090851556687
INFO:root:current train perplexity11.019109725952148
INFO:root:current mean train loss 3018.256261983049
INFO:root:current train perplexity10.887910842895508
INFO:root:current mean train loss 3005.230173594916
INFO:root:current train perplexity10.812287330627441
INFO:root:current mean train loss 2996.801285653744
INFO:root:current train perplexity10.737503051757812
INFO:root:current mean train loss 2989.539556088655
INFO:root:current train perplexity10.68133544921875
INFO:root:current mean train loss 2983.922259901129
INFO:root:current train perplexity10.631208419799805
INFO:root:current mean train loss 2979.700945992755
INFO:root:current train perplexity10.546430587768555
INFO:root:current mean train loss 2974.043383741931
INFO:root:current train perplexity10.489089012145996
INFO:root:current mean train loss 2969.0604460810273
INFO:root:current train perplexity10.426892280578613
INFO:root:current mean train loss 2964.091209041262
INFO:root:current train perplexity10.368669509887695
INFO:root:current mean train loss 2957.6499769016655
INFO:root:current train perplexity10.317161560058594
INFO:root:current mean train loss 2952.6992464623413
INFO:root:current train perplexity10.272773742675781
INFO:root:current mean train loss 2951.2197575569153
INFO:root:current train perplexity10.247209548950195
INFO:root:current mean train loss 2946.816111818794
INFO:root:current train perplexity10.204453468322754
INFO:root:current mean train loss 2942.0088780838223
INFO:root:current train perplexity10.159679412841797
INFO:root:current mean train loss 2935.4331997474555
INFO:root:current train perplexity10.127154350280762
INFO:root:current mean train loss 2931.3711499931396
INFO:root:current train perplexity10.0844087600708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.26s/it]
INFO:root:final mean train loss: 2928.106020497963
INFO:root:final train perplexity: 10.067179679870605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 2410.8966700777096
INFO:root:eval perplexity: 7.027222633361816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 2804.199836460411
INFO:root:eval perplexity: 9.908090591430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:41:48<4:09:39, 394.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2864.1649653596696
INFO:root:current train perplexity9.358118057250977
INFO:root:current mean train loss 2847.8406942529614
INFO:root:current train perplexity9.326898574829102
INFO:root:current mean train loss 2827.0431685014205
INFO:root:current train perplexity9.198585510253906
INFO:root:current mean train loss 2825.5292491534615
INFO:root:current train perplexity9.18946647644043
INFO:root:current mean train loss 2820.1772784302566
INFO:root:current train perplexity9.176019668579102
INFO:root:current mean train loss 2814.7288109777633
INFO:root:current train perplexity9.135406494140625
INFO:root:current mean train loss 2807.7849554789195
INFO:root:current train perplexity9.096149444580078
INFO:root:current mean train loss 2800.1454011428245
INFO:root:current train perplexity9.07554817199707
INFO:root:current mean train loss 2795.689785991995
INFO:root:current train perplexity9.044730186462402
INFO:root:current mean train loss 2792.044291669399
INFO:root:current train perplexity9.0094575881958
INFO:root:current mean train loss 2792.1317503839477
INFO:root:current train perplexity9.016490936279297
INFO:root:current mean train loss 2787.405965416305
INFO:root:current train perplexity9.00243854522705
INFO:root:current mean train loss 2785.6223304304044
INFO:root:current train perplexity8.99384880065918
INFO:root:current mean train loss 2784.1886784792473
INFO:root:current train perplexity8.97749137878418
INFO:root:current mean train loss 2781.9405478092203
INFO:root:current train perplexity8.964021682739258
INFO:root:current mean train loss 2784.005707985804
INFO:root:current train perplexity8.968472480773926
INFO:root:current mean train loss 2783.0011701912717
INFO:root:current train perplexity8.957296371459961
INFO:root:current mean train loss 2781.26881846522
INFO:root:current train perplexity8.951254844665527
INFO:root:current mean train loss 2777.717431139959
INFO:root:current train perplexity8.933679580688477
INFO:root:current mean train loss 2776.138169592854
INFO:root:current train perplexity8.923836708068848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.24s/it]
INFO:root:final mean train loss: 2774.684161995615
INFO:root:final train perplexity: 8.91988468170166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.10s/it]
INFO:root:eval mean loss: 2363.6685241266346
INFO:root:eval perplexity: 6.7638773918151855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 2769.880889243268
INFO:root:eval perplexity: 9.633867263793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:48:26<4:03:47, 395.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2710.0540143694197
INFO:root:current train perplexity8.596025466918945
INFO:root:current mean train loss 2720.0659122242646
INFO:root:current train perplexity8.62485408782959
INFO:root:current mean train loss 2730.8399423104747
INFO:root:current train perplexity8.663516998291016
INFO:root:current mean train loss 2734.149275496199
INFO:root:current train perplexity8.633530616760254
INFO:root:current mean train loss 2726.0670991938164
INFO:root:current train perplexity8.61546802520752
INFO:root:current mean train loss 2726.792162657621
INFO:root:current train perplexity8.615601539611816
INFO:root:current mean train loss 2723.9688768073693
INFO:root:current train perplexity8.60704231262207
INFO:root:current mean train loss 2722.5531982421876
INFO:root:current train perplexity8.595945358276367
INFO:root:current mean train loss 2723.863451867816
INFO:root:current train perplexity8.591972351074219
INFO:root:current mean train loss 2724.498483056137
INFO:root:current train perplexity8.601819038391113
INFO:root:current mean train loss 2725.61742684908
INFO:root:current train perplexity8.594544410705566
INFO:root:current mean train loss 2726.3329879891157
INFO:root:current train perplexity8.593754768371582
INFO:root:current mean train loss 2727.340562138595
INFO:root:current train perplexity8.595304489135742
INFO:root:current mean train loss 2727.0187083000683
INFO:root:current train perplexity8.588829040527344
INFO:root:current mean train loss 2727.309021743463
INFO:root:current train perplexity8.579608917236328
INFO:root:current mean train loss 2727.9056318732582
INFO:root:current train perplexity8.578817367553711
INFO:root:current mean train loss 2726.3342681336544
INFO:root:current train perplexity8.570390701293945
INFO:root:current mean train loss 2724.5867969577594
INFO:root:current train perplexity8.562522888183594
INFO:root:current mean train loss 2721.6058017995906
INFO:root:current train perplexity8.5489501953125
INFO:root:current mean train loss 2721.180946745122
INFO:root:current train perplexity8.543244361877441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.37s/it]
INFO:root:final mean train loss: 2719.6581173125865
INFO:root:final train perplexity: 8.541068077087402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2342.7381332072805
INFO:root:eval perplexity: 6.650346279144287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it]
INFO:root:eval mean loss: 2752.9868064501607
INFO:root:eval perplexity: 9.501675605773926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:54:58<3:56:29, 394.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2691.521967043822
INFO:root:current train perplexity8.248468399047852
INFO:root:current mean train loss 2695.5132749832887
INFO:root:current train perplexity8.370811462402344
INFO:root:current mean train loss 2693.242040335094
INFO:root:current train perplexity8.353769302368164
INFO:root:current mean train loss 2699.8445221656975
INFO:root:current train perplexity8.375697135925293
INFO:root:current mean train loss 2696.0257505694944
INFO:root:current train perplexity8.375277519226074
INFO:root:current mean train loss 2692.585099852268
INFO:root:current train perplexity8.371366500854492
INFO:root:current mean train loss 2691.6575563477986
INFO:root:current train perplexity8.368241310119629
INFO:root:current mean train loss 2692.1227431727484
INFO:root:current train perplexity8.367950439453125
INFO:root:current mean train loss 2691.708723444546
INFO:root:current train perplexity8.36209487915039
INFO:root:current mean train loss 2690.9450545074246
INFO:root:current train perplexity8.352371215820312
INFO:root:current mean train loss 2689.539392887175
INFO:root:current train perplexity8.34253978729248
INFO:root:current mean train loss 2690.627235110507
INFO:root:current train perplexity8.359868049621582
INFO:root:current mean train loss 2690.916456861281
INFO:root:current train perplexity8.358419418334961
INFO:root:current mean train loss 2692.4998649921704
INFO:root:current train perplexity8.362092971801758
INFO:root:current mean train loss 2692.263402942691
INFO:root:current train perplexity8.360663414001465
INFO:root:current mean train loss 2693.6500384902233
INFO:root:current train perplexity8.358774185180664
INFO:root:current mean train loss 2693.974406768672
INFO:root:current train perplexity8.359637260437012
INFO:root:current mean train loss 2692.84886096854
INFO:root:current train perplexity8.360442161560059
INFO:root:current mean train loss 2693.179506496961
INFO:root:current train perplexity8.360471725463867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.81s/it]
INFO:root:final mean train loss: 2693.7429992090974
INFO:root:final train perplexity: 8.368273735046387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it]
INFO:root:eval mean loss: 2337.4035713791
INFO:root:eval perplexity: 6.62171745300293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 2748.463787105912
INFO:root:eval perplexity: 9.466593742370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [7:01:22<3:48:11, 391.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2750.0775146484375
INFO:root:current train perplexity8.368145942687988
INFO:root:current mean train loss 2682.3596308781553
INFO:root:current train perplexity8.288860321044922
INFO:root:current mean train loss 2670.662523456648
INFO:root:current train perplexity8.274420738220215
INFO:root:current mean train loss 2671.5187811600535
INFO:root:current train perplexity8.264290809631348
INFO:root:current mean train loss 2676.506307167582
INFO:root:current train perplexity8.29885482788086
INFO:root:current mean train loss 2676.4103490435887
INFO:root:current train perplexity8.276408195495605
INFO:root:current mean train loss 2674.6368113132503
INFO:root:current train perplexity8.254578590393066
INFO:root:current mean train loss 2671.7257440740414
INFO:root:current train perplexity8.242063522338867
INFO:root:current mean train loss 2665.1424524107974
INFO:root:current train perplexity8.217623710632324
INFO:root:current mean train loss 2666.7640710341193
INFO:root:current train perplexity8.207794189453125
INFO:root:current mean train loss 2668.3856461361584
INFO:root:current train perplexity8.213791847229004
INFO:root:current mean train loss 2670.1702642026153
INFO:root:current train perplexity8.21902847290039
INFO:root:current mean train loss 2670.5802194589
INFO:root:current train perplexity8.215511322021484
INFO:root:current mean train loss 2670.625532653434
INFO:root:current train perplexity8.210394859313965
INFO:root:current mean train loss 2672.2374719690392
INFO:root:current train perplexity8.211262702941895
INFO:root:current mean train loss 2672.4501902803463
INFO:root:current train perplexity8.208985328674316
INFO:root:current mean train loss 2671.247017648749
INFO:root:current train perplexity8.2044095993042
INFO:root:current mean train loss 2670.038977967741
INFO:root:current train perplexity8.19597339630127
INFO:root:current mean train loss 2666.5492105758904
INFO:root:current train perplexity8.184731483459473
INFO:root:current mean train loss 2665.505595872382
INFO:root:current train perplexity8.180606842041016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.75s/it]
INFO:root:final mean train loss: 2664.5898086617103
INFO:root:final train perplexity: 8.17806625366211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 2318.056922425615
INFO:root:eval perplexity: 6.518918037414551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it]
INFO:root:eval mean loss: 2731.6336254363364
INFO:root:eval perplexity: 9.337186813354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [7:07:51<3:41:20, 390.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2736.2289225260415
INFO:root:current train perplexity8.239692687988281
INFO:root:current mean train loss 2665.020057867381
INFO:root:current train perplexity8.113225936889648
INFO:root:current mean train loss 2653.4008037860576
INFO:root:current train perplexity8.076727867126465
INFO:root:current mean train loss 2656.336916344188
INFO:root:current train perplexity8.082218170166016
INFO:root:current mean train loss 2653.579793390922
INFO:root:current train perplexity8.086525917053223
INFO:root:current mean train loss 2650.8021537795407
INFO:root:current train perplexity8.056705474853516
INFO:root:current mean train loss 2650.0884760121025
INFO:root:current train perplexity8.059981346130371
INFO:root:current mean train loss 2648.815743921203
INFO:root:current train perplexity8.065582275390625
INFO:root:current mean train loss 2648.549620912949
INFO:root:current train perplexity8.064630508422852
INFO:root:current mean train loss 2647.83762448256
INFO:root:current train perplexity8.062662124633789
INFO:root:current mean train loss 2646.00327617111
INFO:root:current train perplexity8.051349639892578
INFO:root:current mean train loss 2644.8837359221675
INFO:root:current train perplexity8.039786338806152
INFO:root:current mean train loss 2642.1466807272473
INFO:root:current train perplexity8.024646759033203
INFO:root:current mean train loss 2641.5170482603735
INFO:root:current train perplexity8.01970386505127
INFO:root:current mean train loss 2639.1749175660298
INFO:root:current train perplexity8.015206336975098
INFO:root:current mean train loss 2639.0099323982477
INFO:root:current train perplexity8.005538940429688
INFO:root:current mean train loss 2638.3355950103137
INFO:root:current train perplexity7.999977111816406
INFO:root:current mean train loss 2637.195056017577
INFO:root:current train perplexity7.999195098876953
INFO:root:current mean train loss 2635.8374602617896
INFO:root:current train perplexity8.000532150268555
INFO:root:current mean train loss 2637.551480374195
INFO:root:current train perplexity8.00439167022705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.10s/it]
INFO:root:final mean train loss: 2637.355738314245
INFO:root:final train perplexity: 8.004288673400879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 2309.786161815021
INFO:root:eval perplexity: 6.475459575653076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it]
INFO:root:eval mean loss: 2725.3503179888353
INFO:root:eval perplexity: 9.289329528808594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:14:18<3:34:15, 389.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2614.2102179276317
INFO:root:current train perplexity7.824007034301758
INFO:root:current mean train loss 2605.7531083701315
INFO:root:current train perplexity7.786981582641602
INFO:root:current mean train loss 2621.8031590565915
INFO:root:current train perplexity7.816961288452148
INFO:root:current mean train loss 2618.9117857803253
INFO:root:current train perplexity7.829153537750244
INFO:root:current mean train loss 2620.920710036744
INFO:root:current train perplexity7.842163562774658
INFO:root:current mean train loss 2625.218178220841
INFO:root:current train perplexity7.878261089324951
INFO:root:current mean train loss 2625.886644512882
INFO:root:current train perplexity7.887524604797363
INFO:root:current mean train loss 2626.551769060171
INFO:root:current train perplexity7.889883041381836
INFO:root:current mean train loss 2624.050181386579
INFO:root:current train perplexity7.888201713562012
INFO:root:current mean train loss 2620.945313801389
INFO:root:current train perplexity7.874345779418945
INFO:root:current mean train loss 2621.5235186450054
INFO:root:current train perplexity7.879185199737549
INFO:root:current mean train loss 2621.64124414749
INFO:root:current train perplexity7.882606506347656
INFO:root:current mean train loss 2619.948162319202
INFO:root:current train perplexity7.871370315551758
INFO:root:current mean train loss 2618.700269576502
INFO:root:current train perplexity7.869128227233887
INFO:root:current mean train loss 2616.0744072034727
INFO:root:current train perplexity7.862283229827881
INFO:root:current mean train loss 2615.0930537706236
INFO:root:current train perplexity7.861061096191406
INFO:root:current mean train loss 2615.303607945332
INFO:root:current train perplexity7.85711669921875
INFO:root:current mean train loss 2613.2771852973965
INFO:root:current train perplexity7.845206260681152
INFO:root:current mean train loss 2612.5730376300667
INFO:root:current train perplexity7.842737674713135
INFO:root:current mean train loss 2610.982011698594
INFO:root:current train perplexity7.832852363586426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.59s/it]
INFO:root:final mean train loss: 2609.358830762162
INFO:root:final train perplexity: 7.82949161529541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 2293.064719342171
INFO:root:eval perplexity: 6.3884782791137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it]
INFO:root:eval mean loss: 2712.043179992243
INFO:root:eval perplexity: 9.1887845993042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:20:49<3:28:00, 390.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2589.2285023082386
INFO:root:current train perplexity7.719624996185303
INFO:root:current mean train loss 2583.0931530367943
INFO:root:current train perplexity7.70097017288208
INFO:root:current mean train loss 2582.1126397824755
INFO:root:current train perplexity7.746425151824951
INFO:root:current mean train loss 2580.242811949824
INFO:root:current train perplexity7.726865291595459
INFO:root:current mean train loss 2586.415845531422
INFO:root:current train perplexity7.7333269119262695
INFO:root:current mean train loss 2585.602881299268
INFO:root:current train perplexity7.7116780281066895
INFO:root:current mean train loss 2584.7714881023376
INFO:root:current train perplexity7.695685863494873
INFO:root:current mean train loss 2584.9780153792426
INFO:root:current train perplexity7.688368797302246
INFO:root:current mean train loss 2586.4310341282894
INFO:root:current train perplexity7.69162130355835
INFO:root:current mean train loss 2588.494988853894
INFO:root:current train perplexity7.6953887939453125
INFO:root:current mean train loss 2588.0175848359745
INFO:root:current train perplexity7.690398216247559
INFO:root:current mean train loss 2587.2118117559526
INFO:root:current train perplexity7.689853668212891
INFO:root:current mean train loss 2588.079855383155
INFO:root:current train perplexity7.6887922286987305
INFO:root:current mean train loss 2586.104792363353
INFO:root:current train perplexity7.677418231964111
INFO:root:current mean train loss 2585.6725988643684
INFO:root:current train perplexity7.676351547241211
INFO:root:current mean train loss 2586.6365972292
INFO:root:current train perplexity7.678242206573486
INFO:root:current mean train loss 2585.83664808936
INFO:root:current train perplexity7.675013542175293
INFO:root:current mean train loss 2584.3424454126603
INFO:root:current train perplexity7.665116786956787
INFO:root:current mean train loss 2581.884193243556
INFO:root:current train perplexity7.658642768859863
INFO:root:current mean train loss 2581.3323342091594
INFO:root:current train perplexity7.657561779022217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.99s/it]
INFO:root:final mean train loss: 2581.029125188615
INFO:root:final train perplexity: 7.65649938583374
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.57s/it]
INFO:root:eval mean loss: 2278.100936997867
INFO:root:eval perplexity: 6.311631679534912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.89s/it]
INFO:root:eval mean loss: 2699.620863028452
INFO:root:eval perplexity: 9.095904350280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:27:04<3:19:07, 385.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2570.3692084418403
INFO:root:current train perplexity7.558509826660156
INFO:root:current mean train loss 2570.4365873115007
INFO:root:current train perplexity7.539151668548584
INFO:root:current mean train loss 2570.0050506591797
INFO:root:current train perplexity7.58494758605957
INFO:root:current mean train loss 2569.6232352308048
INFO:root:current train perplexity7.605712890625
INFO:root:current mean train loss 2574.6581762281517
INFO:root:current train perplexity7.6122727394104
INFO:root:current mean train loss 2575.2774329552285
INFO:root:current train perplexity7.607929229736328
INFO:root:current mean train loss 2574.46594056629
INFO:root:current train perplexity7.605118274688721
INFO:root:current mean train loss 2577.876222916835
INFO:root:current train perplexity7.610946178436279
INFO:root:current mean train loss 2579.1971729523543
INFO:root:current train perplexity7.629664897918701
INFO:root:current mean train loss 2579.3357827771347
INFO:root:current train perplexity7.6274094581604
INFO:root:current mean train loss 2578.45900191122
INFO:root:current train perplexity7.626462459564209
INFO:root:current mean train loss 2575.7811550101324
INFO:root:current train perplexity7.612552165985107
INFO:root:current mean train loss 2574.3754965344315
INFO:root:current train perplexity7.604632377624512
INFO:root:current mean train loss 2573.950990371037
INFO:root:current train perplexity7.601728439331055
INFO:root:current mean train loss 2570.3161702363386
INFO:root:current train perplexity7.591346740722656
INFO:root:current mean train loss 2571.868504182073
INFO:root:current train perplexity7.596961498260498
INFO:root:current mean train loss 2571.6956290651165
INFO:root:current train perplexity7.596700668334961
INFO:root:current mean train loss 2572.061487753289
INFO:root:current train perplexity7.59705924987793
INFO:root:current mean train loss 2574.017347026075
INFO:root:current train perplexity7.610363960266113
INFO:root:current mean train loss 2578.7999660035416
INFO:root:current train perplexity7.6356940269470215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.73s/it]
INFO:root:final mean train loss: 2577.8570293786247
INFO:root:final train perplexity: 7.637369155883789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it]
INFO:root:eval mean loss: 2290.336928347324
INFO:root:eval perplexity: 6.374400615692139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.67s/it]
INFO:root:eval mean loss: 2708.877394223044
INFO:root:eval perplexity: 9.165023803710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:33:22<3:11:39, 383.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2646.675528879916
INFO:root:current train perplexity8.076725959777832
INFO:root:current mean train loss 2655.056357731895
INFO:root:current train perplexity8.104837417602539
INFO:root:current mean train loss 2663.2176712194528
INFO:root:current train perplexity8.110371589660645
INFO:root:current mean train loss 2658.5529571768557
INFO:root:current train perplexity8.10828971862793
INFO:root:current mean train loss 2658.1217802394876
INFO:root:current train perplexity8.127057075500488
INFO:root:current mean train loss 2660.2313532934527
INFO:root:current train perplexity8.145638465881348
INFO:root:current mean train loss 2661.772636336062
INFO:root:current train perplexity8.160653114318848
INFO:root:current mean train loss 2670.0665173355314
INFO:root:current train perplexity8.197176933288574
INFO:root:current mean train loss 2665.6689249903334
INFO:root:current train perplexity8.20285415649414
INFO:root:current mean train loss 2667.555288841317
INFO:root:current train perplexity8.210735321044922
INFO:root:current mean train loss 2665.0496121100923
INFO:root:current train perplexity8.197128295898438
INFO:root:current mean train loss 2665.4732788188603
INFO:root:current train perplexity8.20032787322998
INFO:root:current mean train loss 2663.695811198422
INFO:root:current train perplexity8.189579963684082
INFO:root:current mean train loss 2665.9799519944654
INFO:root:current train perplexity8.19448184967041
INFO:root:current mean train loss 2670.3580018114612
INFO:root:current train perplexity8.20741081237793
INFO:root:current mean train loss 2670.8608582810534
INFO:root:current train perplexity8.204017639160156
INFO:root:current mean train loss 2670.1571266802193
INFO:root:current train perplexity8.208314895629883
INFO:root:current mean train loss 2672.587517931849
INFO:root:current train perplexity8.216780662536621
INFO:root:current mean train loss 2674.3595723545445
INFO:root:current train perplexity8.229500770568848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.74s/it]
INFO:root:final mean train loss: 2672.357989628148
INFO:root:final train perplexity: 8.228323936462402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.59s/it]
INFO:root:eval mean loss: 2307.0291825964096
INFO:root:eval perplexity: 6.461036682128906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.70s/it]
INFO:root:eval mean loss: 2722.7471516927085
INFO:root:eval perplexity: 9.269575119018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:39:30<3:02:56, 378.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2718.173299153646
INFO:root:current train perplexity8.461527824401855
INFO:root:current mean train loss 2683.912367334906
INFO:root:current train perplexity8.304323196411133
INFO:root:current mean train loss 2678.5119391876515
INFO:root:current train perplexity8.252837181091309
INFO:root:current mean train loss 2685.5478012982535
INFO:root:current train perplexity8.309501647949219
INFO:root:current mean train loss 2688.7540433536024
INFO:root:current train perplexity8.332536697387695
INFO:root:current mean train loss 2691.865149939013
INFO:root:current train perplexity8.316137313842773
INFO:root:current mean train loss 2690.6062164810232
INFO:root:current train perplexity8.323617935180664
INFO:root:current mean train loss 2687.943986671167
INFO:root:current train perplexity8.319396018981934
INFO:root:current mean train loss 2686.7725472651405
INFO:root:current train perplexity8.312167167663574
INFO:root:current mean train loss 2685.8420827836126
INFO:root:current train perplexity8.305386543273926
INFO:root:current mean train loss 2686.097494136742
INFO:root:current train perplexity8.307321548461914
INFO:root:current mean train loss 2686.0440916644297
INFO:root:current train perplexity8.305215835571289
INFO:root:current mean train loss 2685.0605418140417
INFO:root:current train perplexity8.296975135803223
INFO:root:current mean train loss 2684.9439572017372
INFO:root:current train perplexity8.298276901245117
INFO:root:current mean train loss 2685.974365581659
INFO:root:current train perplexity8.305912971496582
INFO:root:current mean train loss 2685.1919214418367
INFO:root:current train perplexity8.300760269165039
INFO:root:current mean train loss 2684.542194827259
INFO:root:current train perplexity8.302970886230469
INFO:root:current mean train loss 2684.940918254964
INFO:root:current train perplexity8.298664093017578
INFO:root:current mean train loss 2685.0012851854494
INFO:root:current train perplexity8.294571876525879
INFO:root:current mean train loss 2683.359790141535
INFO:root:current train perplexity8.294168472290039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.71s/it]
INFO:root:final mean train loss: 2682.9617456387105
INFO:root:final train perplexity: 8.297422409057617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it]
INFO:root:eval mean loss: 2308.661667411209
INFO:root:eval perplexity: 6.469571590423584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 2724.9746240926975
INFO:root:eval perplexity: 9.28647518157959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:46:04<2:58:54, 383.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2716.5443592900815
INFO:root:current train perplexity8.553661346435547
INFO:root:current mean train loss 2703.1047006002286
INFO:root:current train perplexity8.496788024902344
INFO:root:current mean train loss 2686.7721730048347
INFO:root:current train perplexity8.380163192749023
INFO:root:current mean train loss 2689.824764476103
INFO:root:current train perplexity8.342730522155762
INFO:root:current mean train loss 2691.7925791638963
INFO:root:current train perplexity8.340513229370117
INFO:root:current mean train loss 2691.5318638526232
INFO:root:current train perplexity8.33137321472168
INFO:root:current mean train loss 2690.5949032999347
INFO:root:current train perplexity8.325837135314941
INFO:root:current mean train loss 2693.870539284016
INFO:root:current train perplexity8.341927528381348
INFO:root:current mean train loss 2694.4188328832206
INFO:root:current train perplexity8.347274780273438
INFO:root:current mean train loss 2690.2972450462994
INFO:root:current train perplexity8.333889961242676
INFO:root:current mean train loss 2687.8042832241263
INFO:root:current train perplexity8.324882507324219
INFO:root:current mean train loss 2688.954274613201
INFO:root:current train perplexity8.327019691467285
INFO:root:current mean train loss 2688.651473587298
INFO:root:current train perplexity8.326807975769043
INFO:root:current mean train loss 2689.165106602537
INFO:root:current train perplexity8.326186180114746
INFO:root:current mean train loss 2686.1806450185018
INFO:root:current train perplexity8.320496559143066
INFO:root:current mean train loss 2685.1169345427406
INFO:root:current train perplexity8.317315101623535
INFO:root:current mean train loss 2686.3346275945396
INFO:root:current train perplexity8.32090950012207
INFO:root:current mean train loss 2686.771780942805
INFO:root:current train perplexity8.31710147857666
INFO:root:current mean train loss 2687.0075241649665
INFO:root:current train perplexity8.322782516479492
INFO:root:current mean train loss 2687.729466414985
INFO:root:current train perplexity8.324664115905762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.63s/it]
INFO:root:final mean train loss: 2686.767221147823
INFO:root:final train perplexity: 8.32236385345459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it]
INFO:root:eval mean loss: 2312.5069086602393
INFO:root:eval perplexity: 6.4897236824035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.44s/it]
INFO:root:eval mean loss: 2728.3931075292276
INFO:root:eval perplexity: 9.312475204467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:52:31<2:52:55, 384.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2627.123504638672
INFO:root:current train perplexity8.171123504638672
INFO:root:current mean train loss 2671.620223563058
INFO:root:current train perplexity8.281545639038086
INFO:root:current mean train loss 2676.7543782552084
INFO:root:current train perplexity8.269153594970703
INFO:root:current mean train loss 2688.074356617647
INFO:root:current train perplexity8.315608024597168
INFO:root:current mean train loss 2701.509452126243
INFO:root:current train perplexity8.38109016418457
INFO:root:current mean train loss 2698.5080326786747
INFO:root:current train perplexity8.38681697845459
INFO:root:current mean train loss 2705.4048572540282
INFO:root:current train perplexity8.414041519165039
INFO:root:current mean train loss 2707.8705543311867
INFO:root:current train perplexity8.42302131652832
INFO:root:current mean train loss 2706.713677687872
INFO:root:current train perplexity8.414520263671875
INFO:root:current mean train loss 2709.702741906998
INFO:root:current train perplexity8.426217079162598
INFO:root:current mean train loss 2709.269375375601
INFO:root:current train perplexity8.432130813598633
INFO:root:current mean train loss 2711.113947496916
INFO:root:current train perplexity8.438122749328613
INFO:root:current mean train loss 2711.386076108871
INFO:root:current train perplexity8.441444396972656
INFO:root:current mean train loss 2711.768368849114
INFO:root:current train perplexity8.445518493652344
INFO:root:current mean train loss 2707.7867535061305
INFO:root:current train perplexity8.429266929626465
INFO:root:current mean train loss 2709.0207573432426
INFO:root:current train perplexity8.430301666259766
INFO:root:current mean train loss 2708.5228750833653
INFO:root:current train perplexity8.432378768920898
INFO:root:current mean train loss 2706.886229907507
INFO:root:current train perplexity8.43317699432373
INFO:root:current mean train loss 2706.1107232135273
INFO:root:current train perplexity8.434232711791992
INFO:root:current mean train loss 2705.878042445232
INFO:root:current train perplexity8.440452575683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.11s/it]
INFO:root:final mean train loss: 2704.5713995290535
INFO:root:final train perplexity: 8.440045356750488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.06s/it]
INFO:root:eval mean loss: 2321.9128335722794
INFO:root:eval perplexity: 6.539278507232666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it]
INFO:root:eval mean loss: 2736.77887006178
INFO:root:eval perplexity: 9.376561164855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:58:37<2:44:09, 378.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2732.7897820723683
INFO:root:current train perplexity8.428119659423828
INFO:root:current mean train loss 2726.0219493307127
INFO:root:current train perplexity8.48383903503418
INFO:root:current mean train loss 2729.349443131384
INFO:root:current train perplexity8.514558792114258
INFO:root:current mean train loss 2730.8693539915967
INFO:root:current train perplexity8.509560585021973
INFO:root:current mean train loss 2722.6442390291645
INFO:root:current train perplexity8.511734008789062
INFO:root:current mean train loss 2727.2758434028556
INFO:root:current train perplexity8.530277252197266
INFO:root:current mean train loss 2731.3817612460757
INFO:root:current train perplexity8.562698364257812
INFO:root:current mean train loss 2730.4194416565183
INFO:root:current train perplexity8.559925079345703
INFO:root:current mean train loss 2729.5867941287743
INFO:root:current train perplexity8.554377555847168
INFO:root:current mean train loss 2729.3656665319686
INFO:root:current train perplexity8.560269355773926
INFO:root:current mean train loss 2730.1993760440073
INFO:root:current train perplexity8.563639640808105
INFO:root:current mean train loss 2729.5876648423996
INFO:root:current train perplexity8.563149452209473
INFO:root:current mean train loss 2730.356944664566
INFO:root:current train perplexity8.575173377990723
INFO:root:current mean train loss 2728.4579477218817
INFO:root:current train perplexity8.572999954223633
INFO:root:current mean train loss 2727.515150961683
INFO:root:current train perplexity8.571659088134766
INFO:root:current mean train loss 2727.485385274918
INFO:root:current train perplexity8.571093559265137
INFO:root:current mean train loss 2728.0213404248548
INFO:root:current train perplexity8.581316947937012
INFO:root:current mean train loss 2729.1718226146754
INFO:root:current train perplexity8.587936401367188
INFO:root:current mean train loss 2729.994268677218
INFO:root:current train perplexity8.593886375427246
INFO:root:current mean train loss 2729.3050568921262
INFO:root:current train perplexity8.599529266357422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.80s/it]
INFO:root:final mean train loss: 2728.4218546241686
INFO:root:final train perplexity: 8.600301742553711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.45s/it]
INFO:root:eval mean loss: 2327.437994774352
INFO:root:eval perplexity: 6.568563461303711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it]
INFO:root:eval mean loss: 2740.7542010368184
INFO:root:eval perplexity: 9.407094955444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [8:04:57<2:38:04, 379.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2734.085412927576
INFO:root:current train perplexity8.779348373413086
INFO:root:current mean train loss 2744.5173929148705
INFO:root:current train perplexity8.684805870056152
INFO:root:current mean train loss 2740.6945257256502
INFO:root:current train perplexity8.703696250915527
INFO:root:current mean train loss 2736.513587666068
INFO:root:current train perplexity8.675539016723633
INFO:root:current mean train loss 2727.0962753617814
INFO:root:current train perplexity8.632750511169434
INFO:root:current mean train loss 2728.378472411259
INFO:root:current train perplexity8.624656677246094
INFO:root:current mean train loss 2727.311664343588
INFO:root:current train perplexity8.629215240478516
INFO:root:current mean train loss 2726.662862930495
INFO:root:current train perplexity8.618087768554688
INFO:root:current mean train loss 2731.467172862736
INFO:root:current train perplexity8.638675689697266
INFO:root:current mean train loss 2736.695600255069
INFO:root:current train perplexity8.658409118652344
INFO:root:current mean train loss 2736.4166655300714
INFO:root:current train perplexity8.660594940185547
INFO:root:current mean train loss 2737.2587643157076
INFO:root:current train perplexity8.667411804199219
INFO:root:current mean train loss 2741.735207837642
INFO:root:current train perplexity8.68821907043457
INFO:root:current mean train loss 2745.0273545888485
INFO:root:current train perplexity8.706948280334473
INFO:root:current mean train loss 2749.126237266261
INFO:root:current train perplexity8.72960090637207
INFO:root:current mean train loss 2752.494860793311
INFO:root:current train perplexity8.751949310302734
INFO:root:current mean train loss 2754.385947388133
INFO:root:current train perplexity8.767481803894043
INFO:root:current mean train loss 2755.6579563695655
INFO:root:current train perplexity8.782280921936035
INFO:root:current mean train loss 2756.4343334674327
INFO:root:current train perplexity8.793970108032227
INFO:root:current mean train loss 2759.6514740454027
INFO:root:current train perplexity8.810131072998047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.16s/it]
INFO:root:final mean train loss: 2759.1255970549473
INFO:root:final train perplexity: 8.811101913452148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.49s/it]
INFO:root:eval mean loss: 2342.410264468362
INFO:root:eval perplexity: 6.648582458496094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it]
INFO:root:eval mean loss: 2753.039044319315
INFO:root:eval perplexity: 9.502080917358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [8:11:05<2:30:22, 375.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2831.7491709950204
INFO:root:current train perplexity9.112163543701172
INFO:root:current mean train loss 2833.4427177069697
INFO:root:current train perplexity9.223807334899902
INFO:root:current mean train loss 2830.261245570232
INFO:root:current train perplexity9.237822532653809
INFO:root:current mean train loss 2820.173732591712
INFO:root:current train perplexity9.206890106201172
INFO:root:current mean train loss 2816.8513969219384
INFO:root:current train perplexity9.20297908782959
INFO:root:current mean train loss 2815.478884934169
INFO:root:current train perplexity9.199488639831543
INFO:root:current mean train loss 2808.8040974640467
INFO:root:current train perplexity9.187076568603516
INFO:root:current mean train loss 2810.988928485007
INFO:root:current train perplexity9.205291748046875
INFO:root:current mean train loss 2811.144004059694
INFO:root:current train perplexity9.201094627380371
INFO:root:current mean train loss 2811.082097027545
INFO:root:current train perplexity9.19904613494873
INFO:root:current mean train loss 2812.7676119153157
INFO:root:current train perplexity9.196999549865723
INFO:root:current mean train loss 2813.283122769731
INFO:root:current train perplexity9.199745178222656
INFO:root:current mean train loss 2813.9255526163706
INFO:root:current train perplexity9.196918487548828
INFO:root:current mean train loss 2813.961870183883
INFO:root:current train perplexity9.194300651550293
INFO:root:current mean train loss 2814.6443367234656
INFO:root:current train perplexity9.194945335388184
INFO:root:current mean train loss 2817.5671194904935
INFO:root:current train perplexity9.203927040100098
INFO:root:current mean train loss 2818.9317919315495
INFO:root:current train perplexity9.214735984802246
INFO:root:current mean train loss 2821.692711468584
INFO:root:current train perplexity9.236227989196777
INFO:root:current mean train loss 2823.265600340635
INFO:root:current train perplexity9.25353717803955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.34s/it]
INFO:root:final mean train loss: 2822.984851031128
INFO:root:final train perplexity: 9.266220092773438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.12s/it]
INFO:root:eval mean loss: 2366.8414401872783
INFO:root:eval perplexity: 6.781257152557373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.58s/it]
INFO:root:eval mean loss: 2773.945760524019
INFO:root:eval perplexity: 9.665946960449219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:17:24<2:24:22, 376.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2791.0890502929688
INFO:root:current train perplexity9.229692459106445
INFO:root:current mean train loss 2889.329094780816
INFO:root:current train perplexity9.810334205627441
INFO:root:current mean train loss 2896.987783578726
INFO:root:current train perplexity9.817374229431152
INFO:root:current mean train loss 2893.583167138038
INFO:root:current train perplexity9.817299842834473
INFO:root:current mean train loss 2887.262104707606
INFO:root:current train perplexity9.756656646728516
INFO:root:current mean train loss 2884.7821006474533
INFO:root:current train perplexity9.73146915435791
INFO:root:current mean train loss 2890.8212717959755
INFO:root:current train perplexity9.735915184020996
INFO:root:current mean train loss 2895.924681582693
INFO:root:current train perplexity9.77905559539795
INFO:root:current mean train loss 2894.1586228172378
INFO:root:current train perplexity9.783862113952637
INFO:root:current mean train loss 2896.529361674439
INFO:root:current train perplexity9.801438331604004
INFO:root:current mean train loss 2903.1928979782833
INFO:root:current train perplexity9.842655181884766
INFO:root:current mean train loss 2907.4482941885717
INFO:root:current train perplexity9.875081062316895
INFO:root:current mean train loss 2911.02707313386
INFO:root:current train perplexity9.896831512451172
INFO:root:current mean train loss 2916.4737397640124
INFO:root:current train perplexity9.927704811096191
INFO:root:current mean train loss 2917.459792397239
INFO:root:current train perplexity9.954229354858398
INFO:root:current mean train loss 2918.7879729334177
INFO:root:current train perplexity9.971816062927246
INFO:root:current mean train loss 2920.118304200433
INFO:root:current train perplexity9.995680809020996
INFO:root:current mean train loss 2923.302132885685
INFO:root:current train perplexity10.02462100982666
INFO:root:current mean train loss 2925.7850410663978
INFO:root:current train perplexity10.040379524230957
INFO:root:current mean train loss 2927.289834332416
INFO:root:current train perplexity10.054215431213379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.40s/it]
INFO:root:final mean train loss: 2928.207132636689
INFO:root:final train perplexity: 10.067984580993652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it]
INFO:root:eval mean loss: 2402.670621398493
INFO:root:eval perplexity: 6.980628490447998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it]
INFO:root:eval mean loss: 2806.751309442182
INFO:root:eval perplexity: 9.928786277770996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:23:32<2:17:11, 374.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2933.86072265625
INFO:root:current train perplexity10.40194034576416
INFO:root:current mean train loss 2965.844732421875
INFO:root:current train perplexity10.427252769470215
INFO:root:current mean train loss 2961.088696831597
INFO:root:current train perplexity10.357316970825195
INFO:root:current mean train loss 2960.617072566106
INFO:root:current train perplexity10.389265060424805
INFO:root:current mean train loss 2965.0082864200367
INFO:root:current train perplexity10.46281909942627
INFO:root:current mean train loss 2969.4082393973213
INFO:root:current train perplexity10.495548248291016
INFO:root:current mean train loss 2974.246765234375
INFO:root:current train perplexity10.5306396484375
INFO:root:current mean train loss 2977.920909213362
INFO:root:current train perplexity10.540852546691895
INFO:root:current mean train loss 2976.3548218513256
INFO:root:current train perplexity10.532065391540527
INFO:root:current mean train loss 2978.962215741132
INFO:root:current train perplexity10.525707244873047
INFO:root:current mean train loss 2981.9856295255336
INFO:root:current train perplexity10.550837516784668
INFO:root:current mean train loss 2983.924213107639
INFO:root:current train perplexity10.56497859954834
INFO:root:current mean train loss 2985.8536690848214
INFO:root:current train perplexity10.568455696105957
INFO:root:current mean train loss 2987.567707473467
INFO:root:current train perplexity10.571476936340332
INFO:root:current mean train loss 2990.3840674684757
INFO:root:current train perplexity10.592273712158203
INFO:root:current mean train loss 2993.5489277023567
INFO:root:current train perplexity10.614201545715332
INFO:root:current mean train loss 2995.865992638221
INFO:root:current train perplexity10.627408981323242
INFO:root:current mean train loss 2998.4412957144473
INFO:root:current train perplexity10.645576477050781
INFO:root:current mean train loss 3002.1119983411813
INFO:root:current train perplexity10.660961151123047
INFO:root:current mean train loss 3002.4392434811284
INFO:root:current train perplexity10.669174194335938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.94s/it]
INFO:root:final mean train loss: 3001.827682887552
INFO:root:final train perplexity: 10.669848442077637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 2434.0600715799533
INFO:root:eval perplexity: 7.160106182098389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 2835.764989974651
INFO:root:eval perplexity: 10.167195320129395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:29:45<2:10:46, 373.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3003.0709344773068
INFO:root:current train perplexity11.000937461853027
INFO:root:current mean train loss 3046.233759490537
INFO:root:current train perplexity11.087886810302734
INFO:root:current mean train loss 3049.3033719653927
INFO:root:current train perplexity11.096534729003906
INFO:root:current mean train loss 3044.4833684553178
INFO:root:current train perplexity11.015128135681152
INFO:root:current mean train loss 3053.168231670673
INFO:root:current train perplexity11.024438858032227
INFO:root:current mean train loss 3055.623479751643
INFO:root:current train perplexity11.059885025024414
INFO:root:current mean train loss 3047.46517117224
INFO:root:current train perplexity11.017724990844727
INFO:root:current mean train loss 3043.133409690343
INFO:root:current train perplexity11.000622749328613
INFO:root:current mean train loss 3040.793529519559
INFO:root:current train perplexity10.985913276672363
INFO:root:current mean train loss 3041.2080847867733
INFO:root:current train perplexity10.994481086730957
INFO:root:current mean train loss 3039.465059306022
INFO:root:current train perplexity10.981152534484863
INFO:root:current mean train loss 3036.8483307365777
INFO:root:current train perplexity10.96875
INFO:root:current mean train loss 3037.8536673774656
INFO:root:current train perplexity10.968687057495117
INFO:root:current mean train loss 3037.3608600371995
INFO:root:current train perplexity10.961515426635742
INFO:root:current mean train loss 3042.1983710300906
INFO:root:current train perplexity10.996044158935547
INFO:root:current mean train loss 3043.6103325632293
INFO:root:current train perplexity11.009320259094238
INFO:root:current mean train loss 3045.853514286836
INFO:root:current train perplexity11.032013893127441
INFO:root:current mean train loss 3043.433202452282
INFO:root:current train perplexity11.024604797363281
INFO:root:current mean train loss 3044.304279406089
INFO:root:current train perplexity11.025835037231445
INFO:root:current mean train loss 3045.8257318687242
INFO:root:current train perplexity11.04403305053711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.47s/it]
INFO:root:final mean train loss: 3045.8259497722834
INFO:root:final train perplexity: 11.046586990356445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 2440.0110213908742
INFO:root:eval perplexity: 7.194649696350098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.64s/it]
INFO:root:eval mean loss: 2843.2750884793327
INFO:root:eval perplexity: 10.229836463928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:36:08<2:05:31, 376.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3091.071644928496
INFO:root:current train perplexity11.286378860473633
INFO:root:current mean train loss 3090.3464969659003
INFO:root:current train perplexity11.356816291809082
INFO:root:current mean train loss 3077.450943759049
INFO:root:current train perplexity11.264273643493652
INFO:root:current mean train loss 3073.291391016713
INFO:root:current train perplexity11.289167404174805
INFO:root:current mean train loss 3072.1571467779822
INFO:root:current train perplexity11.251575469970703
INFO:root:current mean train loss 3079.922824047546
INFO:root:current train perplexity11.299405097961426
INFO:root:current mean train loss 3087.1714219135292
INFO:root:current train perplexity11.312589645385742
INFO:root:current mean train loss 3086.3217294162755
INFO:root:current train perplexity11.300525665283203
INFO:root:current mean train loss 3081.27475881521
INFO:root:current train perplexity11.287735939025879
INFO:root:current mean train loss 3082.657856898462
INFO:root:current train perplexity11.309493064880371
INFO:root:current mean train loss 3083.7587814547187
INFO:root:current train perplexity11.330147743225098
INFO:root:current mean train loss 3083.1790747259897
INFO:root:current train perplexity11.329499244689941
INFO:root:current mean train loss 3080.37811953156
INFO:root:current train perplexity11.326701164245605
INFO:root:current mean train loss 3076.904202560189
INFO:root:current train perplexity11.307145118713379
INFO:root:current mean train loss 3075.4521245087067
INFO:root:current train perplexity11.30474853515625
INFO:root:current mean train loss 3074.9913999546484
INFO:root:current train perplexity11.30931568145752
INFO:root:current mean train loss 3074.7574482757404
INFO:root:current train perplexity11.304543495178223
INFO:root:current mean train loss 3075.346495089984
INFO:root:current train perplexity11.294754028320312
INFO:root:current mean train loss 3075.1888051476767
INFO:root:current train perplexity11.301340103149414
INFO:root:current mean train loss 3076.1541459539703
INFO:root:current train perplexity11.303622245788574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.19s/it]
INFO:root:final mean train loss: 3074.9275814023695
INFO:root:final train perplexity: 11.303050994873047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 2452.7375579184672
INFO:root:eval perplexity: 7.2690815925598145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.73s/it]
INFO:root:eval mean loss: 2854.0449958963595
INFO:root:eval perplexity: 10.320337295532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:42:18<1:58:37, 374.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3038.1959646124587
INFO:root:current train perplexity11.247978210449219
INFO:root:current mean train loss 3053.403854370117
INFO:root:current train perplexity11.369612693786621
INFO:root:current mean train loss 3055.0496383888135
INFO:root:current train perplexity11.313252449035645
INFO:root:current mean train loss 3059.2485637258974
INFO:root:current train perplexity11.302530288696289
INFO:root:current mean train loss 3057.6254421202075
INFO:root:current train perplexity11.271078109741211
INFO:root:current mean train loss 3059.1784727308486
INFO:root:current train perplexity11.2531156539917
INFO:root:current mean train loss 3062.0724368123615
INFO:root:current train perplexity11.28642463684082
INFO:root:current mean train loss 3070.4298504701596
INFO:root:current train perplexity11.298478126525879
INFO:root:current mean train loss 3071.8834496066993
INFO:root:current train perplexity11.296558380126953
INFO:root:current mean train loss 3076.3661486516235
INFO:root:current train perplexity11.32753849029541
INFO:root:current mean train loss 3079.3035357734084
INFO:root:current train perplexity11.343445777893066
INFO:root:current mean train loss 3081.1222689881615
INFO:root:current train perplexity11.350687980651855
INFO:root:current mean train loss 3081.110260105432
INFO:root:current train perplexity11.35280704498291
INFO:root:current mean train loss 3082.4244778655298
INFO:root:current train perplexity11.358200073242188
INFO:root:current mean train loss 3086.3976370958776
INFO:root:current train perplexity11.384403228759766
INFO:root:current mean train loss 3089.877669126249
INFO:root:current train perplexity11.419977188110352
INFO:root:current mean train loss 3091.414573214219
INFO:root:current train perplexity11.442030906677246
INFO:root:current mean train loss 3095.3518142012863
INFO:root:current train perplexity11.48241901397705
INFO:root:current mean train loss 3097.149945159457
INFO:root:current train perplexity11.49925422668457
INFO:root:current mean train loss 3100.5205038588056
INFO:root:current train perplexity11.52657413482666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.24s/it]
INFO:root:final mean train loss: 3099.5776460140687
INFO:root:final train perplexity: 11.52493953704834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.27s/it]
INFO:root:eval mean loss: 2473.468724027593
INFO:root:eval perplexity: 7.391984462738037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.25s/it]
INFO:root:eval mean loss: 2873.0359752465647
INFO:root:eval perplexity: 10.481877326965332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:48:31<1:52:13, 374.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3127.3795362903224
INFO:root:current train perplexity11.983500480651855
INFO:root:current mean train loss 3118.1741608140383
INFO:root:current train perplexity11.83946418762207
INFO:root:current mean train loss 3112.4556922261627
INFO:root:current train perplexity11.763657569885254
INFO:root:current mean train loss 3117.5643009253736
INFO:root:current train perplexity11.742955207824707
INFO:root:current mean train loss 3103.599089400038
INFO:root:current train perplexity11.673473358154297
INFO:root:current mean train loss 3106.3717327150084
INFO:root:current train perplexity11.669547080993652
INFO:root:current mean train loss 3110.0739633359262
INFO:root:current train perplexity11.675549507141113
INFO:root:current mean train loss 3112.272698920732
INFO:root:current train perplexity11.664164543151855
INFO:root:current mean train loss 3113.4887555881683
INFO:root:current train perplexity11.666525840759277
INFO:root:current mean train loss 3114.894115497939
INFO:root:current train perplexity11.661731719970703
INFO:root:current mean train loss 3114.905149468564
INFO:root:current train perplexity11.654335021972656
INFO:root:current mean train loss 3112.065926154521
INFO:root:current train perplexity11.641579627990723
INFO:root:current mean train loss 3113.969493750906
INFO:root:current train perplexity11.667740821838379
INFO:root:current mean train loss 3114.9655582951027
INFO:root:current train perplexity11.678141593933105
INFO:root:current mean train loss 3117.8261872462117
INFO:root:current train perplexity11.700197219848633
INFO:root:current mean train loss 3121.6138231716886
INFO:root:current train perplexity11.721302032470703
INFO:root:current mean train loss 3123.164176278472
INFO:root:current train perplexity11.733288764953613
INFO:root:current mean train loss 3124.8297778851347
INFO:root:current train perplexity11.741351127624512
INFO:root:current mean train loss 3123.7360868217197
INFO:root:current train perplexity11.740416526794434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.78s/it]
INFO:root:final mean train loss: 3123.581349552249
INFO:root:final train perplexity: 11.745195388793945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it]
INFO:root:eval mean loss: 2474.10882525072
INFO:root:eval perplexity: 7.395811557769775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.17s/it]
INFO:root:eval mean loss: 2874.224116332142
INFO:root:eval perplexity: 10.4920654296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:54:38<1:45:26, 372.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.7076904296873
INFO:root:current train perplexity12.608977317810059
INFO:root:current mean train loss 3131.8556906960225
INFO:root:current train perplexity11.918058395385742
INFO:root:current mean train loss 3130.858015950521
INFO:root:current train perplexity11.912842750549316
INFO:root:current mean train loss 3141.817937247984
INFO:root:current train perplexity12.005918502807617
INFO:root:current mean train loss 3146.193476086128
INFO:root:current train perplexity12.003777503967285
INFO:root:current mean train loss 3145.8628882314642
INFO:root:current train perplexity12.01618766784668
INFO:root:current mean train loss 3153.3694536052767
INFO:root:current train perplexity12.037300109863281
INFO:root:current mean train loss 3155.1489983357174
INFO:root:current train perplexity12.044571876525879
INFO:root:current mean train loss 3154.6097644193674
INFO:root:current train perplexity12.031383514404297
INFO:root:current mean train loss 3150.9874801468063
INFO:root:current train perplexity12.01492691040039
INFO:root:current mean train loss 3150.8457301980197
INFO:root:current train perplexity12.015419960021973
INFO:root:current mean train loss 3156.162408062359
INFO:root:current train perplexity12.053661346435547
INFO:root:current mean train loss 3153.9172143352916
INFO:root:current train perplexity12.040000915527344
INFO:root:current mean train loss 3154.2404788883587
INFO:root:current train perplexity12.035911560058594
INFO:root:current mean train loss 3154.2579096368017
INFO:root:current train perplexity12.036806106567383
INFO:root:current mean train loss 3154.175935333454
INFO:root:current train perplexity12.037053108215332
INFO:root:current mean train loss 3152.341434909986
INFO:root:current train perplexity12.027044296264648
INFO:root:current mean train loss 3151.7448563425164
INFO:root:current train perplexity12.013620376586914
INFO:root:current mean train loss 3151.0197931953558
INFO:root:current train perplexity11.998598098754883
INFO:root:current mean train loss 3151.167078595386
INFO:root:current train perplexity11.988079071044922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.47s/it]
INFO:root:final mean train loss: 3150.4250371320286
INFO:root:final train perplexity: 11.996499061584473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 2492.248990971991
INFO:root:eval perplexity: 7.505112648010254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it]
INFO:root:eval mean loss: 2888.357160419437
INFO:root:eval perplexity: 10.614039421081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [9:00:44<1:38:43, 370.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3105.6632939091437
INFO:root:current train perplexity11.798017501831055
INFO:root:current mean train loss 3114.1234986312747
INFO:root:current train perplexity11.814774513244629
INFO:root:current mean train loss 3148.0836326834387
INFO:root:current train perplexity11.985318183898926
INFO:root:current mean train loss 3143.9793749701357
INFO:root:current train perplexity12.04254150390625
INFO:root:current mean train loss 3151.043963036995
INFO:root:current train perplexity12.10861587524414
INFO:root:current mean train loss 3154.1346901128145
INFO:root:current train perplexity12.129592895507812
INFO:root:current mean train loss 3161.0660959149473
INFO:root:current train perplexity12.185506820678711
INFO:root:current mean train loss 3169.4627123049563
INFO:root:current train perplexity12.214581489562988
INFO:root:current mean train loss 3173.826474467673
INFO:root:current train perplexity12.249715805053711
INFO:root:current mean train loss 3174.049943481577
INFO:root:current train perplexity12.267824172973633
INFO:root:current mean train loss 3177.537215399069
INFO:root:current train perplexity12.285022735595703
INFO:root:current mean train loss 3180.770418778075
INFO:root:current train perplexity12.327299118041992
INFO:root:current mean train loss 3184.119111773826
INFO:root:current train perplexity12.361262321472168
INFO:root:current mean train loss 3187.2081916078914
INFO:root:current train perplexity12.38688850402832
INFO:root:current mean train loss 3188.536414250011
INFO:root:current train perplexity12.394956588745117
INFO:root:current mean train loss 3194.279763572108
INFO:root:current train perplexity12.430140495300293
INFO:root:current mean train loss 3197.0047522640402
INFO:root:current train perplexity12.464850425720215
INFO:root:current mean train loss 3200.5450527807434
INFO:root:current train perplexity12.490649223327637
INFO:root:current mean train loss 3202.691972303469
INFO:root:current train perplexity12.512649536132812
INFO:root:current mean train loss 3204.596012133295
INFO:root:current train perplexity12.535309791564941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.80s/it]
INFO:root:final mean train loss: 3206.7982050924065
INFO:root:final train perplexity: 12.541886329650879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.52s/it]
INFO:root:eval mean loss: 2530.7712761628713
INFO:root:eval perplexity: 7.742613792419434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it]
INFO:root:eval mean loss: 2924.5053416583555
INFO:root:eval perplexity: 10.93250846862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [9:07:01<1:33:05, 372.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.6913729580965
INFO:root:current train perplexity12.588452339172363
INFO:root:current mean train loss 3196.2769673665366
INFO:root:current train perplexity12.691813468933105
INFO:root:current mean train loss 3202.6098012455172
INFO:root:current train perplexity12.694477081298828
INFO:root:current mean train loss 3212.175608790198
INFO:root:current train perplexity12.728386878967285
INFO:root:current mean train loss 3220.0230982325097
INFO:root:current train perplexity12.753417015075684
INFO:root:current mean train loss 3233.3369154088637
INFO:root:current train perplexity12.850201606750488
INFO:root:current mean train loss 3235.5800091287365
INFO:root:current train perplexity12.866440773010254
INFO:root:current mean train loss 3237.5772396620882
INFO:root:current train perplexity12.889225006103516
INFO:root:current mean train loss 3240.366487765199
INFO:root:current train perplexity12.895981788635254
INFO:root:current mean train loss 3241.1562929315082
INFO:root:current train perplexity12.910465240478516
INFO:root:current mean train loss 3246.288392282537
INFO:root:current train perplexity12.926166534423828
INFO:root:current mean train loss 3242.829389238691
INFO:root:current train perplexity12.905790328979492
INFO:root:current mean train loss 3243.7442236406628
INFO:root:current train perplexity12.922426223754883
INFO:root:current mean train loss 3244.2230012076243
INFO:root:current train perplexity12.935918807983398
INFO:root:current mean train loss 3246.247113764121
INFO:root:current train perplexity12.960099220275879
INFO:root:current mean train loss 3247.8541221816304
INFO:root:current train perplexity12.968942642211914
INFO:root:current mean train loss 3250.4807206128344
INFO:root:current train perplexity12.994889259338379
INFO:root:current mean train loss 3254.1226281682284
INFO:root:current train perplexity13.01863956451416
INFO:root:current mean train loss 3256.3851634788925
INFO:root:current train perplexity13.033671379089355
INFO:root:current mean train loss 3257.058184713984
INFO:root:current train perplexity13.040525436401367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.51s/it]
INFO:root:final mean train loss: 3255.5920178081074
INFO:root:final train perplexity: 13.033926010131836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.93s/it]
INFO:root:eval mean loss: 2549.7672716505986
INFO:root:eval perplexity: 7.862480163574219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it]
INFO:root:eval mean loss: 2943.8178611376607
INFO:root:eval perplexity: 11.106550216674805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [9:13:05<1:26:16, 369.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.1748607197746
INFO:root:current train perplexity13.023852348327637
INFO:root:current mean train loss 3272.6160790105782
INFO:root:current train perplexity13.104752540588379
INFO:root:current mean train loss 3271.872113341116
INFO:root:current train perplexity13.18138599395752
INFO:root:current mean train loss 3275.412439404432
INFO:root:current train perplexity13.24998950958252
INFO:root:current mean train loss 3274.4614649708515
INFO:root:current train perplexity13.2380952835083
INFO:root:current mean train loss 3274.1079188600156
INFO:root:current train perplexity13.217497825622559
INFO:root:current mean train loss 3275.4776949283755
INFO:root:current train perplexity13.224798202514648
INFO:root:current mean train loss 3281.404431938342
INFO:root:current train perplexity13.275153160095215
INFO:root:current mean train loss 3282.945355883874
INFO:root:current train perplexity13.294346809387207
INFO:root:current mean train loss 3286.7079343924784
INFO:root:current train perplexity13.32307243347168
INFO:root:current mean train loss 3288.4896022785847
INFO:root:current train perplexity13.339747428894043
INFO:root:current mean train loss 3285.6438772643464
INFO:root:current train perplexity13.33373737335205
INFO:root:current mean train loss 3288.5216332601235
INFO:root:current train perplexity13.351191520690918
INFO:root:current mean train loss 3287.9350822723413
INFO:root:current train perplexity13.366744041442871
INFO:root:current mean train loss 3288.9810684903855
INFO:root:current train perplexity13.370901107788086
INFO:root:current mean train loss 3291.1723776700633
INFO:root:current train perplexity13.389875411987305
INFO:root:current mean train loss 3292.3613332694445
INFO:root:current train perplexity13.409302711486816
INFO:root:current mean train loss 3292.888518819208
INFO:root:current train perplexity13.413037300109863
INFO:root:current mean train loss 3291.710540525507
INFO:root:current train perplexity13.404041290283203
INFO:root:current mean train loss 3291.013608381008
INFO:root:current train perplexity13.40102481842041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.10s/it]
INFO:root:final mean train loss: 3291.310727548912
INFO:root:final train perplexity: 13.4063138961792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it]
INFO:root:eval mean loss: 2559.3202077446253
INFO:root:eval perplexity: 7.923460483551025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it]
INFO:root:eval mean loss: 2952.140379560755
INFO:root:eval perplexity: 11.182406425476074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [9:19:26<1:20:50, 373.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.688464042468
INFO:root:current train perplexity13.572883605957031
INFO:root:current mean train loss 3316.003372706724
INFO:root:current train perplexity13.541491508483887
INFO:root:current mean train loss 3304.1978786111736
INFO:root:current train perplexity13.442862510681152
INFO:root:current mean train loss 3305.4514069733796
INFO:root:current train perplexity13.440516471862793
INFO:root:current mean train loss 3307.1002519040926
INFO:root:current train perplexity13.502102851867676
INFO:root:current mean train loss 3305.3294407405656
INFO:root:current train perplexity13.493385314941406
INFO:root:current mean train loss 3306.3020206777746
INFO:root:current train perplexity13.534910202026367
INFO:root:current mean train loss 3309.8092637245945
INFO:root:current train perplexity13.5640230178833
INFO:root:current mean train loss 3312.775483498541
INFO:root:current train perplexity13.59970760345459
INFO:root:current mean train loss 3318.087207630368
INFO:root:current train perplexity13.634940147399902
INFO:root:current mean train loss 3318.2979906184773
INFO:root:current train perplexity13.650084495544434
INFO:root:current mean train loss 3317.5539952846457
INFO:root:current train perplexity13.655322074890137
INFO:root:current mean train loss 3321.0662818872875
INFO:root:current train perplexity13.674837112426758
INFO:root:current mean train loss 3321.1509409158425
INFO:root:current train perplexity13.688406944274902
INFO:root:current mean train loss 3322.54090594342
INFO:root:current train perplexity13.69881534576416
INFO:root:current mean train loss 3322.3684713269367
INFO:root:current train perplexity13.708547592163086
INFO:root:current mean train loss 3321.2189657690983
INFO:root:current train perplexity13.704440116882324
INFO:root:current mean train loss 3323.798958434029
INFO:root:current train perplexity13.73575496673584
INFO:root:current mean train loss 3326.234566880491
INFO:root:current train perplexity13.765493392944336
INFO:root:current mean train loss 3325.0001102212227
INFO:root:current train perplexity13.758234977722168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.67s/it]
INFO:root:final mean train loss: 3324.155328286037
INFO:root:final train perplexity: 13.758113861083984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it]
INFO:root:eval mean loss: 2590.691428326546
INFO:root:eval perplexity: 8.127058982849121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.35s/it]
INFO:root:eval mean loss: 2979.192315284242
INFO:root:eval perplexity: 11.432560920715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:25:34<1:14:18, 371.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.87201120477
INFO:root:current train perplexity13.655230522155762
INFO:root:current mean train loss 3308.398108223157
INFO:root:current train perplexity13.632320404052734
INFO:root:current mean train loss 3313.8529454118116
INFO:root:current train perplexity13.699798583984375
INFO:root:current mean train loss 3326.100415966179
INFO:root:current train perplexity13.841215133666992
INFO:root:current mean train loss 3335.3357481060607
INFO:root:current train perplexity13.96010684967041
INFO:root:current mean train loss 3341.5760385208773
INFO:root:current train perplexity14.018918991088867
INFO:root:current mean train loss 3345.2540436010568
INFO:root:current train perplexity14.051498413085938
INFO:root:current mean train loss 3345.1125039922367
INFO:root:current train perplexity14.075291633605957
INFO:root:current mean train loss 3346.541456442039
INFO:root:current train perplexity14.083565711975098
INFO:root:current mean train loss 3355.3830733256123
INFO:root:current train perplexity14.13674259185791
INFO:root:current mean train loss 3360.394647188927
INFO:root:current train perplexity14.175068855285645
INFO:root:current mean train loss 3360.3261780040534
INFO:root:current train perplexity14.176342964172363
INFO:root:current mean train loss 3361.224612391409
INFO:root:current train perplexity14.168108940124512
INFO:root:current mean train loss 3361.849110593078
INFO:root:current train perplexity14.166788101196289
INFO:root:current mean train loss 3362.580380728731
INFO:root:current train perplexity14.175217628479004
INFO:root:current mean train loss 3362.1407168397336
INFO:root:current train perplexity14.169787406921387
INFO:root:current mean train loss 3361.271214307937
INFO:root:current train perplexity14.156031608581543
INFO:root:current mean train loss 3360.158807152028
INFO:root:current train perplexity14.157830238342285
INFO:root:current mean train loss 3361.574842178224
INFO:root:current train perplexity14.168169975280762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.14s/it]
INFO:root:final mean train loss: 3363.2269570278027
INFO:root:final train perplexity: 14.188661575317383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it]
INFO:root:eval mean loss: 2614.4584419845687
INFO:root:eval perplexity: 8.284784317016602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.37s/it]
INFO:root:eval mean loss: 2999.6192220052085
INFO:root:eval perplexity: 11.62514877319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:31:53<1:08:31, 373.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.7208048502603
INFO:root:current train perplexity16.240234375
INFO:root:current mean train loss 3421.105082920619
INFO:root:current train perplexity14.721129417419434
INFO:root:current mean train loss 3407.716916642099
INFO:root:current train perplexity14.570847511291504
INFO:root:current mean train loss 3416.277263934796
INFO:root:current train perplexity14.691802978515625
INFO:root:current mean train loss 3406.618944482896
INFO:root:current train perplexity14.626554489135742
INFO:root:current mean train loss 3394.3172512054443
INFO:root:current train perplexity14.554567337036133
INFO:root:current mean train loss 3400.2338344598907
INFO:root:current train perplexity14.60118579864502
INFO:root:current mean train loss 3404.3048904933285
INFO:root:current train perplexity14.625306129455566
INFO:root:current mean train loss 3405.559024904749
INFO:root:current train perplexity14.635232925415039
INFO:root:current mean train loss 3407.5279688249557
INFO:root:current train perplexity14.650772094726562
INFO:root:current mean train loss 3410.155008549747
INFO:root:current train perplexity14.67384147644043
INFO:root:current mean train loss 3411.541756609361
INFO:root:current train perplexity14.679768562316895
INFO:root:current mean train loss 3409.691159893577
INFO:root:current train perplexity14.660045623779297
INFO:root:current mean train loss 3409.1504326797112
INFO:root:current train perplexity14.656554222106934
INFO:root:current mean train loss 3410.5471184490084
INFO:root:current train perplexity14.673816680908203
INFO:root:current mean train loss 3410.630574059865
INFO:root:current train perplexity14.675992965698242
INFO:root:current mean train loss 3411.23737511268
INFO:root:current train perplexity14.69886589050293
INFO:root:current mean train loss 3412.3286823023145
INFO:root:current train perplexity14.72413444519043
INFO:root:current mean train loss 3416.008099621232
INFO:root:current train perplexity14.757331848144531
INFO:root:current mean train loss 3415.746573859179
INFO:root:current train perplexity14.770999908447266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.63s/it]
INFO:root:final mean train loss: 3415.1085669228482
INFO:root:final train perplexity: 14.781255722045898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.85s/it]
INFO:root:eval mean loss: 2651.319257587406
INFO:root:eval perplexity: 8.535479545593262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.63s/it]
INFO:root:eval mean loss: 3029.7902849346187
INFO:root:eval perplexity: 11.915569305419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:37:59<1:01:54, 371.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3428.678466796875
INFO:root:current train perplexity15.368424415588379
INFO:root:current mean train loss 3445.4882169028583
INFO:root:current train perplexity15.13001537322998
INFO:root:current mean train loss 3454.6026222195687
INFO:root:current train perplexity15.208775520324707
INFO:root:current mean train loss 3441.324071820384
INFO:root:current train perplexity15.125971794128418
INFO:root:current mean train loss 3449.404509715545
INFO:root:current train perplexity15.154788970947266
INFO:root:current mean train loss 3449.9148899936495
INFO:root:current train perplexity15.181900978088379
INFO:root:current mean train loss 3452.1044681227645
INFO:root:current train perplexity15.191615104675293
INFO:root:current mean train loss 3453.2735262479637
INFO:root:current train perplexity15.24179744720459
INFO:root:current mean train loss 3452.4692662587645
INFO:root:current train perplexity15.236045837402344
INFO:root:current mean train loss 3451.6715882858753
INFO:root:current train perplexity15.235421180725098
INFO:root:current mean train loss 3452.1345319238185
INFO:root:current train perplexity15.242542266845703
INFO:root:current mean train loss 3452.2582746156027
INFO:root:current train perplexity15.281611442565918
INFO:root:current mean train loss 3458.196981555762
INFO:root:current train perplexity15.319024085998535
INFO:root:current mean train loss 3460.2122223152983
INFO:root:current train perplexity15.328841209411621
INFO:root:current mean train loss 3461.968562409793
INFO:root:current train perplexity15.338799476623535
INFO:root:current mean train loss 3460.5707100867603
INFO:root:current train perplexity15.33394718170166
INFO:root:current mean train loss 3461.257370978649
INFO:root:current train perplexity15.334949493408203
INFO:root:current mean train loss 3463.1959436790594
INFO:root:current train perplexity15.344999313354492
INFO:root:current mean train loss 3463.3985364109913
INFO:root:current train perplexity15.346792221069336
INFO:root:current mean train loss 3465.024537082037
INFO:root:current train perplexity15.365750312805176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it]
INFO:root:final mean train loss: 3463.7650594013962
INFO:root:final train perplexity: 15.359490394592285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it]
INFO:root:eval mean loss: 2682.8475333139404
INFO:root:eval perplexity: 8.755914688110352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.17s/it]
INFO:root:eval mean loss: 3056.8143327861812
INFO:root:eval perplexity: 12.181843757629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:44:19<56:07, 374.14s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.687643299932
INFO:root:current train perplexity15.10627269744873
INFO:root:current mean train loss 3453.449247177333
INFO:root:current train perplexity15.28045654296875
INFO:root:current mean train loss 3474.9246667381226
INFO:root:current train perplexity15.36678695678711
INFO:root:current mean train loss 3469.0006562161307
INFO:root:current train perplexity15.371997833251953
INFO:root:current mean train loss 3478.938255412696
INFO:root:current train perplexity15.464813232421875
INFO:root:current mean train loss 3486.0531613975218
INFO:root:current train perplexity15.552163124084473
INFO:root:current mean train loss 3489.8027196358603
INFO:root:current train perplexity15.541784286499023
INFO:root:current mean train loss 3493.206642130425
INFO:root:current train perplexity15.594130516052246
INFO:root:current mean train loss 3495.774717939661
INFO:root:current train perplexity15.634451866149902
INFO:root:current mean train loss 3499.1374630434066
INFO:root:current train perplexity15.66959285736084
INFO:root:current mean train loss 3501.7352782736316
INFO:root:current train perplexity15.724806785583496
INFO:root:current mean train loss 3503.092954093041
INFO:root:current train perplexity15.75609016418457
INFO:root:current mean train loss 3504.4241692556807
INFO:root:current train perplexity15.765145301818848
INFO:root:current mean train loss 3505.2359006068327
INFO:root:current train perplexity15.798324584960938
INFO:root:current mean train loss 3507.174418891284
INFO:root:current train perplexity15.825207710266113
INFO:root:current mean train loss 3507.37503632105
INFO:root:current train perplexity15.843706130981445
INFO:root:current mean train loss 3508.871868889068
INFO:root:current train perplexity15.88416862487793
INFO:root:current mean train loss 3511.1010770153207
INFO:root:current train perplexity15.916399002075195
INFO:root:current mean train loss 3513.2802247680797
INFO:root:current train perplexity15.94271469116211
INFO:root:current mean train loss 3515.7128554968526
INFO:root:current train perplexity15.988414764404297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.56s/it]
INFO:root:final mean train loss: 3515.8383486810744
INFO:root:final train perplexity: 16.003402709960938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it]
INFO:root:eval mean loss: 2724.5206783646386
INFO:root:eval perplexity: 9.05604362487793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.83s/it]
INFO:root:eval mean loss: 3092.6391034498283
INFO:root:eval perplexity: 12.544034004211426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:50:25<49:33, 371.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3564.521682012649
INFO:root:current train perplexity16.411256790161133
INFO:root:current mean train loss 3575.2202118481596
INFO:root:current train perplexity16.449268341064453
INFO:root:current mean train loss 3576.0489098146386
INFO:root:current train perplexity16.559404373168945
INFO:root:current mean train loss 3574.2648596225035
INFO:root:current train perplexity16.614051818847656
INFO:root:current mean train loss 3574.8538578437165
INFO:root:current train perplexity16.66290855407715
INFO:root:current mean train loss 3572.1926334577597
INFO:root:current train perplexity16.640342712402344
INFO:root:current mean train loss 3577.249350063042
INFO:root:current train perplexity16.720043182373047
INFO:root:current mean train loss 3591.0314343053738
INFO:root:current train perplexity16.865577697753906
INFO:root:current mean train loss 3593.57443403507
INFO:root:current train perplexity16.901044845581055
INFO:root:current mean train loss 3587.143099363967
INFO:root:current train perplexity16.882587432861328
INFO:root:current mean train loss 3592.4578766701698
INFO:root:current train perplexity16.962541580200195
INFO:root:current mean train loss 3597.163385917683
INFO:root:current train perplexity17.060832977294922
INFO:root:current mean train loss 3603.3904877554683
INFO:root:current train perplexity17.149389266967773
INFO:root:current mean train loss 3609.612428996813
INFO:root:current train perplexity17.236207962036133
INFO:root:current mean train loss 3616.2745398875386
INFO:root:current train perplexity17.30992317199707
INFO:root:current mean train loss 3625.579734797365
INFO:root:current train perplexity17.44334602355957
INFO:root:current mean train loss 3631.8394723274014
INFO:root:current train perplexity17.54178810119629
INFO:root:current mean train loss 3641.856253932838
INFO:root:current train perplexity17.668956756591797
INFO:root:current mean train loss 3652.480079802402
INFO:root:current train perplexity17.820167541503906
INFO:root:current mean train loss 3663.6356980357314
INFO:root:current train perplexity17.976280212402344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.20s/it]
INFO:root:final mean train loss: 3665.0067055568034
INFO:root:final train perplexity: 18.001314163208008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 2822.89032372008
INFO:root:eval perplexity: 9.80593490600586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it]
INFO:root:eval mean loss: 3189.0530261317044
INFO:root:eval perplexity: 13.573174476623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:56:38<43:23, 371.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3861.466589355469
INFO:root:current train perplexity20.914335250854492
INFO:root:current mean train loss 3892.4355455186633
INFO:root:current train perplexity21.402389526367188
INFO:root:current mean train loss 3888.5229143415177
INFO:root:current train perplexity21.46651840209961
INFO:root:current mean train loss 3893.046427837171
INFO:root:current train perplexity21.463422775268555
INFO:root:current mean train loss 3899.1727732340496
INFO:root:current train perplexity21.545228958129883
INFO:root:current mean train loss 3906.541173474542
INFO:root:current train perplexity21.6719970703125
INFO:root:current mean train loss 3905.395234590418
INFO:root:current train perplexity21.606639862060547
INFO:root:current mean train loss 3905.819833608774
INFO:root:current train perplexity21.621929168701172
INFO:root:current mean train loss 3908.511372791637
INFO:root:current train perplexity21.683574676513672
INFO:root:current mean train loss 3909.6246803750796
INFO:root:current train perplexity21.726194381713867
INFO:root:current mean train loss 3909.51888857241
INFO:root:current train perplexity21.740734100341797
INFO:root:current mean train loss 3911.2921163268006
INFO:root:current train perplexity21.794416427612305
INFO:root:current mean train loss 3912.55157661438
INFO:root:current train perplexity21.793954849243164
INFO:root:current mean train loss 3912.450297922328
INFO:root:current train perplexity21.80642318725586
INFO:root:current mean train loss 3915.1176972260346
INFO:root:current train perplexity21.800870895385742
INFO:root:current mean train loss 3913.330841605271
INFO:root:current train perplexity21.777135848999023
INFO:root:current mean train loss 3912.083128720238
INFO:root:current train perplexity21.787282943725586
INFO:root:current mean train loss 3913.9305079770893
INFO:root:current train perplexity21.856470108032227
INFO:root:current mean train loss 3914.5479211685506
INFO:root:current train perplexity21.859628677368164
INFO:root:current mean train loss 3912.597328386403
INFO:root:current train perplexity21.860633850097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.89s/it]
INFO:root:final mean train loss: 3911.154217957128
INFO:root:final train perplexity: 21.858095169067383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 2874.3464961491577
INFO:root:eval perplexity: 10.222617149353027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.72s/it]
INFO:root:eval mean loss: 3237.1674133733654
INFO:root:eval perplexity: 14.117914199829102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [10:03:09<37:46, 377.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3925.3854300902062
INFO:root:current train perplexity22.168611526489258
INFO:root:current mean train loss 3908.200726968988
INFO:root:current train perplexity21.711456298828125
INFO:root:current mean train loss 3889.811644274779
INFO:root:current train perplexity21.659257888793945
INFO:root:current mean train loss 3885.8825585199543
INFO:root:current train perplexity21.565704345703125
INFO:root:current mean train loss 3887.789031552597
INFO:root:current train perplexity21.533740997314453
INFO:root:current mean train loss 3895.2975260416665
INFO:root:current train perplexity21.609695434570312
INFO:root:current mean train loss 3896.2574997057704
INFO:root:current train perplexity21.600433349609375
INFO:root:current mean train loss 3895.081791397918
INFO:root:current train perplexity21.586301803588867
INFO:root:current mean train loss 3896.90702760286
INFO:root:current train perplexity21.598703384399414
INFO:root:current mean train loss 3890.982279357604
INFO:root:current train perplexity21.538902282714844
INFO:root:current mean train loss 3890.2042907325376
INFO:root:current train perplexity21.504785537719727
INFO:root:current mean train loss 3890.792179219207
INFO:root:current train perplexity21.508235931396484
INFO:root:current mean train loss 3890.934846076583
INFO:root:current train perplexity21.497438430786133
INFO:root:current mean train loss 3890.457754933843
INFO:root:current train perplexity21.48842430114746
INFO:root:current mean train loss 3892.30756027028
INFO:root:current train perplexity21.50843620300293
INFO:root:current mean train loss 3890.039501249902
INFO:root:current train perplexity21.485898971557617
INFO:root:current mean train loss 3890.023260113205
INFO:root:current train perplexity21.509681701660156
INFO:root:current mean train loss 3893.123244551466
INFO:root:current train perplexity21.541608810424805
INFO:root:current mean train loss 3895.4221259616334
INFO:root:current train perplexity21.5642032623291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.15s/it]
INFO:root:final mean train loss: 3895.866748465472
INFO:root:final train perplexity: 21.596149444580078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it]
INFO:root:eval mean loss: 2896.023336207613
INFO:root:eval perplexity: 10.403410911560059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it]
INFO:root:eval mean loss: 3256.4818595723905
INFO:root:eval perplexity: 14.342690467834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:09:18<31:16, 375.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3778.5969587053573
INFO:root:current train perplexity20.928756713867188
INFO:root:current mean train loss 3883.914685701069
INFO:root:current train perplexity21.687400817871094
INFO:root:current mean train loss 3880.4496922002772
INFO:root:current train perplexity21.50013542175293
INFO:root:current mean train loss 3884.77943838326
INFO:root:current train perplexity21.49998664855957
INFO:root:current mean train loss 3877.9574900456673
INFO:root:current train perplexity21.46295738220215
INFO:root:current mean train loss 3888.7237173592534
INFO:root:current train perplexity21.612611770629883
INFO:root:current mean train loss 3889.897446623066
INFO:root:current train perplexity21.568660736083984
INFO:root:current mean train loss 3889.4606075340294
INFO:root:current train perplexity21.53215980529785
INFO:root:current mean train loss 3889.9818313186233
INFO:root:current train perplexity21.52878761291504
INFO:root:current mean train loss 3887.317928790003
INFO:root:current train perplexity21.500123977661133
INFO:root:current mean train loss 3892.5948079427085
INFO:root:current train perplexity21.503400802612305
INFO:root:current mean train loss 3894.7308689302345
INFO:root:current train perplexity21.532320022583008
INFO:root:current mean train loss 3893.1295755251235
INFO:root:current train perplexity21.536365509033203
INFO:root:current mean train loss 3892.1168159008753
INFO:root:current train perplexity21.507558822631836
INFO:root:current mean train loss 3888.1703203732764
INFO:root:current train perplexity21.472841262817383
INFO:root:current mean train loss 3886.038068360665
INFO:root:current train perplexity21.449514389038086
INFO:root:current mean train loss 3888.325056451847
INFO:root:current train perplexity21.464082717895508
INFO:root:current mean train loss 3886.2043664992343
INFO:root:current train perplexity21.4498348236084
INFO:root:current mean train loss 3887.040763678335
INFO:root:current train perplexity21.44098472595215
INFO:root:current mean train loss 3885.6238683303945
INFO:root:current train perplexity21.424766540527344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.46s/it]
INFO:root:final mean train loss: 3885.0765214036105
INFO:root:final train perplexity: 21.413148880004883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it]
INFO:root:eval mean loss: 2895.545915752438
INFO:root:eval perplexity: 10.399394035339355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.45s/it]
INFO:root:eval mean loss: 3255.197191170767
INFO:root:eval perplexity: 14.327625274658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:15:56<25:27, 381.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3879.8653603830644
INFO:root:current train perplexity21.65514373779297
INFO:root:current mean train loss 3858.3260712368797
INFO:root:current train perplexity21.171140670776367
INFO:root:current mean train loss 3872.0205944771374
INFO:root:current train perplexity21.15669059753418
INFO:root:current mean train loss 3879.474315078597
INFO:root:current train perplexity21.231571197509766
INFO:root:current mean train loss 3875.7213313197867
INFO:root:current train perplexity21.23679542541504
INFO:root:current mean train loss 3875.449673007886
INFO:root:current train perplexity21.239885330200195
INFO:root:current mean train loss 3879.516667337312
INFO:root:current train perplexity21.34084701538086
INFO:root:current mean train loss 3882.995232077206
INFO:root:current train perplexity21.36690330505371
INFO:root:current mean train loss 3878.167369415614
INFO:root:current train perplexity21.267927169799805
INFO:root:current mean train loss 3869.0922765025007
INFO:root:current train perplexity21.16920280456543
INFO:root:current mean train loss 3869.283118350661
INFO:root:current train perplexity21.15916633605957
INFO:root:current mean train loss 3866.1684701988697
INFO:root:current train perplexity21.11733627319336
INFO:root:current mean train loss 3865.561740010662
INFO:root:current train perplexity21.09537696838379
INFO:root:current mean train loss 3867.3646354875914
INFO:root:current train perplexity21.110858917236328
INFO:root:current mean train loss 3866.0059820424417
INFO:root:current train perplexity21.101076126098633
INFO:root:current mean train loss 3864.8142447044925
INFO:root:current train perplexity21.07655906677246
INFO:root:current mean train loss 3864.7870601277496
INFO:root:current train perplexity21.079212188720703
INFO:root:current mean train loss 3863.9562023566127
INFO:root:current train perplexity21.081071853637695
INFO:root:current mean train loss 3864.8654407811646
INFO:root:current train perplexity21.083303451538086
INFO:root:current mean train loss 3865.529333540345
INFO:root:current train perplexity21.085214614868164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.72s/it]
INFO:root:final mean train loss: 3865.6528755530408
INFO:root:final train perplexity: 21.087623596191406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 2904.3353505236037
INFO:root:eval perplexity: 10.473580360412598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it]
INFO:root:eval mean loss: 3263.094457315215
INFO:root:eval perplexity: 14.420466423034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:22:17<19:05, 381.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3908.263209025065
INFO:root:current train perplexity21.31063461303711
INFO:root:current mean train loss 3875.853226945207
INFO:root:current train perplexity21.354589462280273
INFO:root:current mean train loss 3870.166491108556
INFO:root:current train perplexity21.148948669433594
INFO:root:current mean train loss 3865.350874275997
INFO:root:current train perplexity21.087221145629883
INFO:root:current mean train loss 3872.2148600987025
INFO:root:current train perplexity21.104055404663086
INFO:root:current mean train loss 3874.815314745381
INFO:root:current train perplexity21.135278701782227
INFO:root:current mean train loss 3879.07325876495
INFO:root:current train perplexity21.175270080566406
INFO:root:current mean train loss 3875.0119821477065
INFO:root:current train perplexity21.14797019958496
INFO:root:current mean train loss 3875.951533191609
INFO:root:current train perplexity21.132356643676758
INFO:root:current mean train loss 3872.3331401841046
INFO:root:current train perplexity21.117341995239258
INFO:root:current mean train loss 3877.146180829929
INFO:root:current train perplexity21.13962745666504
INFO:root:current mean train loss 3873.028769888529
INFO:root:current train perplexity21.12858772277832
INFO:root:current mean train loss 3874.4568182138296
INFO:root:current train perplexity21.12584686279297
INFO:root:current mean train loss 3873.988728961888
INFO:root:current train perplexity21.121667861938477
INFO:root:current mean train loss 3871.755278192172
INFO:root:current train perplexity21.117713928222656
INFO:root:current mean train loss 3871.464994681898
INFO:root:current train perplexity21.12085723876953
INFO:root:current mean train loss 3867.8434428983524
INFO:root:current train perplexity21.107662200927734
INFO:root:current mean train loss 3867.6193498484877
INFO:root:current train perplexity21.103023529052734
INFO:root:current mean train loss 3868.298064657104
INFO:root:current train perplexity21.106887817382812
INFO:root:current mean train loss 3866.105330512264
INFO:root:current train perplexity21.083072662353516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.79s/it]
INFO:root:final mean train loss: 3865.154796482996
INFO:root:final train perplexity: 21.079343795776367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it]
INFO:root:eval mean loss: 2915.5441418370456
INFO:root:eval perplexity: 10.568954467773438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it]
INFO:root:eval mean loss: 3273.481577338902
INFO:root:eval perplexity: 14.543488502502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:28:37<12:42, 381.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.1928786057692
INFO:root:current train perplexity21.12031364440918
INFO:root:current mean train loss 3858.244745797822
INFO:root:current train perplexity20.870784759521484
INFO:root:current mean train loss 3858.0895378832547
INFO:root:current train perplexity21.057659149169922
INFO:root:current mean train loss 3862.205911547517
INFO:root:current train perplexity21.04509162902832
INFO:root:current mean train loss 3864.9912440146168
INFO:root:current train perplexity21.11433219909668
INFO:root:current mean train loss 3871.5393278138827
INFO:root:current train perplexity21.137435913085938
INFO:root:current mean train loss 3865.0091771175985
INFO:root:current train perplexity21.068023681640625
INFO:root:current mean train loss 3869.0767281326594
INFO:root:current train perplexity21.122220993041992
INFO:root:current mean train loss 3871.0659289762466
INFO:root:current train perplexity21.12900161743164
INFO:root:current mean train loss 3874.8786793130666
INFO:root:current train perplexity21.172740936279297
INFO:root:current mean train loss 3874.4320477552815
INFO:root:current train perplexity21.17281723022461
INFO:root:current mean train loss 3868.4094940316522
INFO:root:current train perplexity21.114891052246094
INFO:root:current mean train loss 3870.7742990365614
INFO:root:current train perplexity21.12078094482422
INFO:root:current mean train loss 3872.380781035371
INFO:root:current train perplexity21.146150588989258
INFO:root:current mean train loss 3873.821721183074
INFO:root:current train perplexity21.158000946044922
INFO:root:current mean train loss 3874.872535505691
INFO:root:current train perplexity21.167875289916992
INFO:root:current mean train loss 3872.152639064846
INFO:root:current train perplexity21.13960838317871
INFO:root:current mean train loss 3869.749388749336
INFO:root:current train perplexity21.1235408782959
INFO:root:current mean train loss 3871.7707095394185
INFO:root:current train perplexity21.1324520111084
INFO:root:current mean train loss 3870.688320884025
INFO:root:current train perplexity21.142576217651367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.48s/it]
INFO:root:final mean train loss: 3868.722963980455
INFO:root:final train perplexity: 21.138750076293945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 2923.42434151291
INFO:root:eval perplexity: 10.636527061462402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.07s/it]
INFO:root:eval mean loss: 3280.9271149330953
INFO:root:eval perplexity: 14.632316589355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:34:51<06:19, 379.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3806.231609065358
INFO:root:current train perplexity20.66010856628418
INFO:root:current mean train loss 3821.2191041380493
INFO:root:current train perplexity20.61373519897461
INFO:root:current mean train loss 3828.662692888409
INFO:root:current train perplexity20.774023056030273
INFO:root:current mean train loss 3830.437360034563
INFO:root:current train perplexity20.8114070892334
INFO:root:current mean train loss 3825.4654171259076
INFO:root:current train perplexity20.702014923095703
INFO:root:current mean train loss 3834.5533422096487
INFO:root:current train perplexity20.794414520263672
INFO:root:current mean train loss 3844.325980357061
INFO:root:current train perplexity20.918230056762695
INFO:root:current mean train loss 3849.68260657269
INFO:root:current train perplexity20.973466873168945
INFO:root:current mean train loss 3850.6678098648313
INFO:root:current train perplexity21.01203155517578
INFO:root:current mean train loss 3853.8530159074276
INFO:root:current train perplexity21.029232025146484
INFO:root:current mean train loss 3856.310948511148
INFO:root:current train perplexity21.026966094970703
INFO:root:current mean train loss 3852.1746801386025
INFO:root:current train perplexity20.949464797973633
INFO:root:current mean train loss 3852.661389521987
INFO:root:current train perplexity20.951522827148438
INFO:root:current mean train loss 3852.0536300283784
INFO:root:current train perplexity20.9313907623291
INFO:root:current mean train loss 3852.932288042447
INFO:root:current train perplexity20.936426162719727
INFO:root:current mean train loss 3854.5597828166974
INFO:root:current train perplexity20.93924331665039
INFO:root:current mean train loss 3854.0775185674606
INFO:root:current train perplexity20.927663803100586
INFO:root:current mean train loss 3856.490446593759
INFO:root:current train perplexity20.963594436645508
INFO:root:current mean train loss 3857.9265272928983
INFO:root:current train perplexity20.97001838684082
INFO:root:current mean train loss 3860.2456331840076
INFO:root:current train perplexity20.981800079345703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.07s/it]
INFO:root:final mean train loss: 3859.300906767583
INFO:root:final train perplexity: 20.982255935668945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.00s/it]
INFO:root:eval mean loss: 2923.5239967724956
INFO:root:eval perplexity: 10.637381553649902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 3280.780896775266
INFO:root:eval perplexity: 14.630561828613281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:41:00<00:00, 375.99s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:41:00<00:00, 384.61s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.02s/it]
INFO:root:eval mean loss: 2923.5239967724956
INFO:root:eval perplexity: 10.637381553649902
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it]
INFO:root:eval mean loss: 3280.780896775266
INFO:root:eval perplexity: 14.630561828613281
INFO:root:evalaution complete
INFO:root:save model final: multiqal6_minilml6_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x1484781f2f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1484781ea8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14847810fe09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1484781f3a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14847810d948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1484781f3a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x1484780c8b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x148477b2d46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x148574349a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x148574349be0]
python(+0x24a989) [0x56524d385989]
python(+0x24a9bd) [0x56524d3859bd]
python(+0x24aa14) [0x56524d385a14]
python(+0x108f75) [0x56524d243f75]
python(Py_RunMain+0x313) [0x56524d388983]
python(Py_BytesMain+0x39) [0x56524d388bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x1485743270b3]
python(+0x1d6e13) [0x56524d311e13]
/opt/slurm/data/slurmd/job29854147/slurm_script: line 235: 2649003 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path nreimers/MiniLM-L6-H384-uncased --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected --output multiqal6_minilml6_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
