INFO:root:Output: multiqal6_multiqal6_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12257.782581676136
INFO:root:current train perplexity16962.8671875
INFO:root:current mean train loss 10454.6564143962
INFO:root:current train perplexity3831.756591796875
INFO:root:current mean train loss 9086.662104475858
INFO:root:current train perplexity1292.388671875
INFO:root:current mean train loss 8148.785615160949
INFO:root:current train perplexity616.2129516601562
INFO:root:current mean train loss 7466.822979944263
INFO:root:current train perplexity360.6030578613281
INFO:root:current mean train loss 6949.374160384495
INFO:root:current train perplexity239.72950744628906
INFO:root:current mean train loss 6545.7788480614045
INFO:root:current train perplexity173.8301544189453
INFO:root:current mean train loss 6225.082574837199
INFO:root:current train perplexity134.55303955078125
INFO:root:current mean train loss 5951.806782655642
INFO:root:current train perplexity109.00802612304688
INFO:root:current mean train loss 5730.719083829924
INFO:root:current train perplexity91.0957260131836
INFO:root:current mean train loss 5533.164406385066
INFO:root:current train perplexity78.13465881347656
INFO:root:current mean train loss 5365.58605661782
INFO:root:current train perplexity68.50320434570312
INFO:root:current mean train loss 5220.8150697727215
INFO:root:current train perplexity60.94664001464844
INFO:root:current mean train loss 5086.430818679079
INFO:root:current train perplexity54.95853042602539
INFO:root:current mean train loss 4968.85099310999
INFO:root:current train perplexity50.16291809082031
INFO:root:current mean train loss 4863.007434456105
INFO:root:current train perplexity46.17142868041992
INFO:root:current mean train loss 4768.054727016582
INFO:root:current train perplexity42.81057357788086
INFO:root:current mean train loss 4679.9987673544765
INFO:root:current train perplexity39.98429870605469
INFO:root:current mean train loss 4597.967560537619
INFO:root:current train perplexity37.53715133666992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.82s/it]
INFO:root:final mean train loss: 4533.9270685593165
INFO:root:final train perplexity: 35.72061538696289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2896.3231201171875
INFO:root:eval perplexity: 10.40593147277832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.75s/it]
INFO:root:eval mean loss: 3187.3278540212214
INFO:root:eval perplexity: 13.554034233093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/1
  1%|          | 1/100 [06:41<11:01:50, 401.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3084.683151245117
INFO:root:current train perplexity11.472250938415527
INFO:root:current mean train loss 3102.058206492457
INFO:root:current train perplexity11.241962432861328
INFO:root:current mean train loss 3081.910065827546
INFO:root:current train perplexity11.128328323364258
INFO:root:current mean train loss 3052.661910044996
INFO:root:current train perplexity11.034894943237305
INFO:root:current mean train loss 3041.7671620295596
INFO:root:current train perplexity10.927140235900879
INFO:root:current mean train loss 3022.3367300107498
INFO:root:current train perplexity10.810789108276367
INFO:root:current mean train loss 3008.778402749594
INFO:root:current train perplexity10.708930015563965
INFO:root:current mean train loss 2996.416079047006
INFO:root:current train perplexity10.623794555664062
INFO:root:current mean train loss 2983.1243094649967
INFO:root:current train perplexity10.527792930603027
INFO:root:current mean train loss 2973.4513400548412
INFO:root:current train perplexity10.428108215332031
INFO:root:current mean train loss 2963.463952492541
INFO:root:current train perplexity10.33623218536377
INFO:root:current mean train loss 2953.139352012279
INFO:root:current train perplexity10.245096206665039
INFO:root:current mean train loss 2942.5158366153114
INFO:root:current train perplexity10.165188789367676
INFO:root:current mean train loss 2934.4400122738175
INFO:root:current train perplexity10.093592643737793
INFO:root:current mean train loss 2926.0894759873213
INFO:root:current train perplexity10.028273582458496
INFO:root:current mean train loss 2917.9942581861187
INFO:root:current train perplexity9.964037895202637
INFO:root:current mean train loss 2907.5692721829555
INFO:root:current train perplexity9.896210670471191
INFO:root:current mean train loss 2899.06967511655
INFO:root:current train perplexity9.830368995666504
INFO:root:current mean train loss 2889.4657720490172
INFO:root:current train perplexity9.765853881835938
INFO:root:current mean train loss 2883.281981529921
INFO:root:current train perplexity9.711980819702148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.91s/it]
INFO:root:final mean train loss: 2877.754338143753
INFO:root:final train perplexity: 9.675243377685547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.62s/it]
INFO:root:eval mean loss: 2551.6543968687665
INFO:root:eval perplexity: 7.874490261077881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2889.2439588181514
INFO:root:eval perplexity: 10.621740341186523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/2
  2%|â–         | 2/100 [13:33<11:05:52, 407.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2732.9044078480115
INFO:root:current train perplexity8.660250663757324
INFO:root:current mean train loss 2690.6084461642386
INFO:root:current train perplexity8.428342819213867
INFO:root:current mean train loss 2674.9154057973446
INFO:root:current train perplexity8.369963645935059
INFO:root:current mean train loss 2677.6507982591966
INFO:root:current train perplexity8.355448722839355
INFO:root:current mean train loss 2678.404091075166
INFO:root:current train perplexity8.32115364074707
INFO:root:current mean train loss 2673.588487922139
INFO:root:current train perplexity8.284192085266113
INFO:root:current mean train loss 2671.0871805730403
INFO:root:current train perplexity8.256657600402832
INFO:root:current mean train loss 2669.439225970967
INFO:root:current train perplexity8.225957870483398
INFO:root:current mean train loss 2664.270373286033
INFO:root:current train perplexity8.192038536071777
INFO:root:current mean train loss 2662.2554626791934
INFO:root:current train perplexity8.166013717651367
INFO:root:current mean train loss 2660.6112045184686
INFO:root:current train perplexity8.14476490020752
INFO:root:current mean train loss 2655.164630293951
INFO:root:current train perplexity8.111125946044922
INFO:root:current mean train loss 2649.2647222935043
INFO:root:current train perplexity8.076645851135254
INFO:root:current mean train loss 2644.952026825066
INFO:root:current train perplexity8.04597282409668
INFO:root:current mean train loss 2638.174980680009
INFO:root:current train perplexity8.01577377319336
INFO:root:current mean train loss 2636.089539888087
INFO:root:current train perplexity7.998891830444336
INFO:root:current mean train loss 2633.0724572895933
INFO:root:current train perplexity7.974193572998047
INFO:root:current mean train loss 2629.985578234321
INFO:root:current train perplexity7.9497833251953125
INFO:root:current mean train loss 2624.9092890379925
INFO:root:current train perplexity7.917881965637207
INFO:root:current mean train loss 2621.255322151954
INFO:root:current train perplexity7.89717960357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.48s/it]
INFO:root:final mean train loss: 2617.6362704509324
INFO:root:final train perplexity: 7.880766868591309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it]
INFO:root:eval mean loss: 2386.4484880596187
INFO:root:eval perplexity: 6.889644622802734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 2747.8410254945147
INFO:root:eval perplexity: 9.461773872375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/3
  3%|â–Ž         | 3/100 [20:08<10:49:29, 401.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2568.893076171875
INFO:root:current train perplexity7.39742374420166
INFO:root:current mean train loss 2529.2108024088543
INFO:root:current train perplexity7.3089752197265625
INFO:root:current mean train loss 2524.20075390625
INFO:root:current train perplexity7.309739589691162
INFO:root:current mean train loss 2523.428517368862
INFO:root:current train perplexity7.305415153503418
INFO:root:current mean train loss 2522.7804532877603
INFO:root:current train perplexity7.311553955078125
INFO:root:current mean train loss 2515.9753646573154
INFO:root:current train perplexity7.275994777679443
INFO:root:current mean train loss 2514.718756197416
INFO:root:current train perplexity7.25973653793335
INFO:root:current mean train loss 2511.9828810221356
INFO:root:current train perplexity7.239243507385254
INFO:root:current mean train loss 2512.1707752182906
INFO:root:current train perplexity7.228360176086426
INFO:root:current mean train loss 2508.6507970548932
INFO:root:current train perplexity7.207006454467773
INFO:root:current mean train loss 2505.5269235956102
INFO:root:current train perplexity7.197946548461914
INFO:root:current mean train loss 2505.6101791779893
INFO:root:current train perplexity7.1935906410217285
INFO:root:current mean train loss 2503.080766015625
INFO:root:current train perplexity7.179924011230469
INFO:root:current mean train loss 2500.832224573206
INFO:root:current train perplexity7.170843601226807
INFO:root:current mean train loss 2500.030498046875
INFO:root:current train perplexity7.168189525604248
INFO:root:current mean train loss 2498.260872920867
INFO:root:current train perplexity7.166947364807129
INFO:root:current mean train loss 2495.498681862571
INFO:root:current train perplexity7.159574508666992
INFO:root:current mean train loss 2494.0455290876116
INFO:root:current train perplexity7.148162841796875
INFO:root:current mean train loss 2493.109023371516
INFO:root:current train perplexity7.141535758972168
INFO:root:current mean train loss 2491.8595548502603
INFO:root:current train perplexity7.1324849128723145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.76s/it]
INFO:root:final mean train loss: 2490.757197500778
INFO:root:final train perplexity: 7.130354404449463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it]
INFO:root:eval mean loss: 2304.9266006794383
INFO:root:eval perplexity: 6.4500579833984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.17s/it]
INFO:root:eval mean loss: 2681.921432170462
INFO:root:eval perplexity: 8.96518611907959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/4
  4%|â–         | 4/100 [26:43<10:38:33, 399.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2433.7944591009796
INFO:root:current train perplexity6.887659072875977
INFO:root:current mean train loss 2460.982192353574
INFO:root:current train perplexity6.942313194274902
INFO:root:current mean train loss 2445.8332158349426
INFO:root:current train perplexity6.9059529304504395
INFO:root:current mean train loss 2445.5343117363122
INFO:root:current train perplexity6.914641380310059
INFO:root:current mean train loss 2447.0920776105795
INFO:root:current train perplexity6.912927627563477
INFO:root:current mean train loss 2448.7165178571427
INFO:root:current train perplexity6.912932872772217
INFO:root:current mean train loss 2448.7043297809105
INFO:root:current train perplexity6.9035725593566895
INFO:root:current mean train loss 2449.3216304455773
INFO:root:current train perplexity6.901652812957764
INFO:root:current mean train loss 2449.6224852389255
INFO:root:current train perplexity6.894084453582764
INFO:root:current mean train loss 2444.154561465874
INFO:root:current train perplexity6.8711676597595215
INFO:root:current mean train loss 2441.138545228481
INFO:root:current train perplexity6.860558032989502
INFO:root:current mean train loss 2440.1937377197473
INFO:root:current train perplexity6.855014324188232
INFO:root:current mean train loss 2438.124441193518
INFO:root:current train perplexity6.844508647918701
INFO:root:current mean train loss 2439.1011369059183
INFO:root:current train perplexity6.840192794799805
INFO:root:current mean train loss 2437.5557677432153
INFO:root:current train perplexity6.832283973693848
INFO:root:current mean train loss 2433.8413079705447
INFO:root:current train perplexity6.815987586975098
INFO:root:current mean train loss 2431.1466470865985
INFO:root:current train perplexity6.802318572998047
INFO:root:current mean train loss 2428.4519983884234
INFO:root:current train perplexity6.787628650665283
INFO:root:current mean train loss 2426.9956163223505
INFO:root:current train perplexity6.78128719329834
INFO:root:current mean train loss 2425.775744051756
INFO:root:current train perplexity6.77173376083374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.07s/it]
INFO:root:final mean train loss: 2425.497066157308
INFO:root:final train perplexity: 6.772654056549072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it]
INFO:root:eval mean loss: 2240.341976950355
INFO:root:eval perplexity: 6.121805667877197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it]
INFO:root:eval mean loss: 2623.776768028313
INFO:root:eval perplexity: 8.548850059509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/5
  5%|â–Œ         | 5/100 [33:10<10:25:00, 394.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2404.0440775553384
INFO:root:current train perplexity6.589232444763184
INFO:root:current mean train loss 2380.75048828125
INFO:root:current train perplexity6.496732711791992
INFO:root:current mean train loss 2371.433584723674
INFO:root:current train perplexity6.4783935546875
INFO:root:current mean train loss 2374.684022585551
INFO:root:current train perplexity6.4811296463012695
INFO:root:current mean train loss 2370.8099347579578
INFO:root:current train perplexity6.459197044372559
INFO:root:current mean train loss 2367.1256803747724
INFO:root:current train perplexity6.45626163482666
INFO:root:current mean train loss 2364.4020128752054
INFO:root:current train perplexity6.4458818435668945
INFO:root:current mean train loss 2362.1195793930365
INFO:root:current train perplexity6.439752101898193
INFO:root:current mean train loss 2360.9872127205
INFO:root:current train perplexity6.43677282333374
INFO:root:current mean train loss 2360.853104009861
INFO:root:current train perplexity6.428432941436768
INFO:root:current mean train loss 2358.6672301345207
INFO:root:current train perplexity6.417763710021973
INFO:root:current mean train loss 2357.4296650242163
INFO:root:current train perplexity6.417075157165527
INFO:root:current mean train loss 2354.754629069771
INFO:root:current train perplexity6.404622554779053
INFO:root:current mean train loss 2352.4129961487874
INFO:root:current train perplexity6.392870903015137
INFO:root:current mean train loss 2350.9636565257274
INFO:root:current train perplexity6.3883137702941895
INFO:root:current mean train loss 2348.8783769703873
INFO:root:current train perplexity6.378631591796875
INFO:root:current mean train loss 2348.197171825128
INFO:root:current train perplexity6.374467849731445
INFO:root:current mean train loss 2347.316967267092
INFO:root:current train perplexity6.367824077606201
INFO:root:current mean train loss 2344.131349340872
INFO:root:current train perplexity6.353865146636963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.14s/it]
INFO:root:final mean train loss: 2344.4102575135726
INFO:root:final train perplexity: 6.353100776672363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 2181.910377015459
INFO:root:eval perplexity: 5.839242458343506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.40s/it]
INFO:root:eval mean loss: 2577.8927278992132
INFO:root:eval perplexity: 8.233997344970703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/6
  6%|â–Œ         | 6/100 [39:32<10:11:48, 390.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2392.270263671875
INFO:root:current train perplexity6.778909206390381
INFO:root:current mean train loss 2313.1421599435334
INFO:root:current train perplexity6.142748832702637
INFO:root:current mean train loss 2300.2123756218907
INFO:root:current train perplexity6.112959384918213
INFO:root:current mean train loss 2288.5993871340324
INFO:root:current train perplexity6.0914835929870605
INFO:root:current mean train loss 2295.5498673969373
INFO:root:current train perplexity6.121626853942871
INFO:root:current mean train loss 2291.210588588448
INFO:root:current train perplexity6.101983547210693
INFO:root:current mean train loss 2295.1653723692934
INFO:root:current train perplexity6.107304573059082
INFO:root:current mean train loss 2296.551966603234
INFO:root:current train perplexity6.102314472198486
INFO:root:current mean train loss 2296.8762949206557
INFO:root:current train perplexity6.103828430175781
INFO:root:current mean train loss 2298.4143147696136
INFO:root:current train perplexity6.110657691955566
INFO:root:current mean train loss 2295.2143325424577
INFO:root:current train perplexity6.100194931030273
INFO:root:current mean train loss 2293.071815040304
INFO:root:current train perplexity6.09265661239624
INFO:root:current mean train loss 2291.6257089429055
INFO:root:current train perplexity6.085130214691162
INFO:root:current mean train loss 2288.626842032571
INFO:root:current train perplexity6.084101676940918
INFO:root:current mean train loss 2288.7548283557226
INFO:root:current train perplexity6.080462455749512
INFO:root:current mean train loss 2288.700587222451
INFO:root:current train perplexity6.0756683349609375
INFO:root:current mean train loss 2287.896060826851
INFO:root:current train perplexity6.075117588043213
INFO:root:current mean train loss 2287.2752460926017
INFO:root:current train perplexity6.069297790527344
INFO:root:current mean train loss 2284.4972947293822
INFO:root:current train perplexity6.058796405792236
INFO:root:current mean train loss 2283.7264496764656
INFO:root:current train perplexity6.054323673248291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.79s/it]
INFO:root:final mean train loss: 2283.6648748554608
INFO:root:final train perplexity: 6.055915355682373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 2140.7119058379044
INFO:root:eval perplexity: 5.647890567779541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 2543.14297853294
INFO:root:eval perplexity: 8.003287315368652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/7
  7%|â–‹         | 7/100 [46:07<10:07:44, 392.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.657992892795
INFO:root:current train perplexity5.937232971191406
INFO:root:current mean train loss 2244.3378947629767
INFO:root:current train perplexity5.862083435058594
INFO:root:current mean train loss 2244.7612293488387
INFO:root:current train perplexity5.891505241394043
INFO:root:current mean train loss 2243.205695386203
INFO:root:current train perplexity5.8875250816345215
INFO:root:current mean train loss 2243.3726952657744
INFO:root:current train perplexity5.887749671936035
INFO:root:current mean train loss 2240.642416464316
INFO:root:current train perplexity5.875962257385254
INFO:root:current mean train loss 2239.8710495044497
INFO:root:current train perplexity5.877699851989746
INFO:root:current mean train loss 2240.8209988479825
INFO:root:current train perplexity5.876992225646973
INFO:root:current mean train loss 2241.951684331544
INFO:root:current train perplexity5.879863739013672
INFO:root:current mean train loss 2239.5728044364446
INFO:root:current train perplexity5.864323139190674
INFO:root:current mean train loss 2239.984402939472
INFO:root:current train perplexity5.861210346221924
INFO:root:current mean train loss 2238.2076122304406
INFO:root:current train perplexity5.857741832733154
INFO:root:current mean train loss 2239.3295960575097
INFO:root:current train perplexity5.855154037475586
INFO:root:current mean train loss 2237.2243531940558
INFO:root:current train perplexity5.852497577667236
INFO:root:current mean train loss 2237.5213307971176
INFO:root:current train perplexity5.846292018890381
INFO:root:current mean train loss 2236.6076769520955
INFO:root:current train perplexity5.843574047088623
INFO:root:current mean train loss 2238.2332228011046
INFO:root:current train perplexity5.844772815704346
INFO:root:current mean train loss 2238.0918857632196
INFO:root:current train perplexity5.84375
INFO:root:current mean train loss 2236.9227310365313
INFO:root:current train perplexity5.83787202835083
INFO:root:current mean train loss 2236.177737939097
INFO:root:current train perplexity5.833189010620117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.08s/it]
INFO:root:final mean train loss: 2236.0535711383677
INFO:root:final train perplexity: 5.832736492156982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 2109.8155794617132
INFO:root:eval perplexity: 5.508514881134033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it]
INFO:root:eval mean loss: 2516.303530862145
INFO:root:eval perplexity: 7.829526901245117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/8
  8%|â–Š         | 8/100 [52:34<9:58:33, 390.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2187.223360770089
INFO:root:current train perplexity5.618514537811279
INFO:root:current mean train loss 2194.4086651837383
INFO:root:current train perplexity5.627181529998779
INFO:root:current mean train loss 2200.164788169049
INFO:root:current train perplexity5.646417617797852
INFO:root:current mean train loss 2206.1226806640625
INFO:root:current train perplexity5.663232326507568
INFO:root:current mean train loss 2206.606516590338
INFO:root:current train perplexity5.6726884841918945
INFO:root:current mean train loss 2207.377729811624
INFO:root:current train perplexity5.671083450317383
INFO:root:current mean train loss 2209.1367552749753
INFO:root:current train perplexity5.686654567718506
INFO:root:current mean train loss 2207.6458805006378
INFO:root:current train perplexity5.6790595054626465
INFO:root:current mean train loss 2208.4809720890253
INFO:root:current train perplexity5.682744979858398
INFO:root:current mean train loss 2206.1869091013536
INFO:root:current train perplexity5.671923637390137
INFO:root:current mean train loss 2202.254686438519
INFO:root:current train perplexity5.661301136016846
INFO:root:current mean train loss 2201.6936627761906
INFO:root:current train perplexity5.6651811599731445
INFO:root:current mean train loss 2200.2976527905175
INFO:root:current train perplexity5.663570880889893
INFO:root:current mean train loss 2200.4229994184516
INFO:root:current train perplexity5.665862083435059
INFO:root:current mean train loss 2198.6367814439513
INFO:root:current train perplexity5.658850193023682
INFO:root:current mean train loss 2198.72985466078
INFO:root:current train perplexity5.65985107421875
INFO:root:current mean train loss 2198.531392751338
INFO:root:current train perplexity5.658064842224121
INFO:root:current mean train loss 2197.1766944203664
INFO:root:current train perplexity5.655767440795898
INFO:root:current mean train loss 2196.027420052261
INFO:root:current train perplexity5.652171611785889
INFO:root:current mean train loss 2196.4148125227107
INFO:root:current train perplexity5.6513590812683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.59s/it]
INFO:root:final mean train loss: 2195.7102866430087
INFO:root:final train perplexity: 5.650076866149902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 2080.2905957377548
INFO:root:eval perplexity: 5.378539562225342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2491.263007414256
INFO:root:eval perplexity: 7.670816898345947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/9
  9%|â–‰         | 9/100 [59:16<9:57:33, 393.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2150.5492037259614
INFO:root:current train perplexity5.506911754608154
INFO:root:current mean train loss 2172.8608310097143
INFO:root:current train perplexity5.540106296539307
INFO:root:current mean train loss 2168.991444905599
INFO:root:current train perplexity5.534790992736816
INFO:root:current mean train loss 2167.180379000577
INFO:root:current train perplexity5.529716968536377
INFO:root:current mean train loss 2164.1464784335244
INFO:root:current train perplexity5.53389835357666
INFO:root:current mean train loss 2166.6907410552535
INFO:root:current train perplexity5.540694236755371
INFO:root:current mean train loss 2164.3878598827528
INFO:root:current train perplexity5.535431861877441
INFO:root:current mean train loss 2163.2122031678546
INFO:root:current train perplexity5.5278425216674805
INFO:root:current mean train loss 2165.1720366142167
INFO:root:current train perplexity5.526126384735107
INFO:root:current mean train loss 2166.8463254014987
INFO:root:current train perplexity5.526523590087891
INFO:root:current mean train loss 2165.684292057168
INFO:root:current train perplexity5.523660182952881
INFO:root:current mean train loss 2161.902752664354
INFO:root:current train perplexity5.517876625061035
INFO:root:current mean train loss 2162.491213277506
INFO:root:current train perplexity5.518293857574463
INFO:root:current mean train loss 2161.682177030123
INFO:root:current train perplexity5.517241954803467
INFO:root:current mean train loss 2162.170859765087
INFO:root:current train perplexity5.51394510269165
INFO:root:current mean train loss 2162.1883006145044
INFO:root:current train perplexity5.507172584533691
INFO:root:current mean train loss 2162.661944816534
INFO:root:current train perplexity5.508523941040039
INFO:root:current mean train loss 2162.3743366258873
INFO:root:current train perplexity5.509221076965332
INFO:root:current mean train loss 2163.107561346264
INFO:root:current train perplexity5.510709762573242
INFO:root:current mean train loss 2164.220423526451
INFO:root:current train perplexity5.510396480560303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.62s/it]
INFO:root:final mean train loss: 2164.247166343608
INFO:root:final train perplexity: 5.511602401733398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 2064.718523174313
INFO:root:eval perplexity: 5.3112287521362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 2478.603226032663
INFO:root:eval perplexity: 7.591808319091797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:05:48<9:49:52, 393.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2158.172126217165
INFO:root:current train perplexity5.419555187225342
INFO:root:current mean train loss 2143.166202703171
INFO:root:current train perplexity5.388715744018555
INFO:root:current mean train loss 2139.3938405770796
INFO:root:current train perplexity5.373403072357178
INFO:root:current mean train loss 2141.470555251207
INFO:root:current train perplexity5.396911144256592
INFO:root:current mean train loss 2141.264948277585
INFO:root:current train perplexity5.400667190551758
INFO:root:current mean train loss 2138.7272998561757
INFO:root:current train perplexity5.401299476623535
INFO:root:current mean train loss 2139.6762912448035
INFO:root:current train perplexity5.397925853729248
INFO:root:current mean train loss 2139.09954730804
INFO:root:current train perplexity5.392514705657959
INFO:root:current mean train loss 2140.6981622588373
INFO:root:current train perplexity5.398439407348633
INFO:root:current mean train loss 2140.0616041878307
INFO:root:current train perplexity5.398122310638428
INFO:root:current mean train loss 2139.3298355830507
INFO:root:current train perplexity5.39801025390625
INFO:root:current mean train loss 2139.801298665225
INFO:root:current train perplexity5.396008491516113
INFO:root:current mean train loss 2139.1856460511167
INFO:root:current train perplexity5.3960371017456055
INFO:root:current mean train loss 2139.270404021526
INFO:root:current train perplexity5.397819519042969
INFO:root:current mean train loss 2139.4660308817115
INFO:root:current train perplexity5.396902561187744
INFO:root:current mean train loss 2138.2662930023603
INFO:root:current train perplexity5.395528793334961
INFO:root:current mean train loss 2137.9464022097577
INFO:root:current train perplexity5.392873764038086
INFO:root:current mean train loss 2137.579528222049
INFO:root:current train perplexity5.394207000732422
INFO:root:current mean train loss 2136.917196160526
INFO:root:current train perplexity5.39167594909668
INFO:root:current mean train loss 2136.9680845959047
INFO:root:current train perplexity5.390921115875244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it]
INFO:root:final mean train loss: 2136.446437295134
INFO:root:final train perplexity: 5.392075061798096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it]
INFO:root:eval mean loss: 2037.9221987893395
INFO:root:eval perplexity: 5.197364330291748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 2455.6461025806184
INFO:root:eval perplexity: 7.450602054595947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:12:20<9:43:01, 393.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2115.26672221339
INFO:root:current train perplexity5.3305535316467285
INFO:root:current mean train loss 2117.263276787214
INFO:root:current train perplexity5.338149547576904
INFO:root:current mean train loss 2117.8252866518246
INFO:root:current train perplexity5.316831588745117
INFO:root:current mean train loss 2116.57874831758
INFO:root:current train perplexity5.322874546051025
INFO:root:current mean train loss 2118.829714174624
INFO:root:current train perplexity5.32912540435791
INFO:root:current mean train loss 2114.0893625513277
INFO:root:current train perplexity5.309312343597412
INFO:root:current mean train loss 2111.3129292034896
INFO:root:current train perplexity5.299027919769287
INFO:root:current mean train loss 2109.8213903218434
INFO:root:current train perplexity5.2957916259765625
INFO:root:current mean train loss 2112.5839656373446
INFO:root:current train perplexity5.29642915725708
INFO:root:current mean train loss 2110.9371914815224
INFO:root:current train perplexity5.293729782104492
INFO:root:current mean train loss 2112.6766976765725
INFO:root:current train perplexity5.291538238525391
INFO:root:current mean train loss 2112.8991919480527
INFO:root:current train perplexity5.291669845581055
INFO:root:current mean train loss 2112.2753236097274
INFO:root:current train perplexity5.291620254516602
INFO:root:current mean train loss 2113.3096322283945
INFO:root:current train perplexity5.295531272888184
INFO:root:current mean train loss 2114.5877782480234
INFO:root:current train perplexity5.298141002655029
INFO:root:current mean train loss 2114.531623830711
INFO:root:current train perplexity5.299860000610352
INFO:root:current mean train loss 2113.4396677978807
INFO:root:current train perplexity5.296041011810303
INFO:root:current mean train loss 2113.0780243910976
INFO:root:current train perplexity5.292368412017822
INFO:root:current mean train loss 2112.4672843148323
INFO:root:current train perplexity5.290510654449463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.77s/it]
INFO:root:final mean train loss: 2111.6273910206974
INFO:root:final train perplexity: 5.287557601928711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 2026.9934069045046
INFO:root:eval perplexity: 5.151630401611328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it]
INFO:root:eval mean loss: 2448.7094709247563
INFO:root:eval perplexity: 7.408454895019531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:18:52<9:36:03, 392.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2104.873779296875
INFO:root:current train perplexity5.234172821044922
INFO:root:current mean train loss 2097.6388259443265
INFO:root:current train perplexity5.274566173553467
INFO:root:current mean train loss 2084.958456405865
INFO:root:current train perplexity5.206748008728027
INFO:root:current mean train loss 2088.9112822781303
INFO:root:current train perplexity5.226006031036377
INFO:root:current mean train loss 2084.1431406177303
INFO:root:current train perplexity5.197953701019287
INFO:root:current mean train loss 2085.2527018067376
INFO:root:current train perplexity5.196194171905518
INFO:root:current mean train loss 2086.4002462864714
INFO:root:current train perplexity5.194890975952148
INFO:root:current mean train loss 2083.5204822871287
INFO:root:current train perplexity5.18679141998291
INFO:root:current mean train loss 2088.9856308192425
INFO:root:current train perplexity5.196285724639893
INFO:root:current mean train loss 2086.372958194906
INFO:root:current train perplexity5.187982559204102
INFO:root:current mean train loss 2086.4675636177403
INFO:root:current train perplexity5.188945770263672
INFO:root:current mean train loss 2087.7817339650737
INFO:root:current train perplexity5.187286376953125
INFO:root:current mean train loss 2089.234828375026
INFO:root:current train perplexity5.191873550415039
INFO:root:current mean train loss 2086.3471025772856
INFO:root:current train perplexity5.188530445098877
INFO:root:current mean train loss 2087.2548082478115
INFO:root:current train perplexity5.191684722900391
INFO:root:current mean train loss 2087.6057413980634
INFO:root:current train perplexity5.1926116943359375
INFO:root:current mean train loss 2087.0987751390217
INFO:root:current train perplexity5.190011978149414
INFO:root:current mean train loss 2087.7099004399406
INFO:root:current train perplexity5.1906514167785645
INFO:root:current mean train loss 2087.7382369038796
INFO:root:current train perplexity5.191399574279785
INFO:root:current mean train loss 2088.21032676356
INFO:root:current train perplexity5.192507743835449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it]
INFO:root:final mean train loss: 2089.5940428333215
INFO:root:final train perplexity: 5.196469783782959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 2016.8501167026818
INFO:root:eval perplexity: 5.1095428466796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it]
INFO:root:eval mean loss: 2439.849794644836
INFO:root:eval perplexity: 7.354969024658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:25:21<9:27:44, 391.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2116.604595947266
INFO:root:current train perplexity5.22035026550293
INFO:root:current mean train loss 2076.132578531901
INFO:root:current train perplexity5.148008823394775
INFO:root:current mean train loss 2083.4051053133876
INFO:root:current train perplexity5.141541481018066
INFO:root:current mean train loss 2077.776907348633
INFO:root:current train perplexity5.121751308441162
INFO:root:current mean train loss 2072.014630417597
INFO:root:current train perplexity5.11539363861084
INFO:root:current mean train loss 2070.0392549954927
INFO:root:current train perplexity5.120014190673828
INFO:root:current mean train loss 2067.051636923513
INFO:root:current train perplexity5.1102800369262695
INFO:root:current mean train loss 2066.483604092068
INFO:root:current train perplexity5.106953144073486
INFO:root:current mean train loss 2070.088705369903
INFO:root:current train perplexity5.115899085998535
INFO:root:current mean train loss 2070.909317149287
INFO:root:current train perplexity5.120194911956787
INFO:root:current mean train loss 2071.774167288986
INFO:root:current train perplexity5.125741958618164
INFO:root:current mean train loss 2071.52082257952
INFO:root:current train perplexity5.126347541809082
INFO:root:current mean train loss 2071.014242003394
INFO:root:current train perplexity5.124454021453857
INFO:root:current mean train loss 2070.1550235632694
INFO:root:current train perplexity5.124985694885254
INFO:root:current mean train loss 2069.4063139579666
INFO:root:current train perplexity5.121294975280762
INFO:root:current mean train loss 2068.8119579917507
INFO:root:current train perplexity5.120927810668945
INFO:root:current mean train loss 2069.6806144055026
INFO:root:current train perplexity5.118098735809326
INFO:root:current mean train loss 2069.2414882216344
INFO:root:current train perplexity5.115135192871094
INFO:root:current mean train loss 2069.6692033369463
INFO:root:current train perplexity5.114448070526123
INFO:root:current mean train loss 2069.203318977356
INFO:root:current train perplexity5.110515594482422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.96s/it]
INFO:root:final mean train loss: 2068.639446033472
INFO:root:final train perplexity: 5.111298561096191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 2001.549396487838
INFO:root:eval perplexity: 5.046705722808838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.16s/it]
INFO:root:eval mean loss: 2428.9855844484155
INFO:root:eval perplexity: 7.289908409118652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [1:32:11<9:29:06, 397.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2059.745255753801
INFO:root:current train perplexity5.021738052368164
INFO:root:current mean train loss 2054.1698247533645
INFO:root:current train perplexity5.0357136726379395
INFO:root:current mean train loss 2049.7304023066654
INFO:root:current train perplexity5.037447452545166
INFO:root:current mean train loss 2045.793741741237
INFO:root:current train perplexity5.028157711029053
INFO:root:current mean train loss 2054.84928869601
INFO:root:current train perplexity5.054079532623291
INFO:root:current mean train loss 2052.4612932542627
INFO:root:current train perplexity5.0474653244018555
INFO:root:current mean train loss 2053.86160120223
INFO:root:current train perplexity5.048539638519287
INFO:root:current mean train loss 2050.346283828549
INFO:root:current train perplexity5.045415878295898
INFO:root:current mean train loss 2046.7254721802196
INFO:root:current train perplexity5.031970024108887
INFO:root:current mean train loss 2048.0951645565133
INFO:root:current train perplexity5.032934188842773
INFO:root:current mean train loss 2049.841430193203
INFO:root:current train perplexity5.036039352416992
INFO:root:current mean train loss 2050.57342169635
INFO:root:current train perplexity5.036191463470459
INFO:root:current mean train loss 2049.7485781818414
INFO:root:current train perplexity5.0362677574157715
INFO:root:current mean train loss 2050.2291079901365
INFO:root:current train perplexity5.034751892089844
INFO:root:current mean train loss 2051.7688868342793
INFO:root:current train perplexity5.039851665496826
INFO:root:current mean train loss 2053.4977499193083
INFO:root:current train perplexity5.0431952476501465
INFO:root:current mean train loss 2051.8396361484424
INFO:root:current train perplexity5.039491176605225
INFO:root:current mean train loss 2053.6319873833972
INFO:root:current train perplexity5.047772407531738
INFO:root:current mean train loss 2053.5625976828305
INFO:root:current train perplexity5.046903610229492
INFO:root:current mean train loss 2053.1011556409717
INFO:root:current train perplexity5.046660423278809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.76s/it]
INFO:root:final mean train loss: 2051.682819437632
INFO:root:final train perplexity: 5.043399810791016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it]
INFO:root:eval mean loss: 1983.9341677401928
INFO:root:eval perplexity: 4.975318908691406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 2412.2748837301915
INFO:root:eval perplexity: 7.190959930419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [1:38:46<9:21:42, 396.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2028.3661159939236
INFO:root:current train perplexity4.946254253387451
INFO:root:current mean train loss 2046.8384439047281
INFO:root:current train perplexity4.96320104598999
INFO:root:current mean train loss 2046.113272599348
INFO:root:current train perplexity4.975136756896973
INFO:root:current mean train loss 2046.5175550212969
INFO:root:current train perplexity4.987285614013672
INFO:root:current mean train loss 2043.790909687328
INFO:root:current train perplexity4.986208915710449
INFO:root:current mean train loss 2041.0501140498081
INFO:root:current train perplexity4.979232311248779
INFO:root:current mean train loss 2039.3661454226992
INFO:root:current train perplexity4.986124515533447
INFO:root:current mean train loss 2041.2344104554356
INFO:root:current train perplexity4.989999771118164
INFO:root:current mean train loss 2040.4298858999928
INFO:root:current train perplexity4.988005638122559
INFO:root:current mean train loss 2039.169260980698
INFO:root:current train perplexity4.983516216278076
INFO:root:current mean train loss 2036.7321803981483
INFO:root:current train perplexity4.978615760803223
INFO:root:current mean train loss 2038.7235714600033
INFO:root:current train perplexity4.983358860015869
INFO:root:current mean train loss 2037.6793303421239
INFO:root:current train perplexity4.981143951416016
INFO:root:current mean train loss 2038.5978103254536
INFO:root:current train perplexity4.982686519622803
INFO:root:current mean train loss 2039.7260933604496
INFO:root:current train perplexity4.988450050354004
INFO:root:current mean train loss 2040.5823025697293
INFO:root:current train perplexity4.991860389709473
INFO:root:current mean train loss 2038.7771729696474
INFO:root:current train perplexity4.9886369705200195
INFO:root:current mean train loss 2038.9157567301525
INFO:root:current train perplexity4.989303112030029
INFO:root:current mean train loss 2038.8060363308641
INFO:root:current train perplexity4.987670421600342
INFO:root:current mean train loss 2037.3826087162952
INFO:root:current train perplexity4.984363079071045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.75s/it]
INFO:root:final mean train loss: 2036.35002135461
INFO:root:final train perplexity: 4.982780933380127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 1986.5680567964594
INFO:root:eval perplexity: 4.985928058624268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2416.681981296404
INFO:root:eval perplexity: 7.216923236846924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [1:45:28<9:17:19, 398.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.661533409441
INFO:root:current train perplexity4.833189964294434
INFO:root:current mean train loss 2034.4553465369152
INFO:root:current train perplexity4.938082695007324
INFO:root:current mean train loss 2023.5620716277963
INFO:root:current train perplexity4.9025163650512695
INFO:root:current mean train loss 2032.6516633149427
INFO:root:current train perplexity4.9402923583984375
INFO:root:current mean train loss 2030.1121732869726
INFO:root:current train perplexity4.929137229919434
INFO:root:current mean train loss 2024.5636713191632
INFO:root:current train perplexity4.919519901275635
INFO:root:current mean train loss 2021.8532876755194
INFO:root:current train perplexity4.915021896362305
INFO:root:current mean train loss 2020.6026483083049
INFO:root:current train perplexity4.9134931564331055
INFO:root:current mean train loss 2017.2232482419633
INFO:root:current train perplexity4.913333892822266
INFO:root:current mean train loss 2016.5420583141574
INFO:root:current train perplexity4.907695293426514
INFO:root:current mean train loss 2015.3698100171057
INFO:root:current train perplexity4.906672477722168
INFO:root:current mean train loss 2016.1486279547062
INFO:root:current train perplexity4.907290935516357
INFO:root:current mean train loss 2015.571319892217
INFO:root:current train perplexity4.906248569488525
INFO:root:current mean train loss 2015.7798954736222
INFO:root:current train perplexity4.9073262214660645
INFO:root:current mean train loss 2014.465732265864
INFO:root:current train perplexity4.9053874015808105
INFO:root:current mean train loss 2015.185642060317
INFO:root:current train perplexity4.9085540771484375
INFO:root:current mean train loss 2018.1434555555945
INFO:root:current train perplexity4.914493560791016
INFO:root:current mean train loss 2019.0040048850183
INFO:root:current train perplexity4.916159629821777
INFO:root:current mean train loss 2019.8905104979165
INFO:root:current train perplexity4.918606758117676
INFO:root:current mean train loss 2021.742677081847
INFO:root:current train perplexity4.924055099487305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it]
INFO:root:final mean train loss: 2021.4998580155443
INFO:root:final train perplexity: 4.924764156341553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 1970.1760085085605
INFO:root:eval perplexity: 4.920266628265381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.25s/it]
INFO:root:eval mean loss: 2401.848016400709
INFO:root:eval perplexity: 7.1299004554748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [1:52:01<9:08:51, 396.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.7769345370207
INFO:root:current train perplexity4.937839984893799
INFO:root:current mean train loss 2007.8220922591838
INFO:root:current train perplexity4.883737564086914
INFO:root:current mean train loss 2014.6240310668945
INFO:root:current train perplexity4.889163017272949
INFO:root:current mean train loss 2016.7926295958844
INFO:root:current train perplexity4.8920745849609375
INFO:root:current mean train loss 2021.0190967497279
INFO:root:current train perplexity4.908954620361328
INFO:root:current mean train loss 2018.2154156950867
INFO:root:current train perplexity4.9047088623046875
INFO:root:current mean train loss 2018.9915874392486
INFO:root:current train perplexity4.907729148864746
INFO:root:current mean train loss 2022.7786916355192
INFO:root:current train perplexity4.9175591468811035
INFO:root:current mean train loss 2023.1830313742698
INFO:root:current train perplexity4.925264358520508
INFO:root:current mean train loss 2020.2716520363504
INFO:root:current train perplexity4.920019149780273
INFO:root:current mean train loss 2021.7476867226994
INFO:root:current train perplexity4.928512096405029
INFO:root:current mean train loss 2022.3523459900107
INFO:root:current train perplexity4.9254865646362305
INFO:root:current mean train loss 2024.5478936426389
INFO:root:current train perplexity4.9257917404174805
INFO:root:current mean train loss 2022.9703167742198
INFO:root:current train perplexity4.925134658813477
INFO:root:current mean train loss 2022.19576304446
INFO:root:current train perplexity4.923311710357666
INFO:root:current mean train loss 2020.1148399525987
INFO:root:current train perplexity4.917934894561768
INFO:root:current mean train loss 2021.235553325635
INFO:root:current train perplexity4.920084476470947
INFO:root:current mean train loss 2020.2905523995692
INFO:root:current train perplexity4.918978214263916
INFO:root:current mean train loss 2018.7211672896046
INFO:root:current train perplexity4.913462162017822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.91s/it]
INFO:root:final mean train loss: 2018.858877238756
INFO:root:final train perplexity: 4.914516925811768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it]
INFO:root:eval mean loss: 1981.6384541396553
INFO:root:eval perplexity: 4.966090202331543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 2418.118736321199
INFO:root:eval perplexity: 7.225410461425781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [1:58:31<8:59:07, 394.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.646044921875
INFO:root:current train perplexity4.890389919281006
INFO:root:current mean train loss 1979.5430396670388
INFO:root:current train perplexity4.799069881439209
INFO:root:current mean train loss 1988.8689530535441
INFO:root:current train perplexity4.824012279510498
INFO:root:current mean train loss 1997.6616855308657
INFO:root:current train perplexity4.848769664764404
INFO:root:current mean train loss 1997.6786398051697
INFO:root:current train perplexity4.846869945526123
INFO:root:current mean train loss 1997.948182965269
INFO:root:current train perplexity4.844263553619385
INFO:root:current mean train loss 1998.7042115266659
INFO:root:current train perplexity4.8484368324279785
INFO:root:current mean train loss 2003.220135887633
INFO:root:current train perplexity4.86325216293335
INFO:root:current mean train loss 2001.2398041719234
INFO:root:current train perplexity4.85669469833374
INFO:root:current mean train loss 2001.3143553338657
INFO:root:current train perplexity4.8547587394714355
INFO:root:current mean train loss 2001.541361065765
INFO:root:current train perplexity4.857453346252441
INFO:root:current mean train loss 2002.4069296167986
INFO:root:current train perplexity4.857047080993652
INFO:root:current mean train loss 2005.4904978645293
INFO:root:current train perplexity4.86691427230835
INFO:root:current mean train loss 2005.5515277029454
INFO:root:current train perplexity4.866476058959961
INFO:root:current mean train loss 2005.644624475228
INFO:root:current train perplexity4.8664984703063965
INFO:root:current mean train loss 2006.6853389093646
INFO:root:current train perplexity4.867329120635986
INFO:root:current mean train loss 2008.3031618112345
INFO:root:current train perplexity4.86902379989624
INFO:root:current mean train loss 2007.5720693101632
INFO:root:current train perplexity4.869629383087158
INFO:root:current mean train loss 2007.6873792146382
INFO:root:current train perplexity4.869645595550537
INFO:root:current mean train loss 2007.1074623728675
INFO:root:current train perplexity4.8686065673828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.91s/it]
INFO:root:final mean train loss: 2006.2188468005882
INFO:root:final train perplexity: 4.865769386291504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 1955.4761742125165
INFO:root:eval perplexity: 4.862119197845459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it]
INFO:root:eval mean loss: 2391.1835747035684
INFO:root:eval perplexity: 7.067986011505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:05:01<8:51:05, 393.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.1102849786932
INFO:root:current train perplexity4.97145938873291
INFO:root:current mean train loss 1996.603852819224
INFO:root:current train perplexity4.828901290893555
INFO:root:current mean train loss 1993.3281563423775
INFO:root:current train perplexity4.816635608673096
INFO:root:current mean train loss 1995.3364155455406
INFO:root:current train perplexity4.8186798095703125
INFO:root:current mean train loss 2001.5905284429614
INFO:root:current train perplexity4.832319259643555
INFO:root:current mean train loss 2000.7314527957376
INFO:root:current train perplexity4.832343578338623
INFO:root:current mean train loss 1997.99395182815
INFO:root:current train perplexity4.826292037963867
INFO:root:current mean train loss 1994.7474542760453
INFO:root:current train perplexity4.817127227783203
INFO:root:current mean train loss 1994.1310619344968
INFO:root:current train perplexity4.813068389892578
INFO:root:current mean train loss 1995.770723487705
INFO:root:current train perplexity4.818196773529053
INFO:root:current mean train loss 1994.7275947227404
INFO:root:current train perplexity4.817642688751221
INFO:root:current mean train loss 1995.1617703633299
INFO:root:current train perplexity4.822754859924316
INFO:root:current mean train loss 1994.4361967845362
INFO:root:current train perplexity4.8200364112854
INFO:root:current mean train loss 1994.2043623238937
INFO:root:current train perplexity4.820840358734131
INFO:root:current mean train loss 1995.2430583884109
INFO:root:current train perplexity4.826229095458984
INFO:root:current mean train loss 1995.8420245738287
INFO:root:current train perplexity4.829796314239502
INFO:root:current mean train loss 1997.2292404457025
INFO:root:current train perplexity4.830212593078613
INFO:root:current mean train loss 1998.0802196188117
INFO:root:current train perplexity4.830149173736572
INFO:root:current mean train loss 1996.778384697555
INFO:root:current train perplexity4.828763484954834
INFO:root:current mean train loss 1995.6036681811345
INFO:root:current train perplexity4.825551986694336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it]
INFO:root:final mean train loss: 1996.0148420078972
INFO:root:final train perplexity: 4.82676887512207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 1963.4878107165614
INFO:root:eval perplexity: 4.89372444152832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it]
INFO:root:eval mean loss: 2398.41422439467
INFO:root:eval perplexity: 7.109904766082764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:11:35<8:44:45, 393.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.4744622646233
INFO:root:current train perplexity4.761829853057861
INFO:root:current mean train loss 1972.4915007447166
INFO:root:current train perplexity4.749215126037598
INFO:root:current mean train loss 1977.0812926990716
INFO:root:current train perplexity4.775875091552734
INFO:root:current mean train loss 1982.5004346279268
INFO:root:current train perplexity4.774537086486816
INFO:root:current mean train loss 1987.2619712325597
INFO:root:current train perplexity4.787328720092773
INFO:root:current mean train loss 1987.1617644527626
INFO:root:current train perplexity4.782722473144531
INFO:root:current mean train loss 1982.0171421868888
INFO:root:current train perplexity4.775821685791016
INFO:root:current mean train loss 1985.514247372928
INFO:root:current train perplexity4.780797004699707
INFO:root:current mean train loss 1986.911164530412
INFO:root:current train perplexity4.786046981811523
INFO:root:current mean train loss 1987.4656731521234
INFO:root:current train perplexity4.787006855010986
INFO:root:current mean train loss 1987.728603976179
INFO:root:current train perplexity4.788175582885742
INFO:root:current mean train loss 1987.7970978131516
INFO:root:current train perplexity4.787865161895752
INFO:root:current mean train loss 1987.6305153317949
INFO:root:current train perplexity4.788198471069336
INFO:root:current mean train loss 1986.0438577938294
INFO:root:current train perplexity4.783672332763672
INFO:root:current mean train loss 1985.419766805833
INFO:root:current train perplexity4.783939361572266
INFO:root:current mean train loss 1984.5100319746487
INFO:root:current train perplexity4.782549858093262
INFO:root:current mean train loss 1983.8985200222126
INFO:root:current train perplexity4.7818779945373535
INFO:root:current mean train loss 1984.1459598727718
INFO:root:current train perplexity4.784314155578613
INFO:root:current mean train loss 1984.9580433250705
INFO:root:current train perplexity4.784322738647461
INFO:root:current mean train loss 1986.2328048950008
INFO:root:current train perplexity4.78609037399292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.92s/it]
INFO:root:final mean train loss: 1985.3729595236266
INFO:root:final train perplexity: 4.786428928375244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it]
INFO:root:eval mean loss: 1953.6900535204732
INFO:root:eval perplexity: 4.855100154876709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2395.4013901297926
INFO:root:eval perplexity: 7.092407703399658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [2:18:07<8:37:34, 393.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1992.665540422712
INFO:root:current train perplexity4.782259941101074
INFO:root:current mean train loss 1994.4527627015725
INFO:root:current train perplexity4.782715320587158
INFO:root:current mean train loss 1980.3542227745056
INFO:root:current train perplexity4.7535552978515625
INFO:root:current mean train loss 1984.7566562609727
INFO:root:current train perplexity4.773569583892822
INFO:root:current mean train loss 1983.9970895867598
INFO:root:current train perplexity4.773383617401123
INFO:root:current mean train loss 1981.276156418615
INFO:root:current train perplexity4.766364097595215
INFO:root:current mean train loss 1980.0140312008741
INFO:root:current train perplexity4.762553691864014
INFO:root:current mean train loss 1981.4090201564568
INFO:root:current train perplexity4.763491153717041
INFO:root:current mean train loss 1984.6413602739851
INFO:root:current train perplexity4.770026206970215
INFO:root:current mean train loss 1982.419245253048
INFO:root:current train perplexity4.763777732849121
INFO:root:current mean train loss 1984.0843578685415
INFO:root:current train perplexity4.766720771789551
INFO:root:current mean train loss 1981.2866829736836
INFO:root:current train perplexity4.7625932693481445
INFO:root:current mean train loss 1980.3434927387602
INFO:root:current train perplexity4.760723114013672
INFO:root:current mean train loss 1979.4003811726527
INFO:root:current train perplexity4.762560844421387
INFO:root:current mean train loss 1979.316788474282
INFO:root:current train perplexity4.761653900146484
INFO:root:current mean train loss 1979.7518297994657
INFO:root:current train perplexity4.760135650634766
INFO:root:current mean train loss 1980.5904576398325
INFO:root:current train perplexity4.763791561126709
INFO:root:current mean train loss 1979.243329232809
INFO:root:current train perplexity4.759870529174805
INFO:root:current mean train loss 1979.2367482020936
INFO:root:current train perplexity4.760739803314209
INFO:root:current mean train loss 1978.5608707732217
INFO:root:current train perplexity4.757956504821777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it]
INFO:root:final mean train loss: 1977.852324562246
INFO:root:final train perplexity: 4.758123397827148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 1945.681513360206
INFO:root:eval perplexity: 4.823756217956543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 2387.1656957315213
INFO:root:eval perplexity: 7.044801235198975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:24:56<8:36:57, 397.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.4671095756635
INFO:root:current train perplexity4.708865165710449
INFO:root:current mean train loss 1969.306462811597
INFO:root:current train perplexity4.698025226593018
INFO:root:current mean train loss 1968.8768695090716
INFO:root:current train perplexity4.693029880523682
INFO:root:current mean train loss 1966.0361429577538
INFO:root:current train perplexity4.688066482543945
INFO:root:current mean train loss 1971.187883760158
INFO:root:current train perplexity4.698367118835449
INFO:root:current mean train loss 1972.3127876002127
INFO:root:current train perplexity4.7169413566589355
INFO:root:current mean train loss 1966.7374971341592
INFO:root:current train perplexity4.7059431076049805
INFO:root:current mean train loss 1964.0301417342132
INFO:root:current train perplexity4.701390743255615
INFO:root:current mean train loss 1965.7163276104309
INFO:root:current train perplexity4.706003189086914
INFO:root:current mean train loss 1969.2449150751943
INFO:root:current train perplexity4.711095333099365
INFO:root:current mean train loss 1971.4004056420374
INFO:root:current train perplexity4.716719627380371
INFO:root:current mean train loss 1971.998190174932
INFO:root:current train perplexity4.71999454498291
INFO:root:current mean train loss 1971.822229569668
INFO:root:current train perplexity4.7222371101379395
INFO:root:current mean train loss 1972.7020095636267
INFO:root:current train perplexity4.727658271789551
INFO:root:current mean train loss 1971.8614032898156
INFO:root:current train perplexity4.728379726409912
INFO:root:current mean train loss 1971.329372321127
INFO:root:current train perplexity4.726050853729248
INFO:root:current mean train loss 1971.7142012938723
INFO:root:current train perplexity4.7280707359313965
INFO:root:current mean train loss 1970.555844310711
INFO:root:current train perplexity4.726655006408691
INFO:root:current mean train loss 1971.0840374263798
INFO:root:current train perplexity4.728379726409912
INFO:root:current mean train loss 1970.5151482266456
INFO:root:current train perplexity4.728735446929932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it]
INFO:root:final mean train loss: 1970.108464766679
INFO:root:final train perplexity: 4.729153156280518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 1942.289484118739
INFO:root:eval perplexity: 4.81054162979126
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 2383.317295372063
INFO:root:eval perplexity: 7.022661209106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:31:32<8:29:39, 397.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.5430962456596
INFO:root:current train perplexity4.705361843109131
INFO:root:current mean train loss 1967.2814208984375
INFO:root:current train perplexity4.710005760192871
INFO:root:current mean train loss 1963.5042905610183
INFO:root:current train perplexity4.700255870819092
INFO:root:current mean train loss 1963.1763728215144
INFO:root:current train perplexity4.7072248458862305
INFO:root:current mean train loss 1971.8331949039382
INFO:root:current train perplexity4.722662448883057
INFO:root:current mean train loss 1967.751457395392
INFO:root:current train perplexity4.710749626159668
INFO:root:current mean train loss 1971.4965526636097
INFO:root:current train perplexity4.715851306915283
INFO:root:current mean train loss 1971.5173777133605
INFO:root:current train perplexity4.718152046203613
INFO:root:current mean train loss 1969.4244084390361
INFO:root:current train perplexity4.715463638305664
INFO:root:current mean train loss 1967.3605250503078
INFO:root:current train perplexity4.708886623382568
INFO:root:current mean train loss 1965.608900605648
INFO:root:current train perplexity4.703054904937744
INFO:root:current mean train loss 1965.3938132919184
INFO:root:current train perplexity4.701261043548584
INFO:root:current mean train loss 1965.747258054748
INFO:root:current train perplexity4.701709270477295
INFO:root:current mean train loss 1966.2271568682554
INFO:root:current train perplexity4.702221393585205
INFO:root:current mean train loss 1965.4687758887374
INFO:root:current train perplexity4.701302528381348
INFO:root:current mean train loss 1965.384724167158
INFO:root:current train perplexity4.703669548034668
INFO:root:current mean train loss 1965.6015707343288
INFO:root:current train perplexity4.706147193908691
INFO:root:current mean train loss 1964.5976602735466
INFO:root:current train perplexity4.705862998962402
INFO:root:current mean train loss 1964.7088642423116
INFO:root:current train perplexity4.706672191619873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.39s/it]
INFO:root:final mean train loss: 1963.5513069279796
INFO:root:final train perplexity: 4.70475959777832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it]
INFO:root:eval mean loss: 1932.5203584711603
INFO:root:eval perplexity: 4.7726850509643555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 2374.821725398936
INFO:root:eval perplexity: 6.974039077758789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:38:15<8:25:18, 398.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.7185232979912
INFO:root:current train perplexity4.534653186798096
INFO:root:current mean train loss 1958.2674001533294
INFO:root:current train perplexity4.6274189949035645
INFO:root:current mean train loss 1968.3330773984753
INFO:root:current train perplexity4.679431438446045
INFO:root:current mean train loss 1964.2661291861766
INFO:root:current train perplexity4.670868873596191
INFO:root:current mean train loss 1958.4753957837454
INFO:root:current train perplexity4.6698431968688965
INFO:root:current mean train loss 1953.09592342941
INFO:root:current train perplexity4.657427787780762
INFO:root:current mean train loss 1949.6697569694707
INFO:root:current train perplexity4.661299705505371
INFO:root:current mean train loss 1949.4781673706573
INFO:root:current train perplexity4.661443710327148
INFO:root:current mean train loss 1949.852439379308
INFO:root:current train perplexity4.665401458740234
INFO:root:current mean train loss 1953.7442598689877
INFO:root:current train perplexity4.671922206878662
INFO:root:current mean train loss 1954.14058160261
INFO:root:current train perplexity4.672159194946289
INFO:root:current mean train loss 1953.7036966463415
INFO:root:current train perplexity4.670938491821289
INFO:root:current mean train loss 1954.6654185221623
INFO:root:current train perplexity4.672359943389893
INFO:root:current mean train loss 1955.466366593493
INFO:root:current train perplexity4.671053409576416
INFO:root:current mean train loss 1955.0135393068142
INFO:root:current train perplexity4.668524742126465
INFO:root:current mean train loss 1955.6670650084761
INFO:root:current train perplexity4.669633388519287
INFO:root:current mean train loss 1956.1975171339016
INFO:root:current train perplexity4.668795585632324
INFO:root:current mean train loss 1955.6822021341352
INFO:root:current train perplexity4.6684889793396
INFO:root:current mean train loss 1955.1255880586996
INFO:root:current train perplexity4.669322967529297
INFO:root:current mean train loss 1955.5124672388117
INFO:root:current train perplexity4.673455238342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.57s/it]
INFO:root:final mean train loss: 1954.7216122194907
INFO:root:final train perplexity: 4.672111511230469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 1929.9641052678967
INFO:root:eval perplexity: 4.762828350067139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 2374.1537345723905
INFO:root:eval perplexity: 6.970228672027588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:45:02<8:21:47, 401.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1951.4178517659504
INFO:root:current train perplexity4.667593955993652
INFO:root:current mean train loss 1953.456545922064
INFO:root:current train perplexity4.669450283050537
INFO:root:current mean train loss 1951.3197174072266
INFO:root:current train perplexity4.6462812423706055
INFO:root:current mean train loss 1948.0780462571133
INFO:root:current train perplexity4.642858028411865
INFO:root:current mean train loss 1950.2873897912368
INFO:root:current train perplexity4.646625995635986
INFO:root:current mean train loss 1955.5904694768308
INFO:root:current train perplexity4.654808044433594
INFO:root:current mean train loss 1955.6361868442634
INFO:root:current train perplexity4.654711723327637
INFO:root:current mean train loss 1954.5391527038912
INFO:root:current train perplexity4.653100967407227
INFO:root:current mean train loss 1951.390295528671
INFO:root:current train perplexity4.6522746086120605
INFO:root:current mean train loss 1950.9696462391776
INFO:root:current train perplexity4.655362606048584
INFO:root:current mean train loss 1950.1149957180023
INFO:root:current train perplexity4.652586936950684
INFO:root:current mean train loss 1950.6054067374125
INFO:root:current train perplexity4.652153491973877
INFO:root:current mean train loss 1952.0485605476729
INFO:root:current train perplexity4.6545329093933105
INFO:root:current mean train loss 1950.1471938395428
INFO:root:current train perplexity4.651641368865967
INFO:root:current mean train loss 1949.8221860735605
INFO:root:current train perplexity4.651834964752197
INFO:root:current mean train loss 1949.867142644767
INFO:root:current train perplexity4.650569438934326
INFO:root:current mean train loss 1949.6872505225572
INFO:root:current train perplexity4.649167537689209
INFO:root:current mean train loss 1949.172457170597
INFO:root:current train perplexity4.649564266204834
INFO:root:current mean train loss 1949.0497712921679
INFO:root:current train perplexity4.651923656463623
INFO:root:current mean train loss 1950.5758666992188
INFO:root:current train perplexity4.655359268188477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.56s/it]
INFO:root:final mean train loss: 1949.7306397592426
INFO:root:final train perplexity: 4.653756618499756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 1928.6218049610761
INFO:root:eval perplexity: 4.757660865783691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it]
INFO:root:eval mean loss: 2374.435118330286
INFO:root:eval perplexity: 6.971833229064941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:51:34<8:11:26, 398.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1922.6286740186738
INFO:root:current train perplexity4.582756519317627
INFO:root:current mean train loss 1942.5070004294105
INFO:root:current train perplexity4.604855060577393
INFO:root:current mean train loss 1938.22311667288
INFO:root:current train perplexity4.596512794494629
INFO:root:current mean train loss 1937.3084655940706
INFO:root:current train perplexity4.607067108154297
INFO:root:current mean train loss 1934.1956850774163
INFO:root:current train perplexity4.605384826660156
INFO:root:current mean train loss 1938.7033567305193
INFO:root:current train perplexity4.611163139343262
INFO:root:current mean train loss 1939.8633378098796
INFO:root:current train perplexity4.605480194091797
INFO:root:current mean train loss 1939.3474844290338
INFO:root:current train perplexity4.602938652038574
INFO:root:current mean train loss 1939.7182157065156
INFO:root:current train perplexity4.606396198272705
INFO:root:current mean train loss 1940.4898716666114
INFO:root:current train perplexity4.6133198738098145
INFO:root:current mean train loss 1939.7460352359885
INFO:root:current train perplexity4.610823154449463
INFO:root:current mean train loss 1940.7540979677915
INFO:root:current train perplexity4.613440036773682
INFO:root:current mean train loss 1939.2012860761545
INFO:root:current train perplexity4.613105773925781
INFO:root:current mean train loss 1941.1145021351836
INFO:root:current train perplexity4.618346214294434
INFO:root:current mean train loss 1941.6142717053044
INFO:root:current train perplexity4.620148181915283
INFO:root:current mean train loss 1942.4235535658156
INFO:root:current train perplexity4.623908519744873
INFO:root:current mean train loss 1942.1843824090208
INFO:root:current train perplexity4.6238627433776855
INFO:root:current mean train loss 1941.9429158972707
INFO:root:current train perplexity4.625458717346191
INFO:root:current mean train loss 1942.630145784178
INFO:root:current train perplexity4.629543781280518
INFO:root:current mean train loss 1942.9207938507252
INFO:root:current train perplexity4.62833833694458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.27s/it]
INFO:root:final mean train loss: 1942.9408355420487
INFO:root:final train perplexity: 4.628903388977051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 1929.5232816655584
INFO:root:eval perplexity: 4.761130332946777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.41s/it]
INFO:root:eval mean loss: 2373.417949270695
INFO:root:eval perplexity: 6.966036796569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:58:08<8:03:27, 397.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.1020339439656
INFO:root:current train perplexity4.646809101104736
INFO:root:current mean train loss 1921.3540888919106
INFO:root:current train perplexity4.598381519317627
INFO:root:current mean train loss 1919.0275992460029
INFO:root:current train perplexity4.573606014251709
INFO:root:current mean train loss 1925.832647739176
INFO:root:current train perplexity4.5843400955200195
INFO:root:current mean train loss 1928.2175250324099
INFO:root:current train perplexity4.5879740715026855
INFO:root:current mean train loss 1930.9715221774193
INFO:root:current train perplexity4.587784290313721
INFO:root:current mean train loss 1934.1920166015625
INFO:root:current train perplexity4.597557067871094
INFO:root:current mean train loss 1935.3030385845254
INFO:root:current train perplexity4.6022796630859375
INFO:root:current mean train loss 1931.4592231092474
INFO:root:current train perplexity4.597630023956299
INFO:root:current mean train loss 1932.0696018672936
INFO:root:current train perplexity4.600200176239014
INFO:root:current mean train loss 1932.7568310916085
INFO:root:current train perplexity4.602576732635498
INFO:root:current mean train loss 1933.3672046826086
INFO:root:current train perplexity4.605414867401123
INFO:root:current mean train loss 1933.4444077435662
INFO:root:current train perplexity4.604034900665283
INFO:root:current mean train loss 1935.2444709699178
INFO:root:current train perplexity4.606964588165283
INFO:root:current mean train loss 1937.0865551355935
INFO:root:current train perplexity4.609086036682129
INFO:root:current mean train loss 1936.8306601919778
INFO:root:current train perplexity4.609664440155029
INFO:root:current mean train loss 1938.3026829847238
INFO:root:current train perplexity4.610003471374512
INFO:root:current mean train loss 1937.8924804270878
INFO:root:current train perplexity4.608895301818848
INFO:root:current mean train loss 1937.936989183703
INFO:root:current train perplexity4.609560489654541
INFO:root:current mean train loss 1938.5309409588667
INFO:root:current train perplexity4.611209869384766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.08s/it]
INFO:root:final mean train loss: 1938.0031374778882
INFO:root:final train perplexity: 4.610912799835205
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 1928.1597619022884
INFO:root:eval perplexity: 4.755884647369385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.29s/it]
INFO:root:eval mean loss: 2371.2751482158687
INFO:root:eval perplexity: 6.95383882522583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [3:04:44<7:56:12, 396.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1936.2409700520834
INFO:root:current train perplexity4.593522071838379
INFO:root:current mean train loss 1920.914445452009
INFO:root:current train perplexity4.55997371673584
INFO:root:current mean train loss 1921.4953488991478
INFO:root:current train perplexity4.566057205200195
INFO:root:current mean train loss 1922.7383518880208
INFO:root:current train perplexity4.559080123901367
INFO:root:current mean train loss 1928.6969153474506
INFO:root:current train perplexity4.57345724105835
INFO:root:current mean train loss 1935.5309415336278
INFO:root:current train perplexity4.580842971801758
INFO:root:current mean train loss 1934.8975142867478
INFO:root:current train perplexity4.586562156677246
INFO:root:current mean train loss 1936.6216467678933
INFO:root:current train perplexity4.59321403503418
INFO:root:current mean train loss 1936.2126195591518
INFO:root:current train perplexity4.588315486907959
INFO:root:current mean train loss 1934.0652322465946
INFO:root:current train perplexity4.585247993469238
INFO:root:current mean train loss 1933.678475086301
INFO:root:current train perplexity4.583951473236084
INFO:root:current mean train loss 1932.038193671044
INFO:root:current train perplexity4.583595275878906
INFO:root:current mean train loss 1933.790101773131
INFO:root:current train perplexity4.58819580078125
INFO:root:current mean train loss 1932.8276837713067
INFO:root:current train perplexity4.584526062011719
INFO:root:current mean train loss 1931.8135574185646
INFO:root:current train perplexity4.581986904144287
INFO:root:current mean train loss 1931.704673704117
INFO:root:current train perplexity4.580927848815918
INFO:root:current mean train loss 1931.978116327542
INFO:root:current train perplexity4.583598613739014
INFO:root:current mean train loss 1932.3321756024427
INFO:root:current train perplexity4.587130546569824
INFO:root:current mean train loss 1931.7551227213542
INFO:root:current train perplexity4.584928035736084
INFO:root:current mean train loss 1932.823860883109
INFO:root:current train perplexity4.589450359344482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.30s/it]
INFO:root:final mean train loss: 1931.963552593283
INFO:root:final train perplexity: 4.58900260925293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it]
INFO:root:eval mean loss: 1927.404813293024
INFO:root:eval perplexity: 4.752980709075928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 2372.7531162559562
INFO:root:eval perplexity: 6.962249755859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:11:35<7:54:36, 401.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.6335661514945
INFO:root:current train perplexity4.530820369720459
INFO:root:current mean train loss 1917.4451948801677
INFO:root:current train perplexity4.553820610046387
INFO:root:current mean train loss 1924.7963787758188
INFO:root:current train perplexity4.569361686706543
INFO:root:current mean train loss 1923.8143646863043
INFO:root:current train perplexity4.5667924880981445
INFO:root:current mean train loss 1926.4966892149391
INFO:root:current train perplexity4.5690131187438965
INFO:root:current mean train loss 1927.60510625066
INFO:root:current train perplexity4.575425624847412
INFO:root:current mean train loss 1926.910957997934
INFO:root:current train perplexity4.572300910949707
INFO:root:current mean train loss 1924.7529372398299
INFO:root:current train perplexity4.561103343963623
INFO:root:current mean train loss 1924.4185833439165
INFO:root:current train perplexity4.5608601570129395
INFO:root:current mean train loss 1926.6080258277154
INFO:root:current train perplexity4.563440799713135
INFO:root:current mean train loss 1927.1600683862036
INFO:root:current train perplexity4.56259822845459
INFO:root:current mean train loss 1927.823101786159
INFO:root:current train perplexity4.563767910003662
INFO:root:current mean train loss 1926.947626356001
INFO:root:current train perplexity4.562816619873047
INFO:root:current mean train loss 1926.775002490515
INFO:root:current train perplexity4.564274311065674
INFO:root:current mean train loss 1925.9199357838158
INFO:root:current train perplexity4.562465667724609
INFO:root:current mean train loss 1926.6238147218023
INFO:root:current train perplexity4.5629167556762695
INFO:root:current mean train loss 1924.851714149998
INFO:root:current train perplexity4.5626726150512695
INFO:root:current mean train loss 1926.495545251029
INFO:root:current train perplexity4.564479827880859
INFO:root:current mean train loss 1925.925545174274
INFO:root:current train perplexity4.564227104187012

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.81s/it]
INFO:root:final mean train loss: 1924.9731244939899
INFO:root:final train perplexity: 4.563773155212402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 1924.810678035655
INFO:root:eval perplexity: 4.743018627166748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 2370.817648163924
INFO:root:eval perplexity: 6.95123815536499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:18:17<7:48:25, 401.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1921.1244710286458
INFO:root:current train perplexity4.6136369705200195
INFO:root:current mean train loss 1933.8012840900947
INFO:root:current train perplexity4.55903434753418
INFO:root:current mean train loss 1924.6324579704321
INFO:root:current train perplexity4.555357933044434
INFO:root:current mean train loss 1919.7103607276497
INFO:root:current train perplexity4.547518730163574
INFO:root:current mean train loss 1921.0830782491596
INFO:root:current train perplexity4.550764083862305
INFO:root:current mean train loss 1920.088711541856
INFO:root:current train perplexity4.548044204711914
INFO:root:current mean train loss 1922.5982840401787
INFO:root:current train perplexity4.54828405380249
INFO:root:current mean train loss 1921.5935776553133
INFO:root:current train perplexity4.544158935546875
INFO:root:current mean train loss 1923.0973755939044
INFO:root:current train perplexity4.550960063934326
INFO:root:current mean train loss 1921.3501445237298
INFO:root:current train perplexity4.546392440795898
INFO:root:current mean train loss 1924.1976860356401
INFO:root:current train perplexity4.553136825561523
INFO:root:current mean train loss 1923.74282184735
INFO:root:current train perplexity4.550528049468994
INFO:root:current mean train loss 1923.8824621410386
INFO:root:current train perplexity4.552577018737793
INFO:root:current mean train loss 1925.0050230674656
INFO:root:current train perplexity4.554849147796631
INFO:root:current mean train loss 1926.1556293387375
INFO:root:current train perplexity4.559312343597412
INFO:root:current mean train loss 1925.5769668285857
INFO:root:current train perplexity4.557137489318848
INFO:root:current mean train loss 1923.7635052706455
INFO:root:current train perplexity4.554044246673584
INFO:root:current mean train loss 1921.6300810249734
INFO:root:current train perplexity4.54756498336792
INFO:root:current mean train loss 1921.420260149448
INFO:root:current train perplexity4.549270153045654
INFO:root:current mean train loss 1920.9160669725436
INFO:root:current train perplexity4.548681259155273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.31s/it]
INFO:root:final mean train loss: 1920.5594572604934
INFO:root:final train perplexity: 4.547914028167725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 1927.2854250644116
INFO:root:eval perplexity: 4.7525224685668945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it]
INFO:root:eval mean loss: 2371.9914442562886
INFO:root:eval perplexity: 6.957913398742676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:24:50<7:38:33, 398.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.9053203876201
INFO:root:current train perplexity4.567392349243164
INFO:root:current mean train loss 1904.6109745086185
INFO:root:current train perplexity4.4976091384887695
INFO:root:current mean train loss 1911.222038876694
INFO:root:current train perplexity4.526454448699951
INFO:root:current mean train loss 1913.3627480348925
INFO:root:current train perplexity4.524541854858398
INFO:root:current mean train loss 1915.3029702056742
INFO:root:current train perplexity4.531768798828125
INFO:root:current mean train loss 1914.9154389239989
INFO:root:current train perplexity4.529653072357178
INFO:root:current mean train loss 1915.906494530626
INFO:root:current train perplexity4.528275489807129
INFO:root:current mean train loss 1917.8102679292033
INFO:root:current train perplexity4.532186985015869
INFO:root:current mean train loss 1919.4977356400386
INFO:root:current train perplexity4.531138896942139
INFO:root:current mean train loss 1920.2839656030642
INFO:root:current train perplexity4.531138896942139
INFO:root:current mean train loss 1918.5494701244213
INFO:root:current train perplexity4.526790142059326
INFO:root:current mean train loss 1916.9819480123572
INFO:root:current train perplexity4.5270490646362305
INFO:root:current mean train loss 1917.373926856584
INFO:root:current train perplexity4.528093338012695
INFO:root:current mean train loss 1918.460386986826
INFO:root:current train perplexity4.529165744781494
INFO:root:current mean train loss 1916.5662543041342
INFO:root:current train perplexity4.526316165924072
INFO:root:current mean train loss 1915.1278704921976
INFO:root:current train perplexity4.523584842681885
INFO:root:current mean train loss 1914.464090983073
INFO:root:current train perplexity4.523138046264648
INFO:root:current mean train loss 1915.4259855020641
INFO:root:current train perplexity4.525637626647949
INFO:root:current mean train loss 1915.3173838152682
INFO:root:current train perplexity4.526458740234375
INFO:root:current mean train loss 1916.4829597829657
INFO:root:current train perplexity4.529735088348389

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.68s/it]
INFO:root:final mean train loss: 1915.2972326543195
INFO:root:final train perplexity: 4.529079914093018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 1909.722954499806
INFO:root:eval perplexity: 4.6854963302612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 2361.6115402329897
INFO:root:eval perplexity: 6.8990983963012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:31:22<7:29:50, 396.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.9108744776527
INFO:root:current train perplexity4.453489303588867
INFO:root:current mean train loss 1889.4024009437828
INFO:root:current train perplexity4.461863040924072
INFO:root:current mean train loss 1898.1839062098122
INFO:root:current train perplexity4.477120876312256
INFO:root:current mean train loss 1898.005373940871
INFO:root:current train perplexity4.475310802459717
INFO:root:current mean train loss 1902.0948863836766
INFO:root:current train perplexity4.481714248657227
INFO:root:current mean train loss 1907.1016265700534
INFO:root:current train perplexity4.493789196014404
INFO:root:current mean train loss 1907.411414162738
INFO:root:current train perplexity4.497595310211182
INFO:root:current mean train loss 1909.1623014344823
INFO:root:current train perplexity4.502838134765625
INFO:root:current mean train loss 1907.9659367354316
INFO:root:current train perplexity4.501354694366455
INFO:root:current mean train loss 1905.6075904174675
INFO:root:current train perplexity4.490610122680664
INFO:root:current mean train loss 1906.1002918217807
INFO:root:current train perplexity4.496679782867432
INFO:root:current mean train loss 1907.2855440341687
INFO:root:current train perplexity4.500003337860107
INFO:root:current mean train loss 1908.7106369890134
INFO:root:current train perplexity4.5009660720825195
INFO:root:current mean train loss 1909.322046661945
INFO:root:current train perplexity4.5032877922058105
INFO:root:current mean train loss 1908.2903352289338
INFO:root:current train perplexity4.501555919647217
INFO:root:current mean train loss 1909.8726469622134
INFO:root:current train perplexity4.5069260597229
INFO:root:current mean train loss 1909.954236337635
INFO:root:current train perplexity4.5061516761779785
INFO:root:current mean train loss 1908.9397063000888
INFO:root:current train perplexity4.504545211791992
INFO:root:current mean train loss 1910.0106438291637
INFO:root:current train perplexity4.506858825683594
INFO:root:current mean train loss 1909.173558602797
INFO:root:current train perplexity4.506845474243164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.16s/it]
INFO:root:final mean train loss: 1909.7549878926934
INFO:root:final train perplexity: 4.509325981140137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it]
INFO:root:eval mean loss: 1921.7832360233822
INFO:root:eval perplexity: 4.731420516967773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2375.413923547623
INFO:root:eval perplexity: 6.977414608001709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:38:06<7:25:21, 398.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1872.9903645833333
INFO:root:current train perplexity4.4260334968566895
INFO:root:current mean train loss 1879.098638153076
INFO:root:current train perplexity4.433737754821777
INFO:root:current mean train loss 1888.9236417330228
INFO:root:current train perplexity4.434787273406982
INFO:root:current mean train loss 1894.8034176296658
INFO:root:current train perplexity4.460838794708252
INFO:root:current mean train loss 1897.8289672851563
INFO:root:current train perplexity4.465745449066162
INFO:root:current mean train loss 1900.0656437465123
INFO:root:current train perplexity4.47313117980957
INFO:root:current mean train loss 1899.8581905480587
INFO:root:current train perplexity4.473276615142822
INFO:root:current mean train loss 1901.053637374075
INFO:root:current train perplexity4.4698991775512695
INFO:root:current mean train loss 1903.8869262695312
INFO:root:current train perplexity4.479595184326172
INFO:root:current mean train loss 1904.5107494354247
INFO:root:current train perplexity4.478189468383789
INFO:root:current mean train loss 1904.242877773069
INFO:root:current train perplexity4.4832329750061035
INFO:root:current mean train loss 1905.7221278749664
INFO:root:current train perplexity4.486812114715576
INFO:root:current mean train loss 1904.9815237862724
INFO:root:current train perplexity4.487982749938965
INFO:root:current mean train loss 1903.41844626034
INFO:root:current train perplexity4.48396110534668
INFO:root:current mean train loss 1903.6751188095302
INFO:root:current train perplexity4.48570442199707
INFO:root:current mean train loss 1905.4828266632862
INFO:root:current train perplexity4.492786884307861
INFO:root:current mean train loss 1904.6694168274662
INFO:root:current train perplexity4.492563247680664
INFO:root:current mean train loss 1904.527789514715
INFO:root:current train perplexity4.489562511444092
INFO:root:current mean train loss 1904.7920300555486
INFO:root:current train perplexity4.491176128387451
INFO:root:current mean train loss 1905.9444392613002
INFO:root:current train perplexity4.493988990783691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.83s/it]
INFO:root:final mean train loss: 1905.2082992299784
INFO:root:final train perplexity: 4.493185520172119
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it]
INFO:root:eval mean loss: 1906.3437738080397
INFO:root:eval perplexity: 4.6727094650268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it]
INFO:root:eval mean loss: 2358.175175227172
INFO:root:eval perplexity: 6.87973690032959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:44:38<7:16:34, 396.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.1679877739448
INFO:root:current train perplexity4.417446136474609
INFO:root:current mean train loss 1879.137184962041
INFO:root:current train perplexity4.437520980834961
INFO:root:current mean train loss 1881.925356427685
INFO:root:current train perplexity4.439597129821777
INFO:root:current mean train loss 1888.0450157752405
INFO:root:current train perplexity4.43927526473999
INFO:root:current mean train loss 1894.4282341723172
INFO:root:current train perplexity4.451971530914307
INFO:root:current mean train loss 1895.8021695089092
INFO:root:current train perplexity4.45473051071167
INFO:root:current mean train loss 1899.716787498846
INFO:root:current train perplexity4.4634175300598145
INFO:root:current mean train loss 1898.2749783824001
INFO:root:current train perplexity4.464785099029541
INFO:root:current mean train loss 1900.2723012856775
INFO:root:current train perplexity4.468837738037109
INFO:root:current mean train loss 1901.2271878448455
INFO:root:current train perplexity4.4731831550598145
INFO:root:current mean train loss 1899.551933720694
INFO:root:current train perplexity4.474522590637207
INFO:root:current mean train loss 1898.696648220947
INFO:root:current train perplexity4.467944622039795
INFO:root:current mean train loss 1900.2318387670077
INFO:root:current train perplexity4.473957538604736
INFO:root:current mean train loss 1898.8250062231923
INFO:root:current train perplexity4.473639011383057
INFO:root:current mean train loss 1899.541841521163
INFO:root:current train perplexity4.471121311187744
INFO:root:current mean train loss 1899.1863830218076
INFO:root:current train perplexity4.472549915313721
INFO:root:current mean train loss 1899.4119862128243
INFO:root:current train perplexity4.474129676818848
INFO:root:current mean train loss 1900.1687290618845
INFO:root:current train perplexity4.4744086265563965
INFO:root:current mean train loss 1900.718895808013
INFO:root:current train perplexity4.47281551361084
INFO:root:current mean train loss 1900.7079617505613
INFO:root:current train perplexity4.475157737731934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.78s/it]
INFO:root:final mean train loss: 1900.0268418027847
INFO:root:final train perplexity: 4.4748616218566895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 1908.2587293259642
INFO:root:eval perplexity: 4.67995023727417
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 2360.717631455009
INFO:root:eval perplexity: 6.894057273864746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:51:18<7:10:54, 397.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1911.703260056516
INFO:root:current train perplexity4.527230262756348
INFO:root:current mean train loss 1898.8175866825065
INFO:root:current train perplexity4.487842082977295
INFO:root:current mean train loss 1896.4882405598958
INFO:root:current train perplexity4.477799415588379
INFO:root:current mean train loss 1900.147920715022
INFO:root:current train perplexity4.4765849113464355
INFO:root:current mean train loss 1898.188886511181
INFO:root:current train perplexity4.4792160987854
INFO:root:current mean train loss 1898.481740007497
INFO:root:current train perplexity4.475767612457275
INFO:root:current mean train loss 1897.7958456693534
INFO:root:current train perplexity4.474573135375977
INFO:root:current mean train loss 1897.536021350313
INFO:root:current train perplexity4.470106601715088
INFO:root:current mean train loss 1898.6372133122727
INFO:root:current train perplexity4.466686725616455
INFO:root:current mean train loss 1897.7945516114264
INFO:root:current train perplexity4.465106010437012
INFO:root:current mean train loss 1896.1816990937787
INFO:root:current train perplexity4.4625139236450195
INFO:root:current mean train loss 1895.5811872881661
INFO:root:current train perplexity4.457716941833496
INFO:root:current mean train loss 1895.8793087801573
INFO:root:current train perplexity4.459503173828125
INFO:root:current mean train loss 1894.5387647675304
INFO:root:current train perplexity4.456023693084717
INFO:root:current mean train loss 1895.5614478584912
INFO:root:current train perplexity4.455119609832764
INFO:root:current mean train loss 1896.1328027741972
INFO:root:current train perplexity4.45639181137085
INFO:root:current mean train loss 1896.4901154032846
INFO:root:current train perplexity4.459394454956055
INFO:root:current mean train loss 1896.276281248367
INFO:root:current train perplexity4.4593000411987305
INFO:root:current mean train loss 1897.02786599696
INFO:root:current train perplexity4.461448669433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.27s/it]
INFO:root:final mean train loss: 1895.3075215873007
INFO:root:final train perplexity: 4.458237171173096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it]
INFO:root:eval mean loss: 1905.2293393831726
INFO:root:eval perplexity: 4.668498516082764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2361.7714077563996
INFO:root:eval perplexity: 6.900001525878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:58:03<7:06:46, 400.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1826.4043967507102
INFO:root:current train perplexity4.252209663391113
INFO:root:current mean train loss 1891.371470958263
INFO:root:current train perplexity4.451831340789795
INFO:root:current mean train loss 1898.1374077819535
INFO:root:current train perplexity4.437037467956543
INFO:root:current mean train loss 1895.6241266673785
INFO:root:current train perplexity4.431302547454834
INFO:root:current mean train loss 1897.16499926342
INFO:root:current train perplexity4.43856143951416
INFO:root:current mean train loss 1892.5167315160224
INFO:root:current train perplexity4.42483377456665
INFO:root:current mean train loss 1886.6675002477368
INFO:root:current train perplexity4.416860103607178
INFO:root:current mean train loss 1888.1257487322544
INFO:root:current train perplexity4.42482328414917
INFO:root:current mean train loss 1887.075637986716
INFO:root:current train perplexity4.427000045776367
INFO:root:current mean train loss 1885.2739938511938
INFO:root:current train perplexity4.425295829772949
INFO:root:current mean train loss 1887.6438180261266
INFO:root:current train perplexity4.430560111999512
INFO:root:current mean train loss 1889.1253881857913
INFO:root:current train perplexity4.429225921630859
INFO:root:current mean train loss 1889.1243762418715
INFO:root:current train perplexity4.425872802734375
INFO:root:current mean train loss 1889.900271999845
INFO:root:current train perplexity4.429450988769531
INFO:root:current mean train loss 1890.0101147062976
INFO:root:current train perplexity4.433743000030518
INFO:root:current mean train loss 1888.545869192329
INFO:root:current train perplexity4.433656692504883
INFO:root:current mean train loss 1889.8433163510872
INFO:root:current train perplexity4.436166286468506
INFO:root:current mean train loss 1889.8670711372415
INFO:root:current train perplexity4.438342571258545
INFO:root:current mean train loss 1890.7704464740216
INFO:root:current train perplexity4.439565181732178
INFO:root:current mean train loss 1891.1649538496288
INFO:root:current train perplexity4.443187236785889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it]
INFO:root:final mean train loss: 1891.614510355847
INFO:root:final train perplexity: 4.4452714920043945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 1907.2891542691711
INFO:root:eval perplexity: 4.676283359527588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 2361.001160533716
INFO:root:eval perplexity: 6.895656585693359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [4:04:33<6:56:51, 397.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1918.0612226213727
INFO:root:current train perplexity4.482028961181641
INFO:root:current mean train loss 1864.4009418487549
INFO:root:current train perplexity4.375586986541748
INFO:root:current mean train loss 1879.5105189273231
INFO:root:current train perplexity4.404866695404053
INFO:root:current mean train loss 1882.909324832079
INFO:root:current train perplexity4.401024341583252
INFO:root:current mean train loss 1885.3726892203929
INFO:root:current train perplexity4.412669658660889
INFO:root:current mean train loss 1885.8909049756599
INFO:root:current train perplexity4.417636394500732
INFO:root:current mean train loss 1886.1801959967158
INFO:root:current train perplexity4.4222731590271
INFO:root:current mean train loss 1886.2431820041531
INFO:root:current train perplexity4.4259352684021
INFO:root:current mean train loss 1885.5385826221411
INFO:root:current train perplexity4.4231438636779785
INFO:root:current mean train loss 1886.5619846212453
INFO:root:current train perplexity4.421407222747803
INFO:root:current mean train loss 1885.3176478523226
INFO:root:current train perplexity4.41747522354126
INFO:root:current mean train loss 1886.6030776652883
INFO:root:current train perplexity4.4202799797058105
INFO:root:current mean train loss 1886.071559446254
INFO:root:current train perplexity4.420327186584473
INFO:root:current mean train loss 1887.2757544460067
INFO:root:current train perplexity4.421700477600098
INFO:root:current mean train loss 1885.8891886222261
INFO:root:current train perplexity4.416909694671631
INFO:root:current mean train loss 1885.1988770649696
INFO:root:current train perplexity4.418551445007324
INFO:root:current mean train loss 1886.3443594517814
INFO:root:current train perplexity4.4241132736206055
INFO:root:current mean train loss 1885.9374543649178
INFO:root:current train perplexity4.425878047943115
INFO:root:current mean train loss 1886.607350489243
INFO:root:current train perplexity4.4259538650512695
INFO:root:current mean train loss 1887.4853858789468
INFO:root:current train perplexity4.42866325378418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.76s/it]
INFO:root:final mean train loss: 1886.8506285359147
INFO:root:final train perplexity: 4.42860221862793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 1897.0197797193596
INFO:root:eval perplexity: 4.637605667114258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 2352.637274559508
INFO:root:eval perplexity: 6.848649978637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:11:13<6:50:58, 397.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1896.5421495225694
INFO:root:current train perplexity4.430772304534912
INFO:root:current mean train loss 1892.8895112136315
INFO:root:current train perplexity4.421417713165283
INFO:root:current mean train loss 1883.636870715083
INFO:root:current train perplexity4.40546178817749
INFO:root:current mean train loss 1880.263711149796
INFO:root:current train perplexity4.404921054840088
INFO:root:current mean train loss 1878.035389692328
INFO:root:current train perplexity4.398602485656738
INFO:root:current mean train loss 1880.0159052017632
INFO:root:current train perplexity4.405025482177734
INFO:root:current mean train loss 1881.9322977228683
INFO:root:current train perplexity4.406170845031738
INFO:root:current mean train loss 1883.0169010853608
INFO:root:current train perplexity4.41194486618042
INFO:root:current mean train loss 1884.9519876513962
INFO:root:current train perplexity4.420107364654541
INFO:root:current mean train loss 1885.1927782169726
INFO:root:current train perplexity4.414753437042236
INFO:root:current mean train loss 1885.8190900446696
INFO:root:current train perplexity4.417268753051758
INFO:root:current mean train loss 1887.9259379690911
INFO:root:current train perplexity4.422807216644287
INFO:root:current mean train loss 1887.0222801361697
INFO:root:current train perplexity4.418304443359375
INFO:root:current mean train loss 1886.4081379603276
INFO:root:current train perplexity4.417680263519287
INFO:root:current mean train loss 1885.7413563236646
INFO:root:current train perplexity4.415876388549805
INFO:root:current mean train loss 1884.4959678872117
INFO:root:current train perplexity4.413963317871094
INFO:root:current mean train loss 1884.3646419072948
INFO:root:current train perplexity4.414048194885254
INFO:root:current mean train loss 1883.3799862749597
INFO:root:current train perplexity4.413733959197998
INFO:root:current mean train loss 1884.2380353229803
INFO:root:current train perplexity4.415974140167236
INFO:root:current mean train loss 1883.3251068193686
INFO:root:current train perplexity4.414915084838867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.79s/it]
INFO:root:final mean train loss: 1882.9075840937028
INFO:root:final train perplexity: 4.414851665496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it]
INFO:root:eval mean loss: 1901.2286926702404
INFO:root:eval perplexity: 4.653419017791748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 2359.6911054029533
INFO:root:eval perplexity: 6.888271331787109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:17:57<6:46:27, 399.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.8012655934979
INFO:root:current train perplexity4.398461818695068
INFO:root:current mean train loss 1874.2130194769966
INFO:root:current train perplexity4.389410495758057
INFO:root:current mean train loss 1866.3524626520755
INFO:root:current train perplexity4.377148628234863
INFO:root:current mean train loss 1868.381918554148
INFO:root:current train perplexity4.382208824157715
INFO:root:current mean train loss 1870.7483568067676
INFO:root:current train perplexity4.377996444702148
INFO:root:current mean train loss 1870.2230391858736
INFO:root:current train perplexity4.385785102844238
INFO:root:current mean train loss 1871.7384794759607
INFO:root:current train perplexity4.387901306152344
INFO:root:current mean train loss 1874.2574909840982
INFO:root:current train perplexity4.391108989715576
INFO:root:current mean train loss 1876.3481738451185
INFO:root:current train perplexity4.392506122589111
INFO:root:current mean train loss 1876.423380829936
INFO:root:current train perplexity4.394162654876709
INFO:root:current mean train loss 1875.8682347529352
INFO:root:current train perplexity4.392168998718262
INFO:root:current mean train loss 1875.93458134295
INFO:root:current train perplexity4.396233558654785
INFO:root:current mean train loss 1874.2819823251473
INFO:root:current train perplexity4.395804405212402
INFO:root:current mean train loss 1875.7409124836522
INFO:root:current train perplexity4.397982597351074
INFO:root:current mean train loss 1877.7514837137162
INFO:root:current train perplexity4.40137243270874
INFO:root:current mean train loss 1879.5190900932048
INFO:root:current train perplexity4.4024200439453125
INFO:root:current mean train loss 1878.6644591917916
INFO:root:current train perplexity4.399515628814697
INFO:root:current mean train loss 1879.6614226775325
INFO:root:current train perplexity4.401271343231201
INFO:root:current mean train loss 1879.5028954658549
INFO:root:current train perplexity4.401186466217041
INFO:root:current mean train loss 1880.0132263370247
INFO:root:current train perplexity4.40128231048584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.21s/it]
INFO:root:final mean train loss: 1879.2220583947933
INFO:root:final train perplexity: 4.402038097381592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 1909.9878622285019
INFO:root:eval perplexity: 4.68649959564209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.17s/it]
INFO:root:eval mean loss: 2368.6125388720357
INFO:root:eval perplexity: 6.938714504241943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:24:28<6:37:07, 397.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.0335399772548
INFO:root:current train perplexity4.381025314331055
INFO:root:current mean train loss 1878.8111735935317
INFO:root:current train perplexity4.403809070587158
INFO:root:current mean train loss 1871.545910688284
INFO:root:current train perplexity4.378567218780518
INFO:root:current mean train loss 1878.3680529430862
INFO:root:current train perplexity4.386488914489746
INFO:root:current mean train loss 1877.1157356532979
INFO:root:current train perplexity4.385725498199463
INFO:root:current mean train loss 1877.3739654593724
INFO:root:current train perplexity4.386804580688477
INFO:root:current mean train loss 1882.5048441598974
INFO:root:current train perplexity4.397314548492432
INFO:root:current mean train loss 1880.9895682377748
INFO:root:current train perplexity4.393664360046387
INFO:root:current mean train loss 1879.3982616854203
INFO:root:current train perplexity4.389530658721924
INFO:root:current mean train loss 1878.98678074526
INFO:root:current train perplexity4.386592864990234
INFO:root:current mean train loss 1879.8954693473413
INFO:root:current train perplexity4.391302108764648
INFO:root:current mean train loss 1877.7763509321658
INFO:root:current train perplexity4.385581016540527
INFO:root:current mean train loss 1876.5474236005912
INFO:root:current train perplexity4.384852409362793
INFO:root:current mean train loss 1875.826277745989
INFO:root:current train perplexity4.38421630859375
INFO:root:current mean train loss 1875.8824768272746
INFO:root:current train perplexity4.384782791137695
INFO:root:current mean train loss 1873.893344408051
INFO:root:current train perplexity4.382997035980225
INFO:root:current mean train loss 1875.3979618692767
INFO:root:current train perplexity4.385478973388672
INFO:root:current mean train loss 1875.429501889997
INFO:root:current train perplexity4.385818004608154
INFO:root:current mean train loss 1874.036893234537
INFO:root:current train perplexity4.384222507476807
INFO:root:current mean train loss 1874.7141931195522
INFO:root:current train perplexity4.384798526763916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.17s/it]
INFO:root:final mean train loss: 1874.3361274076722
INFO:root:final train perplexity: 4.38510799407959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it]
INFO:root:eval mean loss: 1895.5061771041112
INFO:root:eval perplexity: 4.631932258605957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it]
INFO:root:eval mean loss: 2355.0279298606492
INFO:root:eval perplexity: 6.8620524406433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:31:05<6:30:17, 396.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1878.9171524047852
INFO:root:current train perplexity4.420876979827881
INFO:root:current mean train loss 1872.6377613301179
INFO:root:current train perplexity4.3880228996276855
INFO:root:current mean train loss 1870.4835250442093
INFO:root:current train perplexity4.386192321777344
INFO:root:current mean train loss 1870.3449482002643
INFO:root:current train perplexity4.372488498687744
INFO:root:current mean train loss 1870.5865040440713
INFO:root:current train perplexity4.373952865600586
INFO:root:current mean train loss 1874.8588910198853
INFO:root:current train perplexity4.38032865524292
INFO:root:current mean train loss 1871.280874844255
INFO:root:current train perplexity4.377573490142822
INFO:root:current mean train loss 1869.029784236122
INFO:root:current train perplexity4.367648124694824
INFO:root:current mean train loss 1867.8062178747994
INFO:root:current train perplexity4.364790439605713
INFO:root:current mean train loss 1869.3987957445015
INFO:root:current train perplexity4.3680620193481445
INFO:root:current mean train loss 1868.5184259345062
INFO:root:current train perplexity4.366783142089844
INFO:root:current mean train loss 1870.304374669308
INFO:root:current train perplexity4.369589328765869
INFO:root:current mean train loss 1870.4187566498179
INFO:root:current train perplexity4.3728461265563965
INFO:root:current mean train loss 1870.5169636636203
INFO:root:current train perplexity4.371576309204102
INFO:root:current mean train loss 1869.9704760383156
INFO:root:current train perplexity4.364905834197998
INFO:root:current mean train loss 1870.0880674586858
INFO:root:current train perplexity4.369531154632568
INFO:root:current mean train loss 1871.4356785180435
INFO:root:current train perplexity4.372470378875732
INFO:root:current mean train loss 1871.456623510688
INFO:root:current train perplexity4.3740153312683105
INFO:root:current mean train loss 1871.183074178575
INFO:root:current train perplexity4.3739705085754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 343.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 343.00s/it]
INFO:root:final mean train loss: 1870.5651364540488
INFO:root:final train perplexity: 4.3720855712890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 1901.0228098334997
INFO:root:eval perplexity: 4.652644157409668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 2356.501078720634
INFO:root:eval perplexity: 6.870325565338135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:37:45<6:24:42, 397.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.8502760667068
INFO:root:current train perplexity4.359109878540039
INFO:root:current mean train loss 1859.889138550885
INFO:root:current train perplexity4.3429436683654785
INFO:root:current mean train loss 1866.2240700878447
INFO:root:current train perplexity4.346826076507568
INFO:root:current mean train loss 1861.6219423921725
INFO:root:current train perplexity4.3386712074279785
INFO:root:current mean train loss 1859.9369011756582
INFO:root:current train perplexity4.333090782165527
INFO:root:current mean train loss 1865.549357572262
INFO:root:current train perplexity4.346729278564453
INFO:root:current mean train loss 1864.1703510128848
INFO:root:current train perplexity4.3431901931762695
INFO:root:current mean train loss 1864.1720527124605
INFO:root:current train perplexity4.343783378601074
INFO:root:current mean train loss 1863.8336620072744
INFO:root:current train perplexity4.350116729736328
INFO:root:current mean train loss 1863.135263666527
INFO:root:current train perplexity4.349294662475586
INFO:root:current mean train loss 1864.5358222743014
INFO:root:current train perplexity4.354176998138428
INFO:root:current mean train loss 1866.2360940746435
INFO:root:current train perplexity4.355413913726807
INFO:root:current mean train loss 1866.8829501687449
INFO:root:current train perplexity4.3556084632873535
INFO:root:current mean train loss 1868.403965342072
INFO:root:current train perplexity4.360102653503418
INFO:root:current mean train loss 1868.9762457046454
INFO:root:current train perplexity4.360177993774414
INFO:root:current mean train loss 1868.2146941674757
INFO:root:current train perplexity4.3611602783203125
INFO:root:current mean train loss 1868.7196506564098
INFO:root:current train perplexity4.361449241638184
INFO:root:current mean train loss 1868.7603763328682
INFO:root:current train perplexity4.363306999206543
INFO:root:current mean train loss 1868.674262070485
INFO:root:current train perplexity4.362395286560059
INFO:root:current mean train loss 1868.755390683706
INFO:root:current train perplexity4.36175012588501

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.15s/it]
INFO:root:final mean train loss: 1867.138410744256
INFO:root:final train perplexity: 4.360285758972168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 1896.3078479090482
INFO:root:eval perplexity: 4.634936332702637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.37s/it]
INFO:root:eval mean loss: 2356.0270788314497
INFO:root:eval perplexity: 6.867660999298096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:44:17<6:16:22, 396.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.306746419271
INFO:root:current train perplexity4.3033928871154785
INFO:root:current mean train loss 1865.2381986177884
INFO:root:current train perplexity4.350709915161133
INFO:root:current mean train loss 1852.435298488451
INFO:root:current train perplexity4.3379716873168945
INFO:root:current mean train loss 1852.9692933978456
INFO:root:current train perplexity4.330985069274902
INFO:root:current mean train loss 1851.7057222588119
INFO:root:current train perplexity4.323256969451904
INFO:root:current mean train loss 1854.356037183078
INFO:root:current train perplexity4.3300604820251465
INFO:root:current mean train loss 1856.1571812220982
INFO:root:current train perplexity4.326581954956055
INFO:root:current mean train loss 1855.3226085924123
INFO:root:current train perplexity4.324146747589111
INFO:root:current mean train loss 1857.8851986069278
INFO:root:current train perplexity4.326412677764893
INFO:root:current mean train loss 1857.3084588163642
INFO:root:current train perplexity4.325067520141602
INFO:root:current mean train loss 1858.585631257585
INFO:root:current train perplexity4.326369285583496
INFO:root:current mean train loss 1860.0335182392491
INFO:root:current train perplexity4.331079483032227
INFO:root:current mean train loss 1861.9946462739774
INFO:root:current train perplexity4.335549354553223
INFO:root:current mean train loss 1861.5793467127291
INFO:root:current train perplexity4.33608865737915
INFO:root:current mean train loss 1861.213810164445
INFO:root:current train perplexity4.336944580078125
INFO:root:current mean train loss 1860.3473678289674
INFO:root:current train perplexity4.336444854736328
INFO:root:current mean train loss 1860.4624133525451
INFO:root:current train perplexity4.338230609893799
INFO:root:current mean train loss 1861.702612022444
INFO:root:current train perplexity4.342897415161133
INFO:root:current mean train loss 1863.2435406794314
INFO:root:current train perplexity4.346569538116455
INFO:root:current mean train loss 1863.2472929485104
INFO:root:current train perplexity4.346898078918457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.43s/it]
INFO:root:final mean train loss: 1863.6384696556472
INFO:root:final train perplexity: 4.348267078399658
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it]
INFO:root:eval mean loss: 1903.0619922394449
INFO:root:eval perplexity: 4.660323619842529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2366.595781475094
INFO:root:eval perplexity: 6.927278518676758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:50:52<6:09:25, 395.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1847.6471960189494
INFO:root:current train perplexity4.354485511779785
INFO:root:current mean train loss 1877.001815276892
INFO:root:current train perplexity4.393884658813477
INFO:root:current mean train loss 1864.9437656170926
INFO:root:current train perplexity4.352100372314453
INFO:root:current mean train loss 1866.268453724446
INFO:root:current train perplexity4.342194080352783
INFO:root:current mean train loss 1862.4112464170862
INFO:root:current train perplexity4.335470199584961
INFO:root:current mean train loss 1861.9840451646767
INFO:root:current train perplexity4.334325790405273
INFO:root:current mean train loss 1858.537266538169
INFO:root:current train perplexity4.323732376098633
INFO:root:current mean train loss 1857.0601968420558
INFO:root:current train perplexity4.322665214538574
INFO:root:current mean train loss 1854.4328218390274
INFO:root:current train perplexity4.320781230926514
INFO:root:current mean train loss 1856.2212567596275
INFO:root:current train perplexity4.322234630584717
INFO:root:current mean train loss 1856.4257482548726
INFO:root:current train perplexity4.323512077331543
INFO:root:current mean train loss 1855.7557838127316
INFO:root:current train perplexity4.322956085205078
INFO:root:current mean train loss 1857.246403184048
INFO:root:current train perplexity4.326942443847656
INFO:root:current mean train loss 1857.183039766466
INFO:root:current train perplexity4.327003002166748
INFO:root:current mean train loss 1857.5617816664058
INFO:root:current train perplexity4.32792854309082
INFO:root:current mean train loss 1858.112933030033
INFO:root:current train perplexity4.329115867614746
INFO:root:current mean train loss 1859.4705352505266
INFO:root:current train perplexity4.332777500152588
INFO:root:current mean train loss 1860.668845252576
INFO:root:current train perplexity4.336487293243408
INFO:root:current mean train loss 1860.5894237408847
INFO:root:current train perplexity4.335772514343262
INFO:root:current mean train loss 1860.940302789548
INFO:root:current train perplexity4.336832523345947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.33s/it]
INFO:root:final mean train loss: 1859.9611033075576
INFO:root:final train perplexity: 4.33567476272583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 1895.3591871329234
INFO:root:eval perplexity: 4.631381988525391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.11s/it]
INFO:root:eval mean loss: 2355.320755329538
INFO:root:eval perplexity: 6.863696575164795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:57:20<6:00:45, 393.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1824.1078395843506
INFO:root:current train perplexity4.279802322387695
INFO:root:current mean train loss 1857.6836465975134
INFO:root:current train perplexity4.329224586486816
INFO:root:current mean train loss 1865.6146559281783
INFO:root:current train perplexity4.347120761871338
INFO:root:current mean train loss 1862.8720377827738
INFO:root:current train perplexity4.339621543884277
INFO:root:current mean train loss 1860.2566794033708
INFO:root:current train perplexity4.335989475250244
INFO:root:current mean train loss 1858.0325670174673
INFO:root:current train perplexity4.333738803863525
INFO:root:current mean train loss 1854.4203776164227
INFO:root:current train perplexity4.328220844268799
INFO:root:current mean train loss 1852.8240103996236
INFO:root:current train perplexity4.325509071350098
INFO:root:current mean train loss 1850.6849534776475
INFO:root:current train perplexity4.319873809814453
INFO:root:current mean train loss 1853.4411182957567
INFO:root:current train perplexity4.320171356201172
INFO:root:current mean train loss 1854.2999556692023
INFO:root:current train perplexity4.323305606842041
INFO:root:current mean train loss 1854.9535872731421
INFO:root:current train perplexity4.324429035186768
INFO:root:current mean train loss 1853.8436848121353
INFO:root:current train perplexity4.31995964050293
INFO:root:current mean train loss 1853.376967354604
INFO:root:current train perplexity4.317724704742432
INFO:root:current mean train loss 1854.7228187602725
INFO:root:current train perplexity4.322142601013184
INFO:root:current mean train loss 1854.2217973089585
INFO:root:current train perplexity4.320080757141113
INFO:root:current mean train loss 1854.6310069744404
INFO:root:current train perplexity4.319261074066162
INFO:root:current mean train loss 1855.6934600622476
INFO:root:current train perplexity4.320653438568115
INFO:root:current mean train loss 1856.4854222899344
INFO:root:current train perplexity4.321502685546875
INFO:root:current mean train loss 1856.8869666198607
INFO:root:current train perplexity4.323270320892334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.99s/it]
INFO:root:final mean train loss: 1856.4516261144533
INFO:root:final train perplexity: 4.323691368103027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 1892.7353411735373
INFO:root:eval perplexity: 4.621565341949463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 2353.677255616966
INFO:root:eval perplexity: 6.854476451873779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [5:04:03<5:56:48, 396.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1836.5157003520449
INFO:root:current train perplexity4.282352447509766
INFO:root:current mean train loss 1854.4417778563104
INFO:root:current train perplexity4.301725387573242
INFO:root:current mean train loss 1854.6661759237377
INFO:root:current train perplexity4.315454483032227
INFO:root:current mean train loss 1857.3399017414083
INFO:root:current train perplexity4.3314080238342285
INFO:root:current mean train loss 1855.2667190646928
INFO:root:current train perplexity4.318306922912598
INFO:root:current mean train loss 1852.7002205249569
INFO:root:current train perplexity4.315502643585205
INFO:root:current mean train loss 1849.5546002044903
INFO:root:current train perplexity4.310419082641602
INFO:root:current mean train loss 1851.5394266790372
INFO:root:current train perplexity4.307634353637695
INFO:root:current mean train loss 1849.4191287643657
INFO:root:current train perplexity4.3044281005859375
INFO:root:current mean train loss 1849.768395784555
INFO:root:current train perplexity4.303104877471924
INFO:root:current mean train loss 1852.340203185527
INFO:root:current train perplexity4.311151504516602
INFO:root:current mean train loss 1851.254511020024
INFO:root:current train perplexity4.311165809631348
INFO:root:current mean train loss 1850.8848469099153
INFO:root:current train perplexity4.3099212646484375
INFO:root:current mean train loss 1852.201229065074
INFO:root:current train perplexity4.311459541320801
INFO:root:current mean train loss 1852.1305445967937
INFO:root:current train perplexity4.310763359069824
INFO:root:current mean train loss 1853.2900608359523
INFO:root:current train perplexity4.311593532562256
INFO:root:current mean train loss 1853.501645879615
INFO:root:current train perplexity4.31296968460083
INFO:root:current mean train loss 1853.685082240161
INFO:root:current train perplexity4.313305854797363
INFO:root:current mean train loss 1853.7867368691022
INFO:root:current train perplexity4.313253879547119
INFO:root:current mean train loss 1853.8386080114603
INFO:root:current train perplexity4.3131866455078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.87s/it]
INFO:root:final mean train loss: 1853.3128931427386
INFO:root:final train perplexity: 4.31300163269043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 1886.389896473986
INFO:root:eval perplexity: 4.597908020019531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it]
INFO:root:eval mean loss: 2347.8750748871066
INFO:root:eval perplexity: 6.822027683258057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [5:10:39<5:50:03, 396.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1850.7285230986927
INFO:root:current train perplexity4.239682197570801
INFO:root:current mean train loss 1842.49469487354
INFO:root:current train perplexity4.254066467285156
INFO:root:current mean train loss 1834.3331560992553
INFO:root:current train perplexity4.258317947387695
INFO:root:current mean train loss 1844.6048277275047
INFO:root:current train perplexity4.271500110626221
INFO:root:current mean train loss 1847.8449564861007
INFO:root:current train perplexity4.285097599029541
INFO:root:current mean train loss 1848.5002137251124
INFO:root:current train perplexity4.29152250289917
INFO:root:current mean train loss 1847.4061725255754
INFO:root:current train perplexity4.292696952819824
INFO:root:current mean train loss 1846.8431072187304
INFO:root:current train perplexity4.291598320007324
INFO:root:current mean train loss 1847.8026082266147
INFO:root:current train perplexity4.2944416999816895
INFO:root:current mean train loss 1846.3547275214491
INFO:root:current train perplexity4.2939019203186035
INFO:root:current mean train loss 1848.4419812478654
INFO:root:current train perplexity4.296485900878906
INFO:root:current mean train loss 1847.692567446395
INFO:root:current train perplexity4.293168544769287
INFO:root:current mean train loss 1848.154414619246
INFO:root:current train perplexity4.293697357177734
INFO:root:current mean train loss 1849.3209942775393
INFO:root:current train perplexity4.29619836807251
INFO:root:current mean train loss 1850.3029997027286
INFO:root:current train perplexity4.300247669219971
INFO:root:current mean train loss 1851.30972095246
INFO:root:current train perplexity4.302530288696289
INFO:root:current mean train loss 1850.9892186320994
INFO:root:current train perplexity4.300742149353027
INFO:root:current mean train loss 1850.47113682086
INFO:root:current train perplexity4.299740314483643
INFO:root:current mean train loss 1850.3656400754905
INFO:root:current train perplexity4.299988269805908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.83s/it]
INFO:root:final mean train loss: 1849.812064597418
INFO:root:final train perplexity: 4.301109313964844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 1886.849197279477
INFO:root:eval perplexity: 4.599615573883057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 2349.757669651762
INFO:root:eval perplexity: 6.832538604736328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:17:17<5:43:41, 396.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.485685221354
INFO:root:current train perplexity4.227295875549316
INFO:root:current mean train loss 1866.5919550356657
INFO:root:current train perplexity4.300540447235107
INFO:root:current mean train loss 1857.5363377770711
INFO:root:current train perplexity4.301215171813965
INFO:root:current mean train loss 1845.518005952381
INFO:root:current train perplexity4.279281139373779
INFO:root:current mean train loss 1842.4991622740963
INFO:root:current train perplexity4.2799201011657715
INFO:root:current mean train loss 1838.3141881257584
INFO:root:current train perplexity4.273858547210693
INFO:root:current mean train loss 1835.1284396039762
INFO:root:current train perplexity4.268543720245361
INFO:root:current mean train loss 1839.9326588450613
INFO:root:current train perplexity4.2756757736206055
INFO:root:current mean train loss 1838.9490855960028
INFO:root:current train perplexity4.270937919616699
INFO:root:current mean train loss 1841.903459192495
INFO:root:current train perplexity4.27580451965332
INFO:root:current mean train loss 1842.0489853130773
INFO:root:current train perplexity4.275691509246826
INFO:root:current mean train loss 1841.5791010150995
INFO:root:current train perplexity4.27573823928833
INFO:root:current mean train loss 1843.751022577482
INFO:root:current train perplexity4.279728889465332
INFO:root:current mean train loss 1842.3385187997565
INFO:root:current train perplexity4.278263092041016
INFO:root:current mean train loss 1844.7772407450861
INFO:root:current train perplexity4.283374786376953
INFO:root:current mean train loss 1844.813577200005
INFO:root:current train perplexity4.282285213470459
INFO:root:current mean train loss 1846.5327783354296
INFO:root:current train perplexity4.2866010665893555
INFO:root:current mean train loss 1845.7213186013803
INFO:root:current train perplexity4.2869720458984375
INFO:root:current mean train loss 1845.3192608121342
INFO:root:current train perplexity4.284946918487549
INFO:root:current mean train loss 1846.324622187602
INFO:root:current train perplexity4.287300109863281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.47s/it]
INFO:root:final mean train loss: 1846.0970929906155
INFO:root:final train perplexity: 4.28852653503418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 1887.6937913827016
INFO:root:eval perplexity: 4.602758407592773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it]
INFO:root:eval mean loss: 2350.646238935755
INFO:root:eval perplexity: 6.8375067710876465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:23:45<5:34:56, 394.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.2232818603516
INFO:root:current train perplexity4.305480003356934
INFO:root:current mean train loss 1844.7252409963896
INFO:root:current train perplexity4.261995792388916
INFO:root:current mean train loss 1848.9009420460668
INFO:root:current train perplexity4.265982627868652
INFO:root:current mean train loss 1846.056319638907
INFO:root:current train perplexity4.272355079650879
INFO:root:current mean train loss 1839.6172284726742
INFO:root:current train perplexity4.268061637878418
INFO:root:current mean train loss 1841.0015350571252
INFO:root:current train perplexity4.264974117279053
INFO:root:current mean train loss 1839.4276408907733
INFO:root:current train perplexity4.259607315063477
INFO:root:current mean train loss 1842.9152756988026
INFO:root:current train perplexity4.265817165374756
INFO:root:current mean train loss 1845.5128301473765
INFO:root:current train perplexity4.267191410064697
INFO:root:current mean train loss 1845.19111705338
INFO:root:current train perplexity4.270946979522705
INFO:root:current mean train loss 1847.9710637765338
INFO:root:current train perplexity4.278329372406006
INFO:root:current mean train loss 1845.1524596736624
INFO:root:current train perplexity4.277713775634766
INFO:root:current mean train loss 1844.9027185811624
INFO:root:current train perplexity4.277738094329834
INFO:root:current mean train loss 1844.8827564136402
INFO:root:current train perplexity4.277938365936279
INFO:root:current mean train loss 1845.1736717863455
INFO:root:current train perplexity4.278136730194092
INFO:root:current mean train loss 1843.537074235961
INFO:root:current train perplexity4.275088310241699
INFO:root:current mean train loss 1842.8911067738252
INFO:root:current train perplexity4.2746901512146
INFO:root:current mean train loss 1842.4660299887007
INFO:root:current train perplexity4.273488521575928
INFO:root:current mean train loss 1843.2846793628676
INFO:root:current train perplexity4.276033401489258
INFO:root:current mean train loss 1843.3505808828286
INFO:root:current train perplexity4.277768611907959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.67s/it]
INFO:root:final mean train loss: 1842.867346351458
INFO:root:final train perplexity: 4.27761697769165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 1899.5526443373226
INFO:root:eval perplexity: 4.6471147537231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it]
INFO:root:eval mean loss: 2359.300574769365
INFO:root:eval perplexity: 6.886072635650635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:30:15<5:27:25, 392.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1818.9987817881058
INFO:root:current train perplexity4.213882923126221
INFO:root:current mean train loss 1833.6638503106649
INFO:root:current train perplexity4.239026069641113
INFO:root:current mean train loss 1837.4648197281313
INFO:root:current train perplexity4.257794380187988
INFO:root:current mean train loss 1836.6074348165519
INFO:root:current train perplexity4.263791561126709
INFO:root:current mean train loss 1836.1628113472648
INFO:root:current train perplexity4.256844997406006
INFO:root:current mean train loss 1837.2210288681836
INFO:root:current train perplexity4.258586883544922
INFO:root:current mean train loss 1835.100542112565
INFO:root:current train perplexity4.251059055328369
INFO:root:current mean train loss 1832.677591117584
INFO:root:current train perplexity4.244625568389893
INFO:root:current mean train loss 1833.4972821023355
INFO:root:current train perplexity4.246358394622803
INFO:root:current mean train loss 1834.259805886336
INFO:root:current train perplexity4.246801376342773
INFO:root:current mean train loss 1835.857335762482
INFO:root:current train perplexity4.250715732574463
INFO:root:current mean train loss 1836.2870851521704
INFO:root:current train perplexity4.252809047698975
INFO:root:current mean train loss 1836.3284525081003
INFO:root:current train perplexity4.2529497146606445
INFO:root:current mean train loss 1836.5067975699592
INFO:root:current train perplexity4.255895137786865
INFO:root:current mean train loss 1837.9938954734407
INFO:root:current train perplexity4.258410453796387
INFO:root:current mean train loss 1838.7043139443542
INFO:root:current train perplexity4.262134552001953
INFO:root:current mean train loss 1839.9842035537636
INFO:root:current train perplexity4.265563011169434
INFO:root:current mean train loss 1840.6291484363833
INFO:root:current train perplexity4.268061637878418
INFO:root:current mean train loss 1840.9292921744018
INFO:root:current train perplexity4.270191192626953
INFO:root:current mean train loss 1840.6984072235562
INFO:root:current train perplexity4.268337249755859

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.79s/it]
INFO:root:final mean train loss: 1840.2540580838001
INFO:root:final train perplexity: 4.268809795379639
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 1897.5805391352228
INFO:root:eval perplexity: 4.639709949493408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2360.1854295662956
INFO:root:eval perplexity: 6.891056537628174
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:36:50<5:21:25, 393.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.1162645744555
INFO:root:current train perplexity4.260239601135254
INFO:root:current mean train loss 1844.2577639660203
INFO:root:current train perplexity4.25597620010376
INFO:root:current mean train loss 1841.6079753216047
INFO:root:current train perplexity4.2611541748046875
INFO:root:current mean train loss 1847.1070546634862
INFO:root:current train perplexity4.277013778686523
INFO:root:current mean train loss 1842.1768308975154
INFO:root:current train perplexity4.2691330909729
INFO:root:current mean train loss 1841.3481130431483
INFO:root:current train perplexity4.266141414642334
INFO:root:current mean train loss 1841.5970066746434
INFO:root:current train perplexity4.265115261077881
INFO:root:current mean train loss 1839.7671598031066
INFO:root:current train perplexity4.257979869842529
INFO:root:current mean train loss 1838.9133319105892
INFO:root:current train perplexity4.256816864013672
INFO:root:current mean train loss 1839.5320450997995
INFO:root:current train perplexity4.258640766143799
INFO:root:current mean train loss 1838.980545473367
INFO:root:current train perplexity4.259071350097656
INFO:root:current mean train loss 1840.4387278221484
INFO:root:current train perplexity4.261943340301514
INFO:root:current mean train loss 1840.6083934235535
INFO:root:current train perplexity4.260456085205078
INFO:root:current mean train loss 1839.698350674586
INFO:root:current train perplexity4.2609429359436035
INFO:root:current mean train loss 1839.48368904145
INFO:root:current train perplexity4.259638786315918
INFO:root:current mean train loss 1839.7529187744453
INFO:root:current train perplexity4.259085178375244
INFO:root:current mean train loss 1840.6251206048826
INFO:root:current train perplexity4.262181758880615
INFO:root:current mean train loss 1839.2751721288178
INFO:root:current train perplexity4.2598676681518555
INFO:root:current mean train loss 1837.8170175828352
INFO:root:current train perplexity4.257056713104248
INFO:root:current mean train loss 1837.2398656804346
INFO:root:current train perplexity4.256866455078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.49s/it]
INFO:root:final mean train loss: 1836.9384298704515
INFO:root:final train perplexity: 4.257662773132324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 1883.691414907469
INFO:root:eval perplexity: 4.587884902954102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 2346.068926006344
INFO:root:eval perplexity: 6.811957836151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:43:32<5:16:49, 396.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1842.7091917474586
INFO:root:current train perplexity4.266236305236816
INFO:root:current mean train loss 1840.392125197447
INFO:root:current train perplexity4.248092174530029
INFO:root:current mean train loss 1844.6222303410723
INFO:root:current train perplexity4.260461330413818
INFO:root:current mean train loss 1841.6848817033494
INFO:root:current train perplexity4.256060600280762
INFO:root:current mean train loss 1840.9834123378462
INFO:root:current train perplexity4.258292198181152
INFO:root:current mean train loss 1837.1102713687956
INFO:root:current train perplexity4.250996112823486
INFO:root:current mean train loss 1837.9598706805339
INFO:root:current train perplexity4.250227451324463
INFO:root:current mean train loss 1838.369505744632
INFO:root:current train perplexity4.252594470977783
INFO:root:current mean train loss 1838.4887711901897
INFO:root:current train perplexity4.252557754516602
INFO:root:current mean train loss 1839.1540666426913
INFO:root:current train perplexity4.251416206359863
INFO:root:current mean train loss 1837.9963177146453
INFO:root:current train perplexity4.248236656188965
INFO:root:current mean train loss 1839.4545515613443
INFO:root:current train perplexity4.252828121185303
INFO:root:current mean train loss 1836.9962823262738
INFO:root:current train perplexity4.249630451202393
INFO:root:current mean train loss 1838.1629796665989
INFO:root:current train perplexity4.254045486450195
INFO:root:current mean train loss 1837.4441014275064
INFO:root:current train perplexity4.253381252288818
INFO:root:current mean train loss 1837.049336995494
INFO:root:current train perplexity4.254846096038818
INFO:root:current mean train loss 1836.4442021896352
INFO:root:current train perplexity4.254317283630371
INFO:root:current mean train loss 1836.7666633165225
INFO:root:current train perplexity4.255098819732666
INFO:root:current mean train loss 1835.9816958710544
INFO:root:current train perplexity4.2509260177612305
INFO:root:current mean train loss 1834.6505395655552
INFO:root:current train perplexity4.249985694885254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it]
INFO:root:final mean train loss: 1834.6505395655552
INFO:root:final train perplexity: 4.249985694885254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 1886.8722356701574
INFO:root:eval perplexity: 4.599701404571533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.86s/it]
INFO:root:eval mean loss: 2352.510261697972
INFO:root:eval perplexity: 6.847937107086182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:49:58<5:07:53, 393.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.9134936523437
INFO:root:current train perplexity4.196857452392578
INFO:root:current mean train loss 1823.1957348632814
INFO:root:current train perplexity4.198433876037598
INFO:root:current mean train loss 1817.1704703776043
INFO:root:current train perplexity4.198697566986084
INFO:root:current mean train loss 1827.8882598876953
INFO:root:current train perplexity4.214991569519043
INFO:root:current mean train loss 1825.3126997070312
INFO:root:current train perplexity4.2130513191223145
INFO:root:current mean train loss 1827.6961110432942
INFO:root:current train perplexity4.222484588623047
INFO:root:current mean train loss 1828.0464978027344
INFO:root:current train perplexity4.2229108810424805
INFO:root:current mean train loss 1828.8746980285644
INFO:root:current train perplexity4.22666072845459
INFO:root:current mean train loss 1827.282851155599
INFO:root:current train perplexity4.2263922691345215
INFO:root:current mean train loss 1830.0914951171876
INFO:root:current train perplexity4.232571601867676
INFO:root:current mean train loss 1831.44728515625
INFO:root:current train perplexity4.235971927642822
INFO:root:current mean train loss 1830.8493413289389
INFO:root:current train perplexity4.237018585205078
INFO:root:current mean train loss 1829.579295372596
INFO:root:current train perplexity4.2361907958984375
INFO:root:current mean train loss 1831.384938092913
INFO:root:current train perplexity4.238356590270996
INFO:root:current mean train loss 1831.1697862141928
INFO:root:current train perplexity4.2405314445495605
INFO:root:current mean train loss 1830.187504425049
INFO:root:current train perplexity4.240643501281738
INFO:root:current mean train loss 1830.5521904440486
INFO:root:current train perplexity4.239621639251709
INFO:root:current mean train loss 1831.8736297607422
INFO:root:current train perplexity4.241765975952148
INFO:root:current mean train loss 1832.417708097759
INFO:root:current train perplexity4.242620944976807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.36s/it]
INFO:root:final mean train loss: 1832.6066617210645
INFO:root:final train perplexity: 4.243141174316406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 1881.0066013200908
INFO:root:eval perplexity: 4.5779337882995605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2344.8480367457614
INFO:root:eval perplexity: 6.805159568786621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:56:40<5:03:18, 395.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1843.2445786420037
INFO:root:current train perplexity4.227559566497803
INFO:root:current mean train loss 1841.0589891743457
INFO:root:current train perplexity4.237763404846191
INFO:root:current mean train loss 1831.3970907888104
INFO:root:current train perplexity4.220483303070068
INFO:root:current mean train loss 1828.368441705072
INFO:root:current train perplexity4.216397285461426
INFO:root:current mean train loss 1827.4637793671313
INFO:root:current train perplexity4.216142654418945
INFO:root:current mean train loss 1829.5371686393103
INFO:root:current train perplexity4.219979763031006
INFO:root:current mean train loss 1828.1907094402097
INFO:root:current train perplexity4.2172465324401855
INFO:root:current mean train loss 1828.4304148143306
INFO:root:current train perplexity4.2259907722473145
INFO:root:current mean train loss 1826.1953234071393
INFO:root:current train perplexity4.223486423492432
INFO:root:current mean train loss 1828.339345218571
INFO:root:current train perplexity4.227959632873535
INFO:root:current mean train loss 1829.7622167536642
INFO:root:current train perplexity4.229425430297852
INFO:root:current mean train loss 1829.4718864529711
INFO:root:current train perplexity4.229153633117676
INFO:root:current mean train loss 1828.5275970183147
INFO:root:current train perplexity4.22758674621582
INFO:root:current mean train loss 1828.6579547207195
INFO:root:current train perplexity4.228606700897217
INFO:root:current mean train loss 1828.3163648994355
INFO:root:current train perplexity4.228466987609863
INFO:root:current mean train loss 1828.6466659113382
INFO:root:current train perplexity4.229861259460449
INFO:root:current mean train loss 1830.324340518345
INFO:root:current train perplexity4.232724189758301
INFO:root:current mean train loss 1830.2793904361713
INFO:root:current train perplexity4.232832431793213
INFO:root:current mean train loss 1830.5154538193967
INFO:root:current train perplexity4.232210636138916
INFO:root:current mean train loss 1829.7176029083937
INFO:root:current train perplexity4.231303691864014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.06s/it]
INFO:root:final mean train loss: 1828.989947143493
INFO:root:final train perplexity: 4.231055736541748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 1884.6532765922816
INFO:root:eval perplexity: 4.591454982757568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2350.1782733024434
INFO:root:eval perplexity: 6.834889888763428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [6:03:12<4:55:55, 394.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.2200101964613
INFO:root:current train perplexity4.209784507751465
INFO:root:current mean train loss 1850.0955209305037
INFO:root:current train perplexity4.240564346313477
INFO:root:current mean train loss 1838.7370162050947
INFO:root:current train perplexity4.238189697265625
INFO:root:current mean train loss 1835.5941173073775
INFO:root:current train perplexity4.218639373779297
INFO:root:current mean train loss 1837.4214744743663
INFO:root:current train perplexity4.222479820251465
INFO:root:current mean train loss 1833.939158693235
INFO:root:current train perplexity4.221578598022461
INFO:root:current mean train loss 1832.7927611919608
INFO:root:current train perplexity4.223287582397461
INFO:root:current mean train loss 1831.2372927133003
INFO:root:current train perplexity4.221336841583252
INFO:root:current mean train loss 1832.845767233869
INFO:root:current train perplexity4.2245941162109375
INFO:root:current mean train loss 1832.243232416647
INFO:root:current train perplexity4.2239274978637695
INFO:root:current mean train loss 1831.862760149072
INFO:root:current train perplexity4.225601673126221
INFO:root:current mean train loss 1830.3080961035673
INFO:root:current train perplexity4.220985412597656
INFO:root:current mean train loss 1830.347913151622
INFO:root:current train perplexity4.222558975219727
INFO:root:current mean train loss 1829.4843201873184
INFO:root:current train perplexity4.222751617431641
INFO:root:current mean train loss 1827.8911544821085
INFO:root:current train perplexity4.220364570617676
INFO:root:current mean train loss 1827.203332137564
INFO:root:current train perplexity4.220833778381348
INFO:root:current mean train loss 1825.9602803075036
INFO:root:current train perplexity4.2190470695495605
INFO:root:current mean train loss 1827.977009598359
INFO:root:current train perplexity4.223323822021484
INFO:root:current mean train loss 1828.084008735815
INFO:root:current train perplexity4.22625732421875
INFO:root:current mean train loss 1827.3909754314245
INFO:root:current train perplexity4.223616600036621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.95s/it]
INFO:root:final mean train loss: 1826.7614294255075
INFO:root:final train perplexity: 4.223625659942627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 1881.6616154663952
INFO:root:eval perplexity: 4.580359935760498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 2345.9327565727503
INFO:root:eval perplexity: 6.8112006187438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [6:09:40<4:48:04, 392.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1816.4805142271753
INFO:root:current train perplexity4.170103073120117
INFO:root:current mean train loss 1827.461152537769
INFO:root:current train perplexity4.215363025665283
INFO:root:current mean train loss 1823.7540506917642
INFO:root:current train perplexity4.20233154296875
INFO:root:current mean train loss 1817.2627815616097
INFO:root:current train perplexity4.193408966064453
INFO:root:current mean train loss 1817.181442226909
INFO:root:current train perplexity4.202212810516357
INFO:root:current mean train loss 1820.8273797286183
INFO:root:current train perplexity4.212257385253906
INFO:root:current mean train loss 1822.1058810888896
INFO:root:current train perplexity4.214146614074707
INFO:root:current mean train loss 1820.3314693364575
INFO:root:current train perplexity4.212491035461426
INFO:root:current mean train loss 1819.1670306303247
INFO:root:current train perplexity4.208089828491211
INFO:root:current mean train loss 1819.5215426504174
INFO:root:current train perplexity4.207685947418213
INFO:root:current mean train loss 1820.2011061358974
INFO:root:current train perplexity4.209009170532227
INFO:root:current mean train loss 1820.3980718193418
INFO:root:current train perplexity4.211727142333984
INFO:root:current mean train loss 1821.979851860699
INFO:root:current train perplexity4.215834140777588
INFO:root:current mean train loss 1824.1429819238354
INFO:root:current train perplexity4.220514297485352
INFO:root:current mean train loss 1823.8610164292675
INFO:root:current train perplexity4.2202534675598145
INFO:root:current mean train loss 1825.7259268056646
INFO:root:current train perplexity4.223606109619141
INFO:root:current mean train loss 1826.4035365788018
INFO:root:current train perplexity4.2250590324401855
INFO:root:current mean train loss 1826.2426730623795
INFO:root:current train perplexity4.225020885467529
INFO:root:current mean train loss 1826.266515499962
INFO:root:current train perplexity4.22488260269165
INFO:root:current mean train loss 1827.6335887195269
INFO:root:current train perplexity4.225694179534912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.23s/it]
INFO:root:final mean train loss: 1827.2676363900282
INFO:root:final train perplexity: 4.225312232971191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 1885.8164214005708
INFO:root:eval perplexity: 4.595776081085205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 2356.091544942653
INFO:root:eval perplexity: 6.868022441864014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [6:16:28<4:44:42, 397.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.77052935432
INFO:root:current train perplexity4.288615703582764
INFO:root:current mean train loss 1833.0786576043993
INFO:root:current train perplexity4.260679721832275
INFO:root:current mean train loss 1828.6417682704641
INFO:root:current train perplexity4.23714017868042
INFO:root:current mean train loss 1831.0466056492019
INFO:root:current train perplexity4.239907741546631
INFO:root:current mean train loss 1828.6300763513289
INFO:root:current train perplexity4.23290491104126
INFO:root:current mean train loss 1826.9207875426387
INFO:root:current train perplexity4.224096298217773
INFO:root:current mean train loss 1825.6221795910133
INFO:root:current train perplexity4.218364715576172
INFO:root:current mean train loss 1827.9172603289287
INFO:root:current train perplexity4.2204484939575195
INFO:root:current mean train loss 1826.2642853205105
INFO:root:current train perplexity4.2219414710998535
INFO:root:current mean train loss 1825.931459663328
INFO:root:current train perplexity4.219793319702148
INFO:root:current mean train loss 1827.6620639986759
INFO:root:current train perplexity4.222086429595947
INFO:root:current mean train loss 1828.9163455701855
INFO:root:current train perplexity4.225255489349365
INFO:root:current mean train loss 1829.19012143108
INFO:root:current train perplexity4.228662967681885
INFO:root:current mean train loss 1829.4618307191727
INFO:root:current train perplexity4.230257034301758
INFO:root:current mean train loss 1829.2923950694237
INFO:root:current train perplexity4.227935314178467
INFO:root:current mean train loss 1829.7291804722377
INFO:root:current train perplexity4.229879379272461
INFO:root:current mean train loss 1828.6598679796398
INFO:root:current train perplexity4.226865768432617
INFO:root:current mean train loss 1828.447291861832
INFO:root:current train perplexity4.225882053375244
INFO:root:current mean train loss 1827.6146167697948
INFO:root:current train perplexity4.224494457244873
INFO:root:current mean train loss 1827.9603840897723
INFO:root:current train perplexity4.226550102233887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.78s/it]
INFO:root:final mean train loss: 1827.6433420032188
INFO:root:final train perplexity: 4.226564407348633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 1879.897056633699
INFO:root:eval perplexity: 4.573827743530273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.45s/it]
INFO:root:eval mean loss: 2347.0289739514074
INFO:root:eval perplexity: 6.81730842590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:23:01<4:37:16, 396.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1835.5033088235293
INFO:root:current train perplexity4.261246681213379
INFO:root:current mean train loss 1828.644143264358
INFO:root:current train perplexity4.225202560424805
INFO:root:current mean train loss 1833.879356839364
INFO:root:current train perplexity4.23023796081543
INFO:root:current mean train loss 1831.9560908329952
INFO:root:current train perplexity4.2286787033081055
INFO:root:current mean train loss 1832.0630922297842
INFO:root:current train perplexity4.2291579246521
INFO:root:current mean train loss 1827.9145209418402
INFO:root:current train perplexity4.223171710968018
INFO:root:current mean train loss 1829.1083351747834
INFO:root:current train perplexity4.22654914855957
INFO:root:current mean train loss 1828.3337228179737
INFO:root:current train perplexity4.222873210906982
INFO:root:current mean train loss 1827.8730413576977
INFO:root:current train perplexity4.222164154052734
INFO:root:current mean train loss 1827.708380715617
INFO:root:current train perplexity4.2248053550720215
INFO:root:current mean train loss 1826.7142834641418
INFO:root:current train perplexity4.220193862915039
INFO:root:current mean train loss 1825.8932851026832
INFO:root:current train perplexity4.219268321990967
INFO:root:current mean train loss 1824.8619816999028
INFO:root:current train perplexity4.217574119567871
INFO:root:current mean train loss 1826.3667167580945
INFO:root:current train perplexity4.220664024353027
INFO:root:current mean train loss 1826.4788676149517
INFO:root:current train perplexity4.220800399780273
INFO:root:current mean train loss 1826.3181191621895
INFO:root:current train perplexity4.218385219573975
INFO:root:current mean train loss 1827.2256580930082
INFO:root:current train perplexity4.220553398132324
INFO:root:current mean train loss 1827.7284094887955
INFO:root:current train perplexity4.220437526702881
INFO:root:current mean train loss 1826.8415731333928
INFO:root:current train perplexity4.21923828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.15s/it]
INFO:root:final mean train loss: 1825.338685713329
INFO:root:final train perplexity: 4.218889236450195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 1878.6710932305518
INFO:root:eval perplexity: 4.5692949295043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 2347.005940322335
INFO:root:eval perplexity: 6.817180633544922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:29:39<4:30:58, 396.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1939.1082763671875
INFO:root:current train perplexity4.253047943115234
INFO:root:current mean train loss 1832.7500119676777
INFO:root:current train perplexity4.229650974273682
INFO:root:current mean train loss 1819.7844969494508
INFO:root:current train perplexity4.22165584564209
INFO:root:current mean train loss 1824.450801621999
INFO:root:current train perplexity4.230186939239502
INFO:root:current mean train loss 1829.365043070779
INFO:root:current train perplexity4.227895736694336
INFO:root:current mean train loss 1831.0424466684044
INFO:root:current train perplexity4.2318596839904785
INFO:root:current mean train loss 1829.475707196714
INFO:root:current train perplexity4.227770805358887
INFO:root:current mean train loss 1830.4130102956397
INFO:root:current train perplexity4.232603073120117
INFO:root:current mean train loss 1830.5480852008163
INFO:root:current train perplexity4.230389595031738
INFO:root:current mean train loss 1827.9697616137316
INFO:root:current train perplexity4.222702503204346
INFO:root:current mean train loss 1827.0682270712482
INFO:root:current train perplexity4.220915794372559
INFO:root:current mean train loss 1827.3416833341014
INFO:root:current train perplexity4.219067096710205
INFO:root:current mean train loss 1826.8255266897293
INFO:root:current train perplexity4.221360683441162
INFO:root:current mean train loss 1827.5498660976803
INFO:root:current train perplexity4.221504211425781
INFO:root:current mean train loss 1827.64727591652
INFO:root:current train perplexity4.221808433532715
INFO:root:current mean train loss 1826.6463749830955
INFO:root:current train perplexity4.219148635864258
INFO:root:current mean train loss 1827.119128585606
INFO:root:current train perplexity4.220459461212158
INFO:root:current mean train loss 1825.7528814188042
INFO:root:current train perplexity4.218881130218506
INFO:root:current mean train loss 1825.567741504123
INFO:root:current train perplexity4.219781398773193
INFO:root:current mean train loss 1825.4996100424717
INFO:root:current train perplexity4.219258785247803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.10s/it]
INFO:root:final mean train loss: 1825.2852812751157
INFO:root:final train perplexity: 4.218710899353027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 1877.5725331407912
INFO:root:eval perplexity: 4.565237045288086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it]
INFO:root:eval mean loss: 2345.938237183483
INFO:root:eval perplexity: 6.8112311363220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:36:25<4:26:19, 399.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1761.588558799342
INFO:root:current train perplexity4.105891227722168
INFO:root:current mean train loss 1801.865609818146
INFO:root:current train perplexity4.176169395446777
INFO:root:current mean train loss 1818.025661520762
INFO:root:current train perplexity4.2088303565979
INFO:root:current mean train loss 1810.1008346701117
INFO:root:current train perplexity4.179567813873291
INFO:root:current mean train loss 1810.1961940865529
INFO:root:current train perplexity4.179782390594482
INFO:root:current mean train loss 1812.6111818287873
INFO:root:current train perplexity4.179869174957275
INFO:root:current mean train loss 1813.1128907827645
INFO:root:current train perplexity4.1748504638671875
INFO:root:current mean train loss 1813.9696635748978
INFO:root:current train perplexity4.178842544555664
INFO:root:current mean train loss 1816.2650155427255
INFO:root:current train perplexity4.184882640838623
INFO:root:current mean train loss 1812.5549199516288
INFO:root:current train perplexity4.1815009117126465
INFO:root:current mean train loss 1813.523948302564
INFO:root:current train perplexity4.183715343475342
INFO:root:current mean train loss 1815.7624737532465
INFO:root:current train perplexity4.1898112297058105
INFO:root:current mean train loss 1817.8635831712404
INFO:root:current train perplexity4.193524360656738
INFO:root:current mean train loss 1819.6137133548439
INFO:root:current train perplexity4.198694229125977
INFO:root:current mean train loss 1819.318639388296
INFO:root:current train perplexity4.19983434677124
INFO:root:current mean train loss 1820.307471088864
INFO:root:current train perplexity4.202404975891113
INFO:root:current mean train loss 1819.650911026048
INFO:root:current train perplexity4.2015838623046875
INFO:root:current mean train loss 1820.755217920007
INFO:root:current train perplexity4.203306198120117
INFO:root:current mean train loss 1820.3629205419572
INFO:root:current train perplexity4.202591419219971
INFO:root:current mean train loss 1820.9421060392172
INFO:root:current train perplexity4.204868316650391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.19s/it]
INFO:root:final mean train loss: 1821.3828763668428
INFO:root:final train perplexity: 4.205748081207275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 1878.4254881946754
INFO:root:eval perplexity: 4.568387508392334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it]
INFO:root:eval mean loss: 2345.456156845634
INFO:root:eval perplexity: 6.808545112609863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:43:03<4:19:22, 399.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.8388366699219
INFO:root:current train perplexity4.172144889831543
INFO:root:current mean train loss 1796.3193449132582
INFO:root:current train perplexity4.149624347686768
INFO:root:current mean train loss 1802.8438405182403
INFO:root:current train perplexity4.165399551391602
INFO:root:current mean train loss 1807.6119195847284
INFO:root:current train perplexity4.1790876388549805
INFO:root:current mean train loss 1808.807497077032
INFO:root:current train perplexity4.182435989379883
INFO:root:current mean train loss 1805.2077413530492
INFO:root:current train perplexity4.178905010223389
INFO:root:current mean train loss 1804.3356947029163
INFO:root:current train perplexity4.175357341766357
INFO:root:current mean train loss 1803.2691426484482
INFO:root:current train perplexity4.173107147216797
INFO:root:current mean train loss 1807.2980088229385
INFO:root:current train perplexity4.185807228088379
INFO:root:current mean train loss 1810.360376211313
INFO:root:current train perplexity4.184103965759277
INFO:root:current mean train loss 1811.0867435646794
INFO:root:current train perplexity4.1840128898620605
INFO:root:current mean train loss 1813.7652312802597
INFO:root:current train perplexity4.187735557556152
INFO:root:current mean train loss 1814.878488090046
INFO:root:current train perplexity4.187119483947754
INFO:root:current mean train loss 1815.019791471744
INFO:root:current train perplexity4.187849521636963
INFO:root:current mean train loss 1816.044897052903
INFO:root:current train perplexity4.190194606781006
INFO:root:current mean train loss 1818.5245708624523
INFO:root:current train perplexity4.194973945617676
INFO:root:current mean train loss 1819.17192454443
INFO:root:current train perplexity4.195279121398926
INFO:root:current mean train loss 1820.5328801590176
INFO:root:current train perplexity4.198202610015869
INFO:root:current mean train loss 1819.5125361423866
INFO:root:current train perplexity4.199967861175537
INFO:root:current mean train loss 1820.5728284977683
INFO:root:current train perplexity4.200804233551025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.32s/it]
INFO:root:final mean train loss: 1820.0873984655707
INFO:root:final train perplexity: 4.201452732086182
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it]
INFO:root:eval mean loss: 1877.1343691129211
INFO:root:eval perplexity: 4.563620090484619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it]
INFO:root:eval mean loss: 2348.1737077861812
INFO:root:eval perplexity: 6.823694229125977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:49:33<4:10:57, 396.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.4024358785377
INFO:root:current train perplexity4.247344493865967
INFO:root:current mean train loss 1835.9445393880208
INFO:root:current train perplexity4.218613147735596
INFO:root:current mean train loss 1824.4745379662797
INFO:root:current train perplexity4.187470436096191
INFO:root:current mean train loss 1824.9094027338217
INFO:root:current train perplexity4.189431667327881
INFO:root:current mean train loss 1822.4643948114997
INFO:root:current train perplexity4.18880033493042
INFO:root:current mean train loss 1823.4540062019666
INFO:root:current train perplexity4.191643714904785
INFO:root:current mean train loss 1821.8616767637945
INFO:root:current train perplexity4.189527988433838
INFO:root:current mean train loss 1818.420835538056
INFO:root:current train perplexity4.18836784362793
INFO:root:current mean train loss 1816.9697806569643
INFO:root:current train perplexity4.183877468109131
INFO:root:current mean train loss 1817.071204650815
INFO:root:current train perplexity4.18139123916626
INFO:root:current mean train loss 1817.9693510774646
INFO:root:current train perplexity4.186288356781006
INFO:root:current mean train loss 1815.8437803852382
INFO:root:current train perplexity4.185177326202393
INFO:root:current mean train loss 1816.2122105189733
INFO:root:current train perplexity4.187625885009766
INFO:root:current mean train loss 1816.5321841581786
INFO:root:current train perplexity4.186798095703125
INFO:root:current mean train loss 1816.045943552268
INFO:root:current train perplexity4.185932636260986
INFO:root:current mean train loss 1818.1155316511893
INFO:root:current train perplexity4.189671039581299
INFO:root:current mean train loss 1818.9740525630482
INFO:root:current train perplexity4.191258907318115
INFO:root:current mean train loss 1818.1660525315976
INFO:root:current train perplexity4.190480709075928
INFO:root:current mean train loss 1817.1090019378414
INFO:root:current train perplexity4.189274311065674
INFO:root:current mean train loss 1817.7283753660233
INFO:root:current train perplexity4.191711902618408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.13s/it]
INFO:root:final mean train loss: 1816.8703384591784
INFO:root:final train perplexity: 4.1908063888549805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 1876.2051382944094
INFO:root:eval perplexity: 4.5601911544799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it]
INFO:root:eval mean loss: 2343.844111882203
INFO:root:eval perplexity: 6.7995758056640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:56:04<4:03:22, 394.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.0073346819197
INFO:root:current train perplexity4.1410393714904785
INFO:root:current mean train loss 1800.288381060432
INFO:root:current train perplexity4.1622843742370605
INFO:root:current mean train loss 1810.5411729600694
INFO:root:current train perplexity4.184940814971924
INFO:root:current mean train loss 1814.364568926837
INFO:root:current train perplexity4.180698394775391
INFO:root:current mean train loss 1807.561726541722
INFO:root:current train perplexity4.170147895812988
INFO:root:current mean train loss 1808.497427100466
INFO:root:current train perplexity4.171688556671143
INFO:root:current mean train loss 1807.3093737246386
INFO:root:current train perplexity4.171194553375244
INFO:root:current mean train loss 1808.7264274299919
INFO:root:current train perplexity4.175393581390381
INFO:root:current mean train loss 1809.0383550534302
INFO:root:current train perplexity4.17227029800415
INFO:root:current mean train loss 1809.116956447326
INFO:root:current train perplexity4.174314022064209
INFO:root:current mean train loss 1811.0663925598715
INFO:root:current train perplexity4.175943851470947
INFO:root:current mean train loss 1812.439449473324
INFO:root:current train perplexity4.178646087646484
INFO:root:current mean train loss 1813.61815704586
INFO:root:current train perplexity4.180825710296631
INFO:root:current mean train loss 1814.3534369475651
INFO:root:current train perplexity4.181859970092773
INFO:root:current mean train loss 1815.9314601768442
INFO:root:current train perplexity4.183435916900635
INFO:root:current mean train loss 1816.5632895694416
INFO:root:current train perplexity4.183952808380127
INFO:root:current mean train loss 1816.4463127456027
INFO:root:current train perplexity4.184279441833496
INFO:root:current mean train loss 1816.4073333222987
INFO:root:current train perplexity4.185429573059082
INFO:root:current mean train loss 1816.089056298567
INFO:root:current train perplexity4.1865105628967285
INFO:root:current mean train loss 1816.45553907985
INFO:root:current train perplexity4.186790466308594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it]
INFO:root:final mean train loss: 1815.4912118300967
INFO:root:final train perplexity: 4.186251163482666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 1889.924749712572
INFO:root:eval perplexity: 4.6110711097717285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it]
INFO:root:eval mean loss: 2358.864369060976
INFO:root:eval perplexity: 6.883616924285889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [7:02:34<3:55:53, 393.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1808.8670612203664
INFO:root:current train perplexity4.129132270812988
INFO:root:current mean train loss 1813.074389778994
INFO:root:current train perplexity4.17520809173584
INFO:root:current mean train loss 1810.9967198388501
INFO:root:current train perplexity4.167682647705078
INFO:root:current mean train loss 1813.4865599639656
INFO:root:current train perplexity4.168631553649902
INFO:root:current mean train loss 1811.0807829745252
INFO:root:current train perplexity4.169014930725098
INFO:root:current mean train loss 1808.1961938185423
INFO:root:current train perplexity4.165822505950928
INFO:root:current mean train loss 1807.1856424700918
INFO:root:current train perplexity4.163503170013428
INFO:root:current mean train loss 1808.4763766801343
INFO:root:current train perplexity4.166621685028076
INFO:root:current mean train loss 1809.2869449172508
INFO:root:current train perplexity4.16824197769165
INFO:root:current mean train loss 1809.272309308115
INFO:root:current train perplexity4.166622161865234
INFO:root:current mean train loss 1807.8415879966365
INFO:root:current train perplexity4.16172981262207
INFO:root:current mean train loss 1808.3078515583863
INFO:root:current train perplexity4.1666669845581055
INFO:root:current mean train loss 1808.0717031720449
INFO:root:current train perplexity4.164765357971191
INFO:root:current mean train loss 1809.0924541360625
INFO:root:current train perplexity4.165854454040527
INFO:root:current mean train loss 1808.78823296368
INFO:root:current train perplexity4.16489839553833
INFO:root:current mean train loss 1810.3252796156269
INFO:root:current train perplexity4.166252613067627
INFO:root:current mean train loss 1811.0651964731449
INFO:root:current train perplexity4.168257713317871
INFO:root:current mean train loss 1810.0123287600115
INFO:root:current train perplexity4.167553424835205
INFO:root:current mean train loss 1811.2536459368375
INFO:root:current train perplexity4.170913219451904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.12s/it]
INFO:root:final mean train loss: 1812.0208621426657
INFO:root:final train perplexity: 4.174808979034424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 1882.9547811738144
INFO:root:eval perplexity: 4.585153102874756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.66s/it]
INFO:root:eval mean loss: 2352.691734368074
INFO:root:eval perplexity: 6.848954200744629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [7:09:01<3:48:17, 391.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.1697387695312
INFO:root:current train perplexity4.257009029388428
INFO:root:current mean train loss 1814.0916595458984
INFO:root:current train perplexity4.180055618286133
INFO:root:current mean train loss 1804.2977881338081
INFO:root:current train perplexity4.168914318084717
INFO:root:current mean train loss 1802.8493788869757
INFO:root:current train perplexity4.158795356750488
INFO:root:current mean train loss 1805.6115601794554
INFO:root:current train perplexity4.168535232543945
INFO:root:current mean train loss 1806.2677648635138
INFO:root:current train perplexity4.163295745849609
INFO:root:current mean train loss 1806.6763693702142
INFO:root:current train perplexity4.1611504554748535
INFO:root:current mean train loss 1807.3308951637962
INFO:root:current train perplexity4.165497779846191
INFO:root:current mean train loss 1803.3882599636097
INFO:root:current train perplexity4.158816814422607
INFO:root:current mean train loss 1805.7889055910364
INFO:root:current train perplexity4.159727096557617
INFO:root:current mean train loss 1806.517365231457
INFO:root:current train perplexity4.160571098327637
INFO:root:current mean train loss 1808.4004553089972
INFO:root:current train perplexity4.164584636688232
INFO:root:current mean train loss 1809.8445272350627
INFO:root:current train perplexity4.167208671569824
INFO:root:current mean train loss 1809.8461050021867
INFO:root:current train perplexity4.165354251861572
INFO:root:current mean train loss 1812.3273369335382
INFO:root:current train perplexity4.170213222503662
INFO:root:current mean train loss 1813.158195657933
INFO:root:current train perplexity4.171685218811035
INFO:root:current mean train loss 1812.6485767697457
INFO:root:current train perplexity4.171114921569824
INFO:root:current mean train loss 1812.4471217768853
INFO:root:current train perplexity4.170234203338623
INFO:root:current mean train loss 1811.2787629188824
INFO:root:current train perplexity4.170295715332031
INFO:root:current mean train loss 1811.069731447877
INFO:root:current train perplexity4.1705121994018555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.28s/it]
INFO:root:final mean train loss: 1810.6712709273945
INFO:root:final train perplexity: 4.17036771774292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 1879.7505480177858
INFO:root:eval perplexity: 4.5732855796813965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2350.729010399352
INFO:root:eval perplexity: 6.83797025680542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [7:15:29<3:41:17, 390.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.0785319010417
INFO:root:current train perplexity4.190812587738037
INFO:root:current mean train loss 1818.5174651342975
INFO:root:current train perplexity4.172556400299072
INFO:root:current mean train loss 1810.8374128384828
INFO:root:current train perplexity4.160552978515625
INFO:root:current mean train loss 1813.687574535144
INFO:root:current train perplexity4.165255069732666
INFO:root:current mean train loss 1809.8264096366538
INFO:root:current train perplexity4.160281658172607
INFO:root:current mean train loss 1808.5450758101158
INFO:root:current train perplexity4.151814937591553
INFO:root:current mean train loss 1808.167577771173
INFO:root:current train perplexity4.15332555770874
INFO:root:current mean train loss 1809.1338904773643
INFO:root:current train perplexity4.161306381225586
INFO:root:current mean train loss 1809.8733338368795
INFO:root:current train perplexity4.163994312286377
INFO:root:current mean train loss 1810.1222497730896
INFO:root:current train perplexity4.165713787078857
INFO:root:current mean train loss 1809.3356405140487
INFO:root:current train perplexity4.163250923156738
INFO:root:current mean train loss 1809.4356425929345
INFO:root:current train perplexity4.161998748779297
INFO:root:current mean train loss 1808.41107232721
INFO:root:current train perplexity4.159414291381836
INFO:root:current mean train loss 1808.5259708517162
INFO:root:current train perplexity4.159450531005859
INFO:root:current mean train loss 1807.0088034085536
INFO:root:current train perplexity4.158135890960693
INFO:root:current mean train loss 1807.5669085761579
INFO:root:current train perplexity4.156899929046631
INFO:root:current mean train loss 1807.797236165465
INFO:root:current train perplexity4.157188892364502
INFO:root:current mean train loss 1807.4970510195744
INFO:root:current train perplexity4.158487319946289
INFO:root:current mean train loss 1806.806520163522
INFO:root:current train perplexity4.159750938415527
INFO:root:current mean train loss 1808.1240145411732
INFO:root:current train perplexity4.161595344543457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.06s/it]
INFO:root:final mean train loss: 1808.237749077609
INFO:root:final train perplexity: 4.16237211227417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.77s/it]
INFO:root:eval mean loss: 1878.3290141220634
INFO:root:eval perplexity: 4.568030834197998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 2348.6645975315823
INFO:root:eval perplexity: 6.8264336585998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:21:57<3:34:21, 389.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1803.4686664782073
INFO:root:current train perplexity4.133817672729492
INFO:root:current mean train loss 1796.3173907736073
INFO:root:current train perplexity4.116039276123047
INFO:root:current mean train loss 1804.513718548943
INFO:root:current train perplexity4.117684364318848
INFO:root:current mean train loss 1801.290957479082
INFO:root:current train perplexity4.118112087249756
INFO:root:current mean train loss 1803.0215359343786
INFO:root:current train perplexity4.123948574066162
INFO:root:current mean train loss 1808.3628011370238
INFO:root:current train perplexity4.1447625160217285
INFO:root:current mean train loss 1810.1757100742066
INFO:root:current train perplexity4.152533531188965
INFO:root:current mean train loss 1810.4215357503917
INFO:root:current train perplexity4.1526947021484375
INFO:root:current mean train loss 2068.656026835658
INFO:root:current train perplexity5.094808578491211
INFO:root:current mean train loss 2426.534265579191
INFO:root:current train perplexity6.756735324859619
INFO:root:current mean train loss 2700.8565772613347
INFO:root:current train perplexity8.387081146240234
INFO:root:current mean train loss 2887.6562459238385
INFO:root:current train perplexity9.719724655151367
INFO:root:current mean train loss 2930.9882516691487
INFO:root:current train perplexity10.056097030639648
INFO:root:current mean train loss 2914.6632988762963
INFO:root:current train perplexity9.935355186462402
INFO:root:current mean train loss 2893.028509445084
INFO:root:current train perplexity9.780410766601562
INFO:root:current mean train loss 2866.814188745149
INFO:root:current train perplexity9.58688735961914
INFO:root:current mean train loss 2850.401020129231
INFO:root:current train perplexity9.456730842590332
INFO:root:current mean train loss 2833.492770389254
INFO:root:current train perplexity9.332347869873047
INFO:root:current mean train loss 2823.713272177745
INFO:root:current train perplexity9.263090133666992
INFO:root:current mean train loss 2812.366109338215
INFO:root:current train perplexity9.180524826049805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.93s/it]
INFO:root:final mean train loss: 2805.1958606160174
INFO:root:final train perplexity: 9.137129783630371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2138.613278652759
INFO:root:eval perplexity: 5.6383137702941895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 2597.8843955182015
INFO:root:eval perplexity: 8.369726181030273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:28:25<3:27:29, 389.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2482.6936745383523
INFO:root:current train perplexity7.097014904022217
INFO:root:current mean train loss 2548.4583763860887
INFO:root:current train perplexity7.493043899536133
INFO:root:current mean train loss 2576.098597388174
INFO:root:current train perplexity7.709575176239014
INFO:root:current mean train loss 2590.403640790053
INFO:root:current train perplexity7.789331912994385
INFO:root:current mean train loss 2617.6572871952267
INFO:root:current train perplexity7.926784038543701
INFO:root:current mean train loss 2627.0422710796734
INFO:root:current train perplexity7.968328475952148
INFO:root:current mean train loss 2634.9643010496184
INFO:root:current train perplexity8.00676441192627
INFO:root:current mean train loss 2636.7737666856374
INFO:root:current train perplexity8.009100914001465
INFO:root:current mean train loss 2649.0883871870433
INFO:root:current train perplexity8.081314086914062
INFO:root:current mean train loss 2655.530296445517
INFO:root:current train perplexity8.113001823425293
INFO:root:current mean train loss 2666.704530139218
INFO:root:current train perplexity8.182491302490234
INFO:root:current mean train loss 2683.0358753551136
INFO:root:current train perplexity8.293357849121094
INFO:root:current mean train loss 2694.0504359515066
INFO:root:current train perplexity8.358534812927246
INFO:root:current mean train loss 2715.80032504036
INFO:root:current train perplexity8.50373363494873
INFO:root:current mean train loss 2754.3675442305625
INFO:root:current train perplexity8.768074989318848
INFO:root:current mean train loss 2821.881691494172
INFO:root:current train perplexity9.24215316772461
INFO:root:current mean train loss 2989.111080001416
INFO:root:current train perplexity10.546579360961914
INFO:root:current mean train loss 3150.862761807781
INFO:root:current train perplexity11.978887557983398
INFO:root:current mean train loss 3156.384812610554
INFO:root:current train perplexity12.047204971313477
INFO:root:current mean train loss 3119.6828706316937
INFO:root:current train perplexity11.707717895507812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.10s/it]
INFO:root:final mean train loss: 3108.5745627999127
INFO:root:final train perplexity: 11.607006072998047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it]
INFO:root:eval mean loss: 2216.8906717503323
INFO:root:eval perplexity: 6.006793022155762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 2666.7313037628824
INFO:root:eval perplexity: 8.854504585266113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:34:43<3:19:15, 385.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2557.16214328342
INFO:root:current train perplexity7.48036003112793
INFO:root:current mean train loss 2860.9100114689318
INFO:root:current train perplexity9.47249984741211
INFO:root:current mean train loss 2807.7486603680777
INFO:root:current train perplexity9.148595809936523
INFO:root:current mean train loss 2693.583061300298
INFO:root:current train perplexity8.387770652770996
INFO:root:current mean train loss 2636.0540706828488
INFO:root:current train perplexity7.989785194396973
INFO:root:current mean train loss 2601.602853841715
INFO:root:current train perplexity7.767387866973877
INFO:root:current mean train loss 2588.315332503546
INFO:root:current train perplexity7.688575744628906
INFO:root:current mean train loss 2598.6854572197317
INFO:root:current train perplexity7.736668586730957
INFO:root:current mean train loss 2610.761093979582
INFO:root:current train perplexity7.821774482727051
INFO:root:current mean train loss 2615.228478828085
INFO:root:current train perplexity7.846134185791016
INFO:root:current mean train loss 2616.0880779437166
INFO:root:current train perplexity7.855964660644531
INFO:root:current mean train loss 2613.7435093381705
INFO:root:current train perplexity7.843724727630615
INFO:root:current mean train loss 2610.896905959027
INFO:root:current train perplexity7.8266825675964355
INFO:root:current mean train loss 2608.952158669341
INFO:root:current train perplexity7.8143205642700195
INFO:root:current mean train loss 2605.144764692887
INFO:root:current train perplexity7.8027448654174805
INFO:root:current mean train loss 2604.4690861592767
INFO:root:current train perplexity7.7947587966918945
INFO:root:current mean train loss 2600.9748254073293
INFO:root:current train perplexity7.774116516113281
INFO:root:current mean train loss 2598.0492124535967
INFO:root:current train perplexity7.7543134689331055
INFO:root:current mean train loss 2595.747437501565
INFO:root:current train perplexity7.741878986358643
INFO:root:current mean train loss 2595.5539607111873
INFO:root:current train perplexity7.7372050285339355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.22s/it]
INFO:root:final mean train loss: 2594.0115694708734
INFO:root:final train perplexity: 7.735294342041016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 2288.8866568490967
INFO:root:eval perplexity: 6.366927623748779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it]
INFO:root:eval mean loss: 2723.3458801702404
INFO:root:eval perplexity: 9.274112701416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:41:04<3:12:11, 384.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2563.583773152212
INFO:root:current train perplexity7.564024448394775
INFO:root:current mean train loss 2571.3719359705688
INFO:root:current train perplexity7.587552070617676
INFO:root:current mean train loss 2584.979609611538
INFO:root:current train perplexity7.626682281494141
INFO:root:current mean train loss 2582.514096139942
INFO:root:current train perplexity7.637170314788818
INFO:root:current mean train loss 2580.4909817748276
INFO:root:current train perplexity7.64466667175293
INFO:root:current mean train loss 2583.506080303613
INFO:root:current train perplexity7.667479991912842
INFO:root:current mean train loss 2582.545996944167
INFO:root:current train perplexity7.666335582733154
INFO:root:current mean train loss 2590.4499415795312
INFO:root:current train perplexity7.69875431060791
INFO:root:current mean train loss 2586.8037164299776
INFO:root:current train perplexity7.707702159881592
INFO:root:current mean train loss 2589.187958905381
INFO:root:current train perplexity7.718261241912842
INFO:root:current mean train loss 2588.706031820334
INFO:root:current train perplexity7.717714786529541
INFO:root:current mean train loss 2587.4964150957344
INFO:root:current train perplexity7.710766315460205
INFO:root:current mean train loss 2584.9898421211333
INFO:root:current train perplexity7.696210861206055
INFO:root:current mean train loss 2584.8138384671415
INFO:root:current train perplexity7.686156272888184
INFO:root:current mean train loss 2585.448195130173
INFO:root:current train perplexity7.676036357879639
INFO:root:current mean train loss 2585.3625345392147
INFO:root:current train perplexity7.669504165649414
INFO:root:current mean train loss 2583.530508037994
INFO:root:current train perplexity7.666430950164795
INFO:root:current mean train loss 2583.0032854586625
INFO:root:current train perplexity7.656692981719971
INFO:root:current mean train loss 2582.701500153024
INFO:root:current train perplexity7.655979156494141

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.38s/it]
INFO:root:final mean train loss: 2578.6058030121267
INFO:root:final train perplexity: 7.641880512237549
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2290.9450791812114
INFO:root:eval perplexity: 6.377536296844482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it]
INFO:root:eval mean loss: 2726.460840103474
INFO:root:eval perplexity: 9.297771453857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:47:50<3:08:56, 390.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2580.8831787109375
INFO:root:current train perplexity7.596349239349365
INFO:root:current mean train loss 2564.535722840507
INFO:root:current train perplexity7.558138847351074
INFO:root:current mean train loss 2552.674277296344
INFO:root:current train perplexity7.473787307739258
INFO:root:current mean train loss 2547.653852475235
INFO:root:current train perplexity7.453458786010742
INFO:root:current mean train loss 2539.863424366918
INFO:root:current train perplexity7.409498691558838
INFO:root:current mean train loss 2544.8097111999755
INFO:root:current train perplexity7.407414436340332
INFO:root:current mean train loss 2540.975389738681
INFO:root:current train perplexity7.39829158782959
INFO:root:current mean train loss 2534.758024826266
INFO:root:current train perplexity7.373194217681885
INFO:root:current mean train loss 2529.1009630529816
INFO:root:current train perplexity7.3407673835754395
INFO:root:current mean train loss 2530.5351910117447
INFO:root:current train perplexity7.34849739074707
INFO:root:current mean train loss 2529.3739981983103
INFO:root:current train perplexity7.341991424560547
INFO:root:current mean train loss 2528.9057030013846
INFO:root:current train perplexity7.337823390960693
INFO:root:current mean train loss 2528.3157546010184
INFO:root:current train perplexity7.332910537719727
INFO:root:current mean train loss 2526.024171043501
INFO:root:current train perplexity7.321393966674805
INFO:root:current mean train loss 2524.655056732308
INFO:root:current train perplexity7.31423807144165
INFO:root:current mean train loss 2521.8426607696815
INFO:root:current train perplexity7.298015594482422
INFO:root:current mean train loss 2517.2800644129925
INFO:root:current train perplexity7.277131080627441
INFO:root:current mean train loss 2515.001300556858
INFO:root:current train perplexity7.258399486541748
INFO:root:current mean train loss 2512.636030938538
INFO:root:current train perplexity7.241213321685791
INFO:root:current mean train loss 2508.541386191017
INFO:root:current train perplexity7.226294040679932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.15s/it]
INFO:root:final mean train loss: 2506.0178466427524
INFO:root:final train perplexity: 7.216690540313721
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2242.5529763512577
INFO:root:eval perplexity: 6.132761478424072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it]
INFO:root:eval mean loss: 2684.0349021532857
INFO:root:eval perplexity: 8.980696678161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:54:08<3:00:34, 386.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2483.017047384511
INFO:root:current train perplexity7.112457275390625
INFO:root:current mean train loss 2469.063113328887
INFO:root:current train perplexity7.0598835945129395
INFO:root:current mean train loss 2451.444630438971
INFO:root:current train perplexity6.956442356109619
INFO:root:current mean train loss 2447.2241913881094
INFO:root:current train perplexity6.889911651611328
INFO:root:current mean train loss 2440.2301045591385
INFO:root:current train perplexity6.840729236602783
INFO:root:current mean train loss 2434.662639668977
INFO:root:current train perplexity6.805293560028076
INFO:root:current mean train loss 2427.5303106660062
INFO:root:current train perplexity6.767619609832764
INFO:root:current mean train loss 2421.624802965346
INFO:root:current train perplexity6.732278347015381
INFO:root:current mean train loss 2415.920674023912
INFO:root:current train perplexity6.703362464904785
INFO:root:current mean train loss 2406.0618272246156
INFO:root:current train perplexity6.661291122436523
INFO:root:current mean train loss 2400.27695677637
INFO:root:current train perplexity6.636221885681152
INFO:root:current mean train loss 2396.4763812967844
INFO:root:current train perplexity6.612532138824463
INFO:root:current mean train loss 2390.6994180749502
INFO:root:current train perplexity6.583738803863525
INFO:root:current mean train loss 2386.5485557504253
INFO:root:current train perplexity6.559437274932861
INFO:root:current mean train loss 2379.41050933602
INFO:root:current train perplexity6.532290458679199
INFO:root:current mean train loss 2374.2400846525156
INFO:root:current train perplexity6.50832986831665
INFO:root:current mean train loss 2370.156412534778
INFO:root:current train perplexity6.484370708465576
INFO:root:current mean train loss 2365.345429866036
INFO:root:current train perplexity6.455248832702637
INFO:root:current mean train loss 2360.4697850866105
INFO:root:current train perplexity6.433291435241699
INFO:root:current mean train loss 2356.0096249553108
INFO:root:current train perplexity6.408771514892578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.47s/it]
INFO:root:final mean train loss: 2352.2145820652304
INFO:root:final train perplexity: 6.392323970794678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2150.0404883851397
INFO:root:eval perplexity: 5.6906609535217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 2603.2365545178136
INFO:root:eval perplexity: 8.40644359588623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [8:00:40<2:54:46, 388.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2224.7292053222654
INFO:root:current train perplexity5.923090934753418
INFO:root:current mean train loss 2248.6510323660714
INFO:root:current train perplexity5.925931930541992
INFO:root:current mean train loss 2246.775705464681
INFO:root:current train perplexity5.889594078063965
INFO:root:current mean train loss 2248.453280460133
INFO:root:current train perplexity5.880983829498291
INFO:root:current mean train loss 2255.6561678799717
INFO:root:current train perplexity5.900928974151611
INFO:root:current mean train loss 2248.2836215549046
INFO:root:current train perplexity5.881692886352539
INFO:root:current mean train loss 2248.545329475403
INFO:root:current train perplexity5.872188091278076
INFO:root:current mean train loss 2248.0960373337202
INFO:root:current train perplexity5.865849494934082
INFO:root:current mean train loss 2245.0668679373607
INFO:root:current train perplexity5.851400852203369
INFO:root:current mean train loss 2244.4475952148437
INFO:root:current train perplexity5.843886852264404
INFO:root:current mean train loss 2240.2645494901217
INFO:root:current train perplexity5.829715251922607
INFO:root:current mean train loss 2239.4087195680854
INFO:root:current train perplexity5.822223663330078
INFO:root:current mean train loss 2236.1687117053616
INFO:root:current train perplexity5.808261394500732
INFO:root:current mean train loss 2231.286582832906
INFO:root:current train perplexity5.78685998916626
INFO:root:current mean train loss 2222.8514912075466
INFO:root:current train perplexity5.754279613494873
INFO:root:current mean train loss 2216.9225230823863
INFO:root:current train perplexity5.723505973815918
INFO:root:current mean train loss 2209.2572573033776
INFO:root:current train perplexity5.692047595977783
INFO:root:current mean train loss 2201.9760639760684
INFO:root:current train perplexity5.665886402130127
INFO:root:current mean train loss 2194.3146879113237
INFO:root:current train perplexity5.635159492492676
INFO:root:current mean train loss 2188.2138276719556
INFO:root:current train perplexity5.612311840057373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.65s/it]
INFO:root:final mean train loss: 2184.2272816868185
INFO:root:final train perplexity: 5.599140644073486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 2032.3659693941156
INFO:root:eval perplexity: 5.174063205718994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it]
INFO:root:eval mean loss: 2495.7131421244735
INFO:root:eval perplexity: 7.698787212371826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [8:06:58<2:47:01, 385.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2070.7068342242324
INFO:root:current train perplexity5.028639793395996
INFO:root:current mean train loss 2066.5599645140824
INFO:root:current train perplexity5.057702541351318
INFO:root:current mean train loss 2073.152424971881
INFO:root:current train perplexity5.087802410125732
INFO:root:current mean train loss 2073.783759451046
INFO:root:current train perplexity5.083448886871338
INFO:root:current mean train loss 2067.636571304021
INFO:root:current train perplexity5.084828853607178
INFO:root:current mean train loss 2068.9606795524996
INFO:root:current train perplexity5.08446741104126
INFO:root:current mean train loss 2069.583251209927
INFO:root:current train perplexity5.089139938354492
INFO:root:current mean train loss 2068.671282870294
INFO:root:current train perplexity5.087158679962158
INFO:root:current mean train loss 2066.864677438102
INFO:root:current train perplexity5.079960823059082
INFO:root:current mean train loss 2064.8230500893906
INFO:root:current train perplexity5.075121879577637
INFO:root:current mean train loss 2064.6506890447613
INFO:root:current train perplexity5.073427677154541
INFO:root:current mean train loss 2062.431562234125
INFO:root:current train perplexity5.066201210021973
INFO:root:current mean train loss 2061.255781782176
INFO:root:current train perplexity5.064567565917969
INFO:root:current mean train loss 2058.813351613595
INFO:root:current train perplexity5.059577941894531
INFO:root:current mean train loss 2056.993001357938
INFO:root:current train perplexity5.054563999176025
INFO:root:current mean train loss 2054.781360153365
INFO:root:current train perplexity5.045604705810547
INFO:root:current mean train loss 2053.832945782806
INFO:root:current train perplexity5.044761657714844
INFO:root:current mean train loss 2052.855256638068
INFO:root:current train perplexity5.040360927581787
INFO:root:current mean train loss 2052.039640049685
INFO:root:current train perplexity5.037292003631592
INFO:root:current mean train loss 2050.201821960231
INFO:root:current train perplexity5.034536361694336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.24s/it]
INFO:root:final mean train loss: 2049.4350470823288
INFO:root:final train perplexity: 5.0344672203063965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.56s/it]
INFO:root:eval mean loss: 1998.6120445305573
INFO:root:eval perplexity: 5.034731388092041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it]
INFO:root:eval mean loss: 2462.0461443096187
INFO:root:eval perplexity: 7.489702224731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [8:13:12<2:39:11, 382.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.1183488175675
INFO:root:current train perplexity4.9507975578308105
INFO:root:current mean train loss 2023.5864573511585
INFO:root:current train perplexity4.9222798347473145
INFO:root:current mean train loss 2020.5926504761633
INFO:root:current train perplexity4.9294891357421875
INFO:root:current mean train loss 2020.333203647226
INFO:root:current train perplexity4.928699493408203
INFO:root:current mean train loss 2014.6850884674973
INFO:root:current train perplexity4.915806293487549
INFO:root:current mean train loss 2017.608908623353
INFO:root:current train perplexity4.9200758934021
INFO:root:current mean train loss 2015.0225389972993
INFO:root:current train perplexity4.915012836456299
INFO:root:current mean train loss 2013.8927405699894
INFO:root:current train perplexity4.907807350158691
INFO:root:current mean train loss 2015.9850102125642
INFO:root:current train perplexity4.910816192626953
INFO:root:current mean train loss 2017.4256332366128
INFO:root:current train perplexity4.9097185134887695
INFO:root:current mean train loss 2016.3835049137278
INFO:root:current train perplexity4.907392978668213
INFO:root:current mean train loss 2016.9840877084553
INFO:root:current train perplexity4.91016149520874
INFO:root:current mean train loss 2019.0668730683378
INFO:root:current train perplexity4.914132595062256
INFO:root:current mean train loss 2019.6760104649973
INFO:root:current train perplexity4.914892673492432
INFO:root:current mean train loss 2020.30819192832
INFO:root:current train perplexity4.915054798126221
INFO:root:current mean train loss 2020.5640893182426
INFO:root:current train perplexity4.91569185256958
INFO:root:current mean train loss 2019.5242315404018
INFO:root:current train perplexity4.91268253326416
INFO:root:current mean train loss 2018.4059345026028
INFO:root:current train perplexity4.9108147621154785
INFO:root:current mean train loss 2016.8402646776196
INFO:root:current train perplexity4.9073333740234375
INFO:root:current mean train loss 2017.0725777885955
INFO:root:current train perplexity4.905716419219971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.31s/it]
INFO:root:final mean train loss: 2016.640548113555
INFO:root:final train perplexity: 4.905926704406738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 1987.6845893589318
INFO:root:eval perplexity: 4.9904327392578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 2452.3226387619125
INFO:root:eval perplexity: 7.4303789138793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [8:19:42<2:33:41, 384.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2024.2806262341173
INFO:root:current train perplexity4.852741241455078
INFO:root:current mean train loss 2023.7699831018897
INFO:root:current train perplexity4.888565540313721
INFO:root:current mean train loss 2017.7014281807076
INFO:root:current train perplexity4.879298686981201
INFO:root:current mean train loss 2011.2932403642503
INFO:root:current train perplexity4.870646953582764
INFO:root:current mean train loss 2007.1560906373313
INFO:root:current train perplexity4.8623948097229
INFO:root:current mean train loss 2004.8615563613712
INFO:root:current train perplexity4.856037616729736
INFO:root:current mean train loss 2000.6925299681734
INFO:root:current train perplexity4.853609561920166
INFO:root:current mean train loss 2000.5159776304224
INFO:root:current train perplexity4.85381555557251
INFO:root:current mean train loss 1999.5414789715733
INFO:root:current train perplexity4.848086357116699
INFO:root:current mean train loss 1999.4076948887646
INFO:root:current train perplexity4.846975326538086
INFO:root:current mean train loss 1999.974827893167
INFO:root:current train perplexity4.843793869018555
INFO:root:current mean train loss 1998.9975886244818
INFO:root:current train perplexity4.839688777923584
INFO:root:current mean train loss 1999.868660475467
INFO:root:current train perplexity4.840214252471924
INFO:root:current mean train loss 2000.379980310787
INFO:root:current train perplexity4.841088771820068
INFO:root:current mean train loss 2000.7136416316912
INFO:root:current train perplexity4.8407511711120605
INFO:root:current mean train loss 2002.6096018773815
INFO:root:current train perplexity4.843418121337891
INFO:root:current mean train loss 2002.3056952478194
INFO:root:current train perplexity4.842598915100098
INFO:root:current mean train loss 2002.5008773931506
INFO:root:current train perplexity4.843873977661133
INFO:root:current mean train loss 2001.7767873004527
INFO:root:current train perplexity4.843286514282227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.60s/it]
INFO:root:final mean train loss: 2000.1237021949757
INFO:root:final train perplexity: 4.84243631362915
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 1984.7403867464539
INFO:root:eval perplexity: 4.97856330871582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it]
INFO:root:eval mean loss: 2446.6329999342033
INFO:root:eval perplexity: 7.395884037017822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:26:05<2:27:09, 383.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1903.9184875488281
INFO:root:current train perplexity4.554016590118408
INFO:root:current mean train loss 1998.207891393591
INFO:root:current train perplexity4.850992202758789
INFO:root:current mean train loss 1999.1433938833384
INFO:root:current train perplexity4.836740016937256
INFO:root:current mean train loss 1996.9133146211698
INFO:root:current train perplexity4.83717155456543
INFO:root:current mean train loss 1998.677802291571
INFO:root:current train perplexity4.83986759185791
INFO:root:current mean train loss 1996.3520404485266
INFO:root:current train perplexity4.828896999359131
INFO:root:current mean train loss 1999.2982243989643
INFO:root:current train perplexity4.825736045837402
INFO:root:current mean train loss 1998.7934144445733
INFO:root:current train perplexity4.825161933898926
INFO:root:current mean train loss 1995.6795814438622
INFO:root:current train perplexity4.819596290588379
INFO:root:current mean train loss 1995.4015423610872
INFO:root:current train perplexity4.818297386169434
INFO:root:current mean train loss 1996.3291636875697
INFO:root:current train perplexity4.818323612213135
INFO:root:current mean train loss 1996.7774692356372
INFO:root:current train perplexity4.819818496704102
INFO:root:current mean train loss 1998.9298881884442
INFO:root:current train perplexity4.8259453773498535
INFO:root:current mean train loss 2000.000748940564
INFO:root:current train perplexity4.8261284828186035
INFO:root:current mean train loss 1997.4211145747793
INFO:root:current train perplexity4.822584629058838
INFO:root:current mean train loss 1996.6562801128357
INFO:root:current train perplexity4.822051525115967
INFO:root:current mean train loss 1996.6254778809807
INFO:root:current train perplexity4.8263630867004395
INFO:root:current mean train loss 1997.3879878381376
INFO:root:current train perplexity4.830521106719971
INFO:root:current mean train loss 1997.4345595773343
INFO:root:current train perplexity4.8294219970703125
INFO:root:current mean train loss 1997.4723314969044
INFO:root:current train perplexity4.830195426940918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.24s/it]
INFO:root:final mean train loss: 1996.9090644501703
INFO:root:final train perplexity: 4.830174446105957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 1979.6220352497508
INFO:root:eval perplexity: 4.957998275756836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.73s/it]
INFO:root:eval mean loss: 2442.0358427872893
INFO:root:eval perplexity: 7.368129730224609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:32:17<2:19:29, 380.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1941.054208984375
INFO:root:current train perplexity4.708982467651367
INFO:root:current mean train loss 1991.4960380859375
INFO:root:current train perplexity4.827002048492432
INFO:root:current mean train loss 1989.5921267361111
INFO:root:current train perplexity4.810135364532471
INFO:root:current mean train loss 1988.3554120342549
INFO:root:current train perplexity4.816595077514648
INFO:root:current mean train loss 1984.5793092256433
INFO:root:current train perplexity4.813766956329346
INFO:root:current mean train loss 1985.055384579613
INFO:root:current train perplexity4.814420223236084
INFO:root:current mean train loss 1987.5701228515625
INFO:root:current train perplexity4.8224263191223145
INFO:root:current mean train loss 1987.9499863617996
INFO:root:current train perplexity4.817638397216797
INFO:root:current mean train loss 1988.847793412642
INFO:root:current train perplexity4.822361946105957
INFO:root:current mean train loss 1989.8596715318834
INFO:root:current train perplexity4.817635536193848
INFO:root:current mean train loss 1990.9553061880717
INFO:root:current train perplexity4.821794033050537
INFO:root:current mean train loss 1991.8469383680556
INFO:root:current train perplexity4.824573040008545
INFO:root:current mean train loss 1993.6077099609374
INFO:root:current train perplexity4.827436447143555
INFO:root:current mean train loss 1995.2147049122937
INFO:root:current train perplexity4.83012056350708
INFO:root:current mean train loss 1996.2930986156798
INFO:root:current train perplexity4.833401203155518
INFO:root:current mean train loss 1997.2885010566085
INFO:root:current train perplexity4.835813522338867
INFO:root:current mean train loss 1998.3402085336538
INFO:root:current train perplexity4.837940216064453
INFO:root:current mean train loss 1998.8964680281929
INFO:root:current train perplexity4.839020729064941
INFO:root:current mean train loss 2000.4695160664598
INFO:root:current train perplexity4.84034538269043
INFO:root:current mean train loss 1999.671599786932
INFO:root:current train perplexity4.838951587677002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.47s/it]
INFO:root:final mean train loss: 1999.6437766363208
INFO:root:final train perplexity: 4.840603351593018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 1984.8330151713487
INFO:root:eval perplexity: 4.978936195373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it]
INFO:root:eval mean loss: 2448.009344006261
INFO:root:eval perplexity: 7.4042134284973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:38:46<2:14:05, 383.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.449198404948
INFO:root:current train perplexity4.8812432289123535
INFO:root:current mean train loss 2012.5874289929027
INFO:root:current train perplexity4.901299953460693
INFO:root:current mean train loss 2010.9590191801717
INFO:root:current train perplexity4.889694690704346
INFO:root:current mean train loss 2004.7373000474004
INFO:root:current train perplexity4.854351043701172
INFO:root:current mean train loss 2007.8377950676966
INFO:root:current train perplexity4.847066402435303
INFO:root:current mean train loss 2009.49329153814
INFO:root:current train perplexity4.857466697692871
INFO:root:current mean train loss 2004.4216126058702
INFO:root:current train perplexity4.846400260925293
INFO:root:current mean train loss 2000.7809765756613
INFO:root:current train perplexity4.838432788848877
INFO:root:current mean train loss 1999.8344169852287
INFO:root:current train perplexity4.836434364318848
INFO:root:current mean train loss 2000.7703390911126
INFO:root:current train perplexity4.841445446014404
INFO:root:current mean train loss 1999.3582877307388
INFO:root:current train perplexity4.836570739746094
INFO:root:current mean train loss 1999.1730105104464
INFO:root:current train perplexity4.838834762573242
INFO:root:current mean train loss 2001.228299987105
INFO:root:current train perplexity4.844135284423828
INFO:root:current mean train loss 2001.1837170028118
INFO:root:current train perplexity4.843118667602539
INFO:root:current mean train loss 2003.7670540353297
INFO:root:current train perplexity4.850855350494385
INFO:root:current mean train loss 2003.464245193818
INFO:root:current train perplexity4.8499979972839355
INFO:root:current mean train loss 2004.220075377303
INFO:root:current train perplexity4.853816509246826
INFO:root:current mean train loss 2002.9800244056535
INFO:root:current train perplexity4.853021621704102
INFO:root:current mean train loss 2003.3324317228005
INFO:root:current train perplexity4.852532386779785
INFO:root:current mean train loss 2003.1015900318212
INFO:root:current train perplexity4.853084564208984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.10s/it]
INFO:root:final mean train loss: 2003.0924521334173
INFO:root:final train perplexity: 4.853786945343018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 1988.4259647883423
INFO:root:eval perplexity: 4.9934258460998535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 2452.2804816496287
INFO:root:eval perplexity: 7.430121898651123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:45:14<2:08:06, 384.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.6903365830244
INFO:root:current train perplexity4.8570404052734375
INFO:root:current mean train loss 2012.5887604719437
INFO:root:current train perplexity4.866715908050537
INFO:root:current mean train loss 2008.2289525330298
INFO:root:current train perplexity4.856261730194092
INFO:root:current mean train loss 2003.9156378530859
INFO:root:current train perplexity4.8571319580078125
INFO:root:current mean train loss 2004.988304919407
INFO:root:current train perplexity4.8535051345825195
INFO:root:current mean train loss 2011.7860699211762
INFO:root:current train perplexity4.873592376708984
INFO:root:current mean train loss 2013.4762451912818
INFO:root:current train perplexity4.865650653839111
INFO:root:current mean train loss 2014.4318283141365
INFO:root:current train perplexity4.868037223815918
INFO:root:current mean train loss 2010.9658981873908
INFO:root:current train perplexity4.86378288269043
INFO:root:current mean train loss 2012.0626381087477
INFO:root:current train perplexity4.870643615722656
INFO:root:current mean train loss 2010.3313870092288
INFO:root:current train perplexity4.867053031921387
INFO:root:current mean train loss 2009.4253304640315
INFO:root:current train perplexity4.864847660064697
INFO:root:current mean train loss 2007.586953136635
INFO:root:current train perplexity4.864015579223633
INFO:root:current mean train loss 2005.587305154583
INFO:root:current train perplexity4.859554290771484
INFO:root:current mean train loss 2004.6235596707131
INFO:root:current train perplexity4.858816623687744
INFO:root:current mean train loss 2003.7176548907053
INFO:root:current train perplexity4.85777473449707
INFO:root:current mean train loss 2004.1178361870857
INFO:root:current train perplexity4.858555316925049
INFO:root:current mean train loss 2004.8897930620203
INFO:root:current train perplexity4.857297420501709
INFO:root:current mean train loss 2003.8151300603693
INFO:root:current train perplexity4.855422496795654
INFO:root:current mean train loss 2004.1614658731535
INFO:root:current train perplexity4.854979038238525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.87s/it]
INFO:root:final mean train loss: 2003.1781837205604
INFO:root:final train perplexity: 4.854115009307861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 1990.2100336602393
INFO:root:eval perplexity: 5.000635147094727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 2453.6937160627217
INFO:root:eval perplexity: 7.438714981079102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:51:31<2:01:02, 382.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1979.7965650056537
INFO:root:current train perplexity4.840803146362305
INFO:root:current mean train loss 1979.8314021717417
INFO:root:current train perplexity4.836675643920898
INFO:root:current mean train loss 1992.3447071020155
INFO:root:current train perplexity4.865137100219727
INFO:root:current mean train loss 1994.6322924025515
INFO:root:current train perplexity4.8603925704956055
INFO:root:current mean train loss 1995.129359910468
INFO:root:current train perplexity4.8575520515441895
INFO:root:current mean train loss 1996.020700454712
INFO:root:current train perplexity4.852029323577881
INFO:root:current mean train loss 1996.9526787932807
INFO:root:current train perplexity4.857717514038086
INFO:root:current mean train loss 2000.263116738231
INFO:root:current train perplexity4.852893829345703
INFO:root:current mean train loss 2000.7147060725242
INFO:root:current train perplexity4.85045862197876
INFO:root:current mean train loss 2001.987172111136
INFO:root:current train perplexity4.852807998657227
INFO:root:current mean train loss 2002.598032330935
INFO:root:current train perplexity4.852261066436768
INFO:root:current mean train loss 2003.8739286669258
INFO:root:current train perplexity4.8546319007873535
INFO:root:current mean train loss 2003.7711385410034
INFO:root:current train perplexity4.8548583984375
INFO:root:current mean train loss 2004.1291545601778
INFO:root:current train perplexity4.854455471038818
INFO:root:current mean train loss 2004.2349990803375
INFO:root:current train perplexity4.852252006530762
INFO:root:current mean train loss 2004.2260380468997
INFO:root:current train perplexity4.85340690612793
INFO:root:current mean train loss 2003.1209137035726
INFO:root:current train perplexity4.851437091827393
INFO:root:current mean train loss 2003.1403201678852
INFO:root:current train perplexity4.852828025817871
INFO:root:current mean train loss 2002.5463267897746
INFO:root:current train perplexity4.850704669952393
INFO:root:current mean train loss 2003.1308720391771
INFO:root:current train perplexity4.852047443389893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.71s/it]
INFO:root:final mean train loss: 2002.483934857421
INFO:root:final train perplexity: 4.8514580726623535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 1985.4522847926362
INFO:root:eval perplexity: 4.981431484222412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 2449.8649781139184
INFO:root:eval perplexity: 7.415459632873535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:58:01<1:55:24, 384.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2003.6283641528057
INFO:root:current train perplexity4.9093017578125
INFO:root:current mean train loss 2004.1042961160135
INFO:root:current train perplexity4.896086692810059
INFO:root:current mean train loss 2002.318766831538
INFO:root:current train perplexity4.883217811584473
INFO:root:current mean train loss 2003.952933663327
INFO:root:current train perplexity4.871324062347412
INFO:root:current mean train loss 1995.6891270264166
INFO:root:current train perplexity4.8555169105529785
INFO:root:current mean train loss 1995.5727384673403
INFO:root:current train perplexity4.8471784591674805
INFO:root:current mean train loss 1997.779607070989
INFO:root:current train perplexity4.848124027252197
INFO:root:current mean train loss 2000.9462113254158
INFO:root:current train perplexity4.8517985343933105
INFO:root:current mean train loss 2000.8452181244752
INFO:root:current train perplexity4.849052429199219
INFO:root:current mean train loss 2001.5487176101853
INFO:root:current train perplexity4.847009181976318
INFO:root:current mean train loss 2002.4595095118796
INFO:root:current train perplexity4.848484992980957
INFO:root:current mean train loss 2000.7927804772632
INFO:root:current train perplexity4.845679759979248
INFO:root:current mean train loss 2001.5458617125569
INFO:root:current train perplexity4.8508758544921875
INFO:root:current mean train loss 2002.182851688689
INFO:root:current train perplexity4.853641986846924
INFO:root:current mean train loss 2003.497273981052
INFO:root:current train perplexity4.857522964477539
INFO:root:current mean train loss 2005.1292142993761
INFO:root:current train perplexity4.860076427459717
INFO:root:current mean train loss 2004.4710546990366
INFO:root:current train perplexity4.856931209564209
INFO:root:current mean train loss 2005.2639664640922
INFO:root:current train perplexity4.8580145835876465
INFO:root:current mean train loss 2004.5999208380795
INFO:root:current train perplexity4.857911586761475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.60s/it]
INFO:root:final mean train loss: 2003.80193470057
INFO:root:final train perplexity: 4.856503486633301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it]
INFO:root:eval mean loss: 1983.8408757203015
INFO:root:eval perplexity: 4.974943161010742
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 2448.1563196926254
INFO:root:eval perplexity: 7.4051032066345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [9:04:22<1:48:39, 383.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2063.7903442382812
INFO:root:current train perplexity5.030359745025635
INFO:root:current mean train loss 1993.950948819247
INFO:root:current train perplexity4.843787670135498
INFO:root:current mean train loss 1988.131703985305
INFO:root:current train perplexity4.822612762451172
INFO:root:current mean train loss 1997.1013600995464
INFO:root:current train perplexity4.854218006134033
INFO:root:current mean train loss 1999.9584160037157
INFO:root:current train perplexity4.853959083557129
INFO:root:current mean train loss 1998.43638604856
INFO:root:current train perplexity4.852115154266357
INFO:root:current mean train loss 2006.324939164959
INFO:root:current train perplexity4.869502067565918
INFO:root:current mean train loss 2007.170721693442
INFO:root:current train perplexity4.870272159576416
INFO:root:current mean train loss 2008.0770251615547
INFO:root:current train perplexity4.871675968170166
INFO:root:current mean train loss 2005.2182720477765
INFO:root:current train perplexity4.8653106689453125
INFO:root:current mean train loss 2005.2256373037205
INFO:root:current train perplexity4.865811347961426
INFO:root:current mean train loss 2007.7363546285544
INFO:root:current train perplexity4.872304916381836
INFO:root:current mean train loss 2006.8951408953706
INFO:root:current train perplexity4.871047019958496
INFO:root:current mean train loss 2007.6395483584804
INFO:root:current train perplexity4.872064590454102
INFO:root:current mean train loss 2007.6505826476618
INFO:root:current train perplexity4.872295379638672
INFO:root:current mean train loss 2007.4719843782336
INFO:root:current train perplexity4.8718719482421875
INFO:root:current mean train loss 2007.460927870851
INFO:root:current train perplexity4.873739719390869
INFO:root:current mean train loss 2007.9273343270286
INFO:root:current train perplexity4.873526573181152
INFO:root:current mean train loss 2008.639672649236
INFO:root:current train perplexity4.874154567718506
INFO:root:current mean train loss 2008.9805537518407
INFO:root:current train perplexity4.872378826141357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.26s/it]
INFO:root:final mean train loss: 2008.8007231388679
INFO:root:final train perplexity: 4.875687122344971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 1978.1036329337046
INFO:root:eval perplexity: 4.951913833618164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it]
INFO:root:eval mean loss: 2440.1515728023883
INFO:root:eval perplexity: 7.356784820556641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [9:10:47<1:42:22, 383.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.1662055121528
INFO:root:current train perplexity4.866090297698975
INFO:root:current mean train loss 1982.721461498831
INFO:root:current train perplexity4.817249774932861
INFO:root:current mean train loss 2001.4174616473363
INFO:root:current train perplexity4.850196838378906
INFO:root:current mean train loss 1996.4527520695958
INFO:root:current train perplexity4.8558454513549805
INFO:root:current mean train loss 1997.8323145560414
INFO:root:current train perplexity4.860781192779541
INFO:root:current mean train loss 1999.4343319626869
INFO:root:current train perplexity4.864742755889893
INFO:root:current mean train loss 2001.4722178092604
INFO:root:current train perplexity4.8698625564575195
INFO:root:current mean train loss 2005.9101191419684
INFO:root:current train perplexity4.873833656311035
INFO:root:current mean train loss 2008.7096370895367
INFO:root:current train perplexity4.882846832275391
INFO:root:current mean train loss 2007.6085893781183
INFO:root:current train perplexity4.882619857788086
INFO:root:current mean train loss 2006.4052414638738
INFO:root:current train perplexity4.873816013336182
INFO:root:current mean train loss 2005.2390618717766
INFO:root:current train perplexity4.872042179107666
INFO:root:current mean train loss 2005.0317040577884
INFO:root:current train perplexity4.871572494506836
INFO:root:current mean train loss 2005.3832552463557
INFO:root:current train perplexity4.871795654296875
INFO:root:current mean train loss 2005.1596069763655
INFO:root:current train perplexity4.869717597961426
INFO:root:current mean train loss 2006.8121460200762
INFO:root:current train perplexity4.870870113372803
INFO:root:current mean train loss 2006.08927518895
INFO:root:current train perplexity4.870044231414795
INFO:root:current mean train loss 2006.197301885608
INFO:root:current train perplexity4.86824369430542
INFO:root:current mean train loss 2005.7779834331811
INFO:root:current train perplexity4.866833686828613
INFO:root:current mean train loss 2004.9204879467761
INFO:root:current train perplexity4.864477634429932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.64s/it]
INFO:root:final mean train loss: 2005.4584298261295
INFO:root:final train perplexity: 4.862852096557617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it]
INFO:root:eval mean loss: 1971.0510500644116
INFO:root:eval perplexity: 4.9237494468688965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.21s/it]
INFO:root:eval mean loss: 2434.4598782586713
INFO:root:eval perplexity: 7.3226213455200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [9:17:01<1:35:15, 381.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.2576793323863
INFO:root:current train perplexity4.78781795501709
INFO:root:current mean train loss 1971.2159745958115
INFO:root:current train perplexity4.792562961578369
INFO:root:current mean train loss 1974.6100969158235
INFO:root:current train perplexity4.791238784790039
INFO:root:current mean train loss 1977.9995574951172
INFO:root:current train perplexity4.789602756500244
INFO:root:current mean train loss 1982.5196439725858
INFO:root:current train perplexity4.794216156005859
INFO:root:current mean train loss 1987.9531552931842
INFO:root:current train perplexity4.806083679199219
INFO:root:current mean train loss 1985.9187525399723
INFO:root:current train perplexity4.796871662139893
INFO:root:current mean train loss 1985.097906461326
INFO:root:current train perplexity4.794328689575195
INFO:root:current mean train loss 1985.669456156509
INFO:root:current train perplexity4.791562080383301
INFO:root:current mean train loss 1984.4382320339396
INFO:root:current train perplexity4.788372039794922
INFO:root:current mean train loss 1988.0331660595891
INFO:root:current train perplexity4.793648719787598
INFO:root:current mean train loss 1985.6285496424962
INFO:root:current train perplexity4.787939548492432
INFO:root:current mean train loss 1984.5609093571015
INFO:root:current train perplexity4.785566806793213
INFO:root:current mean train loss 1983.9059256599062
INFO:root:current train perplexity4.785041809082031
INFO:root:current mean train loss 1984.2763861236149
INFO:root:current train perplexity4.787232398986816
INFO:root:current mean train loss 1983.4445884585998
INFO:root:current train perplexity4.782378673553467
INFO:root:current mean train loss 1984.2402781094368
INFO:root:current train perplexity4.785165786743164
INFO:root:current mean train loss 1984.685036895472
INFO:root:current train perplexity4.783790111541748
INFO:root:current mean train loss 1985.9007938409834
INFO:root:current train perplexity4.786539077758789
INFO:root:current mean train loss 1985.605665607217
INFO:root:current train perplexity4.785409927368164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.27s/it]
INFO:root:final mean train loss: 1984.4886288702999
INFO:root:final train perplexity: 4.7830915451049805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it]
INFO:root:eval mean loss: 1957.9804955881539
INFO:root:eval perplexity: 4.871976375579834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it]
INFO:root:eval mean loss: 2421.2803522204676
INFO:root:eval perplexity: 7.244115352630615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [9:23:32<1:29:34, 383.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1997.2745561443392
INFO:root:current train perplexity4.793184757232666
INFO:root:current mean train loss 1975.2252098699535
INFO:root:current train perplexity4.725383281707764
INFO:root:current mean train loss 1969.8765527717912
INFO:root:current train perplexity4.723764896392822
INFO:root:current mean train loss 1969.393701104246
INFO:root:current train perplexity4.728786945343018
INFO:root:current mean train loss 1967.977678874051
INFO:root:current train perplexity4.723089694976807
INFO:root:current mean train loss 1966.9505869819518
INFO:root:current train perplexity4.715641021728516
INFO:root:current mean train loss 1967.8485960621335
INFO:root:current train perplexity4.7174859046936035
INFO:root:current mean train loss 1969.8940192284
INFO:root:current train perplexity4.722625255584717
INFO:root:current mean train loss 1970.4009449745029
INFO:root:current train perplexity4.725165843963623
INFO:root:current mean train loss 1971.8132537619504
INFO:root:current train perplexity4.7281389236450195
INFO:root:current mean train loss 1972.557386047766
INFO:root:current train perplexity4.730478286743164
INFO:root:current mean train loss 1970.8556181573333
INFO:root:current train perplexity4.729218482971191
INFO:root:current mean train loss 1972.0166530624256
INFO:root:current train perplexity4.730823993682861
INFO:root:current mean train loss 1970.0211688398351
INFO:root:current train perplexity4.727996349334717
INFO:root:current mean train loss 1969.6646323285636
INFO:root:current train perplexity4.725211143493652
INFO:root:current mean train loss 1970.200019675138
INFO:root:current train perplexity4.726330280303955
INFO:root:current mean train loss 1969.4827783849855
INFO:root:current train perplexity4.725106716156006
INFO:root:current mean train loss 1969.5898774389107
INFO:root:current train perplexity4.725118637084961
INFO:root:current mean train loss 1969.0105161508009
INFO:root:current train perplexity4.723690509796143
INFO:root:current mean train loss 1968.9774110785313
INFO:root:current train perplexity4.724483013153076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.43s/it]
INFO:root:final mean train loss: 1969.1808493225128
INFO:root:final train perplexity: 4.72569465637207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 1956.164604890431
INFO:root:eval perplexity: 4.864826679229736
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 2418.380650729998
INFO:root:eval perplexity: 7.226956844329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [9:29:50<1:22:46, 382.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2037.38916798127
INFO:root:current train perplexity4.973047733306885
INFO:root:current mean train loss 2040.3990821409761
INFO:root:current train perplexity4.969763278961182
INFO:root:current mean train loss 2023.9165508901472
INFO:root:current train perplexity4.911721706390381
INFO:root:current mean train loss 2021.1064808356068
INFO:root:current train perplexity4.897404670715332
INFO:root:current mean train loss 2020.2226028761604
INFO:root:current train perplexity4.903804779052734
INFO:root:current mean train loss 2018.2695348403033
INFO:root:current train perplexity4.898509979248047
INFO:root:current mean train loss 2018.2612695384519
INFO:root:current train perplexity4.905381679534912
INFO:root:current mean train loss 2027.3673194551836
INFO:root:current train perplexity4.938844203948975
INFO:root:current mean train loss 2035.0912818995587
INFO:root:current train perplexity4.969874858856201
INFO:root:current mean train loss 2040.0367864753084
INFO:root:current train perplexity4.984378814697266
INFO:root:current mean train loss 2041.2467205210387
INFO:root:current train perplexity4.99202823638916
INFO:root:current mean train loss 2039.0538311425616
INFO:root:current train perplexity4.986382961273193
INFO:root:current mean train loss 2040.1072478436156
INFO:root:current train perplexity4.986419677734375
INFO:root:current mean train loss 2039.0570900173768
INFO:root:current train perplexity4.985128402709961
INFO:root:current mean train loss 2037.5483306760877
INFO:root:current train perplexity4.978181838989258
INFO:root:current mean train loss 2035.0773275977306
INFO:root:current train perplexity4.971079349517822
INFO:root:current mean train loss 2032.532761111163
INFO:root:current train perplexity4.962961196899414
INFO:root:current mean train loss 2032.1951244513016
INFO:root:current train perplexity4.96239709854126
INFO:root:current mean train loss 2032.2302836295262
INFO:root:current train perplexity4.96327018737793
INFO:root:current mean train loss 2030.9274650550587
INFO:root:current train perplexity4.959525108337402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.02s/it]
INFO:root:final mean train loss: 2030.3336729202617
INFO:root:final train perplexity: 4.959194183349609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 1970.4898530134917
INFO:root:eval perplexity: 4.921515464782715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it]
INFO:root:eval mean loss: 2429.8862573069036
INFO:root:eval perplexity: 7.295281887054443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:36:06<1:16:04, 380.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2002.539558490954
INFO:root:current train perplexity4.844207286834717
INFO:root:current mean train loss 2001.1509596604567
INFO:root:current train perplexity4.855872631072998
INFO:root:current mean train loss 2002.750634765625
INFO:root:current train perplexity4.86386251449585
INFO:root:current mean train loss 2002.8624545713014
INFO:root:current train perplexity4.866039752960205
INFO:root:current mean train loss 2006.3663803562974
INFO:root:current train perplexity4.883218765258789
INFO:root:current mean train loss 2007.6406805984113
INFO:root:current train perplexity4.886002063751221
INFO:root:current mean train loss 2009.5411043235724
INFO:root:current train perplexity4.89162540435791
INFO:root:current mean train loss 2009.3336319833431
INFO:root:current train perplexity4.896125316619873
INFO:root:current mean train loss 2011.1898556160527
INFO:root:current train perplexity4.901717185974121
INFO:root:current mean train loss 2015.8600246103565
INFO:root:current train perplexity4.910336971282959
INFO:root:current mean train loss 2017.489806404288
INFO:root:current train perplexity4.912973403930664
INFO:root:current mean train loss 2017.4880044210904
INFO:root:current train perplexity4.913392543792725
INFO:root:current mean train loss 2017.949882171513
INFO:root:current train perplexity4.911378383636475
INFO:root:current mean train loss 2018.2164501778113
INFO:root:current train perplexity4.910683631896973
INFO:root:current mean train loss 2017.9009333683894
INFO:root:current train perplexity4.909515857696533
INFO:root:current mean train loss 2016.707007907401
INFO:root:current train perplexity4.904788494110107
INFO:root:current mean train loss 2016.9665227749356
INFO:root:current train perplexity4.9049506187438965
INFO:root:current mean train loss 2015.0980499352586
INFO:root:current train perplexity4.900681018829346
INFO:root:current mean train loss 2014.6949312798895
INFO:root:current train perplexity4.897988796234131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.13s/it]
INFO:root:final mean train loss: 2014.5710817030206
INFO:root:final train perplexity: 4.897926330566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.19s/it]
INFO:root:eval mean loss: 1967.9518649053912
INFO:root:eval perplexity: 4.911424160003662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it]
INFO:root:eval mean loss: 2428.5302526595747
INFO:root:eval perplexity: 7.287194728851318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:42:20<1:09:24, 378.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2093.9464518229165
INFO:root:current train perplexity5.203991889953613
INFO:root:current mean train loss 2034.663699558803
INFO:root:current train perplexity4.95016622543335
INFO:root:current mean train loss 2020.173885705336
INFO:root:current train perplexity4.894866466522217
INFO:root:current mean train loss 2016.751239874424
INFO:root:current train perplexity4.886144638061523
INFO:root:current mean train loss 2009.6158094683897
INFO:root:current train perplexity4.867823123931885
INFO:root:current mean train loss 2004.203570842743
INFO:root:current train perplexity4.860743999481201
INFO:root:current mean train loss 2001.5910818062578
INFO:root:current train perplexity4.846541404724121
INFO:root:current mean train loss 2001.7864263298807
INFO:root:current train perplexity4.842846393585205
INFO:root:current mean train loss 2003.1981948326375
INFO:root:current train perplexity4.847352027893066
INFO:root:current mean train loss 2003.3044938204582
INFO:root:current train perplexity4.84636116027832
INFO:root:current mean train loss 2003.293407093395
INFO:root:current train perplexity4.844907283782959
INFO:root:current mean train loss 2002.699080103593
INFO:root:current train perplexity4.8406829833984375
INFO:root:current mean train loss 2002.489318545502
INFO:root:current train perplexity4.840203762054443
INFO:root:current mean train loss 2001.9542625241163
INFO:root:current train perplexity4.838698387145996
INFO:root:current mean train loss 2001.622273301943
INFO:root:current train perplexity4.837652206420898
INFO:root:current mean train loss 2000.1585465688554
INFO:root:current train perplexity4.832311153411865
INFO:root:current mean train loss 1997.4080275164054
INFO:root:current train perplexity4.8249030113220215
INFO:root:current mean train loss 1996.7666438450324
INFO:root:current train perplexity4.824887275695801
INFO:root:current mean train loss 1997.2193676272766
INFO:root:current train perplexity4.824781894683838
INFO:root:current mean train loss 1995.9652660162378
INFO:root:current train perplexity4.82320499420166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.22s/it]
INFO:root:final mean train loss: 1994.6034652394474
INFO:root:final train perplexity: 4.821399211883545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it]
INFO:root:eval mean loss: 1956.0651232130983
INFO:root:eval perplexity: 4.864434242248535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 2418.593288989777
INFO:root:eval perplexity: 7.228214740753174
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:48:35<1:02:53, 377.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1973.9876624797953
INFO:root:current train perplexity4.821434020996094
INFO:root:current mean train loss 1980.6383983996488
INFO:root:current train perplexity4.766839027404785
INFO:root:current mean train loss 1983.5616503053357
INFO:root:current train perplexity4.772368907928467
INFO:root:current mean train loss 1977.1811623616784
INFO:root:current train perplexity4.762107849121094
INFO:root:current mean train loss 1976.4873533448972
INFO:root:current train perplexity4.747312545776367
INFO:root:current mean train loss 1974.4178716014148
INFO:root:current train perplexity4.743335247039795
INFO:root:current mean train loss 1978.8489831096606
INFO:root:current train perplexity4.7569708824157715
INFO:root:current mean train loss 1983.675465776106
INFO:root:current train perplexity4.781623840332031
INFO:root:current mean train loss 1986.8595702536
INFO:root:current train perplexity4.794357776641846
INFO:root:current mean train loss 1989.4310477495962
INFO:root:current train perplexity4.805723190307617
INFO:root:current mean train loss 1992.7906237899736
INFO:root:current train perplexity4.818763732910156
INFO:root:current mean train loss 1995.3489560988014
INFO:root:current train perplexity4.835378646850586
INFO:root:current mean train loss 2000.4229336048743
INFO:root:current train perplexity4.8484930992126465
INFO:root:current mean train loss 2003.2250993095724
INFO:root:current train perplexity4.856555461883545
INFO:root:current mean train loss 2004.9660222538707
INFO:root:current train perplexity4.86115837097168
INFO:root:current mean train loss 2004.3785495396296
INFO:root:current train perplexity4.861119747161865
INFO:root:current mean train loss 2006.0218438417214
INFO:root:current train perplexity4.866081237792969
INFO:root:current mean train loss 2006.4972752691901
INFO:root:current train perplexity4.865443229675293
INFO:root:current mean train loss 2006.988343386392
INFO:root:current train perplexity4.867205619812012
INFO:root:current mean train loss 2007.0923867233064
INFO:root:current train perplexity4.8674702644348145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.41s/it]
INFO:root:final mean train loss: 2006.4512710455867
INFO:root:final train perplexity: 4.866661548614502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.26s/it]
INFO:root:eval mean loss: 1965.9752677755152
INFO:root:eval perplexity: 4.903578758239746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 2426.884601565963
INFO:root:eval perplexity: 7.277393817901611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:54:52<56:35, 377.25s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.9119076936142
INFO:root:current train perplexity4.857783317565918
INFO:root:current mean train loss 2015.6412161213077
INFO:root:current train perplexity4.910585880279541
INFO:root:current mean train loss 2019.9349707626716
INFO:root:current train perplexity4.8949408531188965
INFO:root:current mean train loss 2015.7406774972906
INFO:root:current train perplexity4.893011569976807
INFO:root:current mean train loss 2019.1355941156635
INFO:root:current train perplexity4.900968074798584
INFO:root:current mean train loss 2020.1807083297563
INFO:root:current train perplexity4.905091285705566
INFO:root:current mean train loss 2019.2741185238488
INFO:root:current train perplexity4.8913397789001465
INFO:root:current mean train loss 2019.4648810583528
INFO:root:current train perplexity4.89401388168335
INFO:root:current mean train loss 2017.927872317339
INFO:root:current train perplexity4.8896918296813965
INFO:root:current mean train loss 2015.907803235044
INFO:root:current train perplexity4.880804538726807
INFO:root:current mean train loss 2013.7330747060976
INFO:root:current train perplexity4.8765974044799805
INFO:root:current mean train loss 2012.3935756716637
INFO:root:current train perplexity4.8740339279174805
INFO:root:current mean train loss 2010.5044809405724
INFO:root:current train perplexity4.865470886230469
INFO:root:current mean train loss 2008.8752216492153
INFO:root:current train perplexity4.863315105438232
INFO:root:current mean train loss 2008.4558313140235
INFO:root:current train perplexity4.862193584442139
INFO:root:current mean train loss 2006.004542342133
INFO:root:current train perplexity4.855622291564941
INFO:root:current mean train loss 2005.1250225451854
INFO:root:current train perplexity4.856062889099121
INFO:root:current mean train loss 2004.3708935155355
INFO:root:current train perplexity4.853926658630371
INFO:root:current mean train loss 2003.8528689036261
INFO:root:current train perplexity4.851765155792236
INFO:root:current mean train loss 2003.3779445542339
INFO:root:current train perplexity4.8525614738464355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.67s/it]
INFO:root:final mean train loss: 2002.528628504643
INFO:root:final train perplexity: 4.851629257202148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 1966.4616945956616
INFO:root:eval perplexity: 4.905508518218994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it]
INFO:root:eval mean loss: 2428.408661537982
INFO:root:eval perplexity: 7.286471366882324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [10:01:30<51:08, 383.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2002.2468087332588
INFO:root:current train perplexity4.814640522003174
INFO:root:current mean train loss 2003.6052470763036
INFO:root:current train perplexity4.803371906280518
INFO:root:current mean train loss 2004.986537918845
INFO:root:current train perplexity4.824839115142822
INFO:root:current mean train loss 2003.5428174231663
INFO:root:current train perplexity4.832075595855713
INFO:root:current mean train loss 2003.539620121406
INFO:root:current train perplexity4.838767051696777
INFO:root:current mean train loss 2003.4268022608376
INFO:root:current train perplexity4.840341091156006
INFO:root:current mean train loss 2003.5505577306042
INFO:root:current train perplexity4.8429765701293945
INFO:root:current mean train loss 2006.1392379100794
INFO:root:current train perplexity4.846938133239746
INFO:root:current mean train loss 2005.8727464377534
INFO:root:current train perplexity4.846192836761475
INFO:root:current mean train loss 2001.922017225224
INFO:root:current train perplexity4.841862201690674
INFO:root:current mean train loss 2001.870220539599
INFO:root:current train perplexity4.843112945556641
INFO:root:current mean train loss 1999.7636090030162
INFO:root:current train perplexity4.840645790100098
INFO:root:current mean train loss 1998.7431497581404
INFO:root:current train perplexity4.837466716766357
INFO:root:current mean train loss 1998.4121590808131
INFO:root:current train perplexity4.83658504486084
INFO:root:current mean train loss 1998.5470145923668
INFO:root:current train perplexity4.834463596343994
INFO:root:current mean train loss 1999.4128449989753
INFO:root:current train perplexity4.8386759757995605
INFO:root:current mean train loss 1997.7878979506868
INFO:root:current train perplexity4.834316253662109
INFO:root:current mean train loss 1998.0522303762452
INFO:root:current train perplexity4.833529472351074
INFO:root:current mean train loss 1998.1505626242326
INFO:root:current train perplexity4.834283828735352
INFO:root:current mean train loss 1998.602083366499
INFO:root:current train perplexity4.835808753967285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.71s/it]
INFO:root:final mean train loss: 1998.321569584141
INFO:root:final train perplexity: 4.83555793762207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.01s/it]
INFO:root:eval mean loss: 1962.598943615636
INFO:root:eval perplexity: 4.890207290649414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.12s/it]
INFO:root:eval mean loss: 2424.7122599283853
INFO:root:eval perplexity: 7.264477252960205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [10:07:42<44:19, 379.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1964.5859176635743
INFO:root:current train perplexity4.6967573165893555
INFO:root:current mean train loss 1984.1901740180122
INFO:root:current train perplexity4.7666192054748535
INFO:root:current mean train loss 1992.226961844308
INFO:root:current train perplexity4.811807155609131
INFO:root:current mean train loss 1997.6302307128906
INFO:root:current train perplexity4.823160648345947
INFO:root:current mean train loss 1999.3742980957031
INFO:root:current train perplexity4.827261447906494
INFO:root:current mean train loss 1999.7896404397898
INFO:root:current train perplexity4.829001426696777
INFO:root:current mean train loss 1997.6424614401424
INFO:root:current train perplexity4.815624713897705
INFO:root:current mean train loss 1997.1567193447015
INFO:root:current train perplexity4.814701557159424
INFO:root:current mean train loss 1996.3972283103249
INFO:root:current train perplexity4.81361722946167
INFO:root:current mean train loss 1995.9389011928013
INFO:root:current train perplexity4.814553260803223
INFO:root:current mean train loss 1995.6390969735605
INFO:root:current train perplexity4.815264701843262
INFO:root:current mean train loss 1997.0408964512712
INFO:root:current train perplexity4.823216915130615
INFO:root:current mean train loss 1997.972779083252
INFO:root:current train perplexity4.824264049530029
INFO:root:current mean train loss 1998.110639931499
INFO:root:current train perplexity4.826393127441406
INFO:root:current mean train loss 2000.885087956609
INFO:root:current train perplexity4.831132888793945
INFO:root:current mean train loss 2001.238798040076
INFO:root:current train perplexity4.833262920379639
INFO:root:current mean train loss 2000.5527393159412
INFO:root:current train perplexity4.834231376647949
INFO:root:current mean train loss 2000.9679972102133
INFO:root:current train perplexity4.840056419372559
INFO:root:current mean train loss 2001.3331184549534
INFO:root:current train perplexity4.840602874755859
INFO:root:current mean train loss 1999.959498118391
INFO:root:current train perplexity4.839279651641846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.63s/it]
INFO:root:final mean train loss: 1999.1787214024284
INFO:root:final train perplexity: 4.838828086853027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it]
INFO:root:eval mean loss: 1962.0780133186502
INFO:root:eval perplexity: 4.888147830963135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it]
INFO:root:eval mean loss: 2423.274585047512
INFO:root:eval perplexity: 7.255940914154053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [10:14:12<38:18, 383.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2011.1038151377254
INFO:root:current train perplexity4.8917694091796875
INFO:root:current mean train loss 2007.5061958429171
INFO:root:current train perplexity4.859711647033691
INFO:root:current mean train loss 2001.8087244515468
INFO:root:current train perplexity4.8681111335754395
INFO:root:current mean train loss 1998.2679861534752
INFO:root:current train perplexity4.851451396942139
INFO:root:current mean train loss 1998.260728678713
INFO:root:current train perplexity4.843974590301514
INFO:root:current mean train loss 2001.9182173890285
INFO:root:current train perplexity4.85197639465332
INFO:root:current mean train loss 2001.975361061917
INFO:root:current train perplexity4.849238872528076
INFO:root:current mean train loss 2003.2852770950144
INFO:root:current train perplexity4.85493278503418
INFO:root:current mean train loss 2001.80916232276
INFO:root:current train perplexity4.847127914428711
INFO:root:current mean train loss 1999.113819485801
INFO:root:current train perplexity4.841560363769531
INFO:root:current mean train loss 1999.036458296241
INFO:root:current train perplexity4.8388495445251465
INFO:root:current mean train loss 1999.4767322970513
INFO:root:current train perplexity4.839774131774902
INFO:root:current mean train loss 2000.4060408710607
INFO:root:current train perplexity4.841792106628418
INFO:root:current mean train loss 2000.352634569194
INFO:root:current train perplexity4.8414812088012695
INFO:root:current mean train loss 2000.8515459467112
INFO:root:current train perplexity4.842073440551758
INFO:root:current mean train loss 2000.180459134192
INFO:root:current train perplexity4.8413519859313965
INFO:root:current mean train loss 2000.1273006333558
INFO:root:current train perplexity4.843936443328857
INFO:root:current mean train loss 2001.2847438466238
INFO:root:current train perplexity4.845961570739746
INFO:root:current mean train loss 2001.758609335361
INFO:root:current train perplexity4.845870018005371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.18s/it]
INFO:root:final mean train loss: 2001.7830608943107
INFO:root:final train perplexity: 4.8487772941589355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 1968.0082349844859
INFO:root:eval perplexity: 4.911647319793701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it]
INFO:root:eval mean loss: 2429.131352850731
INFO:root:eval perplexity: 7.290778160095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:20:38<32:00, 384.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.3115757533483
INFO:root:current train perplexity4.805048942565918
INFO:root:current mean train loss 1982.264514588473
INFO:root:current train perplexity4.808071613311768
INFO:root:current mean train loss 1990.6814438294027
INFO:root:current train perplexity4.825540542602539
INFO:root:current mean train loss 1995.126646394183
INFO:root:current train perplexity4.8340067863464355
INFO:root:current mean train loss 1992.913795950332
INFO:root:current train perplexity4.834660530090332
INFO:root:current mean train loss 1994.0612887965103
INFO:root:current train perplexity4.835169315338135
INFO:root:current mean train loss 1995.1083016162586
INFO:root:current train perplexity4.831823348999023
INFO:root:current mean train loss 1997.3095133805475
INFO:root:current train perplexity4.836875915527344
INFO:root:current mean train loss 1997.6076964582214
INFO:root:current train perplexity4.836604118347168
INFO:root:current mean train loss 1997.3620584099767
INFO:root:current train perplexity4.837579727172852
INFO:root:current mean train loss 2002.6058840779863
INFO:root:current train perplexity4.847624778747559
INFO:root:current mean train loss 2004.6381534596962
INFO:root:current train perplexity4.854547023773193
INFO:root:current mean train loss 2003.6206850055023
INFO:root:current train perplexity4.85427713394165
INFO:root:current mean train loss 2004.3753043396832
INFO:root:current train perplexity4.855815410614014
INFO:root:current mean train loss 2002.214329656145
INFO:root:current train perplexity4.851286888122559
INFO:root:current mean train loss 2002.2581402515325
INFO:root:current train perplexity4.852938652038574
INFO:root:current mean train loss 2003.4225725554475
INFO:root:current train perplexity4.854585647583008
INFO:root:current mean train loss 2002.5194125270064
INFO:root:current train perplexity4.85365104675293
INFO:root:current mean train loss 2003.7453445047634
INFO:root:current train perplexity4.855661392211914
INFO:root:current mean train loss 2003.357127924075
INFO:root:current train perplexity4.855077743530273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.97s/it]
INFO:root:final mean train loss: 2003.4998170792064
INFO:root:final train perplexity: 4.8553466796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 1965.4648550047098
INFO:root:eval perplexity: 4.90155553817749
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it]
INFO:root:eval mean loss: 2426.3701712966813
INFO:root:eval perplexity: 7.2743330001831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:27:06<25:40, 385.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1989.042496219758
INFO:root:current train perplexity4.83821964263916
INFO:root:current mean train loss 1997.316737983063
INFO:root:current train perplexity4.856129169464111
INFO:root:current mean train loss 2005.7136420708198
INFO:root:current train perplexity4.859417915344238
INFO:root:current mean train loss 2008.6570071309716
INFO:root:current train perplexity4.864803314208984
INFO:root:current mean train loss 2007.0851373871628
INFO:root:current train perplexity4.866846561431885
INFO:root:current mean train loss 2004.8943356156574
INFO:root:current train perplexity4.859352111816406
INFO:root:current mean train loss 2008.7519034069805
INFO:root:current train perplexity4.8780317306518555
INFO:root:current mean train loss 2008.819368500716
INFO:root:current train perplexity4.874446868896484
INFO:root:current mean train loss 2007.6704108907284
INFO:root:current train perplexity4.867926597595215
INFO:root:current mean train loss 2004.0438615284725
INFO:root:current train perplexity4.860320091247559
INFO:root:current mean train loss 2004.3202505768443
INFO:root:current train perplexity4.859807968139648
INFO:root:current mean train loss 2003.9726997463183
INFO:root:current train perplexity4.859678745269775
INFO:root:current mean train loss 2003.4400737895703
INFO:root:current train perplexity4.856224060058594
INFO:root:current mean train loss 2003.7738447067525
INFO:root:current train perplexity4.855770587921143
INFO:root:current mean train loss 2002.87080687197
INFO:root:current train perplexity4.853841304779053
INFO:root:current mean train loss 2002.2400596813
INFO:root:current train perplexity4.8508687019348145
INFO:root:current mean train loss 2001.0625410144276
INFO:root:current train perplexity4.846735000610352
INFO:root:current mean train loss 1999.807555129802
INFO:root:current train perplexity4.843803882598877
INFO:root:current mean train loss 1999.7007776632263
INFO:root:current train perplexity4.841863632202148
INFO:root:current mean train loss 2000.3804820380267
INFO:root:current train perplexity4.843374252319336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.31s/it]
INFO:root:final mean train loss: 2000.5377489360246
INFO:root:final train perplexity: 4.844017505645752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 1963.9763153292608
INFO:root:eval perplexity: 4.895658493041992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.87s/it]
INFO:root:eval mean loss: 2424.8710837939107
INFO:root:eval perplexity: 7.265420436859131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:33:41<19:23, 387.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1998.8709615071614
INFO:root:current train perplexity4.780871868133545
INFO:root:current mean train loss 1992.2446181838577
INFO:root:current train perplexity4.823671340942383
INFO:root:current mean train loss 1994.1866750409527
INFO:root:current train perplexity4.818185329437256
INFO:root:current mean train loss 1988.6874477342628
INFO:root:current train perplexity4.799497604370117
INFO:root:current mean train loss 1995.6923307691302
INFO:root:current train perplexity4.814620494842529
INFO:root:current mean train loss 1996.8396009459113
INFO:root:current train perplexity4.817558765411377
INFO:root:current mean train loss 2001.4249391909
INFO:root:current train perplexity4.83133602142334
INFO:root:current mean train loss 2001.8645569500438
INFO:root:current train perplexity4.837770462036133
INFO:root:current mean train loss 2002.7064318387013
INFO:root:current train perplexity4.837283134460449
INFO:root:current mean train loss 1999.67555333391
INFO:root:current train perplexity4.831085205078125
INFO:root:current mean train loss 2002.3877872146722
INFO:root:current train perplexity4.834579944610596
INFO:root:current mean train loss 2000.814059373809
INFO:root:current train perplexity4.835379600524902
INFO:root:current mean train loss 2001.3398855160444
INFO:root:current train perplexity4.834249973297119
INFO:root:current mean train loss 2002.434377426917
INFO:root:current train perplexity4.838842868804932
INFO:root:current mean train loss 2001.5882236206728
INFO:root:current train perplexity4.8395514488220215
INFO:root:current mean train loss 2001.2768838571947
INFO:root:current train perplexity4.83930778503418
INFO:root:current mean train loss 2000.0049430328665
INFO:root:current train perplexity4.840035438537598
INFO:root:current mean train loss 1999.7286101107738
INFO:root:current train perplexity4.83887243270874
INFO:root:current mean train loss 2000.2026115516564
INFO:root:current train perplexity4.839800834655762
INFO:root:current mean train loss 2000.0858974574282
INFO:root:current train perplexity4.840857028961182

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.91s/it]
INFO:root:final mean train loss: 1999.5858180766988
INFO:root:final train perplexity: 4.840381622314453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 1961.3186273236647
INFO:root:eval perplexity: 4.8851470947265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.61s/it]
INFO:root:eval mean loss: 2422.283493583084
INFO:root:eval perplexity: 7.250063419342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:40:07<12:55, 387.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1990.2794151893029
INFO:root:current train perplexity4.871185779571533
INFO:root:current mean train loss 2005.6990256569602
INFO:root:current train perplexity4.852427005767822
INFO:root:current mean train loss 2003.2554143941627
INFO:root:current train perplexity4.86587381362915
INFO:root:current mean train loss 2002.5680844659676
INFO:root:current train perplexity4.853539943695068
INFO:root:current mean train loss 2003.38595062584
INFO:root:current train perplexity4.859410762786865
INFO:root:current mean train loss 2006.3223980658877
INFO:root:current train perplexity4.86041259765625
INFO:root:current mean train loss 2004.0788838551457
INFO:root:current train perplexity4.856501579284668
INFO:root:current mean train loss 2003.3100780611724
INFO:root:current train perplexity4.851953029632568
INFO:root:current mean train loss 2003.6982936969382
INFO:root:current train perplexity4.850306034088135
INFO:root:current mean train loss 2004.3666681003076
INFO:root:current train perplexity4.850511074066162
INFO:root:current mean train loss 2002.2291280397228
INFO:root:current train perplexity4.843238353729248
INFO:root:current mean train loss 2000.4737196762674
INFO:root:current train perplexity4.841563701629639
INFO:root:current mean train loss 2001.7470430034894
INFO:root:current train perplexity4.842455863952637
INFO:root:current mean train loss 2001.9590904375573
INFO:root:current train perplexity4.8431010246276855
INFO:root:current mean train loss 2002.9768527190433
INFO:root:current train perplexity4.845545291900635
INFO:root:current mean train loss 2003.6136248408795
INFO:root:current train perplexity4.847068786621094
INFO:root:current mean train loss 2002.9549187370965
INFO:root:current train perplexity4.846576690673828
INFO:root:current mean train loss 2002.0036708929047
INFO:root:current train perplexity4.845785140991211
INFO:root:current mean train loss 2002.86152605563
INFO:root:current train perplexity4.846126556396484
INFO:root:current mean train loss 2001.8772721229923
INFO:root:current train perplexity4.845705986022949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.99s/it]
INFO:root:final mean train loss: 2000.8068273624144
INFO:root:final train perplexity: 4.84504508972168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 1960.6921997070312
INFO:root:eval perplexity: 4.882672309875488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it]
INFO:root:eval mean loss: 2421.575135575964
INFO:root:eval perplexity: 7.245861530303955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:46:32<06:26, 386.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1992.6371445074315
INFO:root:current train perplexity4.880876064300537
INFO:root:current mean train loss 1996.9046422937415
INFO:root:current train perplexity4.861341953277588
INFO:root:current mean train loss 1993.5753299361425
INFO:root:current train perplexity4.853217601776123
INFO:root:current mean train loss 1991.37289348822
INFO:root:current train perplexity4.845743656158447
INFO:root:current mean train loss 1988.2135455499547
INFO:root:current train perplexity4.830284595489502
INFO:root:current mean train loss 1990.7374353572675
INFO:root:current train perplexity4.833059310913086
INFO:root:current mean train loss 1992.2631209476951
INFO:root:current train perplexity4.834392070770264
INFO:root:current mean train loss 1991.3830286986993
INFO:root:current train perplexity4.827032566070557
INFO:root:current mean train loss 1991.915568172256
INFO:root:current train perplexity4.83170747756958
INFO:root:current mean train loss 1993.4347536665844
INFO:root:current train perplexity4.833263874053955
INFO:root:current mean train loss 1995.241542851418
INFO:root:current train perplexity4.835038661956787
INFO:root:current mean train loss 1995.0157769166071
INFO:root:current train perplexity4.8331098556518555
INFO:root:current mean train loss 1996.5787842939499
INFO:root:current train perplexity4.838362216949463
INFO:root:current mean train loss 1997.0148375493227
INFO:root:current train perplexity4.838820934295654
INFO:root:current mean train loss 1997.1487612087235
INFO:root:current train perplexity4.83819580078125
INFO:root:current mean train loss 1998.0427574803946
INFO:root:current train perplexity4.838726043701172
INFO:root:current mean train loss 1997.9274072091446
INFO:root:current train perplexity4.8378520011901855
INFO:root:current mean train loss 1998.4371732461332
INFO:root:current train perplexity4.839325904846191
INFO:root:current mean train loss 1999.5248856093501
INFO:root:current train perplexity4.84140682220459
INFO:root:current mean train loss 2001.0025908222833
INFO:root:current train perplexity4.843868255615234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.55s/it]
INFO:root:final mean train loss: 2000.5613566757872
INFO:root:final train perplexity: 4.844107627868652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 1961.009799389129
INFO:root:eval perplexity: 4.883926868438721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 2421.961454783771
INFO:root:eval perplexity: 7.248152732849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:52:54<00:00, 385.35s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:52:54<00:00, 391.75s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.08s/it]
INFO:root:eval mean loss: 1961.009799389129
INFO:root:eval perplexity: 4.883926868438721
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2421.961454783771
INFO:root:eval perplexity: 7.248152732849121
INFO:root:evalaution complete
INFO:root:save model final: multiqal6_multiqal6_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x1549e2464f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1549e245c8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x1549e2381e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1549e2465a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x1549e237f948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1549e2465a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x1549e233ab46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x1549e1d9f46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x154ade5bba27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x154ade5bbbe0]
python(+0x24a989) [0x5603134d6989]
python(+0x24a9bd) [0x5603134d69bd]
python(+0x24aa14) [0x5603134d6a14]
python(+0x108f75) [0x560313394f75]
python(Py_RunMain+0x313) [0x5603134d9983]
python(Py_BytesMain+0x39) [0x5603134d9bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x154ade5990b3]
python(+0x1d6e13) [0x560313462e13]
/opt/slurm/data/slurmd/job29854441/slurm_script: line 237: 3100233 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected --output multiqal6_multiqal6_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
