INFO:root:Output: multil6_alll12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.weight', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11650.632343947285
INFO:root:current train perplexity10244.9482421875
INFO:root:current mean train loss 9680.97746545226
INFO:root:current train perplexity2137.41650390625
INFO:root:current mean train loss 8522.708107428407
INFO:root:current train perplexity853.9887084960938
INFO:root:current mean train loss 7711.5182181528035
INFO:root:current train perplexity442.46270751953125
INFO:root:current mean train loss 7094.658192850545
INFO:root:current train perplexity271.7718200683594
INFO:root:current mean train loss 6618.306076533806
INFO:root:current train perplexity186.61492919921875
INFO:root:current mean train loss 6242.808354848445
INFO:root:current train perplexity138.39532470703125
INFO:root:current mean train loss 5945.122476093164
INFO:root:current train perplexity108.81981658935547
INFO:root:current mean train loss 5693.356701673734
INFO:root:current train perplexity89.28076171875
INFO:root:current mean train loss 5479.173128206331
INFO:root:current train perplexity75.48860931396484
INFO:root:current mean train loss 5297.178808016165
INFO:root:current train perplexity65.26829528808594
INFO:root:current mean train loss 5138.866131729241
INFO:root:current train perplexity57.60785675048828
INFO:root:current mean train loss 4999.250057511186
INFO:root:current train perplexity51.579254150390625
INFO:root:current mean train loss 4875.580883143372
INFO:root:current train perplexity46.79397201538086
INFO:root:current mean train loss 4764.005124672959
INFO:root:current train perplexity42.880733489990234
INFO:root:current mean train loss 4664.869621577451
INFO:root:current train perplexity39.61737823486328
INFO:root:current mean train loss 4573.879324550977
INFO:root:current train perplexity36.867340087890625
INFO:root:current mean train loss 4492.267791595375
INFO:root:current train perplexity34.55790710449219
INFO:root:current mean train loss 4417.1744787809785
INFO:root:current train perplexity32.560508728027344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.71s/it]
INFO:root:final mean train loss: 4356.762774476606
INFO:root:final train perplexity: 31.062625885009766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.76s/it]
INFO:root:eval mean loss: 2808.457662379488
INFO:root:eval perplexity: 9.692143440246582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 3111.2642350433566
INFO:root:eval perplexity: 12.736571311950684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/1
  1%|          | 1/100 [08:54<14:42:40, 534.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2956.965072631836
INFO:root:current train perplexity10.29961109161377
INFO:root:current mean train loss 3000.9916192416486
INFO:root:current train perplexity10.523466110229492
INFO:root:current mean train loss 2981.268596507885
INFO:root:current train perplexity10.395646095275879
INFO:root:current mean train loss 2966.0361915298654
INFO:root:current train perplexity10.275720596313477
INFO:root:current mean train loss 2945.0132135244517
INFO:root:current train perplexity10.115269660949707
INFO:root:current mean train loss 2930.3481099919754
INFO:root:current train perplexity10.029328346252441
INFO:root:current mean train loss 2918.7979894861
INFO:root:current train perplexity9.951640129089355
INFO:root:current mean train loss 2904.733836935885
INFO:root:current train perplexity9.854484558105469
INFO:root:current mean train loss 2891.4049649706076
INFO:root:current train perplexity9.763784408569336
INFO:root:current mean train loss 2884.7208856974107
INFO:root:current train perplexity9.699142456054688
INFO:root:current mean train loss 2872.1140787920613
INFO:root:current train perplexity9.607257843017578
INFO:root:current mean train loss 2861.374713637923
INFO:root:current train perplexity9.532073974609375
INFO:root:current mean train loss 2851.7689610531456
INFO:root:current train perplexity9.468667984008789
INFO:root:current mean train loss 2843.486082685755
INFO:root:current train perplexity9.40269947052002
INFO:root:current mean train loss 2836.6990330582958
INFO:root:current train perplexity9.342109680175781
INFO:root:current mean train loss 2826.51610410182
INFO:root:current train perplexity9.278014183044434
INFO:root:current mean train loss 2817.7057588785
INFO:root:current train perplexity9.219621658325195
INFO:root:current mean train loss 2809.835858680707
INFO:root:current train perplexity9.155323028564453
INFO:root:current mean train loss 2799.861739372892
INFO:root:current train perplexity9.086548805236816
INFO:root:current mean train loss 2792.5565948804883
INFO:root:current train perplexity9.038573265075684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.25s/it]
INFO:root:final mean train loss: 2786.475796590354
INFO:root:final train perplexity: 9.00322151184082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it]
INFO:root:eval mean loss: 2476.808113260472
INFO:root:eval perplexity: 7.411975860595703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2822.845034768395
INFO:root:eval perplexity: 10.060332298278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/2
  2%|â–         | 2/100 [18:00<14:43:57, 541.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2597.682469223485
INFO:root:current train perplexity7.807841777801514
INFO:root:current mean train loss 2607.4087519824952
INFO:root:current train perplexity7.818644046783447
INFO:root:current mean train loss 2597.5713037318937
INFO:root:current train perplexity7.791224956512451
INFO:root:current mean train loss 2600.1533679675767
INFO:root:current train perplexity7.7615861892700195
INFO:root:current mean train loss 2596.94306223387
INFO:root:current train perplexity7.750001430511475
INFO:root:current mean train loss 2592.413368554321
INFO:root:current train perplexity7.713595867156982
INFO:root:current mean train loss 2586.3904485476523
INFO:root:current train perplexity7.687127590179443
INFO:root:current mean train loss 2584.123852072764
INFO:root:current train perplexity7.662949562072754
INFO:root:current mean train loss 2580.3126578268025
INFO:root:current train perplexity7.639554500579834
INFO:root:current mean train loss 2573.9885443618955
INFO:root:current train perplexity7.606586933135986
INFO:root:current mean train loss 2567.3442747959903
INFO:root:current train perplexity7.574184417724609
INFO:root:current mean train loss 2561.151745465406
INFO:root:current train perplexity7.539228916168213
INFO:root:current mean train loss 2557.3861942337667
INFO:root:current train perplexity7.519363880157471
INFO:root:current mean train loss 2552.9511515452105
INFO:root:current train perplexity7.489675521850586
INFO:root:current mean train loss 2549.3768609546732
INFO:root:current train perplexity7.465726852416992
INFO:root:current mean train loss 2544.1801313486117
INFO:root:current train perplexity7.436333656311035
INFO:root:current mean train loss 2540.571279643725
INFO:root:current train perplexity7.410429954528809
INFO:root:current mean train loss 2537.3887186463144
INFO:root:current train perplexity7.391182899475098
INFO:root:current mean train loss 2534.6606269499284
INFO:root:current train perplexity7.376123428344727
INFO:root:current mean train loss 2531.5012660453312
INFO:root:current train perplexity7.356635570526123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.65s/it]
INFO:root:final mean train loss: 2529.2688146486344
INFO:root:final train perplexity: 7.350244522094727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it]
INFO:root:eval mean loss: 2340.8679008754434
INFO:root:eval perplexity: 6.64029598236084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 2707.2391560872397
INFO:root:eval perplexity: 9.152751922607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/3
  3%|â–Ž         | 3/100 [26:50<14:26:47, 536.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2414.7617236328124
INFO:root:current train perplexity6.796767711639404
INFO:root:current mean train loss 2425.393016764323
INFO:root:current train perplexity6.842789649963379
INFO:root:current mean train loss 2437.3666391601564
INFO:root:current train perplexity6.840219497680664
INFO:root:current mean train loss 2440.24246547154
INFO:root:current train perplexity6.816335678100586
INFO:root:current mean train loss 2438.8746053059895
INFO:root:current train perplexity6.811583042144775
INFO:root:current mean train loss 2432.2979676402697
INFO:root:current train perplexity6.792117595672607
INFO:root:current mean train loss 2427.845431753305
INFO:root:current train perplexity6.782428741455078
INFO:root:current mean train loss 2422.6031840820315
INFO:root:current train perplexity6.770299434661865
INFO:root:current mean train loss 2421.23282126034
INFO:root:current train perplexity6.750241756439209
INFO:root:current mean train loss 2417.3716434518915
INFO:root:current train perplexity6.729301452636719
INFO:root:current mean train loss 2412.0224291992185
INFO:root:current train perplexity6.717445373535156
INFO:root:current mean train loss 2411.9409707243544
INFO:root:current train perplexity6.714210033416748
INFO:root:current mean train loss 2412.0967711914063
INFO:root:current train perplexity6.709366321563721
INFO:root:current mean train loss 2409.986510507089
INFO:root:current train perplexity6.6956706047058105
INFO:root:current mean train loss 2408.983885119208
INFO:root:current train perplexity6.682255268096924
INFO:root:current mean train loss 2407.496157462828
INFO:root:current train perplexity6.678645133972168
INFO:root:current mean train loss 2406.0514482717804
INFO:root:current train perplexity6.667052268981934
INFO:root:current mean train loss 2404.3873409598214
INFO:root:current train perplexity6.656267166137695
INFO:root:current mean train loss 2401.5899718908363
INFO:root:current train perplexity6.646214962005615
INFO:root:current mean train loss 2399.6508467297676
INFO:root:current train perplexity6.633199214935303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.66s/it]
INFO:root:final mean train loss: 2398.2851275330054
INFO:root:final train perplexity: 6.6288533210754395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2241.4456769794438
INFO:root:eval perplexity: 6.127272605895996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it]
INFO:root:eval mean loss: 2618.5942062486147
INFO:root:eval perplexity: 8.512691497802734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/4
  4%|â–         | 4/100 [35:49<14:19:22, 537.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2358.560987785681
INFO:root:current train perplexity6.358877182006836
INFO:root:current mean train loss 2338.3190238175994
INFO:root:current train perplexity6.281012058258057
INFO:root:current mean train loss 2339.306836303254
INFO:root:current train perplexity6.3142619132995605
INFO:root:current mean train loss 2334.7910275991994
INFO:root:current train perplexity6.299359321594238
INFO:root:current mean train loss 2339.8305975119615
INFO:root:current train perplexity6.334214687347412
INFO:root:current mean train loss 2343.029084166942
INFO:root:current train perplexity6.336361885070801
INFO:root:current mean train loss 2341.116116868324
INFO:root:current train perplexity6.336785793304443
INFO:root:current mean train loss 2344.703096193316
INFO:root:current train perplexity6.343141078948975
INFO:root:current mean train loss 2342.8327267832683
INFO:root:current train perplexity6.341724395751953
INFO:root:current mean train loss 2342.0412832455404
INFO:root:current train perplexity6.334402084350586
INFO:root:current mean train loss 2341.605071306452
INFO:root:current train perplexity6.330916881561279
INFO:root:current mean train loss 2338.913015331278
INFO:root:current train perplexity6.316190719604492
INFO:root:current mean train loss 2339.38715712405
INFO:root:current train perplexity6.312912940979004
INFO:root:current mean train loss 2336.9254177180014
INFO:root:current train perplexity6.307838439941406
INFO:root:current mean train loss 2334.572703230844
INFO:root:current train perplexity6.294697284698486
INFO:root:current mean train loss 2334.2035684104776
INFO:root:current train perplexity6.290243148803711
INFO:root:current mean train loss 2331.1025299090575
INFO:root:current train perplexity6.282741546630859
INFO:root:current mean train loss 2331.6508855382535
INFO:root:current train perplexity6.279295921325684
INFO:root:current mean train loss 2330.1905930145704
INFO:root:current train perplexity6.276474475860596
INFO:root:current mean train loss 2328.8815277518506
INFO:root:current train perplexity6.2716240882873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.73s/it]
INFO:root:final mean train loss: 2327.7483450639024
INFO:root:final train perplexity: 6.270163536071777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 2186.859123067653
INFO:root:eval perplexity: 5.862659454345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.34s/it]
INFO:root:eval mean loss: 2574.091478280142
INFO:root:eval perplexity: 8.2084379196167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/5
  5%|â–Œ         | 5/100 [44:30<14:01:22, 531.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2280.090488978795
INFO:root:current train perplexity6.0926666259765625
INFO:root:current mean train loss 2296.0915865690813
INFO:root:current train perplexity6.083604335784912
INFO:root:current mean train loss 2283.9056968151685
INFO:root:current train perplexity6.0462822914123535
INFO:root:current mean train loss 2282.9042638142905
INFO:root:current train perplexity6.052478313446045
INFO:root:current mean train loss 2278.194425976966
INFO:root:current train perplexity6.0450663566589355
INFO:root:current mean train loss 2280.964732548962
INFO:root:current train perplexity6.038901329040527
INFO:root:current mean train loss 2275.2966774388365
INFO:root:current train perplexity6.024377346038818
INFO:root:current mean train loss 2272.3799696941765
INFO:root:current train perplexity6.011219501495361
INFO:root:current mean train loss 2272.3756647584664
INFO:root:current train perplexity6.005975723266602
INFO:root:current mean train loss 2269.095020697369
INFO:root:current train perplexity5.99637508392334
INFO:root:current mean train loss 2267.8966653408597
INFO:root:current train perplexity5.9873833656311035
INFO:root:current mean train loss 2267.6139963510873
INFO:root:current train perplexity5.98154354095459
INFO:root:current mean train loss 2266.985535903883
INFO:root:current train perplexity5.973184585571289
INFO:root:current mean train loss 2265.828250686557
INFO:root:current train perplexity5.968066215515137
INFO:root:current mean train loss 2262.8855001033157
INFO:root:current train perplexity5.962849140167236
INFO:root:current mean train loss 2260.8042231087734
INFO:root:current train perplexity5.954654216766357
INFO:root:current mean train loss 2260.656558437755
INFO:root:current train perplexity5.950664043426514
INFO:root:current mean train loss 2260.254075123056
INFO:root:current train perplexity5.945127010345459
INFO:root:current mean train loss 2259.374632752372
INFO:root:current train perplexity5.942051410675049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.59s/it]
INFO:root:final mean train loss: 2259.309332296936
INFO:root:final train perplexity: 5.940700531005859
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.13s/it]
INFO:root:eval mean loss: 2132.9445545385915
INFO:root:eval perplexity: 5.612523078918457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it]
INFO:root:eval mean loss: 2526.753471212184
INFO:root:eval perplexity: 7.896727561950684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/6
  6%|â–Œ         | 6/100 [53:21<13:52:11, 531.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2263.799560546875
INFO:root:current train perplexity5.928176403045654
INFO:root:current mean train loss 2197.2818905669865
INFO:root:current train perplexity5.68860387802124
INFO:root:current mean train loss 2203.1585553676928
INFO:root:current train perplexity5.715511322021484
INFO:root:current mean train loss 2203.464398051417
INFO:root:current train perplexity5.695289134979248
INFO:root:current mean train loss 2205.2824268674017
INFO:root:current train perplexity5.703042030334473
INFO:root:current mean train loss 2210.4220331310034
INFO:root:current train perplexity5.704362869262695
INFO:root:current mean train loss 2213.612578076253
INFO:root:current train perplexity5.715137958526611
INFO:root:current mean train loss 2214.9275994185205
INFO:root:current train perplexity5.719888210296631
INFO:root:current mean train loss 2213.3425809595915
INFO:root:current train perplexity5.712808132171631
INFO:root:current mean train loss 2213.4177023901393
INFO:root:current train perplexity5.713264465332031
INFO:root:current mean train loss 2211.0015014282594
INFO:root:current train perplexity5.7121477127075195
INFO:root:current mean train loss 2211.58615691612
INFO:root:current train perplexity5.711386203765869
INFO:root:current mean train loss 2210.307468995564
INFO:root:current train perplexity5.70904016494751
INFO:root:current mean train loss 2208.621347085775
INFO:root:current train perplexity5.702462196350098
INFO:root:current mean train loss 2208.498466497145
INFO:root:current train perplexity5.7007293701171875
INFO:root:current mean train loss 2208.347427967943
INFO:root:current train perplexity5.703286647796631
INFO:root:current mean train loss 2207.3505853275296
INFO:root:current train perplexity5.699840545654297
INFO:root:current mean train loss 2204.8998760064164
INFO:root:current train perplexity5.693546295166016
INFO:root:current mean train loss 2203.996986130752
INFO:root:current train perplexity5.688534736633301
INFO:root:current mean train loss 2204.5864490266226
INFO:root:current train perplexity5.685704708099365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.23s/it]
INFO:root:final mean train loss: 2203.225738202209
INFO:root:final train perplexity: 5.683664798736572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2108.5157635195037
INFO:root:eval perplexity: 5.502726078033447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2508.1116073283742
INFO:root:eval perplexity: 7.777249813079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/7
  7%|â–‹         | 7/100 [1:02:11<13:42:43, 530.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2265.2940673828125
INFO:root:current train perplexity5.605507850646973
INFO:root:current mean train loss 2180.426723674192
INFO:root:current train perplexity5.555947303771973
INFO:root:current mean train loss 2172.9031276877868
INFO:root:current train perplexity5.505565643310547
INFO:root:current mean train loss 2159.86001798042
INFO:root:current train perplexity5.478809833526611
INFO:root:current mean train loss 2171.018295653129
INFO:root:current train perplexity5.516740322113037
INFO:root:current mean train loss 2168.381321498326
INFO:root:current train perplexity5.502438545227051
INFO:root:current mean train loss 2169.0388837400765
INFO:root:current train perplexity5.503488063812256
INFO:root:current mean train loss 2170.794335155434
INFO:root:current train perplexity5.511211395263672
INFO:root:current mean train loss 2165.1399828624026
INFO:root:current train perplexity5.504315376281738
INFO:root:current mean train loss 2166.7189608970757
INFO:root:current train perplexity5.505715370178223
INFO:root:current mean train loss 2165.5504290687545
INFO:root:current train perplexity5.504344463348389
INFO:root:current mean train loss 2163.891918421218
INFO:root:current train perplexity5.503138065338135
INFO:root:current mean train loss 2161.729647130606
INFO:root:current train perplexity5.498924732208252
INFO:root:current mean train loss 2162.7997200347945
INFO:root:current train perplexity5.499375343322754
INFO:root:current mean train loss 2163.261741132427
INFO:root:current train perplexity5.502159118652344
INFO:root:current mean train loss 2162.7067199626617
INFO:root:current train perplexity5.501325607299805
INFO:root:current mean train loss 2161.365610092031
INFO:root:current train perplexity5.495643138885498
INFO:root:current mean train loss 2161.8560462036844
INFO:root:current train perplexity5.495907306671143
INFO:root:current mean train loss 2160.5662716235
INFO:root:current train perplexity5.492910861968994
INFO:root:current mean train loss 2159.416933379904
INFO:root:current train perplexity5.489861488342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.54s/it]
INFO:root:final mean train loss: 2158.5074134476545
INFO:root:final train perplexity: 5.486710548400879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it]
INFO:root:eval mean loss: 2075.5709596458055
INFO:root:eval perplexity: 5.358049392700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it]
INFO:root:eval mean loss: 2477.8598243226397
INFO:root:eval perplexity: 7.587193965911865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/8
  8%|â–Š         | 8/100 [1:10:53<13:29:35, 527.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2079.0833565848216
INFO:root:current train perplexity5.183287620544434
INFO:root:current mean train loss 2112.040804940683
INFO:root:current train perplexity5.307538986206055
INFO:root:current mean train loss 2109.367011407081
INFO:root:current train perplexity5.320583343505859
INFO:root:current mean train loss 2121.188134036847
INFO:root:current train perplexity5.331988334655762
INFO:root:current mean train loss 2127.3978602617635
INFO:root:current train perplexity5.3535919189453125
INFO:root:current mean train loss 2124.653453563084
INFO:root:current train perplexity5.338395118713379
INFO:root:current mean train loss 2125.7640742264393
INFO:root:current train perplexity5.337294578552246
INFO:root:current mean train loss 2124.5896756749576
INFO:root:current train perplexity5.338168621063232
INFO:root:current mean train loss 2123.9736581037146
INFO:root:current train perplexity5.341606616973877
INFO:root:current mean train loss 2127.092387904203
INFO:root:current train perplexity5.343084335327148
INFO:root:current mean train loss 2127.579001311519
INFO:root:current train perplexity5.34366512298584
INFO:root:current mean train loss 2128.446532880472
INFO:root:current train perplexity5.3496809005737305
INFO:root:current mean train loss 2125.6439024149163
INFO:root:current train perplexity5.346245288848877
INFO:root:current mean train loss 2123.693904896711
INFO:root:current train perplexity5.34179162979126
INFO:root:current mean train loss 2124.034898158482
INFO:root:current train perplexity5.3402581214904785
INFO:root:current mean train loss 2124.785966208393
INFO:root:current train perplexity5.34244441986084
INFO:root:current mean train loss 2125.764403699589
INFO:root:current train perplexity5.344425201416016
INFO:root:current mean train loss 2125.441068674577
INFO:root:current train perplexity5.344053745269775
INFO:root:current mean train loss 2124.6794995050664
INFO:root:current train perplexity5.341851234436035
INFO:root:current mean train loss 2125.209899681545
INFO:root:current train perplexity5.341558456420898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.01s/it]
INFO:root:final mean train loss: 2124.1537602088456
INFO:root:final train perplexity: 5.340052604675293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.06s/it]
INFO:root:eval mean loss: 2041.6330250408632
INFO:root:eval perplexity: 5.212985992431641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it]
INFO:root:eval mean loss: 2454.715100443955
INFO:root:eval perplexity: 7.444930553436279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/9
  9%|â–‰         | 9/100 [1:19:37<13:19:07, 526.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2049.5343510554385
INFO:root:current train perplexity5.1544189453125
INFO:root:current mean train loss 2087.900819477282
INFO:root:current train perplexity5.226353645324707
INFO:root:current mean train loss 2099.84970383417
INFO:root:current train perplexity5.22692346572876
INFO:root:current mean train loss 2095.1267953352494
INFO:root:current train perplexity5.223518371582031
INFO:root:current mean train loss 2093.980044744711
INFO:root:current train perplexity5.223567485809326
INFO:root:current mean train loss 2090.43292103643
INFO:root:current train perplexity5.210148811340332
INFO:root:current mean train loss 2091.4218137776193
INFO:root:current train perplexity5.213668346405029
INFO:root:current mean train loss 2091.232620888568
INFO:root:current train perplexity5.2110595703125
INFO:root:current mean train loss 2095.455010642468
INFO:root:current train perplexity5.21828031539917
INFO:root:current mean train loss 2094.191904661034
INFO:root:current train perplexity5.216778755187988
INFO:root:current mean train loss 2094.5978365705946
INFO:root:current train perplexity5.21588659286499
INFO:root:current mean train loss 2095.8332725101045
INFO:root:current train perplexity5.218366622924805
INFO:root:current mean train loss 2093.6650478375223
INFO:root:current train perplexity5.216114044189453
INFO:root:current mean train loss 2094.367462248492
INFO:root:current train perplexity5.212303161621094
INFO:root:current mean train loss 2094.722279278043
INFO:root:current train perplexity5.212218761444092
INFO:root:current mean train loss 2094.628324921598
INFO:root:current train perplexity5.213389873504639
INFO:root:current mean train loss 2096.094411041777
INFO:root:current train perplexity5.217015266418457
INFO:root:current mean train loss 2096.4541386991878
INFO:root:current train perplexity5.218012809753418
INFO:root:current mean train loss 2095.3617262376824
INFO:root:current train perplexity5.215524673461914
INFO:root:current mean train loss 2095.6316802853444
INFO:root:current train perplexity5.215737819671631

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it]
INFO:root:final mean train loss: 2093.7667109517815
INFO:root:final train perplexity: 5.213598728179932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it]
INFO:root:eval mean loss: 2019.353166296127
INFO:root:eval perplexity: 5.119897365570068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.28s/it]
INFO:root:eval mean loss: 2431.249892647385
INFO:root:eval perplexity: 7.303421974182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:28:24<13:10:16, 526.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2079.659905032835
INFO:root:current train perplexity5.140230655670166
INFO:root:current mean train loss 2090.4528050168733
INFO:root:current train perplexity5.155351161956787
INFO:root:current mean train loss 2086.80582379763
INFO:root:current train perplexity5.1422648429870605
INFO:root:current mean train loss 2079.356559774094
INFO:root:current train perplexity5.121554374694824
INFO:root:current mean train loss 2077.835004403901
INFO:root:current train perplexity5.122479438781738
INFO:root:current mean train loss 2074.0023729696422
INFO:root:current train perplexity5.122464179992676
INFO:root:current mean train loss 2071.498410166468
INFO:root:current train perplexity5.1135334968566895
INFO:root:current mean train loss 2072.8976098347084
INFO:root:current train perplexity5.120488166809082
INFO:root:current mean train loss 2072.6237559784954
INFO:root:current train perplexity5.123840808868408
INFO:root:current mean train loss 2072.148413438669
INFO:root:current train perplexity5.122833728790283
INFO:root:current mean train loss 2071.0479440573113
INFO:root:current train perplexity5.119791507720947
INFO:root:current mean train loss 2072.8323098501655
INFO:root:current train perplexity5.120480060577393
INFO:root:current mean train loss 2072.4050743157136
INFO:root:current train perplexity5.122432708740234
INFO:root:current mean train loss 2072.414956582559
INFO:root:current train perplexity5.119370937347412
INFO:root:current mean train loss 2073.0237839337187
INFO:root:current train perplexity5.123353481292725
INFO:root:current mean train loss 2072.032873636298
INFO:root:current train perplexity5.120471000671387
INFO:root:current mean train loss 2071.2853531423193
INFO:root:current train perplexity5.118808269500732
INFO:root:current mean train loss 2071.4131742642385
INFO:root:current train perplexity5.117516040802002
INFO:root:current mean train loss 2070.739705142393
INFO:root:current train perplexity5.114715099334717
INFO:root:current mean train loss 2071.2602136087876
INFO:root:current train perplexity5.120052337646484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.78s/it]
INFO:root:final mean train loss: 2070.544719963439
INFO:root:final train perplexity: 5.118984222412109
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 2003.1060652496121
INFO:root:eval perplexity: 5.053062438964844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it]
INFO:root:eval mean loss: 2420.1532657704456
INFO:root:eval perplexity: 7.237442970275879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:37:15<13:03:32, 528.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2064.80802314226
INFO:root:current train perplexity5.0348124504089355
INFO:root:current mean train loss 2045.696577174689
INFO:root:current train perplexity5.01738166809082
INFO:root:current mean train loss 2044.7609099274748
INFO:root:current train perplexity5.015594482421875
INFO:root:current mean train loss 2047.8304645755748
INFO:root:current train perplexity5.028111457824707
INFO:root:current mean train loss 2042.5912890022184
INFO:root:current train perplexity5.031928062438965
INFO:root:current mean train loss 2046.052598764465
INFO:root:current train perplexity5.031945705413818
INFO:root:current mean train loss 2046.583950031603
INFO:root:current train perplexity5.020166873931885
INFO:root:current mean train loss 2046.7353835554827
INFO:root:current train perplexity5.017308712005615
INFO:root:current mean train loss 2046.3806848116976
INFO:root:current train perplexity5.016030788421631
INFO:root:current mean train loss 2048.9702268526958
INFO:root:current train perplexity5.022793292999268
INFO:root:current mean train loss 2050.705343509906
INFO:root:current train perplexity5.030953407287598
INFO:root:current mean train loss 2051.340481788674
INFO:root:current train perplexity5.0324273109436035
INFO:root:current mean train loss 2051.6202572930843
INFO:root:current train perplexity5.0335564613342285
INFO:root:current mean train loss 2051.269515749008
INFO:root:current train perplexity5.035175800323486
INFO:root:current mean train loss 2050.2360342854927
INFO:root:current train perplexity5.037684440612793
INFO:root:current mean train loss 2051.5222676723333
INFO:root:current train perplexity5.038812637329102
INFO:root:current mean train loss 2050.5485696487153
INFO:root:current train perplexity5.0389404296875
INFO:root:current mean train loss 2050.8421847523928
INFO:root:current train perplexity5.0396199226379395
INFO:root:current mean train loss 2050.390563900119
INFO:root:current train perplexity5.039791107177734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.34s/it]
INFO:root:final mean train loss: 2050.903998008955
INFO:root:final train perplexity: 5.0403032302856445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.07s/it]
INFO:root:eval mean loss: 1993.7777761905752
INFO:root:eval perplexity: 5.015084743499756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it]
INFO:root:eval mean loss: 2411.6695240643007
INFO:root:eval perplexity: 7.187402725219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:46:02<12:53:59, 527.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.490681966146
INFO:root:current train perplexity4.880219459533691
INFO:root:current mean train loss 2035.842784103838
INFO:root:current train perplexity4.983192443847656
INFO:root:current mean train loss 2024.9255341027172
INFO:root:current train perplexity4.939483642578125
INFO:root:current mean train loss 2029.667803169477
INFO:root:current train perplexity4.945465087890625
INFO:root:current mean train loss 2027.6915425568006
INFO:root:current train perplexity4.9412689208984375
INFO:root:current mean train loss 2029.47768248905
INFO:root:current train perplexity4.950872421264648
INFO:root:current mean train loss 2033.7107184617278
INFO:root:current train perplexity4.969614028930664
INFO:root:current mean train loss 2031.7453811233108
INFO:root:current train perplexity4.9608235359191895
INFO:root:current mean train loss 2032.1060164702192
INFO:root:current train perplexity4.962409019470215
INFO:root:current mean train loss 2032.5498655198817
INFO:root:current train perplexity4.9660820960998535
INFO:root:current mean train loss 2031.6015781999704
INFO:root:current train perplexity4.961775779724121
INFO:root:current mean train loss 2031.5884370086198
INFO:root:current train perplexity4.967066287994385
INFO:root:current mean train loss 2030.6477779347206
INFO:root:current train perplexity4.967057228088379
INFO:root:current mean train loss 2030.783398737289
INFO:root:current train perplexity4.9669013023376465
INFO:root:current mean train loss 2031.3857657662988
INFO:root:current train perplexity4.963545322418213
INFO:root:current mean train loss 2031.210936444169
INFO:root:current train perplexity4.96216344833374
INFO:root:current mean train loss 2032.2581085757174
INFO:root:current train perplexity4.966821670532227
INFO:root:current mean train loss 2032.8474140447236
INFO:root:current train perplexity4.968347072601318
INFO:root:current mean train loss 2032.9547044666224
INFO:root:current train perplexity4.967647075653076
INFO:root:current mean train loss 2034.2691555454176
INFO:root:current train perplexity4.97099494934082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.37s/it]
INFO:root:final mean train loss: 2033.042894449008
INFO:root:final train perplexity: 4.969801425933838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it]
INFO:root:eval mean loss: 1982.648517581588
INFO:root:eval perplexity: 4.97014856338501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.21s/it]
INFO:root:eval mean loss: 2406.766023243573
INFO:root:eval perplexity: 7.158636569976807
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:54:52<12:46:05, 528.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1993.996728515625
INFO:root:current train perplexity4.887248516082764
INFO:root:current mean train loss 2005.8247172037761
INFO:root:current train perplexity4.852797508239746
INFO:root:current mean train loss 2007.6637384588068
INFO:root:current train perplexity4.890511989593506
INFO:root:current mean train loss 2008.8428089141846
INFO:root:current train perplexity4.8786396980285645
INFO:root:current mean train loss 2010.4524788992746
INFO:root:current train perplexity4.882403373718262
INFO:root:current mean train loss 2014.7053882305438
INFO:root:current train perplexity4.887307643890381
INFO:root:current mean train loss 2010.998668842931
INFO:root:current train perplexity4.877342224121094
INFO:root:current mean train loss 2008.8430881076388
INFO:root:current train perplexity4.875180244445801
INFO:root:current mean train loss 2007.8292888362232
INFO:root:current train perplexity4.879505157470703
INFO:root:current mean train loss 2006.6819764510444
INFO:root:current train perplexity4.879262447357178
INFO:root:current mean train loss 2008.0805211684283
INFO:root:current train perplexity4.881083011627197
INFO:root:current mean train loss 2008.8438219342913
INFO:root:current train perplexity4.884449481964111
INFO:root:current mean train loss 2008.9499003425974
INFO:root:current train perplexity4.8806023597717285
INFO:root:current mean train loss 2011.142622791637
INFO:root:current train perplexity4.88250732421875
INFO:root:current mean train loss 2011.9930440553478
INFO:root:current train perplexity4.889456272125244
INFO:root:current mean train loss 2011.1840358533357
INFO:root:current train perplexity4.891158580780029
INFO:root:current mean train loss 2011.936644528236
INFO:root:current train perplexity4.893002986907959
INFO:root:current mean train loss 2013.9562904535337
INFO:root:current train perplexity4.894906520843506
INFO:root:current mean train loss 2012.8969501872639
INFO:root:current train perplexity4.893157958984375
INFO:root:current mean train loss 2013.6621819814047
INFO:root:current train perplexity4.8967695236206055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it]
INFO:root:final mean train loss: 2014.4338705165785
INFO:root:final train perplexity: 4.897396087646484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it]
INFO:root:eval mean loss: 1979.6857568186226
INFO:root:eval perplexity: 4.958253860473633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.55s/it]
INFO:root:eval mean loss: 2403.3107485940272
INFO:root:eval perplexity: 7.138434886932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [2:03:41<12:37:54, 528.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2029.999927417652
INFO:root:current train perplexity4.772501468658447
INFO:root:current mean train loss 2007.0082954351049
INFO:root:current train perplexity4.806081295013428
INFO:root:current mean train loss 1996.5849975070873
INFO:root:current train perplexity4.800704479217529
INFO:root:current mean train loss 1993.7289013961656
INFO:root:current train perplexity4.790194511413574
INFO:root:current mean train loss 1994.5881532018736
INFO:root:current train perplexity4.795539379119873
INFO:root:current mean train loss 1998.132441970001
INFO:root:current train perplexity4.810135841369629
INFO:root:current mean train loss 1994.9715152662627
INFO:root:current train perplexity4.807326793670654
INFO:root:current mean train loss 1993.289573307115
INFO:root:current train perplexity4.8058929443359375
INFO:root:current mean train loss 1993.5294889497927
INFO:root:current train perplexity4.804331302642822
INFO:root:current mean train loss 1990.5232263196622
INFO:root:current train perplexity4.79900598526001
INFO:root:current mean train loss 1990.0734609017147
INFO:root:current train perplexity4.801965236663818
INFO:root:current mean train loss 1990.8608986779902
INFO:root:current train perplexity4.805885314941406
INFO:root:current mean train loss 1990.8612355607695
INFO:root:current train perplexity4.805799961090088
INFO:root:current mean train loss 1992.3051437343693
INFO:root:current train perplexity4.810244083404541
INFO:root:current mean train loss 1990.9768525975066
INFO:root:current train perplexity4.805876731872559
INFO:root:current mean train loss 1992.834753568869
INFO:root:current train perplexity4.81035041809082
INFO:root:current mean train loss 1993.3776285757579
INFO:root:current train perplexity4.812638282775879
INFO:root:current mean train loss 1993.6377285532933
INFO:root:current train perplexity4.814287185668945
INFO:root:current mean train loss 1993.5371704433817
INFO:root:current train perplexity4.8150224685668945
INFO:root:current mean train loss 1993.8054145021297
INFO:root:current train perplexity4.817274570465088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.11s/it]
INFO:root:final mean train loss: 1994.2878391806428
INFO:root:final train perplexity: 4.820199489593506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it]
INFO:root:eval mean loss: 1958.6998464165003
INFO:root:eval perplexity: 4.874812126159668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 2385.9476560768508
INFO:root:eval perplexity: 7.037785530090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [2:12:49<12:37:05, 534.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1949.9653501157406
INFO:root:current train perplexity4.709995269775391
INFO:root:current mean train loss 1966.34846397499
INFO:root:current train perplexity4.750267505645752
INFO:root:current mean train loss 1975.3713921974963
INFO:root:current train perplexity4.7624711990356445
INFO:root:current mean train loss 1971.8084537484551
INFO:root:current train perplexity4.751300811767578
INFO:root:current mean train loss 1974.2976195213553
INFO:root:current train perplexity4.747742176055908
INFO:root:current mean train loss 1977.0201294826686
INFO:root:current train perplexity4.755054950714111
INFO:root:current mean train loss 1980.4497242032205
INFO:root:current train perplexity4.760784149169922
INFO:root:current mean train loss 1977.7125159954203
INFO:root:current train perplexity4.750786304473877
INFO:root:current mean train loss 1976.984091551019
INFO:root:current train perplexity4.75085973739624
INFO:root:current mean train loss 1976.3595419829746
INFO:root:current train perplexity4.751015663146973
INFO:root:current mean train loss 1979.5577630001408
INFO:root:current train perplexity4.754796981811523
INFO:root:current mean train loss 1976.3814825259626
INFO:root:current train perplexity4.748727798461914
INFO:root:current mean train loss 1977.3109473512884
INFO:root:current train perplexity4.751542568206787
INFO:root:current mean train loss 1978.4786467108452
INFO:root:current train perplexity4.7498345375061035
INFO:root:current mean train loss 1978.5656988466621
INFO:root:current train perplexity4.750278949737549
INFO:root:current mean train loss 1977.5887429177224
INFO:root:current train perplexity4.749971866607666
INFO:root:current mean train loss 1976.5807126839763
INFO:root:current train perplexity4.7487406730651855
INFO:root:current mean train loss 1976.7595135505007
INFO:root:current train perplexity4.750678539276123
INFO:root:current mean train loss 1976.9453668851554
INFO:root:current train perplexity4.750668525695801
INFO:root:current mean train loss 1975.4579145417854
INFO:root:current train perplexity4.747378826141357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.52s/it]
INFO:root:final mean train loss: 1974.8833048133254
INFO:root:final train perplexity: 4.746994495391846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.06s/it]
INFO:root:eval mean loss: 1953.3041061509587
INFO:root:eval perplexity: 4.853585243225098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it]
INFO:root:eval mean loss: 2384.035535447141
INFO:root:eval perplexity: 7.026789665222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [2:21:41<12:27:22, 533.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1989.4631072568222
INFO:root:current train perplexity4.720565319061279
INFO:root:current mean train loss 1965.7394277115313
INFO:root:current train perplexity4.6893792152404785
INFO:root:current mean train loss 1964.2027885183636
INFO:root:current train perplexity4.698426723480225
INFO:root:current mean train loss 1963.5861632149174
INFO:root:current train perplexity4.693399429321289
INFO:root:current mean train loss 1962.0643092841858
INFO:root:current train perplexity4.699189186096191
INFO:root:current mean train loss 1960.0248585181562
INFO:root:current train perplexity4.691189765930176
INFO:root:current mean train loss 1960.0915812962812
INFO:root:current train perplexity4.685744285583496
INFO:root:current mean train loss 1959.7423782843405
INFO:root:current train perplexity4.6856513023376465
INFO:root:current mean train loss 1958.7009260525797
INFO:root:current train perplexity4.6834282875061035
INFO:root:current mean train loss 1957.9522431017074
INFO:root:current train perplexity4.683619022369385
INFO:root:current mean train loss 1957.0722170704219
INFO:root:current train perplexity4.683609485626221
INFO:root:current mean train loss 1956.112981130077
INFO:root:current train perplexity4.679471015930176
INFO:root:current mean train loss 1955.3842640898529
INFO:root:current train perplexity4.674527168273926
INFO:root:current mean train loss 1956.835616252963
INFO:root:current train perplexity4.678375720977783
INFO:root:current mean train loss 1957.5997505317653
INFO:root:current train perplexity4.68087100982666
INFO:root:current mean train loss 1957.2989681445438
INFO:root:current train perplexity4.682648658752441
INFO:root:current mean train loss 1957.0908561081033
INFO:root:current train perplexity4.682467937469482
INFO:root:current mean train loss 1956.22701921253
INFO:root:current train perplexity4.678840160369873
INFO:root:current mean train loss 1955.8351020588714
INFO:root:current train perplexity4.677539348602295
INFO:root:current mean train loss 1956.7961419587932
INFO:root:current train perplexity4.677560806274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.92s/it]
INFO:root:final mean train loss: 1956.5273910268534
INFO:root:final train perplexity: 4.678769588470459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 1936.521518139129
INFO:root:eval perplexity: 4.788154125213623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.15s/it]
INFO:root:eval mean loss: 2366.254510541334
INFO:root:eval perplexity: 6.925345420837402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [2:30:22<12:13:05, 529.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1956.6220148259943
INFO:root:current train perplexity4.65146017074585
INFO:root:current mean train loss 1929.736489803233
INFO:root:current train perplexity4.598987579345703
INFO:root:current mean train loss 1935.6137258741592
INFO:root:current train perplexity4.618638515472412
INFO:root:current mean train loss 1943.1367093115737
INFO:root:current train perplexity4.623824119567871
INFO:root:current mean train loss 1936.9498135926294
INFO:root:current train perplexity4.6058669090271
INFO:root:current mean train loss 1941.5568127275324
INFO:root:current train perplexity4.617599010467529
INFO:root:current mean train loss 1936.663243848224
INFO:root:current train perplexity4.607653617858887
INFO:root:current mean train loss 1936.3754128393182
INFO:root:current train perplexity4.609739780426025
INFO:root:current mean train loss 1937.8511697580147
INFO:root:current train perplexity4.615004539489746
INFO:root:current mean train loss 1937.2256227562784
INFO:root:current train perplexity4.613035202026367
INFO:root:current mean train loss 1936.949758754057
INFO:root:current train perplexity4.611696243286133
INFO:root:current mean train loss 1937.8398163150055
INFO:root:current train perplexity4.613672256469727
INFO:root:current mean train loss 1938.9065728987225
INFO:root:current train perplexity4.616552829742432
INFO:root:current mean train loss 1938.045966508409
INFO:root:current train perplexity4.615634441375732
INFO:root:current mean train loss 1937.557287975024
INFO:root:current train perplexity4.614543914794922
INFO:root:current mean train loss 1936.996849540499
INFO:root:current train perplexity4.612882137298584
INFO:root:current mean train loss 1937.2802233944572
INFO:root:current train perplexity4.614320278167725
INFO:root:current mean train loss 1938.0797152593898
INFO:root:current train perplexity4.613226413726807
INFO:root:current mean train loss 1940.1048810279976
INFO:root:current train perplexity4.615938186645508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.18s/it]
INFO:root:final mean train loss: 1938.741194870757
INFO:root:final train perplexity: 4.613597393035889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 1931.0828268713985
INFO:root:eval perplexity: 4.767139911651611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2368.699667639766
INFO:root:eval perplexity: 6.939208030700684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:39:25<12:09:34, 533.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.320361328125
INFO:root:current train perplexity4.3274993896484375
INFO:root:current mean train loss 1891.520171828497
INFO:root:current train perplexity4.515566349029541
INFO:root:current mean train loss 1899.9801001572027
INFO:root:current train perplexity4.5035319328308105
INFO:root:current mean train loss 1910.7953881435708
INFO:root:current train perplexity4.519931316375732
INFO:root:current mean train loss 1906.0745111159335
INFO:root:current train perplexity4.516514778137207
INFO:root:current mean train loss 1909.0928374941986
INFO:root:current train perplexity4.517411231994629
INFO:root:current mean train loss 1908.377720049393
INFO:root:current train perplexity4.516262531280518
INFO:root:current mean train loss 1910.4632855787345
INFO:root:current train perplexity4.520276069641113
INFO:root:current mean train loss 1912.8072468822788
INFO:root:current train perplexity4.528223514556885
INFO:root:current mean train loss 1917.9713122626035
INFO:root:current train perplexity4.539417743682861
INFO:root:current mean train loss 1917.4014963026664
INFO:root:current train perplexity4.537394046783447
INFO:root:current mean train loss 1918.5727583250848
INFO:root:current train perplexity4.540850639343262
INFO:root:current mean train loss 1918.1818267189121
INFO:root:current train perplexity4.540873050689697
INFO:root:current mean train loss 1917.8723838601531
INFO:root:current train perplexity4.54010534286499
INFO:root:current mean train loss 1918.9653254281584
INFO:root:current train perplexity4.54059362411499
INFO:root:current mean train loss 1920.0531453585704
INFO:root:current train perplexity4.5420684814453125
INFO:root:current mean train loss 1920.8728795512072
INFO:root:current train perplexity4.544023513793945
INFO:root:current mean train loss 1921.880184372709
INFO:root:current train perplexity4.548013210296631
INFO:root:current mean train loss 1922.1266738173044
INFO:root:current train perplexity4.550648212432861
INFO:root:current mean train loss 1922.6871225752543
INFO:root:current train perplexity4.5528340339660645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.31s/it]
INFO:root:final mean train loss: 1922.200087523737
INFO:root:final train perplexity: 4.553802013397217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it]
INFO:root:eval mean loss: 1915.6972422498338
INFO:root:eval perplexity: 4.708189487457275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it]
INFO:root:eval mean loss: 2346.6434460362643
INFO:root:eval perplexity: 6.815160751342773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:48:20<12:00:54, 534.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.5723211115057
INFO:root:current train perplexity4.525572299957275
INFO:root:current mean train loss 1900.3466116483094
INFO:root:current train perplexity4.514435291290283
INFO:root:current mean train loss 1915.4991400091499
INFO:root:current train perplexity4.53676700592041
INFO:root:current mean train loss 1905.8946207176825
INFO:root:current train perplexity4.512045860290527
INFO:root:current mean train loss 1900.9267763255332
INFO:root:current train perplexity4.494668483734131
INFO:root:current mean train loss 1905.8332320757752
INFO:root:current train perplexity4.503328323364258
INFO:root:current mean train loss 1905.1493412520724
INFO:root:current train perplexity4.500011444091797
INFO:root:current mean train loss 1908.78351235852
INFO:root:current train perplexity4.512728214263916
INFO:root:current mean train loss 1906.5682699755741
INFO:root:current train perplexity4.510461807250977
INFO:root:current mean train loss 1907.0760398748898
INFO:root:current train perplexity4.5069732666015625
INFO:root:current mean train loss 1907.8284582447866
INFO:root:current train perplexity4.505204200744629
INFO:root:current mean train loss 1909.0926856382646
INFO:root:current train perplexity4.505283355712891
INFO:root:current mean train loss 1909.4723787448215
INFO:root:current train perplexity4.504347801208496
INFO:root:current mean train loss 1908.3573109775375
INFO:root:current train perplexity4.500958442687988
INFO:root:current mean train loss 1906.8336890712903
INFO:root:current train perplexity4.495630741119385
INFO:root:current mean train loss 1906.6919954277369
INFO:root:current train perplexity4.495603084564209
INFO:root:current mean train loss 1907.6247639873613
INFO:root:current train perplexity4.497452735900879
INFO:root:current mean train loss 1906.9562260254474
INFO:root:current train perplexity4.496277332305908
INFO:root:current mean train loss 1907.5382418417905
INFO:root:current train perplexity4.497753620147705
INFO:root:current mean train loss 1907.2736326727734
INFO:root:current train perplexity4.498478889465332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.96s/it]
INFO:root:final mean train loss: 1907.0187811608635
INFO:root:final train perplexity: 4.49960470199585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it]
INFO:root:eval mean loss: 1920.9553815692875
INFO:root:eval perplexity: 4.728253364562988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it]
INFO:root:eval mean loss: 2357.92685694052
INFO:root:eval perplexity: 6.878341197967529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:56:58<11:45:56, 529.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.6861134064504
INFO:root:current train perplexity4.380757808685303
INFO:root:current mean train loss 1882.3214559212006
INFO:root:current train perplexity4.420196056365967
INFO:root:current mean train loss 1893.552539266802
INFO:root:current train perplexity4.431638240814209
INFO:root:current mean train loss 1894.032043637076
INFO:root:current train perplexity4.42983865737915
INFO:root:current mean train loss 1895.6201430474978
INFO:root:current train perplexity4.4490203857421875
INFO:root:current mean train loss 1890.0636339629957
INFO:root:current train perplexity4.440783500671387
INFO:root:current mean train loss 1892.711794857688
INFO:root:current train perplexity4.4438886642456055
INFO:root:current mean train loss 1892.4441733973274
INFO:root:current train perplexity4.439368724822998
INFO:root:current mean train loss 1894.3093372294957
INFO:root:current train perplexity4.445459365844727
INFO:root:current mean train loss 1895.3348345771765
INFO:root:current train perplexity4.448072910308838
INFO:root:current mean train loss 1896.4955564761415
INFO:root:current train perplexity4.451107978820801
INFO:root:current mean train loss 1896.022348834298
INFO:root:current train perplexity4.452555179595947
INFO:root:current mean train loss 1894.3170433998878
INFO:root:current train perplexity4.450770378112793
INFO:root:current mean train loss 1895.271964269044
INFO:root:current train perplexity4.449240684509277
INFO:root:current mean train loss 1896.7040829847388
INFO:root:current train perplexity4.451505184173584
INFO:root:current mean train loss 1895.927660609314
INFO:root:current train perplexity4.452481269836426
INFO:root:current mean train loss 1896.565600466772
INFO:root:current train perplexity4.452774524688721
INFO:root:current mean train loss 1897.3811410001258
INFO:root:current train perplexity4.455081939697266
INFO:root:current mean train loss 1895.7686398512906
INFO:root:current train perplexity4.451949119567871
INFO:root:current mean train loss 1894.147091578798
INFO:root:current train perplexity4.452480792999268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.46s/it]
INFO:root:final mean train loss: 1894.0012899871072
INFO:root:final train perplexity: 4.453647136688232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.43s/it]
INFO:root:eval mean loss: 1912.58621367326
INFO:root:eval perplexity: 4.6963582038879395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it]
INFO:root:eval mean loss: 2353.32832585328
INFO:root:eval perplexity: 6.852519989013672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [3:05:54<11:39:37, 531.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.0010593959264
INFO:root:current train perplexity4.428826808929443
INFO:root:current mean train loss 1891.6789143880208
INFO:root:current train perplexity4.4084062576293945
INFO:root:current mean train loss 1886.9456810951233
INFO:root:current train perplexity4.41085147857666
INFO:root:current mean train loss 1886.0263764456417
INFO:root:current train perplexity4.410378456115723
INFO:root:current mean train loss 1880.9779052734375
INFO:root:current train perplexity4.415364742279053
INFO:root:current mean train loss 1880.827286095928
INFO:root:current train perplexity4.412723064422607
INFO:root:current mean train loss 1880.7225131523319
INFO:root:current train perplexity4.410722732543945
INFO:root:current mean train loss 1884.045581474506
INFO:root:current train perplexity4.413021564483643
INFO:root:current mean train loss 1878.1907676625474
INFO:root:current train perplexity4.398261070251465
INFO:root:current mean train loss 1880.412314059844
INFO:root:current train perplexity4.402722358703613
INFO:root:current mean train loss 1880.010997541023
INFO:root:current train perplexity4.403230667114258
INFO:root:current mean train loss 1879.4925694449137
INFO:root:current train perplexity4.4033026695251465
INFO:root:current mean train loss 1880.2883969446657
INFO:root:current train perplexity4.404508113861084
INFO:root:current mean train loss 1879.6522717321166
INFO:root:current train perplexity4.4007086753845215
INFO:root:current mean train loss 1879.5067881489847
INFO:root:current train perplexity4.398919105529785
INFO:root:current mean train loss 1880.3394572986122
INFO:root:current train perplexity4.400566101074219
INFO:root:current mean train loss 1881.926562912798
INFO:root:current train perplexity4.403194427490234
INFO:root:current mean train loss 1881.274470440076
INFO:root:current train perplexity4.4038496017456055
INFO:root:current mean train loss 1882.0075946018615
INFO:root:current train perplexity4.4070258140563965
INFO:root:current mean train loss 1881.9216085172625
INFO:root:current train perplexity4.408976078033447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.40s/it]
INFO:root:final mean train loss: 1881.2215702058809
INFO:root:final train perplexity: 4.408985137939453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 1902.2089242055906
INFO:root:eval perplexity: 4.657108783721924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it]
INFO:root:eval mean loss: 2340.9608085037125
INFO:root:eval perplexity: 6.783559799194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:14:33<11:25:45, 527.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1883.6060406410531
INFO:root:current train perplexity4.377099990844727
INFO:root:current mean train loss 1883.445007677023
INFO:root:current train perplexity4.386179447174072
INFO:root:current mean train loss 1887.9088358337626
INFO:root:current train perplexity4.384612560272217
INFO:root:current mean train loss 1882.1853050252387
INFO:root:current train perplexity4.37520694732666
INFO:root:current mean train loss 1877.1800364197939
INFO:root:current train perplexity4.365562915802002
INFO:root:current mean train loss 1872.3938171493237
INFO:root:current train perplexity4.358776569366455
INFO:root:current mean train loss 1869.0131019716985
INFO:root:current train perplexity4.348961353302002
INFO:root:current mean train loss 1870.75264227745
INFO:root:current train perplexity4.355895519256592
INFO:root:current mean train loss 1868.0597483142271
INFO:root:current train perplexity4.356243133544922
INFO:root:current mean train loss 1869.8771783215168
INFO:root:current train perplexity4.364019393920898
INFO:root:current mean train loss 1871.037857724036
INFO:root:current train perplexity4.364660739898682
INFO:root:current mean train loss 1870.580968728354
INFO:root:current train perplexity4.364275932312012
INFO:root:current mean train loss 1871.39122844735
INFO:root:current train perplexity4.366879940032959
INFO:root:current mean train loss 1871.2278664207597
INFO:root:current train perplexity4.364528179168701
INFO:root:current mean train loss 1870.710199111348
INFO:root:current train perplexity4.363450527191162
INFO:root:current mean train loss 1871.1538597344595
INFO:root:current train perplexity4.363409042358398
INFO:root:current mean train loss 1871.1989205423688
INFO:root:current train perplexity4.365047931671143
INFO:root:current mean train loss 1871.4327705155235
INFO:root:current train perplexity4.369496822357178
INFO:root:current mean train loss 1871.9129164207445
INFO:root:current train perplexity4.373981475830078
INFO:root:current mean train loss 1871.1743331112598
INFO:root:current train perplexity4.372194290161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.54s/it]
INFO:root:final mean train loss: 1870.4228950227323
INFO:root:final train perplexity: 4.3715949058532715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it]
INFO:root:eval mean loss: 1892.6193427769006
INFO:root:eval perplexity: 4.621131420135498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 2330.725137047734
INFO:root:eval perplexity: 6.727012634277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:23:14<11:14:25, 525.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1835.0732652452257
INFO:root:current train perplexity4.259649753570557
INFO:root:current mean train loss 1846.2668540553043
INFO:root:current train perplexity4.2916412353515625
INFO:root:current mean train loss 1848.8429274986531
INFO:root:current train perplexity4.307259559631348
INFO:root:current mean train loss 1854.9974988105969
INFO:root:current train perplexity4.317543029785156
INFO:root:current mean train loss 1853.715860421317
INFO:root:current train perplexity4.314625263214111
INFO:root:current mean train loss 1858.589111535024
INFO:root:current train perplexity4.32283353805542
INFO:root:current mean train loss 1857.2143894361413
INFO:root:current train perplexity4.321305751800537
INFO:root:current mean train loss 1857.2957456178303
INFO:root:current train perplexity4.327176570892334
INFO:root:current mean train loss 1858.1889712901598
INFO:root:current train perplexity4.329131603240967
INFO:root:current mean train loss 1857.2833572541824
INFO:root:current train perplexity4.329824924468994
INFO:root:current mean train loss 1867.95769670119
INFO:root:current train perplexity4.361908912658691
INFO:root:current mean train loss 1877.6459257238052
INFO:root:current train perplexity4.397204399108887
INFO:root:current mean train loss 1885.5338995881782
INFO:root:current train perplexity4.427046298980713
INFO:root:current mean train loss 1890.8656934998876
INFO:root:current train perplexity4.446534156799316
INFO:root:current mean train loss 1896.785704009805
INFO:root:current train perplexity4.46709680557251
INFO:root:current mean train loss 1901.8109310510024
INFO:root:current train perplexity4.48634147644043
INFO:root:current mean train loss 1906.2187427046736
INFO:root:current train perplexity4.502893447875977
INFO:root:current mean train loss 1912.901271167947
INFO:root:current train perplexity4.521601676940918
INFO:root:current mean train loss 1949.2898991014592
INFO:root:current train perplexity4.652374267578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.94s/it]
INFO:root:final mean train loss: 1956.8411614691677
INFO:root:final train perplexity: 4.679926872253418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.81s/it]
INFO:root:eval mean loss: 1943.5980042802526
INFO:root:eval perplexity: 4.8156352043151855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it]
INFO:root:eval mean loss: 2384.5745325832504
INFO:root:eval perplexity: 7.029887676239014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:32:07<11:08:38, 527.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2130.6095668247767
INFO:root:current train perplexity5.343862056732178
INFO:root:current mean train loss 2077.4847423517817
INFO:root:current train perplexity5.137287616729736
INFO:root:current mean train loss 2064.200584522192
INFO:root:current train perplexity5.07191276550293
INFO:root:current mean train loss 2068.5507442710455
INFO:root:current train perplexity5.105631351470947
INFO:root:current mean train loss 2058.0576351831232
INFO:root:current train perplexity5.074521541595459
INFO:root:current mean train loss 2051.9692293727658
INFO:root:current train perplexity5.053822040557861
INFO:root:current mean train loss 2046.447555416302
INFO:root:current train perplexity5.024725437164307
INFO:root:current mean train loss 2034.7021543079252
INFO:root:current train perplexity4.981884479522705
INFO:root:current mean train loss 2025.931566808008
INFO:root:current train perplexity4.945346355438232
INFO:root:current mean train loss 2284.50545211506
INFO:root:current train perplexity6.064680099487305
INFO:root:current mean train loss 2753.170048672961
INFO:root:current train perplexity8.777006149291992
INFO:root:current mean train loss 3053.0947062725836
INFO:root:current train perplexity11.114507675170898
INFO:root:current mean train loss 2994.85059756806
INFO:root:current train perplexity10.608819961547852
INFO:root:current mean train loss 2935.7959343954726
INFO:root:current train perplexity10.133984565734863
INFO:root:current mean train loss 2885.330600762926
INFO:root:current train perplexity9.740399360656738
INFO:root:current mean train loss 2840.5749509288685
INFO:root:current train perplexity9.395206451416016
INFO:root:current mean train loss 2800.1112795855292
INFO:root:current train perplexity9.101183891296387
INFO:root:current mean train loss 2762.1839419400126
INFO:root:current train perplexity8.834792137145996
INFO:root:current mean train loss 2729.1904935261527
INFO:root:current train perplexity8.608631134033203
INFO:root:current mean train loss 2711.8672524078643
INFO:root:current train perplexity8.488164901733398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.77s/it]
INFO:root:final mean train loss: 2702.433544195486
INFO:root:final train perplexity: 8.42582893371582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 2154.210726257757
INFO:root:eval perplexity: 5.70988655090332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it]
INFO:root:eval mean loss: 2571.9641918425864
INFO:root:eval perplexity: 8.194171905517578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [3:40:44<10:55:49, 524.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2343.9041035970054
INFO:root:current train perplexity6.403231620788574
INFO:root:current mean train loss 2363.5392318233366
INFO:root:current train perplexity6.401620388031006
INFO:root:current mean train loss 2332.0880017961777
INFO:root:current train perplexity6.243524551391602
INFO:root:current mean train loss 2309.2338708948205
INFO:root:current train perplexity6.143398284912109
INFO:root:current mean train loss 2300.5313916476266
INFO:root:current train perplexity6.10825252532959
INFO:root:current mean train loss 2281.8646689844495
INFO:root:current train perplexity6.032651901245117
INFO:root:current mean train loss 2271.971900744316
INFO:root:current train perplexity5.9850568771362305
INFO:root:current mean train loss 2259.19492217849
INFO:root:current train perplexity5.95080041885376
INFO:root:current mean train loss 2253.185381250474
INFO:root:current train perplexity5.915419101715088
INFO:root:current mean train loss 2247.4654758998327
INFO:root:current train perplexity5.892201900482178
INFO:root:current mean train loss 2246.2112069129944
INFO:root:current train perplexity5.876959800720215
INFO:root:current mean train loss 2242.5712772247207
INFO:root:current train perplexity5.856008529663086
INFO:root:current mean train loss 2242.319304322885
INFO:root:current train perplexity5.851140022277832
INFO:root:current mean train loss 2241.868219657967
INFO:root:current train perplexity5.84545373916626
INFO:root:current mean train loss 2241.8175919779233
INFO:root:current train perplexity5.8521904945373535
INFO:root:current mean train loss 2242.2456948588215
INFO:root:current train perplexity5.852263450622559
INFO:root:current mean train loss 2243.66360172967
INFO:root:current train perplexity5.857668876647949
INFO:root:current mean train loss 2245.6266080143832
INFO:root:current train perplexity5.865720748901367
INFO:root:current mean train loss 2246.2261218690037
INFO:root:current train perplexity5.87455940246582
INFO:root:current mean train loss 2247.995460177162
INFO:root:current train perplexity5.8827900886535645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.86s/it]
INFO:root:final mean train loss: 2248.296463051169
INFO:root:final train perplexity: 5.8893280029296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it]
INFO:root:eval mean loss: 2241.8300391663897
INFO:root:eval perplexity: 6.129177093505859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it]
INFO:root:eval mean loss: 2656.046659861896
INFO:root:eval perplexity: 8.777470588684082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [3:49:27<10:46:27, 524.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2292.495379192073
INFO:root:current train perplexity6.232314586639404
INFO:root:current mean train loss 2304.7063880000555
INFO:root:current train perplexity6.184873580932617
INFO:root:current mean train loss 2305.5953055100817
INFO:root:current train perplexity6.182857036590576
INFO:root:current mean train loss 2309.6174484655653
INFO:root:current train perplexity6.221304893493652
INFO:root:current mean train loss 2305.7338883795705
INFO:root:current train perplexity6.193390846252441
INFO:root:current mean train loss 2303.2499041037286
INFO:root:current train perplexity6.166143417358398
INFO:root:current mean train loss 2303.716543402947
INFO:root:current train perplexity6.168120861053467
INFO:root:current mean train loss 2304.885438247248
INFO:root:current train perplexity6.163845062255859
INFO:root:current mean train loss 2306.198729162409
INFO:root:current train perplexity6.1623711585998535
INFO:root:current mean train loss 2304.6458598835184
INFO:root:current train perplexity6.152193069458008
INFO:root:current mean train loss 2312.9392711335254
INFO:root:current train perplexity6.195690631866455
INFO:root:current mean train loss 2316.9225081394475
INFO:root:current train perplexity6.218588352203369
INFO:root:current mean train loss 2318.329102251051
INFO:root:current train perplexity6.2281341552734375
INFO:root:current mean train loss 2323.567900860336
INFO:root:current train perplexity6.248932838439941
INFO:root:current mean train loss 2324.5117375561135
INFO:root:current train perplexity6.255430698394775
INFO:root:current mean train loss 2344.9470591907143
INFO:root:current train perplexity6.354111671447754
INFO:root:current mean train loss 2361.5323040745448
INFO:root:current train perplexity6.4347734451293945
INFO:root:current mean train loss 2362.4469108428166
INFO:root:current train perplexity6.438169956207275
INFO:root:current mean train loss 2360.365134981519
INFO:root:current train perplexity6.42905330657959
INFO:root:current mean train loss 2359.960779267694
INFO:root:current train perplexity6.426942348480225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.27s/it]
INFO:root:final mean train loss: 2358.0821233413703
INFO:root:final train perplexity: 6.421973705291748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 2169.4362169630986
INFO:root:eval perplexity: 5.780630588531494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 2599.3531520113033
INFO:root:eval perplexity: 8.379783630371094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [3:58:11<10:37:24, 523.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2289.932996026401
INFO:root:current train perplexity6.017033100128174
INFO:root:current mean train loss 2669.507984016515
INFO:root:current train perplexity8.19948959350586
INFO:root:current mean train loss 3155.4931498682777
INFO:root:current train perplexity12.087112426757812
INFO:root:current mean train loss 3844.698190358764
INFO:root:current train perplexity20.894269943237305
INFO:root:current mean train loss 4789.809286725573
INFO:root:current train perplexity44.040523529052734
INFO:root:current mean train loss 5268.491656341006
INFO:root:current train perplexity64.14176177978516
INFO:root:current mean train loss 5542.247373818626
INFO:root:current train perplexity79.61772918701172
INFO:root:current mean train loss 5742.166802157199
INFO:root:current train perplexity92.75358581542969
INFO:root:current mean train loss 5883.207991308821
INFO:root:current train perplexity103.82505798339844
INFO:root:current mean train loss 6005.0602451396135
INFO:root:current train perplexity113.70455932617188
INFO:root:current mean train loss 6096.34439658037
INFO:root:current train perplexity122.31796264648438
INFO:root:current mean train loss 6173.213599012306
INFO:root:current train perplexity130.08348083496094
INFO:root:current mean train loss 6219.599335347526
INFO:root:current train perplexity135.14364624023438
INFO:root:current mean train loss 6260.420075406733
INFO:root:current train perplexity139.770263671875
INFO:root:current mean train loss 6294.383361062886
INFO:root:current train perplexity143.7068328857422
INFO:root:current mean train loss 6326.8349972922015
INFO:root:current train perplexity147.10043334960938
INFO:root:current mean train loss 6347.7367254057035
INFO:root:current train perplexity149.6922607421875
INFO:root:current mean train loss 6368.834118805105
INFO:root:current train perplexity152.10418701171875
INFO:root:current mean train loss 6255.727666126001
INFO:root:current train perplexity139.1289825439453
INFO:root:current mean train loss 6099.37798878998
INFO:root:current train perplexity122.54383850097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.18s/it]
INFO:root:final mean train loss: 6060.82960369439
INFO:root:final train perplexity: 119.09664916992188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it]
INFO:root:eval mean loss: 2627.729115154726
INFO:root:eval perplexity: 8.374178886413574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2971.3408562409963
INFO:root:eval perplexity: 11.359383583068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:07:09<10:34:04, 528.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.2074055989583
INFO:root:current train perplexity13.274250984191895
INFO:root:current mean train loss 2989.3336146763395
INFO:root:current train perplexity10.52734088897705
INFO:root:current mean train loss 3071.707624289773
INFO:root:current train perplexity11.233680725097656
INFO:root:current mean train loss 3075.1255859375
INFO:root:current train perplexity11.252053260803223
INFO:root:current mean train loss 3043.0209267064147
INFO:root:current train perplexity10.986895561218262
INFO:root:current mean train loss 2965.391489045516
INFO:root:current train perplexity10.32390308380127
INFO:root:current mean train loss 2888.0876989293984
INFO:root:current train perplexity9.741783142089844
INFO:root:current mean train loss 2839.3619446194557
INFO:root:current train perplexity9.367426872253418
INFO:root:current mean train loss 2798.191458984375
INFO:root:current train perplexity9.05276870727539
INFO:root:current mean train loss 2751.644989858774
INFO:root:current train perplexity8.736205101013184
INFO:root:current mean train loss 2711.55946754633
INFO:root:current train perplexity8.44977855682373
INFO:root:current mean train loss 2673.2315647855717
INFO:root:current train perplexity8.217103958129883
INFO:root:current mean train loss 2642.6994161688112
INFO:root:current train perplexity8.027711868286133
INFO:root:current mean train loss 2614.6671938920454
INFO:root:current train perplexity7.857124328613281
INFO:root:current mean train loss 2589.497397709216
INFO:root:current train perplexity7.700628757476807
INFO:root:current mean train loss 2565.3653194754465
INFO:root:current train perplexity7.552090167999268
INFO:root:current mean train loss 2543.3558229361006
INFO:root:current train perplexity7.419393062591553
INFO:root:current mean train loss 2522.469435175506
INFO:root:current train perplexity7.30043363571167
INFO:root:current mean train loss 2503.525926106771
INFO:root:current train perplexity7.195033073425293
INFO:root:current mean train loss 2486.965730196796
INFO:root:current train perplexity7.104569435119629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.58s/it]
INFO:root:final mean train loss: 2485.041956852977
INFO:root:final train perplexity: 7.098288059234619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it]
INFO:root:eval mean loss: 2094.0522339732934
INFO:root:eval perplexity: 5.438734531402588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.68s/it]
INFO:root:eval mean loss: 2532.0844345633864
INFO:root:eval perplexity: 7.931230545043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:15:49<10:22:17, 525.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2173.8149745775304
INFO:root:current train perplexity5.523049831390381
INFO:root:current mean train loss 2170.485792795817
INFO:root:current train perplexity5.514287948608398
INFO:root:current mean train loss 2169.904783484054
INFO:root:current train perplexity5.5330586433410645
INFO:root:current mean train loss 2166.455339704241
INFO:root:current train perplexity5.531050682067871
INFO:root:current mean train loss 2182.4791721250954
INFO:root:current train perplexity5.60020112991333
INFO:root:current mean train loss 2188.9000677160316
INFO:root:current train perplexity5.6089935302734375
INFO:root:current mean train loss 2187.81924632519
INFO:root:current train perplexity5.615614414215088
INFO:root:current mean train loss 2189.3208824697167
INFO:root:current train perplexity5.621067047119141
INFO:root:current mean train loss 2190.415985244272
INFO:root:current train perplexity5.622448921203613
INFO:root:current mean train loss 2192.3782216964228
INFO:root:current train perplexity5.634424209594727
INFO:root:current mean train loss 2194.7610863765954
INFO:root:current train perplexity5.641052722930908
INFO:root:current mean train loss 2196.965151076349
INFO:root:current train perplexity5.647684574127197
INFO:root:current mean train loss 2198.869584783312
INFO:root:current train perplexity5.65800666809082
INFO:root:current mean train loss 2200.272568801354
INFO:root:current train perplexity5.663437843322754
INFO:root:current mean train loss 2198.969981584728
INFO:root:current train perplexity5.661808013916016
INFO:root:current mean train loss 2199.50327542559
INFO:root:current train perplexity5.668857097625732
INFO:root:current mean train loss 2202.3094638256316
INFO:root:current train perplexity5.679365634918213
INFO:root:current mean train loss 2206.18646805627
INFO:root:current train perplexity5.6925272941589355
INFO:root:current mean train loss 2208.1635300231032
INFO:root:current train perplexity5.7016801834106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.60s/it]
INFO:root:final mean train loss: 2209.586402881524
INFO:root:final train perplexity: 5.712249279022217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.25s/it]
INFO:root:eval mean loss: 2132.395307824967
INFO:root:eval perplexity: 5.610029697418213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it]
INFO:root:eval mean loss: 2562.788746069509
INFO:root:eval perplexity: 8.13291072845459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:24:45<10:16:59, 528.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2299.707329644097
INFO:root:current train perplexity5.935065746307373
INFO:root:current mean train loss 2245.50176386002
INFO:root:current train perplexity5.878477096557617
INFO:root:current mean train loss 2240.6813538473757
INFO:root:current train perplexity5.86569881439209
INFO:root:current mean train loss 2245.712405109097
INFO:root:current train perplexity5.870723247528076
INFO:root:current mean train loss 2234.9881612689105
INFO:root:current train perplexity5.817361831665039
INFO:root:current mean train loss 2225.439543778395
INFO:root:current train perplexity5.7672343254089355
INFO:root:current mean train loss 2215.1185420996253
INFO:root:current train perplexity5.735315322875977
INFO:root:current mean train loss 2209.161986443825
INFO:root:current train perplexity5.700285911560059
INFO:root:current mean train loss 2202.267179321742
INFO:root:current train perplexity5.678499698638916
INFO:root:current mean train loss 2201.5037167657197
INFO:root:current train perplexity5.669151782989502
INFO:root:current mean train loss 2198.3695548655846
INFO:root:current train perplexity5.655899524688721
INFO:root:current mean train loss 2193.9890556094665
INFO:root:current train perplexity5.6483306884765625
INFO:root:current mean train loss 2192.8851836325216
INFO:root:current train perplexity5.643211364746094
INFO:root:current mean train loss 2192.5381898231594
INFO:root:current train perplexity5.6446638107299805
INFO:root:current mean train loss 2193.4140770548706
INFO:root:current train perplexity5.645602703094482
INFO:root:current mean train loss 2192.4969898221348
INFO:root:current train perplexity5.641879081726074
INFO:root:current mean train loss 2192.5583911845965
INFO:root:current train perplexity5.639801979064941
INFO:root:current mean train loss 2192.0617752209123
INFO:root:current train perplexity5.63206148147583
INFO:root:current mean train loss 2190.9307847157443
INFO:root:current train perplexity5.626284122467041
INFO:root:current mean train loss 2191.2210085245874
INFO:root:current train perplexity5.62624454498291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.07s/it]
INFO:root:final mean train loss: 2190.7329828567235
INFO:root:final train perplexity: 5.627940654754639
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 2100.0851332211323
INFO:root:eval perplexity: 5.465335845947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it]
INFO:root:eval mean loss: 2538.0262503116687
INFO:root:eval perplexity: 7.969865322113037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [4:33:28<10:06:03, 527.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2193.904611440805
INFO:root:current train perplexity5.63296365737915
INFO:root:current mean train loss 2193.6538851298983
INFO:root:current train perplexity5.571763038635254
INFO:root:current mean train loss 2189.0337319163095
INFO:root:current train perplexity5.579085826873779
INFO:root:current mean train loss 2178.3701744781683
INFO:root:current train perplexity5.559389114379883
INFO:root:current mean train loss 2190.4818510673417
INFO:root:current train perplexity5.592833995819092
INFO:root:current mean train loss 2190.3720468731435
INFO:root:current train perplexity5.5949225425720215
INFO:root:current mean train loss 2182.953486335925
INFO:root:current train perplexity5.57666540145874
INFO:root:current mean train loss 2177.778852310391
INFO:root:current train perplexity5.560524940490723
INFO:root:current mean train loss 2182.8590658340268
INFO:root:current train perplexity5.574358940124512
INFO:root:current mean train loss 2182.2554126187483
INFO:root:current train perplexity5.5825958251953125
INFO:root:current mean train loss 2181.0973024126615
INFO:root:current train perplexity5.578606128692627
INFO:root:current mean train loss 2178.8276654475535
INFO:root:current train perplexity5.576414108276367
INFO:root:current mean train loss 2177.253919492538
INFO:root:current train perplexity5.570827484130859
INFO:root:current mean train loss 2178.010302053138
INFO:root:current train perplexity5.572264194488525
INFO:root:current mean train loss 2177.623396650103
INFO:root:current train perplexity5.573293209075928
INFO:root:current mean train loss 2178.358706573046
INFO:root:current train perplexity5.577090263366699
INFO:root:current mean train loss 2179.2500591583066
INFO:root:current train perplexity5.577666759490967
INFO:root:current mean train loss 2178.3978687343842
INFO:root:current train perplexity5.5701775550842285
INFO:root:current mean train loss 2180.4880508807246
INFO:root:current train perplexity5.581774711608887
INFO:root:current mean train loss 2179.9844372393804
INFO:root:current train perplexity5.580726146697998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.79s/it]
INFO:root:final mean train loss: 2179.9508975707577
INFO:root:final train perplexity: 5.580288887023926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.28s/it]
INFO:root:eval mean loss: 2079.0133056640625
INFO:root:eval perplexity: 5.372986316680908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2522.145921639517
INFO:root:eval perplexity: 7.867027282714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [4:42:20<9:58:52, 528.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2194.2078630314318
INFO:root:current train perplexity5.637277603149414
INFO:root:current mean train loss 2194.4996175699303
INFO:root:current train perplexity5.623284816741943
INFO:root:current mean train loss 2192.9366419913836
INFO:root:current train perplexity5.5728373527526855
INFO:root:current mean train loss 2178.3835292627095
INFO:root:current train perplexity5.536949157714844
INFO:root:current mean train loss 2169.475737492064
INFO:root:current train perplexity5.530320167541504
INFO:root:current mean train loss 2171.922333831506
INFO:root:current train perplexity5.545184135437012
INFO:root:current mean train loss 2175.376349797701
INFO:root:current train perplexity5.562963962554932
INFO:root:current mean train loss 2176.3227609708847
INFO:root:current train perplexity5.571014881134033
INFO:root:current mean train loss 2178.6055788015274
INFO:root:current train perplexity5.580951690673828
INFO:root:current mean train loss 2179.4666450314407
INFO:root:current train perplexity5.57794713973999
INFO:root:current mean train loss 2178.1853082351463
INFO:root:current train perplexity5.576305866241455
INFO:root:current mean train loss 2177.8075653903857
INFO:root:current train perplexity5.576868057250977
INFO:root:current mean train loss 2178.6224033297403
INFO:root:current train perplexity5.576959609985352
INFO:root:current mean train loss 2179.8062366931545
INFO:root:current train perplexity5.578746318817139
INFO:root:current mean train loss 2181.1781597177105
INFO:root:current train perplexity5.585070610046387
INFO:root:current mean train loss 2182.750967148134
INFO:root:current train perplexity5.594372272491455
INFO:root:current mean train loss 2189.9123154011572
INFO:root:current train perplexity5.623955726623535
INFO:root:current mean train loss 2198.7572342242856
INFO:root:current train perplexity5.661220550537109
INFO:root:current mean train loss 2210.7851841347538
INFO:root:current train perplexity5.712838649749756
INFO:root:current mean train loss 2216.328892290132
INFO:root:current train perplexity5.737799644470215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.30s/it]
INFO:root:final mean train loss: 2218.167337714814
INFO:root:final train perplexity: 5.751037120819092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.30s/it]
INFO:root:eval mean loss: 2121.96142578125
INFO:root:eval perplexity: 5.562890529632568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it]
INFO:root:eval mean loss: 2562.0858924811614
INFO:root:eval perplexity: 8.128236770629883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [4:51:08<9:49:54, 528.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2287.896124267578
INFO:root:current train perplexity6.10329008102417
INFO:root:current mean train loss 2305.9039726257324
INFO:root:current train perplexity6.206686019897461
INFO:root:current mean train loss 2303.561788236178
INFO:root:current train perplexity6.173710823059082
INFO:root:current mean train loss 2289.5168887668187
INFO:root:current train perplexity6.115759372711182
INFO:root:current mean train loss 2291.8301219110904
INFO:root:current train perplexity6.127818584442139
INFO:root:current mean train loss 2283.258264378139
INFO:root:current train perplexity6.08406925201416
INFO:root:current mean train loss 2273.9407829515862
INFO:root:current train perplexity6.04739236831665
INFO:root:current mean train loss 2272.3530968917044
INFO:root:current train perplexity6.018054008483887
INFO:root:current mean train loss 2267.370075172602
INFO:root:current train perplexity5.995481491088867
INFO:root:current mean train loss 2265.6653798421225
INFO:root:current train perplexity5.983621597290039
INFO:root:current mean train loss 2263.095670764851
INFO:root:current train perplexity5.965429306030273
INFO:root:current mean train loss 2261.2010569605336
INFO:root:current train perplexity5.952038288116455
INFO:root:current mean train loss 2259.063900514633
INFO:root:current train perplexity5.942900657653809
INFO:root:current mean train loss 2258.7771093929514
INFO:root:current train perplexity5.936121940612793
INFO:root:current mean train loss 2258.372459683353
INFO:root:current train perplexity5.927826881408691
INFO:root:current mean train loss 2257.7301671737278
INFO:root:current train perplexity5.921896934509277
INFO:root:current mean train loss 2257.3555347120905
INFO:root:current train perplexity5.921016693115234
INFO:root:current mean train loss 2255.941836339777
INFO:root:current train perplexity5.915744304656982
INFO:root:current mean train loss 2254.2845993206065
INFO:root:current train perplexity5.912385940551758
INFO:root:current mean train loss 2252.587080227599
INFO:root:current train perplexity5.906932830810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.74s/it]
INFO:root:final mean train loss: 2251.7131267630325
INFO:root:final train perplexity: 5.90521764755249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it]
INFO:root:eval mean loss: 2114.752686845495
INFO:root:eval perplexity: 5.530552864074707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it]
INFO:root:eval mean loss: 2553.611868783937
INFO:root:eval perplexity: 8.072102546691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [4:59:55<9:40:45, 527.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2226.3144325157264
INFO:root:current train perplexity5.74289083480835
INFO:root:current mean train loss 2223.8870090980313
INFO:root:current train perplexity5.7927165031433105
INFO:root:current mean train loss 2227.602212513397
INFO:root:current train perplexity5.8067307472229
INFO:root:current mean train loss 2225.1565954881257
INFO:root:current train perplexity5.794823169708252
INFO:root:current mean train loss 2223.5368097013397
INFO:root:current train perplexity5.778815269470215
INFO:root:current mean train loss 2220.858545471932
INFO:root:current train perplexity5.774643421173096
INFO:root:current mean train loss 2217.388390951002
INFO:root:current train perplexity5.761133193969727
INFO:root:current mean train loss 2217.333485410634
INFO:root:current train perplexity5.752282619476318
INFO:root:current mean train loss 2221.1810032704266
INFO:root:current train perplexity5.765326499938965
INFO:root:current mean train loss 2221.0320938719456
INFO:root:current train perplexity5.760745048522949
INFO:root:current mean train loss 2218.7644183513958
INFO:root:current train perplexity5.753880500793457
INFO:root:current mean train loss 2217.496923454758
INFO:root:current train perplexity5.757008075714111
INFO:root:current mean train loss 2218.1303804617146
INFO:root:current train perplexity5.7580037117004395
INFO:root:current mean train loss 2216.157706067453
INFO:root:current train perplexity5.749233722686768
INFO:root:current mean train loss 2217.6534663505786
INFO:root:current train perplexity5.751675605773926
INFO:root:current mean train loss 2218.5389177495344
INFO:root:current train perplexity5.751070976257324
INFO:root:current mean train loss 2218.161403885752
INFO:root:current train perplexity5.748579978942871
INFO:root:current mean train loss 2218.2535732185565
INFO:root:current train perplexity5.74876070022583
INFO:root:current mean train loss 2219.3364518602034
INFO:root:current train perplexity5.751185894012451
INFO:root:current mean train loss 2218.4300231470506
INFO:root:current train perplexity5.749556541442871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.86s/it]
INFO:root:final mean train loss: 2217.7559299209292
INFO:root:final train perplexity: 5.749169826507568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.38s/it]
INFO:root:eval mean loss: 2140.3581343846963
INFO:root:eval perplexity: 5.646275043487549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it]
INFO:root:eval mean loss: 2585.1787451345026
INFO:root:eval perplexity: 8.283208847045898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:08:37<9:29:59, 526.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2249.2218381191824
INFO:root:current train perplexity5.792742729187012
INFO:root:current mean train loss 2222.126376751772
INFO:root:current train perplexity5.714174270629883
INFO:root:current mean train loss 2224.011476685401
INFO:root:current train perplexity5.754169940948486
INFO:root:current mean train loss 2231.391700705901
INFO:root:current train perplexity5.805063247680664
INFO:root:current mean train loss 2237.9876328441296
INFO:root:current train perplexity5.840386390686035
INFO:root:current mean train loss 2239.396920663339
INFO:root:current train perplexity5.84935998916626
INFO:root:current mean train loss 2253.234041681207
INFO:root:current train perplexity5.9104132652282715
INFO:root:current mean train loss 2256.7219164485596
INFO:root:current train perplexity5.91166353225708
INFO:root:current mean train loss 2253.3703550471023
INFO:root:current train perplexity5.8904619216918945
INFO:root:current mean train loss 2250.0327745280274
INFO:root:current train perplexity5.877429485321045
INFO:root:current mean train loss 2248.2918287203997
INFO:root:current train perplexity5.879715442657471
INFO:root:current mean train loss 2247.340358510489
INFO:root:current train perplexity5.879973888397217
INFO:root:current mean train loss 2245.5141444965343
INFO:root:current train perplexity5.871668815612793
INFO:root:current mean train loss 2245.375561751115
INFO:root:current train perplexity5.868285179138184
INFO:root:current mean train loss 2245.373145250272
INFO:root:current train perplexity5.865930557250977
INFO:root:current mean train loss 2244.6798574335153
INFO:root:current train perplexity5.8608222007751465
INFO:root:current mean train loss 2245.064771848136
INFO:root:current train perplexity5.859026908874512
INFO:root:current mean train loss 2243.902985673817
INFO:root:current train perplexity5.854076385498047
INFO:root:current mean train loss 2242.553376243132
INFO:root:current train perplexity5.855578422546387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.27s/it]
INFO:root:final mean train loss: 2240.902829261122
INFO:root:final train perplexity: 5.855086803436279
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 2102.1349370428857
INFO:root:eval perplexity: 5.4744038581848145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it]
INFO:root:eval mean loss: 2542.303220059009
INFO:root:eval perplexity: 7.997791767120361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:17:37<9:25:50, 530.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2309.4848410866475
INFO:root:current train perplexity5.998049736022949
INFO:root:current mean train loss 2242.535497167089
INFO:root:current train perplexity5.861896514892578
INFO:root:current mean train loss 2243.4057206429575
INFO:root:current train perplexity5.870940208435059
INFO:root:current mean train loss 2247.588822833978
INFO:root:current train perplexity5.882596015930176
INFO:root:current mean train loss 2259.4579662313718
INFO:root:current train perplexity5.918676853179932
INFO:root:current mean train loss 2299.3434325216335
INFO:root:current train perplexity6.110203266143799
INFO:root:current mean train loss 2320.296779701245
INFO:root:current train perplexity6.210814952850342
INFO:root:current mean train loss 2342.984384099475
INFO:root:current train perplexity6.335209369659424
INFO:root:current mean train loss 2346.6979021667407
INFO:root:current train perplexity6.353841304779053
INFO:root:current mean train loss 2360.5805814137966
INFO:root:current train perplexity6.414623737335205
INFO:root:current mean train loss 2362.8060197688706
INFO:root:current train perplexity6.42886209487915
INFO:root:current mean train loss 2363.606018341092
INFO:root:current train perplexity6.442111492156982
INFO:root:current mean train loss 2362.474925588518
INFO:root:current train perplexity6.436549663543701
INFO:root:current mean train loss 2361.4651128447395
INFO:root:current train perplexity6.431110858917236
INFO:root:current mean train loss 2360.084130755559
INFO:root:current train perplexity6.427762985229492
INFO:root:current mean train loss 2363.485042145361
INFO:root:current train perplexity6.44516134262085
INFO:root:current mean train loss 2364.1030047633944
INFO:root:current train perplexity6.450685501098633
INFO:root:current mean train loss 2365.4622085722895
INFO:root:current train perplexity6.454832553863525
INFO:root:current mean train loss 2366.5514902149625
INFO:root:current train perplexity6.457851886749268
INFO:root:current mean train loss 2365.4416340379303
INFO:root:current train perplexity6.45458984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.81s/it]
INFO:root:final mean train loss: 2364.683478327995
INFO:root:final train perplexity: 6.455493450164795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it]
INFO:root:eval mean loss: 2150.5624978356327
INFO:root:eval perplexity: 5.693063735961914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it]
INFO:root:eval mean loss: 2589.033336017149
INFO:root:eval perplexity: 8.309359550476074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [5:26:26<9:16:22, 529.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2366.7803780691966
INFO:root:current train perplexity6.698984622955322
INFO:root:current mean train loss 2507.167890548706
INFO:root:current train perplexity7.152623653411865
INFO:root:current mean train loss 2436.862553111294
INFO:root:current train perplexity6.819033145904541
INFO:root:current mean train loss 2499.2910357219416
INFO:root:current train perplexity7.20326566696167
INFO:root:current mean train loss 2567.5761342271467
INFO:root:current train perplexity7.61363410949707
INFO:root:current mean train loss 2622.4371458111386
INFO:root:current train perplexity7.920912265777588
INFO:root:current mean train loss 2668.2263739519058
INFO:root:current train perplexity8.204313278198242
INFO:root:current mean train loss 2681.649563296811
INFO:root:current train perplexity8.297538757324219
INFO:root:current mean train loss 2667.10723464155
INFO:root:current train perplexity8.190134048461914
INFO:root:current mean train loss 2647.7015075683594
INFO:root:current train perplexity8.048885345458984
INFO:root:current mean train loss 2625.4539205944493
INFO:root:current train perplexity7.896795272827148
INFO:root:current mean train loss 2603.257317725648
INFO:root:current train perplexity7.770230770111084
INFO:root:current mean train loss 2582.776414802874
INFO:root:current train perplexity7.6600341796875
INFO:root:current mean train loss 2567.5643995353976
INFO:root:current train perplexity7.5620880126953125
INFO:root:current mean train loss 2559.0056989226355
INFO:root:current train perplexity7.508808612823486
INFO:root:current mean train loss 2545.750439069658
INFO:root:current train perplexity7.427445888519287
INFO:root:current mean train loss 2531.0925860580705
INFO:root:current train perplexity7.346498489379883
INFO:root:current mean train loss 2518.5847745118317
INFO:root:current train perplexity7.2687087059021
INFO:root:current mean train loss 2505.460546781511
INFO:root:current train perplexity7.204638957977295
INFO:root:current mean train loss 2492.3899752668326
INFO:root:current train perplexity7.134496212005615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.82s/it]
INFO:root:final mean train loss: 2485.4105660442865
INFO:root:final train perplexity: 7.100351333618164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it]
INFO:root:eval mean loss: 2130.126872177665
INFO:root:eval perplexity: 5.599747180938721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 2571.9937657565933
INFO:root:eval perplexity: 8.194369316101074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [5:35:09<9:05:29, 527.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2256.06663140191
INFO:root:current train perplexity5.927894115447998
INFO:root:current mean train loss 2264.7555983970906
INFO:root:current train perplexity5.968599796295166
INFO:root:current mean train loss 2260.769327467315
INFO:root:current train perplexity5.933294773101807
INFO:root:current mean train loss 2258.4257097769473
INFO:root:current train perplexity5.907104015350342
INFO:root:current mean train loss 2249.219786911868
INFO:root:current train perplexity5.888326168060303
INFO:root:current mean train loss 2241.8411155210724
INFO:root:current train perplexity5.866092681884766
INFO:root:current mean train loss 2238.962254534581
INFO:root:current train perplexity5.841336250305176
INFO:root:current mean train loss 2236.1891300073407
INFO:root:current train perplexity5.833590507507324
INFO:root:current mean train loss 2231.677363107896
INFO:root:current train perplexity5.811518669128418
INFO:root:current mean train loss 2224.6720187717015
INFO:root:current train perplexity5.7816643714904785
INFO:root:current mean train loss 2220.23142288427
INFO:root:current train perplexity5.764490127563477
INFO:root:current mean train loss 2221.4123603387693
INFO:root:current train perplexity5.7695231437683105
INFO:root:current mean train loss 2221.202257957612
INFO:root:current train perplexity5.773877143859863
INFO:root:current mean train loss 2219.208958145766
INFO:root:current train perplexity5.7593092918396
INFO:root:current mean train loss 2215.6136734800766
INFO:root:current train perplexity5.741335391998291
INFO:root:current mean train loss 2211.1118264405086
INFO:root:current train perplexity5.720509052276611
INFO:root:current mean train loss 2206.993303348808
INFO:root:current train perplexity5.69771146774292
INFO:root:current mean train loss 2203.2849908080007
INFO:root:current train perplexity5.679597854614258
INFO:root:current mean train loss 2198.775816448594
INFO:root:current train perplexity5.659385681152344
INFO:root:current mean train loss 2194.0666421061615
INFO:root:current train perplexity5.638676166534424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.63s/it]
INFO:root:final mean train loss: 2192.1848758268525
INFO:root:final train perplexity: 5.634389877319336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 2041.7061884453956
INFO:root:eval perplexity: 5.213294506072998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it]
INFO:root:eval mean loss: 2489.481241429106
INFO:root:eval perplexity: 7.659648895263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [5:44:04<8:58:56, 530.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2099.810513404108
INFO:root:current train perplexity5.220846176147461
INFO:root:current mean train loss 2105.862043969425
INFO:root:current train perplexity5.21440315246582
INFO:root:current mean train loss 2091.135665311158
INFO:root:current train perplexity5.187832832336426
INFO:root:current mean train loss 2087.5898026102814
INFO:root:current train perplexity5.17716646194458
INFO:root:current mean train loss 2086.2455465473654
INFO:root:current train perplexity5.165024280548096
INFO:root:current mean train loss 2081.2328517275773
INFO:root:current train perplexity5.157339096069336
INFO:root:current mean train loss 2082.650379930018
INFO:root:current train perplexity5.162538051605225
INFO:root:current mean train loss 2083.6015660243397
INFO:root:current train perplexity5.1566925048828125
INFO:root:current mean train loss 2082.325745903422
INFO:root:current train perplexity5.148133277893066
INFO:root:current mean train loss 2082.1338428648
INFO:root:current train perplexity5.143550395965576
INFO:root:current mean train loss 2083.889119466146
INFO:root:current train perplexity5.150783538818359
INFO:root:current mean train loss 2079.900562805071
INFO:root:current train perplexity5.136107921600342
INFO:root:current mean train loss 2076.7698530629395
INFO:root:current train perplexity5.125871181488037
INFO:root:current mean train loss 2076.976310920435
INFO:root:current train perplexity5.125425815582275
INFO:root:current mean train loss 2076.6611196202225
INFO:root:current train perplexity5.1260762214660645
INFO:root:current mean train loss 2076.7413715357666
INFO:root:current train perplexity5.126717567443848
INFO:root:current mean train loss 2079.471882623886
INFO:root:current train perplexity5.141569137573242
INFO:root:current mean train loss 2083.660001064132
INFO:root:current train perplexity5.159800052642822
INFO:root:current mean train loss 2083.667824127492
INFO:root:current train perplexity5.164222717285156
INFO:root:current mean train loss 2083.3217092158234
INFO:root:current train perplexity5.166667461395264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.14s/it]
INFO:root:final mean train loss: 2082.4632960794193
INFO:root:final train perplexity: 5.167328357696533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 2015.293402922069
INFO:root:eval perplexity: 5.103114128112793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.00s/it]
INFO:root:eval mean loss: 2458.8272484312665
INFO:root:eval perplexity: 7.470012664794922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [5:52:41<8:46:05, 526.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2055.805457006527
INFO:root:current train perplexity5.0784010887146
INFO:root:current mean train loss 2053.581503415241
INFO:root:current train perplexity5.085174083709717
INFO:root:current mean train loss 2056.3995028806844
INFO:root:current train perplexity5.08419942855835
INFO:root:current mean train loss 2060.617166242373
INFO:root:current train perplexity5.094813346862793
INFO:root:current mean train loss 2057.532343026243
INFO:root:current train perplexity5.085427284240723
INFO:root:current mean train loss 2056.575316750324
INFO:root:current train perplexity5.0785722732543945
INFO:root:current mean train loss 2053.934030074961
INFO:root:current train perplexity5.06837797164917
INFO:root:current mean train loss 2055.1655810922957
INFO:root:current train perplexity5.06417179107666
INFO:root:current mean train loss 2058.786467221274
INFO:root:current train perplexity5.069263935089111
INFO:root:current mean train loss 2057.28442943912
INFO:root:current train perplexity5.067027568817139
INFO:root:current mean train loss 2056.3424589282613
INFO:root:current train perplexity5.065103530883789
INFO:root:current mean train loss 2058.6951950888597
INFO:root:current train perplexity5.065331935882568
INFO:root:current mean train loss 2055.99707269855
INFO:root:current train perplexity5.054343223571777
INFO:root:current mean train loss 2055.8367238310993
INFO:root:current train perplexity5.053825855255127
INFO:root:current mean train loss 2055.605045837031
INFO:root:current train perplexity5.052720546722412
INFO:root:current mean train loss 2056.6767697953364
INFO:root:current train perplexity5.056989669799805
INFO:root:current mean train loss 2056.1198571973646
INFO:root:current train perplexity5.057547569274902
INFO:root:current mean train loss 2056.6888556735043
INFO:root:current train perplexity5.058922290802002
INFO:root:current mean train loss 2056.8377239233387
INFO:root:current train perplexity5.061567306518555
INFO:root:current mean train loss 2055.855306709216
INFO:root:current train perplexity5.05807638168335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.56s/it]
INFO:root:final mean train loss: 2055.489314046101
INFO:root:final train perplexity: 5.058563232421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.49s/it]
INFO:root:eval mean loss: 2003.5118330285904
INFO:root:eval perplexity: 5.054721355438232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.38s/it]
INFO:root:eval mean loss: 2446.9351823955562
INFO:root:eval perplexity: 7.397712707519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:01:26<8:36:57, 525.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2046.2062543233235
INFO:root:current train perplexity5.003920555114746
INFO:root:current mean train loss 2051.717684998804
INFO:root:current train perplexity5.026031494140625
INFO:root:current mean train loss 2064.7995725064666
INFO:root:current train perplexity5.0477166175842285
INFO:root:current mean train loss 2058.5559279316603
INFO:root:current train perplexity5.0265607833862305
INFO:root:current mean train loss 2053.898781314973
INFO:root:current train perplexity5.035248756408691
INFO:root:current mean train loss 2055.63019515684
INFO:root:current train perplexity5.0331525802612305
INFO:root:current mean train loss 2056.3396520505007
INFO:root:current train perplexity5.033398151397705
INFO:root:current mean train loss 2051.872138248616
INFO:root:current train perplexity5.015254974365234
INFO:root:current mean train loss 2049.6304033824376
INFO:root:current train perplexity5.013185977935791
INFO:root:current mean train loss 2047.8405284958192
INFO:root:current train perplexity5.009859561920166
INFO:root:current mean train loss 2047.5991996152557
INFO:root:current train perplexity5.010791778564453
INFO:root:current mean train loss 2048.0587567485695
INFO:root:current train perplexity5.0124993324279785
INFO:root:current mean train loss 2048.5941411713025
INFO:root:current train perplexity5.013061046600342
INFO:root:current mean train loss 2048.152665190164
INFO:root:current train perplexity5.011781215667725
INFO:root:current mean train loss 2046.1005385291767
INFO:root:current train perplexity5.009032249450684
INFO:root:current mean train loss 2044.8269452929198
INFO:root:current train perplexity5.004622936248779
INFO:root:current mean train loss 2042.5273297867684
INFO:root:current train perplexity4.999835014343262
INFO:root:current mean train loss 2040.3116975712087
INFO:root:current train perplexity4.996139049530029
INFO:root:current mean train loss 2039.980006801428
INFO:root:current train perplexity4.993468761444092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.53s/it]
INFO:root:final mean train loss: 2038.9916298424303
INFO:root:final train perplexity: 4.9931721687316895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 1991.8044844823526
INFO:root:eval perplexity: 5.007087230682373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 2438.859050777787
INFO:root:eval perplexity: 7.349013328552246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:10:24<8:31:43, 529.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1996.9798208383413
INFO:root:current train perplexity4.9035139083862305
INFO:root:current mean train loss 2030.230712890625
INFO:root:current train perplexity4.899205207824707
INFO:root:current mean train loss 2018.91181537467
INFO:root:current train perplexity4.929238319396973
INFO:root:current mean train loss 2018.0463036485373
INFO:root:current train perplexity4.924221515655518
INFO:root:current mean train loss 2023.0720933078276
INFO:root:current train perplexity4.930889129638672
INFO:root:current mean train loss 2021.8774066649914
INFO:root:current train perplexity4.932208061218262
INFO:root:current mean train loss 2024.887893253594
INFO:root:current train perplexity4.94118595123291
INFO:root:current mean train loss 2025.653240187807
INFO:root:current train perplexity4.942057132720947
INFO:root:current mean train loss 2022.847326975467
INFO:root:current train perplexity4.931872367858887
INFO:root:current mean train loss 2020.485780479874
INFO:root:current train perplexity4.926420211791992
INFO:root:current mean train loss 2021.226700597313
INFO:root:current train perplexity4.926363468170166
INFO:root:current mean train loss 2021.7025301128706
INFO:root:current train perplexity4.925296783447266
INFO:root:current mean train loss 2022.2022138502807
INFO:root:current train perplexity4.92155647277832
INFO:root:current mean train loss 2020.1817906794436
INFO:root:current train perplexity4.916823863983154
INFO:root:current mean train loss 2019.2032377400976
INFO:root:current train perplexity4.915071487426758
INFO:root:current mean train loss 2018.3858950779443
INFO:root:current train perplexity4.911056995391846
INFO:root:current mean train loss 2019.5667535411742
INFO:root:current train perplexity4.915435314178467
INFO:root:current mean train loss 2020.2359534339882
INFO:root:current train perplexity4.91675329208374
INFO:root:current mean train loss 2021.899024622518
INFO:root:current train perplexity4.923584461212158
INFO:root:current mean train loss 2025.008019247419
INFO:root:current train perplexity4.934406757354736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.54s/it]
INFO:root:final mean train loss: 2024.1619634508065
INFO:root:final train perplexity: 4.935113906860352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 1981.042051058289
INFO:root:eval perplexity: 4.963695526123047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it]
INFO:root:eval mean loss: 2425.0657283701794
INFO:root:eval perplexity: 7.266576766967773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [6:19:07<8:21:07, 527.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2050.7733561197915
INFO:root:current train perplexity4.981867790222168
INFO:root:current mean train loss 2029.7519211989184
INFO:root:current train perplexity4.9513678550720215
INFO:root:current mean train loss 2034.1328745966373
INFO:root:current train perplexity4.954349040985107
INFO:root:current mean train loss 2036.9230539032908
INFO:root:current train perplexity4.969663619995117
INFO:root:current mean train loss 2035.498457088027
INFO:root:current train perplexity4.962661266326904
INFO:root:current mean train loss 2036.1717904720667
INFO:root:current train perplexity4.964717864990234
INFO:root:current mean train loss 2033.505249798487
INFO:root:current train perplexity4.956714153289795
INFO:root:current mean train loss 2033.515802921661
INFO:root:current train perplexity4.963388442993164
INFO:root:current mean train loss 2032.438677610834
INFO:root:current train perplexity4.959623336791992
INFO:root:current mean train loss 2029.2592188025033
INFO:root:current train perplexity4.950353145599365
INFO:root:current mean train loss 2025.5432695407312
INFO:root:current train perplexity4.944428443908691
INFO:root:current mean train loss 2022.8562595063606
INFO:root:current train perplexity4.933104515075684
INFO:root:current mean train loss 2021.1761073662983
INFO:root:current train perplexity4.924786567687988
INFO:root:current mean train loss 2019.4468168100916
INFO:root:current train perplexity4.9228620529174805
INFO:root:current mean train loss 2019.2344263036769
INFO:root:current train perplexity4.918974876403809
INFO:root:current mean train loss 2020.9032345441433
INFO:root:current train perplexity4.918683052062988
INFO:root:current mean train loss 2019.4425743056222
INFO:root:current train perplexity4.9147257804870605
INFO:root:current mean train loss 2020.3443405945177
INFO:root:current train perplexity4.9132585525512695
INFO:root:current mean train loss 2019.6359651159069
INFO:root:current train perplexity4.909686088562012
INFO:root:current mean train loss 2016.9788500850066
INFO:root:current train perplexity4.9032182693481445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.87s/it]
INFO:root:final mean train loss: 2015.5997056523418
INFO:root:final train perplexity: 4.9019012451171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it]
INFO:root:eval mean loss: 1967.8758687770112
INFO:root:eval perplexity: 4.911121845245361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2412.0078583845857
INFO:root:eval perplexity: 7.189390659332275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [6:27:46<8:09:51, 524.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1977.7905507189162
INFO:root:current train perplexity4.801268577575684
INFO:root:current mean train loss 1990.656293181335
INFO:root:current train perplexity4.798941612243652
INFO:root:current mean train loss 1987.4179667731528
INFO:root:current train perplexity4.793156623840332
INFO:root:current mean train loss 1985.103749915571
INFO:root:current train perplexity4.793767929077148
INFO:root:current mean train loss 1982.6077260949735
INFO:root:current train perplexity4.782705783843994
INFO:root:current mean train loss 1975.8957432497573
INFO:root:current train perplexity4.768887042999268
INFO:root:current mean train loss 1978.4032520134997
INFO:root:current train perplexity4.7674078941345215
INFO:root:current mean train loss 1977.5451380718184
INFO:root:current train perplexity4.764669418334961
INFO:root:current mean train loss 1977.0792010058478
INFO:root:current train perplexity4.7617878913879395
INFO:root:current mean train loss 1975.6015670115744
INFO:root:current train perplexity4.759350776672363
INFO:root:current mean train loss 1975.3392553174622
INFO:root:current train perplexity4.756999969482422
INFO:root:current mean train loss 1975.693925347033
INFO:root:current train perplexity4.754382133483887
INFO:root:current mean train loss 1972.9323794098023
INFO:root:current train perplexity4.7436676025390625
INFO:root:current mean train loss 1973.0740071433336
INFO:root:current train perplexity4.741858959197998
INFO:root:current mean train loss 1973.137397433942
INFO:root:current train perplexity4.738286018371582
INFO:root:current mean train loss 1973.5718650891847
INFO:root:current train perplexity4.739480495452881
INFO:root:current mean train loss 1972.500589672985
INFO:root:current train perplexity4.736198902130127
INFO:root:current mean train loss 1972.128168517682
INFO:root:current train perplexity4.731590270996094
INFO:root:current mean train loss 1970.5602857489553
INFO:root:current train perplexity4.727415084838867
INFO:root:current mean train loss 1970.3899523906973
INFO:root:current train perplexity4.727235794067383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.40s/it]
INFO:root:final mean train loss: 1969.5857514705071
INFO:root:final train perplexity: 4.727203845977783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it]
INFO:root:eval mean loss: 1954.0908337315768
INFO:root:eval perplexity: 4.856674671173096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it]
INFO:root:eval mean loss: 2402.289990580674
INFO:root:eval perplexity: 7.1324782371521
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [6:36:28<8:00:19, 523.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.707571029663
INFO:root:current train perplexity4.73985481262207
INFO:root:current mean train loss 1961.3244085544493
INFO:root:current train perplexity4.653316974639893
INFO:root:current mean train loss 1949.7091702547941
INFO:root:current train perplexity4.636881351470947
INFO:root:current mean train loss 1945.5758868206988
INFO:root:current train perplexity4.62525749206543
INFO:root:current mean train loss 1940.795013164652
INFO:root:current train perplexity4.6235737800598145
INFO:root:current mean train loss 1945.7402858869405
INFO:root:current train perplexity4.638418197631836
INFO:root:current mean train loss 1949.0556526643684
INFO:root:current train perplexity4.640610694885254
INFO:root:current mean train loss 1945.291969339261
INFO:root:current train perplexity4.639313697814941
INFO:root:current mean train loss 1948.4717329519767
INFO:root:current train perplexity4.643531322479248
INFO:root:current mean train loss 1949.688557984918
INFO:root:current train perplexity4.643711090087891
INFO:root:current mean train loss 1949.0810047809343
INFO:root:current train perplexity4.645465850830078
INFO:root:current mean train loss 1950.7355039406477
INFO:root:current train perplexity4.650463581085205
INFO:root:current mean train loss 1949.521540195127
INFO:root:current train perplexity4.648736953735352
INFO:root:current mean train loss 1949.982714432076
INFO:root:current train perplexity4.654800891876221
INFO:root:current mean train loss 1950.3140327995593
INFO:root:current train perplexity4.658576965332031
INFO:root:current mean train loss 1949.852288443719
INFO:root:current train perplexity4.658749580383301
INFO:root:current mean train loss 1952.2395969537588
INFO:root:current train perplexity4.665615558624268
INFO:root:current mean train loss 1952.8329735580755
INFO:root:current train perplexity4.665105819702148
INFO:root:current mean train loss 1954.1731827371623
INFO:root:current train perplexity4.66839599609375
INFO:root:current mean train loss 1954.8212356101228
INFO:root:current train perplexity4.67067289352417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.86s/it]
INFO:root:final mean train loss: 1954.5218164518033
INFO:root:final train perplexity: 4.671375274658203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.78s/it]
INFO:root:eval mean loss: 1949.789136954233
INFO:root:eval perplexity: 4.839807987213135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 2396.3132263616467
INFO:root:eval perplexity: 7.097701072692871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [6:45:18<7:53:21, 525.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.4903669945988
INFO:root:current train perplexity4.664011478424072
INFO:root:current mean train loss 1949.32863823485
INFO:root:current train perplexity4.652567386627197
INFO:root:current mean train loss 1937.405825143183
INFO:root:current train perplexity4.6277546882629395
INFO:root:current mean train loss 1942.7409398837353
INFO:root:current train perplexity4.633374214172363
INFO:root:current mean train loss 1940.6140573227976
INFO:root:current train perplexity4.644047737121582
INFO:root:current mean train loss 1941.3816449531384
INFO:root:current train perplexity4.63450288772583
INFO:root:current mean train loss 1941.3997318755162
INFO:root:current train perplexity4.631131649017334
INFO:root:current mean train loss 1941.9348897897328
INFO:root:current train perplexity4.633914470672607
INFO:root:current mean train loss 1941.0566573906162
INFO:root:current train perplexity4.637100696563721
INFO:root:current mean train loss 1942.8306533860139
INFO:root:current train perplexity4.640589237213135
INFO:root:current mean train loss 1945.6120790663304
INFO:root:current train perplexity4.650164604187012
INFO:root:current mean train loss 1946.3751456368082
INFO:root:current train perplexity4.650463581085205
INFO:root:current mean train loss 1946.9613279153555
INFO:root:current train perplexity4.649054050445557
INFO:root:current mean train loss 1947.2678328727484
INFO:root:current train perplexity4.6458563804626465
INFO:root:current mean train loss 1947.7532289699475
INFO:root:current train perplexity4.643160343170166
INFO:root:current mean train loss 1948.520947450931
INFO:root:current train perplexity4.6434006690979
INFO:root:current mean train loss 1949.0601941709501
INFO:root:current train perplexity4.643600940704346
INFO:root:current mean train loss 1948.4240303189483
INFO:root:current train perplexity4.640945911407471
INFO:root:current mean train loss 1946.3204601395328
INFO:root:current train perplexity4.638796806335449
INFO:root:current mean train loss 1946.388911085981
INFO:root:current train perplexity4.6397881507873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.74s/it]
INFO:root:final mean train loss: 1946.0457075756726
INFO:root:final train perplexity: 4.640252113342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it]
INFO:root:eval mean loss: 1949.780101586741
INFO:root:eval perplexity: 4.8397722244262695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it]
INFO:root:eval mean loss: 2398.4535422900044
INFO:root:eval perplexity: 7.110134601593018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [6:54:16<7:47:40, 529.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.7616029077647
INFO:root:current train perplexity4.623201370239258
INFO:root:current mean train loss 1930.1109051945234
INFO:root:current train perplexity4.574750900268555
INFO:root:current mean train loss 1921.3070396064911
INFO:root:current train perplexity4.548700332641602
INFO:root:current mean train loss 1917.772438547719
INFO:root:current train perplexity4.551568031311035
INFO:root:current mean train loss 1916.4801939692363
INFO:root:current train perplexity4.550544738769531
INFO:root:current mean train loss 1919.1670677159543
INFO:root:current train perplexity4.556435585021973
INFO:root:current mean train loss 1920.5189791354203
INFO:root:current train perplexity4.557344913482666
INFO:root:current mean train loss 1921.0939808322075
INFO:root:current train perplexity4.55827522277832
INFO:root:current mean train loss 1923.2363311155866
INFO:root:current train perplexity4.561341285705566
INFO:root:current mean train loss 1923.260139297149
INFO:root:current train perplexity4.554971218109131
INFO:root:current mean train loss 1922.9015859801912
INFO:root:current train perplexity4.55234432220459
INFO:root:current mean train loss 1925.123310070006
INFO:root:current train perplexity4.554710388183594
INFO:root:current mean train loss 1924.9917784986217
INFO:root:current train perplexity4.551750659942627
INFO:root:current mean train loss 1923.6682560256281
INFO:root:current train perplexity4.550736904144287
INFO:root:current mean train loss 1923.2804218287142
INFO:root:current train perplexity4.551832675933838
INFO:root:current mean train loss 1923.252756436268
INFO:root:current train perplexity4.5520734786987305
INFO:root:current mean train loss 1922.2106586361942
INFO:root:current train perplexity4.551621437072754
INFO:root:current mean train loss 1922.5006914149403
INFO:root:current train perplexity4.54935884475708
INFO:root:current mean train loss 1920.7481296487051
INFO:root:current train perplexity4.5459370613098145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.86s/it]
INFO:root:final mean train loss: 1919.358203543597
INFO:root:final train perplexity: 4.54360818862915
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it]
INFO:root:eval mean loss: 1925.7171314861757
INFO:root:eval perplexity: 4.746497631072998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it]
INFO:root:eval mean loss: 2371.687843701518
INFO:root:eval perplexity: 6.956186294555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:03:01<7:37:43, 528.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1885.2906005859375
INFO:root:current train perplexity4.4355058670043945
INFO:root:current mean train loss 1913.4901940387228
INFO:root:current train perplexity4.498992919921875
INFO:root:current mean train loss 1898.85234885992
INFO:root:current train perplexity4.482253074645996
INFO:root:current mean train loss 1905.3410070994544
INFO:root:current train perplexity4.494527339935303
INFO:root:current mean train loss 1906.164411356363
INFO:root:current train perplexity4.492992877960205
INFO:root:current mean train loss 1904.0051549226334
INFO:root:current train perplexity4.487626075744629
INFO:root:current mean train loss 1901.8302434657646
INFO:root:current train perplexity4.481011867523193
INFO:root:current mean train loss 1903.910358050153
INFO:root:current train perplexity4.48714542388916
INFO:root:current mean train loss 1900.0818291974215
INFO:root:current train perplexity4.480438232421875
INFO:root:current mean train loss 1899.5452772797132
INFO:root:current train perplexity4.47955846786499
INFO:root:current mean train loss 1899.7608898745382
INFO:root:current train perplexity4.483304977416992
INFO:root:current mean train loss 1900.9829433287205
INFO:root:current train perplexity4.484330654144287
INFO:root:current mean train loss 1901.1943644708076
INFO:root:current train perplexity4.482205867767334
INFO:root:current mean train loss 1900.6944351718453
INFO:root:current train perplexity4.4810614585876465
INFO:root:current mean train loss 1902.70733828056
INFO:root:current train perplexity4.484775543212891
INFO:root:current mean train loss 1902.8692449689304
INFO:root:current train perplexity4.486725330352783
INFO:root:current mean train loss 1901.9986189047988
INFO:root:current train perplexity4.483254909515381
INFO:root:current mean train loss 1901.969089020932
INFO:root:current train perplexity4.482937335968018
INFO:root:current mean train loss 1901.6146737931517
INFO:root:current train perplexity4.482600212097168
INFO:root:current mean train loss 1902.81184910707
INFO:root:current train perplexity4.483293056488037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.83s/it]
INFO:root:final mean train loss: 1902.6051805951172
INFO:root:final train perplexity: 4.483970642089844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it]
INFO:root:eval mean loss: 1915.255750290891
INFO:root:eval perplexity: 4.706508636474609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2366.826739372091
INFO:root:eval perplexity: 6.928585529327393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [7:11:48<7:28:39, 527.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1888.9640007019043
INFO:root:current train perplexity4.488356113433838
INFO:root:current mean train loss 1884.775801225142
INFO:root:current train perplexity4.4119791984558105
INFO:root:current mean train loss 1894.5317961594153
INFO:root:current train perplexity4.4308648109436035
INFO:root:current mean train loss 1892.7215098185711
INFO:root:current train perplexity4.429865837097168
INFO:root:current mean train loss 1895.7298095137985
INFO:root:current train perplexity4.438640117645264
INFO:root:current mean train loss 1895.6935521175988
INFO:root:current train perplexity4.430199146270752
INFO:root:current mean train loss 1898.0779420876804
INFO:root:current train perplexity4.440266132354736
INFO:root:current mean train loss 1899.4281127596162
INFO:root:current train perplexity4.447909355163574
INFO:root:current mean train loss 1898.6458247258113
INFO:root:current train perplexity4.447722434997559
INFO:root:current mean train loss 1898.2228373908179
INFO:root:current train perplexity4.4476189613342285
INFO:root:current mean train loss 1895.9417244371518
INFO:root:current train perplexity4.444810390472412
INFO:root:current mean train loss 1894.3174924816765
INFO:root:current train perplexity4.44224214553833
INFO:root:current mean train loss 1893.997960375501
INFO:root:current train perplexity4.441506862640381
INFO:root:current mean train loss 1893.2132319086666
INFO:root:current train perplexity4.441852569580078
INFO:root:current mean train loss 1892.6456741247764
INFO:root:current train perplexity4.441241264343262
INFO:root:current mean train loss 1892.7430541036024
INFO:root:current train perplexity4.442441463470459
INFO:root:current mean train loss 1891.4242188696767
INFO:root:current train perplexity4.444112777709961
INFO:root:current mean train loss 1891.4650542719535
INFO:root:current train perplexity4.443096160888672
INFO:root:current mean train loss 1891.8778565252712
INFO:root:current train perplexity4.443594455718994
INFO:root:current mean train loss 1891.6410565425645
INFO:root:current train perplexity4.442843437194824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.46s/it]
INFO:root:final mean train loss: 1891.0029912766818
INFO:root:final train perplexity: 4.44312858581543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 1915.0488458728114
INFO:root:eval perplexity: 4.705721378326416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it]
INFO:root:eval mean loss: 2365.873254654255
INFO:root:eval perplexity: 6.923186302185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [7:20:28<7:17:56, 525.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.5556142378828
INFO:root:current train perplexity4.390316963195801
INFO:root:current mean train loss 1883.8745149958054
INFO:root:current train perplexity4.4025797843933105
INFO:root:current mean train loss 1883.4822502902234
INFO:root:current train perplexity4.407821178436279
INFO:root:current mean train loss 1880.6178412232496
INFO:root:current train perplexity4.409926414489746
INFO:root:current mean train loss 1881.7162248573218
INFO:root:current train perplexity4.413351058959961
INFO:root:current mean train loss 1879.5486504671135
INFO:root:current train perplexity4.410079002380371
INFO:root:current mean train loss 1881.0798411317892
INFO:root:current train perplexity4.408148288726807
INFO:root:current mean train loss 1881.9735826153621
INFO:root:current train perplexity4.407957077026367
INFO:root:current mean train loss 1882.5585027364455
INFO:root:current train perplexity4.408137798309326
INFO:root:current mean train loss 1882.4952481333146
INFO:root:current train perplexity4.410546779632568
INFO:root:current mean train loss 1882.4483515736713
INFO:root:current train perplexity4.414400577545166
INFO:root:current mean train loss 1881.0551517709014
INFO:root:current train perplexity4.410384178161621
INFO:root:current mean train loss 1883.3683725300552
INFO:root:current train perplexity4.416172504425049
INFO:root:current mean train loss 1882.6144957998401
INFO:root:current train perplexity4.41620397567749
INFO:root:current mean train loss 1882.4444061974314
INFO:root:current train perplexity4.416323184967041
INFO:root:current mean train loss 1882.871890162252
INFO:root:current train perplexity4.418664932250977
INFO:root:current mean train loss 1882.9786961025147
INFO:root:current train perplexity4.418632507324219
INFO:root:current mean train loss 1883.6134726958933
INFO:root:current train perplexity4.419652462005615
INFO:root:current mean train loss 1883.6591169028234
INFO:root:current train perplexity4.417792797088623
INFO:root:current mean train loss 1884.9023572785723
INFO:root:current train perplexity4.42085075378418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.20s/it]
INFO:root:final mean train loss: 1884.4950667711682
INFO:root:final train perplexity: 4.420382022857666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it]
INFO:root:eval mean loss: 1909.084490836935
INFO:root:eval perplexity: 4.683077335357666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 2360.169415413065
INFO:root:eval perplexity: 6.890967845916748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [7:29:19<7:10:30, 527.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.0146114464962
INFO:root:current train perplexity4.373745918273926
INFO:root:current mean train loss 1871.1620476044804
INFO:root:current train perplexity4.359955310821533
INFO:root:current mean train loss 1870.9317291948132
INFO:root:current train perplexity4.371015548706055
INFO:root:current mean train loss 1866.258408843494
INFO:root:current train perplexity4.3630499839782715
INFO:root:current mean train loss 1874.9648974504594
INFO:root:current train perplexity4.374989032745361
INFO:root:current mean train loss 1875.8134621124807
INFO:root:current train perplexity4.379894256591797
INFO:root:current mean train loss 1875.033913552224
INFO:root:current train perplexity4.3829193115234375
INFO:root:current mean train loss 1875.3296511976278
INFO:root:current train perplexity4.380241394042969
INFO:root:current mean train loss 1876.014408948515
INFO:root:current train perplexity4.382562160491943
INFO:root:current mean train loss 1877.5601124259997
INFO:root:current train perplexity4.3882012367248535
INFO:root:current mean train loss 1879.606039136704
INFO:root:current train perplexity4.388644218444824
INFO:root:current mean train loss 1879.6868568799916
INFO:root:current train perplexity4.391223430633545
INFO:root:current mean train loss 1880.0654141635503
INFO:root:current train perplexity4.394486904144287
INFO:root:current mean train loss 1879.9388744080572
INFO:root:current train perplexity4.3938517570495605
INFO:root:current mean train loss 1880.879214423415
INFO:root:current train perplexity4.397288799285889
INFO:root:current mean train loss 1880.214280168672
INFO:root:current train perplexity4.394723892211914
INFO:root:current mean train loss 1877.4054969888346
INFO:root:current train perplexity4.390227317810059
INFO:root:current mean train loss 1878.5774307337379
INFO:root:current train perplexity4.392301559448242
INFO:root:current mean train loss 1877.6049790295501
INFO:root:current train perplexity4.390120983123779
INFO:root:current mean train loss 1876.6601334627137
INFO:root:current train perplexity4.391463279724121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.34s/it]
INFO:root:final mean train loss: 1876.0242857132305
INFO:root:final train perplexity: 4.390949726104736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it]
INFO:root:eval mean loss: 1901.8823774621842
INFO:root:eval perplexity: 4.655879020690918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2352.7561329510195
INFO:root:eval perplexity: 6.849313735961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [7:38:04<7:01:11, 526.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1835.531211761107
INFO:root:current train perplexity4.3163933753967285
INFO:root:current mean train loss 1861.4762022925204
INFO:root:current train perplexity4.383956432342529
INFO:root:current mean train loss 1869.5280688390294
INFO:root:current train perplexity4.401148319244385
INFO:root:current mean train loss 1873.1070043499103
INFO:root:current train perplexity4.395532608032227
INFO:root:current mean train loss 1873.4236790121959
INFO:root:current train perplexity4.396834850311279
INFO:root:current mean train loss 1874.3632959068127
INFO:root:current train perplexity4.392261028289795
INFO:root:current mean train loss 1872.4900370607613
INFO:root:current train perplexity4.386521816253662
INFO:root:current mean train loss 1874.7026192578624
INFO:root:current train perplexity4.384639263153076
INFO:root:current mean train loss 1876.4637894938244
INFO:root:current train perplexity4.390008449554443
INFO:root:current mean train loss 1878.049276295659
INFO:root:current train perplexity4.395710468292236
INFO:root:current mean train loss 1878.9879152644924
INFO:root:current train perplexity4.396434307098389
INFO:root:current mean train loss 1879.3536825816911
INFO:root:current train perplexity4.397890567779541
INFO:root:current mean train loss 1880.2838568624256
INFO:root:current train perplexity4.398553848266602
INFO:root:current mean train loss 1879.92849027533
INFO:root:current train perplexity4.400544166564941
INFO:root:current mean train loss 1880.3077931728865
INFO:root:current train perplexity4.401406288146973
INFO:root:current mean train loss 1880.0341122133855
INFO:root:current train perplexity4.399942874908447
INFO:root:current mean train loss 1878.8994372000102
INFO:root:current train perplexity4.397617340087891
INFO:root:current mean train loss 1879.4804890836415
INFO:root:current train perplexity4.398814678192139
INFO:root:current mean train loss 1879.4177043183458
INFO:root:current train perplexity4.396385669708252
INFO:root:current mean train loss 1877.5029871214897
INFO:root:current train perplexity4.396074295043945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.61s/it]
INFO:root:final mean train loss: 1877.5029871214897
INFO:root:final train perplexity: 4.396074295043945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it]
INFO:root:eval mean loss: 1906.7938184805796
INFO:root:eval perplexity: 4.674409866333008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.01s/it]
INFO:root:eval mean loss: 2359.068053766345
INFO:root:eval perplexity: 6.884762763977051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [7:46:40<6:50:05, 523.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1826.9355334472657
INFO:root:current train perplexity4.282230377197266
INFO:root:current mean train loss 1838.5435736083984
INFO:root:current train perplexity4.295314788818359
INFO:root:current mean train loss 1845.2393619791667
INFO:root:current train perplexity4.2995171546936035
INFO:root:current mean train loss 1845.7902352905273
INFO:root:current train perplexity4.311611175537109
INFO:root:current mean train loss 1849.8242983398438
INFO:root:current train perplexity4.3172926902771
INFO:root:current mean train loss 1852.9556327311197
INFO:root:current train perplexity4.315981864929199
INFO:root:current mean train loss 1853.2049237932479
INFO:root:current train perplexity4.315735816955566
INFO:root:current mean train loss 1853.7336903381347
INFO:root:current train perplexity4.318233966827393
INFO:root:current mean train loss 1855.6639599609375
INFO:root:current train perplexity4.323423862457275
INFO:root:current mean train loss 1856.9717943115234
INFO:root:current train perplexity4.325566291809082
INFO:root:current mean train loss 1856.38997125799
INFO:root:current train perplexity4.325872421264648
INFO:root:current mean train loss 1859.3425665283203
INFO:root:current train perplexity4.334274768829346
INFO:root:current mean train loss 1858.828095703125
INFO:root:current train perplexity4.332415580749512
INFO:root:current mean train loss 1860.3445795549665
INFO:root:current train perplexity4.33648681640625
INFO:root:current mean train loss 1860.4048028157551
INFO:root:current train perplexity4.337442398071289
INFO:root:current mean train loss 1861.412625732422
INFO:root:current train perplexity4.340704441070557
INFO:root:current mean train loss 1862.963730396944
INFO:root:current train perplexity4.34263277053833
INFO:root:current mean train loss 1862.7002720133464
INFO:root:current train perplexity4.340975761413574
INFO:root:current mean train loss 1863.5780797054892
INFO:root:current train perplexity4.343988418579102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.79s/it]
INFO:root:final mean train loss: 1862.06158856629
INFO:root:final train perplexity: 4.342863082885742
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it]
INFO:root:eval mean loss: 1895.8103949364195
INFO:root:eval perplexity: 4.633071422576904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 2347.5568929902206
INFO:root:eval perplexity: 6.82025146484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [7:55:10<6:38:13, 519.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1842.133243336397
INFO:root:current train perplexity4.354218482971191
INFO:root:current mean train loss 1858.3916777260283
INFO:root:current train perplexity4.311155796051025
INFO:root:current mean train loss 1857.6370225194412
INFO:root:current train perplexity4.31298303604126
INFO:root:current mean train loss 1854.236271903342
INFO:root:current train perplexity4.310632228851318
INFO:root:current mean train loss 1850.1421123843113
INFO:root:current train perplexity4.305222034454346
INFO:root:current mean train loss 1855.4440020740149
INFO:root:current train perplexity4.314721584320068
INFO:root:current mean train loss 1858.0200365459127
INFO:root:current train perplexity4.317617416381836
INFO:root:current mean train loss 1858.4967655623475
INFO:root:current train perplexity4.319406986236572
INFO:root:current mean train loss 1859.1411906771152
INFO:root:current train perplexity4.319545745849609
INFO:root:current mean train loss 1860.2154804591655
INFO:root:current train perplexity4.322267532348633
INFO:root:current mean train loss 1857.8069388990675
INFO:root:current train perplexity4.319131374359131
INFO:root:current mean train loss 1858.166846183975
INFO:root:current train perplexity4.320393085479736
INFO:root:current mean train loss 1857.166591371585
INFO:root:current train perplexity4.319291114807129
INFO:root:current mean train loss 1857.403095265637
INFO:root:current train perplexity4.3210625648498535
INFO:root:current mean train loss 1856.548855175161
INFO:root:current train perplexity4.319173336029053
INFO:root:current mean train loss 1855.9042444097108
INFO:root:current train perplexity4.318548202514648
INFO:root:current mean train loss 1854.0460569703735
INFO:root:current train perplexity4.315237045288086
INFO:root:current mean train loss 1853.3025580591147
INFO:root:current train perplexity4.313989162445068
INFO:root:current mean train loss 1853.8075592091402
INFO:root:current train perplexity4.315896034240723
INFO:root:current mean train loss 1855.0194220426
INFO:root:current train perplexity4.317296504974365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.95s/it]
INFO:root:final mean train loss: 1854.793820410501
INFO:root:final train perplexity: 4.3180413246154785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.46s/it]
INFO:root:eval mean loss: 1899.9019026519559
INFO:root:eval perplexity: 4.648427963256836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it]
INFO:root:eval mean loss: 2354.2926016733154
INFO:root:eval perplexity: 6.857926368713379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:03:50<6:29:32, 519.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1818.0516465130975
INFO:root:current train perplexity4.249561786651611
INFO:root:current mean train loss 1835.6285382171175
INFO:root:current train perplexity4.27934455871582
INFO:root:current mean train loss 1840.4955094818376
INFO:root:current train perplexity4.270746231079102
INFO:root:current mean train loss 1841.904867023765
INFO:root:current train perplexity4.265114784240723
INFO:root:current mean train loss 1837.7159741660967
INFO:root:current train perplexity4.260143280029297
INFO:root:current mean train loss 1838.729570138767
INFO:root:current train perplexity4.257388591766357
INFO:root:current mean train loss 1837.3491370745637
INFO:root:current train perplexity4.258481502532959
INFO:root:current mean train loss 1836.5706863611206
INFO:root:current train perplexity4.259399890899658
INFO:root:current mean train loss 1838.7471273957397
INFO:root:current train perplexity4.265902519226074
INFO:root:current mean train loss 1841.2567285051693
INFO:root:current train perplexity4.2721405029296875
INFO:root:current mean train loss 1842.095450366258
INFO:root:current train perplexity4.275247097015381
INFO:root:current mean train loss 1842.1364251999628
INFO:root:current train perplexity4.273911476135254
INFO:root:current mean train loss 1841.8584342474296
INFO:root:current train perplexity4.274040699005127
INFO:root:current mean train loss 1842.6567769887029
INFO:root:current train perplexity4.276742458343506
INFO:root:current mean train loss 1843.220238849209
INFO:root:current train perplexity4.278481483459473
INFO:root:current mean train loss 1843.9017185176367
INFO:root:current train perplexity4.279428005218506
INFO:root:current mean train loss 1842.3444657623404
INFO:root:current train perplexity4.275116443634033
INFO:root:current mean train loss 1842.4669210572556
INFO:root:current train perplexity4.274188995361328
INFO:root:current mean train loss 1840.5378891873127
INFO:root:current train perplexity4.270634651184082
INFO:root:current mean train loss 1840.4745396295525
INFO:root:current train perplexity4.270256042480469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.72s/it]
INFO:root:final mean train loss: 1840.7277676596284
INFO:root:final train perplexity: 4.270404815673828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it]
INFO:root:eval mean loss: 1890.9689465245456
INFO:root:eval perplexity: 4.614967346191406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 2344.7783757203015
INFO:root:eval perplexity: 6.804772853851318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [8:12:20<6:18:57, 516.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1818.0159600949755
INFO:root:current train perplexity4.211851119995117
INFO:root:current mean train loss 1807.3944601096855
INFO:root:current train perplexity4.189369201660156
INFO:root:current mean train loss 1822.0990452253486
INFO:root:current train perplexity4.213057041168213
INFO:root:current mean train loss 1830.4476593104523
INFO:root:current train perplexity4.225656032562256
INFO:root:current mean train loss 1833.3453869872505
INFO:root:current train perplexity4.23482608795166
INFO:root:current mean train loss 1828.9399575789048
INFO:root:current train perplexity4.2226128578186035
INFO:root:current mean train loss 1831.563938217046
INFO:root:current train perplexity4.230208396911621
INFO:root:current mean train loss 1831.3425713956913
INFO:root:current train perplexity4.227869510650635
INFO:root:current mean train loss 1830.4595324721377
INFO:root:current train perplexity4.2295823097229
INFO:root:current mean train loss 1829.147522678636
INFO:root:current train perplexity4.226085186004639
INFO:root:current mean train loss 1829.2346930100055
INFO:root:current train perplexity4.227607250213623
INFO:root:current mean train loss 1830.8899048806065
INFO:root:current train perplexity4.229006767272949
INFO:root:current mean train loss 1829.2553089364446
INFO:root:current train perplexity4.225190162658691
INFO:root:current mean train loss 1830.8144576427762
INFO:root:current train perplexity4.230293273925781
INFO:root:current mean train loss 1831.795545687107
INFO:root:current train perplexity4.232120513916016
INFO:root:current mean train loss 1832.4834913085308
INFO:root:current train perplexity4.233287334442139
INFO:root:current mean train loss 1832.4652757650429
INFO:root:current train perplexity4.234255313873291
INFO:root:current mean train loss 1833.143591566538
INFO:root:current train perplexity4.237224578857422
INFO:root:current mean train loss 1831.71139504934
INFO:root:current train perplexity4.235284328460693
INFO:root:current mean train loss 1830.7312368982452
INFO:root:current train perplexity4.235149383544922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.82s/it]
INFO:root:final mean train loss: 1830.0947624510488
INFO:root:final train perplexity: 4.234744071960449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it]
INFO:root:eval mean loss: 1883.4666051120623
INFO:root:eval perplexity: 4.587049961090088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 2338.696635361259
INFO:root:eval perplexity: 6.7710113525390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [8:21:01<6:11:11, 517.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1816.9426969640394
INFO:root:current train perplexity4.2004170417785645
INFO:root:current mean train loss 1823.363526843843
INFO:root:current train perplexity4.202667236328125
INFO:root:current mean train loss 1823.5944887986823
INFO:root:current train perplexity4.217461109161377
INFO:root:current mean train loss 1823.4502404254415
INFO:root:current train perplexity4.218790531158447
INFO:root:current mean train loss 1823.4710474258814
INFO:root:current train perplexity4.214196681976318
INFO:root:current mean train loss 1823.0989532470703
INFO:root:current train perplexity4.205206394195557
INFO:root:current mean train loss 1822.8123722647479
INFO:root:current train perplexity4.203817367553711
INFO:root:current mean train loss 1819.0696458816528
INFO:root:current train perplexity4.200350284576416
INFO:root:current mean train loss 1817.846182546308
INFO:root:current train perplexity4.197483539581299
INFO:root:current mean train loss 1819.5291111213116
INFO:root:current train perplexity4.203241348266602
INFO:root:current mean train loss 1822.2876343459225
INFO:root:current train perplexity4.208363056182861
INFO:root:current mean train loss 1821.8154550839777
INFO:root:current train perplexity4.2100701332092285
INFO:root:current mean train loss 1821.4432459689842
INFO:root:current train perplexity4.208483695983887
INFO:root:current mean train loss 1820.439978437814
INFO:root:current train perplexity4.20656156539917
INFO:root:current mean train loss 1821.0152502241835
INFO:root:current train perplexity4.206920146942139
INFO:root:current mean train loss 1821.306229182652
INFO:root:current train perplexity4.206457614898682
INFO:root:current mean train loss 1821.6003447974042
INFO:root:current train perplexity4.2066731452941895
INFO:root:current mean train loss 1821.767525375159
INFO:root:current train perplexity4.204824447631836
INFO:root:current mean train loss 1822.026798942615
INFO:root:current train perplexity4.205236434936523
INFO:root:current mean train loss 1822.02842799241
INFO:root:current train perplexity4.205456733703613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.53s/it]
INFO:root:final mean train loss: 1821.3358941013262
INFO:root:final train perplexity: 4.205592155456543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it]
INFO:root:eval mean loss: 1885.8280847427693
INFO:root:eval perplexity: 4.595818996429443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.38s/it]
INFO:root:eval mean loss: 2341.8732169942655
INFO:root:eval perplexity: 6.788623809814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [8:29:40<6:02:50, 518.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.728901941636
INFO:root:current train perplexity4.189785480499268
INFO:root:current mean train loss 1810.9571572793498
INFO:root:current train perplexity4.185949325561523
INFO:root:current mean train loss 1816.3218338815789
INFO:root:current train perplexity4.199977874755859
INFO:root:current mean train loss 1816.652351359578
INFO:root:current train perplexity4.2051873207092285
INFO:root:current mean train loss 1815.167097394491
INFO:root:current train perplexity4.194843292236328
INFO:root:current mean train loss 1815.1799454126603
INFO:root:current train perplexity4.191318988800049
INFO:root:current mean train loss 1813.2252603572651
INFO:root:current train perplexity4.185695171356201
INFO:root:current mean train loss 1812.003111937699
INFO:root:current train perplexity4.184650897979736
INFO:root:current mean train loss 1813.6199636685647
INFO:root:current train perplexity4.181806564331055
INFO:root:current mean train loss 1812.8045204433693
INFO:root:current train perplexity4.178125381469727
INFO:root:current mean train loss 1811.1108046289962
INFO:root:current train perplexity4.174931049346924
INFO:root:current mean train loss 1812.3306103927678
INFO:root:current train perplexity4.177050590515137
INFO:root:current mean train loss 1814.266064168136
INFO:root:current train perplexity4.17902135848999
INFO:root:current mean train loss 1813.830740389497
INFO:root:current train perplexity4.17948579788208
INFO:root:current mean train loss 1813.1091056232901
INFO:root:current train perplexity4.17784309387207
INFO:root:current mean train loss 1814.7521916434591
INFO:root:current train perplexity4.181262016296387
INFO:root:current mean train loss 1815.0572849534033
INFO:root:current train perplexity4.1839799880981445
INFO:root:current mean train loss 1814.9998660987833
INFO:root:current train perplexity4.182322978973389
INFO:root:current mean train loss 1814.421136490799
INFO:root:current train perplexity4.18233585357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.86s/it]
INFO:root:final mean train loss: 1813.768300759089
INFO:root:final train perplexity: 4.180566310882568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it]
INFO:root:eval mean loss: 1873.3281825721688
INFO:root:eval perplexity: 4.549593448638916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2328.2389677872893
INFO:root:eval perplexity: 6.713348865509033
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [8:38:14<5:53:13, 516.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1842.3165893554688
INFO:root:current train perplexity4.141228199005127
INFO:root:current mean train loss 1782.2887692918964
INFO:root:current train perplexity4.086731433868408
INFO:root:current mean train loss 1793.3507684386602
INFO:root:current train perplexity4.122524261474609
INFO:root:current mean train loss 1794.6027448035234
INFO:root:current train perplexity4.118566989898682
INFO:root:current mean train loss 1794.9720759605293
INFO:root:current train perplexity4.118780136108398
INFO:root:current mean train loss 1794.8238119300142
INFO:root:current train perplexity4.12204122543335
INFO:root:current mean train loss 1800.097722151747
INFO:root:current train perplexity4.138699054718018
INFO:root:current mean train loss 1802.716433098513
INFO:root:current train perplexity4.146115779876709
INFO:root:current mean train loss 1803.4552406824735
INFO:root:current train perplexity4.1446990966796875
INFO:root:current mean train loss 1804.9261684375433
INFO:root:current train perplexity4.1474223136901855
INFO:root:current mean train loss 1805.7989041448354
INFO:root:current train perplexity4.1536946296691895
INFO:root:current mean train loss 1808.5162554012236
INFO:root:current train perplexity4.158010482788086
INFO:root:current mean train loss 1808.4058727194586
INFO:root:current train perplexity4.156154155731201
INFO:root:current mean train loss 1807.3505591232838
INFO:root:current train perplexity4.157336711883545
INFO:root:current mean train loss 1806.5437228519804
INFO:root:current train perplexity4.157529830932617
INFO:root:current mean train loss 1806.499916696358
INFO:root:current train perplexity4.157345771789551
INFO:root:current mean train loss 1805.3206238478756
INFO:root:current train perplexity4.156132221221924
INFO:root:current mean train loss 1804.9062006554789
INFO:root:current train perplexity4.15341854095459
INFO:root:current mean train loss 1804.9002130743402
INFO:root:current train perplexity4.15169095993042
INFO:root:current mean train loss 1804.5947078219474
INFO:root:current train perplexity4.150878429412842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.90s/it]
INFO:root:final mean train loss: 1804.8679675065202
INFO:root:final train perplexity: 4.15132474899292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it]
INFO:root:eval mean loss: 1873.2168146228114
INFO:root:eval perplexity: 4.549183368682861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 2330.2075619528478
INFO:root:eval perplexity: 6.724165439605713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [8:46:53<5:45:00, 517.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.6456812808387
INFO:root:current train perplexity4.198001861572266
INFO:root:current mean train loss 1804.8711173434217
INFO:root:current train perplexity4.1589813232421875
INFO:root:current mean train loss 1811.0937349502356
INFO:root:current train perplexity4.15776252746582
INFO:root:current mean train loss 1802.9116605083022
INFO:root:current train perplexity4.139606475830078
INFO:root:current mean train loss 1797.1738930932092
INFO:root:current train perplexity4.127849578857422
INFO:root:current mean train loss 1801.2453387486453
INFO:root:current train perplexity4.135501861572266
INFO:root:current mean train loss 1798.400408176305
INFO:root:current train perplexity4.135597229003906
INFO:root:current mean train loss 1799.3026773296244
INFO:root:current train perplexity4.138516426086426
INFO:root:current mean train loss 1798.7539621430003
INFO:root:current train perplexity4.136392116546631
INFO:root:current mean train loss 1797.5029229131953
INFO:root:current train perplexity4.133118152618408
INFO:root:current mean train loss 1797.505756471763
INFO:root:current train perplexity4.132813453674316
INFO:root:current mean train loss 1797.1858831956197
INFO:root:current train perplexity4.131617069244385
INFO:root:current mean train loss 1797.8049062051375
INFO:root:current train perplexity4.131897449493408
INFO:root:current mean train loss 1797.909108333284
INFO:root:current train perplexity4.132348537445068
INFO:root:current mean train loss 1797.7331980839003
INFO:root:current train perplexity4.129817962646484
INFO:root:current mean train loss 1797.8966586807985
INFO:root:current train perplexity4.12910270690918
INFO:root:current mean train loss 1799.0155642287389
INFO:root:current train perplexity4.132244110107422
INFO:root:current mean train loss 1798.7693886571044
INFO:root:current train perplexity4.131132125854492
INFO:root:current mean train loss 1798.3722140588493
INFO:root:current train perplexity4.1312737464904785
INFO:root:current mean train loss 1797.9716429837115
INFO:root:current train perplexity4.128337860107422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.43s/it]
INFO:root:final mean train loss: 1797.7298555359719
INFO:root:final train perplexity: 4.128020763397217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it]
INFO:root:eval mean loss: 1866.8823276817375
INFO:root:eval perplexity: 4.525937557220459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it]
INFO:root:eval mean loss: 2324.2335127160904
INFO:root:eval perplexity: 6.6913933753967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [8:55:25<5:35:19, 515.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1765.6639268663193
INFO:root:current train perplexity4.037635326385498
INFO:root:current mean train loss 1777.2100264605353
INFO:root:current train perplexity4.076154708862305
INFO:root:current mean train loss 1788.6227101471466
INFO:root:current train perplexity4.1158318519592285
INFO:root:current mean train loss 1793.2809800647553
INFO:root:current train perplexity4.117595195770264
INFO:root:current mean train loss 1789.5131029601491
INFO:root:current train perplexity4.1107563972473145
INFO:root:current mean train loss 1787.618597457658
INFO:root:current train perplexity4.102065086364746
INFO:root:current mean train loss 1787.3281541740369
INFO:root:current train perplexity4.099885940551758
INFO:root:current mean train loss 1790.8877520353897
INFO:root:current train perplexity4.105663776397705
INFO:root:current mean train loss 1791.4244321978263
INFO:root:current train perplexity4.110319137573242
INFO:root:current mean train loss 1790.3800711346487
INFO:root:current train perplexity4.104918003082275
INFO:root:current mean train loss 1787.7372209114458
INFO:root:current train perplexity4.095771312713623
INFO:root:current mean train loss 1786.9988924483177
INFO:root:current train perplexity4.094168186187744
INFO:root:current mean train loss 1787.6787239741352
INFO:root:current train perplexity4.0997209548950195
INFO:root:current mean train loss 1789.4087763803448
INFO:root:current train perplexity4.103392601013184
INFO:root:current mean train loss 1788.8360606754059
INFO:root:current train perplexity4.104547500610352
INFO:root:current mean train loss 1790.0355741182964
INFO:root:current train perplexity4.107978820800781
INFO:root:current mean train loss 1790.4744645470803
INFO:root:current train perplexity4.107680320739746
INFO:root:current mean train loss 1790.9120924286028
INFO:root:current train perplexity4.108247756958008
INFO:root:current mean train loss 1791.9302978515625
INFO:root:current train perplexity4.1085405349731445
INFO:root:current mean train loss 1792.3938367859391
INFO:root:current train perplexity4.10852575302124

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.53s/it]
INFO:root:final mean train loss: 1791.1389337752241
INFO:root:final train perplexity: 4.106618404388428
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 1865.9204097233765
INFO:root:eval perplexity: 4.5224175453186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it]
INFO:root:eval mean loss: 2325.8899501502938
INFO:root:eval perplexity: 6.700464725494385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [9:03:57<5:25:55, 514.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.6334343676297
INFO:root:current train perplexity4.069431781768799
INFO:root:current mean train loss 1788.594149720435
INFO:root:current train perplexity4.094779968261719
INFO:root:current mean train loss 1795.0517447852335
INFO:root:current train perplexity4.106817722320557
INFO:root:current mean train loss 1791.8889844856587
INFO:root:current train perplexity4.101172924041748
INFO:root:current mean train loss 1791.9002273256415
INFO:root:current train perplexity4.101759433746338
INFO:root:current mean train loss 1789.5363171320496
INFO:root:current train perplexity4.095499515533447
INFO:root:current mean train loss 1788.794879440144
INFO:root:current train perplexity4.089016914367676
INFO:root:current mean train loss 1787.7208193592817
INFO:root:current train perplexity4.080041885375977
INFO:root:current mean train loss 1786.281423445743
INFO:root:current train perplexity4.07728910446167
INFO:root:current mean train loss 1783.4084390678286
INFO:root:current train perplexity4.071849346160889
INFO:root:current mean train loss 1784.3395508044352
INFO:root:current train perplexity4.0768256187438965
INFO:root:current mean train loss 1783.6107518641927
INFO:root:current train perplexity4.076956748962402
INFO:root:current mean train loss 1783.7166196635887
INFO:root:current train perplexity4.0776848793029785
INFO:root:current mean train loss 1784.1561163812767
INFO:root:current train perplexity4.081193447113037
INFO:root:current mean train loss 1783.6208850626936
INFO:root:current train perplexity4.080519199371338
INFO:root:current mean train loss 1782.5471988439713
INFO:root:current train perplexity4.080854415893555
INFO:root:current mean train loss 1783.211458348103
INFO:root:current train perplexity4.080376148223877
INFO:root:current mean train loss 1783.210048538443
INFO:root:current train perplexity4.080771446228027
INFO:root:current mean train loss 1783.0984131122884
INFO:root:current train perplexity4.080821990966797
INFO:root:current mean train loss 1782.9111907537083
INFO:root:current train perplexity4.079618453979492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.85s/it]
INFO:root:final mean train loss: 1782.808019871791
INFO:root:final train perplexity: 4.07972526550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 1862.3898908466313
INFO:root:eval perplexity: 4.509523868560791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 2321.8821385160404
INFO:root:eval perplexity: 6.678536891937256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [9:12:34<5:17:48, 515.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1801.0393973214286
INFO:root:current train perplexity4.106016159057617
INFO:root:current mean train loss 1790.3617216222426
INFO:root:current train perplexity4.069336891174316
INFO:root:current mean train loss 1779.6350463867188
INFO:root:current train perplexity4.051619529724121
INFO:root:current mean train loss 1773.5791668866132
INFO:root:current train perplexity4.050333499908447
INFO:root:current mean train loss 1778.8844360351563
INFO:root:current train perplexity4.064197063446045
INFO:root:current mean train loss 1780.32156554105
INFO:root:current train perplexity4.071976184844971
INFO:root:current mean train loss 1778.2467880932252
INFO:root:current train perplexity4.064472675323486
INFO:root:current mean train loss 1778.7064415077111
INFO:root:current train perplexity4.065091609954834
INFO:root:current mean train loss 1777.8221199824893
INFO:root:current train perplexity4.066437244415283
INFO:root:current mean train loss 1775.9172423687178
INFO:root:current train perplexity4.059524059295654
INFO:root:current mean train loss 1774.9313657956702
INFO:root:current train perplexity4.060417175292969
INFO:root:current mean train loss 1774.8521731645633
INFO:root:current train perplexity4.061613082885742
INFO:root:current mean train loss 1774.198858594519
INFO:root:current train perplexity4.060852527618408
INFO:root:current mean train loss 1775.964879569172
INFO:root:current train perplexity4.063526153564453
INFO:root:current mean train loss 1776.4301497063668
INFO:root:current train perplexity4.063122272491455
INFO:root:current mean train loss 1776.0977119980344
INFO:root:current train perplexity4.062726974487305
INFO:root:current mean train loss 1776.6674036448587
INFO:root:current train perplexity4.062527179718018
INFO:root:current mean train loss 1777.1359379137978
INFO:root:current train perplexity4.061601638793945
INFO:root:current mean train loss 1777.4737178700493
INFO:root:current train perplexity4.060958385467529
INFO:root:current mean train loss 1778.5095862993735
INFO:root:current train perplexity4.0638041496276855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.53s/it]
INFO:root:final mean train loss: 1777.7287603196505
INFO:root:final train perplexity: 4.063416004180908
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 1856.8540060706173
INFO:root:eval perplexity: 4.489379405975342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it]
INFO:root:eval mean loss: 2316.4685556398217
INFO:root:eval perplexity: 6.64903450012207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [9:21:09<5:09:15, 515.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1777.282716246857
INFO:root:current train perplexity4.025014877319336
INFO:root:current mean train loss 1771.0349512763203
INFO:root:current train perplexity4.037313461303711
INFO:root:current mean train loss 1774.5569974786313
INFO:root:current train perplexity4.055155277252197
INFO:root:current mean train loss 1772.1219365713823
INFO:root:current train perplexity4.046105861663818
INFO:root:current mean train loss 1770.9286821118615
INFO:root:current train perplexity4.047891139984131
INFO:root:current mean train loss 1773.8115063850885
INFO:root:current train perplexity4.045797824859619
INFO:root:current mean train loss 1769.9383587566526
INFO:root:current train perplexity4.040564060211182
INFO:root:current mean train loss 1769.4020572647812
INFO:root:current train perplexity4.040469169616699
INFO:root:current mean train loss 1769.1522940686214
INFO:root:current train perplexity4.038901329040527
INFO:root:current mean train loss 1768.7206020799692
INFO:root:current train perplexity4.040599346160889
INFO:root:current mean train loss 1769.7191386709767
INFO:root:current train perplexity4.045615196228027
INFO:root:current mean train loss 1771.3844563870643
INFO:root:current train perplexity4.049566268920898
INFO:root:current mean train loss 1771.7702134968981
INFO:root:current train perplexity4.050479888916016
INFO:root:current mean train loss 1770.3016697141707
INFO:root:current train perplexity4.047417640686035
INFO:root:current mean train loss 1771.4497891229194
INFO:root:current train perplexity4.048083305358887
INFO:root:current mean train loss 1772.1181529092578
INFO:root:current train perplexity4.049012184143066
INFO:root:current mean train loss 1772.030474451921
INFO:root:current train perplexity4.046535015106201
INFO:root:current mean train loss 1770.8624938384207
INFO:root:current train perplexity4.0449700355529785
INFO:root:current mean train loss 1771.8499268742548
INFO:root:current train perplexity4.045339107513428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.82s/it]
INFO:root:final mean train loss: 1771.8215295711793
INFO:root:final train perplexity: 4.044528484344482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it]
INFO:root:eval mean loss: 1851.3893142591976
INFO:root:eval perplexity: 4.469582557678223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2312.4402149822695
INFO:root:eval perplexity: 6.627164840698242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [9:29:37<4:59:23, 513.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.5903625488281
INFO:root:current train perplexity3.950486183166504
INFO:root:current mean train loss 1742.5109405517578
INFO:root:current train perplexity3.9716742038726807
INFO:root:current mean train loss 1747.8497278550092
INFO:root:current train perplexity3.9898476600646973
INFO:root:current mean train loss 1749.2248366506476
INFO:root:current train perplexity3.9996371269226074
INFO:root:current mean train loss 1754.7439194480971
INFO:root:current train perplexity4.008787631988525
INFO:root:current mean train loss 1758.2765195331876
INFO:root:current train perplexity4.014573574066162
INFO:root:current mean train loss 1762.060939157246
INFO:root:current train perplexity4.01871395111084
INFO:root:current mean train loss 1764.6983190016313
INFO:root:current train perplexity4.0262298583984375
INFO:root:current mean train loss 1765.9527534750564
INFO:root:current train perplexity4.028524398803711
INFO:root:current mean train loss 1766.9463653564453
INFO:root:current train perplexity4.032159805297852
INFO:root:current mean train loss 1767.0732971434575
INFO:root:current train perplexity4.03225040435791
INFO:root:current mean train loss 1767.9461343737617
INFO:root:current train perplexity4.03187894821167
INFO:root:current mean train loss 1768.024399361341
INFO:root:current train perplexity4.030318260192871
INFO:root:current mean train loss 1768.625219146167
INFO:root:current train perplexity4.032095432281494
INFO:root:current mean train loss 1768.934349646935
INFO:root:current train perplexity4.033239364624023
INFO:root:current mean train loss 1769.0220190819273
INFO:root:current train perplexity4.032045364379883
INFO:root:current mean train loss 1768.2307969090944
INFO:root:current train perplexity4.0297956466674805
INFO:root:current mean train loss 1766.9277609525152
INFO:root:current train perplexity4.026760101318359
INFO:root:current mean train loss 1765.9327798576946
INFO:root:current train perplexity4.024261951446533
INFO:root:current mean train loss 1766.062408831941
INFO:root:current train perplexity4.024913787841797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.78s/it]
INFO:root:final mean train loss: 1765.3938537997785
INFO:root:final train perplexity: 4.024077892303467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 1846.3118740649934
INFO:root:eval perplexity: 4.451266765594482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it]
INFO:root:eval mean loss: 2306.8843011517897
INFO:root:eval perplexity: 6.5971221923828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [9:38:08<4:50:27, 512.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1807.8124476841517
INFO:root:current train perplexity4.143119812011719
INFO:root:current mean train loss 1778.0091310611442
INFO:root:current train perplexity4.060224533081055
INFO:root:current mean train loss 1784.387603621677
INFO:root:current train perplexity4.063814640045166
INFO:root:current mean train loss 1772.520515418127
INFO:root:current train perplexity4.040729522705078
INFO:root:current mean train loss 1766.96528186934
INFO:root:current train perplexity4.028004169464111
INFO:root:current mean train loss 1764.3394145123561
INFO:root:current train perplexity4.021547317504883
INFO:root:current mean train loss 1763.03621124415
INFO:root:current train perplexity4.01932430267334
INFO:root:current mean train loss 1763.5699809969876
INFO:root:current train perplexity4.017167568206787
INFO:root:current mean train loss 1761.3816414576354
INFO:root:current train perplexity4.010572910308838
INFO:root:current mean train loss 1760.4937240484612
INFO:root:current train perplexity4.011993885040283
INFO:root:current mean train loss 1759.580284604363
INFO:root:current train perplexity4.012307167053223
INFO:root:current mean train loss 1760.3554169163972
INFO:root:current train perplexity4.010317325592041
INFO:root:current mean train loss 1758.0784244271792
INFO:root:current train perplexity4.005982398986816
INFO:root:current mean train loss 1758.0156544779936
INFO:root:current train perplexity4.007399082183838
INFO:root:current mean train loss 1758.9729587197892
INFO:root:current train perplexity4.007983684539795
INFO:root:current mean train loss 1761.6820417475653
INFO:root:current train perplexity4.011131763458252
INFO:root:current mean train loss 1762.3854151354535
INFO:root:current train perplexity4.011521816253662
INFO:root:current mean train loss 1762.0960385523724
INFO:root:current train perplexity4.012327194213867
INFO:root:current mean train loss 1762.0058434207251
INFO:root:current train perplexity4.0124592781066895
INFO:root:current mean train loss 1761.2785397340456
INFO:root:current train perplexity4.009725570678711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.30s/it]
INFO:root:final mean train loss: 1761.1647148343932
INFO:root:final train perplexity: 4.010678768157959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 1848.912091194315
INFO:root:eval perplexity: 4.460636615753174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it]
INFO:root:eval mean loss: 2309.4245328429743
INFO:root:eval perplexity: 6.610841751098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [9:46:46<4:42:49, 514.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1717.807716771176
INFO:root:current train perplexity3.9299533367156982
INFO:root:current mean train loss 1740.7988785453465
INFO:root:current train perplexity3.952305793762207
INFO:root:current mean train loss 1742.8533043100053
INFO:root:current train perplexity3.9525744915008545
INFO:root:current mean train loss 1748.3042830066568
INFO:root:current train perplexity3.967602014541626
INFO:root:current mean train loss 1746.470821572221
INFO:root:current train perplexity3.965848684310913
INFO:root:current mean train loss 1748.0569135814794
INFO:root:current train perplexity3.9680330753326416
INFO:root:current mean train loss 1749.9233103785023
INFO:root:current train perplexity3.9743690490722656
INFO:root:current mean train loss 1750.8912786881774
INFO:root:current train perplexity3.983790397644043
INFO:root:current mean train loss 1752.4150610584632
INFO:root:current train perplexity3.9878172874450684
INFO:root:current mean train loss 1752.6892888896755
INFO:root:current train perplexity3.9874773025512695
INFO:root:current mean train loss 1749.756355653149
INFO:root:current train perplexity3.9793965816497803
INFO:root:current mean train loss 1749.9014843235116
INFO:root:current train perplexity3.978210926055908
INFO:root:current mean train loss 1752.0034060378066
INFO:root:current train perplexity3.981854200363159
INFO:root:current mean train loss 1753.7537990507346
INFO:root:current train perplexity3.9868357181549072
INFO:root:current mean train loss 1754.9044300657652
INFO:root:current train perplexity3.988384485244751
INFO:root:current mean train loss 1755.5939625515584
INFO:root:current train perplexity3.9901530742645264
INFO:root:current mean train loss 1756.072765233898
INFO:root:current train perplexity3.9915528297424316
INFO:root:current mean train loss 1755.1549568132373
INFO:root:current train perplexity3.9910292625427246
INFO:root:current mean train loss 1754.1627332751718
INFO:root:current train perplexity3.9892921447753906
INFO:root:current mean train loss 1755.346060391673
INFO:root:current train perplexity3.9907805919647217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.98s/it]
INFO:root:final mean train loss: 1755.001188446522
INFO:root:final train perplexity: 3.9912304878234863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it]
INFO:root:eval mean loss: 1843.0610117810838
INFO:root:eval perplexity: 4.439579010009766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 2303.085357882452
INFO:root:eval perplexity: 6.576656341552734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [9:55:18<4:33:51, 513.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1762.885633433949
INFO:root:current train perplexity3.9909017086029053
INFO:root:current mean train loss 1758.3479586693547
INFO:root:current train perplexity3.984696626663208
INFO:root:current mean train loss 1750.9616325827205
INFO:root:current train perplexity3.9650180339813232
INFO:root:current mean train loss 1745.9754456426056
INFO:root:current train perplexity3.95457124710083
INFO:root:current mean train loss 1750.6504204047906
INFO:root:current train perplexity3.961097478866577
INFO:root:current mean train loss 1750.0182867926521
INFO:root:current train perplexity3.9563632011413574
INFO:root:current mean train loss 1748.4651810740697
INFO:root:current train perplexity3.958869695663452
INFO:root:current mean train loss 1749.4437826598717
INFO:root:current train perplexity3.962803840637207
INFO:root:current mean train loss 1749.6291348284449
INFO:root:current train perplexity3.9650299549102783
INFO:root:current mean train loss 1749.7166710978404
INFO:root:current train perplexity3.9655494689941406
INFO:root:current mean train loss 1750.9636527834346
INFO:root:current train perplexity3.9676361083984375
INFO:root:current mean train loss 1748.6452068114177
INFO:root:current train perplexity3.9627177715301514
INFO:root:current mean train loss 1750.2435658732259
INFO:root:current train perplexity3.9702460765838623
INFO:root:current mean train loss 1749.7749906307656
INFO:root:current train perplexity3.97115159034729
INFO:root:current mean train loss 1749.360226471891
INFO:root:current train perplexity3.9685704708099365
INFO:root:current mean train loss 1749.9175380105758
INFO:root:current train perplexity3.9695119857788086
INFO:root:current mean train loss 1749.1613992281912
INFO:root:current train perplexity3.9686460494995117
INFO:root:current mean train loss 1750.5621424139736
INFO:root:current train perplexity3.9716579914093018
INFO:root:current mean train loss 1749.3758318548896
INFO:root:current train perplexity3.9717347621917725
INFO:root:current mean train loss 1750.5073186615848
INFO:root:current train perplexity3.9760220050811768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.62s/it]
INFO:root:final mean train loss: 1750.1341972562682
INFO:root:final train perplexity: 3.975939989089966
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it]
INFO:root:eval mean loss: 1842.5476130492298
INFO:root:eval perplexity: 4.437735557556152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it]
INFO:root:eval mean loss: 2303.839735531638
INFO:root:eval perplexity: 6.580715656280518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [10:03:58<4:26:14, 515.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1774.6248626708984
INFO:root:current train perplexity4.01825475692749
INFO:root:current mean train loss 1767.9384439157884
INFO:root:current train perplexity4.006643295288086
INFO:root:current mean train loss 1761.6832979987648
INFO:root:current train perplexity3.9983441829681396
INFO:root:current mean train loss 1757.3544239331318
INFO:root:current train perplexity3.9870777130126953
INFO:root:current mean train loss 1749.7987013994637
INFO:root:current train perplexity3.972473382949829
INFO:root:current mean train loss 1747.2753404737352
INFO:root:current train perplexity3.967398166656494
INFO:root:current mean train loss 1747.2166157677061
INFO:root:current train perplexity3.9662373065948486
INFO:root:current mean train loss 1747.714513274672
INFO:root:current train perplexity3.9661223888397217
INFO:root:current mean train loss 1746.6805121745538
INFO:root:current train perplexity3.9649558067321777
INFO:root:current mean train loss 1748.1136984491545
INFO:root:current train perplexity3.9664194583892822
INFO:root:current mean train loss 1744.8000536107306
INFO:root:current train perplexity3.9624876976013184
INFO:root:current mean train loss 1745.1620972929554
INFO:root:current train perplexity3.9622867107391357
INFO:root:current mean train loss 1744.0887815847336
INFO:root:current train perplexity3.9621596336364746
INFO:root:current mean train loss 1745.0303613423605
INFO:root:current train perplexity3.963776111602783
INFO:root:current mean train loss 1745.667632807856
INFO:root:current train perplexity3.964993953704834
INFO:root:current mean train loss 1745.0261409070351
INFO:root:current train perplexity3.9625322818756104
INFO:root:current mean train loss 1745.0420042339124
INFO:root:current train perplexity3.960706949234009
INFO:root:current mean train loss 1746.9205052222947
INFO:root:current train perplexity3.964360237121582
INFO:root:current mean train loss 1747.3870013636401
INFO:root:current train perplexity3.9651708602905273
INFO:root:current mean train loss 1747.3606962935194
INFO:root:current train perplexity3.965808629989624

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.20s/it]
INFO:root:final mean train loss: 1746.9279035374905
INFO:root:final train perplexity: 3.965898275375366
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it]
INFO:root:eval mean loss: 1843.8689315471242
INFO:root:eval perplexity: 4.44248104095459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 2304.4868406471633
INFO:root:eval perplexity: 6.58419942855835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [10:12:29<4:17:03, 514.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1717.5145537987185
INFO:root:current train perplexity3.921674966812134
INFO:root:current mean train loss 1724.5027785528273
INFO:root:current train perplexity3.925001621246338
INFO:root:current mean train loss 1738.9832979090074
INFO:root:current train perplexity3.936845064163208
INFO:root:current mean train loss 1735.375849785106
INFO:root:current train perplexity3.9346227645874023
INFO:root:current mean train loss 1735.706432131902
INFO:root:current train perplexity3.9357523918151855
INFO:root:current mean train loss 1738.3900009699305
INFO:root:current train perplexity3.944812774658203
INFO:root:current mean train loss 1739.6445069776737
INFO:root:current train perplexity3.9472291469573975
INFO:root:current mean train loss 1739.8854678774062
INFO:root:current train perplexity3.9426989555358887
INFO:root:current mean train loss 1740.4584314198273
INFO:root:current train perplexity3.945178508758545
INFO:root:current mean train loss 1741.9475945606753
INFO:root:current train perplexity3.9496099948883057
INFO:root:current mean train loss 1739.4454761571683
INFO:root:current train perplexity3.944005250930786
INFO:root:current mean train loss 1739.518892973185
INFO:root:current train perplexity3.9438846111297607
INFO:root:current mean train loss 1738.535046585592
INFO:root:current train perplexity3.941154956817627
INFO:root:current mean train loss 1738.9947846359792
INFO:root:current train perplexity3.9436442852020264
INFO:root:current mean train loss 1740.1936733637824
INFO:root:current train perplexity3.946056365966797
INFO:root:current mean train loss 1740.9147201739745
INFO:root:current train perplexity3.9485018253326416
INFO:root:current mean train loss 1740.9077269134611
INFO:root:current train perplexity3.948214530944824
INFO:root:current mean train loss 1741.5555629399717
INFO:root:current train perplexity3.9475631713867188
INFO:root:current mean train loss 1742.1410171888442
INFO:root:current train perplexity3.9496710300445557

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.88s/it]
INFO:root:final mean train loss: 1741.543279404479
INFO:root:final train perplexity: 3.9490928649902344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.18s/it]
INFO:root:eval mean loss: 1841.2261724810228
INFO:root:eval perplexity: 4.432995319366455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it]
INFO:root:eval mean loss: 2303.6470466776095
INFO:root:eval perplexity: 6.579677581787109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [10:20:58<4:07:40, 512.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.9912923177083
INFO:root:current train perplexity3.8713014125823975
INFO:root:current mean train loss 1718.7278638155956
INFO:root:current train perplexity3.893848419189453
INFO:root:current mean train loss 1731.2961722068417
INFO:root:current train perplexity3.8991549015045166
INFO:root:current mean train loss 1733.93332726971
INFO:root:current train perplexity3.90883469581604
INFO:root:current mean train loss 1738.5617841147437
INFO:root:current train perplexity3.919942855834961
INFO:root:current mean train loss 1735.8490492025383
INFO:root:current train perplexity3.9231770038604736
INFO:root:current mean train loss 1735.9144871274236
INFO:root:current train perplexity3.9220592975616455
INFO:root:current mean train loss 1732.663112046023
INFO:root:current train perplexity3.916303873062134
INFO:root:current mean train loss 1730.8832482274058
INFO:root:current train perplexity3.9188241958618164
INFO:root:current mean train loss 1731.7757158763625
INFO:root:current train perplexity3.924696683883667
INFO:root:current mean train loss 1733.8951576187408
INFO:root:current train perplexity3.927079200744629
INFO:root:current mean train loss 1736.462123877748
INFO:root:current train perplexity3.9329893589019775
INFO:root:current mean train loss 1736.897518126328
INFO:root:current train perplexity3.9334797859191895
INFO:root:current mean train loss 1737.374932141618
INFO:root:current train perplexity3.936203718185425
INFO:root:current mean train loss 1737.9183613545185
INFO:root:current train perplexity3.937284469604492
INFO:root:current mean train loss 1738.1389064510188
INFO:root:current train perplexity3.937115430831909
INFO:root:current mean train loss 1738.3138433054999
INFO:root:current train perplexity3.93753981590271
INFO:root:current mean train loss 1738.8646353288943
INFO:root:current train perplexity3.9367945194244385
INFO:root:current mean train loss 1738.230546818223
INFO:root:current train perplexity3.9352803230285645
INFO:root:current mean train loss 1738.615137410439
INFO:root:current train perplexity3.936589479446411

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.43s/it]
INFO:root:final mean train loss: 1738.4983365072846
INFO:root:final train perplexity: 3.93962025642395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it]
INFO:root:eval mean loss: 1835.8538584607713
INFO:root:eval perplexity: 4.4137773513793945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 2298.9944219927415
INFO:root:eval perplexity: 6.554689884185791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [10:29:29<3:59:02, 512.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1777.0802320397418
INFO:root:current train perplexity3.97786808013916
INFO:root:current mean train loss 1747.2400041285568
INFO:root:current train perplexity3.938481569290161
INFO:root:current mean train loss 1734.8523929065652
INFO:root:current train perplexity3.911086320877075
INFO:root:current mean train loss 1732.9024711112859
INFO:root:current train perplexity3.907633066177368
INFO:root:current mean train loss 1733.61852305888
INFO:root:current train perplexity3.907271146774292
INFO:root:current mean train loss 1731.6429702437858
INFO:root:current train perplexity3.906167984008789
INFO:root:current mean train loss 1732.304852285125
INFO:root:current train perplexity3.9105913639068604
INFO:root:current mean train loss 1730.2407581123573
INFO:root:current train perplexity3.909804105758667
INFO:root:current mean train loss 1729.1917393847775
INFO:root:current train perplexity3.9088895320892334
INFO:root:current mean train loss 1731.5301903820762
INFO:root:current train perplexity3.9165830612182617
INFO:root:current mean train loss 1729.5594009891634
INFO:root:current train perplexity3.915015459060669
INFO:root:current mean train loss 1729.5993233848021
INFO:root:current train perplexity3.9138898849487305
INFO:root:current mean train loss 1729.5054730019995
INFO:root:current train perplexity3.913290023803711
INFO:root:current mean train loss 1729.6448228162792
INFO:root:current train perplexity3.913362741470337
INFO:root:current mean train loss 1730.5626605872276
INFO:root:current train perplexity3.9163150787353516
INFO:root:current mean train loss 1733.024641291217
INFO:root:current train perplexity3.921016216278076
INFO:root:current mean train loss 1732.1051238242742
INFO:root:current train perplexity3.9203522205352783
INFO:root:current mean train loss 1732.53331633937
INFO:root:current train perplexity3.9213833808898926
INFO:root:current mean train loss 1732.9006724647945
INFO:root:current train perplexity3.9233620166778564
INFO:root:current mean train loss 1733.394996424857
INFO:root:current train perplexity3.923619270324707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.93s/it]
INFO:root:final mean train loss: 1733.235682685148
INFO:root:final train perplexity: 3.9233031272888184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 1836.0571644018728
INFO:root:eval perplexity: 4.41450309753418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 2297.812935903563
INFO:root:eval perplexity: 6.548359394073486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [10:38:07<3:51:16, 513.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.499282836914
INFO:root:current train perplexity3.9271271228790283
INFO:root:current mean train loss 1723.969886125837
INFO:root:current train perplexity3.88427996635437
INFO:root:current mean train loss 1735.065217590332
INFO:root:current train perplexity3.901219367980957
INFO:root:current mean train loss 1731.0308184455423
INFO:root:current train perplexity3.906052827835083
INFO:root:current mean train loss 1732.69907060103
INFO:root:current train perplexity3.9111433029174805
INFO:root:current mean train loss 1733.8465777361835
INFO:root:current train perplexity3.909977436065674
INFO:root:current mean train loss 1732.7262517929078
INFO:root:current train perplexity3.9108798503875732
INFO:root:current mean train loss 1731.5603134567673
INFO:root:current train perplexity3.9094512462615967
INFO:root:current mean train loss 1731.6995463053386
INFO:root:current train perplexity3.9094371795654297
INFO:root:current mean train loss 1731.8426322774685
INFO:root:current train perplexity3.90993070602417
INFO:root:current mean train loss 1729.0135667067307
INFO:root:current train perplexity3.9045021533966064
INFO:root:current mean train loss 1729.011179284882
INFO:root:current train perplexity3.9049713611602783
INFO:root:current mean train loss 1729.8565122542843
INFO:root:current train perplexity3.9077556133270264
INFO:root:current mean train loss 1729.987057267374
INFO:root:current train perplexity3.908956289291382
INFO:root:current mean train loss 1729.8816411336263
INFO:root:current train perplexity3.9088523387908936
INFO:root:current mean train loss 1729.3366902933492
INFO:root:current train perplexity3.9077532291412354
INFO:root:current mean train loss 1728.0783023741187
INFO:root:current train perplexity3.906113862991333
INFO:root:current mean train loss 1728.9017136847835
INFO:root:current train perplexity3.9060723781585693
INFO:root:current mean train loss 1729.6780567998471
INFO:root:current train perplexity3.9083850383758545
INFO:root:current mean train loss 1729.7011891158586
INFO:root:current train perplexity3.9093868732452393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 452.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 452.00s/it]
INFO:root:final mean train loss: 1729.1612891092843
INFO:root:final train perplexity: 3.9107167720794678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 1832.6301979443706
INFO:root:eval perplexity: 4.402285575866699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it]
INFO:root:eval mean loss: 2297.2405637916945
INFO:root:eval perplexity: 6.545294284820557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [10:46:43<3:43:00, 514.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1674.5640783477247
INFO:root:current train perplexity3.809264898300171
INFO:root:current mean train loss 1717.4421596648588
INFO:root:current train perplexity3.8798303604125977
INFO:root:current mean train loss 1726.301734063412
INFO:root:current train perplexity3.8950936794281006
INFO:root:current mean train loss 1718.404516738336
INFO:root:current train perplexity3.8834664821624756
INFO:root:current mean train loss 1724.2580299293968
INFO:root:current train perplexity3.8927438259124756
INFO:root:current mean train loss 1718.8227648640877
INFO:root:current train perplexity3.88824200630188
INFO:root:current mean train loss 1721.2378204670852
INFO:root:current train perplexity3.891272783279419
INFO:root:current mean train loss 1723.2673505936777
INFO:root:current train perplexity3.8968729972839355
INFO:root:current mean train loss 1723.1796904912212
INFO:root:current train perplexity3.8992345333099365
INFO:root:current mean train loss 1724.7733753806247
INFO:root:current train perplexity3.9000422954559326
INFO:root:current mean train loss 1724.2799202766528
INFO:root:current train perplexity3.8969779014587402
INFO:root:current mean train loss 1724.3387086121502
INFO:root:current train perplexity3.898285388946533
INFO:root:current mean train loss 1725.0822630573475
INFO:root:current train perplexity3.8992855548858643
INFO:root:current mean train loss 1724.6493653063399
INFO:root:current train perplexity3.8970582485198975
INFO:root:current mean train loss 1725.6301548525169
INFO:root:current train perplexity3.899240493774414
INFO:root:current mean train loss 1726.0338141037703
INFO:root:current train perplexity3.901613235473633
INFO:root:current mean train loss 1725.4052602506647
INFO:root:current train perplexity3.899822473526001
INFO:root:current mean train loss 1725.9508231721552
INFO:root:current train perplexity3.9002368450164795
INFO:root:current mean train loss 1726.9147289894445
INFO:root:current train perplexity3.9019105434417725
INFO:root:current mean train loss 1726.0430774717959
INFO:root:current train perplexity3.899721622467041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.77s/it]
INFO:root:final mean train loss: 1725.3970679794365
INFO:root:final train perplexity: 3.8991243839263916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.14s/it]
INFO:root:eval mean loss: 1829.253088984929
INFO:root:eval perplexity: 4.390278339385986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.28s/it]
INFO:root:eval mean loss: 2293.542396491301
INFO:root:eval perplexity: 6.525528430938721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [10:55:29<3:35:46, 517.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.790672508446
INFO:root:current train perplexity3.8756861686706543
INFO:root:current mean train loss 1714.985750746453
INFO:root:current train perplexity3.870190382003784
INFO:root:current mean train loss 1712.3090949511006
INFO:root:current train perplexity3.8733043670654297
INFO:root:current mean train loss 1713.5664415002507
INFO:root:current train perplexity3.873972177505493
INFO:root:current mean train loss 1714.1774425908986
INFO:root:current train perplexity3.8713290691375732
INFO:root:current mean train loss 1718.4914995253293
INFO:root:current train perplexity3.876493453979492
INFO:root:current mean train loss 1719.2830006404163
INFO:root:current train perplexity3.8791000843048096
INFO:root:current mean train loss 1720.1272816423914
INFO:root:current train perplexity3.8781578540802
INFO:root:current mean train loss 1718.6351140980316
INFO:root:current train perplexity3.878009080886841
INFO:root:current mean train loss 1720.7338873453944
INFO:root:current train perplexity3.880398988723755
INFO:root:current mean train loss 1722.451152893862
INFO:root:current train perplexity3.882721185684204
INFO:root:current mean train loss 1721.8316579685504
INFO:root:current train perplexity3.8844332695007324
INFO:root:current mean train loss 1721.1167374495622
INFO:root:current train perplexity3.8851678371429443
INFO:root:current mean train loss 1723.1339760770618
INFO:root:current train perplexity3.8884692192077637
INFO:root:current mean train loss 1723.0407148384497
INFO:root:current train perplexity3.8889882564544678
INFO:root:current mean train loss 1722.894488827852
INFO:root:current train perplexity3.8899526596069336
INFO:root:current mean train loss 1723.369231120375
INFO:root:current train perplexity3.8898205757141113
INFO:root:current mean train loss 1723.62352538512
INFO:root:current train perplexity3.8896522521972656
INFO:root:current mean train loss 1723.4758613448005
INFO:root:current train perplexity3.8903417587280273
INFO:root:current mean train loss 1722.4137553453686
INFO:root:current train perplexity3.8886852264404297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.13s/it]
INFO:root:final mean train loss: 1722.0924978713103
INFO:root:final train perplexity: 3.8889753818511963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 1832.9621941316213
INFO:root:eval perplexity: 4.403467178344727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it]
INFO:root:eval mean loss: 2297.0974406790224
INFO:root:eval perplexity: 6.544528961181641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [11:04:00<3:26:20, 515.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1693.2428219973385
INFO:root:current train perplexity3.8819873332977295
INFO:root:current mean train loss 1714.0133791618946
INFO:root:current train perplexity3.8907229900360107
INFO:root:current mean train loss 1709.2930920787694
INFO:root:current train perplexity3.8882944583892822
INFO:root:current mean train loss 1706.3833588505036
INFO:root:current train perplexity3.864121675491333
INFO:root:current mean train loss 1705.8159159798242
INFO:root:current train perplexity3.8642189502716064
INFO:root:current mean train loss 1704.58178628318
INFO:root:current train perplexity3.8570072650909424
INFO:root:current mean train loss 1709.6923950018654
INFO:root:current train perplexity3.8628695011138916
INFO:root:current mean train loss 1710.9943555983823
INFO:root:current train perplexity3.8689370155334473
INFO:root:current mean train loss 1712.8111240716628
INFO:root:current train perplexity3.8722429275512695
INFO:root:current mean train loss 1713.5650814606852
INFO:root:current train perplexity3.871062755584717
INFO:root:current mean train loss 1713.576671233208
INFO:root:current train perplexity3.8719589710235596
INFO:root:current mean train loss 1715.4587361346164
INFO:root:current train perplexity3.874488353729248
INFO:root:current mean train loss 1715.4347796569398
INFO:root:current train perplexity3.8743128776550293
INFO:root:current mean train loss 1716.5811293689062
INFO:root:current train perplexity3.8739876747131348
INFO:root:current mean train loss 1716.7922416497684
INFO:root:current train perplexity3.8736002445220947
INFO:root:current mean train loss 1718.009554706528
INFO:root:current train perplexity3.877492666244507
INFO:root:current mean train loss 1718.1616400792568
INFO:root:current train perplexity3.8787026405334473
INFO:root:current mean train loss 1719.0848476595215
INFO:root:current train perplexity3.878525495529175
INFO:root:current mean train loss 1718.5282629246058
INFO:root:current train perplexity3.8782005310058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.90s/it]
INFO:root:final mean train loss: 1718.7284551746486
INFO:root:final train perplexity: 3.878671646118164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.91s/it]
INFO:root:eval mean loss: 1829.0173196995513
INFO:root:eval perplexity: 4.389440536499023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 2293.899667726341
INFO:root:eval perplexity: 6.52743673324585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [11:12:36<3:17:47, 515.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1632.3099212646484
INFO:root:current train perplexity3.7082717418670654
INFO:root:current mean train loss 1714.082004123264
INFO:root:current train perplexity3.848623275756836
INFO:root:current mean train loss 1714.5654584444487
INFO:root:current train perplexity3.869856357574463
INFO:root:current mean train loss 1707.0801447088068
INFO:root:current train perplexity3.857936143875122
INFO:root:current mean train loss 1707.5988978965609
INFO:root:current train perplexity3.8531665802001953
INFO:root:current mean train loss 1707.9778415950263
INFO:root:current train perplexity3.853595733642578
INFO:root:current mean train loss 1705.8147558914989
INFO:root:current train perplexity3.8502533435821533
INFO:root:current mean train loss 1704.4443385237355
INFO:root:current train perplexity3.8468379974365234
INFO:root:current mean train loss 1710.3050786386623
INFO:root:current train perplexity3.8563387393951416
INFO:root:current mean train loss 1711.4478410225083
INFO:root:current train perplexity3.857607364654541
INFO:root:current mean train loss 1712.6763549078078
INFO:root:current train perplexity3.861426830291748
INFO:root:current mean train loss 1713.7015656288781
INFO:root:current train perplexity3.8632335662841797
INFO:root:current mean train loss 1713.5610449582537
INFO:root:current train perplexity3.862415313720703
INFO:root:current mean train loss 1715.1027373800948
INFO:root:current train perplexity3.865298271179199
INFO:root:current mean train loss 1714.652345570651
INFO:root:current train perplexity3.86480712890625
INFO:root:current mean train loss 1715.5122030647744
INFO:root:current train perplexity3.8670146465301514
INFO:root:current mean train loss 1716.8718647363767
INFO:root:current train perplexity3.86867094039917
INFO:root:current mean train loss 1716.210437211834
INFO:root:current train perplexity3.8675918579101562
INFO:root:current mean train loss 1715.57684866306
INFO:root:current train perplexity3.8674216270446777
INFO:root:current mean train loss 1715.0888144695034
INFO:root:current train perplexity3.86678409576416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.63s/it]
INFO:root:final mean train loss: 1714.7279827754664
INFO:root:final train perplexity: 3.8664536476135254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 1826.5632358848625
INFO:root:eval perplexity: 4.3807373046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 2290.3203185602283
INFO:root:eval perplexity: 6.508357048034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [11:21:20<3:09:58, 518.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.2210791015625
INFO:root:current train perplexity3.8998546600341797
INFO:root:current mean train loss 1701.4050791015625
INFO:root:current train perplexity3.873357057571411
INFO:root:current mean train loss 1703.4014816623264
INFO:root:current train perplexity3.854205369949341
INFO:root:current mean train loss 1706.8280254657452
INFO:root:current train perplexity3.8582115173339844
INFO:root:current mean train loss 1708.9451542394302
INFO:root:current train perplexity3.864626169204712
INFO:root:current mean train loss 1710.4667824590774
INFO:root:current train perplexity3.8634612560272217
INFO:root:current mean train loss 1705.493184765625
INFO:root:current train perplexity3.8595848083496094
INFO:root:current mean train loss 1704.7103284954203
INFO:root:current train perplexity3.853139877319336
INFO:root:current mean train loss 1707.045068507339
INFO:root:current train perplexity3.851905107498169
INFO:root:current mean train loss 1707.3486826963683
INFO:root:current train perplexity3.852496862411499
INFO:root:current mean train loss 1705.8537359470274
INFO:root:current train perplexity3.8521971702575684
INFO:root:current mean train loss 1707.7215989583333
INFO:root:current train perplexity3.8528335094451904
INFO:root:current mean train loss 1710.004774493782
INFO:root:current train perplexity3.8561506271362305
INFO:root:current mean train loss 1710.0730981905956
INFO:root:current train perplexity3.8551127910614014
INFO:root:current mean train loss 1710.792517304002
INFO:root:current train perplexity3.855689287185669
INFO:root:current mean train loss 1710.99345703125
INFO:root:current train perplexity3.854937791824341
INFO:root:current mean train loss 1711.1157421875
INFO:root:current train perplexity3.856844902038574
INFO:root:current mean train loss 1711.1083548460144
INFO:root:current train perplexity3.8541905879974365
INFO:root:current mean train loss 1712.1606603167809
INFO:root:current train perplexity3.855634927749634
INFO:root:current mean train loss 1711.8638140472808
INFO:root:current train perplexity3.8556597232818604

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.76s/it]
INFO:root:final mean train loss: 1711.3476122973004
INFO:root:final train perplexity: 3.856158971786499
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it]
INFO:root:eval mean loss: 1824.4244917199967
INFO:root:eval perplexity: 4.373166561126709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2289.3785525923927
INFO:root:eval perplexity: 6.503345489501953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [11:29:54<3:00:58, 517.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1696.3360334123884
INFO:root:current train perplexity3.7932498455047607
INFO:root:current mean train loss 1724.266034193442
INFO:root:current train perplexity3.864511728286743
INFO:root:current mean train loss 1720.2054746013043
INFO:root:current train perplexity3.861767053604126
INFO:root:current mean train loss 1714.0157759817023
INFO:root:current train perplexity3.852424383163452
INFO:root:current mean train loss 1710.8515705091381
INFO:root:current train perplexity3.8537161350250244
INFO:root:current mean train loss 1707.9054497863094
INFO:root:current train perplexity3.844390630722046
INFO:root:current mean train loss 1710.864304396965
INFO:root:current train perplexity3.8493692874908447
INFO:root:current mean train loss 1712.787836532387
INFO:root:current train perplexity3.855617046356201
INFO:root:current mean train loss 1710.2054565139733
INFO:root:current train perplexity3.851658582687378
INFO:root:current mean train loss 1709.947972000025
INFO:root:current train perplexity3.8532662391662598
INFO:root:current mean train loss 1712.1692503711313
INFO:root:current train perplexity3.856085777282715
INFO:root:current mean train loss 1708.4899556014668
INFO:root:current train perplexity3.849658489227295
INFO:root:current mean train loss 1708.5436893776418
INFO:root:current train perplexity3.850259780883789
INFO:root:current mean train loss 1707.355572355131
INFO:root:current train perplexity3.8473751544952393
INFO:root:current mean train loss 1708.017327212097
INFO:root:current train perplexity3.849353313446045
INFO:root:current mean train loss 1709.1715317465143
INFO:root:current train perplexity3.8503987789154053
INFO:root:current mean train loss 1709.1120475369453
INFO:root:current train perplexity3.8489434719085693
INFO:root:current mean train loss 1708.4782333636804
INFO:root:current train perplexity3.8479604721069336
INFO:root:current mean train loss 1709.7437352481804
INFO:root:current train perplexity3.8497350215911865
INFO:root:current mean train loss 1709.0455228607145
INFO:root:current train perplexity3.848478317260742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.71s/it]
INFO:root:final mean train loss: 1709.2743953179663
INFO:root:final train perplexity: 3.8498594760894775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it]
INFO:root:eval mean loss: 1825.68196571296
INFO:root:eval perplexity: 4.3776164054870605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it]
INFO:root:eval mean loss: 2290.458951909491
INFO:root:eval perplexity: 6.50909423828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [11:38:33<2:52:35, 517.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.1474154197563
INFO:root:current train perplexity3.830824851989746
INFO:root:current mean train loss 1695.5186514224647
INFO:root:current train perplexity3.8032195568084717
INFO:root:current mean train loss 1691.7601898075532
INFO:root:current train perplexity3.8037586212158203
INFO:root:current mean train loss 1697.4087417305013
INFO:root:current train perplexity3.8114047050476074
INFO:root:current mean train loss 1699.0278080958947
INFO:root:current train perplexity3.8193554878234863
INFO:root:current mean train loss 1701.7984350542263
INFO:root:current train perplexity3.819593667984009
INFO:root:current mean train loss 1703.3529638079121
INFO:root:current train perplexity3.8233118057250977
INFO:root:current mean train loss 1702.3814618458705
INFO:root:current train perplexity3.8238396644592285
INFO:root:current mean train loss 1701.066152019745
INFO:root:current train perplexity3.8245229721069336
INFO:root:current mean train loss 1703.050813708738
INFO:root:current train perplexity3.8298773765563965
INFO:root:current mean train loss 1703.490387222247
INFO:root:current train perplexity3.8306427001953125
INFO:root:current mean train loss 1703.348554346251
INFO:root:current train perplexity3.830491065979004
INFO:root:current mean train loss 1704.9584667154302
INFO:root:current train perplexity3.833040475845337
INFO:root:current mean train loss 1705.2807404305497
INFO:root:current train perplexity3.833791732788086
INFO:root:current mean train loss 1705.7332731041702
INFO:root:current train perplexity3.834364891052246
INFO:root:current mean train loss 1705.3444502404136
INFO:root:current train perplexity3.835345506668091
INFO:root:current mean train loss 1706.9299871940223
INFO:root:current train perplexity3.8382411003112793
INFO:root:current mean train loss 1706.6188336795808
INFO:root:current train perplexity3.8395965099334717
INFO:root:current mean train loss 1705.6980099978148
INFO:root:current train perplexity3.838122606277466
INFO:root:current mean train loss 1706.1032389572167
INFO:root:current train perplexity3.8399596214294434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.41s/it]
INFO:root:final mean train loss: 1706.3254696783008
INFO:root:final train perplexity: 3.840916395187378
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 1825.5026868454954
INFO:root:eval perplexity: 4.376981258392334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2291.193636414007
INFO:root:eval perplexity: 6.513006687164307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [11:47:15<2:44:19, 518.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.5933805766858
INFO:root:current train perplexity3.865920305252075
INFO:root:current mean train loss 1709.9488379738548
INFO:root:current train perplexity3.8479626178741455
INFO:root:current mean train loss 1702.1023263240206
INFO:root:current train perplexity3.828535795211792
INFO:root:current mean train loss 1703.8671556838015
INFO:root:current train perplexity3.8356704711914062
INFO:root:current mean train loss 1702.9985405417049
INFO:root:current train perplexity3.8247787952423096
INFO:root:current mean train loss 1706.8687561882866
INFO:root:current train perplexity3.8298637866973877
INFO:root:current mean train loss 1706.6714777297523
INFO:root:current train perplexity3.8319995403289795
INFO:root:current mean train loss 1706.4610809640785
INFO:root:current train perplexity3.831199884414673
INFO:root:current mean train loss 1705.6227663641107
INFO:root:current train perplexity3.829183578491211
INFO:root:current mean train loss 1704.8459537693711
INFO:root:current train perplexity3.8256990909576416
INFO:root:current mean train loss 1704.1513287285447
INFO:root:current train perplexity3.8267366886138916
INFO:root:current mean train loss 1704.4364971757745
INFO:root:current train perplexity3.828373432159424
INFO:root:current mean train loss 1705.838021400954
INFO:root:current train perplexity3.8322253227233887
INFO:root:current mean train loss 1705.0133464724518
INFO:root:current train perplexity3.8306875228881836
INFO:root:current mean train loss 1702.6904506114763
INFO:root:current train perplexity3.8275580406188965
INFO:root:current mean train loss 1703.280951175593
INFO:root:current train perplexity3.8294007778167725
INFO:root:current mean train loss 1702.1466739627228
INFO:root:current train perplexity3.827258586883545
INFO:root:current mean train loss 1701.7236013326558
INFO:root:current train perplexity3.827233076095581
INFO:root:current mean train loss 1702.3313153557685
INFO:root:current train perplexity3.828228712081909
INFO:root:current mean train loss 1702.9328157370871
INFO:root:current train perplexity3.8295135498046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.74s/it]
INFO:root:final mean train loss: 1702.6086675708366
INFO:root:final train perplexity: 3.8296737670898438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it]
INFO:root:eval mean loss: 1821.9497931730662
INFO:root:eval perplexity: 4.364422798156738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.17s/it]
INFO:root:eval mean loss: 2287.7563459247563
INFO:root:eval perplexity: 6.494723320007324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [11:55:57<2:35:58, 519.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1699.669669858871
INFO:root:current train perplexity3.8205695152282715
INFO:root:current mean train loss 1708.5482310556995
INFO:root:current train perplexity3.853191375732422
INFO:root:current mean train loss 1706.206667538796
INFO:root:current train perplexity3.844569683074951
INFO:root:current mean train loss 1706.7354984817312
INFO:root:current train perplexity3.8384835720062256
INFO:root:current mean train loss 1707.2369800745594
INFO:root:current train perplexity3.8382556438446045
INFO:root:current mean train loss 1710.1496740537389
INFO:root:current train perplexity3.8441665172576904
INFO:root:current mean train loss 1708.477648802478
INFO:root:current train perplexity3.8478920459747314
INFO:root:current mean train loss 1707.869825019211
INFO:root:current train perplexity3.8471527099609375
INFO:root:current mean train loss 1706.2493014789509
INFO:root:current train perplexity3.8402886390686035
INFO:root:current mean train loss 1707.8094109941464
INFO:root:current train perplexity3.842083215713501
INFO:root:current mean train loss 1707.5795811324194
INFO:root:current train perplexity3.839844226837158
INFO:root:current mean train loss 1706.8671177163008
INFO:root:current train perplexity3.8400497436523438
INFO:root:current mean train loss 1704.5921810235704
INFO:root:current train perplexity3.8353559970855713
INFO:root:current mean train loss 1703.7287666884927
INFO:root:current train perplexity3.8333377838134766
INFO:root:current mean train loss 1702.6301779724652
INFO:root:current train perplexity3.8292336463928223
INFO:root:current mean train loss 1702.8829328844702
INFO:root:current train perplexity3.8261542320251465
INFO:root:current mean train loss 1702.1935858503996
INFO:root:current train perplexity3.8268191814422607
INFO:root:current mean train loss 1701.9938966886198
INFO:root:current train perplexity3.82690691947937
INFO:root:current mean train loss 1702.0732676591183
INFO:root:current train perplexity3.826115369796753

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.23s/it]
INFO:root:final mean train loss: 1700.9726611131139
INFO:root:final train perplexity: 3.824735403060913
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 1822.7267819668384
INFO:root:eval perplexity: 4.367166519165039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it]
INFO:root:eval mean loss: 2289.8506357179467
INFO:root:eval perplexity: 6.505856037139893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [12:04:37<2:27:18, 519.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1684.7611572265625
INFO:root:current train perplexity3.815727472305298
INFO:root:current mean train loss 1689.2697498668324
INFO:root:current train perplexity3.7941677570343018
INFO:root:current mean train loss 1693.9635986328126
INFO:root:current train perplexity3.798952579498291
INFO:root:current mean train loss 1695.5002976940525
INFO:root:current train perplexity3.8001980781555176
INFO:root:current mean train loss 1693.1618050924162
INFO:root:current train perplexity3.7987990379333496
INFO:root:current mean train loss 1694.9420438878676
INFO:root:current train perplexity3.803555965423584
INFO:root:current mean train loss 1692.4841996990267
INFO:root:current train perplexity3.8027195930480957
INFO:root:current mean train loss 1691.4143895108934
INFO:root:current train perplexity3.802675247192383
INFO:root:current mean train loss 1690.0083006305458
INFO:root:current train perplexity3.7996408939361572
INFO:root:current mean train loss 1690.6176451966003
INFO:root:current train perplexity3.802445411682129
INFO:root:current mean train loss 1693.672796812152
INFO:root:current train perplexity3.805232286453247
INFO:root:current mean train loss 1693.2681946350647
INFO:root:current train perplexity3.8042352199554443
INFO:root:current mean train loss 1694.5331082935177
INFO:root:current train perplexity3.8065760135650635
INFO:root:current mean train loss 1694.8785819716127
INFO:root:current train perplexity3.809535026550293
INFO:root:current mean train loss 1694.9932769558955
INFO:root:current train perplexity3.810823917388916
INFO:root:current mean train loss 1695.7596978800186
INFO:root:current train perplexity3.8113861083984375
INFO:root:current mean train loss 1696.317351347171
INFO:root:current train perplexity3.8127284049987793
INFO:root:current mean train loss 1695.2779009188826
INFO:root:current train perplexity3.8113605976104736
INFO:root:current mean train loss 1696.8948889632252
INFO:root:current train perplexity3.8139843940734863
INFO:root:current mean train loss 1697.8714003318266
INFO:root:current train perplexity3.8144659996032715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.00s/it]
INFO:root:final mean train loss: 1698.2386305323769
INFO:root:final train perplexity: 3.816497325897217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it]
INFO:root:eval mean loss: 1824.7287788120568
INFO:root:eval perplexity: 4.37424373626709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it]
INFO:root:eval mean loss: 2291.9465349346187
INFO:root:eval perplexity: 6.5170183181762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [12:13:16<2:18:34, 519.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1677.885281032986
INFO:root:current train perplexity3.795630931854248
INFO:root:current mean train loss 1695.8800308347686
INFO:root:current train perplexity3.810309886932373
INFO:root:current mean train loss 1703.694305823238
INFO:root:current train perplexity3.821152925491333
INFO:root:current mean train loss 1694.316309191036
INFO:root:current train perplexity3.8080883026123047
INFO:root:current mean train loss 1694.1004278464395
INFO:root:current train perplexity3.803560972213745
INFO:root:current mean train loss 1694.0505285389736
INFO:root:current train perplexity3.799840211868286
INFO:root:current mean train loss 1695.0205699184485
INFO:root:current train perplexity3.801598310470581
INFO:root:current mean train loss 1698.6554425225133
INFO:root:current train perplexity3.8097317218780518
INFO:root:current mean train loss 1698.106200286238
INFO:root:current train perplexity3.8085291385650635
INFO:root:current mean train loss 1695.6272473052354
INFO:root:current train perplexity3.8025922775268555
INFO:root:current mean train loss 1694.175818572374
INFO:root:current train perplexity3.7982678413391113
INFO:root:current mean train loss 1697.0574482170587
INFO:root:current train perplexity3.80265736579895
INFO:root:current mean train loss 1696.4496711165125
INFO:root:current train perplexity3.802919864654541
INFO:root:current mean train loss 1696.2237852394087
INFO:root:current train perplexity3.803086757659912
INFO:root:current mean train loss 1696.307056707691
INFO:root:current train perplexity3.802555561065674
INFO:root:current mean train loss 1695.2792828053373
INFO:root:current train perplexity3.802034616470337
INFO:root:current mean train loss 1694.7498237595796
INFO:root:current train perplexity3.801474094390869
INFO:root:current mean train loss 1695.4482732882166
INFO:root:current train perplexity3.805219888687134
INFO:root:current mean train loss 1695.5876839005628
INFO:root:current train perplexity3.8064463138580322
INFO:root:current mean train loss 1696.2730469636863
INFO:root:current train perplexity3.80820369720459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.94s/it]
INFO:root:final mean train loss: 1695.4336376719202
INFO:root:final train perplexity: 3.8080642223358154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.04s/it]
INFO:root:eval mean loss: 1822.6019642065603
INFO:root:eval perplexity: 4.366725444793701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it]
INFO:root:eval mean loss: 2289.9340841956173
INFO:root:eval perplexity: 6.50629997253418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [12:22:03<2:10:25, 521.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1672.751875443892
INFO:root:current train perplexity3.747361421585083
INFO:root:current mean train loss 1681.7469931708442
INFO:root:current train perplexity3.780764102935791
INFO:root:current mean train loss 1689.2862058545722
INFO:root:current train perplexity3.802042007446289
INFO:root:current mean train loss 1692.8612433145213
INFO:root:current train perplexity3.803184747695923
INFO:root:current mean train loss 1695.1055789981876
INFO:root:current train perplexity3.807251453399658
INFO:root:current mean train loss 1696.2859802246094
INFO:root:current train perplexity3.8093647956848145
INFO:root:current mean train loss 1696.706041608538
INFO:root:current train perplexity3.806978225708008
INFO:root:current mean train loss 1699.309601158224
INFO:root:current train perplexity3.810493230819702
INFO:root:current mean train loss 1700.1805343266346
INFO:root:current train perplexity3.8114733695983887
INFO:root:current mean train loss 1699.167367708885
INFO:root:current train perplexity3.8079445362091064
INFO:root:current mean train loss 1696.9378213115122
INFO:root:current train perplexity3.8042125701904297
INFO:root:current mean train loss 1695.1541252936518
INFO:root:current train perplexity3.8008813858032227
INFO:root:current mean train loss 1696.240771621753
INFO:root:current train perplexity3.80234956741333
INFO:root:current mean train loss 1695.9928926740374
INFO:root:current train perplexity3.8016412258148193
INFO:root:current mean train loss 1697.0679431186159
INFO:root:current train perplexity3.804379463195801
INFO:root:current mean train loss 1696.3312064847798
INFO:root:current train perplexity3.802934408187866
INFO:root:current mean train loss 1695.1743853863718
INFO:root:current train perplexity3.801410675048828
INFO:root:current mean train loss 1694.317705696876
INFO:root:current train perplexity3.801290988922119
INFO:root:current mean train loss 1693.549834079701
INFO:root:current train perplexity3.800855875015259
INFO:root:current mean train loss 1693.144108525029
INFO:root:current train perplexity3.800675630569458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.93s/it]
INFO:root:final mean train loss: 1692.946849951886
INFO:root:final train perplexity: 3.800603151321411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it]
INFO:root:eval mean loss: 1819.2583090058456
INFO:root:eval perplexity: 4.354933261871338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it]
INFO:root:eval mean loss: 2286.8243551051364
INFO:root:eval perplexity: 6.489773750305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [12:30:40<2:01:22, 520.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1686.4758280769724
INFO:root:current train perplexity3.7756330966949463
INFO:root:current mean train loss 1684.1265626516401
INFO:root:current train perplexity3.7870728969573975
INFO:root:current mean train loss 1689.8689123862548
INFO:root:current train perplexity3.8033447265625
INFO:root:current mean train loss 1689.875826764305
INFO:root:current train perplexity3.800814390182495
INFO:root:current mean train loss 1687.671374802993
INFO:root:current train perplexity3.7938449382781982
INFO:root:current mean train loss 1686.2350458427334
INFO:root:current train perplexity3.7947046756744385
INFO:root:current mean train loss 1686.6471931584483
INFO:root:current train perplexity3.790208101272583
INFO:root:current mean train loss 1688.6191518535438
INFO:root:current train perplexity3.7949671745300293
INFO:root:current mean train loss 1688.0867189768437
INFO:root:current train perplexity3.792680025100708
INFO:root:current mean train loss 1687.5566359251025
INFO:root:current train perplexity3.792285442352295
INFO:root:current mean train loss 1687.024971720186
INFO:root:current train perplexity3.7892775535583496
INFO:root:current mean train loss 1688.1072304107115
INFO:root:current train perplexity3.7897138595581055
INFO:root:current mean train loss 1688.2870247679793
INFO:root:current train perplexity3.7906088829040527
INFO:root:current mean train loss 1689.4609703271376
INFO:root:current train perplexity3.790536642074585
INFO:root:current mean train loss 1690.3037085144754
INFO:root:current train perplexity3.791855812072754
INFO:root:current mean train loss 1689.6561757881316
INFO:root:current train perplexity3.788748264312744
INFO:root:current mean train loss 1688.9164264456183
INFO:root:current train perplexity3.7880423069000244
INFO:root:current mean train loss 1689.0761225200524
INFO:root:current train perplexity3.78859543800354
INFO:root:current mean train loss 1690.219800880428
INFO:root:current train perplexity3.7936513423919678
INFO:root:current mean train loss 1692.0143615318038
INFO:root:current train perplexity3.7959322929382324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.91s/it]
INFO:root:final mean train loss: 1691.3786396713372
INFO:root:final train perplexity: 3.795905590057373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 1819.6715486134199
INFO:root:eval perplexity: 4.356389045715332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2287.5243062770114
INFO:root:eval perplexity: 6.493490695953369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [12:39:24<1:52:57, 521.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.8777465820312
INFO:root:current train perplexity3.7642176151275635
INFO:root:current mean train loss 1702.1786025829529
INFO:root:current train perplexity3.805619716644287
INFO:root:current mean train loss 1690.671389353361
INFO:root:current train perplexity3.781733751296997
INFO:root:current mean train loss 1691.7124152612435
INFO:root:current train perplexity3.7820005416870117
INFO:root:current mean train loss 1693.2353735249412
INFO:root:current train perplexity3.790470600128174
INFO:root:current mean train loss 1692.9115317585558
INFO:root:current train perplexity3.788968563079834
INFO:root:current mean train loss 1693.0199536348866
INFO:root:current train perplexity3.7897517681121826
INFO:root:current mean train loss 1692.2709069730076
INFO:root:current train perplexity3.788712978363037
INFO:root:current mean train loss 1690.9597541965493
INFO:root:current train perplexity3.791266441345215
INFO:root:current mean train loss 1691.4728654420692
INFO:root:current train perplexity3.7937259674072266
INFO:root:current mean train loss 1689.2762454569008
INFO:root:current train perplexity3.7909882068634033
INFO:root:current mean train loss 1690.9199789724041
INFO:root:current train perplexity3.791898012161255
INFO:root:current mean train loss 1690.7218387227663
INFO:root:current train perplexity3.7925164699554443
INFO:root:current mean train loss 1690.7233895577263
INFO:root:current train perplexity3.791569232940674
INFO:root:current mean train loss 1691.855064546949
INFO:root:current train perplexity3.7928872108459473
INFO:root:current mean train loss 1690.116258435074
INFO:root:current train perplexity3.7888898849487305
INFO:root:current mean train loss 1691.5119121128669
INFO:root:current train perplexity3.7926719188690186
INFO:root:current mean train loss 1690.9973686226845
INFO:root:current train perplexity3.7915070056915283
INFO:root:current mean train loss 1690.8777786921135
INFO:root:current train perplexity3.7924561500549316
INFO:root:current mean train loss 1690.3494383037632
INFO:root:current train perplexity3.7915520668029785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.38s/it]
INFO:root:final mean train loss: 1690.001822405732
INFO:root:final train perplexity: 3.791785955429077
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it]
INFO:root:eval mean loss: 1817.8385702363144
INFO:root:eval perplexity: 4.349936008453369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it]
INFO:root:eval mean loss: 2284.1934108869405
INFO:root:eval perplexity: 6.47582483291626
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [12:47:56<1:43:45, 518.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1690.7693526418586
INFO:root:current train perplexity3.7929255962371826
INFO:root:current mean train loss 1682.9112123147036
INFO:root:current train perplexity3.7725608348846436
INFO:root:current mean train loss 1685.6544230832892
INFO:root:current train perplexity3.7737410068511963
INFO:root:current mean train loss 1680.6142071301424
INFO:root:current train perplexity3.7715399265289307
INFO:root:current mean train loss 1686.9399458451705
INFO:root:current train perplexity3.7837624549865723
INFO:root:current mean train loss 1687.4332511324842
INFO:root:current train perplexity3.782965898513794
INFO:root:current mean train loss 1687.4397756013939
INFO:root:current train perplexity3.784843921661377
INFO:root:current mean train loss 1687.2605071061812
INFO:root:current train perplexity3.7824671268463135
INFO:root:current mean train loss 1690.6729055734986
INFO:root:current train perplexity3.7848026752471924
INFO:root:current mean train loss 1689.6710827084642
INFO:root:current train perplexity3.787909984588623
INFO:root:current mean train loss 1690.6328958868437
INFO:root:current train perplexity3.787466049194336
INFO:root:current mean train loss 1690.5494621755688
INFO:root:current train perplexity3.7905895709991455
INFO:root:current mean train loss 1690.0436356592363
INFO:root:current train perplexity3.7883732318878174
INFO:root:current mean train loss 1689.956978046595
INFO:root:current train perplexity3.7861361503601074
INFO:root:current mean train loss 1689.3279063349185
INFO:root:current train perplexity3.785879373550415
INFO:root:current mean train loss 1688.1925294499413
INFO:root:current train perplexity3.7857823371887207
INFO:root:current mean train loss 1687.5458643010231
INFO:root:current train perplexity3.782571792602539
INFO:root:current mean train loss 1686.5985317559628
INFO:root:current train perplexity3.7803144454956055
INFO:root:current mean train loss 1686.4392839658228
INFO:root:current train perplexity3.7803561687469482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.14s/it]
INFO:root:final mean train loss: 1686.2044625717524
INFO:root:final train perplexity: 3.780446767807007
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it]
INFO:root:eval mean loss: 1820.0728963216145
INFO:root:eval perplexity: 4.357802867889404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it]
INFO:root:eval mean loss: 2287.4568650265956
INFO:root:eval perplexity: 6.493133068084717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [12:56:39<1:35:19, 519.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.6440938313801
INFO:root:current train perplexity3.8494107723236084
INFO:root:current mean train loss 1680.8569891793388
INFO:root:current train perplexity3.7470004558563232
INFO:root:current mean train loss 1681.7226142163547
INFO:root:current train perplexity3.749743700027466
INFO:root:current mean train loss 1681.1071350880159
INFO:root:current train perplexity3.759582996368408
INFO:root:current mean train loss 1682.2382575470267
INFO:root:current train perplexity3.766326427459717
INFO:root:current mean train loss 1686.755565404892
INFO:root:current train perplexity3.7803192138671875
INFO:root:current mean train loss 1690.4436314402062
INFO:root:current train perplexity3.785804510116577
INFO:root:current mean train loss 1688.7867985414655
INFO:root:current train perplexity3.7848384380340576
INFO:root:current mean train loss 1687.952424899698
INFO:root:current train perplexity3.788641929626465
INFO:root:current mean train loss 1689.0109781633344
INFO:root:current train perplexity3.7920727729797363
INFO:root:current mean train loss 1689.7287945050025
INFO:root:current train perplexity3.7914459705352783
INFO:root:current mean train loss 1689.0986958236144
INFO:root:current train perplexity3.786993980407715
INFO:root:current mean train loss 1688.9963514875658
INFO:root:current train perplexity3.7853081226348877
INFO:root:current mean train loss 1688.6955839947957
INFO:root:current train perplexity3.784682273864746
INFO:root:current mean train loss 1687.7616362747322
INFO:root:current train perplexity3.781899929046631
INFO:root:current mean train loss 1687.1960102868459
INFO:root:current train perplexity3.78056263923645
INFO:root:current mean train loss 1686.4673264269202
INFO:root:current train perplexity3.7803454399108887
INFO:root:current mean train loss 1686.3610603118611
INFO:root:current train perplexity3.7803220748901367
INFO:root:current mean train loss 1685.5491483237834
INFO:root:current train perplexity3.776954412460327
INFO:root:current mean train loss 1684.917154671258
INFO:root:current train perplexity3.7757272720336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.36s/it]
INFO:root:final mean train loss: 1684.5289127197882
INFO:root:final train perplexity: 3.7754549980163574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 1813.8545263845024
INFO:root:eval perplexity: 4.335942268371582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it]
INFO:root:eval mean loss: 2282.2138204371677
INFO:root:eval perplexity: 6.46535062789917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [13:05:14<1:26:26, 518.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1630.9890220905172
INFO:root:current train perplexity3.6935698986053467
INFO:root:current mean train loss 1679.0783842811288
INFO:root:current train perplexity3.770120859146118
INFO:root:current mean train loss 1681.043632940434
INFO:root:current train perplexity3.782883405685425
INFO:root:current mean train loss 1679.46588969593
INFO:root:current train perplexity3.778839588165283
INFO:root:current mean train loss 1684.8072956503133
INFO:root:current train perplexity3.7807321548461914
INFO:root:current mean train loss 1685.310836936215
INFO:root:current train perplexity3.7726786136627197
INFO:root:current mean train loss 1685.50509027381
INFO:root:current train perplexity3.772775650024414
INFO:root:current mean train loss 1685.3352697134344
INFO:root:current train perplexity3.774364709854126
INFO:root:current mean train loss 1683.886336047054
INFO:root:current train perplexity3.7698984146118164
INFO:root:current mean train loss 1684.4486593815175
INFO:root:current train perplexity3.7702436447143555
INFO:root:current mean train loss 1684.906726774136
INFO:root:current train perplexity3.7729780673980713
INFO:root:current mean train loss 1683.993968710211
INFO:root:current train perplexity3.7725143432617188
INFO:root:current mean train loss 1685.3026250182759
INFO:root:current train perplexity3.776371479034424
INFO:root:current mean train loss 1684.3088048241746
INFO:root:current train perplexity3.77490496635437
INFO:root:current mean train loss 1685.4904551949844
INFO:root:current train perplexity3.7780721187591553
INFO:root:current mean train loss 1685.591143730967
INFO:root:current train perplexity3.7768611907958984
INFO:root:current mean train loss 1686.0733817927746
INFO:root:current train perplexity3.7763943672180176
INFO:root:current mean train loss 1685.1029952199835
INFO:root:current train perplexity3.7735254764556885
INFO:root:current mean train loss 1683.8730468082586
INFO:root:current train perplexity3.7716610431671143
INFO:root:current mean train loss 1683.5882610758083
INFO:root:current train perplexity3.7712290287017822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.00s/it]
INFO:root:final mean train loss: 1682.8885467883258
INFO:root:final train perplexity: 3.770573854446411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 1813.1145893935616
INFO:root:eval perplexity: 4.333348751068115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it]
INFO:root:eval mean loss: 2281.25474472587
INFO:root:eval perplexity: 6.460280418395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [13:13:46<1:17:27, 516.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1653.3997218919837
INFO:root:current train perplexity3.6935439109802246
INFO:root:current mean train loss 1660.1050866531998
INFO:root:current train perplexity3.722224235534668
INFO:root:current mean train loss 1668.0026091288744
INFO:root:current train perplexity3.7348625659942627
INFO:root:current mean train loss 1668.6975775040644
INFO:root:current train perplexity3.7420670986175537
INFO:root:current mean train loss 1671.6228662328335
INFO:root:current train perplexity3.743201494216919
INFO:root:current mean train loss 1674.9637075570913
INFO:root:current train perplexity3.756112575531006
INFO:root:current mean train loss 1675.966990940342
INFO:root:current train perplexity3.755064010620117
INFO:root:current mean train loss 1678.7801408946673
INFO:root:current train perplexity3.759803056716919
INFO:root:current mean train loss 1677.712791208398
INFO:root:current train perplexity3.7599849700927734
INFO:root:current mean train loss 1677.7251735308205
INFO:root:current train perplexity3.7608022689819336
INFO:root:current mean train loss 1680.8448229583682
INFO:root:current train perplexity3.764573097229004
INFO:root:current mean train loss 1679.3394283274706
INFO:root:current train perplexity3.762282371520996
INFO:root:current mean train loss 1680.7565731826219
INFO:root:current train perplexity3.764683485031128
INFO:root:current mean train loss 1681.265292526177
INFO:root:current train perplexity3.764998197555542
INFO:root:current mean train loss 1682.3065425297696
INFO:root:current train perplexity3.766214609146118
INFO:root:current mean train loss 1681.7440581130488
INFO:root:current train perplexity3.765240430831909
INFO:root:current mean train loss 1682.3934329138347
INFO:root:current train perplexity3.767314910888672
INFO:root:current mean train loss 1681.5406475263771
INFO:root:current train perplexity3.7658352851867676
INFO:root:current mean train loss 1680.8428011446836
INFO:root:current train perplexity3.764313220977783
INFO:root:current mean train loss 1681.3318233039126
INFO:root:current train perplexity3.7653298377990723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it]
INFO:root:final mean train loss: 1681.1539895754538
INFO:root:final train perplexity: 3.765418767929077
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it]
INFO:root:eval mean loss: 1812.2472464919936
INFO:root:eval perplexity: 4.330309867858887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
INFO:root:eval mean loss: 2280.7041625976562
INFO:root:eval perplexity: 6.457372188568115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [13:22:28<1:09:04, 518.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1655.4834197513642
INFO:root:current train perplexity3.7220449447631836
INFO:root:current mean train loss 1665.0512837603048
INFO:root:current train perplexity3.7493841648101807
INFO:root:current mean train loss 1673.822947919142
INFO:root:current train perplexity3.7605221271514893
INFO:root:current mean train loss 1673.7959273577394
INFO:root:current train perplexity3.756368637084961
INFO:root:current mean train loss 1674.4334289682606
INFO:root:current train perplexity3.7544007301330566
INFO:root:current mean train loss 1672.121509612983
INFO:root:current train perplexity3.7490034103393555
INFO:root:current mean train loss 1675.0396605156486
INFO:root:current train perplexity3.7562131881713867
INFO:root:current mean train loss 1676.3350694088917
INFO:root:current train perplexity3.7563717365264893
INFO:root:current mean train loss 1678.0291063434693
INFO:root:current train perplexity3.758796453475952
INFO:root:current mean train loss 1677.6503408081435
INFO:root:current train perplexity3.7553796768188477
INFO:root:current mean train loss 1679.961563469213
INFO:root:current train perplexity3.7583913803100586
INFO:root:current mean train loss 1680.3074785332585
INFO:root:current train perplexity3.759028673171997
INFO:root:current mean train loss 1680.8211252389215
INFO:root:current train perplexity3.760619640350342
INFO:root:current mean train loss 1680.5073161583477
INFO:root:current train perplexity3.758645534515381
INFO:root:current mean train loss 1679.4054911281667
INFO:root:current train perplexity3.7576329708099365
INFO:root:current mean train loss 1679.3315789728538
INFO:root:current train perplexity3.756563425064087
INFO:root:current mean train loss 1678.7266497769704
INFO:root:current train perplexity3.7573204040527344
INFO:root:current mean train loss 1678.1743682670917
INFO:root:current train perplexity3.755575656890869
INFO:root:current mean train loss 1678.9786670498481
INFO:root:current train perplexity3.7573840618133545
INFO:root:current mean train loss 1678.4814956206421
INFO:root:current train perplexity3.7556724548339844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.01s/it]
INFO:root:final mean train loss: 1677.9463863555554
INFO:root:final train perplexity: 3.755906105041504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it]
INFO:root:eval mean loss: 1811.6613250083112
INFO:root:eval perplexity: 4.328258991241455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 2280.037782926086
INFO:root:eval perplexity: 6.453853607177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [13:31:01<1:00:17, 516.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1666.093115234375
INFO:root:current train perplexity3.7253923416137695
INFO:root:current mean train loss 1683.305603705512
INFO:root:current train perplexity3.7563865184783936
INFO:root:current mean train loss 1681.056593976702
INFO:root:current train perplexity3.7536520957946777
INFO:root:current mean train loss 1679.4126249614515
INFO:root:current train perplexity3.746636390686035
INFO:root:current mean train loss 1675.9157203674317
INFO:root:current train perplexity3.7454569339752197
INFO:root:current mean train loss 1675.8836621514681
INFO:root:current train perplexity3.746807813644409
INFO:root:current mean train loss 1677.1313643511603
INFO:root:current train perplexity3.7489380836486816
INFO:root:current mean train loss 1677.3124591533954
INFO:root:current train perplexity3.748706340789795
INFO:root:current mean train loss 1676.740309420499
INFO:root:current train perplexity3.7508881092071533
INFO:root:current mean train loss 1678.7112441705199
INFO:root:current train perplexity3.7549033164978027
INFO:root:current mean train loss 1677.4271057128906
INFO:root:current train perplexity3.752164840698242
INFO:root:current mean train loss 1677.8274449235303
INFO:root:current train perplexity3.752542018890381
INFO:root:current mean train loss 1676.994490146637
INFO:root:current train perplexity3.751420736312866
INFO:root:current mean train loss 1677.134645500736
INFO:root:current train perplexity3.7500391006469727
INFO:root:current mean train loss 1676.655589913033
INFO:root:current train perplexity3.7506349086761475
INFO:root:current mean train loss 1678.5725813080992
INFO:root:current train perplexity3.7553765773773193
INFO:root:current mean train loss 1679.1727556501116
INFO:root:current train perplexity3.757223606109619
INFO:root:current mean train loss 1678.8215216818821
INFO:root:current train perplexity3.756298780441284
INFO:root:current mean train loss 1678.2722193941156
INFO:root:current train perplexity3.7550156116485596
INFO:root:current mean train loss 1677.9281565040048
INFO:root:current train perplexity3.7545456886291504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.78s/it]
INFO:root:final mean train loss: 1677.4867782400404
INFO:root:final train perplexity: 3.754544258117676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it]
INFO:root:eval mean loss: 1810.7662903264904
INFO:root:eval perplexity: 4.325126647949219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 2280.0180148943095
INFO:root:eval perplexity: 6.453749656677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [13:39:29<51:24, 514.12s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1673.621721719958
INFO:root:current train perplexity3.7614428997039795
INFO:root:current mean train loss 1677.8909633268559
INFO:root:current train perplexity3.7653968334198
INFO:root:current mean train loss 1672.177417896412
INFO:root:current train perplexity3.7518227100372314
INFO:root:current mean train loss 1669.7978936875197
INFO:root:current train perplexity3.7411437034606934
INFO:root:current mean train loss 1669.206791039204
INFO:root:current train perplexity3.745598077774048
INFO:root:current mean train loss 1670.783979917491
INFO:root:current train perplexity3.7505204677581787
INFO:root:current mean train loss 1670.6721956753834
INFO:root:current train perplexity3.7482097148895264
INFO:root:current mean train loss 1675.0498383831948
INFO:root:current train perplexity3.7552859783172607
INFO:root:current mean train loss 1677.0374357123571
INFO:root:current train perplexity3.7575018405914307
INFO:root:current mean train loss 1675.5789006423568
INFO:root:current train perplexity3.753131628036499
INFO:root:current mean train loss 1676.267875567065
INFO:root:current train perplexity3.752772808074951
INFO:root:current mean train loss 1677.2175402087576
INFO:root:current train perplexity3.7536849975585938
INFO:root:current mean train loss 1676.939594771739
INFO:root:current train perplexity3.752735137939453
INFO:root:current mean train loss 1676.5445239450048
INFO:root:current train perplexity3.7493789196014404
INFO:root:current mean train loss 1676.167991419036
INFO:root:current train perplexity3.7472264766693115
INFO:root:current mean train loss 1676.550636554257
INFO:root:current train perplexity3.7475128173828125
INFO:root:current mean train loss 1675.203443807086
INFO:root:current train perplexity3.7467052936553955
INFO:root:current mean train loss 1676.066210883156
INFO:root:current train perplexity3.749305486679077
INFO:root:current mean train loss 1676.4712227442797
INFO:root:current train perplexity3.7499442100524902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it]
INFO:root:final mean train loss: 1675.7020890644205
INFO:root:final train perplexity: 3.7492640018463135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.51s/it]
INFO:root:eval mean loss: 1809.6694803440826
INFO:root:eval perplexity: 4.321291923522949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it]
INFO:root:eval mean loss: 2278.060316153452
INFO:root:eval perplexity: 6.44342565536499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [13:48:11<43:01, 516.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.9759783063616
INFO:root:current train perplexity3.849264621734619
INFO:root:current mean train loss 1674.099843878495
INFO:root:current train perplexity3.771376848220825
INFO:root:current mean train loss 1681.8438224435968
INFO:root:current train perplexity3.758165121078491
INFO:root:current mean train loss 1681.5876943017267
INFO:root:current train perplexity3.765373468399048
INFO:root:current mean train loss 1681.848851300668
INFO:root:current train perplexity3.7587404251098633
INFO:root:current mean train loss 1679.034612633375
INFO:root:current train perplexity3.7509140968322754
INFO:root:current mean train loss 1677.8483956302805
INFO:root:current train perplexity3.7531254291534424
INFO:root:current mean train loss 1676.2707589627648
INFO:root:current train perplexity3.7478702068328857
INFO:root:current mean train loss 1676.6127724237465
INFO:root:current train perplexity3.7478063106536865
INFO:root:current mean train loss 1675.2136194408592
INFO:root:current train perplexity3.743964672088623
INFO:root:current mean train loss 1674.3716570310573
INFO:root:current train perplexity3.7439892292022705
INFO:root:current mean train loss 1674.9579681451273
INFO:root:current train perplexity3.742358684539795
INFO:root:current mean train loss 1673.7389182478828
INFO:root:current train perplexity3.740668773651123
INFO:root:current mean train loss 1674.125022574647
INFO:root:current train perplexity3.742293119430542
INFO:root:current mean train loss 1675.9091116596314
INFO:root:current train perplexity3.744140625
INFO:root:current mean train loss 1675.8104393982983
INFO:root:current train perplexity3.7459137439727783
INFO:root:current mean train loss 1675.570177723484
INFO:root:current train perplexity3.7463314533233643
INFO:root:current mean train loss 1674.8627832116713
INFO:root:current train perplexity3.7458839416503906
INFO:root:current mean train loss 1674.822503574628
INFO:root:current train perplexity3.7455079555511475
INFO:root:current mean train loss 1675.4630561278532
INFO:root:current train perplexity3.747281312942505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.87s/it]
INFO:root:final mean train loss: 1675.005256595121
INFO:root:final train perplexity: 3.747204065322876
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it]
INFO:root:eval mean loss: 1810.9406682007702
INFO:root:eval perplexity: 4.3257365226745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it]
INFO:root:eval mean loss: 2279.342783826463
INFO:root:eval perplexity: 6.450188159942627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [13:56:50<34:28, 517.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1677.4777083858366
INFO:root:current train perplexity3.7036123275756836
INFO:root:current mean train loss 1671.2686953945015
INFO:root:current train perplexity3.7191545963287354
INFO:root:current mean train loss 1675.087468399114
INFO:root:current train perplexity3.7318575382232666
INFO:root:current mean train loss 1674.5582452411018
INFO:root:current train perplexity3.7343318462371826
INFO:root:current mean train loss 1671.7972913419012
INFO:root:current train perplexity3.719252109527588
INFO:root:current mean train loss 1669.2597120611906
INFO:root:current train perplexity3.721571207046509
INFO:root:current mean train loss 1672.715858036289
INFO:root:current train perplexity3.731160879135132
INFO:root:current mean train loss 1675.197851595898
INFO:root:current train perplexity3.73403000831604
INFO:root:current mean train loss 1674.7481664480858
INFO:root:current train perplexity3.733588933944702
INFO:root:current mean train loss 1674.2328304368623
INFO:root:current train perplexity3.737072706222534
INFO:root:current mean train loss 1675.9409987174922
INFO:root:current train perplexity3.7413671016693115
INFO:root:current mean train loss 1676.3187168435013
INFO:root:current train perplexity3.7448787689208984
INFO:root:current mean train loss 1675.2122541934275
INFO:root:current train perplexity3.7445802688598633
INFO:root:current mean train loss 1674.1710702163846
INFO:root:current train perplexity3.743788957595825
INFO:root:current mean train loss 1673.4805891142285
INFO:root:current train perplexity3.74129319190979
INFO:root:current mean train loss 1672.8643585145278
INFO:root:current train perplexity3.740053415298462
INFO:root:current mean train loss 1673.7367924562193
INFO:root:current train perplexity3.741213321685791
INFO:root:current mean train loss 1674.8696288357298
INFO:root:current train perplexity3.7432122230529785
INFO:root:current mean train loss 1674.2226768506152
INFO:root:current train perplexity3.7426531314849854
INFO:root:current mean train loss 1673.8889834672166
INFO:root:current train perplexity3.743213653564453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.86s/it]
INFO:root:final mean train loss: 1673.4428438233776
INFO:root:final train perplexity: 3.742588996887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 1807.9777182721077
INFO:root:eval perplexity: 4.3153839111328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.39s/it]
INFO:root:eval mean loss: 2276.8467805470136
INFO:root:eval perplexity: 6.437032699584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [14:05:53<26:15, 525.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1690.9647547403972
INFO:root:current train perplexity3.7546844482421875
INFO:root:current mean train loss 1686.6524146827492
INFO:root:current train perplexity3.7487223148345947
INFO:root:current mean train loss 1685.2552603444744
INFO:root:current train perplexity3.7625632286071777
INFO:root:current mean train loss 1679.713011993759
INFO:root:current train perplexity3.7623932361602783
INFO:root:current mean train loss 1676.151819229126
INFO:root:current train perplexity3.7549996376037598
INFO:root:current mean train loss 1677.3991126735716
INFO:root:current train perplexity3.75307297706604
INFO:root:current mean train loss 1672.9916093614365
INFO:root:current train perplexity3.7459306716918945
INFO:root:current mean train loss 1674.202337254815
INFO:root:current train perplexity3.7497193813323975
INFO:root:current mean train loss 1676.3316171034328
INFO:root:current train perplexity3.7505366802215576
INFO:root:current mean train loss 1674.7158843092777
INFO:root:current train perplexity3.744093656539917
INFO:root:current mean train loss 1673.4556256942167
INFO:root:current train perplexity3.741434097290039
INFO:root:current mean train loss 1674.0784907856055
INFO:root:current train perplexity3.743241786956787
INFO:root:current mean train loss 1674.6306159190642
INFO:root:current train perplexity3.7431628704071045
INFO:root:current mean train loss 1674.5224032529384
INFO:root:current train perplexity3.7410759925842285
INFO:root:current mean train loss 1672.7636438022002
INFO:root:current train perplexity3.7394301891326904
INFO:root:current mean train loss 1671.338265667898
INFO:root:current train perplexity3.737560987472534
INFO:root:current mean train loss 1671.1460320185688
INFO:root:current train perplexity3.7378721237182617
INFO:root:current mean train loss 1671.9506257011362
INFO:root:current train perplexity3.7381038665771484
INFO:root:current mean train loss 1672.4999673686502
INFO:root:current train perplexity3.7387709617614746
INFO:root:current mean train loss 1672.5816137168931
INFO:root:current train perplexity3.7374582290649414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.68s/it]
INFO:root:final mean train loss: 1671.8198356993921
INFO:root:final train perplexity: 3.7378017902374268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.09s/it]
INFO:root:eval mean loss: 1808.8373659823803
INFO:root:eval perplexity: 4.318384647369385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it]
INFO:root:eval mean loss: 2277.8561245532746
INFO:root:eval perplexity: 6.442349910736084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [14:14:43<17:33, 526.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1641.9042630709134
INFO:root:current train perplexity3.68021559715271
INFO:root:current mean train loss 1664.7682106711648
INFO:root:current train perplexity3.7074601650238037
INFO:root:current mean train loss 1666.1263653449294
INFO:root:current train perplexity3.712914228439331
INFO:root:current mean train loss 1666.417042687821
INFO:root:current train perplexity3.7102057933807373
INFO:root:current mean train loss 1668.7318763650874
INFO:root:current train perplexity3.720374345779419
INFO:root:current mean train loss 1667.1187517284293
INFO:root:current train perplexity3.726752996444702
INFO:root:current mean train loss 1668.0234426398026
INFO:root:current train perplexity3.731433153152466
INFO:root:current mean train loss 1668.3450495302288
INFO:root:current train perplexity3.7323060035705566
INFO:root:current mean train loss 1669.9066794334808
INFO:root:current train perplexity3.735971689224243
INFO:root:current mean train loss 1670.1763493513197
INFO:root:current train perplexity3.7362189292907715
INFO:root:current mean train loss 1670.7920740261884
INFO:root:current train perplexity3.7352640628814697
INFO:root:current mean train loss 1671.0670914154707
INFO:root:current train perplexity3.7365200519561768
INFO:root:current mean train loss 1670.355778798944
INFO:root:current train perplexity3.7348697185516357
INFO:root:current mean train loss 1669.0411024603652
INFO:root:current train perplexity3.7333240509033203
INFO:root:current mean train loss 1670.3897905056795
INFO:root:current train perplexity3.7347323894500732
INFO:root:current mean train loss 1670.5583458653655
INFO:root:current train perplexity3.7366981506347656
INFO:root:current mean train loss 1671.7081606020083
INFO:root:current train perplexity3.7377607822418213
INFO:root:current mean train loss 1671.7812542880224
INFO:root:current train perplexity3.7383222579956055
INFO:root:current mean train loss 1671.2625638169195
INFO:root:current train perplexity3.7361390590667725
INFO:root:current mean train loss 1671.3884979946922
INFO:root:current train perplexity3.7353696823120117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.52s/it]
INFO:root:final mean train loss: 1671.0837221054255
INFO:root:final train perplexity: 3.7356324195861816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.30s/it]
INFO:root:eval mean loss: 1807.5519842053136
INFO:root:eval perplexity: 4.313897609710693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it]
INFO:root:eval mean loss: 2276.8147998566324
INFO:root:eval perplexity: 6.436864852905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [14:23:41<08:49, 529.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1660.756582864901
INFO:root:current train perplexity3.7296066284179688
INFO:root:current mean train loss 1663.508286025498
INFO:root:current train perplexity3.735889196395874
INFO:root:current mean train loss 1672.0893450797873
INFO:root:current train perplexity3.740368604660034
INFO:root:current mean train loss 1674.2633622254377
INFO:root:current train perplexity3.737118721008301
INFO:root:current mean train loss 1672.1118480634887
INFO:root:current train perplexity3.736100912094116
INFO:root:current mean train loss 1670.0795986529479
INFO:root:current train perplexity3.7321457862854004
INFO:root:current mean train loss 1667.331424478212
INFO:root:current train perplexity3.7285854816436768
INFO:root:current mean train loss 1665.9434737964054
INFO:root:current train perplexity3.7253689765930176
INFO:root:current mean train loss 1669.3210709413975
INFO:root:current train perplexity3.7319655418395996
INFO:root:current mean train loss 1669.983543877689
INFO:root:current train perplexity3.729008197784424
INFO:root:current mean train loss 1669.514175048377
INFO:root:current train perplexity3.728886127471924
INFO:root:current mean train loss 1669.022114348694
INFO:root:current train perplexity3.725041627883911
INFO:root:current mean train loss 1670.0057014072554
INFO:root:current train perplexity3.7269208431243896
INFO:root:current mean train loss 1670.7428157822958
INFO:root:current train perplexity3.7292826175689697
INFO:root:current mean train loss 1671.1685106532293
INFO:root:current train perplexity3.7315168380737305
INFO:root:current mean train loss 1671.125303323893
INFO:root:current train perplexity3.732860803604126
INFO:root:current mean train loss 1672.1705799080103
INFO:root:current train perplexity3.7350170612335205
INFO:root:current mean train loss 1671.4186943216891
INFO:root:current train perplexity3.732969045639038
INFO:root:current mean train loss 1670.2981431172582
INFO:root:current train perplexity3.7322263717651367
INFO:root:current mean train loss 1670.8647541619694
INFO:root:current train perplexity3.733454942703247

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.86s/it]
INFO:root:final mean train loss: 1670.3193411084058
INFO:root:final train perplexity: 3.7333810329437256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]
INFO:root:eval mean loss: 1806.3622808794603
INFO:root:eval perplexity: 4.309749603271484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it]
INFO:root:eval mean loss: 2275.4788112775655
INFO:root:eval perplexity: 6.429834365844727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_alll12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:32:30<00:00, 529.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:32:31<00:00, 523.51s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it]
INFO:root:eval mean loss: 1806.3622808794603
INFO:root:eval perplexity: 4.309749603271484
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.24s/it]
INFO:root:eval mean loss: 2275.4788112775655
INFO:root:eval perplexity: 6.429834365844727
INFO:root:evalaution complete
INFO:root:save model final: multil6_alll12_not_concat_100e/final
