INFO:root:Output: alll6_alll6_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12288.549627130682
INFO:root:current train perplexity17382.626953125
INFO:root:current mean train loss 10661.540085682318
INFO:root:current train perplexity4511.3701171875
INFO:root:current mean train loss 9265.469849041074
INFO:root:current train perplexity1488.0567626953125
INFO:root:current mean train loss 8297.09476449914
INFO:root:current train perplexity692.6345825195312
INFO:root:current mean train loss 7592.3651330982275
INFO:root:current train perplexity398.12701416015625
INFO:root:current mean train loss 7058.423063911859
INFO:root:current train perplexity261.2546081542969
INFO:root:current mean train loss 6642.920629498614
INFO:root:current train perplexity187.65896606445312
INFO:root:current mean train loss 6312.500379502699
INFO:root:current train perplexity144.1416015625
INFO:root:current mean train loss 6032.40993492118
INFO:root:current train perplexity116.15851593017578
INFO:root:current mean train loss 5805.687372919795
INFO:root:current train perplexity96.63449096679688
INFO:root:current mean train loss 5604.316822555306
INFO:root:current train perplexity82.63883209228516
INFO:root:current mean train loss 5432.882230553456
INFO:root:current train perplexity72.23287963867188
INFO:root:current mean train loss 5284.491351332455
INFO:root:current train perplexity64.07964324951172
INFO:root:current mean train loss 5147.19009410321
INFO:root:current train perplexity57.6528434753418
INFO:root:current mean train loss 5027.286696502095
INFO:root:current train perplexity52.52667236328125
INFO:root:current mean train loss 4919.366606081926
INFO:root:current train perplexity48.26834487915039
INFO:root:current mean train loss 4822.730508266582
INFO:root:current train perplexity44.69514083862305
INFO:root:current mean train loss 4733.2398948308955
INFO:root:current train perplexity41.69779586791992
INFO:root:current mean train loss 4649.656618332223
INFO:root:current train perplexity39.09856414794922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.40s/it]
INFO:root:final mean train loss: 4584.729550791099
INFO:root:final train perplexity: 37.180843353271484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 2924.0102885361257
INFO:root:eval perplexity: 10.641570091247559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 3216.94662670379
INFO:root:eval perplexity: 13.886366844177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/1
  1%|          | 1/100 [07:06<11:44:17, 426.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3104.4313201904297
INFO:root:current train perplexity11.652862548828125
INFO:root:current mean train loss 3125.7642527613148
INFO:root:current train perplexity11.45177173614502
INFO:root:current mean train loss 3105.891392460576
INFO:root:current train perplexity11.33894157409668
INFO:root:current mean train loss 3078.2542191517505
INFO:root:current train perplexity11.259268760681152
INFO:root:current mean train loss 3067.370824960562
INFO:root:current train perplexity11.149311065673828
INFO:root:current mean train loss 3047.754596089208
INFO:root:current train perplexity11.029407501220703
INFO:root:current mean train loss 3032.8411603655136
INFO:root:current train perplexity10.913934707641602
INFO:root:current mean train loss 3020.3334674515536
INFO:root:current train perplexity10.826085090637207
INFO:root:current mean train loss 3007.0058462105544
INFO:root:current train perplexity10.728071212768555
INFO:root:current mean train loss 2997.507964688097
INFO:root:current train perplexity10.62779426574707
INFO:root:current mean train loss 2987.452621339813
INFO:root:current train perplexity10.533514976501465
INFO:root:current mean train loss 2976.79347453237
INFO:root:current train perplexity10.437826156616211
INFO:root:current mean train loss 2965.993635478773
INFO:root:current train perplexity10.355020523071289
INFO:root:current mean train loss 2957.7436558685768
INFO:root:current train perplexity10.280624389648438
INFO:root:current mean train loss 2949.099869205453
INFO:root:current train perplexity10.211740493774414
INFO:root:current mean train loss 2940.710139694818
INFO:root:current train perplexity10.143970489501953
INFO:root:current mean train loss 2929.8366513393894
INFO:root:current train perplexity10.071465492248535
INFO:root:current mean train loss 2921.168013423751
INFO:root:current train perplexity10.00312614440918
INFO:root:current mean train loss 2911.235164827187
INFO:root:current train perplexity9.93497371673584
INFO:root:current mean train loss 2905.1845957969076
INFO:root:current train perplexity9.881159782409668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.72s/it]
INFO:root:final mean train loss: 2899.3597106164116
INFO:root:final train perplexity: 9.841512680053711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 2568.73861889129
INFO:root:eval perplexity: 7.984044075012207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 2906.593445689966
INFO:root:eval perplexity: 10.773529052734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/2
  2%|â–         | 2/100 [14:19<11:42:23, 430.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2751.988887902462
INFO:root:current train perplexity8.791796684265137
INFO:root:current mean train loss 2709.796649215813
INFO:root:current train perplexity8.55744743347168
INFO:root:current mean train loss 2692.819334889686
INFO:root:current train perplexity8.489842414855957
INFO:root:current mean train loss 2695.5650308511636
INFO:root:current train perplexity8.474964141845703
INFO:root:current mean train loss 2696.3540117999423
INFO:root:current train perplexity8.440152168273926
INFO:root:current mean train loss 2691.005341778553
INFO:root:current train perplexity8.39908504486084
INFO:root:current mean train loss 2689.0373303743336
INFO:root:current train perplexity8.374624252319336
INFO:root:current mean train loss 2687.758924622165
INFO:root:current train perplexity8.345784187316895
INFO:root:current mean train loss 2682.831823452037
INFO:root:current train perplexity8.31295394897461
INFO:root:current mean train loss 2680.861603404676
INFO:root:current train perplexity8.286742210388184
INFO:root:current mean train loss 2679.1057989188803
INFO:root:current train perplexity8.264381408691406
INFO:root:current mean train loss 2673.496797297344
INFO:root:current train perplexity8.229205131530762
INFO:root:current mean train loss 2667.395235555112
INFO:root:current train perplexity8.192940711975098
INFO:root:current mean train loss 2663.1684997054926
INFO:root:current train perplexity8.16235637664795
INFO:root:current mean train loss 2656.151064269125
INFO:root:current train perplexity8.130264282226562
INFO:root:current mean train loss 2654.047170421304
INFO:root:current train perplexity8.11299991607666
INFO:root:current mean train loss 2651.0204631106953
INFO:root:current train perplexity8.087850570678711
INFO:root:current mean train loss 2647.64134220711
INFO:root:current train perplexity8.061197280883789
INFO:root:current mean train loss 2642.3941909448736
INFO:root:current train perplexity8.027763366699219
INFO:root:current mean train loss 2638.722590573267
INFO:root:current train perplexity8.006682395935059

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.74s/it]
INFO:root:final mean train loss: 2635.200364413432
INFO:root:final train perplexity: 7.990691661834717
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 2405.335859149906
INFO:root:eval perplexity: 6.995691776275635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 2765.2598262272827
INFO:root:eval perplexity: 9.597526550292969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/3
  3%|â–Ž         | 3/100 [21:16<11:25:58, 424.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2579.986669921875
INFO:root:current train perplexity7.4616289138793945
INFO:root:current mean train loss 2542.7198763020833
INFO:root:current train perplexity7.387042045593262
INFO:root:current mean train loss 2538.394918457031
INFO:root:current train perplexity7.391961574554443
INFO:root:current mean train loss 2537.0979802594866
INFO:root:current train perplexity7.384536266326904
INFO:root:current mean train loss 2535.7143806966146
INFO:root:current train perplexity7.38651180267334
INFO:root:current mean train loss 2528.3432952325993
INFO:root:current train perplexity7.347323894500732
INFO:root:current mean train loss 2526.723519193209
INFO:root:current train perplexity7.328763961791992
INFO:root:current mean train loss 2523.4174466145832
INFO:root:current train perplexity7.304768085479736
INFO:root:current mean train loss 2523.0899482996324
INFO:root:current train perplexity7.290772914886475
INFO:root:current mean train loss 2519.019726177015
INFO:root:current train perplexity7.266079425811768
INFO:root:current mean train loss 2515.02041469029
INFO:root:current train perplexity7.251980304718018
INFO:root:current mean train loss 2514.2159589419157
INFO:root:current train perplexity7.242507457733154
INFO:root:current mean train loss 2510.7367919921876
INFO:root:current train perplexity7.223343372344971
INFO:root:current mean train loss 2507.76836895978
INFO:root:current train perplexity7.2101311683654785
INFO:root:current mean train loss 2505.9847747171334
INFO:root:current train perplexity7.201894760131836
INFO:root:current mean train loss 2503.213240139869
INFO:root:current train perplexity7.194982528686523
INFO:root:current mean train loss 2498.981452858665
INFO:root:current train perplexity7.179269313812256
INFO:root:current mean train loss 2496.4871000279018
INFO:root:current train perplexity7.161937236785889
INFO:root:current mean train loss 2494.5594556323904
INFO:root:current train perplexity7.1497087478637695
INFO:root:current mean train loss 2492.355926607572
INFO:root:current train perplexity7.135276794433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.55s/it]
INFO:root:final mean train loss: 2491.0949492192426
INFO:root:final train perplexity: 7.132253646850586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 2309.3459671778037
INFO:root:eval perplexity: 6.473153591156006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it]
INFO:root:eval mean loss: 2685.9875860552415
INFO:root:eval perplexity: 8.995049476623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/4
  4%|â–         | 4/100 [28:14<11:14:44, 421.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2420.9864556611474
INFO:root:current train perplexity6.81806755065918
INFO:root:current mean train loss 2449.492707943488
INFO:root:current train perplexity6.879795074462891
INFO:root:current mean train loss 2434.7434548367273
INFO:root:current train perplexity6.845708847045898
INFO:root:current mean train loss 2435.106626588577
INFO:root:current train perplexity6.857863426208496
INFO:root:current mean train loss 2438.1972123009236
INFO:root:current train perplexity6.864516735076904
INFO:root:current mean train loss 2440.8030809944057
INFO:root:current train perplexity6.869873523712158
INFO:root:current mean train loss 2442.7310165107874
INFO:root:current train perplexity6.871111869812012
INFO:root:current mean train loss 2445.123815106289
INFO:root:current train perplexity6.878839492797852
INFO:root:current mean train loss 2447.2236197184525
INFO:root:current train perplexity6.881062984466553
INFO:root:current mean train loss 2443.2615548955373
INFO:root:current train perplexity6.866331100463867
INFO:root:current mean train loss 2442.1352296523546
INFO:root:current train perplexity6.865954399108887
INFO:root:current mean train loss 2442.3823662686777
INFO:root:current train perplexity6.866858005523682
INFO:root:current mean train loss 2441.528562718898
INFO:root:current train perplexity6.862916946411133
INFO:root:current mean train loss 2443.6758341143927
INFO:root:current train perplexity6.864905834197998
INFO:root:current mean train loss 2443.1076652667275
INFO:root:current train perplexity6.8622541427612305
INFO:root:current mean train loss 2440.1944196806944
INFO:root:current train perplexity6.850220680236816
INFO:root:current mean train loss 2438.5953991574734
INFO:root:current train perplexity6.842395782470703
INFO:root:current mean train loss 2436.885033737554
INFO:root:current train perplexity6.832920551300049
INFO:root:current mean train loss 2436.1371945430715
INFO:root:current train perplexity6.830357074737549
INFO:root:current mean train loss 2435.7593279219427
INFO:root:current train perplexity6.825252056121826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.49s/it]
INFO:root:final mean train loss: 2435.584891868972
INFO:root:final train perplexity: 6.826750755310059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it]
INFO:root:eval mean loss: 2252.9484858952515
INFO:root:eval perplexity: 6.1845383644104
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 2638.9828768249945
INFO:root:eval perplexity: 8.655826568603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/5
  5%|â–Œ         | 5/100 [35:31<11:16:29, 427.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2417.017025902158
INFO:root:current train perplexity6.656615257263184
INFO:root:current mean train loss 2398.5480366582456
INFO:root:current train perplexity6.588254928588867
INFO:root:current mean train loss 2390.4714364065253
INFO:root:current train perplexity6.576301097869873
INFO:root:current mean train loss 2394.4752979278564
INFO:root:current train perplexity6.582869052886963
INFO:root:current mean train loss 2390.722574029087
INFO:root:current train perplexity6.561199188232422
INFO:root:current mean train loss 2386.949324516401
INFO:root:current train perplexity6.557892322540283
INFO:root:current mean train loss 2384.1800010636534
INFO:root:current train perplexity6.547143936157227
INFO:root:current mean train loss 2382.0415230575873
INFO:root:current train perplexity6.541707992553711
INFO:root:current mean train loss 2381.094029077038
INFO:root:current train perplexity6.539655685424805
INFO:root:current mean train loss 2380.5570196136227
INFO:root:current train perplexity6.529043197631836
INFO:root:current mean train loss 2378.603143333069
INFO:root:current train perplexity6.51940393447876
INFO:root:current mean train loss 2377.112099621747
INFO:root:current train perplexity6.517449378967285
INFO:root:current mean train loss 2374.0966075291144
INFO:root:current train perplexity6.5030622482299805
INFO:root:current mean train loss 2371.9179651337554
INFO:root:current train perplexity6.491968154907227
INFO:root:current mean train loss 2370.2395151143446
INFO:root:current train perplexity6.486191272735596
INFO:root:current mean train loss 2368.0833223130967
INFO:root:current train perplexity6.476005554199219
INFO:root:current mean train loss 2367.3654374147536
INFO:root:current train perplexity6.471584796905518
INFO:root:current mean train loss 2366.2689277409436
INFO:root:current train perplexity6.463717460632324
INFO:root:current mean train loss 2363.022625058573
INFO:root:current train perplexity6.449257850646973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.24s/it]
INFO:root:final mean train loss: 2363.3611342160316
INFO:root:final train perplexity: 6.448765754699707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 2197.973279587766
INFO:root:eval perplexity: 5.91559362411499
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.70s/it]
INFO:root:eval mean loss: 2593.3269674963985
INFO:root:eval perplexity: 8.33858871459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/6
  6%|â–Œ         | 6/100 [42:40<11:10:19, 427.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2381.999267578125
INFO:root:current train perplexity6.72343635559082
INFO:root:current mean train loss 2333.793050935953
INFO:root:current train perplexity6.243110179901123
INFO:root:current mean train loss 2318.231727106654
INFO:root:current train perplexity6.2002716064453125
INFO:root:current mean train loss 2306.7588782833263
INFO:root:current train perplexity6.179448127746582
INFO:root:current mean train loss 2312.929694501539
INFO:root:current train perplexity6.206180095672607
INFO:root:current mean train loss 2308.3942215666325
INFO:root:current train perplexity6.18531608581543
INFO:root:current mean train loss 2312.273616035449
INFO:root:current train perplexity6.1902384757995605
INFO:root:current mean train loss 2314.460898493224
INFO:root:current train perplexity6.188993453979492
INFO:root:current mean train loss 2314.2394135626364
INFO:root:current train perplexity6.187866687774658
INFO:root:current mean train loss 2315.995648010457
INFO:root:current train perplexity6.195852279663086
INFO:root:current mean train loss 2312.5181420142358
INFO:root:current train perplexity6.183928489685059
INFO:root:current mean train loss 2310.2843947796036
INFO:root:current train perplexity6.175863265991211
INFO:root:current mean train loss 2308.928689592982
INFO:root:current train perplexity6.1686692237854
INFO:root:current mean train loss 2305.8685507279556
INFO:root:current train perplexity6.167431354522705
INFO:root:current mean train loss 2305.610528176721
INFO:root:current train perplexity6.161834239959717
INFO:root:current mean train loss 2305.648255899062
INFO:root:current train perplexity6.157387733459473
INFO:root:current mean train loss 2304.895759806493
INFO:root:current train perplexity6.157105445861816
INFO:root:current mean train loss 2304.4026362594614
INFO:root:current train perplexity6.151806354522705
INFO:root:current mean train loss 2301.789741715215
INFO:root:current train perplexity6.1419830322265625
INFO:root:current mean train loss 2301.188942176301
INFO:root:current train perplexity6.138265132904053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.51s/it]
INFO:root:final mean train loss: 2301.12912321259
INFO:root:final train perplexity: 6.139902591705322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 2157.647055767952
INFO:root:eval perplexity: 5.7257771492004395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 2560.493310806599
INFO:root:eval perplexity: 8.117656707763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/7
  7%|â–‹         | 7/100 [49:51<11:04:42, 428.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2293.781202528212
INFO:root:current train perplexity6.031575679779053
INFO:root:current mean train loss 2260.9190963486494
INFO:root:current train perplexity5.939178466796875
INFO:root:current mean train loss 2262.544027066012
INFO:root:current train perplexity5.9748640060424805
INFO:root:current mean train loss 2260.155359808004
INFO:root:current train perplexity5.966920852661133
INFO:root:current mean train loss 2260.701757111618
INFO:root:current train perplexity5.968935966491699
INFO:root:current mean train loss 2258.32928301837
INFO:root:current train perplexity5.958675384521484
INFO:root:current mean train loss 2257.0034744608365
INFO:root:current train perplexity5.957869052886963
INFO:root:current mean train loss 2258.153122585796
INFO:root:current train perplexity5.958051681518555
INFO:root:current mean train loss 2259.7019986103683
INFO:root:current train perplexity5.962916374206543
INFO:root:current mean train loss 2257.278518710001
INFO:root:current train perplexity5.946908473968506
INFO:root:current mean train loss 2257.908597155498
INFO:root:current train perplexity5.944737911224365
INFO:root:current mean train loss 2255.920180755779
INFO:root:current train perplexity5.940263748168945
INFO:root:current mean train loss 2256.944353275894
INFO:root:current train perplexity5.937121391296387
INFO:root:current mean train loss 2254.821503935888
INFO:root:current train perplexity5.934401988983154
INFO:root:current mean train loss 2255.2315833948564
INFO:root:current train perplexity5.9285783767700195
INFO:root:current mean train loss 2254.5395595465097
INFO:root:current train perplexity5.926868915557861
INFO:root:current mean train loss 2256.420272167003
INFO:root:current train perplexity5.929227352142334
INFO:root:current mean train loss 2256.24394302457
INFO:root:current train perplexity5.9280219078063965
INFO:root:current mean train loss 2255.237260908708
INFO:root:current train perplexity5.922816276550293
INFO:root:current mean train loss 2254.540043772199
INFO:root:current train perplexity5.918275356292725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.36s/it]
INFO:root:final mean train loss: 2254.6345860591396
INFO:root:final train perplexity: 5.918840408325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 2129.7779095155975
INFO:root:eval perplexity: 5.5981669425964355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 2537.329758664395
INFO:root:eval perplexity: 7.965325355529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/8
  8%|â–Š         | 8/100 [56:54<10:54:49, 427.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2207.0662004743303
INFO:root:current train perplexity5.707188606262207
INFO:root:current mean train loss 2215.634867802373
INFO:root:current train perplexity5.722006797790527
INFO:root:current mean train loss 2223.0564557014627
INFO:root:current train perplexity5.749032974243164
INFO:root:current mean train loss 2229.0728821711755
INFO:root:current train perplexity5.7663164138793945
INFO:root:current mean train loss 2227.9885186557112
INFO:root:current train perplexity5.76890230178833
INFO:root:current mean train loss 2228.523984192465
INFO:root:current train perplexity5.766150951385498
INFO:root:current mean train loss 2230.779823795829
INFO:root:current train perplexity5.784318447113037
INFO:root:current mean train loss 2229.4832645753613
INFO:root:current train perplexity5.777466297149658
INFO:root:current mean train loss 2230.105242152414
INFO:root:current train perplexity5.780246257781982
INFO:root:current mean train loss 2227.5318828072777
INFO:root:current train perplexity5.767966270446777
INFO:root:current mean train loss 2223.2099039713544
INFO:root:current train perplexity5.755466938018799
INFO:root:current mean train loss 2222.510163025709
INFO:root:current train perplexity5.758843898773193
INFO:root:current mean train loss 2221.672866092327
INFO:root:current train perplexity5.759786605834961
INFO:root:current mean train loss 2221.9283220498305
INFO:root:current train perplexity5.76272439956665
INFO:root:current mean train loss 2220.1061514930857
INFO:root:current train perplexity5.755438327789307
INFO:root:current mean train loss 2220.354177349476
INFO:root:current train perplexity5.757168292999268
INFO:root:current mean train loss 2219.9553758720376
INFO:root:current train perplexity5.754429817199707
INFO:root:current mean train loss 2218.3268316175477
INFO:root:current train perplexity5.750890731811523
INFO:root:current mean train loss 2217.1001975742934
INFO:root:current train perplexity5.746898651123047
INFO:root:current mean train loss 2217.355638891412
INFO:root:current train perplexity5.745449066162109

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.63s/it]
INFO:root:final mean train loss: 2216.670868643233
INFO:root:final train perplexity: 5.744252681732178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 2102.058220180214
INFO:root:eval perplexity: 5.474064350128174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it]
INFO:root:eval mean loss: 2512.9197465612533
INFO:root:eval perplexity: 7.807889938354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/9
  9%|â–‰         | 9/100 [1:03:50<10:42:11, 423.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2170.921353853666
INFO:root:current train perplexity5.596630573272705
INFO:root:current mean train loss 2193.1043661017166
INFO:root:current train perplexity5.62917947769165
INFO:root:current mean train loss 2190.824454655723
INFO:root:current train perplexity5.630943775177002
INFO:root:current mean train loss 2188.716386274858
INFO:root:current train perplexity5.624492645263672
INFO:root:current mean train loss 2186.152648655714
INFO:root:current train perplexity5.631015300750732
INFO:root:current mean train loss 2188.3964317432346
INFO:root:current train perplexity5.636547565460205
INFO:root:current mean train loss 2185.6531235396496
INFO:root:current train perplexity5.6292805671691895
INFO:root:current mean train loss 2184.6719384700696
INFO:root:current train perplexity5.622403144836426
INFO:root:current mean train loss 2186.5289249330617
INFO:root:current train perplexity5.620100021362305
INFO:root:current mean train loss 2188.172860538258
INFO:root:current train perplexity5.620298385620117
INFO:root:current mean train loss 2187.114604993465
INFO:root:current train perplexity5.617868423461914
INFO:root:current mean train loss 2183.2081332736543
INFO:root:current train perplexity5.611541748046875
INFO:root:current mean train loss 2184.108172236921
INFO:root:current train perplexity5.613324165344238
INFO:root:current mean train loss 2183.2329020302677
INFO:root:current train perplexity5.611985206604004
INFO:root:current mean train loss 2183.6137278323004
INFO:root:current train perplexity5.608100414276123
INFO:root:current mean train loss 2183.619995195841
INFO:root:current train perplexity5.601093292236328
INFO:root:current mean train loss 2184.072321413793
INFO:root:current train perplexity5.6023664474487305
INFO:root:current mean train loss 2184.0103136175844
INFO:root:current train perplexity5.604092597961426
INFO:root:current mean train loss 2184.652861955614
INFO:root:current train perplexity5.605187892913818
INFO:root:current mean train loss 2185.743841390141
INFO:root:current train perplexity5.604720115661621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it]
INFO:root:final mean train loss: 2185.8473268509874
INFO:root:final train perplexity: 5.606297492980957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 2086.1864039644283
INFO:root:eval perplexity: 5.404247760772705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 2499.114468188996
INFO:root:eval perplexity: 7.7202324867248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:10:50<10:33:34, 422.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2180.9892931951995
INFO:root:current train perplexity5.517259120941162
INFO:root:current mean train loss 2166.767542009523
INFO:root:current train perplexity5.489599227905273
INFO:root:current mean train loss 2162.468177313255
INFO:root:current train perplexity5.471739768981934
INFO:root:current mean train loss 2164.7365216511052
INFO:root:current train perplexity5.496669769287109
INFO:root:current mean train loss 2163.8748568471815
INFO:root:current train perplexity5.49770450592041
INFO:root:current mean train loss 2161.1837130313597
INFO:root:current train perplexity5.497806549072266
INFO:root:current mean train loss 2162.311732362026
INFO:root:current train perplexity5.495068073272705
INFO:root:current mean train loss 2161.6640712306466
INFO:root:current train perplexity5.489221572875977
INFO:root:current mean train loss 2163.5677785225926
INFO:root:current train perplexity5.496563911437988
INFO:root:current mean train loss 2162.7988394628
INFO:root:current train perplexity5.495692253112793
INFO:root:current mean train loss 2162.110919434964
INFO:root:current train perplexity5.49580192565918
INFO:root:current mean train loss 2162.8999152921833
INFO:root:current train perplexity5.495094299316406
INFO:root:current mean train loss 2162.449690678253
INFO:root:current train perplexity5.495868682861328
INFO:root:current mean train loss 2162.7504030371165
INFO:root:current train perplexity5.498636245727539
INFO:root:current mean train loss 2163.1830775479707
INFO:root:current train perplexity5.498708724975586
INFO:root:current mean train loss 2162.0850935887956
INFO:root:current train perplexity5.497793674468994
INFO:root:current mean train loss 2161.760587350561
INFO:root:current train perplexity5.495052337646484
INFO:root:current mean train loss 2161.503102614692
INFO:root:current train perplexity5.496917724609375
INFO:root:current mean train loss 2161.103203036174
INFO:root:current train perplexity5.495479583740234
INFO:root:current mean train loss 2161.1575371009435
INFO:root:current train perplexity5.494713306427002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.31s/it]
INFO:root:final mean train loss: 2160.6431604059308
INFO:root:final train perplexity: 5.495959758758545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 2067.275765060533
INFO:root:eval perplexity: 5.322223663330078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 2485.505000554078
INFO:root:eval perplexity: 7.634779930114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:17:38<10:20:17, 418.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2139.386246082395
INFO:root:current train perplexity5.433245658874512
INFO:root:current mean train loss 2139.3292223202284
INFO:root:current train perplexity5.432147026062012
INFO:root:current mean train loss 2141.1374733664775
INFO:root:current train perplexity5.415524959564209
INFO:root:current mean train loss 2138.7636854735065
INFO:root:current train perplexity5.416982173919678
INFO:root:current mean train loss 2142.16199182581
INFO:root:current train perplexity5.428224086761475
INFO:root:current mean train loss 2138.3836801157877
INFO:root:current train perplexity5.4121551513671875
INFO:root:current mean train loss 2136.4943671490637
INFO:root:current train perplexity5.405471324920654
INFO:root:current mean train loss 2135.0970795997832
INFO:root:current train perplexity5.402609825134277
INFO:root:current mean train loss 2137.9104075550226
INFO:root:current train perplexity5.403342247009277
INFO:root:current mean train loss 2136.2134122094085
INFO:root:current train perplexity5.400426864624023
INFO:root:current mean train loss 2138.4486311039655
INFO:root:current train perplexity5.400185585021973
INFO:root:current mean train loss 2138.86118114658
INFO:root:current train perplexity5.401119709014893
INFO:root:current mean train loss 2138.3873883331917
INFO:root:current train perplexity5.401740550994873
INFO:root:current mean train loss 2139.5691059767596
INFO:root:current train perplexity5.4063568115234375
INFO:root:current mean train loss 2140.522087661928
INFO:root:current train perplexity5.407598495483398
INFO:root:current mean train loss 2140.1577397811907
INFO:root:current train perplexity5.408064365386963
INFO:root:current mean train loss 2139.3939253149792
INFO:root:current train perplexity5.405573844909668
INFO:root:current mean train loss 2138.8789158187815
INFO:root:current train perplexity5.40114688873291
INFO:root:current mean train loss 2138.3510912412803
INFO:root:current train perplexity5.399611473083496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it]
INFO:root:final mean train loss: 2137.4248853290073
INFO:root:final train perplexity: 5.396236896514893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it]
INFO:root:eval mean loss: 2054.27125841506
INFO:root:eval perplexity: 5.266541957855225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 2473.0282384994184
INFO:root:eval perplexity: 7.557273864746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:24:44<10:16:36, 420.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2146.7081705729165
INFO:root:current train perplexity5.4092254638671875
INFO:root:current mean train loss 2128.404452129475
INFO:root:current train perplexity5.40479040145874
INFO:root:current mean train loss 2114.733780283059
INFO:root:current train perplexity5.3308916091918945
INFO:root:current mean train loss 2117.870901579904
INFO:root:current train perplexity5.347197532653809
INFO:root:current mean train loss 2113.3167912409854
INFO:root:current train perplexity5.319276332855225
INFO:root:current mean train loss 2114.272784193278
INFO:root:current train perplexity5.316739082336426
INFO:root:current mean train loss 2115.806536571699
INFO:root:current train perplexity5.316943645477295
INFO:root:current mean train loss 2112.8874195690346
INFO:root:current train perplexity5.308539390563965
INFO:root:current mean train loss 2118.3955254465677
INFO:root:current train perplexity5.318252086639404
INFO:root:current mean train loss 2114.932779001635
INFO:root:current train perplexity5.306228160858154
INFO:root:current mean train loss 2115.115098430295
INFO:root:current train perplexity5.307588577270508
INFO:root:current mean train loss 2115.9862244261035
INFO:root:current train perplexity5.303940296173096
INFO:root:current mean train loss 2117.682886290134
INFO:root:current train perplexity5.309630870819092
INFO:root:current mean train loss 2114.5919573557717
INFO:root:current train perplexity5.305478096008301
INFO:root:current mean train loss 2115.51600356588
INFO:root:current train perplexity5.308764934539795
INFO:root:current mean train loss 2116.093411565541
INFO:root:current train perplexity5.310655117034912
INFO:root:current mean train loss 2115.546062543254
INFO:root:current train perplexity5.3078203201293945
INFO:root:current mean train loss 2116.3420867471923
INFO:root:current train perplexity5.3092217445373535
INFO:root:current mean train loss 2116.5421726186605
INFO:root:current train perplexity5.310716152191162
INFO:root:current mean train loss 2117.09263661355
INFO:root:current train perplexity5.312165260314941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.08s/it]
INFO:root:final mean train loss: 2118.3152946591435
INFO:root:final train perplexity: 5.315520286560059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it]
INFO:root:eval mean loss: 2047.33506136414
INFO:root:eval perplexity: 5.237082004547119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.54s/it]
INFO:root:eval mean loss: 2469.4170242201353
INFO:root:eval perplexity: 7.534987926483154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:32:02<10:17:20, 425.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2147.251629638672
INFO:root:current train perplexity5.346768856048584
INFO:root:current mean train loss 2107.0334208170575
INFO:root:current train perplexity5.275105953216553
INFO:root:current mean train loss 2113.8647238991475
INFO:root:current train perplexity5.266105651855469
INFO:root:current mean train loss 2107.835007476807
INFO:root:current train perplexity5.244225025177002
INFO:root:current mean train loss 2102.927865455264
INFO:root:current train perplexity5.241493225097656
INFO:root:current mean train loss 2101.0458129882813
INFO:root:current train perplexity5.246807098388672
INFO:root:current mean train loss 2097.5802070863783
INFO:root:current train perplexity5.23489236831665
INFO:root:current mean train loss 2097.8330284966364
INFO:root:current train perplexity5.234859466552734
INFO:root:current mean train loss 2101.400546487948
INFO:root:current train perplexity5.243786811828613
INFO:root:current mean train loss 2101.986881554645
INFO:root:current train perplexity5.2472357749938965
INFO:root:current mean train loss 2102.418629844516
INFO:root:current train perplexity5.251158237457275
INFO:root:current mean train loss 2102.2340364728657
INFO:root:current train perplexity5.252087593078613
INFO:root:current mean train loss 2101.9114435915085
INFO:root:current train perplexity5.250912189483643
INFO:root:current mean train loss 2101.033494706587
INFO:root:current train perplexity5.251439571380615
INFO:root:current mean train loss 2100.497204503879
INFO:root:current train perplexity5.248528480529785
INFO:root:current mean train loss 2099.8416462145356
INFO:root:current train perplexity5.247930526733398
INFO:root:current mean train loss 2100.744683009018
INFO:root:current train perplexity5.2450761795043945
INFO:root:current mean train loss 2100.1944886673327
INFO:root:current train perplexity5.241560935974121
INFO:root:current mean train loss 2100.6343831827353
INFO:root:current train perplexity5.240869045257568
INFO:root:current mean train loss 2100.417995961507
INFO:root:current train perplexity5.2378387451171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.71s/it]
INFO:root:final mean train loss: 2099.9737390007444
INFO:root:final train perplexity: 5.239182949066162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 2035.2114547837712
INFO:root:eval perplexity: 5.185983657836914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 2460.948748649435
INFO:root:eval perplexity: 7.4829840660095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [1:39:03<10:08:28, 424.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2086.974421320735
INFO:root:current train perplexity5.130020618438721
INFO:root:current mean train loss 2087.122861541971
INFO:root:current train perplexity5.168012619018555
INFO:root:current mean train loss 2083.0586406208795
INFO:root:current train perplexity5.171640396118164
INFO:root:current mean train loss 2080.7879312668074
INFO:root:current train perplexity5.169003963470459
INFO:root:current mean train loss 2088.569776172769
INFO:root:current train perplexity5.190257549285889
INFO:root:current mean train loss 2085.9417317708335
INFO:root:current train perplexity5.1825337409973145
INFO:root:current mean train loss 2088.1652157482586
INFO:root:current train perplexity5.18692684173584
INFO:root:current mean train loss 2083.6309206586034
INFO:root:current train perplexity5.17973518371582
INFO:root:current mean train loss 2079.5523028265475
INFO:root:current train perplexity5.1640801429748535
INFO:root:current mean train loss 2081.0629570145743
INFO:root:current train perplexity5.1655707359313965
INFO:root:current mean train loss 2082.439421695132
INFO:root:current train perplexity5.1671881675720215
INFO:root:current mean train loss 2083.1207591034176
INFO:root:current train perplexity5.1670918464660645
INFO:root:current mean train loss 2082.3151793298744
INFO:root:current train perplexity5.167303085327148
INFO:root:current mean train loss 2082.6043860036752
INFO:root:current train perplexity5.164912223815918
INFO:root:current mean train loss 2083.9172816903706
INFO:root:current train perplexity5.169203758239746
INFO:root:current mean train loss 2085.3941325558108
INFO:root:current train perplexity5.1715497970581055
INFO:root:current mean train loss 2083.7334632384172
INFO:root:current train perplexity5.167786598205566
INFO:root:current mean train loss 2085.37989229983
INFO:root:current train perplexity5.1757025718688965
INFO:root:current mean train loss 2085.2346774845196
INFO:root:current train perplexity5.174491882324219
INFO:root:current mean train loss 2085.046058509051
INFO:root:current train perplexity5.175381183624268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it]
INFO:root:final mean train loss: 2083.7815238733333
INFO:root:final train perplexity: 5.172702789306641
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 2028.7231553530862
INFO:root:eval perplexity: 5.158842086791992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 2455.4629265534963
INFO:root:eval perplexity: 7.449486255645752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [1:45:58<9:57:12, 421.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2059.372083875868
INFO:root:current train perplexity5.068614482879639
INFO:root:current mean train loss 2079.5785451121146
INFO:root:current train perplexity5.092029094696045
INFO:root:current mean train loss 2079.2037613035186
INFO:root:current train perplexity5.10591983795166
INFO:root:current mean train loss 2079.4128835214733
INFO:root:current train perplexity5.117779731750488
INFO:root:current mean train loss 2076.4966465618118
INFO:root:current train perplexity5.1160712242126465
INFO:root:current mean train loss 2074.3782520500763
INFO:root:current train perplexity5.111475467681885
INFO:root:current mean train loss 2072.8753167481964
INFO:root:current train perplexity5.119507312774658
INFO:root:current mean train loss 2074.5446098995462
INFO:root:current train perplexity5.122624397277832
INFO:root:current mean train loss 2074.26761914863
INFO:root:current train perplexity5.122725486755371
INFO:root:current mean train loss 2072.9318607098403
INFO:root:current train perplexity5.117819309234619
INFO:root:current mean train loss 2070.3351653531563
INFO:root:current train perplexity5.1122236251831055
INFO:root:current mean train loss 2071.5741722067264
INFO:root:current train perplexity5.114008903503418
INFO:root:current mean train loss 2070.7627161442756
INFO:root:current train perplexity5.112705707550049
INFO:root:current mean train loss 2072.0800263758424
INFO:root:current train perplexity5.115861892700195
INFO:root:current mean train loss 2073.4456845877753
INFO:root:current train perplexity5.1227593421936035
INFO:root:current mean train loss 2074.118855794271
INFO:root:current train perplexity5.125523567199707
INFO:root:current mean train loss 2072.3626635919313
INFO:root:current train perplexity5.122477054595947
INFO:root:current mean train loss 2072.695429977017
INFO:root:current train perplexity5.1239471435546875
INFO:root:current mean train loss 2072.5148296335624
INFO:root:current train perplexity5.121964454650879
INFO:root:current mean train loss 2071.1079171531155
INFO:root:current train perplexity5.118672847747803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.99s/it]
INFO:root:final mean train loss: 2070.2318214958987
INFO:root:final train perplexity: 5.117722034454346
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 2019.8967172609152
INFO:root:eval perplexity: 5.122148036956787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 2449.436343362145
INFO:root:eval perplexity: 7.4128594398498535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [1:52:44<9:43:29, 416.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.7834489849251
INFO:root:current train perplexity4.964357376098633
INFO:root:current mean train loss 2065.710347136559
INFO:root:current train perplexity5.060731887817383
INFO:root:current mean train loss 2055.9166264270066
INFO:root:current train perplexity5.028727054595947
INFO:root:current mean train loss 2066.178916252527
INFO:root:current train perplexity5.072190761566162
INFO:root:current mean train loss 2065.1262790169685
INFO:root:current train perplexity5.0666327476501465
INFO:root:current mean train loss 2060.094792193999
INFO:root:current train perplexity5.059014320373535
INFO:root:current mean train loss 2057.5175031727367
INFO:root:current train perplexity5.055028438568115
INFO:root:current mean train loss 2056.8466986867707
INFO:root:current train perplexity5.05582332611084
INFO:root:current mean train loss 2053.305827196649
INFO:root:current train perplexity5.055254936218262
INFO:root:current mean train loss 2052.70776895195
INFO:root:current train perplexity5.049729824066162
INFO:root:current mean train loss 2051.9234266948965
INFO:root:current train perplexity5.050288200378418
INFO:root:current mean train loss 2052.6587694853824
INFO:root:current train perplexity5.05070686340332
INFO:root:current mean train loss 2051.920068532252
INFO:root:current train perplexity5.049014568328857
INFO:root:current mean train loss 2051.999238373849
INFO:root:current train perplexity5.0496110916137695
INFO:root:current mean train loss 2050.403742372058
INFO:root:current train perplexity5.046554088592529
INFO:root:current mean train loss 2051.4084583770536
INFO:root:current train perplexity5.050954818725586
INFO:root:current mean train loss 2054.5810124632985
INFO:root:current train perplexity5.057819366455078
INFO:root:current mean train loss 2055.365472794656
INFO:root:current train perplexity5.059200286865234
INFO:root:current mean train loss 2055.8400805833694
INFO:root:current train perplexity5.060056209564209
INFO:root:current mean train loss 2057.3915243937486
INFO:root:current train perplexity5.064428806304932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.07s/it]
INFO:root:final mean train loss: 2057.1312041328342
INFO:root:final train perplexity: 5.065117835998535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it]
INFO:root:eval mean loss: 2020.61418249252
INFO:root:eval perplexity: 5.125120639801025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.87s/it]
INFO:root:eval mean loss: 2449.5462161666114
INFO:root:eval perplexity: 7.413527488708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [1:59:35<9:34:17, 415.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2045.0482094504616
INFO:root:current train perplexity5.053683280944824
INFO:root:current mean train loss 2037.1707841589096
INFO:root:current train perplexity4.998271942138672
INFO:root:current mean train loss 2041.3519897460938
INFO:root:current train perplexity4.993195056915283
INFO:root:current mean train loss 2042.369179951776
INFO:root:current train perplexity4.991569519042969
INFO:root:current mean train loss 2045.8583101366387
INFO:root:current train perplexity5.005893230438232
INFO:root:current mean train loss 2042.8135519222337
INFO:root:current train perplexity5.000696182250977
INFO:root:current mean train loss 2043.9737962234851
INFO:root:current train perplexity5.005290985107422
INFO:root:current mean train loss 2047.56237421181
INFO:root:current train perplexity5.01447057723999
INFO:root:current mean train loss 2048.20157162778
INFO:root:current train perplexity5.02333402633667
INFO:root:current mean train loss 2045.609693025288
INFO:root:current train perplexity5.019325256347656
INFO:root:current mean train loss 2047.091854319853
INFO:root:current train perplexity5.028049945831299
INFO:root:current mean train loss 2048.106172503847
INFO:root:current train perplexity5.026516437530518
INFO:root:current mean train loss 2050.4526428791305
INFO:root:current train perplexity5.027320384979248
INFO:root:current mean train loss 2048.3603548165356
INFO:root:current train perplexity5.024681568145752
INFO:root:current mean train loss 2047.9670173070765
INFO:root:current train perplexity5.024346351623535
INFO:root:current mean train loss 2046.2522177900414
INFO:root:current train perplexity5.02034330368042
INFO:root:current mean train loss 2047.6777587456727
INFO:root:current train perplexity5.023715496063232
INFO:root:current mean train loss 2047.0153157278996
INFO:root:current train perplexity5.023739814758301
INFO:root:current mean train loss 2046.013403359106
INFO:root:current train perplexity5.020360946655273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.29s/it]
INFO:root:final mean train loss: 2046.3103943332783
INFO:root:final train perplexity: 5.022076606750488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 2011.3826973556627
INFO:root:eval perplexity: 5.086999893188477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 2443.785721582724
INFO:root:eval perplexity: 7.378682613372803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:06:34<9:28:49, 416.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1984.573681640625
INFO:root:current train perplexity4.9901347160339355
INFO:root:current mean train loss 2007.1526262555803
INFO:root:current train perplexity4.905209541320801
INFO:root:current mean train loss 2016.0587455935595
INFO:root:current train perplexity4.928913116455078
INFO:root:current mean train loss 2024.966713627049
INFO:root:current train perplexity4.954537868499756
INFO:root:current mean train loss 2024.7612265504438
INFO:root:current train perplexity4.951698303222656
INFO:root:current mean train loss 2024.732082495359
INFO:root:current train perplexity4.947818756103516
INFO:root:current mean train loss 2027.1490167791194
INFO:root:current train perplexity4.958599090576172
INFO:root:current mean train loss 2031.4418136704899
INFO:root:current train perplexity4.972837924957275
INFO:root:current mean train loss 2029.9734065654116
INFO:root:current train perplexity4.968155860900879
INFO:root:current mean train loss 2030.430126143819
INFO:root:current train perplexity4.9676408767700195
INFO:root:current mean train loss 2031.0305436926694
INFO:root:current train perplexity4.971892356872559
INFO:root:current mean train loss 2031.758023167951
INFO:root:current train perplexity4.970876693725586
INFO:root:current mean train loss 2034.919331581464
INFO:root:current train perplexity4.981252193450928
INFO:root:current mean train loss 2035.0452707809507
INFO:root:current train perplexity4.981048583984375
INFO:root:current mean train loss 2034.9747855732874
INFO:root:current train perplexity4.980423450469971
INFO:root:current mean train loss 2036.1094410234116
INFO:root:current train perplexity4.981595039367676
INFO:root:current mean train loss 2037.8373916958724
INFO:root:current train perplexity4.983694553375244
INFO:root:current mean train loss 2037.046577950307
INFO:root:current train perplexity4.984131336212158
INFO:root:current mean train loss 2037.3636052604527
INFO:root:current train perplexity4.9849348068237305
INFO:root:current mean train loss 2036.6563304190247
INFO:root:current train perplexity4.9833879470825195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.19s/it]
INFO:root:final mean train loss: 2035.7007642352576
INFO:root:final train perplexity: 4.98022985458374
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 1998.6402488329732
INFO:root:eval perplexity: 5.034846305847168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 2433.4648779470026
INFO:root:eval perplexity: 7.316664218902588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:13:21<9:18:18, 413.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2065.231789328835
INFO:root:current train perplexity5.062553882598877
INFO:root:current mean train loss 2026.2815461705943
INFO:root:current train perplexity4.943255424499512
INFO:root:current mean train loss 2022.8269774290893
INFO:root:current train perplexity4.930007457733154
INFO:root:current mean train loss 2026.2190521429784
INFO:root:current train perplexity4.937397003173828
INFO:root:current mean train loss 2031.9270470786435
INFO:root:current train perplexity4.949084758758545
INFO:root:current mean train loss 2030.0504583015295
INFO:root:current train perplexity4.945197105407715
INFO:root:current mean train loss 2027.1664416935666
INFO:root:current train perplexity4.9384989738464355
INFO:root:current mean train loss 2023.9661816203363
INFO:root:current train perplexity4.929348468780518
INFO:root:current mean train loss 2024.0006724262469
INFO:root:current train perplexity4.927696704864502
INFO:root:current mean train loss 2025.1779998315906
INFO:root:current train perplexity4.931131839752197
INFO:root:current mean train loss 2024.3070867430208
INFO:root:current train perplexity4.931285858154297
INFO:root:current mean train loss 2025.1490384950146
INFO:root:current train perplexity4.9381608963012695
INFO:root:current mean train loss 2024.4456263665481
INFO:root:current train perplexity4.935462474822998
INFO:root:current mean train loss 2024.0138270945124
INFO:root:current train perplexity4.93553352355957
INFO:root:current mean train loss 2025.0232206577994
INFO:root:current train perplexity4.940958023071289
INFO:root:current mean train loss 2025.5471857900532
INFO:root:current train perplexity4.944336891174316
INFO:root:current mean train loss 2026.869344953544
INFO:root:current train perplexity4.944436073303223
INFO:root:current mean train loss 2027.658164419779
INFO:root:current train perplexity4.94407844543457
INFO:root:current mean train loss 2026.2381597156714
INFO:root:current train perplexity4.942252159118652
INFO:root:current mean train loss 2025.1000056906869
INFO:root:current train perplexity4.939128398895264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.90s/it]
INFO:root:final mean train loss: 2025.5356742947376
INFO:root:final train perplexity: 4.940464973449707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 2025.9435797075853
INFO:root:eval perplexity: 5.147258758544922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2460.248255520002
INFO:root:eval perplexity: 7.478696346282959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:20:16<9:11:45, 413.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1997.2000669821714
INFO:root:current train perplexity4.899126052856445
INFO:root:current mean train loss 2006.872409299123
INFO:root:current train perplexity4.879950523376465
INFO:root:current mean train loss 2009.734526183316
INFO:root:current train perplexity4.900813579559326
INFO:root:current mean train loss 2015.4310093882514
INFO:root:current train perplexity4.900142669677734
INFO:root:current mean train loss 2020.0589035138453
INFO:root:current train perplexity4.912665367126465
INFO:root:current mean train loss 2019.2266379163527
INFO:root:current train perplexity4.905037879943848
INFO:root:current mean train loss 2014.4029747331647
INFO:root:current train perplexity4.899409294128418
INFO:root:current mean train loss 2017.3749018812373
INFO:root:current train perplexity4.902346134185791
INFO:root:current mean train loss 2019.2969516758696
INFO:root:current train perplexity4.909760475158691
INFO:root:current mean train loss 2019.81089059588
INFO:root:current train perplexity4.910568714141846
INFO:root:current mean train loss 2019.860315846066
INFO:root:current train perplexity4.91094446182251
INFO:root:current mean train loss 2019.4553913923603
INFO:root:current train perplexity4.908785343170166
INFO:root:current mean train loss 2019.0392775762648
INFO:root:current train perplexity4.908177852630615
INFO:root:current mean train loss 2017.2257634363039
INFO:root:current train perplexity4.902685642242432
INFO:root:current mean train loss 2016.6891510455123
INFO:root:current train perplexity4.903339385986328
INFO:root:current mean train loss 2015.3040239260986
INFO:root:current train perplexity4.900111675262451
INFO:root:current mean train loss 2014.84619393852
INFO:root:current train perplexity4.900042533874512
INFO:root:current mean train loss 2015.3335857336517
INFO:root:current train perplexity4.90349006652832
INFO:root:current mean train loss 2016.011007104638
INFO:root:current train perplexity4.90293025970459
INFO:root:current mean train loss 2016.9387093711723
INFO:root:current train perplexity4.903350353240967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.56s/it]
INFO:root:final mean train loss: 2015.9575179615108
INFO:root:final train perplexity: 4.903285026550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 2002.6548886130042
INFO:root:eval perplexity: 5.051218509674072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 2439.2503623150765
INFO:root:eval perplexity: 7.351363658905029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [2:26:58<9:00:18, 410.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2024.1632472446986
INFO:root:current train perplexity4.902030944824219
INFO:root:current mean train loss 2024.06545707507
INFO:root:current train perplexity4.895150661468506
INFO:root:current mean train loss 2009.8777656555176
INFO:root:current train perplexity4.865323543548584
INFO:root:current mean train loss 2013.11933710334
INFO:root:current train perplexity4.881397247314453
INFO:root:current mean train loss 2013.3233294570655
INFO:root:current train perplexity4.884952545166016
INFO:root:current mean train loss 2009.3623141281896
INFO:root:current train perplexity4.873051643371582
INFO:root:current mean train loss 2007.545298506574
INFO:root:current train perplexity4.867041110992432
INFO:root:current mean train loss 2009.1990186903213
INFO:root:current train perplexity4.868928909301758
INFO:root:current mean train loss 2012.0648437214788
INFO:root:current train perplexity4.874123573303223
INFO:root:current mean train loss 2010.1013431309657
INFO:root:current train perplexity4.8687591552734375
INFO:root:current mean train loss 2011.7272608207934
INFO:root:current train perplexity4.871569633483887
INFO:root:current mean train loss 2009.5622847929958
INFO:root:current train perplexity4.86986780166626
INFO:root:current mean train loss 2008.576076823435
INFO:root:current train perplexity4.8678154945373535
INFO:root:current mean train loss 2007.2752397475342
INFO:root:current train perplexity4.868398666381836
INFO:root:current mean train loss 2007.530632019043
INFO:root:current train perplexity4.868764400482178
INFO:root:current mean train loss 2038.204902237056
INFO:root:current train perplexity4.984555244445801
INFO:root:current mean train loss 2051.7462641766683
INFO:root:current train perplexity5.03859281539917
INFO:root:current mean train loss 2058.2442929348263
INFO:root:current train perplexity5.065718650817871
INFO:root:current mean train loss 2064.4145478873415
INFO:root:current train perplexity5.091416358947754
INFO:root:current mean train loss 2068.5997361883306
INFO:root:current train perplexity5.107965469360352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.79s/it]
INFO:root:final mean train loss: 2068.9851985590903
INFO:root:final train perplexity: 5.112692356109619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 2052.794311090564
INFO:root:eval perplexity: 5.260254859924316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it]
INFO:root:eval mean loss: 2489.081797498338
INFO:root:eval perplexity: 7.657147407531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:33:54<8:55:38, 412.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2151.236130805865
INFO:root:current train perplexity5.418812274932861
INFO:root:current mean train loss 2143.634818545656
INFO:root:current train perplexity5.38759708404541
INFO:root:current mean train loss 2137.954015263708
INFO:root:current train perplexity5.359375953674316
INFO:root:current mean train loss 2132.6103793801317
INFO:root:current train perplexity5.3437275886535645
INFO:root:current mean train loss 2136.9106976950648
INFO:root:current train perplexity5.351052761077881
INFO:root:current mean train loss 2134.981008373214
INFO:root:current train perplexity5.360697269439697
INFO:root:current mean train loss 2127.429413612672
INFO:root:current train perplexity5.340784549713135
INFO:root:current mean train loss 2123.0505693245673
INFO:root:current train perplexity5.329102993011475
INFO:root:current mean train loss 2123.152451837459
INFO:root:current train perplexity5.327527046203613
INFO:root:current mean train loss 2125.753043352149
INFO:root:current train perplexity5.328672885894775
INFO:root:current mean train loss 2126.559237662366
INFO:root:current train perplexity5.329162120819092
INFO:root:current mean train loss 2126.059274866961
INFO:root:current train perplexity5.328349590301514
INFO:root:current mean train loss 2124.6275484215435
INFO:root:current train perplexity5.325870037078857
INFO:root:current mean train loss 2125.3257864599927
INFO:root:current train perplexity5.331408977508545
INFO:root:current mean train loss 2124.1536208888906
INFO:root:current train perplexity5.331166744232178
INFO:root:current mean train loss 2123.432590879912
INFO:root:current train perplexity5.3277177810668945
INFO:root:current mean train loss 2122.9805043568813
INFO:root:current train perplexity5.326531410217285
INFO:root:current mean train loss 2121.3463844604835
INFO:root:current train perplexity5.323190689086914
INFO:root:current mean train loss 2121.387507481939
INFO:root:current train perplexity5.323067665100098
INFO:root:current mean train loss 2120.530497903336
INFO:root:current train perplexity5.3224711418151855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.33s/it]
INFO:root:final mean train loss: 2120.044058733857
INFO:root:final train perplexity: 5.322771072387695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 2042.1008430643285
INFO:root:eval perplexity: 5.214958190917969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 2481.5171517446533
INFO:root:eval perplexity: 7.609922885894775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:40:37<8:45:29, 409.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.2477715386285
INFO:root:current train perplexity5.2760910987854
INFO:root:current mean train loss 2112.6062731291117
INFO:root:current train perplexity5.281267166137695
INFO:root:current mean train loss 2108.526076744343
INFO:root:current train perplexity5.269428730010986
INFO:root:current mean train loss 2108.7257342998796
INFO:root:current train perplexity5.280116081237793
INFO:root:current mean train loss 2117.048810686384
INFO:root:current train perplexity5.294650554656982
INFO:root:current mean train loss 2114.2494719941737
INFO:root:current train perplexity5.286900520324707
INFO:root:current mean train loss 2118.035838782269
INFO:root:current train perplexity5.292064189910889
INFO:root:current mean train loss 2118.4488214806665
INFO:root:current train perplexity5.296465873718262
INFO:root:current mean train loss 2115.921103625351
INFO:root:current train perplexity5.292061805725098
INFO:root:current mean train loss 2113.56816443241
INFO:root:current train perplexity5.283567905426025
INFO:root:current mean train loss 2111.7517643079846
INFO:root:current train perplexity5.276810646057129
INFO:root:current mean train loss 2111.5945720768777
INFO:root:current train perplexity5.274953842163086
INFO:root:current mean train loss 2111.404473829639
INFO:root:current train perplexity5.273127555847168
INFO:root:current mean train loss 2111.6509755964757
INFO:root:current train perplexity5.272627830505371
INFO:root:current mean train loss 2110.984268987259
INFO:root:current train perplexity5.2721357345581055
INFO:root:current mean train loss 2110.0103392019214
INFO:root:current train perplexity5.271315574645996
INFO:root:current mean train loss 2109.8648792153986
INFO:root:current train perplexity5.272724628448486
INFO:root:current mean train loss 2108.731686929884
INFO:root:current train perplexity5.272151947021484
INFO:root:current mean train loss 2108.555596568597
INFO:root:current train perplexity5.2718963623046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.25s/it]
INFO:root:final mean train loss: 2107.112047773506
INFO:root:final train perplexity: 5.26876163482666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 2035.3888562790892
INFO:root:eval perplexity: 5.186727046966553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 2474.475111075327
INFO:root:eval perplexity: 7.566219806671143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:47:22<8:36:48, 408.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.3263113839287
INFO:root:current train perplexity5.1457295417785645
INFO:root:current mean train loss 2099.5171400408876
INFO:root:current train perplexity5.16808557510376
INFO:root:current mean train loss 2108.661612248075
INFO:root:current train perplexity5.223639965057373
INFO:root:current mean train loss 2106.3394652127445
INFO:root:current train perplexity5.221732139587402
INFO:root:current mean train loss 2097.565053878897
INFO:root:current train perplexity5.2099761962890625
INFO:root:current mean train loss 2091.72831024832
INFO:root:current train perplexity5.1948347091674805
INFO:root:current mean train loss 2087.9761586825575
INFO:root:current train perplexity5.199120044708252
INFO:root:current mean train loss 2088.1835476498964
INFO:root:current train perplexity5.200986385345459
INFO:root:current mean train loss 2087.893125096809
INFO:root:current train perplexity5.202874660491943
INFO:root:current mean train loss 2091.163173553568
INFO:root:current train perplexity5.206972122192383
INFO:root:current mean train loss 2091.69414586178
INFO:root:current train perplexity5.207695484161377
INFO:root:current mean train loss 2090.7854980909833
INFO:root:current train perplexity5.2044267654418945
INFO:root:current mean train loss 2091.4933134393445
INFO:root:current train perplexity5.204801559448242
INFO:root:current mean train loss 2091.7122249822173
INFO:root:current train perplexity5.200629711151123
INFO:root:current mean train loss 2090.807793742643
INFO:root:current train perplexity5.195897579193115
INFO:root:current mean train loss 2090.950974391641
INFO:root:current train perplexity5.19494104385376
INFO:root:current mean train loss 2091.0674875635646
INFO:root:current train perplexity5.192101001739502
INFO:root:current mean train loss 2090.047316369636
INFO:root:current train perplexity5.189816474914551
INFO:root:current mean train loss 2089.0808576996574
INFO:root:current train perplexity5.1892876625061035
INFO:root:current mean train loss 2088.7594381411413
INFO:root:current train perplexity5.191186904907227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.78s/it]
INFO:root:final mean train loss: 2087.441966062114
INFO:root:final train perplexity: 5.187657833099365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it]
INFO:root:eval mean loss: 2029.9192375020777
INFO:root:eval perplexity: 5.163835048675537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 2470.990260347407
INFO:root:eval perplexity: 7.5446882247924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:54:17<8:32:48, 410.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2080.440485636393
INFO:root:current train perplexity5.16810941696167
INFO:root:current mean train loss 2082.0134887695312
INFO:root:current train perplexity5.167853832244873
INFO:root:current mean train loss 2078.449421473912
INFO:root:current train perplexity5.135324954986572
INFO:root:current mean train loss 2074.2190050666713
INFO:root:current train perplexity5.12814998626709
INFO:root:current mean train loss 2075.156313914173
INFO:root:current train perplexity5.126865386962891
INFO:root:current mean train loss 2079.030777559936
INFO:root:current train perplexity5.129333972930908
INFO:root:current mean train loss 2078.4772841624726
INFO:root:current train perplexity5.1267924308776855
INFO:root:current mean train loss 2076.492418152193
INFO:root:current train perplexity5.121607303619385
INFO:root:current mean train loss 2073.0145413296896
INFO:root:current train perplexity5.120105266571045
INFO:root:current mean train loss 2072.3226730544848
INFO:root:current train perplexity5.122725486755371
INFO:root:current mean train loss 2070.638233065605
INFO:root:current train perplexity5.1163482666015625
INFO:root:current mean train loss 2070.8981681633672
INFO:root:current train perplexity5.114791393280029
INFO:root:current mean train loss 2071.426639531952
INFO:root:current train perplexity5.113523006439209
INFO:root:current mean train loss 2069.1837530683533
INFO:root:current train perplexity5.109245300292969
INFO:root:current mean train loss 2068.6164519920776
INFO:root:current train perplexity5.108574390411377
INFO:root:current mean train loss 2068.1238227904314
INFO:root:current train perplexity5.104925632476807
INFO:root:current mean train loss 2067.6549363911445
INFO:root:current train perplexity5.102174282073975
INFO:root:current mean train loss 2066.706592958101
INFO:root:current train perplexity5.101017475128174
INFO:root:current mean train loss 2066.16710087291
INFO:root:current train perplexity5.102115631103516
INFO:root:current mean train loss 2067.517292363728
INFO:root:current train perplexity5.105031490325928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.30s/it]
INFO:root:final mean train loss: 2066.585618442799
INFO:root:final train perplexity: 5.103025913238525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 2029.5699030017176
INFO:root:eval perplexity: 5.1623759269714355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it]
INFO:root:eval mean loss: 2471.443929902205
INFO:root:eval perplexity: 7.547487258911133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [3:01:19<8:30:06, 413.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.0270192216083
INFO:root:current train perplexity5.0132646560668945
INFO:root:current mean train loss 2057.6652355870456
INFO:root:current train perplexity5.041195869445801
INFO:root:current mean train loss 2052.1693251993647
INFO:root:current train perplexity5.027729034423828
INFO:root:current mean train loss 2049.9535130475624
INFO:root:current train perplexity5.034999847412109
INFO:root:current mean train loss 2046.3782106429812
INFO:root:current train perplexity5.031935214996338
INFO:root:current mean train loss 2049.658679447421
INFO:root:current train perplexity5.032704830169678
INFO:root:current mean train loss 2050.841483415196
INFO:root:current train perplexity5.025975704193115
INFO:root:current mean train loss 2050.2231091127383
INFO:root:current train perplexity5.022755146026611
INFO:root:current mean train loss 2049.8023960326714
INFO:root:current train perplexity5.0235276222229
INFO:root:current mean train loss 2049.990042383435
INFO:root:current train perplexity5.029019832611084
INFO:root:current mean train loss 2048.7714207014365
INFO:root:current train perplexity5.024430274963379
INFO:root:current mean train loss 2049.4095967164903
INFO:root:current train perplexity5.025751113891602
INFO:root:current mean train loss 2047.3542590636962
INFO:root:current train perplexity5.023722171783447
INFO:root:current mean train loss 2048.868874364251
INFO:root:current train perplexity5.027744293212891
INFO:root:current mean train loss 2049.241260070589
INFO:root:current train perplexity5.029198169708252
INFO:root:current mean train loss 2049.6069488822445
INFO:root:current train perplexity5.031581878662109
INFO:root:current mean train loss 2049.1534080900556
INFO:root:current train perplexity5.030731678009033
INFO:root:current mean train loss 2048.719098471828
INFO:root:current train perplexity5.031851768493652
INFO:root:current mean train loss 2049.2049225698925
INFO:root:current train perplexity5.035589218139648
INFO:root:current mean train loss 2049.1491351434706
INFO:root:current train perplexity5.032768249511719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.05s/it]
INFO:root:final mean train loss: 2049.1442776909394
INFO:root:final train perplexity: 5.033312797546387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 2021.4835598992963
INFO:root:eval perplexity: 5.128726482391357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 2462.0310301002883
INFO:root:eval perplexity: 7.489609718322754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [3:08:18<8:25:25, 415.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2053.307598245555
INFO:root:current train perplexity5.040373802185059
INFO:root:current mean train loss 2021.3673814218255
INFO:root:current train perplexity4.978469371795654
INFO:root:current mean train loss 2016.430145973383
INFO:root:current train perplexity4.940500736236572
INFO:root:current mean train loss 2023.2198063514752
INFO:root:current train perplexity4.951272964477539
INFO:root:current mean train loss 2026.2084334594194
INFO:root:current train perplexity4.95728874206543
INFO:root:current mean train loss 2030.2036005929378
INFO:root:current train perplexity4.961381435394287
INFO:root:current mean train loss 2032.2344428992924
INFO:root:current train perplexity4.96718168258667
INFO:root:current mean train loss 2032.7283858246412
INFO:root:current train perplexity4.969900608062744
INFO:root:current mean train loss 2029.5501425860923
INFO:root:current train perplexity4.9679975509643555
INFO:root:current mean train loss 2029.80685507629
INFO:root:current train perplexity4.969406604766846
INFO:root:current mean train loss 2029.7921675626183
INFO:root:current train perplexity4.969211578369141
INFO:root:current mean train loss 2030.0288236680633
INFO:root:current train perplexity4.970841884613037
INFO:root:current mean train loss 2030.021596256614
INFO:root:current train perplexity4.968931198120117
INFO:root:current mean train loss 2031.7160150137495
INFO:root:current train perplexity4.971482276916504
INFO:root:current mean train loss 2033.1770293310346
INFO:root:current train perplexity4.972032070159912
INFO:root:current mean train loss 2032.6777199584803
INFO:root:current train perplexity4.9717817306518555
INFO:root:current mean train loss 2033.9768744492847
INFO:root:current train perplexity4.9712018966674805
INFO:root:current mean train loss 2033.2391783765288
INFO:root:current train perplexity4.968745231628418
INFO:root:current mean train loss 2032.7741074413223
INFO:root:current train perplexity4.967491626739502
INFO:root:current mean train loss 2033.448722738046
INFO:root:current train perplexity4.969557762145996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it]
INFO:root:final mean train loss: 2032.8895279984852
INFO:root:final train perplexity: 4.969200134277344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 2016.2701753656916
INFO:root:eval perplexity: 5.107147216796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 2458.1824916542
INFO:root:eval perplexity: 7.466072082519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [3:15:17<8:19:27, 416.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2025.0602408854168
INFO:root:current train perplexity4.926289081573486
INFO:root:current mean train loss 2012.3859779575894
INFO:root:current train perplexity4.901638031005859
INFO:root:current mean train loss 2012.0155996981534
INFO:root:current train perplexity4.904693126678467
INFO:root:current mean train loss 2013.4355341796875
INFO:root:current train perplexity4.897303581237793
INFO:root:current mean train loss 2018.301474609375
INFO:root:current train perplexity4.908158779144287
INFO:root:current mean train loss 2028.56177288553
INFO:root:current train perplexity4.9284868240356445
INFO:root:current mean train loss 2067.8682562934027
INFO:root:current train perplexity5.092679500579834
INFO:root:current mean train loss 2193.2783281880043
INFO:root:current train perplexity5.621673583984375
INFO:root:current mean train loss 2296.9302784598212
INFO:root:current train perplexity6.094242095947266
INFO:root:current mean train loss 2381.200299979968
INFO:root:current train perplexity6.520226955413818
INFO:root:current mean train loss 2451.8743320766716
INFO:root:current train perplexity6.89353609085083
INFO:root:current mean train loss 2509.9748466589094
INFO:root:current train perplexity7.227614879608154
INFO:root:current mean train loss 2562.1731565946693
INFO:root:current train perplexity7.527346134185791
INFO:root:current mean train loss 2605.8733000710226
INFO:root:current train perplexity7.790568828582764
INFO:root:current mean train loss 2644.655392280191
INFO:root:current train perplexity8.034957885742188
INFO:root:current mean train loss 2680.3473849826387
INFO:root:current train perplexity8.262462615966797
INFO:root:current mean train loss 2713.139656308302
INFO:root:current train perplexity8.483086585998535
INFO:root:current mean train loss 2741.2612460112236
INFO:root:current train perplexity8.67922592163086
INFO:root:current mean train loss 2765.24479609375
INFO:root:current train perplexity8.84455394744873
INFO:root:current mean train loss 2784.292338558149
INFO:root:current train perplexity8.980212211608887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.85s/it]
INFO:root:final mean train loss: 2784.4144048262774
INFO:root:final train perplexity: 8.988594055175781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it]
INFO:root:eval mean loss: 2699.7053845994014
INFO:root:eval perplexity: 8.876108169555664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 3113.240715730275
INFO:root:eval perplexity: 12.757172584533691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:22:04<8:09:23, 413.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3059.756682022758
INFO:root:current train perplexity11.385540962219238
INFO:root:current mean train loss 3046.182486216227
INFO:root:current train perplexity11.115788459777832
INFO:root:current mean train loss 3008.5383643581445
INFO:root:current train perplexity10.749344825744629
INFO:root:current mean train loss 2960.4079403001433
INFO:root:current train perplexity10.352004051208496
INFO:root:current mean train loss 2927.807475764577
INFO:root:current train perplexity10.063983917236328
INFO:root:current mean train loss 2891.7882830645585
INFO:root:current train perplexity9.789889335632324
INFO:root:current mean train loss 2855.695864638841
INFO:root:current train perplexity9.513154983520508
INFO:root:current mean train loss 2819.6500968547784
INFO:root:current train perplexity9.236315727233887
INFO:root:current mean train loss 2790.084685458196
INFO:root:current train perplexity9.026253700256348
INFO:root:current mean train loss 2766.9605847020302
INFO:root:current train perplexity8.848390579223633
INFO:root:current mean train loss 2742.390871264559
INFO:root:current train perplexity8.671082496643066
INFO:root:current mean train loss 2720.0618104870687
INFO:root:current train perplexity8.516718864440918
INFO:root:current mean train loss 2696.385171045829
INFO:root:current train perplexity8.365025520324707
INFO:root:current mean train loss 2674.6120115258227
INFO:root:current train perplexity8.227974891662598
INFO:root:current mean train loss 2657.438034180342
INFO:root:current train perplexity8.1204833984375
INFO:root:current mean train loss 2641.3464961986447
INFO:root:current train perplexity8.013142585754395
INFO:root:current mean train loss 2625.0550185760426
INFO:root:current train perplexity7.925442218780518
INFO:root:current mean train loss 2611.9752681595937
INFO:root:current train perplexity7.834546089172363
INFO:root:current mean train loss 2599.099079607909
INFO:root:current train perplexity7.75956916809082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.59s/it]
INFO:root:final mean train loss: 2585.5748653594615
INFO:root:final train perplexity: 7.683998107910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 2179.280338801391
INFO:root:eval perplexity: 5.826836109161377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 2608.1338548592644
INFO:root:eval perplexity: 8.440178871154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:29:02<8:04:05, 414.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2374.1283094618057
INFO:root:current train perplexity6.616462230682373
INFO:root:current mean train loss 2361.0000100792
INFO:root:current train perplexity6.374195098876953
INFO:root:current mean train loss 2351.5624702125074
INFO:root:current train perplexity6.376739978790283
INFO:root:current mean train loss 2340.199995022376
INFO:root:current train perplexity6.336538791656494
INFO:root:current mean train loss 2331.989119923785
INFO:root:current train perplexity6.292799949645996
INFO:root:current mean train loss 2326.5919023974707
INFO:root:current train perplexity6.267482757568359
INFO:root:current mean train loss 2322.081880716659
INFO:root:current train perplexity6.230705738067627
INFO:root:current mean train loss 2317.732539124482
INFO:root:current train perplexity6.208522796630859
INFO:root:current mean train loss 2314.3719485439683
INFO:root:current train perplexity6.194427013397217
INFO:root:current mean train loss 2308.408917686202
INFO:root:current train perplexity6.168150424957275
INFO:root:current mean train loss 2307.068878506527
INFO:root:current train perplexity6.156013011932373
INFO:root:current mean train loss 2301.237179645232
INFO:root:current train perplexity6.126221656799316
INFO:root:current mean train loss 2295.802491244055
INFO:root:current train perplexity6.102529048919678
INFO:root:current mean train loss 2291.922198407062
INFO:root:current train perplexity6.081112861633301
INFO:root:current mean train loss 2288.8118185201715
INFO:root:current train perplexity6.066758632659912
INFO:root:current mean train loss 2285.401186953798
INFO:root:current train perplexity6.05033016204834
INFO:root:current mean train loss 2279.8915148462993
INFO:root:current train perplexity6.029482364654541
INFO:root:current mean train loss 2274.1294221024264
INFO:root:current train perplexity6.003996849060059
INFO:root:current mean train loss 2270.519062605268
INFO:root:current train perplexity5.990758895874023
INFO:root:current mean train loss 2266.581101367085
INFO:root:current train perplexity5.974073886871338

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.70s/it]
INFO:root:final mean train loss: 2263.822949938983
INFO:root:final train perplexity: 5.961886882781982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it]
INFO:root:eval mean loss: 2084.811637283217
INFO:root:eval perplexity: 5.39824104309082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 2520.916822501108
INFO:root:eval perplexity: 7.859123229980469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:35:48<7:53:59, 412.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2193.2652963491587
INFO:root:current train perplexity5.685551166534424
INFO:root:current mean train loss 2196.1846836635045
INFO:root:current train perplexity5.661684513092041
INFO:root:current mean train loss 2199.005535294524
INFO:root:current train perplexity5.681976318359375
INFO:root:current mean train loss 2198.5575220775017
INFO:root:current train perplexity5.666184902191162
INFO:root:current mean train loss 2198.1168155580617
INFO:root:current train perplexity5.664639472961426
INFO:root:current mean train loss 2195.2028613652565
INFO:root:current train perplexity5.650588512420654
INFO:root:current mean train loss 2194.833724244334
INFO:root:current train perplexity5.641919136047363
INFO:root:current mean train loss 2195.681585474776
INFO:root:current train perplexity5.64157247543335
INFO:root:current mean train loss 2196.2601092248506
INFO:root:current train perplexity5.634072780609131
INFO:root:current mean train loss 2196.1097906454593
INFO:root:current train perplexity5.629420280456543
INFO:root:current mean train loss 2192.795778270818
INFO:root:current train perplexity5.617356777191162
INFO:root:current mean train loss 2190.5737067268333
INFO:root:current train perplexity5.615819931030273
INFO:root:current mean train loss 2190.4110698855525
INFO:root:current train perplexity5.614599227905273
INFO:root:current mean train loss 2190.5863071171225
INFO:root:current train perplexity5.611407279968262
INFO:root:current mean train loss 2188.121340801137
INFO:root:current train perplexity5.60604190826416
INFO:root:current mean train loss 2186.895652760997
INFO:root:current train perplexity5.604019641876221
INFO:root:current mean train loss 2186.874032971897
INFO:root:current train perplexity5.606639862060547
INFO:root:current mean train loss 2188.8433487097604
INFO:root:current train perplexity5.614029884338379
INFO:root:current mean train loss 2189.0407684092193
INFO:root:current train perplexity5.616617202758789
INFO:root:current mean train loss 2190.847298912294
INFO:root:current train perplexity5.6233673095703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.23s/it]
INFO:root:final mean train loss: 2190.1890257865684
INFO:root:final train perplexity: 5.625527381896973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 2083.7351879363364
INFO:root:eval perplexity: 5.393544673919678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2519.744789502299
INFO:root:eval perplexity: 7.851592540740967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:42:38<7:46:21, 411.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2200.175792605378
INFO:root:current train perplexity5.608633041381836
INFO:root:current mean train loss 2191.4733383072007
INFO:root:current train perplexity5.667068958282471
INFO:root:current mean train loss 2200.005816675508
INFO:root:current train perplexity5.682131767272949
INFO:root:current mean train loss 2202.883872340789
INFO:root:current train perplexity5.693320274353027
INFO:root:current mean train loss 2212.539242161047
INFO:root:current train perplexity5.724894046783447
INFO:root:current mean train loss 2219.955433095577
INFO:root:current train perplexity5.750051498413086
INFO:root:current mean train loss 2222.745789618366
INFO:root:current train perplexity5.766755104064941
INFO:root:current mean train loss 2229.961663350122
INFO:root:current train perplexity5.798191547393799
INFO:root:current mean train loss 2229.7467109073805
INFO:root:current train perplexity5.80136775970459
INFO:root:current mean train loss 2228.585391225643
INFO:root:current train perplexity5.7924628257751465
INFO:root:current mean train loss 2232.0849272306446
INFO:root:current train perplexity5.815013408660889
INFO:root:current mean train loss 2235.9106262687624
INFO:root:current train perplexity5.8312458992004395
INFO:root:current mean train loss 2239.320392439851
INFO:root:current train perplexity5.840707302093506
INFO:root:current mean train loss 2242.482443689501
INFO:root:current train perplexity5.855515003204346
INFO:root:current mean train loss 2241.844382599998
INFO:root:current train perplexity5.855517864227295
INFO:root:current mean train loss 2246.3645828850304
INFO:root:current train perplexity5.876040935516357
INFO:root:current mean train loss 2247.69214439276
INFO:root:current train perplexity5.880556583404541
INFO:root:current mean train loss 2246.6897144241025
INFO:root:current train perplexity5.878978729248047
INFO:root:current mean train loss 2248.758389800512
INFO:root:current train perplexity5.886281490325928
INFO:root:current mean train loss 2248.678633599078
INFO:root:current train perplexity5.890467166900635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.77s/it]
INFO:root:final mean train loss: 2249.616343534299
INFO:root:final train perplexity: 5.895460605621338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 2126.581974976452
INFO:root:eval perplexity: 5.583717346191406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 2562.6589688781305
INFO:root:eval perplexity: 8.132047653198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:49:29<7:39:21, 411.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2250.838869222005
INFO:root:current train perplexity5.975010395050049
INFO:root:current mean train loss 2253.3882591247557
INFO:root:current train perplexity5.964819431304932
INFO:root:current mean train loss 2264.0528193547175
INFO:root:current train perplexity5.9612579345703125
INFO:root:current mean train loss 2265.9206349690753
INFO:root:current train perplexity5.978764533996582
INFO:root:current mean train loss 2268.80377621858
INFO:root:current train perplexity5.9831624031066895
INFO:root:current mean train loss 2270.0416684831894
INFO:root:current train perplexity5.988210201263428
INFO:root:current mean train loss 2265.4174727006393
INFO:root:current train perplexity5.967813491821289
INFO:root:current mean train loss 2265.6339347437806
INFO:root:current train perplexity5.956765174865723
INFO:root:current mean train loss 2266.2466525765353
INFO:root:current train perplexity5.9591827392578125
INFO:root:current mean train loss 2267.140292485555
INFO:root:current train perplexity5.957664489746094
INFO:root:current mean train loss 2266.261515030771
INFO:root:current train perplexity5.963022708892822
INFO:root:current mean train loss 2267.9547950481547
INFO:root:current train perplexity5.9683709144592285
INFO:root:current mean train loss 2265.85381101578
INFO:root:current train perplexity5.964487552642822
INFO:root:current mean train loss 2264.4967742022345
INFO:root:current train perplexity5.960491180419922
INFO:root:current mean train loss 2265.136020691754
INFO:root:current train perplexity5.964817047119141
INFO:root:current mean train loss 2267.5756717779695
INFO:root:current train perplexity5.977386474609375
INFO:root:current mean train loss 2266.6467321924415
INFO:root:current train perplexity5.977216720581055
INFO:root:current mean train loss 2266.105266501687
INFO:root:current train perplexity5.970709800720215
INFO:root:current mean train loss 2266.2003131169145
INFO:root:current train perplexity5.97222900390625
INFO:root:current mean train loss 2267.6283160774074
INFO:root:current train perplexity5.976948261260986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.79s/it]
INFO:root:final mean train loss: 2266.8754112716883
INFO:root:final train perplexity: 5.976256370544434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 2107.2402897828015
INFO:root:eval perplexity: 5.497053146362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 2543.099214594415
INFO:root:eval perplexity: 8.002997398376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:56:16<7:31:15, 410.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2232.090175083705
INFO:root:current train perplexity5.855510234832764
INFO:root:current mean train loss 2237.4159639002914
INFO:root:current train perplexity5.895559787750244
INFO:root:current mean train loss 2238.533068274763
INFO:root:current train perplexity5.8885626792907715
INFO:root:current mean train loss 2248.3290649737855
INFO:root:current train perplexity5.899764060974121
INFO:root:current mean train loss 2256.9226199615928
INFO:root:current train perplexity5.924494743347168
INFO:root:current mean train loss 2263.314689437893
INFO:root:current train perplexity5.9511284828186035
INFO:root:current mean train loss 2267.3697071610736
INFO:root:current train perplexity5.9620819091796875
INFO:root:current mean train loss 2265.657079512548
INFO:root:current train perplexity5.96429967880249
INFO:root:current mean train loss 2268.4442971032727
INFO:root:current train perplexity5.972659587860107
INFO:root:current mean train loss 2270.9280808447816
INFO:root:current train perplexity5.985929012298584
INFO:root:current mean train loss 2268.9557739371157
INFO:root:current train perplexity5.988206386566162
INFO:root:current mean train loss 2267.9751553207307
INFO:root:current train perplexity5.9778852462768555
INFO:root:current mean train loss 2267.987009309845
INFO:root:current train perplexity5.978900909423828
INFO:root:current mean train loss 2266.467136047851
INFO:root:current train perplexity5.97914457321167
INFO:root:current mean train loss 2268.870649602499
INFO:root:current train perplexity5.982424259185791
INFO:root:current mean train loss 2268.95506604956
INFO:root:current train perplexity5.987110137939453
INFO:root:current mean train loss 2268.9417271850075
INFO:root:current train perplexity5.988302230834961
INFO:root:current mean train loss 2271.103977458827
INFO:root:current train perplexity5.994692325592041
INFO:root:current mean train loss 2271.8529889732204
INFO:root:current train perplexity5.99257230758667
INFO:root:current mean train loss 2271.9124627429305
INFO:root:current train perplexity5.996667861938477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it]
INFO:root:final mean train loss: 2271.124248033332
INFO:root:final train perplexity: 5.9963154792785645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 2125.365131351119
INFO:root:eval perplexity: 5.578223705291748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it]
INFO:root:eval mean loss: 2561.8912885949967
INFO:root:eval perplexity: 8.126946449279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [4:03:18<7:27:59, 413.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2306.2587202356217
INFO:root:current train perplexity6.182861328125
INFO:root:current mean train loss 2294.413696918291
INFO:root:current train perplexity6.135950565338135
INFO:root:current mean train loss 2289.4046863374256
INFO:root:current train perplexity6.108757495880127
INFO:root:current mean train loss 2292.797961239887
INFO:root:current train perplexity6.101822853088379
INFO:root:current mean train loss 2288.9118877210117
INFO:root:current train perplexity6.098813056945801
INFO:root:current mean train loss 2285.332354099261
INFO:root:current train perplexity6.074265480041504
INFO:root:current mean train loss 2283.6805409368244
INFO:root:current train perplexity6.068354606628418
INFO:root:current mean train loss 2284.9655735582787
INFO:root:current train perplexity6.068711757659912
INFO:root:current mean train loss 2286.241918508372
INFO:root:current train perplexity6.062884330749512
INFO:root:current mean train loss 2284.703701211173
INFO:root:current train perplexity6.057799816131592
INFO:root:current mean train loss 2282.1872371136596
INFO:root:current train perplexity6.050822734832764
INFO:root:current mean train loss 2280.674958348873
INFO:root:current train perplexity6.039233684539795
INFO:root:current mean train loss 2280.728898816352
INFO:root:current train perplexity6.040694713592529
INFO:root:current mean train loss 2279.926852824185
INFO:root:current train perplexity6.038885116577148
INFO:root:current mean train loss 2281.6059623422075
INFO:root:current train perplexity6.039544582366943
INFO:root:current mean train loss 2281.203318673664
INFO:root:current train perplexity6.036430358886719
INFO:root:current mean train loss 2281.3441389099626
INFO:root:current train perplexity6.039947032928467
INFO:root:current mean train loss 2281.07668437979
INFO:root:current train perplexity6.039745807647705
INFO:root:current mean train loss 2281.9243276851857
INFO:root:current train perplexity6.042977809906006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.28s/it]
INFO:root:final mean train loss: 2280.833882557402
INFO:root:final train perplexity: 6.0424089431762695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 2127.239759512827
INFO:root:eval perplexity: 5.586688041687012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 2569.7179972330728
INFO:root:eval perplexity: 8.179132461547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [4:10:03<7:18:39, 411.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2233.4080144708805
INFO:root:current train perplexity5.8708062171936035
INFO:root:current mean train loss 2287.23217993384
INFO:root:current train perplexity6.085226058959961
INFO:root:current mean train loss 2295.4428520021847
INFO:root:current train perplexity6.060916423797607
INFO:root:current mean train loss 2291.7197214598823
INFO:root:current train perplexity6.048196315765381
INFO:root:current mean train loss 2292.863096807995
INFO:root:current train perplexity6.0567498207092285
INFO:root:current mean train loss 2287.4103994350844
INFO:root:current train perplexity6.034902095794678
INFO:root:current mean train loss 2282.7371308721613
INFO:root:current train perplexity6.033132553100586
INFO:root:current mean train loss 2283.733537333256
INFO:root:current train perplexity6.042639255523682
INFO:root:current mean train loss 2285.135715244731
INFO:root:current train perplexity6.058987140655518
INFO:root:current mean train loss 2284.222451370189
INFO:root:current train perplexity6.062224388122559
INFO:root:current mean train loss 2286.574977735148
INFO:root:current train perplexity6.068480491638184
INFO:root:current mean train loss 2286.9139658106437
INFO:root:current train perplexity6.059315204620361
INFO:root:current mean train loss 2286.8515392149116
INFO:root:current train perplexity6.053471565246582
INFO:root:current mean train loss 2288.4192984877063
INFO:root:current train perplexity6.0623955726623535
INFO:root:current mean train loss 2288.0089957428518
INFO:root:current train perplexity6.066911220550537
INFO:root:current mean train loss 2286.812701484685
INFO:root:current train perplexity6.069525718688965
INFO:root:current mean train loss 2288.5241544641817
INFO:root:current train perplexity6.074358940124512
INFO:root:current mean train loss 2288.768576162172
INFO:root:current train perplexity6.079000949859619
INFO:root:current mean train loss 2290.4190495205085
INFO:root:current train perplexity6.0836968421936035
INFO:root:current mean train loss 2291.2334764321895
INFO:root:current train perplexity6.091325283050537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.02s/it]
INFO:root:final mean train loss: 2291.8771711033037
INFO:root:final train perplexity: 6.0952653884887695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 2120.066979374446
INFO:root:eval perplexity: 5.554373741149902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it]
INFO:root:eval mean loss: 2558.288885887633
INFO:root:eval perplexity: 8.103034973144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [4:17:05<7:15:02, 414.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2325.4237758091517
INFO:root:current train perplexity6.163628578186035
INFO:root:current mean train loss 2273.5574522018433
INFO:root:current train perplexity6.049458026885986
INFO:root:current mean train loss 2291.4591364274947
INFO:root:current train perplexity6.096339225769043
INFO:root:current mean train loss 2292.0258777897534
INFO:root:current train perplexity6.072737693786621
INFO:root:current mean train loss 2294.4603357047677
INFO:root:current train perplexity6.089596748352051
INFO:root:current mean train loss 2294.439767779726
INFO:root:current train perplexity6.094812393188477
INFO:root:current mean train loss 2293.5050305409036
INFO:root:current train perplexity6.096409797668457
INFO:root:current mean train loss 2292.3994667137063
INFO:root:current train perplexity6.096863269805908
INFO:root:current mean train loss 2293.16657246023
INFO:root:current train perplexity6.099994659423828
INFO:root:current mean train loss 2295.5883116886534
INFO:root:current train perplexity6.102739334106445
INFO:root:current mean train loss 2294.347441795735
INFO:root:current train perplexity6.097446918487549
INFO:root:current mean train loss 2295.034095493614
INFO:root:current train perplexity6.09794282913208
INFO:root:current mean train loss 2295.0176925410665
INFO:root:current train perplexity6.10105037689209
INFO:root:current mean train loss 2297.141754609993
INFO:root:current train perplexity6.106523036956787
INFO:root:current mean train loss 2296.017746099905
INFO:root:current train perplexity6.101181507110596
INFO:root:current mean train loss 2294.4712348658377
INFO:root:current train perplexity6.100546360015869
INFO:root:current mean train loss 2295.668394646422
INFO:root:current train perplexity6.108944416046143
INFO:root:current mean train loss 2295.006182493987
INFO:root:current train perplexity6.111105442047119
INFO:root:current mean train loss 2296.162844534776
INFO:root:current train perplexity6.112879753112793
INFO:root:current mean train loss 2296.6786765577385
INFO:root:current train perplexity6.114768981933594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.99s/it]
INFO:root:final mean train loss: 2295.7543701541226
INFO:root:final train perplexity: 6.113931179046631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 2142.6242879231772
INFO:root:eval perplexity: 5.656632423400879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 2582.360055044188
INFO:root:eval perplexity: 8.26413345336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:23:53<7:06:14, 412.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2312.805544704861
INFO:root:current train perplexity6.142880439758301
INFO:root:current mean train loss 2311.3996758822736
INFO:root:current train perplexity6.141756057739258
INFO:root:current mean train loss 2304.5237319634884
INFO:root:current train perplexity6.1360273361206055
INFO:root:current mean train loss 2304.218002363564
INFO:root:current train perplexity6.153618812561035
INFO:root:current mean train loss 2303.0944056135886
INFO:root:current train perplexity6.150596618652344
INFO:root:current mean train loss 2306.347032235522
INFO:root:current train perplexity6.165616035461426
INFO:root:current mean train loss 2310.245140844537
INFO:root:current train perplexity6.175107955932617
INFO:root:current mean train loss 2311.8923952653104
INFO:root:current train perplexity6.186583995819092
INFO:root:current mean train loss 2313.230172314164
INFO:root:current train perplexity6.195566654205322
INFO:root:current mean train loss 2313.609066917783
INFO:root:current train perplexity6.18676233291626
INFO:root:current mean train loss 2314.185480291193
INFO:root:current train perplexity6.190151214599609
INFO:root:current mean train loss 2317.163265045033
INFO:root:current train perplexity6.201595306396484
INFO:root:current mean train loss 2317.268540372427
INFO:root:current train perplexity6.19977331161499
INFO:root:current mean train loss 2315.684909023583
INFO:root:current train perplexity6.194648265838623
INFO:root:current mean train loss 2315.0443334031684
INFO:root:current train perplexity6.192411422729492
INFO:root:current mean train loss 2315.66110594913
INFO:root:current train perplexity6.199589252471924
INFO:root:current mean train loss 2315.8512487533244
INFO:root:current train perplexity6.20145320892334
INFO:root:current mean train loss 2314.678812581147
INFO:root:current train perplexity6.201094150543213
INFO:root:current mean train loss 2315.9284967024473
INFO:root:current train perplexity6.2059173583984375
INFO:root:current mean train loss 2315.2383645339614
INFO:root:current train perplexity6.206202030181885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.15s/it]
INFO:root:final mean train loss: 2314.966953848927
INFO:root:final train perplexity: 6.207276344299316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it]
INFO:root:eval mean loss: 2144.2850978120846
INFO:root:eval perplexity: 5.664235591888428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it]
INFO:root:eval mean loss: 2580.209014243268
INFO:root:eval perplexity: 8.24960708618164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:30:43<6:58:39, 411.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2318.913351735761
INFO:root:current train perplexity6.228993892669678
INFO:root:current mean train loss 2316.794499150029
INFO:root:current train perplexity6.22451639175415
INFO:root:current mean train loss 2311.5622260406726
INFO:root:current train perplexity6.225074291229248
INFO:root:current mean train loss 2316.8021931516532
INFO:root:current train perplexity6.2474446296691895
INFO:root:current mean train loss 2320.7636401684254
INFO:root:current train perplexity6.245059490203857
INFO:root:current mean train loss 2316.5457524744215
INFO:root:current train perplexity6.24122428894043
INFO:root:current mean train loss 2318.784620210123
INFO:root:current train perplexity6.246742248535156
INFO:root:current mean train loss 2321.0048610256727
INFO:root:current train perplexity6.247957706451416
INFO:root:current mean train loss 2322.1504332504805
INFO:root:current train perplexity6.243305683135986
INFO:root:current mean train loss 2321.2940063476562
INFO:root:current train perplexity6.241543769836426
INFO:root:current mean train loss 2320.4610777314324
INFO:root:current train perplexity6.23732328414917
INFO:root:current mean train loss 2320.3802304292503
INFO:root:current train perplexity6.243659496307373
INFO:root:current mean train loss 2318.6916813434777
INFO:root:current train perplexity6.244660377502441
INFO:root:current mean train loss 2320.8527671601105
INFO:root:current train perplexity6.250246047973633
INFO:root:current mean train loss 2323.5330992566905
INFO:root:current train perplexity6.257158279418945
INFO:root:current mean train loss 2326.0502288857433
INFO:root:current train perplexity6.260631084442139
INFO:root:current mean train loss 2325.1181750062283
INFO:root:current train perplexity6.256138801574707
INFO:root:current mean train loss 2326.0537047023536
INFO:root:current train perplexity6.257754325866699
INFO:root:current mean train loss 2326.29155359975
INFO:root:current train perplexity6.259749412536621
INFO:root:current mean train loss 2328.0160432245875
INFO:root:current train perplexity6.265312194824219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it]
INFO:root:final mean train loss: 2326.8552001091307
INFO:root:final train perplexity: 6.265748500823975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 2149.4313293889904
INFO:root:eval perplexity: 5.687858581542969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 2591.568427336131
INFO:root:eval perplexity: 8.326604843139648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:37:43<6:54:06, 414.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2308.3020328570014
INFO:root:current train perplexity6.205630779266357
INFO:root:current mean train loss 2328.4087350515015
INFO:root:current train perplexity6.279080390930176
INFO:root:current mean train loss 2323.2801465543794
INFO:root:current train perplexity6.253597736358643
INFO:root:current mean train loss 2334.8065774962897
INFO:root:current train perplexity6.282751560211182
INFO:root:current mean train loss 2337.281715345283
INFO:root:current train perplexity6.301366806030273
INFO:root:current mean train loss 2337.746170070299
INFO:root:current train perplexity6.304008960723877
INFO:root:current mean train loss 2346.808334148334
INFO:root:current train perplexity6.336131572723389
INFO:root:current mean train loss 2349.8345061903283
INFO:root:current train perplexity6.354104995727539
INFO:root:current mean train loss 2351.359329310429
INFO:root:current train perplexity6.364208698272705
INFO:root:current mean train loss 2352.1155374934165
INFO:root:current train perplexity6.365241050720215
INFO:root:current mean train loss 2352.2091435528773
INFO:root:current train perplexity6.368565082550049
INFO:root:current mean train loss 2351.6510518133086
INFO:root:current train perplexity6.368670463562012
INFO:root:current mean train loss 2350.5976864096706
INFO:root:current train perplexity6.3697829246521
INFO:root:current mean train loss 2350.3086515541436
INFO:root:current train perplexity6.371706962585449
INFO:root:current mean train loss 2350.945557796125
INFO:root:current train perplexity6.375582695007324
INFO:root:current mean train loss 2348.3709217383184
INFO:root:current train perplexity6.371919631958008
INFO:root:current mean train loss 2351.527972423015
INFO:root:current train perplexity6.382837772369385
INFO:root:current mean train loss 2353.01242331322
INFO:root:current train perplexity6.390729904174805
INFO:root:current mean train loss 2351.202674008989
INFO:root:current train perplexity6.387497425079346
INFO:root:current mean train loss 2352.173317761298
INFO:root:current train perplexity6.38916015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.90s/it]
INFO:root:final mean train loss: 2351.6818761474487
INFO:root:final train perplexity: 6.389638423919678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 2155.332704801086
INFO:root:eval perplexity: 5.715069770812988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 2595.333148929244
INFO:root:eval perplexity: 8.35228157043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:44:34<6:46:11, 413.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2364.5750732421875
INFO:root:current train perplexity6.4916911125183105
INFO:root:current mean train loss 2362.579050492267
INFO:root:current train perplexity6.461104393005371
INFO:root:current mean train loss 2353.838359523464
INFO:root:current train perplexity6.427035808563232
INFO:root:current mean train loss 2353.3935093735204
INFO:root:current train perplexity6.400409698486328
INFO:root:current mean train loss 2351.6903356736707
INFO:root:current train perplexity6.3929762840271
INFO:root:current mean train loss 2355.528024763069
INFO:root:current train perplexity6.396960258483887
INFO:root:current mean train loss 2353.597314768824
INFO:root:current train perplexity6.404854774475098
INFO:root:current mean train loss 2350.167963842651
INFO:root:current train perplexity6.383582592010498
INFO:root:current mean train loss 2348.989124434335
INFO:root:current train perplexity6.3801422119140625
INFO:root:current mean train loss 2351.046128606222
INFO:root:current train perplexity6.386430740356445
INFO:root:current mean train loss 2352.1107423879803
INFO:root:current train perplexity6.395025730133057
INFO:root:current mean train loss 2356.8158645885046
INFO:root:current train perplexity6.412609100341797
INFO:root:current mean train loss 2358.090754379461
INFO:root:current train perplexity6.424361228942871
INFO:root:current mean train loss 2358.0755888930707
INFO:root:current train perplexity6.421303749084473
INFO:root:current mean train loss 2358.1843082203586
INFO:root:current train perplexity6.412984371185303
INFO:root:current mean train loss 2359.7948600749924
INFO:root:current train perplexity6.428964614868164
INFO:root:current mean train loss 2361.9392554804963
INFO:root:current train perplexity6.436673641204834
INFO:root:current mean train loss 2362.195254319495
INFO:root:current train perplexity6.440709590911865
INFO:root:current mean train loss 2361.951987415426
INFO:root:current train perplexity6.441145896911621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.27s/it]
INFO:root:final mean train loss: 2361.53025263076
INFO:root:final train perplexity: 6.4394612312316895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2168.33961779006
INFO:root:eval perplexity: 5.775505065917969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it]
INFO:root:eval mean loss: 2605.6473665710882
INFO:root:eval perplexity: 8.423032760620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:51:19<6:37:07, 410.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2353.469914362981
INFO:root:current train perplexity6.469090461730957
INFO:root:current mean train loss 2370.067563217298
INFO:root:current train perplexity6.497288227081299
INFO:root:current mean train loss 2374.91972759408
INFO:root:current train perplexity6.488216876983643
INFO:root:current mean train loss 2365.6971217146315
INFO:root:current train perplexity6.455578327178955
INFO:root:current mean train loss 2365.6273870214136
INFO:root:current train perplexity6.455562591552734
INFO:root:current mean train loss 2368.6591285274276
INFO:root:current train perplexity6.460484981536865
INFO:root:current mean train loss 2369.033949088117
INFO:root:current train perplexity6.464622974395752
INFO:root:current mean train loss 2369.993912235383
INFO:root:current train perplexity6.470628261566162
INFO:root:current mean train loss 2372.060395375682
INFO:root:current train perplexity6.495405197143555
INFO:root:current mean train loss 2373.4182616920093
INFO:root:current train perplexity6.505363464355469
INFO:root:current mean train loss 2375.4629413570847
INFO:root:current train perplexity6.516006946563721
INFO:root:current mean train loss 2377.27795903702
INFO:root:current train perplexity6.516561508178711
INFO:root:current mean train loss 2377.851139933436
INFO:root:current train perplexity6.515641689300537
INFO:root:current mean train loss 2379.475954658642
INFO:root:current train perplexity6.522599697113037
INFO:root:current mean train loss 2378.9700173541996
INFO:root:current train perplexity6.516401290893555
INFO:root:current mean train loss 2378.7139230187336
INFO:root:current train perplexity6.521937847137451
INFO:root:current mean train loss 2378.8637838345912
INFO:root:current train perplexity6.519954204559326
INFO:root:current mean train loss 2378.5217532432366
INFO:root:current train perplexity6.521463394165039
INFO:root:current mean train loss 2378.357917562612
INFO:root:current train perplexity6.519451141357422
INFO:root:current mean train loss 2377.1806653387184
INFO:root:current train perplexity6.511648178100586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.86s/it]
INFO:root:final mean train loss: 2374.4417282620043
INFO:root:final train perplexity: 6.505367755889893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.35s/it]
INFO:root:eval mean loss: 2174.9893980634974
INFO:root:eval perplexity: 5.806649684906006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it]
INFO:root:eval mean loss: 2614.931689106826
INFO:root:eval perplexity: 8.487232208251953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:58:12<6:30:55, 411.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2394.628759765625
INFO:root:current train perplexity6.440188884735107
INFO:root:current mean train loss 2382.9464515099157
INFO:root:current train perplexity6.543294429779053
INFO:root:current mean train loss 2359.6987145465355
INFO:root:current train perplexity6.483340263366699
INFO:root:current mean train loss 2361.7713230942236
INFO:root:current train perplexity6.477171897888184
INFO:root:current mean train loss 2358.349264455396
INFO:root:current train perplexity6.453192710876465
INFO:root:current mean train loss 2360.349840156987
INFO:root:current train perplexity6.459108829498291
INFO:root:current mean train loss 2361.3696943979417
INFO:root:current train perplexity6.446027755737305
INFO:root:current mean train loss 2360.3378459773653
INFO:root:current train perplexity6.441564083099365
INFO:root:current mean train loss 2364.052788056523
INFO:root:current train perplexity6.4481706619262695
INFO:root:current mean train loss 2362.905824591524
INFO:root:current train perplexity6.44351863861084
INFO:root:current mean train loss 2364.1656847314925
INFO:root:current train perplexity6.444134712219238
INFO:root:current mean train loss 2365.6290821176713
INFO:root:current train perplexity6.451136112213135
INFO:root:current mean train loss 2367.711750905107
INFO:root:current train perplexity6.4575114250183105
INFO:root:current mean train loss 2367.6906105901962
INFO:root:current train perplexity6.461112022399902
INFO:root:current mean train loss 2367.012492573345
INFO:root:current train perplexity6.4616475105285645
INFO:root:current mean train loss 2365.5439677319496
INFO:root:current train perplexity6.458834171295166
INFO:root:current mean train loss 2364.976652217935
INFO:root:current train perplexity6.458581447601318
INFO:root:current mean train loss 2365.8412161590045
INFO:root:current train perplexity6.46378231048584
INFO:root:current mean train loss 2367.3119602224215
INFO:root:current train perplexity6.468240737915039
INFO:root:current mean train loss 2366.6801571228343
INFO:root:current train perplexity6.465616226196289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.88s/it]
INFO:root:final mean train loss: 2367.067974265633
INFO:root:final train perplexity: 6.467645168304443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it]
INFO:root:eval mean loss: 2184.520293540143
INFO:root:eval perplexity: 5.851580619812012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 2622.4651385368184
INFO:root:eval perplexity: 8.539685249328613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [5:05:04<6:24:04, 411.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2357.6733943858044
INFO:root:current train perplexity6.535961627960205
INFO:root:current mean train loss 2384.604264655081
INFO:root:current train perplexity6.55686092376709
INFO:root:current mean train loss 2373.145111454643
INFO:root:current train perplexity6.497491836547852
INFO:root:current mean train loss 2376.2381225937725
INFO:root:current train perplexity6.485856533050537
INFO:root:current mean train loss 2371.22559522249
INFO:root:current train perplexity6.472552299499512
INFO:root:current mean train loss 2371.5574614195325
INFO:root:current train perplexity6.474844455718994
INFO:root:current mean train loss 2367.210209040222
INFO:root:current train perplexity6.4549126625061035
INFO:root:current mean train loss 2371.712733910904
INFO:root:current train perplexity6.485439300537109
INFO:root:current mean train loss 2367.532425305075
INFO:root:current train perplexity6.477611541748047
INFO:root:current mean train loss 2367.370001046685
INFO:root:current train perplexity6.467906951904297
INFO:root:current mean train loss 2368.2746004907995
INFO:root:current train perplexity6.473631858825684
INFO:root:current mean train loss 2366.5524801239308
INFO:root:current train perplexity6.468140125274658
INFO:root:current mean train loss 2366.695474901482
INFO:root:current train perplexity6.466774940490723
INFO:root:current mean train loss 2365.5387672475294
INFO:root:current train perplexity6.4614033699035645
INFO:root:current mean train loss 2364.757219526796
INFO:root:current train perplexity6.456725597381592
INFO:root:current mean train loss 2365.0019506788594
INFO:root:current train perplexity6.456653118133545
INFO:root:current mean train loss 2366.134619466739
INFO:root:current train perplexity6.460572242736816
INFO:root:current mean train loss 2367.8624824475887
INFO:root:current train perplexity6.468648433685303
INFO:root:current mean train loss 2367.6635162568314
INFO:root:current train perplexity6.466789722442627
INFO:root:current mean train loss 2368.0436715163755
INFO:root:current train perplexity6.4684648513793945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.50s/it]
INFO:root:final mean train loss: 2366.8240361062194
INFO:root:final train perplexity: 6.466402530670166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it]
INFO:root:eval mean loss: 2183.5730400355997
INFO:root:eval perplexity: 5.847098350524902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it]
INFO:root:eval mean loss: 2622.3942927367298
INFO:root:eval perplexity: 8.539190292358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [5:11:52<6:16:19, 410.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2330.177759170532
INFO:root:current train perplexity6.406225681304932
INFO:root:current mean train loss 2369.461113906488
INFO:root:current train perplexity6.482405185699463
INFO:root:current mean train loss 2377.542934995709
INFO:root:current train perplexity6.506171703338623
INFO:root:current mean train loss 2373.876196892707
INFO:root:current train perplexity6.490995407104492
INFO:root:current mean train loss 2370.464700633082
INFO:root:current train perplexity6.483668327331543
INFO:root:current mean train loss 2366.6527844151706
INFO:root:current train perplexity6.4743828773498535
INFO:root:current mean train loss 2362.1982453127944
INFO:root:current train perplexity6.464632987976074
INFO:root:current mean train loss 2358.429699483342
INFO:root:current train perplexity6.450621128082275
INFO:root:current mean train loss 2355.6920401961715
INFO:root:current train perplexity6.439850330352783
INFO:root:current mean train loss 2358.1513825096035
INFO:root:current train perplexity6.435083866119385
INFO:root:current mean train loss 2358.067175843662
INFO:root:current train perplexity6.435040473937988
INFO:root:current mean train loss 2359.2853664122904
INFO:root:current train perplexity6.4391350746154785
INFO:root:current mean train loss 2360.289095045645
INFO:root:current train perplexity6.4429450035095215
INFO:root:current mean train loss 2360.258701716001
INFO:root:current train perplexity6.441564083099365
INFO:root:current mean train loss 2360.2249637457844
INFO:root:current train perplexity6.441069602966309
INFO:root:current mean train loss 2358.9834937366377
INFO:root:current train perplexity6.434092998504639
INFO:root:current mean train loss 2359.396445274353
INFO:root:current train perplexity6.431994915008545
INFO:root:current mean train loss 2360.698713445339
INFO:root:current train perplexity6.434381484985352
INFO:root:current mean train loss 2361.837775496454
INFO:root:current train perplexity6.4366559982299805
INFO:root:current mean train loss 2363.0167082807925
INFO:root:current train perplexity6.443401336669922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it]
INFO:root:final mean train loss: 2362.5124039258008
INFO:root:final train perplexity: 6.444450378417969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 2174.7461915793992
INFO:root:eval perplexity: 5.805507659912109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 2611.096845478031
INFO:root:eval perplexity: 8.46065616607666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [5:18:43<6:09:36, 410.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2352.294389889564
INFO:root:current train perplexity6.442996978759766
INFO:root:current mean train loss 2373.408147148006
INFO:root:current train perplexity6.470946788787842
INFO:root:current mean train loss 2366.2555422528358
INFO:root:current train perplexity6.4593915939331055
INFO:root:current mean train loss 2369.030975101501
INFO:root:current train perplexity6.4866180419921875
INFO:root:current mean train loss 2365.8852853755197
INFO:root:current train perplexity6.459049701690674
INFO:root:current mean train loss 2367.4364503213747
INFO:root:current train perplexity6.4783172607421875
INFO:root:current mean train loss 2361.2396064567847
INFO:root:current train perplexity6.45745325088501
INFO:root:current mean train loss 2363.4436369638283
INFO:root:current train perplexity6.450449466705322
INFO:root:current mean train loss 2360.983587431718
INFO:root:current train perplexity6.44557523727417
INFO:root:current mean train loss 2361.498064171405
INFO:root:current train perplexity6.443395137786865
INFO:root:current mean train loss 2364.0764445852724
INFO:root:current train perplexity6.455188751220703
INFO:root:current mean train loss 2363.5049628145507
INFO:root:current train perplexity6.459367752075195
INFO:root:current mean train loss 2362.8689178300033
INFO:root:current train perplexity6.456150054931641
INFO:root:current mean train loss 2364.5065385844723
INFO:root:current train perplexity6.4588727951049805
INFO:root:current mean train loss 2363.39093384366
INFO:root:current train perplexity6.452322006225586
INFO:root:current mean train loss 2363.9306078530203
INFO:root:current train perplexity6.449123859405518
INFO:root:current mean train loss 2363.5065948468173
INFO:root:current train perplexity6.4482197761535645
INFO:root:current mean train loss 2363.372661130071
INFO:root:current train perplexity6.446991443634033
INFO:root:current mean train loss 2363.156454229279
INFO:root:current train perplexity6.445134162902832
INFO:root:current mean train loss 2363.6685375076904
INFO:root:current train perplexity6.447272777557373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.38s/it]
INFO:root:final mean train loss: 2363.0584591833317
INFO:root:final train perplexity: 6.4472270011901855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 2181.7343221894394
INFO:root:eval perplexity: 5.838410377502441
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it]
INFO:root:eval mean loss: 2617.417631974457
INFO:root:eval perplexity: 8.504504203796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [5:25:31<6:02:02, 409.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2356.138710489078
INFO:root:current train perplexity6.289989948272705
INFO:root:current mean train loss 2357.346137152778
INFO:root:current train perplexity6.37546968460083
INFO:root:current mean train loss 2342.2979326696204
INFO:root:current train perplexity6.360439300537109
INFO:root:current mean train loss 2354.4021606445312
INFO:root:current train perplexity6.380506992340088
INFO:root:current mean train loss 2357.2126393758626
INFO:root:current train perplexity6.3997626304626465
INFO:root:current mean train loss 2354.422961180824
INFO:root:current train perplexity6.39371395111084
INFO:root:current mean train loss 2351.7642631640065
INFO:root:current train perplexity6.38956356048584
INFO:root:current mean train loss 2352.954202522909
INFO:root:current train perplexity6.397093772888184
INFO:root:current mean train loss 2352.950817218602
INFO:root:current train perplexity6.396308898925781
INFO:root:current mean train loss 2351.313413081045
INFO:root:current train perplexity6.3963236808776855
INFO:root:current mean train loss 2356.4051640411544
INFO:root:current train perplexity6.413525581359863
INFO:root:current mean train loss 2355.6366810488184
INFO:root:current train perplexity6.408158779144287
INFO:root:current mean train loss 2355.7959841124266
INFO:root:current train perplexity6.406993865966797
INFO:root:current mean train loss 2356.676998111141
INFO:root:current train perplexity6.408689022064209
INFO:root:current mean train loss 2356.537782391496
INFO:root:current train perplexity6.409358978271484
INFO:root:current mean train loss 2356.8700110061895
INFO:root:current train perplexity6.4088897705078125
INFO:root:current mean train loss 2356.0085189693527
INFO:root:current train perplexity6.4032111167907715
INFO:root:current mean train loss 2354.6348405780727
INFO:root:current train perplexity6.397709369659424
INFO:root:current mean train loss 2353.965169828232
INFO:root:current train perplexity6.39547872543335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.36s/it]
INFO:root:final mean train loss: 2352.946752905064
INFO:root:final train perplexity: 6.3960161209106445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 2168.202943626025
INFO:root:eval perplexity: 5.774867057800293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 2604.4185388443316
INFO:root:eval perplexity: 8.414572715759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:32:28<5:57:10, 412.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2315.789095052083
INFO:root:current train perplexity6.301890850067139
INFO:root:current mean train loss 2383.537992527174
INFO:root:current train perplexity6.441322326660156
INFO:root:current mean train loss 2364.4734624818316
INFO:root:current train perplexity6.4047698974609375
INFO:root:current mean train loss 2352.298189096602
INFO:root:current train perplexity6.378897666931152
INFO:root:current mean train loss 2347.122824795275
INFO:root:current train perplexity6.373430252075195
INFO:root:current mean train loss 2341.2715125815384
INFO:root:current train perplexity6.359320640563965
INFO:root:current mean train loss 2335.1776770118777
INFO:root:current train perplexity6.339033603668213
INFO:root:current mean train loss 2342.551603133195
INFO:root:current train perplexity6.3588385581970215
INFO:root:current mean train loss 2339.8066487130945
INFO:root:current train perplexity6.342390060424805
INFO:root:current mean train loss 2342.027316934554
INFO:root:current train perplexity6.343884468078613
INFO:root:current mean train loss 2341.847978683998
INFO:root:current train perplexity6.341848850250244
INFO:root:current mean train loss 2340.7639676902327
INFO:root:current train perplexity6.339502811431885
INFO:root:current mean train loss 2343.6186663089957
INFO:root:current train perplexity6.3474955558776855
INFO:root:current mean train loss 2341.878617829878
INFO:root:current train perplexity6.345010757446289
INFO:root:current mean train loss 2345.916363719495
INFO:root:current train perplexity6.359348297119141
INFO:root:current mean train loss 2345.9113483491906
INFO:root:current train perplexity6.357034683227539
INFO:root:current mean train loss 2347.661515349869
INFO:root:current train perplexity6.362996578216553
INFO:root:current mean train loss 2345.276766353863
INFO:root:current train perplexity6.35690975189209
INFO:root:current mean train loss 2345.0612283838027
INFO:root:current train perplexity6.354572296142578
INFO:root:current mean train loss 2346.0549406285695
INFO:root:current train perplexity6.3575873374938965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.49s/it]
INFO:root:final mean train loss: 2345.1895004018534
INFO:root:final train perplexity: 6.357007026672363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 2165.470127403313
INFO:root:eval perplexity: 5.762118816375732
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it]
INFO:root:eval mean loss: 2603.309040475399
INFO:root:eval perplexity: 8.406942367553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:39:32<5:53:21, 415.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2381.054676055908
INFO:root:current train perplexity6.389620304107666
INFO:root:current mean train loss 2332.5524153275924
INFO:root:current train perplexity6.253321170806885
INFO:root:current mean train loss 2344.366732893319
INFO:root:current train perplexity6.292899131774902
INFO:root:current mean train loss 2346.6584071883235
INFO:root:current train perplexity6.334142208099365
INFO:root:current mean train loss 2346.8451863041632
INFO:root:current train perplexity6.367969036102295
INFO:root:current mean train loss 2349.6282880969516
INFO:root:current train perplexity6.367192268371582
INFO:root:current mean train loss 2346.250194114975
INFO:root:current train perplexity6.350114345550537
INFO:root:current mean train loss 2349.161182674554
INFO:root:current train perplexity6.35422945022583
INFO:root:current mean train loss 2360.836912742028
INFO:root:current train perplexity6.39877986907959
INFO:root:current mean train loss 2358.2448122736723
INFO:root:current train perplexity6.395004749298096
INFO:root:current mean train loss 2358.5400526652966
INFO:root:current train perplexity6.392734527587891
INFO:root:current mean train loss 2353.642726615124
INFO:root:current train perplexity6.385018825531006
INFO:root:current mean train loss 2351.9829377013366
INFO:root:current train perplexity6.378322124481201
INFO:root:current mean train loss 2350.11768980284
INFO:root:current train perplexity6.369462966918945
INFO:root:current mean train loss 2349.2441232350952
INFO:root:current train perplexity6.363600730895996
INFO:root:current mean train loss 2346.156791587411
INFO:root:current train perplexity6.352799892425537
INFO:root:current mean train loss 2344.2616960114124
INFO:root:current train perplexity6.346676349639893
INFO:root:current mean train loss 2343.018426626439
INFO:root:current train perplexity6.340895652770996
INFO:root:current mean train loss 2344.4532652609214
INFO:root:current train perplexity6.347668170928955
INFO:root:current mean train loss 2343.150923829641
INFO:root:current train perplexity6.3440070152282715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.76s/it]
INFO:root:final mean train loss: 2342.310902005425
INFO:root:final train perplexity: 6.342590808868408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 2169.622345620013
INFO:root:eval perplexity: 5.781499862670898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 2605.3942247755986
INFO:root:eval perplexity: 8.421290397644043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:46:18<5:43:53, 412.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2324.3874013472578
INFO:root:current train perplexity6.284107208251953
INFO:root:current mean train loss 2327.192750661965
INFO:root:current train perplexity6.253081798553467
INFO:root:current mean train loss 2328.6671907355985
INFO:root:current train perplexity6.271657943725586
INFO:root:current mean train loss 2325.6255627826154
INFO:root:current train perplexity6.2731614112854
INFO:root:current mean train loss 2325.20054222056
INFO:root:current train perplexity6.260904788970947
INFO:root:current mean train loss 2326.498237873904
INFO:root:current train perplexity6.263940334320068
INFO:root:current mean train loss 2324.5347464022175
INFO:root:current train perplexity6.253478527069092
INFO:root:current mean train loss 2322.3204151759637
INFO:root:current train perplexity6.245702743530273
INFO:root:current mean train loss 2324.231135463827
INFO:root:current train perplexity6.25323486328125
INFO:root:current mean train loss 2323.7760803415604
INFO:root:current train perplexity6.247056007385254
INFO:root:current mean train loss 2325.230420457169
INFO:root:current train perplexity6.2515459060668945
INFO:root:current mean train loss 2326.0262590346906
INFO:root:current train perplexity6.256684303283691
INFO:root:current mean train loss 2326.0978064678307
INFO:root:current train perplexity6.2570390701293945
INFO:root:current mean train loss 2326.1583169607698
INFO:root:current train perplexity6.261713981628418
INFO:root:current mean train loss 2328.0244416947035
INFO:root:current train perplexity6.2663140296936035
INFO:root:current mean train loss 2328.4319363046725
INFO:root:current train perplexity6.270821571350098
INFO:root:current mean train loss 2329.5929246003734
INFO:root:current train perplexity6.274935722351074
INFO:root:current mean train loss 2329.2960372584557
INFO:root:current train perplexity6.274081230163574
INFO:root:current mean train loss 2329.4704185143364
INFO:root:current train perplexity6.27702522277832
INFO:root:current mean train loss 2329.068121059177
INFO:root:current train perplexity6.273033142089844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.38s/it]
INFO:root:final mean train loss: 2329.502014129377
INFO:root:final train perplexity: 6.278840065002441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2221.942043439716
INFO:root:eval perplexity: 6.031382083892822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 2664.8277315180353
INFO:root:eval perplexity: 8.840729713439941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:53:00<5:34:17, 409.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2343.162079782197
INFO:root:current train perplexity6.331506252288818
INFO:root:current mean train loss 2344.1853255306382
INFO:root:current train perplexity6.302366733551025
INFO:root:current mean train loss 2339.71910290252
INFO:root:current train perplexity6.306658744812012
INFO:root:current mean train loss 2344.6046326017117
INFO:root:current train perplexity6.326030254364014
INFO:root:current mean train loss 2337.920850500017
INFO:root:current train perplexity6.309123516082764
INFO:root:current mean train loss 2335.2667896284233
INFO:root:current train perplexity6.295559883117676
INFO:root:current mean train loss 2334.8011177681587
INFO:root:current train perplexity6.289766311645508
INFO:root:current mean train loss 2334.5899846248776
INFO:root:current train perplexity6.286862373352051
INFO:root:current mean train loss 2332.791957934514
INFO:root:current train perplexity6.28114652633667
INFO:root:current mean train loss 2331.9457964847793
INFO:root:current train perplexity6.276491641998291
INFO:root:current mean train loss 2330.724916841031
INFO:root:current train perplexity6.274714946746826
INFO:root:current mean train loss 2332.020766714629
INFO:root:current train perplexity6.277348518371582
INFO:root:current mean train loss 2331.6302583763763
INFO:root:current train perplexity6.271581649780273
INFO:root:current mean train loss 2330.6945210983254
INFO:root:current train perplexity6.273561000823975
INFO:root:current mean train loss 2330.6813967341777
INFO:root:current train perplexity6.272408485412598
INFO:root:current mean train loss 2330.210475565982
INFO:root:current train perplexity6.267364978790283
INFO:root:current mean train loss 2331.4687787224266
INFO:root:current train perplexity6.273896217346191
INFO:root:current mean train loss 2329.7423725408985
INFO:root:current train perplexity6.269500732421875
INFO:root:current mean train loss 2328.4376473217276
INFO:root:current train perplexity6.266939640045166
INFO:root:current mean train loss 2328.452047229662
INFO:root:current train perplexity6.27026891708374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.34s/it]
INFO:root:final mean train loss: 2327.930341988937
INFO:root:final train perplexity: 6.2710652351379395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 2161.916883969138
INFO:root:eval perplexity: 5.745584487915039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it]
INFO:root:eval mean loss: 2598.555216471354
INFO:root:eval perplexity: 8.374319076538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:59:44<5:26:13, 407.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2329.1567706372366
INFO:root:current train perplexity6.257015228271484
INFO:root:current mean train loss 2343.8160940701846
INFO:root:current train perplexity6.310026168823242
INFO:root:current mean train loss 2355.090876818546
INFO:root:current train perplexity6.362801551818848
INFO:root:current mean train loss 2418.867418573046
INFO:root:current train perplexity6.700981140136719
INFO:root:current mean train loss 2442.134803282301
INFO:root:current train perplexity6.834470272064209
INFO:root:current mean train loss 2428.9648504502575
INFO:root:current train perplexity6.775933742523193
INFO:root:current mean train loss 2422.9362969908148
INFO:root:current train perplexity6.736274719238281
INFO:root:current mean train loss 2412.314045912157
INFO:root:current train perplexity6.68223237991333
INFO:root:current mean train loss 2403.5568513103412
INFO:root:current train perplexity6.6354241371154785
INFO:root:current mean train loss 2397.331328383297
INFO:root:current train perplexity6.596164226531982
INFO:root:current mean train loss 2390.4671465168367
INFO:root:current train perplexity6.562021732330322
INFO:root:current mean train loss 2388.1465805453563
INFO:root:current train perplexity6.549474716186523
INFO:root:current mean train loss 2380.823864622406
INFO:root:current train perplexity6.5218281745910645
INFO:root:current mean train loss 2379.3863549222137
INFO:root:current train perplexity6.515453815460205
INFO:root:current mean train loss 2375.915220068985
INFO:root:current train perplexity6.501112937927246
INFO:root:current mean train loss 2372.999639572558
INFO:root:current train perplexity6.491688251495361
INFO:root:current mean train loss 2370.6830464282066
INFO:root:current train perplexity6.482794761657715
INFO:root:current mean train loss 2369.507841186181
INFO:root:current train perplexity6.476202964782715
INFO:root:current mean train loss 2367.409921898338
INFO:root:current train perplexity6.4624810218811035
INFO:root:current mean train loss 2364.9388750300404
INFO:root:current train perplexity6.456795692443848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.20s/it]
INFO:root:final mean train loss: 2364.9388750300404
INFO:root:final train perplexity: 6.456795692443848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 2180.3303841665283
INFO:root:eval perplexity: 5.831784725189209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 2613.0814745747452
INFO:root:eval perplexity: 8.474400520324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [6:06:36<5:20:22, 409.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2363.7029382324217
INFO:root:current train perplexity6.351518154144287
INFO:root:current mean train loss 2359.140992431641
INFO:root:current train perplexity6.401027679443359
INFO:root:current mean train loss 2353.2815104166666
INFO:root:current train perplexity6.411344051361084
INFO:root:current mean train loss 2364.4840084838866
INFO:root:current train perplexity6.430020809173584
INFO:root:current mean train loss 2362.4622583007813
INFO:root:current train perplexity6.432827472686768
INFO:root:current mean train loss 2366.8277162679037
INFO:root:current train perplexity6.457991123199463
INFO:root:current mean train loss 2367.456253138951
INFO:root:current train perplexity6.4597249031066895
INFO:root:current mean train loss 2366.8794291687013
INFO:root:current train perplexity6.458752632141113
INFO:root:current mean train loss 2364.9997858344186
INFO:root:current train perplexity6.459140777587891
INFO:root:current mean train loss 2373.4994931640626
INFO:root:current train perplexity6.496231555938721
INFO:root:current mean train loss 2377.6196330122516
INFO:root:current train perplexity6.515120506286621
INFO:root:current mean train loss 2378.6327789306642
INFO:root:current train perplexity6.526413917541504
INFO:root:current mean train loss 2380.8310049203724
INFO:root:current train perplexity6.544600009918213
INFO:root:current mean train loss 2387.6805313546315
INFO:root:current train perplexity6.572234153747559
INFO:root:current mean train loss 2391.872690673828
INFO:root:current train perplexity6.599878311157227
INFO:root:current mean train loss 2400.8981462860106
INFO:root:current train perplexity6.654032230377197
INFO:root:current mean train loss 2410.3205266974956
INFO:root:current train perplexity6.699042320251465
INFO:root:current mean train loss 2417.9061080593533
INFO:root:current train perplexity6.7344841957092285
INFO:root:current mean train loss 2423.066815314042
INFO:root:current train perplexity6.759922027587891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.61s/it]
INFO:root:final mean train loss: 2425.0030441245704
INFO:root:final train perplexity: 6.770014762878418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 2255.1325900030474
INFO:root:eval perplexity: 6.1954731941223145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 2677.1913417518563
INFO:root:eval perplexity: 8.930572509765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [6:13:21<5:12:48, 408.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2504.7168255974266
INFO:root:current train perplexity7.09202241897583
INFO:root:current mean train loss 2472.617442073985
INFO:root:current train perplexity6.9545674324035645
INFO:root:current mean train loss 2455.6953091247838
INFO:root:current train perplexity6.895085334777832
INFO:root:current mean train loss 2449.587798205836
INFO:root:current train perplexity6.875052452087402
INFO:root:current mean train loss 2449.190247021133
INFO:root:current train perplexity6.878906726837158
INFO:root:current mean train loss 2451.2729317464036
INFO:root:current train perplexity6.883526802062988
INFO:root:current mean train loss 2451.7195483042315
INFO:root:current train perplexity6.889749050140381
INFO:root:current mean train loss 2450.892367183414
INFO:root:current train perplexity6.902663230895996
INFO:root:current mean train loss 2450.4817093250363
INFO:root:current train perplexity6.911259174346924
INFO:root:current mean train loss 2451.513704489206
INFO:root:current train perplexity6.911022663116455
INFO:root:current mean train loss 2450.1864016072473
INFO:root:current train perplexity6.896630764007568
INFO:root:current mean train loss 2449.4960570305507
INFO:root:current train perplexity6.894398212432861
INFO:root:current mean train loss 2444.373847905005
INFO:root:current train perplexity6.870050430297852
INFO:root:current mean train loss 2440.2022148022256
INFO:root:current train perplexity6.848756790161133
INFO:root:current mean train loss 2437.318730151729
INFO:root:current train perplexity6.835354328155518
INFO:root:current mean train loss 2436.8905786502964
INFO:root:current train perplexity6.833677291870117
INFO:root:current mean train loss 2437.739547550199
INFO:root:current train perplexity6.832370281219482
INFO:root:current mean train loss 2438.0399381074367
INFO:root:current train perplexity6.834543704986572
INFO:root:current mean train loss 2437.907236438304
INFO:root:current train perplexity6.830795764923096
INFO:root:current mean train loss 2435.972398291296
INFO:root:current train perplexity6.824153900146484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.37s/it]
INFO:root:final mean train loss: 2434.286892166176
INFO:root:final train perplexity: 6.819764614105225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 2207.862747517038
INFO:root:eval perplexity: 5.963095188140869
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 2636.870121949108
INFO:root:eval perplexity: 8.640883445739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [6:20:17<5:07:39, 410.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2472.4601548138785
INFO:root:current train perplexity6.777318954467773
INFO:root:current mean train loss 2453.7494597933187
INFO:root:current train perplexity6.794244289398193
INFO:root:current mean train loss 2440.9757946047007
INFO:root:current train perplexity6.8014235496521
INFO:root:current mean train loss 2440.9700920424775
INFO:root:current train perplexity6.781929969787598
INFO:root:current mean train loss 2446.8062873523904
INFO:root:current train perplexity6.808295726776123
INFO:root:current mean train loss 2442.01947684413
INFO:root:current train perplexity6.805562973022461
INFO:root:current mean train loss 2437.807445441887
INFO:root:current train perplexity6.7948737144470215
INFO:root:current mean train loss 2434.903935320696
INFO:root:current train perplexity6.7862420082092285
INFO:root:current mean train loss 2437.8048375264634
INFO:root:current train perplexity6.797277450561523
INFO:root:current mean train loss 2438.272180724706
INFO:root:current train perplexity6.8026347160339355
INFO:root:current mean train loss 2438.838807332908
INFO:root:current train perplexity6.81196928024292
INFO:root:current mean train loss 2436.8753434976784
INFO:root:current train perplexity6.8026323318481445
INFO:root:current mean train loss 2438.8908805167075
INFO:root:current train perplexity6.816529750823975
INFO:root:current mean train loss 2440.1449539207447
INFO:root:current train perplexity6.829863548278809
INFO:root:current mean train loss 2438.565358692632
INFO:root:current train perplexity6.827648639678955
INFO:root:current mean train loss 2437.596876957581
INFO:root:current train perplexity6.828385829925537
INFO:root:current mean train loss 2436.789025595022
INFO:root:current train perplexity6.829108715057373
INFO:root:current mean train loss 2441.937191656304
INFO:root:current train perplexity6.851600170135498
INFO:root:current mean train loss 2442.0362639349187
INFO:root:current train perplexity6.857720375061035
INFO:root:current mean train loss 2440.9253890344253
INFO:root:current train perplexity6.850998878479004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.36s/it]
INFO:root:final mean train loss: 2440.989863670299
INFO:root:final train perplexity: 6.855913162231445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 2236.029448380707
INFO:root:eval perplexity: 6.100490570068359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2665.7516332315213
INFO:root:eval perplexity: 8.847412109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [6:26:57<4:58:40, 407.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2440.991641773897
INFO:root:current train perplexity6.813259124755859
INFO:root:current mean train loss 2432.940019013866
INFO:root:current train perplexity6.789798259735107
INFO:root:current mean train loss 2429.121986662724
INFO:root:current train perplexity6.767817497253418
INFO:root:current mean train loss 2427.2087395388176
INFO:root:current train perplexity6.78462028503418
INFO:root:current mean train loss 2446.473585445971
INFO:root:current train perplexity6.908586025238037
INFO:root:current mean train loss 2470.8995768967643
INFO:root:current train perplexity7.038488864898682
INFO:root:current mean train loss 2519.866192373812
INFO:root:current train perplexity7.310331344604492
INFO:root:current mean train loss 2544.097480865357
INFO:root:current train perplexity7.462020397186279
INFO:root:current mean train loss 2578.145670620731
INFO:root:current train perplexity7.664095401763916
INFO:root:current mean train loss 2595.2071399708775
INFO:root:current train perplexity7.763919830322266
INFO:root:current mean train loss 2604.011543019855
INFO:root:current train perplexity7.815604209899902
INFO:root:current mean train loss 2599.851540334322
INFO:root:current train perplexity7.7954277992248535
INFO:root:current mean train loss 2598.401813802864
INFO:root:current train perplexity7.783456325531006
INFO:root:current mean train loss 2595.0294484012134
INFO:root:current train perplexity7.756145477294922
INFO:root:current mean train loss 2594.9443050623763
INFO:root:current train perplexity7.757401466369629
INFO:root:current mean train loss 2599.493063871973
INFO:root:current train perplexity7.777792930603027
INFO:root:current mean train loss 2605.2156169112704
INFO:root:current train perplexity7.810869216918945
INFO:root:current mean train loss 2611.389351662331
INFO:root:current train perplexity7.850334644317627
INFO:root:current mean train loss 2612.1159834817963
INFO:root:current train perplexity7.8542585372924805
INFO:root:current mean train loss 2615.5056911294487
INFO:root:current train perplexity7.865307331085205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.25s/it]
INFO:root:final mean train loss: 2618.6335062631983
INFO:root:final train perplexity: 7.886970043182373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 2276.0935205770725
INFO:root:eval perplexity: 6.301393985748291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2703.4331050358765
INFO:root:eval perplexity: 9.124305725097656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [6:33:39<4:50:42, 405.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2845.0279792336855
INFO:root:current train perplexity9.444246292114258
INFO:root:current mean train loss 3541.852736700149
INFO:root:current train perplexity16.454004287719727
INFO:root:current mean train loss 3798.4185791015625
INFO:root:current train perplexity20.069812774658203
INFO:root:current mean train loss 3587.121426789657
INFO:root:current train perplexity16.94438934326172
INFO:root:current mean train loss 3409.5113441923745
INFO:root:current train perplexity14.73594856262207
INFO:root:current mean train loss 3283.215801830023
INFO:root:current train perplexity13.320655822753906
INFO:root:current mean train loss 3193.0934013321016
INFO:root:current train perplexity12.399508476257324
INFO:root:current mean train loss 3130.9812726974487
INFO:root:current train perplexity11.780306816101074
INFO:root:current mean train loss 3078.287307106405
INFO:root:current train perplexity11.332914352416992
INFO:root:current mean train loss 3035.809876497127
INFO:root:current train perplexity10.955057144165039
INFO:root:current mean train loss 3002.159559842799
INFO:root:current train perplexity10.653816223144531
INFO:root:current mean train loss 2973.168781437286
INFO:root:current train perplexity10.409134864807129
INFO:root:current mean train loss 2945.5906603118224
INFO:root:current train perplexity10.195074081420898
INFO:root:current mean train loss 2921.163998252467
INFO:root:current train perplexity10.003250122070312
INFO:root:current mean train loss 2900.0601334324974
INFO:root:current train perplexity9.83172607421875
INFO:root:current mean train loss 2882.379139180086
INFO:root:current train perplexity9.697434425354004
INFO:root:current mean train loss 2864.8696965279337
INFO:root:current train perplexity9.5664701461792
INFO:root:current mean train loss 2851.3732686452736
INFO:root:current train perplexity9.464271545410156
INFO:root:current mean train loss 2837.478086810551
INFO:root:current train perplexity9.365950584411621
INFO:root:current mean train loss 2825.297495896254
INFO:root:current train perplexity9.279500961303711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.50s/it]
INFO:root:final mean train loss: 2822.739354089842
INFO:root:final train perplexity: 9.264427185058594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 2292.0086592004654
INFO:root:eval perplexity: 6.383025646209717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it]
INFO:root:eval mean loss: 2714.0465183122783
INFO:root:eval perplexity: 9.203849792480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:40:21<4:43:12, 404.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2575.889487591912
INFO:root:current train perplexity7.646673679351807
INFO:root:current mean train loss 2566.0091189822633
INFO:root:current train perplexity7.554544448852539
INFO:root:current mean train loss 2574.0152292351972
INFO:root:current train perplexity7.571108341217041
INFO:root:current mean train loss 2569.9590534953327
INFO:root:current train perplexity7.559115409851074
INFO:root:current mean train loss 2570.101495550097
INFO:root:current train perplexity7.560272693634033
INFO:root:current mean train loss 2562.9543920272436
INFO:root:current train perplexity7.5373759269714355
INFO:root:current mean train loss 2557.778128207687
INFO:root:current train perplexity7.505209445953369
INFO:root:current mean train loss 2553.5375900365743
INFO:root:current train perplexity7.477453708648682
INFO:root:current mean train loss 2551.123941367629
INFO:root:current train perplexity7.465281963348389
INFO:root:current mean train loss 2547.7483716935676
INFO:root:current train perplexity7.453291893005371
INFO:root:current mean train loss 2544.235098533806
INFO:root:current train perplexity7.429486274719238
INFO:root:current mean train loss 2540.5795415306898
INFO:root:current train perplexity7.412520408630371
INFO:root:current mean train loss 2535.263468677803
INFO:root:current train perplexity7.385733604431152
INFO:root:current mean train loss 2533.9807147415104
INFO:root:current train perplexity7.373614311218262
INFO:root:current mean train loss 2532.009918438947
INFO:root:current train perplexity7.361594200134277
INFO:root:current mean train loss 2529.8816772075857
INFO:root:current train perplexity7.344715118408203
INFO:root:current mean train loss 2529.0667140700343
INFO:root:current train perplexity7.337954521179199
INFO:root:current mean train loss 2528.1851303314293
INFO:root:current train perplexity7.3285627365112305
INFO:root:current mean train loss 2525.4340646111364
INFO:root:current train perplexity7.316887378692627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.44s/it]
INFO:root:final mean train loss: 2521.1586649053575
INFO:root:final train perplexity: 7.303380012512207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 2263.6603060242132
INFO:root:eval perplexity: 6.238348960876465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it]
INFO:root:eval mean loss: 2690.0101894081063
INFO:root:eval perplexity: 9.024691581726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:47:00<4:35:16, 402.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2654.7489013671875
INFO:root:current train perplexity7.256484031677246
INFO:root:current mean train loss 2491.4838795381434
INFO:root:current train perplexity7.102532386779785
INFO:root:current mean train loss 2475.246664217203
INFO:root:current train perplexity7.09207820892334
INFO:root:current mean train loss 2479.1720043460264
INFO:root:current train perplexity7.097975254058838
INFO:root:current mean train loss 2489.159521605838
INFO:root:current train perplexity7.111277103424072
INFO:root:current mean train loss 2489.032922022846
INFO:root:current train perplexity7.106848239898682
INFO:root:current mean train loss 2490.109726205617
INFO:root:current train perplexity7.115471839904785
INFO:root:current mean train loss 2492.8899687416533
INFO:root:current train perplexity7.135002136230469
INFO:root:current mean train loss 2494.522922734667
INFO:root:current train perplexity7.138063907623291
INFO:root:current mean train loss 2491.5590032674786
INFO:root:current train perplexity7.1234822273254395
INFO:root:current mean train loss 2489.290570348561
INFO:root:current train perplexity7.1135406494140625
INFO:root:current mean train loss 2489.0374320526953
INFO:root:current train perplexity7.105792045593262
INFO:root:current mean train loss 2488.0248764469698
INFO:root:current train perplexity7.109321594238281
INFO:root:current mean train loss 2488.809111939414
INFO:root:current train perplexity7.108517169952393
INFO:root:current mean train loss 2489.7182689454517
INFO:root:current train perplexity7.1135663986206055
INFO:root:current mean train loss 2489.4625649687137
INFO:root:current train perplexity7.113667964935303
INFO:root:current mean train loss 2490.01050711452
INFO:root:current train perplexity7.116142272949219
INFO:root:current mean train loss 2488.8153880171994
INFO:root:current train perplexity7.1162567138671875
INFO:root:current mean train loss 2490.8530123728624
INFO:root:current train perplexity7.131194591522217
INFO:root:current mean train loss 2492.4371800628246
INFO:root:current train perplexity7.139424800872803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.92s/it]
INFO:root:final mean train loss: 2494.1137333349093
INFO:root:final train perplexity: 7.14925479888916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it]
INFO:root:eval mean loss: 2258.4365043910684
INFO:root:eval perplexity: 6.2120490074157715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 2682.597237228502
INFO:root:eval perplexity: 8.970144271850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:53:58<4:31:33, 407.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2436.9692639802633
INFO:root:current train perplexity7.056405067443848
INFO:root:current mean train loss 2483.81812036338
INFO:root:current train perplexity7.173383712768555
INFO:root:current mean train loss 2499.6900010479094
INFO:root:current train perplexity7.2142181396484375
INFO:root:current mean train loss 2493.561973069529
INFO:root:current train perplexity7.172316551208496
INFO:root:current mean train loss 2499.4035842640587
INFO:root:current train perplexity7.205256462097168
INFO:root:current mean train loss 2505.4168680003613
INFO:root:current train perplexity7.220709800720215
INFO:root:current mean train loss 2511.259274188459
INFO:root:current train perplexity7.238044261932373
INFO:root:current mean train loss 2513.3118120599356
INFO:root:current train perplexity7.252579689025879
INFO:root:current mean train loss 2515.0839563539757
INFO:root:current train perplexity7.259047031402588
INFO:root:current mean train loss 2508.960677685494
INFO:root:current train perplexity7.24528694152832
INFO:root:current mean train loss 2510.2765626916707
INFO:root:current train perplexity7.250455856323242
INFO:root:current mean train loss 2514.462536304736
INFO:root:current train perplexity7.2713165283203125
INFO:root:current mean train loss 2516.530009268932
INFO:root:current train perplexity7.275410175323486
INFO:root:current mean train loss 2519.1378444992656
INFO:root:current train perplexity7.288891792297363
INFO:root:current mean train loss 2518.4640965317235
INFO:root:current train perplexity7.290107250213623
INFO:root:current mean train loss 2521.7021651528553
INFO:root:current train perplexity7.307051658630371
INFO:root:current mean train loss 2521.058651957709
INFO:root:current train perplexity7.306603908538818
INFO:root:current mean train loss 2522.0702640695445
INFO:root:current train perplexity7.307767868041992
INFO:root:current mean train loss 2521.4972341913913
INFO:root:current train perplexity7.305875778198242
INFO:root:current mean train loss 2522.576835342097
INFO:root:current train perplexity7.312957286834717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.19s/it]
INFO:root:final mean train loss: 2523.90703887093
INFO:root:final train perplexity: 7.319228172302246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 2274.933866893146
INFO:root:eval perplexity: 6.295486927032471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 2702.4556815505875
INFO:root:eval perplexity: 9.117016792297363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [7:00:39<4:23:41, 405.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2501.9736328125
INFO:root:current train perplexity7.340655326843262
INFO:root:current mean train loss 2518.0599356258617
INFO:root:current train perplexity7.35051155090332
INFO:root:current mean train loss 2513.962011822199
INFO:root:current train perplexity7.31266450881958
INFO:root:current mean train loss 2516.367298307873
INFO:root:current train perplexity7.3215718269348145
INFO:root:current mean train loss 2515.788511223749
INFO:root:current train perplexity7.316745281219482
INFO:root:current mean train loss 2513.018768766033
INFO:root:current train perplexity7.3211164474487305
INFO:root:current mean train loss 2507.962489098123
INFO:root:current train perplexity7.2902445793151855
INFO:root:current mean train loss 2508.1394222093663
INFO:root:current train perplexity7.294369697570801
INFO:root:current mean train loss 2515.137475702751
INFO:root:current train perplexity7.3333563804626465
INFO:root:current mean train loss 2521.6414552346255
INFO:root:current train perplexity7.3422112464904785
INFO:root:current mean train loss 2521.517668381621
INFO:root:current train perplexity7.335402965545654
INFO:root:current mean train loss 2525.891519788285
INFO:root:current train perplexity7.348230361938477
INFO:root:current mean train loss 2530.8426046525774
INFO:root:current train perplexity7.3664655685424805
INFO:root:current mean train loss 2531.605890605264
INFO:root:current train perplexity7.371547222137451
INFO:root:current mean train loss 2532.473190010092
INFO:root:current train perplexity7.374032974243164
INFO:root:current mean train loss 2533.4696714878082
INFO:root:current train perplexity7.371445178985596
INFO:root:current mean train loss 2532.88060814594
INFO:root:current train perplexity7.363533020019531
INFO:root:current mean train loss 2532.4066894109346
INFO:root:current train perplexity7.356932163238525
INFO:root:current mean train loss 2530.2795780489387
INFO:root:current train perplexity7.357125759124756
INFO:root:current mean train loss 2530.9576747043075
INFO:root:current train perplexity7.354546070098877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.52s/it]
INFO:root:final mean train loss: 2529.72619099504
INFO:root:final train perplexity: 7.352895259857178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 2251.97051612367
INFO:root:eval perplexity: 6.179649353027344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 2677.1700348549703
INFO:root:eval perplexity: 8.930419921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [7:07:32<4:18:12, 407.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2547.4244177476417
INFO:root:current train perplexity7.3078131675720215
INFO:root:current mean train loss 2542.317861519608
INFO:root:current train perplexity7.340093612670898
INFO:root:current mean train loss 2534.951323377285
INFO:root:current train perplexity7.313897132873535
INFO:root:current mean train loss 2541.6133179056746
INFO:root:current train perplexity7.353542327880859
INFO:root:current mean train loss 2547.3769881562157
INFO:root:current train perplexity7.405171871185303
INFO:root:current mean train loss 2553.2138870542776
INFO:root:current train perplexity7.438188552856445
INFO:root:current mean train loss 2554.3909768167355
INFO:root:current train perplexity7.452872276306152
INFO:root:current mean train loss 2550.2322052934096
INFO:root:current train perplexity7.453885555267334
INFO:root:current mean train loss 2550.8270703010517
INFO:root:current train perplexity7.458112716674805
INFO:root:current mean train loss 2551.892794854243
INFO:root:current train perplexity7.45731258392334
INFO:root:current mean train loss 2555.662847129481
INFO:root:current train perplexity7.4843525886535645
INFO:root:current mean train loss 2555.176138779441
INFO:root:current train perplexity7.496330261230469
INFO:root:current mean train loss 2556.452723522141
INFO:root:current train perplexity7.506988048553467
INFO:root:current mean train loss 2558.1333454411206
INFO:root:current train perplexity7.512176513671875
INFO:root:current mean train loss 2558.292042511049
INFO:root:current train perplexity7.514989376068115
INFO:root:current mean train loss 2561.763568512179
INFO:root:current train perplexity7.527740955352783
INFO:root:current mean train loss 2563.5247141058635
INFO:root:current train perplexity7.535034656524658
INFO:root:current mean train loss 2562.4767132599695
INFO:root:current train perplexity7.533604621887207
INFO:root:current mean train loss 2560.1941833002015
INFO:root:current train perplexity7.5258402824401855
INFO:root:current mean train loss 2560.4275894907273
INFO:root:current train perplexity7.528214931488037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.19s/it]
INFO:root:final mean train loss: 2559.3454752973516
INFO:root:final train perplexity: 7.5266804695129395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it]
INFO:root:eval mean loss: 2273.7379241294047
INFO:root:eval perplexity: 6.289401054382324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 2698.4036267869014
INFO:root:eval perplexity: 9.08685302734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [7:14:21<4:11:41, 408.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2540.9030168805803
INFO:root:current train perplexity7.515926361083984
INFO:root:current mean train loss 2554.9207347196693
INFO:root:current train perplexity7.567264080047607
INFO:root:current mean train loss 2564.5788257740164
INFO:root:current train perplexity7.5963454246521
INFO:root:current mean train loss 2569.5802193306586
INFO:root:current train perplexity7.5829644203186035
INFO:root:current mean train loss 2560.823163491107
INFO:root:current train perplexity7.561114311218262
INFO:root:current mean train loss 2562.117460123698
INFO:root:current train perplexity7.5648884773254395
INFO:root:current mean train loss 2561.700272380772
INFO:root:current train perplexity7.5711894035339355
INFO:root:current mean train loss 2561.894300901735
INFO:root:current train perplexity7.571127891540527
INFO:root:current mean train loss 2562.7382193729795
INFO:root:current train perplexity7.56551456451416
INFO:root:current mean train loss 2562.794464929325
INFO:root:current train perplexity7.570431232452393
INFO:root:current mean train loss 2565.3247396593897
INFO:root:current train perplexity7.573236465454102
INFO:root:current mean train loss 2569.554584001068
INFO:root:current train perplexity7.5938591957092285
INFO:root:current mean train loss 2572.59843865342
INFO:root:current train perplexity7.607706069946289
INFO:root:current mean train loss 2573.708450651517
INFO:root:current train perplexity7.610779285430908
INFO:root:current mean train loss 2576.980793274341
INFO:root:current train perplexity7.62105655670166
INFO:root:current mean train loss 2577.74512325214
INFO:root:current train perplexity7.621596336364746
INFO:root:current mean train loss 2576.776643636555
INFO:root:current train perplexity7.617619514465332
INFO:root:current mean train loss 2577.4432808913753
INFO:root:current train perplexity7.624931335449219
INFO:root:current mean train loss 2577.280076036096
INFO:root:current train perplexity7.629459381103516
INFO:root:current mean train loss 2578.4308063332805
INFO:root:current train perplexity7.633979320526123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.80s/it]
INFO:root:final mean train loss: 2577.278180390251
INFO:root:final train perplexity: 7.633882522583008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it]
INFO:root:eval mean loss: 2318.8829540496176
INFO:root:eval perplexity: 6.523275375366211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 2743.103179715204
INFO:root:eval perplexity: 9.42518424987793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [7:21:35<4:09:32, 415.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2594.711190059267
INFO:root:current train perplexity7.64561653137207
INFO:root:current mean train loss 2589.313566646474
INFO:root:current train perplexity7.698598384857178
INFO:root:current mean train loss 2581.425104971962
INFO:root:current train perplexity7.6490607261657715
INFO:root:current mean train loss 2586.3692977077276
INFO:root:current train perplexity7.659954071044922
INFO:root:current mean train loss 2579.8078362623523
INFO:root:current train perplexity7.642077445983887
INFO:root:current mean train loss 2575.2501260214813
INFO:root:current train perplexity7.631038665771484
INFO:root:current mean train loss 2570.8314640761464
INFO:root:current train perplexity7.607076644897461
INFO:root:current mean train loss 2570.825061919274
INFO:root:current train perplexity7.604122638702393
INFO:root:current mean train loss 2568.7757107327193
INFO:root:current train perplexity7.58912992477417
INFO:root:current mean train loss 2569.32411634451
INFO:root:current train perplexity7.588351726531982
INFO:root:current mean train loss 2567.586941239147
INFO:root:current train perplexity7.577461242675781
INFO:root:current mean train loss 2566.4862437967304
INFO:root:current train perplexity7.579676151275635
INFO:root:current mean train loss 2564.2733432203645
INFO:root:current train perplexity7.563555717468262
INFO:root:current mean train loss 2564.5985479705523
INFO:root:current train perplexity7.55966329574585
INFO:root:current mean train loss 2564.266884450393
INFO:root:current train perplexity7.557799816131592
INFO:root:current mean train loss 2565.604600643165
INFO:root:current train perplexity7.556268692016602
INFO:root:current mean train loss 2565.9261240888504
INFO:root:current train perplexity7.55709171295166
INFO:root:current mean train loss 2564.001798470726
INFO:root:current train perplexity7.552705764770508
INFO:root:current mean train loss 2564.8003417451228
INFO:root:current train perplexity7.5556111335754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.20s/it]
INFO:root:final mean train loss: 2565.138355587927
INFO:root:final train perplexity: 7.561143398284912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2274.514961837877
INFO:root:eval perplexity: 6.293354511260986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2695.132616841201
INFO:root:eval perplexity: 9.062577247619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [7:28:15<3:59:54, 411.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2621.5633544921875
INFO:root:current train perplexity7.577287673950195
INFO:root:current mean train loss 2556.8694880558896
INFO:root:current train perplexity7.508002758026123
INFO:root:current mean train loss 2546.3749700808057
INFO:root:current train perplexity7.499424457550049
INFO:root:current mean train loss 2542.0403996517784
INFO:root:current train perplexity7.460227012634277
INFO:root:current mean train loss 2544.6271132667466
INFO:root:current train perplexity7.477139949798584
INFO:root:current mean train loss 2550.1782512362042
INFO:root:current train perplexity7.491213321685791
INFO:root:current mean train loss 2550.163355543124
INFO:root:current train perplexity7.48227071762085
INFO:root:current mean train loss 2547.15423896096
INFO:root:current train perplexity7.470076560974121
INFO:root:current mean train loss 2541.4770283105954
INFO:root:current train perplexity7.452483177185059
INFO:root:current mean train loss 2543.8555189824738
INFO:root:current train perplexity7.448873519897461
INFO:root:current mean train loss 2544.6403674851376
INFO:root:current train perplexity7.449584007263184
INFO:root:current mean train loss 2546.8901973116226
INFO:root:current train perplexity7.457335472106934
INFO:root:current mean train loss 2548.823405623832
INFO:root:current train perplexity7.4633636474609375
INFO:root:current mean train loss 2548.952507159461
INFO:root:current train perplexity7.4594340324401855
INFO:root:current mean train loss 2552.1515607263286
INFO:root:current train perplexity7.469954013824463
INFO:root:current mean train loss 2554.4467625719435
INFO:root:current train perplexity7.480292320251465
INFO:root:current mean train loss 2554.247231043485
INFO:root:current train perplexity7.481906414031982
INFO:root:current mean train loss 2554.053357406401
INFO:root:current train perplexity7.4802141189575195
INFO:root:current mean train loss 2551.7626445626474
INFO:root:current train perplexity7.476571083068848
INFO:root:current mean train loss 2550.825405473469
INFO:root:current train perplexity7.473329544067383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.27s/it]
INFO:root:final mean train loss: 2550.560158995505
INFO:root:final train perplexity: 7.474708557128906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2274.1909841983875
INFO:root:eval perplexity: 6.29170560836792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2692.9111085715867
INFO:root:eval perplexity: 9.046127319335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [7:35:15<3:54:27, 413.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2630.9061221168154
INFO:root:current train perplexity7.597238540649414
INFO:root:current mean train loss 2561.7400003228304
INFO:root:current train perplexity7.480984210968018
INFO:root:current mean train loss 2546.3990417756645
INFO:root:current train perplexity7.42420768737793
INFO:root:current mean train loss 2550.6451655592873
INFO:root:current train perplexity7.437402725219727
INFO:root:current mean train loss 2548.402013783217
INFO:root:current train perplexity7.443577766418457
INFO:root:current mean train loss 2548.931328068768
INFO:root:current train perplexity7.4359025955200195
INFO:root:current mean train loss 2552.1937996930355
INFO:root:current train perplexity7.461979389190674
INFO:root:current mean train loss 2552.190199768659
INFO:root:current train perplexity7.4741668701171875
INFO:root:current mean train loss 2550.821347941725
INFO:root:current train perplexity7.466770172119141
INFO:root:current mean train loss 2550.1608587175965
INFO:root:current train perplexity7.465160846710205
INFO:root:current mean train loss 2547.4319808915125
INFO:root:current train perplexity7.449420928955078
INFO:root:current mean train loss 2546.0879633662744
INFO:root:current train perplexity7.437558650970459
INFO:root:current mean train loss 2543.9301423893708
INFO:root:current train perplexity7.426865100860596
INFO:root:current mean train loss 2543.497366755772
INFO:root:current train perplexity7.423478603363037
INFO:root:current mean train loss 2541.097847129827
INFO:root:current train perplexity7.418625354766846
INFO:root:current mean train loss 2541.6491294725406
INFO:root:current train perplexity7.414158821105957
INFO:root:current mean train loss 2542.3946146885605
INFO:root:current train perplexity7.417348384857178
INFO:root:current mean train loss 2541.456459838938
INFO:root:current train perplexity7.417588710784912
INFO:root:current mean train loss 2539.2914642216674
INFO:root:current train perplexity7.413771629333496
INFO:root:current mean train loss 2540.285600303797
INFO:root:current train perplexity7.413377285003662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.40s/it]
INFO:root:final mean train loss: 2539.8229166051083
INFO:root:final train perplexity: 7.411679267883301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 2293.0296773707614
INFO:root:eval perplexity: 6.388297080993652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 2716.0023531000666
INFO:root:eval perplexity: 9.218585968017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:42:07<3:47:14, 413.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2527.0027240953946
INFO:root:current train perplexity7.305086612701416
INFO:root:current mean train loss 2515.701226718184
INFO:root:current train perplexity7.253781318664551
INFO:root:current mean train loss 2528.915754045759
INFO:root:current train perplexity7.267728328704834
INFO:root:current mean train loss 2527.2564603365386
INFO:root:current train perplexity7.285123348236084
INFO:root:current mean train loss 2532.1776234526615
INFO:root:current train perplexity7.313930034637451
INFO:root:current mean train loss 2538.1558869656133
INFO:root:current train perplexity7.357010364532471
INFO:root:current mean train loss 2537.9403730529975
INFO:root:current train perplexity7.36038064956665
INFO:root:current mean train loss 2533.756311432133
INFO:root:current train perplexity7.334614276885986
INFO:root:current mean train loss 2529.01170170677
INFO:root:current train perplexity7.319661617279053
INFO:root:current mean train loss 2524.9568491856426
INFO:root:current train perplexity7.301159381866455
INFO:root:current mean train loss 2524.9670049119777
INFO:root:current train perplexity7.30233907699585
INFO:root:current mean train loss 2526.0741828154178
INFO:root:current train perplexity7.311112880706787
INFO:root:current mean train loss 2525.8365404563497
INFO:root:current train perplexity7.309087753295898
INFO:root:current mean train loss 2525.870100309318
INFO:root:current train perplexity7.314202308654785
INFO:root:current mean train loss 2523.5177257468868
INFO:root:current train perplexity7.309104919433594
INFO:root:current mean train loss 2522.851093346803
INFO:root:current train perplexity7.309621810913086
INFO:root:current mean train loss 2524.392821445861
INFO:root:current train perplexity7.3137969970703125
INFO:root:current mean train loss 2522.6375859549184
INFO:root:current train perplexity7.304253578186035
INFO:root:current mean train loss 2521.46541604591
INFO:root:current train perplexity7.299198150634766
INFO:root:current mean train loss 2520.354448348007
INFO:root:current train perplexity7.292758464813232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.57s/it]
INFO:root:final mean train loss: 2519.1940093086155
INFO:root:final train perplexity: 7.292072296142578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 2257.2881175372618
INFO:root:eval perplexity: 6.206282615661621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2679.7902702169217
INFO:root:eval perplexity: 8.949577331542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:48:52<3:39:07, 410.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2503.490784801136
INFO:root:current train perplexity7.214481353759766
INFO:root:current mean train loss 2487.511671496976
INFO:root:current train perplexity7.1407012939453125
INFO:root:current mean train loss 2485.4165498621323
INFO:root:current train perplexity7.1747331619262695
INFO:root:current mean train loss 2485.2346521511886
INFO:root:current train perplexity7.166479110717773
INFO:root:current mean train loss 2492.6424895904875
INFO:root:current train perplexity7.180548667907715
INFO:root:current mean train loss 2489.7919737119933
INFO:root:current train perplexity7.149489879608154
INFO:root:current mean train loss 2489.4747353590174
INFO:root:current train perplexity7.137936115264893
INFO:root:current mean train loss 2489.7493189931706
INFO:root:current train perplexity7.131824970245361
INFO:root:current mean train loss 2492.2024471171417
INFO:root:current train perplexity7.14066219329834
INFO:root:current mean train loss 2493.069136023397
INFO:root:current train perplexity7.137716770172119
INFO:root:current mean train loss 2492.1221212233413
INFO:root:current train perplexity7.130520343780518
INFO:root:current mean train loss 2491.7201279677356
INFO:root:current train perplexity7.132136344909668
INFO:root:current mean train loss 2492.9700298415714
INFO:root:current train perplexity7.133515357971191
INFO:root:current mean train loss 2491.0733396635724
INFO:root:current train perplexity7.123383522033691
INFO:root:current mean train loss 2490.6275820178266
INFO:root:current train perplexity7.122264385223389
INFO:root:current mean train loss 2491.9925443692223
INFO:root:current train perplexity7.126405715942383
INFO:root:current mean train loss 2492.708718549377
INFO:root:current train perplexity7.131868362426758
INFO:root:current mean train loss 2493.8494861222403
INFO:root:current train perplexity7.137509346008301
INFO:root:current mean train loss 2492.2935000684383
INFO:root:current train perplexity7.136283874511719
INFO:root:current mean train loss 2492.6967159651736
INFO:root:current train perplexity7.14057731628418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.66s/it]
INFO:root:final mean train loss: 2492.4423002626822
INFO:root:final train perplexity: 7.13983678817749
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it]
INFO:root:eval mean loss: 2254.8579915364585
INFO:root:eval perplexity: 6.194097518920898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 2677.629243025543
INFO:root:eval perplexity: 8.933771133422852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:55:59<3:34:45, 415.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2475.8847079806856
INFO:root:current train perplexity7.016904354095459
INFO:root:current mean train loss 2471.2168593295787
INFO:root:current train perplexity6.973607063293457
INFO:root:current mean train loss 2475.156469008502
INFO:root:current train perplexity7.038451194763184
INFO:root:current mean train loss 2474.2735326623406
INFO:root:current train perplexity7.054137706756592
INFO:root:current mean train loss 2482.75420987404
INFO:root:current train perplexity7.08024263381958
INFO:root:current mean train loss 2480.2914053109976
INFO:root:current train perplexity7.0593061447143555
INFO:root:current mean train loss 2479.4577436901272
INFO:root:current train perplexity7.05650520324707
INFO:root:current mean train loss 2479.8448884795985
INFO:root:current train perplexity7.04562520980835
INFO:root:current mean train loss 2479.3052071387615
INFO:root:current train perplexity7.05222225189209
INFO:root:current mean train loss 2477.432119110484
INFO:root:current train perplexity7.03908634185791
INFO:root:current mean train loss 2475.451821170636
INFO:root:current train perplexity7.031940460205078
INFO:root:current mean train loss 2472.6353471254733
INFO:root:current train perplexity7.0182647705078125
INFO:root:current mean train loss 2470.443042875086
INFO:root:current train perplexity7.006601810455322
INFO:root:current mean train loss 2469.421879715544
INFO:root:current train perplexity7.000647068023682
INFO:root:current mean train loss 2465.8543813124948
INFO:root:current train perplexity6.991031646728516
INFO:root:current mean train loss 2466.711333296681
INFO:root:current train perplexity6.992505073547363
INFO:root:current mean train loss 2464.4787192458743
INFO:root:current train perplexity6.980889797210693
INFO:root:current mean train loss 2462.3706476973625
INFO:root:current train perplexity6.967683792114258
INFO:root:current mean train loss 2460.7267321725176
INFO:root:current train perplexity6.960044860839844
INFO:root:current mean train loss 2461.7368793603614
INFO:root:current train perplexity6.962608814239502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.84s/it]
INFO:root:final mean train loss: 2460.3452418371094
INFO:root:final train perplexity: 6.961369037628174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 2243.6120921466368
INFO:root:eval perplexity: 6.138016700744629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it]
INFO:root:eval mean loss: 2667.93479627244
INFO:root:eval perplexity: 8.8632230758667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [8:02:46<3:26:30, 413.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2443.164904647999
INFO:root:current train perplexity6.878209114074707
INFO:root:current mean train loss 2453.1129841476522
INFO:root:current train perplexity6.912341594696045
INFO:root:current mean train loss 2461.0277078489944
INFO:root:current train perplexity6.918739318847656
INFO:root:current mean train loss 2452.6621278895204
INFO:root:current train perplexity6.895051002502441
INFO:root:current mean train loss 2449.4483078408584
INFO:root:current train perplexity6.894453525543213
INFO:root:current mean train loss 2449.062014413001
INFO:root:current train perplexity6.896295547485352
INFO:root:current mean train loss 2446.6655758884026
INFO:root:current train perplexity6.887240886688232
INFO:root:current mean train loss 2449.695885874624
INFO:root:current train perplexity6.8905839920043945
INFO:root:current mean train loss 2443.7285892241985
INFO:root:current train perplexity6.884453296661377
INFO:root:current mean train loss 2445.6100274405176
INFO:root:current train perplexity6.891345024108887
INFO:root:current mean train loss 2447.836252371908
INFO:root:current train perplexity6.905485153198242
INFO:root:current mean train loss 2446.8809641973626
INFO:root:current train perplexity6.900632381439209
INFO:root:current mean train loss 2443.692504977514
INFO:root:current train perplexity6.883867263793945
INFO:root:current mean train loss 2444.4835757865935
INFO:root:current train perplexity6.88055944442749
INFO:root:current mean train loss 2447.0777224713
INFO:root:current train perplexity6.882804870605469
INFO:root:current mean train loss 2446.8575070707057
INFO:root:current train perplexity6.87650728225708
INFO:root:current mean train loss 2446.2282985147463
INFO:root:current train perplexity6.879888534545898
INFO:root:current mean train loss 2447.4862952362964
INFO:root:current train perplexity6.8811354637146
INFO:root:current mean train loss 2447.9455645244675
INFO:root:current train perplexity6.884572982788086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it]
INFO:root:final mean train loss: 2445.1998399358413
INFO:root:final train perplexity: 6.878713607788086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 2235.231281253463
INFO:root:eval perplexity: 6.096555233001709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 2657.852871942182
INFO:root:eval perplexity: 8.79044246673584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [8:09:45<3:20:25, 414.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2488.698201497396
INFO:root:current train perplexity7.065634727478027
INFO:root:current mean train loss 2446.1508316903746
INFO:root:current train perplexity6.884385108947754
INFO:root:current mean train loss 2448.2233714872195
INFO:root:current train perplexity6.883305549621582
INFO:root:current mean train loss 2443.425677929049
INFO:root:current train perplexity6.86544132232666
INFO:root:current mean train loss 2445.9981656379887
INFO:root:current train perplexity6.880884170532227
INFO:root:current mean train loss 2447.5658496962233
INFO:root:current train perplexity6.86174201965332
INFO:root:current mean train loss 2442.4437088667364
INFO:root:current train perplexity6.845876216888428
INFO:root:current mean train loss 2439.472116962033
INFO:root:current train perplexity6.8397321701049805
INFO:root:current mean train loss 2437.381416869814
INFO:root:current train perplexity6.828805923461914
INFO:root:current mean train loss 2437.3996079468043
INFO:root:current train perplexity6.828388690948486
INFO:root:current mean train loss 2436.844046196454
INFO:root:current train perplexity6.825593948364258
INFO:root:current mean train loss 2436.6211327109586
INFO:root:current train perplexity6.823089599609375
INFO:root:current mean train loss 2437.7039149143607
INFO:root:current train perplexity6.827566146850586
INFO:root:current mean train loss 2437.0971589957408
INFO:root:current train perplexity6.825841903686523
INFO:root:current mean train loss 2437.924861294786
INFO:root:current train perplexity6.830965518951416
INFO:root:current mean train loss 2438.6545445010324
INFO:root:current train perplexity6.834868431091309
INFO:root:current mean train loss 2441.6192702201947
INFO:root:current train perplexity6.855712890625
INFO:root:current mean train loss 2452.8709001977168
INFO:root:current train perplexity6.911539077758789
INFO:root:current mean train loss 2461.48463123951
INFO:root:current train perplexity6.955168724060059
INFO:root:current mean train loss 2470.689359554839
INFO:root:current train perplexity7.013829708099365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.71s/it]
INFO:root:final mean train loss: 2476.342990369311
INFO:root:final train perplexity: 7.049756050109863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it]
INFO:root:eval mean loss: 2372.7668972150655
INFO:root:eval perplexity: 6.8138298988342285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 2804.5719236549758
INFO:root:eval perplexity: 9.911108016967773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [8:16:37<3:13:13, 414.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2637.2844450577445
INFO:root:current train perplexity8.034427642822266
INFO:root:current mean train loss 2609.4496732882367
INFO:root:current train perplexity7.8896684646606445
INFO:root:current mean train loss 2574.823131612598
INFO:root:current train perplexity7.669791221618652
INFO:root:current mean train loss 2565.057896097378
INFO:root:current train perplexity7.560901641845703
INFO:root:current mean train loss 2557.8303450636267
INFO:root:current train perplexity7.504949569702148
INFO:root:current mean train loss 2550.2406136565637
INFO:root:current train perplexity7.45390510559082
INFO:root:current mean train loss 2541.8429488033585
INFO:root:current train perplexity7.405274391174316
INFO:root:current mean train loss 2539.448128559118
INFO:root:current train perplexity7.386795520782471
INFO:root:current mean train loss 2534.170419500636
INFO:root:current train perplexity7.35760498046875
INFO:root:current mean train loss 2524.2736791278016
INFO:root:current train perplexity7.311734199523926
INFO:root:current mean train loss 2518.8926665454314
INFO:root:current train perplexity7.286822319030762
INFO:root:current mean train loss 2516.3745946569943
INFO:root:current train perplexity7.267946243286133
INFO:root:current mean train loss 2510.8969356259263
INFO:root:current train perplexity7.238073825836182
INFO:root:current mean train loss 2508.030475780807
INFO:root:current train perplexity7.218506813049316
INFO:root:current mean train loss 2501.536447381605
INFO:root:current train perplexity7.192824840545654
INFO:root:current mean train loss 2497.446216525643
INFO:root:current train perplexity7.172701835632324
INFO:root:current mean train loss 2496.026689022908
INFO:root:current train perplexity7.161157131195068
INFO:root:current mean train loss 2493.3172016553385
INFO:root:current train perplexity7.140548229217529
INFO:root:current mean train loss 2490.8101487905196
INFO:root:current train perplexity7.129733085632324
INFO:root:current mean train loss 2487.999268911186
INFO:root:current train perplexity7.1116838455200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.04s/it]
INFO:root:final mean train loss: 2485.055974870875
INFO:root:final train perplexity: 7.098365783691406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 2237.778005613503
INFO:root:eval perplexity: 6.109125137329102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2666.874106549202
INFO:root:eval perplexity: 8.855539321899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [8:23:44<3:08:03, 417.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2367.727893066406
INFO:root:current train perplexity6.640570640563965
INFO:root:current mean train loss 2404.4165675571985
INFO:root:current train perplexity6.703258991241455
INFO:root:current mean train loss 2411.335559082031
INFO:root:current train perplexity6.70638370513916
INFO:root:current mean train loss 2421.052830954159
INFO:root:current train perplexity6.737761974334717
INFO:root:current mean train loss 2431.206169267134
INFO:root:current train perplexity6.775143623352051
INFO:root:current mean train loss 2424.8494687680845
INFO:root:current train perplexity6.7598042488098145
INFO:root:current mean train loss 2425.5024234771727
INFO:root:current train perplexity6.749991416931152
INFO:root:current mean train loss 2426.2260610219596
INFO:root:current train perplexity6.748547077178955
INFO:root:current mean train loss 2423.8462413969496
INFO:root:current train perplexity6.735321521759033
INFO:root:current mean train loss 2424.512138983544
INFO:root:current train perplexity6.733047962188721
INFO:root:current mean train loss 2422.5065490722654
INFO:root:current train perplexity6.728704929351807
INFO:root:current mean train loss 2423.9182522957785
INFO:root:current train perplexity6.731720924377441
INFO:root:current mean train loss 2422.1533072194748
INFO:root:current train perplexity6.723458766937256
INFO:root:current mean train loss 2420.9622449277053
INFO:root:current train perplexity6.718250274658203
INFO:root:current mean train loss 2416.7463681538898
INFO:root:current train perplexity6.703217506408691
INFO:root:current mean train loss 2416.3532434240565
INFO:root:current train perplexity6.696073532104492
INFO:root:current mean train loss 2414.9681007943504
INFO:root:current train perplexity6.69258451461792
INFO:root:current mean train loss 2412.582091864224
INFO:root:current train perplexity6.688266754150391
INFO:root:current mean train loss 2409.3801404206647
INFO:root:current train perplexity6.6757917404174805
INFO:root:current mean train loss 2407.3546637780887
INFO:root:current train perplexity6.670605659484863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.01s/it]
INFO:root:final mean train loss: 2404.8512615409695
INFO:root:final train perplexity: 6.663269996643066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it]
INFO:root:eval mean loss: 2215.995253109763
INFO:root:eval perplexity: 6.002445220947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 2646.2573341748393
INFO:root:eval perplexity: 8.707477569580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [8:30:30<2:59:31, 414.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2370.738553231223
INFO:root:current train perplexity6.354569911956787
INFO:root:current mean train loss 2370.1202415903663
INFO:root:current train perplexity6.417385101318359
INFO:root:current mean train loss 2383.1554605803135
INFO:root:current train perplexity6.489021301269531
INFO:root:current mean train loss 2388.1565608176866
INFO:root:current train perplexity6.5044050216674805
INFO:root:current mean train loss 2380.773554228067
INFO:root:current train perplexity6.504885196685791
INFO:root:current mean train loss 2383.086875929225
INFO:root:current train perplexity6.50838565826416
INFO:root:current mean train loss 2383.6301589106497
INFO:root:current train perplexity6.51438570022583
INFO:root:current mean train loss 2383.0018733035936
INFO:root:current train perplexity6.513625621795654
INFO:root:current mean train loss 2380.7253245617435
INFO:root:current train perplexity6.502011299133301
INFO:root:current mean train loss 2377.929204448513
INFO:root:current train perplexity6.492609024047852
INFO:root:current mean train loss 2377.1081138762415
INFO:root:current train perplexity6.486933708190918
INFO:root:current mean train loss 2375.636483155352
INFO:root:current train perplexity6.481821060180664
INFO:root:current mean train loss 2374.8433001752687
INFO:root:current train perplexity6.482274532318115
INFO:root:current mean train loss 2372.003668496252
INFO:root:current train perplexity6.474786281585693
INFO:root:current mean train loss 2370.572543529754
INFO:root:current train perplexity6.470788955688477
INFO:root:current mean train loss 2368.4629224557943
INFO:root:current train perplexity6.459807395935059
INFO:root:current mean train loss 2367.1916714600934
INFO:root:current train perplexity6.4576544761657715
INFO:root:current mean train loss 2366.4330292529658
INFO:root:current train perplexity6.453034400939941
INFO:root:current mean train loss 2365.658409007724
INFO:root:current train perplexity6.4493489265441895
INFO:root:current mean train loss 2363.4264632718687
INFO:root:current train perplexity6.444705486297607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.55s/it]
INFO:root:final mean train loss: 2362.6825877625834
INFO:root:final train perplexity: 6.445317268371582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 2197.8928750761856
INFO:root:eval perplexity: 5.915208339691162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 2627.184079434009
INFO:root:eval perplexity: 8.57270336151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [8:37:22<2:52:18, 413.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2324.91665731894
INFO:root:current train perplexity6.342619895935059
INFO:root:current mean train loss 2338.1859453573993
INFO:root:current train perplexity6.306303024291992
INFO:root:current mean train loss 2335.2672961158473
INFO:root:current train perplexity6.319672584533691
INFO:root:current mean train loss 2336.585264154934
INFO:root:current train perplexity6.326577663421631
INFO:root:current mean train loss 2330.772966988479
INFO:root:current train perplexity6.311032772064209
INFO:root:current mean train loss 2334.3105062557847
INFO:root:current train perplexity6.318146228790283
INFO:root:current mean train loss 2331.2335927719887
INFO:root:current train perplexity6.31020450592041
INFO:root:current mean train loss 2331.3552195625402
INFO:root:current train perplexity6.306615829467773
INFO:root:current mean train loss 2334.429069606336
INFO:root:current train perplexity6.314339637756348
INFO:root:current mean train loss 2336.3641384994226
INFO:root:current train perplexity6.314034461975098
INFO:root:current mean train loss 2335.09492319345
INFO:root:current train perplexity6.3102617263793945
INFO:root:current mean train loss 2335.603994236285
INFO:root:current train perplexity6.313455104827881
INFO:root:current mean train loss 2338.8393498155724
INFO:root:current train perplexity6.32347297668457
INFO:root:current mean train loss 2343.1397071627375
INFO:root:current train perplexity6.342555046081543
INFO:root:current mean train loss 2349.7182536028135
INFO:root:current train perplexity6.372086048126221
INFO:root:current mean train loss 2354.8841808663237
INFO:root:current train perplexity6.39754581451416
INFO:root:current mean train loss 2356.9373613765447
INFO:root:current train perplexity6.409455299377441
INFO:root:current mean train loss 2358.1234863006007
INFO:root:current train perplexity6.41920804977417
INFO:root:current mean train loss 2358.184829825907
INFO:root:current train perplexity6.423463344573975
INFO:root:current mean train loss 2359.540812174479
INFO:root:current train perplexity6.426480293273926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.21s/it]
INFO:root:final mean train loss: 2358.9981388432534
INFO:root:final train perplexity: 6.426614284515381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2199.7610404373063
INFO:root:eval perplexity: 5.924151420593262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2629.2579142252603
INFO:root:eval perplexity: 8.58725643157959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [8:44:02<2:43:49, 409.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2399.5555808937156
INFO:root:current train perplexity6.503693580627441
INFO:root:current mean train loss 2400.5408398693144
INFO:root:current train perplexity6.5688347816467285
INFO:root:current mean train loss 2390.913859049479
INFO:root:current train perplexity6.5415754318237305
INFO:root:current mean train loss 2389.2742551525535
INFO:root:current train perplexity6.558497428894043
INFO:root:current mean train loss 2390.0341272295855
INFO:root:current train perplexity6.574629783630371
INFO:root:current mean train loss 2387.3387407796636
INFO:root:current train perplexity6.564587593078613
INFO:root:current mean train loss 2379.244046819883
INFO:root:current train perplexity6.544483184814453
INFO:root:current mean train loss 2376.1386056699885
INFO:root:current train perplexity6.529865741729736
INFO:root:current mean train loss 2372.2715850727327
INFO:root:current train perplexity6.506775856018066
INFO:root:current mean train loss 2370.6493458213768
INFO:root:current train perplexity6.497498035430908
INFO:root:current mean train loss 2369.2269143892145
INFO:root:current train perplexity6.4817214012146
INFO:root:current mean train loss 2366.0748321763813
INFO:root:current train perplexity6.465035438537598
INFO:root:current mean train loss 2365.2835009727805
INFO:root:current train perplexity6.456581115722656
INFO:root:current mean train loss 2364.2279025529633
INFO:root:current train perplexity6.449512958526611
INFO:root:current mean train loss 2362.921640602076
INFO:root:current train perplexity6.440342426300049
INFO:root:current mean train loss 2364.2663085477147
INFO:root:current train perplexity6.439993381500244
INFO:root:current mean train loss 2362.122008374991
INFO:root:current train perplexity6.429657459259033
INFO:root:current mean train loss 2360.247952272212
INFO:root:current train perplexity6.4210004806518555
INFO:root:current mean train loss 2358.0796359348146
INFO:root:current train perplexity6.413433074951172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.78s/it]
INFO:root:final mean train loss: 2355.926832421284
INFO:root:final train perplexity: 6.411065101623535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 2196.3839254176364
INFO:root:eval perplexity: 5.907993316650391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it]
INFO:root:eval mean loss: 2623.4935930400875
INFO:root:eval perplexity: 8.546869277954102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:51:07<2:38:49, 414.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2253.18505859375
INFO:root:current train perplexity6.014153957366943
INFO:root:current mean train loss 2361.448600486473
INFO:root:current train perplexity6.464025974273682
INFO:root:current mean train loss 2363.6097048245942
INFO:root:current train perplexity6.446951866149902
INFO:root:current mean train loss 2366.129108775746
INFO:root:current train perplexity6.473926544189453
INFO:root:current mean train loss 2366.139237347771
INFO:root:current train perplexity6.467578887939453
INFO:root:current mean train loss 2362.4434377114603
INFO:root:current train perplexity6.445431709289551
INFO:root:current mean train loss 2364.452233967028
INFO:root:current train perplexity6.432950973510742
INFO:root:current mean train loss 2363.9830215367892
INFO:root:current train perplexity6.432696342468262
INFO:root:current mean train loss 2360.3269795332803
INFO:root:current train perplexity6.424055576324463
INFO:root:current mean train loss 2360.292072850702
INFO:root:current train perplexity6.423494338989258
INFO:root:current mean train loss 2361.0372519114662
INFO:root:current train perplexity6.421756267547607
INFO:root:current mean train loss 2362.618571808192
INFO:root:current train perplexity6.429431915283203
INFO:root:current mean train loss 2364.5667362844706
INFO:root:current train perplexity6.436069965362549
INFO:root:current mean train loss 2365.156895628763
INFO:root:current train perplexity6.432934284210205
INFO:root:current mean train loss 2362.5085945129395
INFO:root:current train perplexity6.429385185241699
INFO:root:current mean train loss 2361.6361774474935
INFO:root:current train perplexity6.428708553314209
INFO:root:current mean train loss 2361.8145227384803
INFO:root:current train perplexity6.436594486236572
INFO:root:current mean train loss 2362.908277596467
INFO:root:current train perplexity6.444130897521973
INFO:root:current mean train loss 2363.2674485603266
INFO:root:current train perplexity6.443938732147217
INFO:root:current mean train loss 2362.7583861281037
INFO:root:current train perplexity6.442346572875977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.13s/it]
INFO:root:final mean train loss: 2362.1115246809795
INFO:root:final train perplexity: 6.442414283752441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 2205.052422706117
INFO:root:eval perplexity: 5.949558258056641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it]
INFO:root:eval mean loss: 2635.6441581130875
INFO:root:eval perplexity: 8.632223129272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:58:09<2:32:46, 416.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2290.41607421875
INFO:root:current train perplexity6.223635673522949
INFO:root:current mean train loss 2350.3641142578126
INFO:root:current train perplexity6.410268783569336
INFO:root:current mean train loss 2349.426672092014
INFO:root:current train perplexity6.390445709228516
INFO:root:current mean train loss 2350.729064002404
INFO:root:current train perplexity6.414578914642334
INFO:root:current mean train loss 2348.7049508846508
INFO:root:current train perplexity6.422523021697998
INFO:root:current mean train loss 2346.9375304594496
INFO:root:current train perplexity6.411713123321533
INFO:root:current mean train loss 2349.2007693359374
INFO:root:current train perplexity6.420710563659668
INFO:root:current mean train loss 2348.9107630657327
INFO:root:current train perplexity6.409428596496582
INFO:root:current mean train loss 2348.384130267519
INFO:root:current train perplexity6.408803939819336
INFO:root:current mean train loss 2349.0137142366975
INFO:root:current train perplexity6.398529052734375
INFO:root:current mean train loss 2349.860460532584
INFO:root:current train perplexity6.40278959274292
INFO:root:current mean train loss 2350.4266195746527
INFO:root:current train perplexity6.4046854972839355
INFO:root:current mean train loss 2352.434084123884
INFO:root:current train perplexity6.408813953399658
INFO:root:current mean train loss 2353.6056703272407
INFO:root:current train perplexity6.409350395202637
INFO:root:current mean train loss 2353.7454836554275
INFO:root:current train perplexity6.408758163452148
INFO:root:current mean train loss 2354.4607867731816
INFO:root:current train perplexity6.410210132598877
INFO:root:current mean train loss 2354.8539988731973
INFO:root:current train perplexity6.409251689910889
INFO:root:current mean train loss 2354.253772432631
INFO:root:current train perplexity6.404590606689453
INFO:root:current mean train loss 2355.838973472282
INFO:root:current train perplexity6.4053053855896
INFO:root:current mean train loss 2354.6154612038354
INFO:root:current train perplexity6.401700496673584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.83s/it]
INFO:root:final mean train loss: 2353.624240553986
INFO:root:final train perplexity: 6.399435520172119
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 2203.340358003657
INFO:root:eval perplexity: 5.9413251876831055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 2631.884306346271
INFO:root:eval perplexity: 8.605720520019531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [9:05:03<2:25:27, 415.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2311.712079729353
INFO:root:current train perplexity6.333948135375977
INFO:root:current mean train loss 2354.4119563572845
INFO:root:current train perplexity6.420309543609619
INFO:root:current mean train loss 2352.7860314235213
INFO:root:current train perplexity6.4039411544799805
INFO:root:current mean train loss 2344.312666329724
INFO:root:current train perplexity6.343844890594482
INFO:root:current mean train loss 2349.2001605141754
INFO:root:current train perplexity6.338997840881348
INFO:root:current mean train loss 2354.4444620618083
INFO:root:current train perplexity6.371467113494873
INFO:root:current mean train loss 2349.094907766562
INFO:root:current train perplexity6.357431411743164
INFO:root:current mean train loss 2345.0077587035144
INFO:root:current train perplexity6.346080303192139
INFO:root:current mean train loss 2342.59999776736
INFO:root:current train perplexity6.336519241333008
INFO:root:current mean train loss 2342.723647066995
INFO:root:current train perplexity6.339347839355469
INFO:root:current mean train loss 2341.079258426366
INFO:root:current train perplexity6.331921100616455
INFO:root:current mean train loss 2340.0529151288515
INFO:root:current train perplexity6.331350803375244
INFO:root:current mean train loss 2341.3108952963025
INFO:root:current train perplexity6.333735942840576
INFO:root:current mean train loss 2341.6099355956303
INFO:root:current train perplexity6.333930969238281
INFO:root:current mean train loss 2344.256641911733
INFO:root:current train perplexity6.3438920974731445
INFO:root:current mean train loss 2343.3692730657476
INFO:root:current train perplexity6.3399152755737305
INFO:root:current mean train loss 2343.3363232630036
INFO:root:current train perplexity6.341170787811279
INFO:root:current mean train loss 2341.012514099051
INFO:root:current train perplexity6.335587024688721
INFO:root:current mean train loss 2341.1325632565445
INFO:root:current train perplexity6.333382606506348
INFO:root:current mean train loss 2340.136404522661
INFO:root:current train perplexity6.330598831176758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it]
INFO:root:final mean train loss: 2339.7972031062864
INFO:root:final train perplexity: 6.330028533935547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 2185.710941395861
INFO:root:eval perplexity: 5.857217788696289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 2617.2218498067655
INFO:root:eval perplexity: 8.503141403198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [9:12:04<2:19:06, 417.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2339.7369798563295
INFO:root:current train perplexity6.26201868057251
INFO:root:current mean train loss 2337.327184521177
INFO:root:current train perplexity6.28237771987915
INFO:root:current mean train loss 2333.0118323366614
INFO:root:current train perplexity6.2703962326049805
INFO:root:current mean train loss 2327.6450436732894
INFO:root:current train perplexity6.2699408531188965
INFO:root:current mean train loss 2329.553529028799
INFO:root:current train perplexity6.267773628234863
INFO:root:current mean train loss 2335.5451692912147
INFO:root:current train perplexity6.288479328155518
INFO:root:current mean train loss 2339.540030356423
INFO:root:current train perplexity6.286618232727051
INFO:root:current mean train loss 2341.4624274333005
INFO:root:current train perplexity6.294215202331543
INFO:root:current mean train loss 2335.9705406961675
INFO:root:current train perplexity6.280589580535889
INFO:root:current mean train loss 2336.7878564351295
INFO:root:current train perplexity6.288621425628662
INFO:root:current mean train loss 2334.9890906718456
INFO:root:current train perplexity6.284284591674805
INFO:root:current mean train loss 2333.516609251139
INFO:root:current train perplexity6.278900623321533
INFO:root:current mean train loss 2330.9943517998536
INFO:root:current train perplexity6.2757368087768555
INFO:root:current mean train loss 2329.2564022690167
INFO:root:current train perplexity6.271939754486084
INFO:root:current mean train loss 2327.8529189111764
INFO:root:current train perplexity6.269430160522461
INFO:root:current mean train loss 2326.295189349142
INFO:root:current train perplexity6.26536750793457
INFO:root:current mean train loss 2326.8062939129372
INFO:root:current train perplexity6.266767978668213
INFO:root:current mean train loss 2327.270263186092
INFO:root:current train perplexity6.262748718261719
INFO:root:current mean train loss 2326.4070952334923
INFO:root:current train perplexity6.261839866638184
INFO:root:current mean train loss 2326.7007199219747
INFO:root:current train perplexity6.260639667510986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.42s/it]
INFO:root:final mean train loss: 2325.336716644703
INFO:root:final train perplexity: 6.258248329162598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it]
INFO:root:eval mean loss: 2178.261132206477
INFO:root:eval perplexity: 5.8220343589782715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 2610.088711785932
INFO:root:eval perplexity: 8.453683853149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [9:18:56<2:11:37, 415.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2293.9589715254933
INFO:root:current train perplexity6.2173171043396
INFO:root:current mean train loss 2295.9013054587626
INFO:root:current train perplexity6.220587253570557
INFO:root:current mean train loss 2309.064685323964
INFO:root:current train perplexity6.256357669830322
INFO:root:current mean train loss 2313.7848127649186
INFO:root:current train perplexity6.259542942047119
INFO:root:current mean train loss 2314.275157768185
INFO:root:current train perplexity6.254872798919678
INFO:root:current mean train loss 2313.447339587741
INFO:root:current train perplexity6.237429618835449
INFO:root:current mean train loss 2314.4431435850247
INFO:root:current train perplexity6.24548864364624
INFO:root:current mean train loss 2318.433963421694
INFO:root:current train perplexity6.239058971405029
INFO:root:current mean train loss 2317.8021004733428
INFO:root:current train perplexity6.229747772216797
INFO:root:current mean train loss 2319.391968774014
INFO:root:current train perplexity6.233814239501953
INFO:root:current mean train loss 2319.760238250392
INFO:root:current train perplexity6.231329441070557
INFO:root:current mean train loss 2319.712078276135
INFO:root:current train perplexity6.227360248565674
INFO:root:current mean train loss 2319.3367460723207
INFO:root:current train perplexity6.226437091827393
INFO:root:current mean train loss 2319.84490354671
INFO:root:current train perplexity6.22629976272583
INFO:root:current mean train loss 2319.6862820260894
INFO:root:current train perplexity6.221649646759033
INFO:root:current mean train loss 2319.8219989447425
INFO:root:current train perplexity6.2240800857543945
INFO:root:current mean train loss 2318.2587382241477
INFO:root:current train perplexity6.219764232635498
INFO:root:current mean train loss 2317.981879363189
INFO:root:current train perplexity6.220358848571777
INFO:root:current mean train loss 2317.2980878947897
INFO:root:current train perplexity6.217227458953857
INFO:root:current mean train loss 2317.6130289548805
INFO:root:current train perplexity6.2174458503723145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.01s/it]
INFO:root:final mean train loss: 2316.955286931102
INFO:root:final train perplexity: 6.217018127441406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2182.642240050837
INFO:root:eval perplexity: 5.842698574066162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it]
INFO:root:eval mean loss: 2614.1044735739415
INFO:root:eval perplexity: 8.48149299621582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [9:26:07<2:06:03, 420.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2307.969919512349
INFO:root:current train perplexity6.251473426818848
INFO:root:current mean train loss 2311.190153922442
INFO:root:current train perplexity6.245303153991699
INFO:root:current mean train loss 2308.7452359248346
INFO:root:current train perplexity6.224474906921387
INFO:root:current mean train loss 2314.2974822454476
INFO:root:current train perplexity6.225013732910156
INFO:root:current mean train loss 2304.447824969495
INFO:root:current train perplexity6.200187683105469
INFO:root:current mean train loss 2302.9163244031934
INFO:root:current train perplexity6.181061744689941
INFO:root:current mean train loss 2305.553559978975
INFO:root:current train perplexity6.182893753051758
INFO:root:current mean train loss 2310.1627625204424
INFO:root:current train perplexity6.192967891693115
INFO:root:current mean train loss 2310.652295632699
INFO:root:current train perplexity6.191882133483887
INFO:root:current mean train loss 2310.678310920585
INFO:root:current train perplexity6.185032844543457
INFO:root:current mean train loss 2311.0786959272073
INFO:root:current train perplexity6.184033393859863
INFO:root:current mean train loss 2308.1853974846763
INFO:root:current train perplexity6.175177097320557
INFO:root:current mean train loss 2308.3620811279484
INFO:root:current train perplexity6.179442882537842
INFO:root:current mean train loss 2308.8057220743785
INFO:root:current train perplexity6.182086944580078
INFO:root:current mean train loss 2309.60956836657
INFO:root:current train perplexity6.18431282043457
INFO:root:current mean train loss 2311.3794933062863
INFO:root:current train perplexity6.187519073486328
INFO:root:current mean train loss 2310.2129586180918
INFO:root:current train perplexity6.180914402008057
INFO:root:current mean train loss 2310.8854071579362
INFO:root:current train perplexity6.181327819824219
INFO:root:current mean train loss 2309.218162282711
INFO:root:current train perplexity6.176780700683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.94s/it]
INFO:root:final mean train loss: 2308.212249802028
INFO:root:final train perplexity: 6.174297332763672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 2180.073007570091
INFO:root:eval perplexity: 5.830571174621582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 2613.420298907774
INFO:root:eval perplexity: 8.476746559143066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [9:32:51<1:57:43, 415.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2396.885693359375
INFO:root:current train perplexity6.528853416442871
INFO:root:current mean train loss 2286.68329856179
INFO:root:current train perplexity6.106287956237793
INFO:root:current mean train loss 2281.7720999581475
INFO:root:current train perplexity6.084164142608643
INFO:root:current mean train loss 2290.7036412392895
INFO:root:current train perplexity6.123343467712402
INFO:root:current mean train loss 2297.216193371284
INFO:root:current train perplexity6.138636112213135
INFO:root:current mean train loss 2297.2343410117956
INFO:root:current train perplexity6.144529342651367
INFO:root:current mean train loss 2306.445747350474
INFO:root:current train perplexity6.1705451011657715
INFO:root:current mean train loss 2307.7766082333846
INFO:root:current train perplexity6.173412799835205
INFO:root:current mean train loss 2307.7441046067224
INFO:root:current train perplexity6.170228481292725
INFO:root:current mean train loss 2304.720382791037
INFO:root:current train perplexity6.162235260009766
INFO:root:current mean train loss 2304.394171203009
INFO:root:current train perplexity6.161337852478027
INFO:root:current mean train loss 2307.0800713066583
INFO:root:current train perplexity6.1698174476623535
INFO:root:current mean train loss 2304.840523005714
INFO:root:current train perplexity6.1617960929870605
INFO:root:current mean train loss 2305.2040159269145
INFO:root:current train perplexity6.160886287689209
INFO:root:current mean train loss 2304.150902281416
INFO:root:current train perplexity6.1560444831848145
INFO:root:current mean train loss 2303.292995831824
INFO:root:current train perplexity6.152261257171631
INFO:root:current mean train loss 2302.9815478212345
INFO:root:current train perplexity6.15351676940918
INFO:root:current mean train loss 2303.2577498943483
INFO:root:current train perplexity6.151952266693115
INFO:root:current mean train loss 2303.6394083434047
INFO:root:current train perplexity6.150748252868652
INFO:root:current mean train loss 2303.772996896474
INFO:root:current train perplexity6.146930694580078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.97s/it]
INFO:root:final mean train loss: 2303.170893882178
INFO:root:final train perplexity: 6.149797439575195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it]
INFO:root:eval mean loss: 2169.4617880963265
INFO:root:eval perplexity: 5.780749797821045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 2602.8286284318206
INFO:root:eval perplexity: 8.403637886047363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [9:39:54<1:51:21, 417.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2282.842095269097
INFO:root:current train perplexity6.135382175445557
INFO:root:current mean train loss 2267.5799041507753
INFO:root:current train perplexity6.03805685043335
INFO:root:current mean train loss 2292.670302067559
INFO:root:current train perplexity6.103140354156494
INFO:root:current mean train loss 2286.2232580155774
INFO:root:current train perplexity6.107609272003174
INFO:root:current mean train loss 2287.2991337296
INFO:root:current train perplexity6.112279415130615
INFO:root:current mean train loss 2289.098711335908
INFO:root:current train perplexity6.117817401885986
INFO:root:current mean train loss 2291.2194687936103
INFO:root:current train perplexity6.12415885925293
INFO:root:current mean train loss 2294.8491521570345
INFO:root:current train perplexity6.122860431671143
INFO:root:current mean train loss 2297.3839703228914
INFO:root:current train perplexity6.13258171081543
INFO:root:current mean train loss 2296.2775924995367
INFO:root:current train perplexity6.132994651794434
INFO:root:current mean train loss 2296.0599476963775
INFO:root:current train perplexity6.125947952270508
INFO:root:current mean train loss 2294.9570470639
INFO:root:current train perplexity6.124518394470215
INFO:root:current mean train loss 2295.0621735837854
INFO:root:current train perplexity6.125499725341797
INFO:root:current mean train loss 2295.379555881158
INFO:root:current train perplexity6.125409126281738
INFO:root:current mean train loss 2295.0565897267265
INFO:root:current train perplexity6.12209415435791
INFO:root:current mean train loss 2296.93541233385
INFO:root:current train perplexity6.123691558837891
INFO:root:current mean train loss 2296.5948742923374
INFO:root:current train perplexity6.1248555183410645
INFO:root:current mean train loss 2297.317112094899
INFO:root:current train perplexity6.125154972076416
INFO:root:current mean train loss 2297.1844114273313
INFO:root:current train perplexity6.124803066253662
INFO:root:current mean train loss 2296.6142144195765
INFO:root:current train perplexity6.123395919799805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.18s/it]
INFO:root:final mean train loss: 2297.7174183378543
INFO:root:final train perplexity: 6.1234049797058105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 2166.0887594020114
INFO:root:eval perplexity: 5.765002250671387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 2599.6134712814437
INFO:root:eval perplexity: 8.381571769714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [9:46:46<1:44:02, 416.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2266.288271817294
INFO:root:current train perplexity6.046928405761719
INFO:root:current mean train loss 2268.5466384887695
INFO:root:current train perplexity6.070466995239258
INFO:root:current mean train loss 2272.8442998166943
INFO:root:current train perplexity6.070422172546387
INFO:root:current mean train loss 2277.222562568132
INFO:root:current train perplexity6.070327281951904
INFO:root:current mean train loss 2285.1589163015556
INFO:root:current train perplexity6.090203762054443
INFO:root:current mean train loss 2291.273073757396
INFO:root:current train perplexity6.106864929199219
INFO:root:current mean train loss 2290.237624648195
INFO:root:current train perplexity6.099678039550781
INFO:root:current mean train loss 2289.937842092206
INFO:root:current train perplexity6.099064350128174
INFO:root:current mean train loss 2290.712902051013
INFO:root:current train perplexity6.0955610275268555
INFO:root:current mean train loss 2290.068434117204
INFO:root:current train perplexity6.0946125984191895
INFO:root:current mean train loss 2293.9988690957257
INFO:root:current train perplexity6.101312160491943
INFO:root:current mean train loss 2290.908104956567
INFO:root:current train perplexity6.091408729553223
INFO:root:current mean train loss 2290.3601500091063
INFO:root:current train perplexity6.091211318969727
INFO:root:current mean train loss 2290.3202780768984
INFO:root:current train perplexity6.0938825607299805
INFO:root:current mean train loss 2291.014104446876
INFO:root:current train perplexity6.098383903503418
INFO:root:current mean train loss 2290.8142348373494
INFO:root:current train perplexity6.094902515411377
INFO:root:current mean train loss 2291.982592060618
INFO:root:current train perplexity6.1002044677734375
INFO:root:current mean train loss 2293.234488041029
INFO:root:current train perplexity6.1017303466796875
INFO:root:current mean train loss 2294.583626836086
INFO:root:current train perplexity6.105513095855713
INFO:root:current mean train loss 2295.025998213654
INFO:root:current train perplexity6.107623100280762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.22s/it]
INFO:root:final mean train loss: 2294.1097281913353
INFO:root:final train perplexity: 6.106006145477295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 2169.697463448166
INFO:root:eval perplexity: 5.781850337982178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2601.969233086769
INFO:root:eval perplexity: 8.397733688354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [9:53:30<1:36:14, 412.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2317.228587666496
INFO:root:current train perplexity6.161081314086914
INFO:root:current mean train loss 2294.366398971273
INFO:root:current train perplexity6.073054790496826
INFO:root:current mean train loss 2289.315859973659
INFO:root:current train perplexity6.076203346252441
INFO:root:current mean train loss 2286.3596319901317
INFO:root:current train perplexity6.072227954864502
INFO:root:current mean train loss 2287.1053612433907
INFO:root:current train perplexity6.075174808502197
INFO:root:current mean train loss 2287.5975080683907
INFO:root:current train perplexity6.072109222412109
INFO:root:current mean train loss 2288.585601760472
INFO:root:current train perplexity6.074600696563721
INFO:root:current mean train loss 2291.308369499938
INFO:root:current train perplexity6.083948135375977
INFO:root:current mean train loss 2292.1387301454974
INFO:root:current train perplexity6.088909149169922
INFO:root:current mean train loss 2293.914238809671
INFO:root:current train perplexity6.094003200531006
INFO:root:current mean train loss 2294.51695603812
INFO:root:current train perplexity6.09624719619751
INFO:root:current mean train loss 2293.2963751530874
INFO:root:current train perplexity6.0980072021484375
INFO:root:current mean train loss 2294.4112838273195
INFO:root:current train perplexity6.099281311035156
INFO:root:current mean train loss 2292.7466230203263
INFO:root:current train perplexity6.098197937011719
INFO:root:current mean train loss 2292.714665448804
INFO:root:current train perplexity6.095858097076416
INFO:root:current mean train loss 2292.9659235365953
INFO:root:current train perplexity6.09575080871582
INFO:root:current mean train loss 2292.290258803761
INFO:root:current train perplexity6.09467887878418
INFO:root:current mean train loss 2292.649345714216
INFO:root:current train perplexity6.095823287963867
INFO:root:current mean train loss 2291.832309827441
INFO:root:current train perplexity6.092991352081299
INFO:root:current mean train loss 2291.0530381501785
INFO:root:current train perplexity6.090625286102295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.56s/it]
INFO:root:final mean train loss: 2290.986655677261
INFO:root:final train perplexity: 6.0909857749938965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 2161.999226888021
INFO:root:eval perplexity: 5.74596643447876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 2593.308600675975
INFO:root:eval perplexity: 8.338462829589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [10:00:29<1:29:47, 414.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2316.832363030849
INFO:root:current train perplexity6.196830749511719
INFO:root:current mean train loss 2313.0601333446716
INFO:root:current train perplexity6.157264709472656
INFO:root:current mean train loss 2302.7063985042437
INFO:root:current train perplexity6.115747928619385
INFO:root:current mean train loss 2300.7593474211517
INFO:root:current train perplexity6.1014628410339355
INFO:root:current mean train loss 2298.765884974013
INFO:root:current train perplexity6.105793476104736
INFO:root:current mean train loss 2295.612953265233
INFO:root:current train perplexity6.093826770782471
INFO:root:current mean train loss 2292.7710303022445
INFO:root:current train perplexity6.089942932128906
INFO:root:current mean train loss 2295.1500884303705
INFO:root:current train perplexity6.0987677574157715
INFO:root:current mean train loss 2295.6949298832574
INFO:root:current train perplexity6.102615833282471
INFO:root:current mean train loss 2296.83095595783
INFO:root:current train perplexity6.101328372955322
INFO:root:current mean train loss 2295.566673830843
INFO:root:current train perplexity6.099240303039551
INFO:root:current mean train loss 2294.6372488957713
INFO:root:current train perplexity6.098865032196045
INFO:root:current mean train loss 2296.415636901378
INFO:root:current train perplexity6.101764678955078
INFO:root:current mean train loss 2295.80448038796
INFO:root:current train perplexity6.102728366851807
INFO:root:current mean train loss 2295.484177771376
INFO:root:current train perplexity6.099775791168213
INFO:root:current mean train loss 2293.1051733986355
INFO:root:current train perplexity6.091915130615234
INFO:root:current mean train loss 2290.7969595326003
INFO:root:current train perplexity6.083384990692139
INFO:root:current mean train loss 2291.3319289526066
INFO:root:current train perplexity6.086996078491211
INFO:root:current mean train loss 2291.5406060589517
INFO:root:current train perplexity6.089016914367676
INFO:root:current mean train loss 2290.0409052186355
INFO:root:current train perplexity6.0836896896362305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.32s/it]
INFO:root:final mean train loss: 2289.413903987113
INFO:root:final train perplexity: 6.083436012268066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 2161.3357942188886
INFO:root:eval perplexity: 5.742884159088135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 2592.8001553149934
INFO:root:eval perplexity: 8.334997177124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [10:07:24<1:22:53, 414.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2272.400232576069
INFO:root:current train perplexity5.991875171661377
INFO:root:current mean train loss 2267.595037059295
INFO:root:current train perplexity5.992948055267334
INFO:root:current mean train loss 2268.3792695643538
INFO:root:current train perplexity5.9992499351501465
INFO:root:current mean train loss 2269.74172425089
INFO:root:current train perplexity6.008152484893799
INFO:root:current mean train loss 2274.485866230666
INFO:root:current train perplexity6.035885334014893
INFO:root:current mean train loss 2277.0152546858585
INFO:root:current train perplexity6.044963359832764
INFO:root:current mean train loss 2278.213374866513
INFO:root:current train perplexity6.048279285430908
INFO:root:current mean train loss 2277.1041431738895
INFO:root:current train perplexity6.050405025482178
INFO:root:current mean train loss 2277.962885305735
INFO:root:current train perplexity6.052281379699707
INFO:root:current mean train loss 2283.0231543459486
INFO:root:current train perplexity6.063239097595215
INFO:root:current mean train loss 2284.88742787261
INFO:root:current train perplexity6.067014694213867
INFO:root:current mean train loss 2285.211704040272
INFO:root:current train perplexity6.069162368774414
INFO:root:current mean train loss 2285.403532686565
INFO:root:current train perplexity6.064759254455566
INFO:root:current mean train loss 2285.7983884093583
INFO:root:current train perplexity6.064233303070068
INFO:root:current mean train loss 2286.127804106135
INFO:root:current train perplexity6.065884590148926
INFO:root:current mean train loss 2285.220556104893
INFO:root:current train perplexity6.061397075653076
INFO:root:current mean train loss 2285.541327822525
INFO:root:current train perplexity6.061750411987305
INFO:root:current mean train loss 2284.0778788872085
INFO:root:current train perplexity6.058894634246826
INFO:root:current mean train loss 2283.9421758405138
INFO:root:current train perplexity6.0566558837890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.77s/it]
INFO:root:final mean train loss: 2284.622747270254
INFO:root:final train perplexity: 6.060492038726807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2162.3888826843695
INFO:root:eval perplexity: 5.747778415679932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2595.721158940741
INFO:root:eval perplexity: 8.354930877685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [10:14:09<1:15:27, 411.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2387.342732747396
INFO:root:current train perplexity6.55703067779541
INFO:root:current mean train loss 2309.3428998674667
INFO:root:current train perplexity6.143180847167969
INFO:root:current mean train loss 2292.124275639372
INFO:root:current train perplexity6.061663627624512
INFO:root:current mean train loss 2289.7999549278848
INFO:root:current train perplexity6.0568342208862305
INFO:root:current mean train loss 2282.1340927568453
INFO:root:current train perplexity6.033125400543213
INFO:root:current mean train loss 2277.4815545082092
INFO:root:current train perplexity6.030264377593994
INFO:root:current mean train loss 2276.56199017693
INFO:root:current train perplexity6.019964694976807
INFO:root:current mean train loss 2278.8878376135667
INFO:root:current train perplexity6.024723052978516
INFO:root:current mean train loss 2280.8125715584592
INFO:root:current train perplexity6.032616138458252
INFO:root:current mean train loss 2282.0001068115234
INFO:root:current train perplexity6.036280632019043
INFO:root:current mean train loss 2283.1939352284307
INFO:root:current train perplexity6.039953708648682
INFO:root:current mean train loss 2283.626429386276
INFO:root:current train perplexity6.0392279624938965
INFO:root:current mean train loss 2284.204524376998
INFO:root:current train perplexity6.042435646057129
INFO:root:current mean train loss 2284.4069306908586
INFO:root:current train perplexity6.044158458709717
INFO:root:current mean train loss 2284.301739484663
INFO:root:current train perplexity6.043970108032227
INFO:root:current mean train loss 2283.953720012039
INFO:root:current train perplexity6.042647838592529
INFO:root:current mean train loss 2281.867406120963
INFO:root:current train perplexity6.037084579467773
INFO:root:current mean train loss 2281.4273645989247
INFO:root:current train perplexity6.038453578948975
INFO:root:current mean train loss 2282.652621372383
INFO:root:current train perplexity6.041670322418213
INFO:root:current mean train loss 2281.850718733656
INFO:root:current train perplexity6.042420864105225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.18s/it]
INFO:root:final mean train loss: 2280.83061380622
INFO:root:final train perplexity: 6.042393684387207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2159.829720138658
INFO:root:eval perplexity: 5.735893726348877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2592.931406007591
INFO:root:eval perplexity: 8.335892677307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [10:21:08<1:09:00, 414.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2263.441027411099
INFO:root:current train perplexity6.072296619415283
INFO:root:current mean train loss 2282.475954987282
INFO:root:current train perplexity6.047680854797363
INFO:root:current mean train loss 2281.71247377354
INFO:root:current train perplexity6.036083221435547
INFO:root:current mean train loss 2273.5404564761825
INFO:root:current train perplexity6.017199993133545
INFO:root:current mean train loss 2273.602188217056
INFO:root:current train perplexity5.999769687652588
INFO:root:current mean train loss 2272.025055335465
INFO:root:current train perplexity5.997786998748779
INFO:root:current mean train loss 2274.6343056780356
INFO:root:current train perplexity6.005834579467773
INFO:root:current mean train loss 2277.6998590749313
INFO:root:current train perplexity6.029807090759277
INFO:root:current mean train loss 2278.2011433084854
INFO:root:current train perplexity6.0332159996032715
INFO:root:current mean train loss 2277.7528815952132
INFO:root:current train perplexity6.033423900604248
INFO:root:current mean train loss 2277.0729785915482
INFO:root:current train perplexity6.030593395233154
INFO:root:current mean train loss 2276.4126127934014
INFO:root:current train perplexity6.037247657775879
INFO:root:current mean train loss 2279.966398582117
INFO:root:current train perplexity6.045260906219482
INFO:root:current mean train loss 2281.1954950084355
INFO:root:current train perplexity6.047337532043457
INFO:root:current mean train loss 2282.0272243278187
INFO:root:current train perplexity6.048374652862549
INFO:root:current mean train loss 2280.8160455477946
INFO:root:current train perplexity6.045730113983154
INFO:root:current mean train loss 2281.6969373315446
INFO:root:current train perplexity6.048033237457275
INFO:root:current mean train loss 2281.5186766166094
INFO:root:current train perplexity6.043704032897949
INFO:root:current mean train loss 2281.233773658548
INFO:root:current train perplexity6.042174816131592
INFO:root:current mean train loss 2281.1319119387676
INFO:root:current train perplexity6.041499137878418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.79s/it]
INFO:root:final mean train loss: 2280.1719210456854
INFO:root:final train perplexity: 6.0392560958862305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 34.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 34.00s/it]
INFO:root:eval mean loss: 2166.6571083880485
INFO:root:eval perplexity: 5.7676520347595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it]
INFO:root:eval mean loss: 2601.405039685838
INFO:root:eval perplexity: 8.393860816955566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [10:28:14<1:02:38, 417.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2252.0494888969088
INFO:root:current train perplexity5.97152042388916
INFO:root:current mean train loss 2279.3457817182148
INFO:root:current train perplexity6.047189712524414
INFO:root:current mean train loss 2287.4710420437946
INFO:root:current train perplexity6.040919303894043
INFO:root:current mean train loss 2283.21568554123
INFO:root:current train perplexity6.040575981140137
INFO:root:current mean train loss 2286.5539643839334
INFO:root:current train perplexity6.04928731918335
INFO:root:current mean train loss 2287.928317003634
INFO:root:current train perplexity6.055960655212402
INFO:root:current mean train loss 2287.0311598644907
INFO:root:current train perplexity6.037350654602051
INFO:root:current mean train loss 2288.315618356495
INFO:root:current train perplexity6.04616641998291
INFO:root:current mean train loss 2287.187600138058
INFO:root:current train perplexity6.043031692504883
INFO:root:current mean train loss 2286.6930868459303
INFO:root:current train perplexity6.03910493850708
INFO:root:current mean train loss 2285.524176807294
INFO:root:current train perplexity6.039363861083984
INFO:root:current mean train loss 2285.6847103844552
INFO:root:current train perplexity6.0437517166137695
INFO:root:current mean train loss 2285.007713648519
INFO:root:current train perplexity6.038667678833008
INFO:root:current mean train loss 2284.2714597976933
INFO:root:current train perplexity6.040929317474365
INFO:root:current mean train loss 2284.7776548351326
INFO:root:current train perplexity6.044023036956787
INFO:root:current mean train loss 2282.5728492884864
INFO:root:current train perplexity6.037507057189941
INFO:root:current mean train loss 2282.099152315865
INFO:root:current train perplexity6.040639400482178
INFO:root:current mean train loss 2281.6141866397747
INFO:root:current train perplexity6.03939151763916
INFO:root:current mean train loss 2281.0321758431446
INFO:root:current train perplexity6.036365985870361
INFO:root:current mean train loss 2280.620693602763
INFO:root:current train perplexity6.038110256195068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it]
INFO:root:final mean train loss: 2279.5041059454584
INFO:root:final train perplexity: 6.036075592041016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2154.9436848958335
INFO:root:eval perplexity: 5.713271141052246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 2588.2110271048036
INFO:root:eval perplexity: 8.3037748336792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [10:35:11<55:39, 417.38s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2272.3411380828375
INFO:root:current train perplexity5.951668739318848
INFO:root:current mean train loss 2276.6574564740704
INFO:root:current train perplexity5.948774337768555
INFO:root:current mean train loss 2281.0287217985087
INFO:root:current train perplexity5.992160320281982
INFO:root:current mean train loss 2278.957120364691
INFO:root:current train perplexity6.000357627868652
INFO:root:current mean train loss 2281.143170021008
INFO:root:current train perplexity6.020174980163574
INFO:root:current mean train loss 2280.9154640319716
INFO:root:current train perplexity6.021936893463135
INFO:root:current mean train loss 2282.1966661364063
INFO:root:current train perplexity6.031081199645996
INFO:root:current mean train loss 2286.2636401975137
INFO:root:current train perplexity6.042014122009277
INFO:root:current mean train loss 2286.0874270972895
INFO:root:current train perplexity6.041560173034668
INFO:root:current mean train loss 2281.3540963146174
INFO:root:current train perplexity6.034311294555664
INFO:root:current mean train loss 2281.8735983158663
INFO:root:current train perplexity6.038839817047119
INFO:root:current mean train loss 2280.4576299508276
INFO:root:current train perplexity6.040026664733887
INFO:root:current mean train loss 2279.285374778089
INFO:root:current train perplexity6.035462379455566
INFO:root:current mean train loss 2279.2474886473715
INFO:root:current train perplexity6.035824298858643
INFO:root:current mean train loss 2279.1874017096184
INFO:root:current train perplexity6.031785011291504
INFO:root:current mean train loss 2279.813817781435
INFO:root:current train perplexity6.036060333251953
INFO:root:current mean train loss 2278.006509144336
INFO:root:current train perplexity6.030077934265137
INFO:root:current mean train loss 2278.3414256095343
INFO:root:current train perplexity6.029117584228516
INFO:root:current mean train loss 2278.2383204985867
INFO:root:current train perplexity6.029168605804443
INFO:root:current mean train loss 2278.543578541892
INFO:root:current train perplexity6.030340671539307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.45s/it]
INFO:root:final mean train loss: 2278.154169941574
INFO:root:final train perplexity: 6.0296525955200195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it]
INFO:root:eval mean loss: 2152.121037909325
INFO:root:eval perplexity: 5.700244903564453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 2584.8730191710993
INFO:root:eval perplexity: 8.281137466430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [10:42:05<48:35, 416.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2243.0290191650392
INFO:root:current train perplexity5.848073959350586
INFO:root:current mean train loss 2264.220886908637
INFO:root:current train perplexity5.941921234130859
INFO:root:current mean train loss 2273.0539494105747
INFO:root:current train perplexity6.004645347595215
INFO:root:current mean train loss 2279.1880229749177
INFO:root:current train perplexity6.020666599273682
INFO:root:current mean train loss 2281.0126790364584
INFO:root:current train perplexity6.025724411010742
INFO:root:current mean train loss 2283.1253495841192
INFO:root:current train perplexity6.035984992980957
INFO:root:current mean train loss 2282.0092466466567
INFO:root:current train perplexity6.023223400115967
INFO:root:current mean train loss 2281.306528101212
INFO:root:current train perplexity6.021205425262451
INFO:root:current mean train loss 2279.461597650701
INFO:root:current train perplexity6.015027046203613
INFO:root:current mean train loss 2278.707816236846
INFO:root:current train perplexity6.015270709991455
INFO:root:current mean train loss 2277.7956181278937
INFO:root:current train perplexity6.013584613800049
INFO:root:current mean train loss 2278.8082183320644
INFO:root:current train perplexity6.022133827209473
INFO:root:current mean train loss 2279.0091690063477
INFO:root:current train perplexity6.019534111022949
INFO:root:current mean train loss 2278.3944033415423
INFO:root:current train perplexity6.0189056396484375
INFO:root:current mean train loss 2280.5636099325643
INFO:root:current train perplexity6.02092981338501
INFO:root:current mean train loss 2280.1937994462023
INFO:root:current train perplexity6.020290374755859
INFO:root:current mean train loss 2278.9313348679316
INFO:root:current train perplexity6.019384860992432
INFO:root:current mean train loss 2278.7846002814476
INFO:root:current train perplexity6.024704933166504
INFO:root:current mean train loss 2278.9177493480925
INFO:root:current train perplexity6.024137496948242
INFO:root:current mean train loss 2276.888065530796
INFO:root:current train perplexity6.020051956176758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.75s/it]
INFO:root:final mean train loss: 2275.977513361867
INFO:root:final train perplexity: 6.019309997558594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 2158.6353365850787
INFO:root:eval perplexity: 5.730355739593506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 2592.2902442445147
INFO:root:eval perplexity: 8.331523895263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [10:49:01<41:37, 416.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2279.4442000241625
INFO:root:current train perplexity6.045901298522949
INFO:root:current mean train loss 2275.9761231708044
INFO:root:current train perplexity6.00389289855957
INFO:root:current mean train loss 2268.494256119134
INFO:root:current train perplexity6.010799407958984
INFO:root:current mean train loss 2264.811078818679
INFO:root:current train perplexity5.989053249359131
INFO:root:current mean train loss 2268.259534256319
INFO:root:current train perplexity5.994931221008301
INFO:root:current mean train loss 2272.913369541392
INFO:root:current train perplexity6.008553504943848
INFO:root:current mean train loss 2273.6515202570167
INFO:root:current train perplexity6.007892608642578
INFO:root:current mean train loss 2275.6716791054832
INFO:root:current train perplexity6.0184326171875
INFO:root:current mean train loss 2274.8430468368956
INFO:root:current train perplexity6.011463165283203
INFO:root:current mean train loss 2271.960823755446
INFO:root:current train perplexity6.004472255706787
INFO:root:current mean train loss 2271.7212798710616
INFO:root:current train perplexity5.999934196472168
INFO:root:current mean train loss 2272.8527147744035
INFO:root:current train perplexity6.004225730895996
INFO:root:current mean train loss 2273.562613882096
INFO:root:current train perplexity6.005430698394775
INFO:root:current mean train loss 2273.0329321586155
INFO:root:current train perplexity6.002770900726318
INFO:root:current mean train loss 2273.613532077175
INFO:root:current train perplexity6.003670692443848
INFO:root:current mean train loss 2272.7379557036875
INFO:root:current train perplexity6.002120018005371
INFO:root:current mean train loss 2272.386908725071
INFO:root:current train perplexity6.004383563995361
INFO:root:current mean train loss 2273.4013021784353
INFO:root:current train perplexity6.005812168121338
INFO:root:current mean train loss 2273.8579429099605
INFO:root:current train perplexity6.005296230316162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.05s/it]
INFO:root:final mean train loss: 2273.8889993964813
INFO:root:final train perplexity: 6.009403705596924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 2153.275372444315
INFO:root:eval perplexity: 5.705569267272949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2586.614108904034
INFO:root:eval perplexity: 8.29293441772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:55:47<34:25, 413.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2190.0298985072545
INFO:root:current train perplexity5.827567100524902
INFO:root:current mean train loss 2250.5171840734647
INFO:root:current train perplexity5.946475028991699
INFO:root:current mean train loss 2258.249382232951
INFO:root:current train perplexity5.962406635284424
INFO:root:current mean train loss 2264.476153914336
INFO:root:current train perplexity5.97986364364624
INFO:root:current mean train loss 2262.1087658278607
INFO:root:current train perplexity5.981464385986328
INFO:root:current mean train loss 2265.2222978762616
INFO:root:current train perplexity5.990747451782227
INFO:root:current mean train loss 2267.016619654354
INFO:root:current train perplexity5.988895893096924
INFO:root:current mean train loss 2269.2894435850512
INFO:root:current train perplexity5.994932651519775
INFO:root:current mean train loss 2269.8446977695025
INFO:root:current train perplexity5.995572090148926
INFO:root:current mean train loss 2269.548650628889
INFO:root:current train perplexity5.996869087219238
INFO:root:current mean train loss 2274.824711967032
INFO:root:current train perplexity6.007787704467773
INFO:root:current mean train loss 2275.8559115562234
INFO:root:current train perplexity6.011479377746582
INFO:root:current mean train loss 2274.5913867227723
INFO:root:current train perplexity6.0105814933776855
INFO:root:current mean train loss 2275.1729232811313
INFO:root:current train perplexity6.011438846588135
INFO:root:current mean train loss 2272.2110174413788
INFO:root:current train perplexity6.002665042877197
INFO:root:current mean train loss 2272.284252736181
INFO:root:current train perplexity6.00509786605835
INFO:root:current mean train loss 2273.2394230687783
INFO:root:current train perplexity6.005673885345459
INFO:root:current mean train loss 2272.3509486586795
INFO:root:current train perplexity6.005007743835449
INFO:root:current mean train loss 2273.333505582126
INFO:root:current train perplexity6.005894660949707
INFO:root:current mean train loss 2272.758823948843
INFO:root:current train perplexity6.004440784454346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.21s/it]
INFO:root:final mean train loss: 2272.979632971567
INFO:root:final train perplexity: 6.005095481872559
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 2157.407467673011
INFO:root:eval perplexity: 5.724666118621826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2590.6806831089316
INFO:root:eval perplexity: 8.320562362670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [11:02:47<27:40, 415.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2264.854259860131
INFO:root:current train perplexity6.020435333251953
INFO:root:current mean train loss 2268.424018219227
INFO:root:current train perplexity6.017890930175781
INFO:root:current mean train loss 2279.6133911661254
INFO:root:current train perplexity6.030371189117432
INFO:root:current mean train loss 2283.5592122149974
INFO:root:current train perplexity6.040822982788086
INFO:root:current mean train loss 2280.2052265353104
INFO:root:current train perplexity6.036245346069336
INFO:root:current mean train loss 2277.55178264036
INFO:root:current train perplexity6.024905204772949
INFO:root:current mean train loss 2280.8923982115443
INFO:root:current train perplexity6.046252250671387
INFO:root:current mean train loss 2279.5878234946777
INFO:root:current train perplexity6.0346293449401855
INFO:root:current mean train loss 2278.205024067389
INFO:root:current train perplexity6.025094985961914
INFO:root:current mean train loss 2274.441297291429
INFO:root:current train perplexity6.016081809997559
INFO:root:current mean train loss 2275.7920403762655
INFO:root:current train perplexity6.020285606384277
INFO:root:current mean train loss 2275.037998081413
INFO:root:current train perplexity6.018397331237793
INFO:root:current mean train loss 2274.218372385256
INFO:root:current train perplexity6.012520790100098
INFO:root:current mean train loss 2274.5037917918858
INFO:root:current train perplexity6.011439323425293
INFO:root:current mean train loss 2273.393840456575
INFO:root:current train perplexity6.008327007293701
INFO:root:current mean train loss 2273.395351616718
INFO:root:current train perplexity6.007549285888672
INFO:root:current mean train loss 2272.0991597880184
INFO:root:current train perplexity6.001927375793457
INFO:root:current mean train loss 2271.4406354651846
INFO:root:current train perplexity6.001436710357666
INFO:root:current mean train loss 2271.5809102165185
INFO:root:current train perplexity5.999942779541016
INFO:root:current mean train loss 2272.4879463942543
INFO:root:current train perplexity6.0027079582214355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.71s/it]
INFO:root:final mean train loss: 2272.7979156447973
INFO:root:final train perplexity: 6.00423526763916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 2152.567486269254
INFO:root:eval perplexity: 5.702302932739258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 2586.1688249736812
INFO:root:eval perplexity: 8.289916038513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [11:09:38<20:41, 413.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2283.620236714681
INFO:root:current train perplexity5.9745659828186035
INFO:root:current mean train loss 2271.716147757865
INFO:root:current train perplexity6.015085220336914
INFO:root:current mean train loss 2270.135772705078
INFO:root:current train perplexity5.989336013793945
INFO:root:current mean train loss 2263.2659442068516
INFO:root:current train perplexity5.9600324630737305
INFO:root:current mean train loss 2270.3979127066477
INFO:root:current train perplexity5.977452754974365
INFO:root:current mean train loss 2272.089667995481
INFO:root:current train perplexity5.983424186706543
INFO:root:current mean train loss 2276.6365855652607
INFO:root:current train perplexity5.99973201751709
INFO:root:current mean train loss 2275.663515141941
INFO:root:current train perplexity6.0018534660339355
INFO:root:current mean train loss 2275.69134118422
INFO:root:current train perplexity5.9967803955078125
INFO:root:current mean train loss 2272.2198114193943
INFO:root:current train perplexity5.987919330596924
INFO:root:current mean train loss 2275.5052108182254
INFO:root:current train perplexity5.993802070617676
INFO:root:current mean train loss 2273.2772336953194
INFO:root:current train perplexity5.992854595184326
INFO:root:current mean train loss 2274.0666143955327
INFO:root:current train perplexity5.992168426513672
INFO:root:current mean train loss 2275.3378683480737
INFO:root:current train perplexity5.998770236968994
INFO:root:current mean train loss 2274.6849129186808
INFO:root:current train perplexity6.001224040985107
INFO:root:current mean train loss 2274.8403192564497
INFO:root:current train perplexity6.003289699554443
INFO:root:current mean train loss 2273.251828758462
INFO:root:current train perplexity6.003640651702881
INFO:root:current mean train loss 2272.5105375032404
INFO:root:current train perplexity5.9999799728393555
INFO:root:current mean train loss 2272.7291018002993
INFO:root:current train perplexity5.9997735023498535
INFO:root:current mean train loss 2272.5141852220227
INFO:root:current train perplexity6.000871181488037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.88s/it]
INFO:root:final mean train loss: 2271.984588238307
INFO:root:final train perplexity: 6.000385761260986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 2148.4482880720857
INFO:root:eval perplexity: 5.6833391189575195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 2581.6453363946143
INFO:root:eval perplexity: 8.259305953979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [11:16:32<13:47, 413.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2256.443201622596
INFO:root:current train perplexity6.019955158233643
INFO:root:current mean train loss 2273.194153941761
INFO:root:current train perplexity5.990232467651367
INFO:root:current mean train loss 2270.3264791236734
INFO:root:current train perplexity6.008584499359131
INFO:root:current mean train loss 2271.178344392123
INFO:root:current train perplexity5.999037265777588
INFO:root:current mean train loss 2270.7878150201614
INFO:root:current train perplexity6.00102424621582
INFO:root:current mean train loss 2274.500423249101
INFO:root:current train perplexity6.004243850708008
INFO:root:current mean train loss 2272.926339285714
INFO:root:current train perplexity6.003352642059326
INFO:root:current mean train loss 2272.56482555913
INFO:root:current train perplexity5.999392032623291
INFO:root:current mean train loss 2273.9516453384663
INFO:root:current train perplexity6.001555919647217
INFO:root:current mean train loss 2274.6234108089784
INFO:root:current train perplexity6.0014328956604
INFO:root:current mean train loss 2272.337235800873
INFO:root:current train perplexity5.991881847381592
INFO:root:current mean train loss 2270.5384113884793
INFO:root:current train perplexity5.990443229675293
INFO:root:current mean train loss 2272.2089883314293
INFO:root:current train perplexity5.992759704589844
INFO:root:current mean train loss 2272.52177957947
INFO:root:current train perplexity5.9940056800842285
INFO:root:current mean train loss 2273.6907771504375
INFO:root:current train perplexity5.9975056648254395
INFO:root:current mean train loss 2274.300371748952
INFO:root:current train perplexity5.999113082885742
INFO:root:current mean train loss 2274.0319132120403
INFO:root:current train perplexity6.000685214996338
INFO:root:current mean train loss 2272.8519796830738
INFO:root:current train perplexity5.9990997314453125
INFO:root:current mean train loss 2273.8804233908972
INFO:root:current train perplexity5.999837875366211
INFO:root:current mean train loss 2272.7330670150486
INFO:root:current train perplexity5.999105930328369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.45s/it]
INFO:root:final mean train loss: 2271.6740477653807
INFO:root:final train perplexity: 5.998915672302246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it]
INFO:root:eval mean loss: 2148.5487463119184
INFO:root:eval perplexity: 5.68380069732666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2582.0367068026926
INFO:root:eval perplexity: 8.261950492858887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [11:23:23<06:53, 413.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2252.3102863590893
INFO:root:current train perplexity6.0009541511535645
INFO:root:current mean train loss 2261.2938312907795
INFO:root:current train perplexity5.99352502822876
INFO:root:current mean train loss 2260.3996452169217
INFO:root:current train perplexity5.995832443237305
INFO:root:current mean train loss 2257.542230576121
INFO:root:current train perplexity5.983654022216797
INFO:root:current mean train loss 2254.3857903065027
INFO:root:current train perplexity5.9640278816223145
INFO:root:current mean train loss 2257.5088746375645
INFO:root:current train perplexity5.969144821166992
INFO:root:current mean train loss 2259.5050018400043
INFO:root:current train perplexity5.972270488739014
INFO:root:current mean train loss 2257.986054013147
INFO:root:current train perplexity5.9595046043396
INFO:root:current mean train loss 2258.778022195206
INFO:root:current train perplexity5.9669389724731445
INFO:root:current mean train loss 2260.4156828528753
INFO:root:current train perplexity5.968715667724609
INFO:root:current mean train loss 2262.9309171158375
INFO:root:current train perplexity5.973401069641113
INFO:root:current mean train loss 2262.989493794449
INFO:root:current train perplexity5.972184181213379
INFO:root:current mean train loss 2264.507012377663
INFO:root:current train perplexity5.978338241577148
INFO:root:current mean train loss 2265.065949678766
INFO:root:current train perplexity5.979285717010498
INFO:root:current mean train loss 2265.4803301235925
INFO:root:current train perplexity5.979648590087891
INFO:root:current mean train loss 2266.8339309788835
INFO:root:current train perplexity5.981993675231934
INFO:root:current mean train loss 2266.168404414736
INFO:root:current train perplexity5.978245735168457
INFO:root:current mean train loss 2266.4357273088963
INFO:root:current train perplexity5.978845119476318
INFO:root:current mean train loss 2268.222967782259
INFO:root:current train perplexity5.984373569488525
INFO:root:current mean train loss 2270.077010415517
INFO:root:current train perplexity5.988664627075195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.68s/it]
INFO:root:final mean train loss: 2269.5521541254966
INFO:root:final train perplexity: 5.988885879516602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it]
INFO:root:eval mean loss: 2147.9613690748283
INFO:root:eval perplexity: 5.681100845336914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 2581.6356556128103
INFO:root:eval perplexity: 8.259241104125977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll6_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:30:30<00:00, 417.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:30:31<00:00, 414.31s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 42.00s/it]
INFO:root:eval mean loss: 2147.9613690748283
INFO:root:eval perplexity: 5.681100845336914
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2581.6356556128103
INFO:root:eval perplexity: 8.259241104125977
INFO:root:evalaution complete
INFO:root:save model final: alll6_alll6_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14742876cf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1474287648e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x147428689e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14742876da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x147428687948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14742876da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x147428642b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x1474280a746a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x1475248c3a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x1475248c3be0]
python(+0x24a989) [0x56179394a989]
python(+0x24a9bd) [0x56179394a9bd]
python(+0x24aa14) [0x56179394aa14]
python(+0x108f75) [0x561793808f75]
python(Py_RunMain+0x313) [0x56179394d983]
python(Py_BytesMain+0x39) [0x56179394dbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x1475248a10b3]
python(+0x1d6e13) [0x5617938d6e13]
/opt/slurm/data/slurmd/job29854442/slurm_script: line 238:  3594 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L6-v2 --data_config data_config.json --data_folder fast_processed_data_opt_allmini --output alll6_alll6_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
