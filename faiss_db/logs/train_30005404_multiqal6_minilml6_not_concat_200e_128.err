INFO:root:Output: multiqal6_minilml6_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23915.899325284092
INFO:root:current train perplexity12531.142578125
INFO:root:current mean train loss 20175.62962763034
INFO:root:current train perplexity2839.693115234375
INFO:root:current mean train loss 17475.94813767245
INFO:root:current train perplexity982.4031372070312
INFO:root:current mean train loss 15650.154142680922
INFO:root:current train perplexity474.3099060058594
INFO:root:current mean train loss 14326.977678012274
INFO:root:current train perplexity281.5375671386719
INFO:root:current mean train loss 13319.03874132669
INFO:root:current train perplexity189.82350158691406
INFO:root:current mean train loss 12534.901910653613
INFO:root:current train perplexity139.33566284179688
INFO:root:current mean train loss 11902.896209373044
INFO:root:current train perplexity108.86590576171875
INFO:root:current mean train loss 11385.217523050786
INFO:root:current train perplexity88.81275939941406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.66s/it]
INFO:root:final mean train loss: 10965.612653916882
INFO:root:final train perplexity: 75.66011047363281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 6457.307565242686
INFO:root:eval perplexity: 13.61463737487793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 6951.6620608931735
INFO:root:eval perplexity: 17.160837173461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/1
  0%|          | 1/200 [07:15<24:05:24, 435.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6869.628696986607
INFO:root:current train perplexity15.171432495117188
INFO:root:current mean train loss 6879.269024715245
INFO:root:current train perplexity14.72463607788086
INFO:root:current mean train loss 6779.841938405797
INFO:root:current train perplexity14.359835624694824
INFO:root:current mean train loss 6690.23937709945
INFO:root:current train perplexity13.961718559265137
INFO:root:current mean train loss 6619.810338125768
INFO:root:current train perplexity13.628179550170898
INFO:root:current mean train loss 6565.071485530695
INFO:root:current train perplexity13.293665885925293
INFO:root:current mean train loss 6511.648072294584
INFO:root:current train perplexity13.0082368850708
INFO:root:current mean train loss 6464.41873881166
INFO:root:current train perplexity12.767396926879883
INFO:root:current mean train loss 6415.916684213329
INFO:root:current train perplexity12.54094409942627
INFO:root:current mean train loss 6368.709027981154
INFO:root:current train perplexity12.321969032287598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.80s/it]
INFO:root:final mean train loss: 6331.659105977705
INFO:root:final train perplexity: 12.158430099487305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.01s/it]
INFO:root:eval mean loss: 5525.1777897828015
INFO:root:eval perplexity: 9.339192390441895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 6127.643118351064
INFO:root:eval perplexity: 12.251852989196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/2
  1%|          | 2/200 [14:38<24:11:19, 439.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5905.084049479166
INFO:root:current train perplexity10.339742660522461
INFO:root:current mean train loss 5808.457612941576
INFO:root:current train perplexity10.041420936584473
INFO:root:current mean train loss 5810.666378997093
INFO:root:current train perplexity9.955589294433594
INFO:root:current mean train loss 5788.654989769345
INFO:root:current train perplexity9.855913162231445
INFO:root:current mean train loss 5775.166845114834
INFO:root:current train perplexity9.775593757629395
INFO:root:current mean train loss 5765.097683745449
INFO:root:current train perplexity9.703676223754883
INFO:root:current mean train loss 5737.583074504573
INFO:root:current train perplexity9.601924896240234
INFO:root:current mean train loss 5712.484876256556
INFO:root:current train perplexity9.519963264465332
INFO:root:current mean train loss 5698.359830329755
INFO:root:current train perplexity9.45571231842041
INFO:root:current mean train loss 5677.946260779542
INFO:root:current train perplexity9.373344421386719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.52s/it]
INFO:root:final mean train loss: 5657.420496540685
INFO:root:final train perplexity: 9.318634033203125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it]
INFO:root:eval mean loss: 5139.26013962766
INFO:root:eval perplexity: 7.989802360534668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it]
INFO:root:eval mean loss: 5795.557340148493
INFO:root:eval perplexity: 10.696141242980957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/3
  2%|â–         | 3/200 [21:57<24:02:47, 439.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5555.084217900815
INFO:root:current train perplexity8.650715827941895
INFO:root:current mean train loss 5450.4084690993395
INFO:root:current train perplexity8.55936336517334
INFO:root:current mean train loss 5434.440856659893
INFO:root:current train perplexity8.525471687316895
INFO:root:current mean train loss 5410.233294129741
INFO:root:current train perplexity8.443338394165039
INFO:root:current mean train loss 5403.791753241357
INFO:root:current train perplexity8.392833709716797
INFO:root:current mean train loss 5382.843717323434
INFO:root:current train perplexity8.334309577941895
INFO:root:current mean train loss 5373.639903942616
INFO:root:current train perplexity8.295710563659668
INFO:root:current mean train loss 5359.148078886799
INFO:root:current train perplexity8.256927490234375
INFO:root:current mean train loss 5340.382611373216
INFO:root:current train perplexity8.218710899353027
INFO:root:current mean train loss 5327.510569199451
INFO:root:current train perplexity8.170805931091309

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:16<00:00, 376.95s/it]
INFO:root:final mean train loss: 5314.926248488888
INFO:root:final train perplexity: 8.14083194732666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it]
INFO:root:eval mean loss: 4893.657174617686
INFO:root:eval perplexity: 7.234428882598877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 5586.883543190381
INFO:root:eval perplexity: 9.821300506591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/4
  2%|â–         | 4/200 [29:16<23:54:55, 439.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5125.011466733871
INFO:root:current train perplexity7.6205549240112305
INFO:root:current mean train loss 5147.662172739742
INFO:root:current train perplexity7.633353233337402
INFO:root:current mean train loss 5139.630221015963
INFO:root:current train perplexity7.620658874511719
INFO:root:current mean train loss 5144.91551849273
INFO:root:current train perplexity7.611893653869629
INFO:root:current mean train loss 5143.663859710339
INFO:root:current train perplexity7.591089725494385
INFO:root:current mean train loss 5124.200638535782
INFO:root:current train perplexity7.547347068786621
INFO:root:current mean train loss 5115.640604106825
INFO:root:current train perplexity7.5235137939453125
INFO:root:current mean train loss 5113.632765074598
INFO:root:current train perplexity7.508044242858887
INFO:root:current mean train loss 5099.850209884552
INFO:root:current train perplexity7.470835208892822
INFO:root:current mean train loss 5091.753747335694
INFO:root:current train perplexity7.447552680969238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.73s/it]
INFO:root:final mean train loss: 5085.564394181774
INFO:root:final train perplexity: 7.436514377593994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 4763.392997146499
INFO:root:eval perplexity: 6.863216400146484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it]
INFO:root:eval mean loss: 5477.805473598182
INFO:root:eval perplexity: 9.392861366271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/5
  2%|â–Ž         | 5/200 [36:34<23:46:44, 439.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5066.99114833734
INFO:root:current train perplexity7.266872882843018
INFO:root:current mean train loss 4986.9677523606115
INFO:root:current train perplexity7.122165203094482
INFO:root:current mean train loss 4979.598475500131
INFO:root:current train perplexity7.091270923614502
INFO:root:current mean train loss 4963.500700013828
INFO:root:current train perplexity7.068971157073975
INFO:root:current mean train loss 4954.864157709282
INFO:root:current train perplexity7.053603649139404
INFO:root:current mean train loss 4948.834599482549
INFO:root:current train perplexity7.0316619873046875
INFO:root:current mean train loss 4939.606585148915
INFO:root:current train perplexity7.011112689971924
INFO:root:current mean train loss 4931.352435327512
INFO:root:current train perplexity6.992669582366943
INFO:root:current mean train loss 4923.86734405263
INFO:root:current train perplexity6.972992897033691
INFO:root:current mean train loss 4913.718677199814
INFO:root:current train perplexity6.945178985595703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.37s/it]
INFO:root:final mean train loss: 4912.166313048332
INFO:root:final train perplexity: 6.944789886474609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it]
INFO:root:eval mean loss: 4577.196394683621
INFO:root:eval perplexity: 6.365444660186768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 5314.859491010085
INFO:root:eval perplexity: 8.787400245666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/6
  3%|â–Ž         | 6/200 [43:50<23:35:58, 437.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4854.725367769282
INFO:root:current train perplexity6.7227630615234375
INFO:root:current mean train loss 4796.002840003189
INFO:root:current train perplexity6.641392230987549
INFO:root:current mean train loss 4803.792551635248
INFO:root:current train perplexity6.66303014755249
INFO:root:current mean train loss 4816.154059066553
INFO:root:current train perplexity6.658166408538818
INFO:root:current mean train loss 4817.5051285916525
INFO:root:current train perplexity6.665163516998291
INFO:root:current mean train loss 4804.237915262226
INFO:root:current train perplexity6.640192985534668
INFO:root:current mean train loss 4795.4983736536415
INFO:root:current train perplexity6.630496025085449
INFO:root:current mean train loss 4794.464905847348
INFO:root:current train perplexity6.619382858276367
INFO:root:current mean train loss 4789.288694127251
INFO:root:current train perplexity6.6061811447143555
INFO:root:current mean train loss 4781.502245990629
INFO:root:current train perplexity6.586069583892822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.97s/it]
INFO:root:final mean train loss: 4778.110886789137
INFO:root:final train perplexity: 6.587034225463867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 4471.410395196143
INFO:root:eval perplexity: 6.0988922119140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 5225.917525487589
INFO:root:eval perplexity: 8.473549842834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/7
  4%|â–Ž         | 7/200 [51:06<23:25:57, 437.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4698.537420099432
INFO:root:current train perplexity6.36574125289917
INFO:root:current mean train loss 4693.977496534778
INFO:root:current train perplexity6.381803035736084
INFO:root:current mean train loss 4688.261949486826
INFO:root:current train perplexity6.37705135345459
INFO:root:current mean train loss 4687.058836515185
INFO:root:current train perplexity6.373330593109131
INFO:root:current mean train loss 4688.822237186641
INFO:root:current train perplexity6.3673882484436035
INFO:root:current mean train loss 4684.221790980434
INFO:root:current train perplexity6.358928203582764
INFO:root:current mean train loss 4683.056259318344
INFO:root:current train perplexity6.3535966873168945
INFO:root:current mean train loss 4680.938937034354
INFO:root:current train perplexity6.343481540679932
INFO:root:current mean train loss 4686.183478389986
INFO:root:current train perplexity6.347532749176025
INFO:root:current mean train loss 4682.579176210733
INFO:root:current train perplexity6.337581157684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.82s/it]
INFO:root:final mean train loss: 4680.717361450195
INFO:root:final train perplexity: 6.3387298583984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 4404.7032098431955
INFO:root:eval perplexity: 5.936577796936035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it]
INFO:root:eval mean loss: 5164.91238295102
INFO:root:eval perplexity: 8.264781951904297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/8
  4%|â–         | 8/200 [58:18<23:14:11, 435.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4624.755766369048
INFO:root:current train perplexity6.146477222442627
INFO:root:current mean train loss 4640.164227257477
INFO:root:current train perplexity6.200461387634277
INFO:root:current mean train loss 4648.032661931143
INFO:root:current train perplexity6.216159343719482
INFO:root:current mean train loss 4651.346424785856
INFO:root:current train perplexity6.233529567718506
INFO:root:current mean train loss 4646.8986394565
INFO:root:current train perplexity6.217445373535156
INFO:root:current mean train loss 4636.890334026005
INFO:root:current train perplexity6.209329605102539
INFO:root:current mean train loss 4636.7975632335265
INFO:root:current train perplexity6.217666149139404
INFO:root:current mean train loss 4633.441017480853
INFO:root:current train perplexity6.2110419273376465
INFO:root:current mean train loss 4630.142730606804
INFO:root:current train perplexity6.206353187561035
INFO:root:current mean train loss 4628.587708089954
INFO:root:current train perplexity6.2026495933532715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.59s/it]
INFO:root:final mean train loss: 4625.337774953535
INFO:root:final train perplexity: 6.201737880706787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it]
INFO:root:eval mean loss: 4342.563015985151
INFO:root:eval perplexity: 5.789262771606445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 5113.271742367575
INFO:root:eval perplexity: 8.09208869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/9
  4%|â–         | 9/200 [1:05:36<23:09:14, 436.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4596.203200649208
INFO:root:current train perplexity6.124101161956787
INFO:root:current mean train loss 4583.415618718019
INFO:root:current train perplexity6.092745780944824
INFO:root:current mean train loss 4572.167318308925
INFO:root:current train perplexity6.086987495422363
INFO:root:current mean train loss 4559.438961553445
INFO:root:current train perplexity6.064110279083252
INFO:root:current mean train loss 4568.7784566373075
INFO:root:current train perplexity6.064570903778076
INFO:root:current mean train loss 4558.6518601719845
INFO:root:current train perplexity6.054067611694336
INFO:root:current mean train loss 4556.536242330128
INFO:root:current train perplexity6.0525288581848145
INFO:root:current mean train loss 4555.511181387302
INFO:root:current train perplexity6.036874294281006
INFO:root:current mean train loss 4558.9354033617965
INFO:root:current train perplexity6.040299892425537
INFO:root:current mean train loss 4560.396384556433
INFO:root:current train perplexity6.038389205932617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.57s/it]
INFO:root:final mean train loss: 4558.410204610517
INFO:root:final train perplexity: 6.040124893188477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it]
INFO:root:eval mean loss: 4308.448524420988
INFO:root:eval perplexity: 5.709949493408203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it]
INFO:root:eval mean loss: 5088.380779726285
INFO:root:eval perplexity: 8.010144233703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/10
  5%|â–Œ         | 10/200 [1:12:52<23:01:14, 436.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4513.821681541733
INFO:root:current train perplexity5.885716915130615
INFO:root:current mean train loss 4503.774324044169
INFO:root:current train perplexity5.889314651489258
INFO:root:current mean train loss 4498.071193681396
INFO:root:current train perplexity5.892541408538818
INFO:root:current mean train loss 4496.909293705681
INFO:root:current train perplexity5.881248950958252
INFO:root:current mean train loss 4502.056281294853
INFO:root:current train perplexity5.890566825866699
INFO:root:current mean train loss 4500.944843615069
INFO:root:current train perplexity5.8879714012146
INFO:root:current mean train loss 4498.513273483523
INFO:root:current train perplexity5.886650562286377
INFO:root:current mean train loss 4495.7820466694075
INFO:root:current train perplexity5.881894111633301
INFO:root:current mean train loss 4494.254636727638
INFO:root:current train perplexity5.878637313842773
INFO:root:current mean train loss 4489.641966651238
INFO:root:current train perplexity5.870100021362305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.57s/it]
INFO:root:final mean train loss: 4487.1747398376465
INFO:root:final train perplexity: 5.872734069824219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it]
INFO:root:eval mean loss: 4232.49962599734
INFO:root:eval perplexity: 5.537253379821777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 5022.468446988586
INFO:root:eval perplexity: 7.797133922576904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/11
  6%|â–Œ         | 11/200 [1:20:05<22:50:37, 435.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4429.965360093391
INFO:root:current train perplexity5.782252311706543
INFO:root:current mean train loss 4437.326238458807
INFO:root:current train perplexity5.775583744049072
INFO:root:current mean train loss 4433.2398047895795
INFO:root:current train perplexity5.760056972503662
INFO:root:current mean train loss 4426.778272367571
INFO:root:current train perplexity5.745568752288818
INFO:root:current mean train loss 4425.357168710697
INFO:root:current train perplexity5.738668918609619
INFO:root:current mean train loss 4430.8586113846895
INFO:root:current train perplexity5.736292839050293
INFO:root:current mean train loss 4433.165856773677
INFO:root:current train perplexity5.743257999420166
INFO:root:current mean train loss 4432.745272606119
INFO:root:current train perplexity5.742727279663086
INFO:root:current mean train loss 4428.775921293686
INFO:root:current train perplexity5.732828617095947
INFO:root:current mean train loss 4426.386615849798
INFO:root:current train perplexity5.725463390350342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.79s/it]
INFO:root:final mean train loss: 4422.778958228327
INFO:root:final train perplexity: 5.725411415100098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 4186.588352933843
INFO:root:eval perplexity: 5.4354023933410645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4986.714803925643
INFO:root:eval perplexity: 7.683968544006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/12
  6%|â–Œ         | 12/200 [1:27:19<22:43:02, 435.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4378.4083855879935
INFO:root:current train perplexity5.6559929847717285
INFO:root:current mean train loss 4370.688490334535
INFO:root:current train perplexity5.635921955108643
INFO:root:current mean train loss 4373.117444054555
INFO:root:current train perplexity5.620891571044922
INFO:root:current mean train loss 4373.052238058742
INFO:root:current train perplexity5.613581657409668
INFO:root:current mean train loss 4371.101344992898
INFO:root:current train perplexity5.611943244934082
INFO:root:current mean train loss 4374.931305393251
INFO:root:current train perplexity5.609182834625244
INFO:root:current mean train loss 4370.644240037657
INFO:root:current train perplexity5.606581211090088
INFO:root:current mean train loss 4368.7057844437895
INFO:root:current train perplexity5.603959083557129
INFO:root:current mean train loss 4369.293300181128
INFO:root:current train perplexity5.603579521179199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it]
INFO:root:final mean train loss: 4369.969267568281
INFO:root:final train perplexity: 5.60735559463501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 4155.034345910904
INFO:root:eval perplexity: 5.366488933563232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 4963.923611688276
INFO:root:eval perplexity: 7.612690448760986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/13
  6%|â–‹         | 13/200 [1:34:34<22:35:16, 434.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4476.9853515625
INFO:root:current train perplexity5.702408313751221
INFO:root:current mean train loss 4347.700875587834
INFO:root:current train perplexity5.5339508056640625
INFO:root:current mean train loss 4335.685142780172
INFO:root:current train perplexity5.514164924621582
INFO:root:current mean train loss 4329.492285800846
INFO:root:current train perplexity5.514161586761475
INFO:root:current mean train loss 4331.6879319411055
INFO:root:current train perplexity5.514394760131836
INFO:root:current mean train loss 4335.031235438929
INFO:root:current train perplexity5.527125835418701
INFO:root:current mean train loss 4331.372845651301
INFO:root:current train perplexity5.521697044372559
INFO:root:current mean train loss 4326.636299230974
INFO:root:current train perplexity5.515301704406738
INFO:root:current mean train loss 4327.191830379728
INFO:root:current train perplexity5.512851238250732
INFO:root:current mean train loss 4325.952227384413
INFO:root:current train perplexity5.505788326263428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.44s/it]
INFO:root:final mean train loss: 4322.191786673761
INFO:root:final train perplexity: 5.502649307250977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 4116.085513284021
INFO:root:eval perplexity: 5.2826313972473145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4930.719600163453
INFO:root:eval perplexity: 7.510025978088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/14
  7%|â–‹         | 14/200 [1:41:49<22:28:00, 434.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4390.402476917614
INFO:root:current train perplexity5.462667465209961
INFO:root:current mean train loss 4298.16332787866
INFO:root:current train perplexity5.443160057067871
INFO:root:current mean train loss 4291.78586205939
INFO:root:current train perplexity5.433404922485352
INFO:root:current mean train loss 4294.133142992615
INFO:root:current train perplexity5.432894229888916
INFO:root:current mean train loss 4277.204558360896
INFO:root:current train perplexity5.408944606781006
INFO:root:current mean train loss 4281.944725320297
INFO:root:current train perplexity5.4106764793396
INFO:root:current mean train loss 4281.739226246036
INFO:root:current train perplexity5.412210464477539
INFO:root:current mean train loss 4283.485378002483
INFO:root:current train perplexity5.411419868469238
INFO:root:current mean train loss 4283.508759259884
INFO:root:current train perplexity5.409228801727295
INFO:root:current mean train loss 4285.840622534474
INFO:root:current train perplexity5.414646148681641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.35s/it]
INFO:root:final mean train loss: 4279.255448126024
INFO:root:final train perplexity: 5.410222053527832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it]
INFO:root:eval mean loss: 4085.2246561253323
INFO:root:eval perplexity: 5.2171173095703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 4901.750754931294
INFO:root:eval perplexity: 7.421590328216553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/15
  8%|â–Š         | 15/200 [1:49:01<22:18:07, 433.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4190.948473478618
INFO:root:current train perplexity5.2647199630737305
INFO:root:current mean train loss 4267.488710034795
INFO:root:current train perplexity5.331748962402344
INFO:root:current mean train loss 4261.830410334617
INFO:root:current train perplexity5.334921836853027
INFO:root:current mean train loss 4254.409338111041
INFO:root:current train perplexity5.342647552490234
INFO:root:current mean train loss 4251.63576665983
INFO:root:current train perplexity5.338613986968994
INFO:root:current mean train loss 4248.123795761079
INFO:root:current train perplexity5.330260276794434
INFO:root:current mean train loss 4246.238129007219
INFO:root:current train perplexity5.327225208282471
INFO:root:current mean train loss 4248.759894995762
INFO:root:current train perplexity5.332713603973389
INFO:root:current mean train loss 4246.717482495803
INFO:root:current train perplexity5.331332683563232
INFO:root:current mean train loss 4246.746799605975
INFO:root:current train perplexity5.331541061401367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.57s/it]
INFO:root:final mean train loss: 4238.953701080814
INFO:root:final train perplexity: 5.324878215789795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 4075.160358834774
INFO:root:eval perplexity: 5.195928573608398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 4897.005906125332
INFO:root:eval perplexity: 7.40720272064209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/16
  8%|â–Š         | 16/200 [1:56:12<22:08:40, 433.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4133.998580367477
INFO:root:current train perplexity5.056535243988037
INFO:root:current mean train loss 4205.48184708723
INFO:root:current train perplexity5.213482856750488
INFO:root:current mean train loss 4225.049067963588
INFO:root:current train perplexity5.262452602386475
INFO:root:current mean train loss 4209.262645289803
INFO:root:current train perplexity5.242608070373535
INFO:root:current mean train loss 4197.636497479692
INFO:root:current train perplexity5.240076541900635
INFO:root:current mean train loss 4194.409648048358
INFO:root:current train perplexity5.236413955688477
INFO:root:current mean train loss 4195.238410913203
INFO:root:current train perplexity5.232618808746338
INFO:root:current mean train loss 4190.96153492252
INFO:root:current train perplexity5.229532241821289
INFO:root:current mean train loss 4198.4260186007405
INFO:root:current train perplexity5.240856647491455
INFO:root:current mean train loss 4201.5847897493595
INFO:root:current train perplexity5.242583274841309

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.48s/it]
INFO:root:final mean train loss: 4202.489623777328
INFO:root:final train perplexity: 5.2488226890563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 4050.757315561281
INFO:root:eval perplexity: 5.144907474517822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 4873.922629931294
INFO:root:eval perplexity: 7.337615966796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/17
  8%|â–Š         | 17/200 [2:03:24<21:59:42, 432.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4170.0759765625
INFO:root:current train perplexity5.232089996337891
INFO:root:current mean train loss 4169.93238208912
INFO:root:current train perplexity5.165824890136719
INFO:root:current mean train loss 4181.359356299867
INFO:root:current train perplexity5.179542064666748
INFO:root:current mean train loss 4173.364953795476
INFO:root:current train perplexity5.177914142608643
INFO:root:current mean train loss 4182.3012830010775
INFO:root:current train perplexity5.194326400756836
INFO:root:current mean train loss 4177.650773492261
INFO:root:current train perplexity5.196193695068359
INFO:root:current mean train loss 4183.336792568898
INFO:root:current train perplexity5.193564414978027
INFO:root:current mean train loss 4177.180078125
INFO:root:current train perplexity5.187580108642578
INFO:root:current mean train loss 4175.729589551366
INFO:root:current train perplexity5.185562610626221
INFO:root:current mean train loss 4171.806883721173
INFO:root:current train perplexity5.1812310218811035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.22s/it]
INFO:root:final mean train loss: 4169.984233610092
INFO:root:final train perplexity: 5.18194055557251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 4015.941354305186
INFO:root:eval perplexity: 5.072982311248779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 4847.934975482048
INFO:root:eval perplexity: 7.260054111480713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/18
  9%|â–‰         | 18/200 [2:10:37<21:52:36, 432.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4073.776838435683
INFO:root:current train perplexity5.048183441162109
INFO:root:current mean train loss 4124.56656502677
INFO:root:current train perplexity5.09466028213501
INFO:root:current mean train loss 4125.208274056391
INFO:root:current train perplexity5.095516204833984
INFO:root:current mean train loss 4132.478652286808
INFO:root:current train perplexity5.108397483825684
INFO:root:current mean train loss 4127.783650073187
INFO:root:current train perplexity5.102499008178711
INFO:root:current mean train loss 4131.10720066471
INFO:root:current train perplexity5.104424953460693
INFO:root:current mean train loss 4136.692074504277
INFO:root:current train perplexity5.1122212409973145
INFO:root:current mean train loss 4136.051311261882
INFO:root:current train perplexity5.111596584320068
INFO:root:current mean train loss 4141.385738712189
INFO:root:current train perplexity5.115174770355225
INFO:root:current mean train loss 4137.868769624453
INFO:root:current train perplexity5.112632751464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.13s/it]
INFO:root:final mean train loss: 4134.742001810381
INFO:root:final train perplexity: 5.110387802124023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it]
INFO:root:eval mean loss: 3987.9635572501106
INFO:root:eval perplexity: 5.015913009643555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 4825.623304867575
INFO:root:eval perplexity: 7.194117069244385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/19
 10%|â–‰         | 19/200 [2:17:46<21:42:00, 431.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4124.951947380515
INFO:root:current train perplexity5.057292938232422
INFO:root:current mean train loss 4114.342796073055
INFO:root:current train perplexity5.057671070098877
INFO:root:current mean train loss 4111.39699405503
INFO:root:current train perplexity5.053858280181885
INFO:root:current mean train loss 4102.381836633057
INFO:root:current train perplexity5.037884712219238
INFO:root:current mean train loss 4107.379640837202
INFO:root:current train perplexity5.042272567749023
INFO:root:current mean train loss 4108.437513735679
INFO:root:current train perplexity5.050525665283203
INFO:root:current mean train loss 4105.593640868015
INFO:root:current train perplexity5.049705982208252
INFO:root:current mean train loss 4106.115541907665
INFO:root:current train perplexity5.053134441375732
INFO:root:current mean train loss 4111.929902665063
INFO:root:current train perplexity5.055719375610352
INFO:root:current mean train loss 4106.916544724714
INFO:root:current train perplexity5.049857139587402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.33s/it]
INFO:root:final mean train loss: 4105.081735303325
INFO:root:final train perplexity: 5.0509352684021
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 3972.9595713513963
INFO:root:eval perplexity: 4.985572814941406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 4812.240871564716
INFO:root:eval perplexity: 7.154856204986572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/20
 10%|â–ˆ         | 20/200 [2:24:56<21:33:51, 431.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4067.1773991988875
INFO:root:current train perplexity4.981653690338135
INFO:root:current mean train loss 4076.357036470617
INFO:root:current train perplexity4.989683628082275
INFO:root:current mean train loss 4086.115650073902
INFO:root:current train perplexity5.002941131591797
INFO:root:current mean train loss 4088.8872213124564
INFO:root:current train perplexity5.006468296051025
INFO:root:current mean train loss 4092.122052228009
INFO:root:current train perplexity5.012810230255127
INFO:root:current mean train loss 4092.2452543255254
INFO:root:current train perplexity5.0114665031433105
INFO:root:current mean train loss 4086.602321595813
INFO:root:current train perplexity5.004838943481445
INFO:root:current mean train loss 4083.5274042222495
INFO:root:current train perplexity5.0030646324157715
INFO:root:current mean train loss 4079.756738451779
INFO:root:current train perplexity4.9998345375061035
INFO:root:current mean train loss 4082.8979993706826
INFO:root:current train perplexity4.999359607696533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.96s/it]
INFO:root:final mean train loss: 4080.017843431042
INFO:root:final train perplexity: 5.0012359619140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 3962.703682541002
INFO:root:eval perplexity: 4.964939594268799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4807.943331671099
INFO:root:eval perplexity: 7.142294406890869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/21
 10%|â–ˆ         | 21/200 [2:32:06<21:25:29, 430.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.164332147854
INFO:root:current train perplexity5.005434989929199
INFO:root:current mean train loss 4079.244105538922
INFO:root:current train perplexity4.984848976135254
INFO:root:current mean train loss 4075.330251858029
INFO:root:current train perplexity4.9751176834106445
INFO:root:current mean train loss 4065.449696387517
INFO:root:current train perplexity4.962404727935791
INFO:root:current mean train loss 4069.2034229874866
INFO:root:current train perplexity4.965354919433594
INFO:root:current mean train loss 4068.4569546062057
INFO:root:current train perplexity4.963630199432373
INFO:root:current mean train loss 4058.944669754966
INFO:root:current train perplexity4.955016613006592
INFO:root:current mean train loss 4058.076484769699
INFO:root:current train perplexity4.9498467445373535
INFO:root:current mean train loss 4058.8901296789395
INFO:root:current train perplexity4.952251434326172
INFO:root:current mean train loss 4057.1798932648494
INFO:root:current train perplexity4.949913024902344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.36s/it]
INFO:root:final mean train loss: 4053.434912650816
INFO:root:final train perplexity: 4.9490580558776855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 3960.168810255984
INFO:root:eval perplexity: 4.959852695465088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4804.8040399213205
INFO:root:eval perplexity: 7.133131980895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/22
 11%|â–ˆ         | 22/200 [2:39:16<21:17:25, 430.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4033.883821614583
INFO:root:current train perplexity4.877297878265381
INFO:root:current mean train loss 4036.3699623325892
INFO:root:current train perplexity4.886783599853516
INFO:root:current mean train loss 4045.3795871803977
INFO:root:current train perplexity4.905951499938965
INFO:root:current mean train loss 4029.6570006510415
INFO:root:current train perplexity4.894708633422852
INFO:root:current mean train loss 4035.3803212376642
INFO:root:current train perplexity4.893845558166504
INFO:root:current mean train loss 4039.585056470788
INFO:root:current train perplexity4.902602195739746
INFO:root:current mean train loss 4043.63197265625
INFO:root:current train perplexity4.912137508392334
INFO:root:current mean train loss 4040.1597905115927
INFO:root:current train perplexity4.911507606506348
INFO:root:current mean train loss 4037.377511160714
INFO:root:current train perplexity4.908470630645752
INFO:root:current mean train loss 4035.5827749399036
INFO:root:current train perplexity4.907251834869385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.20s/it]
INFO:root:final mean train loss: 4032.0860687378913
INFO:root:final train perplexity: 4.907548904418945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it]
INFO:root:eval mean loss: 3962.316279850953
INFO:root:eval perplexity: 4.9641618728637695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it]
INFO:root:eval mean loss: 4809.27830646055
INFO:root:eval perplexity: 7.146193027496338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/23
 12%|â–ˆâ–        | 23/200 [2:46:25<21:08:38, 430.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4009.3333902014306
INFO:root:current train perplexity4.861590385437012
INFO:root:current mean train loss 4020.8478443583504
INFO:root:current train perplexity4.882303237915039
INFO:root:current mean train loss 4024.8692683027825
INFO:root:current train perplexity4.880851745605469
INFO:root:current mean train loss 4032.36500680789
INFO:root:current train perplexity4.884243965148926
INFO:root:current mean train loss 4021.591559810915
INFO:root:current train perplexity4.874174118041992
INFO:root:current mean train loss 4017.0409301967197
INFO:root:current train perplexity4.86509370803833
INFO:root:current mean train loss 4019.2561042305315
INFO:root:current train perplexity4.865834712982178
INFO:root:current mean train loss 4014.5624881515405
INFO:root:current train perplexity4.861957550048828
INFO:root:current mean train loss 4013.0307241161167
INFO:root:current train perplexity4.863631725311279
INFO:root:current mean train loss 4013.2214300828937
INFO:root:current train perplexity4.864570140838623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.85s/it]
INFO:root:final mean train loss: 4009.1554554970035
INFO:root:final train perplexity: 4.863351345062256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 3944.9808098542776
INFO:root:eval perplexity: 4.929484844207764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 4795.339571905474
INFO:root:eval perplexity: 7.105579376220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/24
 12%|â–ˆâ–        | 24/200 [2:53:35<21:01:56, 430.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4018.0548457889768
INFO:root:current train perplexity4.828785419464111
INFO:root:current mean train loss 4008.029068073053
INFO:root:current train perplexity4.840156078338623
INFO:root:current mean train loss 3992.2955653659255
INFO:root:current train perplexity4.82785701751709
INFO:root:current mean train loss 3987.024552679428
INFO:root:current train perplexity4.827988147735596
INFO:root:current mean train loss 3994.475290084808
INFO:root:current train perplexity4.832232475280762
INFO:root:current mean train loss 3993.127796257006
INFO:root:current train perplexity4.830765247344971
INFO:root:current mean train loss 3994.419938480802
INFO:root:current train perplexity4.826085090637207
INFO:root:current mean train loss 3996.6123398733803
INFO:root:current train perplexity4.8277587890625
INFO:root:current mean train loss 3992.6151099756244
INFO:root:current train perplexity4.825035095214844
INFO:root:current mean train loss 3991.9551170495397
INFO:root:current train perplexity4.824651718139648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.04s/it]
INFO:root:final mean train loss: 3988.964969142791
INFO:root:final train perplexity: 4.824765682220459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it]
INFO:root:eval mean loss: 3903.2474702875666
INFO:root:eval perplexity: 4.846993446350098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 4758.008243641955
INFO:root:eval perplexity: 6.9979352951049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/25
 12%|â–ˆâ–Ž        | 25/200 [3:00:51<20:59:42, 431.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3990.233469953441
INFO:root:current train perplexity4.813059329986572
INFO:root:current mean train loss 3976.455425319959
INFO:root:current train perplexity4.789708614349365
INFO:root:current mean train loss 3984.3081511940845
INFO:root:current train perplexity4.793878078460693
INFO:root:current mean train loss 3977.9143029693373
INFO:root:current train perplexity4.790183067321777
INFO:root:current mean train loss 3975.175846321549
INFO:root:current train perplexity4.790859222412109
INFO:root:current mean train loss 3977.691077740244
INFO:root:current train perplexity4.791966438293457
INFO:root:current mean train loss 3975.682272107475
INFO:root:current train perplexity4.792977333068848
INFO:root:current mean train loss 3974.675394108358
INFO:root:current train perplexity4.789148330688477
INFO:root:current mean train loss 3972.6128068187745
INFO:root:current train perplexity4.790674686431885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.56s/it]
INFO:root:final mean train loss: 3971.2064642137098
INFO:root:final train perplexity: 4.791079998016357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 3893.962227462877
INFO:root:eval perplexity: 4.828829288482666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 4752.427936959774
INFO:root:eval perplexity: 6.9819841384887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/26
 13%|â–ˆâ–Ž        | 26/200 [3:08:02<20:51:19, 431.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3918.9626813616073
INFO:root:current train perplexity4.633563041687012
INFO:root:current mean train loss 3942.736996659609
INFO:root:current train perplexity4.719078063964844
INFO:root:current mean train loss 3948.135939151193
INFO:root:current train perplexity4.749606609344482
INFO:root:current mean train loss 3960.488732154672
INFO:root:current train perplexity4.752353191375732
INFO:root:current mean train loss 3955.849682557202
INFO:root:current train perplexity4.747372627258301
INFO:root:current mean train loss 3954.15201293223
INFO:root:current train perplexity4.747485637664795
INFO:root:current mean train loss 3953.376929394692
INFO:root:current train perplexity4.750373840332031
INFO:root:current mean train loss 3956.8848574798885
INFO:root:current train perplexity4.755753517150879
INFO:root:current mean train loss 3955.426238975856
INFO:root:current train perplexity4.756313800811768
INFO:root:current mean train loss 3958.300744642365
INFO:root:current train perplexity4.763612270355225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.12s/it]
INFO:root:final mean train loss: 3954.823781290362
INFO:root:final train perplexity: 4.7602128982543945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 3884.0062593500666
INFO:root:eval perplexity: 4.809427738189697
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 4741.458109970634
INFO:root:eval perplexity: 6.950735092163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/27
 14%|â–ˆâ–Ž        | 27/200 [3:15:12<20:42:55, 431.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3959.101416015625
INFO:root:current train perplexity4.74701452255249
INFO:root:current mean train loss 3917.11015625
INFO:root:current train perplexity4.725243091583252
INFO:root:current mean train loss 3935.667594022529
INFO:root:current train perplexity4.725350856781006
INFO:root:current mean train loss 3941.171658761161
INFO:root:current train perplexity4.731736183166504
INFO:root:current mean train loss 3935.4877906155875
INFO:root:current train perplexity4.729982376098633
INFO:root:current mean train loss 3936.260106473756
INFO:root:current train perplexity4.733860492706299
INFO:root:current mean train loss 3937.878894340701
INFO:root:current train perplexity4.734187126159668
INFO:root:current mean train loss 3942.205994249891
INFO:root:current train perplexity4.7335405349731445
INFO:root:current mean train loss 3943.473522275211
INFO:root:current train perplexity4.734935760498047
INFO:root:current mean train loss 3942.9894918139516
INFO:root:current train perplexity4.733546257019043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.45s/it]
INFO:root:final mean train loss: 3940.1900477870818
INFO:root:final train perplexity: 4.732809066772461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 3879.4111051085993
INFO:root:eval perplexity: 4.80049991607666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 4740.741536458333
INFO:root:eval perplexity: 6.9486985206604
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/28
 14%|â–ˆâ–        | 28/200 [3:22:22<20:35:21, 430.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3916.161759086277
INFO:root:current train perplexity4.672481536865234
INFO:root:current mean train loss 3907.758296811484
INFO:root:current train perplexity4.6829047203063965
INFO:root:current mean train loss 3915.7511988071046
INFO:root:current train perplexity4.681013107299805
INFO:root:current mean train loss 3935.8618587340366
INFO:root:current train perplexity4.701300144195557
INFO:root:current mean train loss 3931.1830916167996
INFO:root:current train perplexity4.697248935699463
INFO:root:current mean train loss 3928.242253319939
INFO:root:current train perplexity4.696697235107422
INFO:root:current mean train loss 3928.766020405924
INFO:root:current train perplexity4.70004940032959
INFO:root:current mean train loss 3927.918712315223
INFO:root:current train perplexity4.696335315704346
INFO:root:current mean train loss 3924.980554184386
INFO:root:current train perplexity4.694951057434082
INFO:root:current mean train loss 3925.866695515642
INFO:root:current train perplexity4.697610378265381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.44s/it]
INFO:root:final mean train loss: 3922.7314904120663
INFO:root:final train perplexity: 4.700322151184082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it]
INFO:root:eval mean loss: 3872.927287649601
INFO:root:eval perplexity: 4.787929534912109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 4740.063824592753
INFO:root:eval perplexity: 6.946773052215576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/29
 14%|â–ˆâ–        | 29/200 [3:29:32<20:26:43, 430.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.4724908644152
INFO:root:current train perplexity4.632011413574219
INFO:root:current mean train loss 3926.068603515625
INFO:root:current train perplexity4.700256824493408
INFO:root:current mean train loss 3920.073807621415
INFO:root:current train perplexity4.692872524261475
INFO:root:current mean train loss 3920.410127484186
INFO:root:current train perplexity4.6964802742004395
INFO:root:current mean train loss 3915.2923048687644
INFO:root:current train perplexity4.681424617767334
INFO:root:current mean train loss 3920.419389455332
INFO:root:current train perplexity4.683532238006592
INFO:root:current mean train loss 3920.549172088575
INFO:root:current train perplexity4.6835126876831055
INFO:root:current mean train loss 3917.4850810373205
INFO:root:current train perplexity4.682631492614746
INFO:root:current mean train loss 3913.9096124421817
INFO:root:current train perplexity4.677889823913574
INFO:root:current mean train loss 3914.825555885389
INFO:root:current train perplexity4.678792953491211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.28s/it]
INFO:root:final mean train loss: 3910.3540571274298
INFO:root:final train perplexity: 4.677425384521484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it]
INFO:root:eval mean loss: 3882.9929597462324
INFO:root:eval perplexity: 4.807457447052002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 4746.3815883338875
INFO:root:eval perplexity: 6.964742660522461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/30
 15%|â–ˆâ–Œ        | 30/200 [3:36:42<20:19:09, 430.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3909.8841145833335
INFO:root:current train perplexity4.684825420379639
INFO:root:current mean train loss 3892.4606476927834
INFO:root:current train perplexity4.637628078460693
INFO:root:current mean train loss 3889.5905925160173
INFO:root:current train perplexity4.644428253173828
INFO:root:current mean train loss 3902.976424225664
INFO:root:current train perplexity4.651145935058594
INFO:root:current mean train loss 3901.687751926431
INFO:root:current train perplexity4.651485443115234
INFO:root:current mean train loss 3901.9135823718693
INFO:root:current train perplexity4.6488494873046875
INFO:root:current mean train loss 3903.351939981905
INFO:root:current train perplexity4.65121603012085
INFO:root:current mean train loss 3907.185853454838
INFO:root:current train perplexity4.658116817474365
INFO:root:current mean train loss 3900.801678372225
INFO:root:current train perplexity4.650664329528809
INFO:root:current mean train loss 3896.101610600123
INFO:root:current train perplexity4.6468706130981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.58s/it]
INFO:root:final mean train loss: 3893.652994032829
INFO:root:final train perplexity: 4.646707057952881
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it]
INFO:root:eval mean loss: 3890.119975205009
INFO:root:eval perplexity: 4.8213324546813965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4762.124302208001
INFO:root:eval perplexity: 7.009722709655762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/31
 16%|â–ˆâ–Œ        | 31/200 [3:43:52<20:11:47, 430.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3874.362481299867
INFO:root:current train perplexity4.630465984344482
INFO:root:current mean train loss 3888.168566645408
INFO:root:current train perplexity4.6374311447143555
INFO:root:current mean train loss 3887.605685214765
INFO:root:current train perplexity4.634374141693115
INFO:root:current mean train loss 3892.5104136178406
INFO:root:current train perplexity4.634322643280029
INFO:root:current mean train loss 3894.346388575748
INFO:root:current train perplexity4.631098747253418
INFO:root:current mean train loss 3890.7386990116543
INFO:root:current train perplexity4.627640247344971
INFO:root:current mean train loss 3891.797274983095
INFO:root:current train perplexity4.629884243011475
INFO:root:current mean train loss 3886.6270119540663
INFO:root:current train perplexity4.6241350173950195
INFO:root:current mean train loss 3883.3343590890645
INFO:root:current train perplexity4.619747161865234
INFO:root:current mean train loss 3884.428387393166
INFO:root:current train perplexity4.623693466186523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.56s/it]
INFO:root:final mean train loss: 3881.182497024536
INFO:root:final train perplexity: 4.623901844024658
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it]
INFO:root:eval mean loss: 3836.703266982491
INFO:root:eval perplexity: 4.718307018280029
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 4705.602357255651
INFO:root:eval perplexity: 6.849567413330078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/32
 16%|â–ˆâ–Œ        | 32/200 [3:51:01<20:03:48, 429.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3815.210213955966
INFO:root:current train perplexity4.535980224609375
INFO:root:current mean train loss 3852.1708937121975
INFO:root:current train perplexity4.573553562164307
INFO:root:current mean train loss 3855.2949984681372
INFO:root:current train perplexity4.571220874786377
INFO:root:current mean train loss 3859.3661765514967
INFO:root:current train perplexity4.577082633972168
INFO:root:current mean train loss 3855.1085631653505
INFO:root:current train perplexity4.572185516357422
INFO:root:current mean train loss 3858.247285860079
INFO:root:current train perplexity4.579108715057373
INFO:root:current mean train loss 3865.5484251997855
INFO:root:current train perplexity4.586487770080566
INFO:root:current mean train loss 3867.245791080298
INFO:root:current train perplexity4.593024253845215
INFO:root:current mean train loss 3866.1630422491776
INFO:root:current train perplexity4.58999490737915
INFO:root:current mean train loss 3867.030850938727
INFO:root:current train perplexity4.594564914703369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.61s/it]
INFO:root:final mean train loss: 3866.261889919158
INFO:root:final train perplexity: 4.596761703491211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 3833.84625547152
INFO:root:eval perplexity: 4.712859630584717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 4704.401226936503
INFO:root:eval perplexity: 6.846203327178955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/33
 16%|â–ˆâ–‹        | 33/200 [3:58:11<19:56:41, 429.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3805.489304315476
INFO:root:current train perplexity4.51215124130249
INFO:root:current mean train loss 3838.046227952454
INFO:root:current train perplexity4.541996479034424
INFO:root:current mean train loss 3846.0274245113474
INFO:root:current train perplexity4.555119514465332
INFO:root:current mean train loss 3848.6191143950155
INFO:root:current train perplexity4.556267261505127
INFO:root:current mean train loss 3864.8404116537863
INFO:root:current train perplexity4.577041149139404
INFO:root:current mean train loss 3863.232285711312
INFO:root:current train perplexity4.579352855682373
INFO:root:current mean train loss 3856.429789133201
INFO:root:current train perplexity4.573981285095215
INFO:root:current mean train loss 3860.158945466088
INFO:root:current train perplexity4.580560684204102
INFO:root:current mean train loss 3856.234025338572
INFO:root:current train perplexity4.575851917266846
INFO:root:current mean train loss 3859.8505212896707
INFO:root:current train perplexity4.579592704772949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.99s/it]
INFO:root:final mean train loss: 3856.923060632521
INFO:root:final train perplexity: 4.579856872558594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 3839.608734347296
INFO:root:eval perplexity: 4.723855018615723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 4717.7592634918
INFO:root:eval perplexity: 6.883701801300049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/34
 17%|â–ˆâ–‹        | 34/200 [4:05:21<19:49:55, 430.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3807.8053786586706
INFO:root:current train perplexity4.517000198364258
INFO:root:current mean train loss 3820.9447371276497
INFO:root:current train perplexity4.522691249847412
INFO:root:current mean train loss 3832.880138664668
INFO:root:current train perplexity4.5314836502075195
INFO:root:current mean train loss 3849.2750925233745
INFO:root:current train perplexity4.553628921508789
INFO:root:current mean train loss 3851.5839548293193
INFO:root:current train perplexity4.560551166534424
INFO:root:current mean train loss 3847.7264209753994
INFO:root:current train perplexity4.56003475189209
INFO:root:current mean train loss 3846.626117734724
INFO:root:current train perplexity4.562390327453613
INFO:root:current mean train loss 3849.400455539174
INFO:root:current train perplexity4.561901092529297
INFO:root:current mean train loss 4211.561622663426
INFO:root:current train perplexity5.26516580581665
INFO:root:current mean train loss 4247.382127598803
INFO:root:current train perplexity5.334417819976807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.73s/it]
INFO:root:final mean train loss: 4243.718725635159
INFO:root:final train perplexity: 5.334897994995117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it]
INFO:root:eval mean loss: 3980.8945762688386
INFO:root:eval perplexity: 5.0015950202941895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4841.1811038619235
INFO:root:eval perplexity: 7.240031719207764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/35
 18%|â–ˆâ–Š        | 35/200 [4:12:30<19:41:58, 429.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4208.532016416139
INFO:root:current train perplexity5.296235084533691
INFO:root:current mean train loss 4168.939331736645
INFO:root:current train perplexity5.183913230895996
INFO:root:current mean train loss 4147.733068541386
INFO:root:current train perplexity5.141757965087891
INFO:root:current mean train loss 4135.257997376938
INFO:root:current train perplexity5.1137237548828125
INFO:root:current mean train loss 4123.286954429802
INFO:root:current train perplexity5.081368923187256
INFO:root:current mean train loss 4110.4629854982995
INFO:root:current train perplexity5.0544047355651855
INFO:root:current mean train loss 4100.140816285438
INFO:root:current train perplexity5.037240028381348
INFO:root:current mean train loss 4096.737876960647
INFO:root:current train perplexity5.024236679077148
INFO:root:current mean train loss 4090.962028494738
INFO:root:current train perplexity5.015233039855957
INFO:root:current mean train loss 4085.782306612695
INFO:root:current train perplexity5.007416725158691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.13s/it]
INFO:root:final mean train loss: 4081.949481410365
INFO:root:final train perplexity: 5.005048751831055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 3907.4036873891846
INFO:root:eval perplexity: 4.855146408081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 4786.347277052859
INFO:root:eval perplexity: 7.0794997215271
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/36
 18%|â–ˆâ–Š        | 36/200 [4:19:43<19:37:19, 430.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4048.4256297144398
INFO:root:current train perplexity4.903807163238525
INFO:root:current mean train loss 4045.6436291046957
INFO:root:current train perplexity4.895447254180908
INFO:root:current mean train loss 4026.813644994011
INFO:root:current train perplexity4.875110626220703
INFO:root:current mean train loss 4019.636063292353
INFO:root:current train perplexity4.875925540924072
INFO:root:current mean train loss 4019.308366152785
INFO:root:current train perplexity4.881093502044678
INFO:root:current mean train loss 4021.34682234548
INFO:root:current train perplexity4.8711323738098145
INFO:root:current mean train loss 4023.3928272408343
INFO:root:current train perplexity4.877254009246826
INFO:root:current mean train loss 4021.852708440875
INFO:root:current train perplexity4.878584384918213
INFO:root:current mean train loss 4022.5203814759197
INFO:root:current train perplexity4.880740642547607
INFO:root:current mean train loss 4024.4250164244554
INFO:root:current train perplexity4.887105464935303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.67s/it]
INFO:root:final mean train loss: 4021.6120711911108
INFO:root:final train perplexity: 4.8873114585876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 3896.490132216866
INFO:root:eval perplexity: 4.833767890930176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it]
INFO:root:eval mean loss: 4773.524476396276
INFO:root:eval perplexity: 7.04247522354126
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/37
 18%|â–ˆâ–Š        | 37/200 [4:26:59<19:34:17, 432.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.1559133429278
INFO:root:current train perplexity4.818572044372559
INFO:root:current mean train loss 4012.780327273638
INFO:root:current train perplexity4.848494052886963
INFO:root:current mean train loss 4007.7396964380296
INFO:root:current train perplexity4.857658386230469
INFO:root:current mean train loss 4005.4153987836235
INFO:root:current train perplexity4.849705696105957
INFO:root:current mean train loss 4004.5943132496845
INFO:root:current train perplexity4.843989372253418
INFO:root:current mean train loss 4002.2883469012604
INFO:root:current train perplexity4.838891983032227
INFO:root:current mean train loss 4003.3269857941773
INFO:root:current train perplexity4.838756561279297
INFO:root:current mean train loss 4003.3559389126376
INFO:root:current train perplexity4.8441972732543945
INFO:root:current mean train loss 4004.845478897521
INFO:root:current train perplexity4.847972393035889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.09s/it]
INFO:root:final mean train loss: 4001.884866837532
INFO:root:final train perplexity: 4.84942102432251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 3897.7155969498003
INFO:root:eval perplexity: 4.83616304397583
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4782.696531471631
INFO:root:eval perplexity: 7.068938255310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/38
 19%|â–ˆâ–‰        | 38/200 [4:34:10<19:25:33, 431.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4141.436767578125
INFO:root:current train perplexity5.0374836921691895
INFO:root:current mean train loss 3998.5938685148667
INFO:root:current train perplexity4.831013202667236
INFO:root:current mean train loss 3992.349479487377
INFO:root:current train perplexity4.82518196105957
INFO:root:current mean train loss 3990.1669382026093
INFO:root:current train perplexity4.818951606750488
INFO:root:current mean train loss 3996.950466714485
INFO:root:current train perplexity4.832644939422607
INFO:root:current mean train loss 4001.2573183943214
INFO:root:current train perplexity4.831920146942139
INFO:root:current mean train loss 4002.722774878861
INFO:root:current train perplexity4.833489418029785
INFO:root:current mean train loss 3997.4929418007646
INFO:root:current train perplexity4.828332901000977
INFO:root:current mean train loss 3994.6726949841413
INFO:root:current train perplexity4.825656890869141
INFO:root:current mean train loss 3992.5162565753044
INFO:root:current train perplexity4.823711395263672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.08s/it]
INFO:root:final mean train loss: 3987.626530924151
INFO:root:final train perplexity: 4.82221794128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 3889.7037795046544
INFO:root:eval perplexity: 4.820521354675293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4769.447258699025
INFO:root:eval perplexity: 7.030743598937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/39
 20%|â–ˆâ–‰        | 39/200 [4:41:22<19:19:00, 431.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3959.3608620383525
INFO:root:current train perplexity4.827903747558594
INFO:root:current mean train loss 3956.092238967483
INFO:root:current train perplexity4.767096996307373
INFO:root:current mean train loss 3956.38311102266
INFO:root:current train perplexity4.767288684844971
INFO:root:current mean train loss 3955.491225852844
INFO:root:current train perplexity4.7754058837890625
INFO:root:current mean train loss 3965.023821234413
INFO:root:current train perplexity4.77899694442749
INFO:root:current mean train loss 3967.783870570114
INFO:root:current train perplexity4.7815775871276855
INFO:root:current mean train loss 3963.34573589019
INFO:root:current train perplexity4.78259801864624
INFO:root:current mean train loss 3966.2127203103023
INFO:root:current train perplexity4.786131381988525
INFO:root:current mean train loss 3971.985601422819
INFO:root:current train perplexity4.787456035614014
INFO:root:current mean train loss 3972.5732965898565
INFO:root:current train perplexity4.786828994750977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.93s/it]
INFO:root:final mean train loss: 3968.7492473356187
INFO:root:final train perplexity: 4.78643798828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it]
INFO:root:eval mean loss: 3883.0003307153147
INFO:root:eval perplexity: 4.80747127532959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 4765.001431945368
INFO:root:eval perplexity: 7.017973899841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/40
 20%|â–ˆâ–ˆ        | 40/200 [4:48:34<19:11:53, 431.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3956.441958778783
INFO:root:current train perplexity4.785088062286377
INFO:root:current mean train loss 3962.163672695641
INFO:root:current train perplexity4.775813579559326
INFO:root:current mean train loss 3966.7918327714756
INFO:root:current train perplexity4.760201930999756
INFO:root:current mean train loss 3968.644573343211
INFO:root:current train perplexity4.768897533416748
INFO:root:current mean train loss 3968.3996319827716
INFO:root:current train perplexity4.768527030944824
INFO:root:current mean train loss 3969.6701664860307
INFO:root:current train perplexity4.764729976654053
INFO:root:current mean train loss 3962.1786087849605
INFO:root:current train perplexity4.759936809539795
INFO:root:current mean train loss 3960.624460106267
INFO:root:current train perplexity4.760617733001709
INFO:root:current mean train loss 3956.208747686775
INFO:root:current train perplexity4.757633686065674
INFO:root:current mean train loss 3956.578754346181
INFO:root:current train perplexity4.757279396057129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.40s/it]
INFO:root:final mean train loss: 3952.5979391528713
INFO:root:final train perplexity: 4.756034851074219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it]
INFO:root:eval mean loss: 3886.4676868628103
INFO:root:eval perplexity: 4.814218044281006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it]
INFO:root:eval mean loss: 4768.126695132425
INFO:root:eval perplexity: 7.02694845199585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/41
 20%|â–ˆâ–ˆ        | 41/200 [4:55:45<19:03:46, 431.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3964.8700900607637
INFO:root:current train perplexity4.767032146453857
INFO:root:current mean train loss 3937.9478961614172
INFO:root:current train perplexity4.739238262176514
INFO:root:current mean train loss 3942.592029185022
INFO:root:current train perplexity4.73424768447876
INFO:root:current mean train loss 3942.2135737707854
INFO:root:current train perplexity4.729124546051025
INFO:root:current mean train loss 3931.5635806224386
INFO:root:current train perplexity4.716651439666748
INFO:root:current mean train loss 3934.522430362014
INFO:root:current train perplexity4.718883514404297
INFO:root:current mean train loss 3938.267588248854
INFO:root:current train perplexity4.723979949951172
INFO:root:current mean train loss 3940.1487477970254
INFO:root:current train perplexity4.7253265380859375
INFO:root:current mean train loss 3939.193801307909
INFO:root:current train perplexity4.724857330322266
INFO:root:current mean train loss 3940.310178425448
INFO:root:current train perplexity4.728347301483154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.38s/it]
INFO:root:final mean train loss: 3938.068276374571
INFO:root:final train perplexity: 4.728848934173584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it]
INFO:root:eval mean loss: 3872.722322071698
INFO:root:eval perplexity: 4.787532806396484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 4757.0321417193045
INFO:root:eval perplexity: 6.995142459869385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/42
 21%|â–ˆâ–ˆ        | 42/200 [5:02:56<18:56:28, 431.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3969.6743373325894
INFO:root:current train perplexity4.754674911499023
INFO:root:current mean train loss 3923.9805103443286
INFO:root:current train perplexity4.701813220977783
INFO:root:current mean train loss 3927.057627576463
INFO:root:current train perplexity4.699065208435059
INFO:root:current mean train loss 3931.9257142024253
INFO:root:current train perplexity4.7035393714904785
INFO:root:current mean train loss 3924.194369050826
INFO:root:current train perplexity4.701634883880615
INFO:root:current mean train loss 3927.427778183411
INFO:root:current train perplexity4.70621395111084
INFO:root:current mean train loss 3934.5572677011564
INFO:root:current train perplexity4.711724758148193
INFO:root:current mean train loss 3934.2515070285926
INFO:root:current train perplexity4.71359920501709
INFO:root:current mean train loss 3935.8814599316993
INFO:root:current train perplexity4.716723918914795
INFO:root:current mean train loss 3933.740301481033
INFO:root:current train perplexity4.713098049163818

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.43s/it]
INFO:root:final mean train loss: 3927.9663239755937
INFO:root:final train perplexity: 4.7100396156311035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it]
INFO:root:eval mean loss: 3873.4922532967644
INFO:root:eval perplexity: 4.7890238761901855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4764.032605759641
INFO:root:eval perplexity: 7.015194892883301
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:10:04<18:46:25, 430.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3946.8546852289246
INFO:root:current train perplexity4.714966773986816
INFO:root:current mean train loss 3908.104632184222
INFO:root:current train perplexity4.688512802124023
INFO:root:current mean train loss 3899.670077602559
INFO:root:current train perplexity4.673347473144531
INFO:root:current mean train loss 3903.619011792775
INFO:root:current train perplexity4.667670249938965
INFO:root:current mean train loss 3909.7115255317085
INFO:root:current train perplexity4.670140266418457
INFO:root:current mean train loss 3913.376557913933
INFO:root:current train perplexity4.674539089202881
INFO:root:current mean train loss 3917.6489781784603
INFO:root:current train perplexity4.6813154220581055
INFO:root:current mean train loss 3917.3222593818346
INFO:root:current train perplexity4.684113025665283
INFO:root:current mean train loss 3916.8020908631747
INFO:root:current train perplexity4.68618631362915
INFO:root:current mean train loss 3921.0735471691078
INFO:root:current train perplexity4.693161964416504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.81s/it]
INFO:root:final mean train loss: 3919.893513464159
INFO:root:final train perplexity: 4.695062637329102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it]
INFO:root:eval mean loss: 3868.779186059397
INFO:root:eval perplexity: 4.779905796051025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 4756.799422027371
INFO:root:eval perplexity: 6.994475841522217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:17:16<18:40:31, 430.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3929.322552849265
INFO:root:current train perplexity4.743081569671631
INFO:root:current mean train loss 3924.646938702918
INFO:root:current train perplexity4.692223072052002
INFO:root:current mean train loss 3920.801700424863
INFO:root:current train perplexity4.684445858001709
INFO:root:current mean train loss 3914.5830585881854
INFO:root:current train perplexity4.678046703338623
INFO:root:current mean train loss 3910.102196940826
INFO:root:current train perplexity4.670510768890381
INFO:root:current mean train loss 3907.321684295599
INFO:root:current train perplexity4.672690391540527
INFO:root:current mean train loss 3909.299272903466
INFO:root:current train perplexity4.672858715057373
INFO:root:current mean train loss 3913.0335795761903
INFO:root:current train perplexity4.676653861999512
INFO:root:current mean train loss 3915.6694215445063
INFO:root:current train perplexity4.683732032775879
INFO:root:current mean train loss 3918.929828952665
INFO:root:current train perplexity4.686877250671387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.44s/it]
INFO:root:final mean train loss: 3914.918141211233
INFO:root:final train perplexity: 4.685855388641357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it]
INFO:root:eval mean loss: 3869.4791683981603
INFO:root:eval perplexity: 4.781258583068848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 4759.751681280474
INFO:root:eval perplexity: 7.002924919128418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:24:26<18:32:22, 430.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3909.9682658567267
INFO:root:current train perplexity4.711325645446777
INFO:root:current mean train loss 3928.653300351317
INFO:root:current train perplexity4.706743240356445
INFO:root:current mean train loss 3917.059830477799
INFO:root:current train perplexity4.694404125213623
INFO:root:current mean train loss 3906.4480014471624
INFO:root:current train perplexity4.681279182434082
INFO:root:current mean train loss 3904.3607754842387
INFO:root:current train perplexity4.6753058433532715
INFO:root:current mean train loss 3908.774077768616
INFO:root:current train perplexity4.678267002105713
INFO:root:current mean train loss 3907.8510149433328
INFO:root:current train perplexity4.675110340118408
INFO:root:current mean train loss 3910.051654881011
INFO:root:current train perplexity4.679043769836426
INFO:root:current mean train loss 3914.9037707931643
INFO:root:current train perplexity4.6819939613342285
INFO:root:current mean train loss 3918.473089542329
INFO:root:current train perplexity4.686171054840088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.87s/it]
INFO:root:final mean train loss: 3915.2881925644415
INFO:root:final train perplexity: 4.686539173126221
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 3867.2838576296544
INFO:root:eval perplexity: 4.777015209197998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4760.230875651042
INFO:root:eval perplexity: 7.004295825958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:31:38<18:25:58, 430.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3900.3546087919776
INFO:root:current train perplexity4.64076042175293
INFO:root:current mean train loss 3914.77669319564
INFO:root:current train perplexity4.679288864135742
INFO:root:current mean train loss 3918.3677653909176
INFO:root:current train perplexity4.688269138336182
INFO:root:current mean train loss 3909.7041607682645
INFO:root:current train perplexity4.675902843475342
INFO:root:current mean train loss 3905.409388801526
INFO:root:current train perplexity4.668177127838135
INFO:root:current mean train loss 3912.4828856130125
INFO:root:current train perplexity4.681767463684082
INFO:root:current mean train loss 3912.5535378062923
INFO:root:current train perplexity4.683315277099609
INFO:root:current mean train loss 3917.398318135288
INFO:root:current train perplexity4.687896728515625
INFO:root:current mean train loss 3922.17335730248
INFO:root:current train perplexity4.693377494812012
INFO:root:current mean train loss 3920.7042129027436
INFO:root:current train perplexity4.692615032196045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.71s/it]
INFO:root:final mean train loss: 3918.9932250976562
INFO:root:final train perplexity: 4.693394660949707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it]
INFO:root:eval mean loss: 3865.8787417580897
INFO:root:eval perplexity: 4.774302005767822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 4762.729725939163
INFO:root:eval perplexity: 7.0114569664001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:38:46<18:16:38, 430.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3897.019951171875
INFO:root:current train perplexity4.608266830444336
INFO:root:current mean train loss 3901.670567801339
INFO:root:current train perplexity4.653517246246338
INFO:root:current mean train loss 3911.118173828125
INFO:root:current train perplexity4.667965888977051
INFO:root:current mean train loss 3909.713845703125
INFO:root:current train perplexity4.675708770751953
INFO:root:current mean train loss 3909.629611430921
INFO:root:current train perplexity4.677500247955322
INFO:root:current mean train loss 3915.6114707880433
INFO:root:current train perplexity4.683718204498291
INFO:root:current mean train loss 3918.0311241319446
INFO:root:current train perplexity4.6861066818237305
INFO:root:current mean train loss 3926.17431577621
INFO:root:current train perplexity4.6992974281311035
INFO:root:current mean train loss 3925.28612890625
INFO:root:current train perplexity4.698065757751465
INFO:root:current mean train loss 3925.902505759215
INFO:root:current train perplexity4.69875955581665

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.12s/it]
INFO:root:final mean train loss: 3922.2119009571693
INFO:root:final train perplexity: 4.699358940124512
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it]
INFO:root:eval mean loss: 3861.301683358267
INFO:root:eval perplexity: 4.76547384262085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 4756.592411555297
INFO:root:eval perplexity: 6.993884086608887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:45:57<18:10:13, 430.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3950.7593361728163
INFO:root:current train perplexity4.721116542816162
INFO:root:current mean train loss 3925.68466770193
INFO:root:current train perplexity4.701756477355957
INFO:root:current mean train loss 3916.8737094191697
INFO:root:current train perplexity4.698281764984131
INFO:root:current mean train loss 3916.3572810001224
INFO:root:current train perplexity4.6955885887146
INFO:root:current mean train loss 3925.8845664709497
INFO:root:current train perplexity4.703482151031494
INFO:root:current mean train loss 3925.9055092028034
INFO:root:current train perplexity4.7036614418029785
INFO:root:current mean train loss 3927.047330752997
INFO:root:current train perplexity4.70448637008667
INFO:root:current mean train loss 3932.0490033574793
INFO:root:current train perplexity4.709956169128418
INFO:root:current mean train loss 3929.4452558195603
INFO:root:current train perplexity4.708703517913818
INFO:root:current mean train loss 3932.848003461184
INFO:root:current train perplexity4.713160514831543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.43s/it]
INFO:root:final mean train loss: 3929.6103271976594
INFO:root:final train perplexity: 4.713095664978027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it]
INFO:root:eval mean loss: 3869.994824565049
INFO:root:eval perplexity: 4.782255172729492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4768.132824620457
INFO:root:eval perplexity: 7.026965618133545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:53:06<18:02:09, 430.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3936.528084220467
INFO:root:current train perplexity4.681554794311523
INFO:root:current mean train loss 3936.775367616983
INFO:root:current train perplexity4.708632469177246
INFO:root:current mean train loss 3930.0579234119955
INFO:root:current train perplexity4.697696685791016
INFO:root:current mean train loss 3937.215773482457
INFO:root:current train perplexity4.707155227661133
INFO:root:current mean train loss 3941.521481888843
INFO:root:current train perplexity4.7148847579956055
INFO:root:current mean train loss 3938.0123173282836
INFO:root:current train perplexity4.71522855758667
INFO:root:current mean train loss 3938.682727421762
INFO:root:current train perplexity4.720398426055908
INFO:root:current mean train loss 3937.5799950986684
INFO:root:current train perplexity4.718824863433838
INFO:root:current mean train loss 3936.711221645711
INFO:root:current train perplexity4.719660758972168
INFO:root:current mean train loss 3938.0307255041466
INFO:root:current train perplexity4.722909450531006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.78s/it]
INFO:root:final mean train loss: 3934.9015522618447
INFO:root:final train perplexity: 4.722944736480713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it]
INFO:root:eval mean loss: 3892.196515888187
INFO:root:eval perplexity: 4.825382232666016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 4796.42227670656
INFO:root:eval perplexity: 7.1087260246276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [6:00:14<17:53:42, 429.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3928.3274320351957
INFO:root:current train perplexity4.71488094329834
INFO:root:current mean train loss 3940.169145286982
INFO:root:current train perplexity4.731166362762451
INFO:root:current mean train loss 3935.8420524469584
INFO:root:current train perplexity4.718740940093994
INFO:root:current mean train loss 3927.5805841508068
INFO:root:current train perplexity4.706853866577148
INFO:root:current mean train loss 3934.000259307678
INFO:root:current train perplexity4.713328838348389
INFO:root:current mean train loss 3933.819949345915
INFO:root:current train perplexity4.714864253997803
INFO:root:current mean train loss 3936.827758963698
INFO:root:current train perplexity4.720342636108398
INFO:root:current mean train loss 3940.5903845871794
INFO:root:current train perplexity4.72768497467041
INFO:root:current mean train loss 3945.324405046406
INFO:root:current train perplexity4.736084461212158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.15s/it]
INFO:root:final mean train loss: 3940.950617636404
INFO:root:final train perplexity: 4.734229564666748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it]
INFO:root:eval mean loss: 3872.28818636414
INFO:root:eval perplexity: 4.7866926193237305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 4769.207839857602
INFO:root:eval perplexity: 7.030054569244385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [6:07:22<17:45:34, 429.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3943.5405622209823
INFO:root:current train perplexity4.690881729125977
INFO:root:current mean train loss 3945.8747421692465
INFO:root:current train perplexity4.719277381896973
INFO:root:current mean train loss 3957.332415741999
INFO:root:current train perplexity4.750420093536377
INFO:root:current mean train loss 3953.9250973381513
INFO:root:current train perplexity4.747747421264648
INFO:root:current mean train loss 3946.3654671183967
INFO:root:current train perplexity4.731207370758057
INFO:root:current mean train loss 3950.1355808717026
INFO:root:current train perplexity4.738325119018555
INFO:root:current mean train loss 3952.2529980629633
INFO:root:current train perplexity4.742768287658691
INFO:root:current mean train loss 3951.497927394581
INFO:root:current train perplexity4.742133140563965
INFO:root:current mean train loss 3952.308214379066
INFO:root:current train perplexity4.741776466369629
INFO:root:current mean train loss 3949.3899243406318
INFO:root:current train perplexity4.741002082824707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.48s/it]
INFO:root:final mean train loss: 3943.5401498117753
INFO:root:final train perplexity: 4.739068984985352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 3880.1258467004654
INFO:root:eval perplexity: 4.801887035369873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 4781.032595370678
INFO:root:eval perplexity: 7.064129829406738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:14:31<17:38:16, 429.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.868619791667
INFO:root:current train perplexity4.741358757019043
INFO:root:current mean train loss 3956.3204356317933
INFO:root:current train perplexity4.732888698577881
INFO:root:current mean train loss 3949.7433241733283
INFO:root:current train perplexity4.732741355895996
INFO:root:current mean train loss 3947.5185523623513
INFO:root:current train perplexity4.729955673217773
INFO:root:current mean train loss 3948.9309246752637
INFO:root:current train perplexity4.733869552612305
INFO:root:current mean train loss 3947.1314510012135
INFO:root:current train perplexity4.7260236740112305
INFO:root:current mean train loss 3946.6521659044715
INFO:root:current train perplexity4.727489471435547
INFO:root:current mean train loss 3946.848840417395
INFO:root:current train perplexity4.732645511627197
INFO:root:current mean train loss 3944.5029141104296
INFO:root:current train perplexity4.732944011688232
INFO:root:current mean train loss 3943.819187318562
INFO:root:current train perplexity4.733651638031006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.86s/it]
INFO:root:final mean train loss: 3937.942937789425
INFO:root:final train perplexity: 4.728615760803223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 3865.689376939273
INFO:root:eval perplexity: 4.773936748504639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 4767.11453138852
INFO:root:eval perplexity: 7.024040222167969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:21:40<17:31:02, 428.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3914.3633024796195
INFO:root:current train perplexity4.628575801849365
INFO:root:current mean train loss 3912.043758733486
INFO:root:current train perplexity4.6758503913879395
INFO:root:current mean train loss 3931.4298944173906
INFO:root:current train perplexity4.69710636138916
INFO:root:current mean train loss 3926.6182638351393
INFO:root:current train perplexity4.703146934509277
INFO:root:current mean train loss 3934.8841197778147
INFO:root:current train perplexity4.711004257202148
INFO:root:current mean train loss 3939.5612279479865
INFO:root:current train perplexity4.722908020019531
INFO:root:current mean train loss 3936.3207192704153
INFO:root:current train perplexity4.722624778747559
INFO:root:current mean train loss 3937.973328903008
INFO:root:current train perplexity4.725067615509033
INFO:root:current mean train loss 3933.7276301331826
INFO:root:current train perplexity4.722585678100586
INFO:root:current mean train loss 3937.172090838299
INFO:root:current train perplexity4.724391937255859

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.45s/it]
INFO:root:final mean train loss: 3935.804924749559
INFO:root:final train perplexity: 4.724628925323486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it]
INFO:root:eval mean loss: 3882.4280010250445
INFO:root:eval perplexity: 4.806359767913818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 4783.1723147994235
INFO:root:eval perplexity: 7.070312976837158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:28:47<17:21:55, 428.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3973.362351940524
INFO:root:current train perplexity4.735990524291992
INFO:root:current mean train loss 3926.8224818105914
INFO:root:current train perplexity4.688251495361328
INFO:root:current mean train loss 3930.577804763596
INFO:root:current train perplexity4.693434715270996
INFO:root:current mean train loss 3932.0851202558533
INFO:root:current train perplexity4.705559730529785
INFO:root:current mean train loss 3931.8863669835773
INFO:root:current train perplexity4.712767124176025
INFO:root:current mean train loss 3933.6271614031602
INFO:root:current train perplexity4.714287281036377
INFO:root:current mean train loss 3934.6057515816906
INFO:root:current train perplexity4.715615749359131
INFO:root:current mean train loss 3935.5293740247735
INFO:root:current train perplexity4.718991756439209
INFO:root:current mean train loss 3937.1592305134063
INFO:root:current train perplexity4.720726490020752
INFO:root:current mean train loss 3936.235466421355
INFO:root:current train perplexity4.718533039093018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.30s/it]
INFO:root:final mean train loss: 3932.561879250311
INFO:root:final train perplexity: 4.718587398529053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 3875.278512508311
INFO:root:eval perplexity: 4.792483806610107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it]
INFO:root:eval mean loss: 4779.977360718639
INFO:root:eval perplexity: 7.06108283996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:35:59<17:18:11, 429.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3998.8322315705127
INFO:root:current train perplexity4.734004974365234
INFO:root:current mean train loss 3961.915190113534
INFO:root:current train perplexity4.7151384353637695
INFO:root:current mean train loss 3947.5907518714043
INFO:root:current train perplexity4.703794956207275
INFO:root:current mean train loss 3932.6729206996683
INFO:root:current train perplexity4.697412014007568
INFO:root:current mean train loss 3939.062978827057
INFO:root:current train perplexity4.704453468322754
INFO:root:current mean train loss 3937.431946819921
INFO:root:current train perplexity4.705336570739746
INFO:root:current mean train loss 3933.9229910168474
INFO:root:current train perplexity4.7038893699646
INFO:root:current mean train loss 3929.70752911187
INFO:root:current train perplexity4.702358722686768
INFO:root:current mean train loss 3926.638574393344
INFO:root:current train perplexity4.701384544372559
INFO:root:current mean train loss 3929.6794376393605
INFO:root:current train perplexity4.708135604858398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.58s/it]
INFO:root:final mean train loss: 3925.518626674529
INFO:root:final train perplexity: 4.705493927001953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 3859.8054476257757
INFO:root:eval perplexity: 4.762591361999512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 4758.355394295767
INFO:root:eval perplexity: 6.998927593231201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:43:12<17:12:52, 430.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3908.441188081782
INFO:root:current train perplexity4.669087886810303
INFO:root:current mean train loss 3923.0276526626276
INFO:root:current train perplexity4.681461334228516
INFO:root:current mean train loss 3913.992840847988
INFO:root:current train perplexity4.6955695152282715
INFO:root:current mean train loss 3916.7811275779
INFO:root:current train perplexity4.698341369628906
INFO:root:current mean train loss 3913.2215415049986
INFO:root:current train perplexity4.6932291984558105
INFO:root:current mean train loss 3914.1534167190357
INFO:root:current train perplexity4.689962387084961
INFO:root:current mean train loss 3915.626236174169
INFO:root:current train perplexity4.694326877593994
INFO:root:current mean train loss 3921.297314257028
INFO:root:current train perplexity4.697487831115723
INFO:root:current mean train loss 3920.5063297852716
INFO:root:current train perplexity4.696962356567383
INFO:root:current mean train loss 3922.581156520179
INFO:root:current train perplexity4.698113918304443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.88s/it]
INFO:root:final mean train loss: 3921.406277994956
INFO:root:final train perplexity: 4.697865009307861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it]
INFO:root:eval mean loss: 3861.01176896332
INFO:root:eval perplexity: 4.764915943145752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 4759.9941891068265
INFO:root:eval perplexity: 7.0036187171936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:50:26<17:08:54, 431.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3910.638454367898
INFO:root:current train perplexity4.691025257110596
INFO:root:current mean train loss 3906.616814201109
INFO:root:current train perplexity4.677501201629639
INFO:root:current mean train loss 3910.3687863817404
INFO:root:current train perplexity4.674891471862793
INFO:root:current mean train loss 3908.6460696797976
INFO:root:current train perplexity4.667630672454834
INFO:root:current mean train loss 3912.504820570055
INFO:root:current train perplexity4.67507266998291
INFO:root:current mean train loss 3915.671746991132
INFO:root:current train perplexity4.678750991821289
INFO:root:current mean train loss 3915.680871302481
INFO:root:current train perplexity4.682755470275879
INFO:root:current mean train loss 3917.482416701159
INFO:root:current train perplexity4.682773590087891
INFO:root:current mean train loss 3915.5722576297517
INFO:root:current train perplexity4.678401470184326
INFO:root:current mean train loss 3916.0868245868783
INFO:root:current train perplexity4.682331085205078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.57s/it]
INFO:root:final mean train loss: 3913.6212495373143
INFO:root:final train perplexity: 4.6834588050842285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it]
INFO:root:eval mean loss: 3884.129908784907
INFO:root:eval perplexity: 4.809668064117432
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it]
INFO:root:eval mean loss: 4788.015782565935
INFO:root:eval perplexity: 7.084331512451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:57:37<17:01:02, 431.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3904.4153994605654
INFO:root:current train perplexity4.68130350112915
INFO:root:current mean train loss 3918.6571576639185
INFO:root:current train perplexity4.682489395141602
INFO:root:current mean train loss 3921.307137260872
INFO:root:current train perplexity4.685765266418457
INFO:root:current mean train loss 3914.3918181280133
INFO:root:current train perplexity4.67637300491333
INFO:root:current mean train loss 3916.869513427207
INFO:root:current train perplexity4.679592132568359
INFO:root:current mean train loss 3913.188780545765
INFO:root:current train perplexity4.67468786239624
INFO:root:current mean train loss 3911.2964128635226
INFO:root:current train perplexity4.674782752990723
INFO:root:current mean train loss 3914.049744532274
INFO:root:current train perplexity4.675791263580322
INFO:root:current mean train loss 3913.9142308240694
INFO:root:current train perplexity4.67502498626709
INFO:root:current mean train loss 3913.5910682559384
INFO:root:current train perplexity4.6761627197265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.75s/it]
INFO:root:final mean train loss: 3910.112372367613
INFO:root:final train perplexity: 4.676979064941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it]
INFO:root:eval mean loss: 3862.8012470218305
INFO:root:eval perplexity: 4.768364429473877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4762.335783397052
INFO:root:eval perplexity: 7.0103278160095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [7:04:46<16:52:14, 430.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3897.3982690085827
INFO:root:current train perplexity4.671287536621094
INFO:root:current mean train loss 3894.0910858689695
INFO:root:current train perplexity4.662594795227051
INFO:root:current mean train loss 3912.7786959827604
INFO:root:current train perplexity4.661654472351074
INFO:root:current mean train loss 3909.966259239176
INFO:root:current train perplexity4.663656234741211
INFO:root:current mean train loss 3905.5208711725386
INFO:root:current train perplexity4.658127784729004
INFO:root:current mean train loss 3904.551820237248
INFO:root:current train perplexity4.657515048980713
INFO:root:current mean train loss 3906.9998228070276
INFO:root:current train perplexity4.661759376525879
INFO:root:current mean train loss 3905.578349191391
INFO:root:current train perplexity4.662417411804199
INFO:root:current mean train loss 3903.227081614165
INFO:root:current train perplexity4.6607465744018555
INFO:root:current mean train loss 3904.616563696817
INFO:root:current train perplexity4.661263465881348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.34s/it]
INFO:root:final mean train loss: 3901.6815585474815
INFO:root:final train perplexity: 4.661449432373047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 3855.04227961547
INFO:root:eval perplexity: 4.753427982330322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 4761.380227379765
INFO:root:eval perplexity: 7.007591724395752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [7:11:54<16:43:13, 429.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3902.6647980122625
INFO:root:current train perplexity4.669606685638428
INFO:root:current mean train loss 3877.7079641672485
INFO:root:current train perplexity4.630244731903076
INFO:root:current mean train loss 3878.6426542548725
INFO:root:current train perplexity4.618925094604492
INFO:root:current mean train loss 3884.508606762244
INFO:root:current train perplexity4.624119758605957
INFO:root:current mean train loss 3883.4223449324763
INFO:root:current train perplexity4.6283345222473145
INFO:root:current mean train loss 3887.7033623940792
INFO:root:current train perplexity4.632143020629883
INFO:root:current mean train loss 3892.7836399892994
INFO:root:current train perplexity4.642705917358398
INFO:root:current mean train loss 3894.8265128570283
INFO:root:current train perplexity4.645577907562256
INFO:root:current mean train loss 3897.2533124244524
INFO:root:current train perplexity4.65005350112915
INFO:root:current mean train loss 3898.97115674277
INFO:root:current train perplexity4.652491092681885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it]
INFO:root:final mean train loss: 3897.180594598093
INFO:root:final train perplexity: 4.6531782150268555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 3859.614089857602
INFO:root:eval perplexity: 4.762223720550537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it]
INFO:root:eval mean loss: 4763.987199066379
INFO:root:eval perplexity: 7.0150651931762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [7:19:09<16:39:31, 431.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3843.311700228987
INFO:root:current train perplexity4.5785231590271
INFO:root:current mean train loss 3874.243359897226
INFO:root:current train perplexity4.629754066467285
INFO:root:current mean train loss 3863.3634717987807
INFO:root:current train perplexity4.620180130004883
INFO:root:current mean train loss 3861.8818756813225
INFO:root:current train perplexity4.618820667266846
INFO:root:current mean train loss 3876.3158944069237
INFO:root:current train perplexity4.627532005310059
INFO:root:current mean train loss 3883.298297420677
INFO:root:current train perplexity4.630610466003418
INFO:root:current mean train loss 3884.6626790364585
INFO:root:current train perplexity4.63256311416626
INFO:root:current mean train loss 3890.9378762929837
INFO:root:current train perplexity4.636946678161621
INFO:root:current mean train loss 3893.958981347326
INFO:root:current train perplexity4.640072345733643
INFO:root:current mean train loss 3894.87764423838
INFO:root:current train perplexity4.643060207366943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.69s/it]
INFO:root:final mean train loss: 3891.213651103358
INFO:root:final train perplexity: 4.642237186431885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it]
INFO:root:eval mean loss: 3858.7896823747783
INFO:root:eval perplexity: 4.760636806488037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4766.262489264738
INFO:root:eval perplexity: 7.0215935707092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [7:26:24<16:34:49, 432.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3914.129818564967
INFO:root:current train perplexity4.633798122406006
INFO:root:current mean train loss 3904.226872996795
INFO:root:current train perplexity4.6335930824279785
INFO:root:current mean train loss 3901.031305448888
INFO:root:current train perplexity4.635268211364746
INFO:root:current mean train loss 3893.350898684731
INFO:root:current train perplexity4.633072853088379
INFO:root:current mean train loss 3889.6857732599433
INFO:root:current train perplexity4.626497745513916
INFO:root:current mean train loss 3889.2268320804883
INFO:root:current train perplexity4.630858898162842
INFO:root:current mean train loss 3888.1848783863534
INFO:root:current train perplexity4.631686687469482
INFO:root:current mean train loss 3894.377251007272
INFO:root:current train perplexity4.636620998382568
INFO:root:current mean train loss 3891.261822407472
INFO:root:current train perplexity4.634459018707275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.00s/it]
INFO:root:final mean train loss: 3887.5558787930395
INFO:root:final train perplexity: 4.635543346405029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it]
INFO:root:eval mean loss: 3845.0123628656916
INFO:root:eval perplexity: 4.73418664932251
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 4754.472303025266
INFO:root:eval perplexity: 6.987823486328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:33:40<16:29:18, 433.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3649.604248046875
INFO:root:current train perplexity4.449911117553711
INFO:root:current mean train loss 3879.9210667286106
INFO:root:current train perplexity4.644132614135742
INFO:root:current mean train loss 3881.5856380368687
INFO:root:current train perplexity4.616898059844971
INFO:root:current mean train loss 3871.243845722463
INFO:root:current train perplexity4.613924026489258
INFO:root:current mean train loss 3870.7410940165555
INFO:root:current train perplexity4.61016845703125
INFO:root:current mean train loss 3872.534260744129
INFO:root:current train perplexity4.612614154815674
INFO:root:current mean train loss 3880.026153007748
INFO:root:current train perplexity4.62019157409668
INFO:root:current mean train loss 3886.3572371199325
INFO:root:current train perplexity4.627732276916504
INFO:root:current mean train loss 3890.7934220671505
INFO:root:current train perplexity4.631051063537598
INFO:root:current mean train loss 3886.7317232488926
INFO:root:current train perplexity4.62864875793457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.54s/it]
INFO:root:final mean train loss: 3883.420541517196
INFO:root:final train perplexity: 4.627986431121826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it]
INFO:root:eval mean loss: 3851.6323120982934
INFO:root:eval perplexity: 4.7468767166137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 4760.569083139406
INFO:root:eval perplexity: 7.005266189575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:40:55<16:23:21, 433.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3906.4535023082385
INFO:root:current train perplexity4.54400634765625
INFO:root:current mean train loss 3868.1707422754785
INFO:root:current train perplexity4.598459243774414
INFO:root:current mean train loss 3881.5967294412767
INFO:root:current train perplexity4.6141438484191895
INFO:root:current mean train loss 3868.865856894343
INFO:root:current train perplexity4.607393264770508
INFO:root:current mean train loss 3875.800807386709
INFO:root:current train perplexity4.614213943481445
INFO:root:current mean train loss 3871.51337279079
INFO:root:current train perplexity4.6030592918396
INFO:root:current mean train loss 3869.7945266948395
INFO:root:current train perplexity4.603588104248047
INFO:root:current mean train loss 3872.397185549622
INFO:root:current train perplexity4.606181621551514
INFO:root:current mean train loss 3876.1221160700525
INFO:root:current train perplexity4.6079206466674805
INFO:root:current mean train loss 3875.1684755226916
INFO:root:current train perplexity4.608784198760986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.03s/it]
INFO:root:final mean train loss: 3877.988447189331
INFO:root:final train perplexity: 4.618078708648682
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it]
INFO:root:eval mean loss: 3845.6133349263077
INFO:root:eval perplexity: 4.7353386878967285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 4754.191182887301
INFO:root:eval perplexity: 6.987019062042236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:48:06<16:14:36, 433.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3849.3377235814146
INFO:root:current train perplexity4.610392093658447
INFO:root:current mean train loss 3856.3450937992384
INFO:root:current train perplexity4.592289924621582
INFO:root:current mean train loss 3858.138416586401
INFO:root:current train perplexity4.59184455871582
INFO:root:current mean train loss 3863.4125249497943
INFO:root:current train perplexity4.592430114746094
INFO:root:current mean train loss 3858.998439014954
INFO:root:current train perplexity4.59003210067749
INFO:root:current mean train loss 3864.4997295166486
INFO:root:current train perplexity4.593476295471191
INFO:root:current mean train loss 3871.8521631884846
INFO:root:current train perplexity4.6012444496154785
INFO:root:current mean train loss 3876.6602027691456
INFO:root:current train perplexity4.605745792388916
INFO:root:current mean train loss 3876.868678278102
INFO:root:current train perplexity4.605429172515869
INFO:root:current mean train loss 3874.3471193531523
INFO:root:current train perplexity4.605853080749512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.42s/it]
INFO:root:final mean train loss: 3870.793742825908
INFO:root:final train perplexity: 4.6049885749816895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it]
INFO:root:eval mean loss: 3856.7959105579566
INFO:root:eval perplexity: 4.756799697875977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 4766.772279130651
INFO:root:eval perplexity: 7.023058891296387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:55:23<16:10:03, 434.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3926.4988425925926
INFO:root:current train perplexity4.659922122955322
INFO:root:current mean train loss 3874.6784110482286
INFO:root:current train perplexity4.5938005447387695
INFO:root:current mean train loss 3869.94617075647
INFO:root:current train perplexity4.595947265625
INFO:root:current mean train loss 3868.239992474197
INFO:root:current train perplexity4.590098857879639
INFO:root:current mean train loss 3867.9129229864975
INFO:root:current train perplexity4.594785213470459
INFO:root:current mean train loss 3870.3756244811434
INFO:root:current train perplexity4.595097541809082
INFO:root:current mean train loss 3867.491819536857
INFO:root:current train perplexity4.590771675109863
INFO:root:current mean train loss 3864.861626332531
INFO:root:current train perplexity4.588596820831299
INFO:root:current mean train loss 3865.666983035917
INFO:root:current train perplexity4.588726997375488
INFO:root:current mean train loss 3866.8410073026225
INFO:root:current train perplexity4.595344066619873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.23s/it]
INFO:root:final mean train loss: 3866.1647630506945
INFO:root:final train perplexity: 4.596586227416992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it]
INFO:root:eval mean loss: 3851.5392200659353
INFO:root:eval perplexity: 4.746699333190918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4760.960747035682
INFO:root:eval perplexity: 7.006387233734131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [8:02:37<16:02:35, 434.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3853.3327008928572
INFO:root:current train perplexity4.575992584228516
INFO:root:current mean train loss 3856.494887514468
INFO:root:current train perplexity4.54783821105957
INFO:root:current mean train loss 3865.0483907496678
INFO:root:current train perplexity4.569260120391846
INFO:root:current mean train loss 3874.6142767607275
INFO:root:current train perplexity4.592343807220459
INFO:root:current mean train loss 3870.063211655891
INFO:root:current train perplexity4.587741374969482
INFO:root:current mean train loss 3870.9080794575057
INFO:root:current train perplexity4.591013431549072
INFO:root:current mean train loss 3872.5718480868604
INFO:root:current train perplexity4.593335151672363
INFO:root:current mean train loss 3868.482957987883
INFO:root:current train perplexity4.591935634613037
INFO:root:current mean train loss 3867.7355784524702
INFO:root:current train perplexity4.593350410461426
INFO:root:current mean train loss 3867.2974011426304
INFO:root:current train perplexity4.590888977050781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.37s/it]
INFO:root:final mean train loss: 3861.649264366396
INFO:root:final train perplexity: 4.588404655456543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 3848.664323955563
INFO:root:eval perplexity: 4.741184234619141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 4755.717627992021
INFO:root:eval perplexity: 6.991383075714111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [8:09:49<15:53:41, 433.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.5912291061045
INFO:root:current train perplexity4.54996395111084
INFO:root:current mean train loss 3835.2702687937062
INFO:root:current train perplexity4.565939903259277
INFO:root:current mean train loss 3844.306830512153
INFO:root:current train perplexity4.567394733428955
INFO:root:current mean train loss 3842.8138915303844
INFO:root:current train perplexity4.5603532791137695
INFO:root:current mean train loss 3851.450841761604
INFO:root:current train perplexity4.566958427429199
INFO:root:current mean train loss 3853.9694941118496
INFO:root:current train perplexity4.568085193634033
INFO:root:current mean train loss 3856.950568927391
INFO:root:current train perplexity4.572445869445801
INFO:root:current mean train loss 3856.802216849449
INFO:root:current train perplexity4.573599815368652
INFO:root:current mean train loss 3858.4880527482765
INFO:root:current train perplexity4.574674129486084
INFO:root:current mean train loss 3855.8436410040263
INFO:root:current train perplexity4.57430362701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.23s/it]
INFO:root:final mean train loss: 3853.9395679350823
INFO:root:final train perplexity: 4.574468612670898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 3839.9207737699467
INFO:root:eval perplexity: 4.72445011138916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4749.827567458999
INFO:root:eval perplexity: 6.974564075469971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [8:17:01<15:45:32, 433.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3837.613185508578
INFO:root:current train perplexity4.52518892288208
INFO:root:current mean train loss 3851.2749346802566
INFO:root:current train perplexity4.567122936248779
INFO:root:current mean train loss 3863.538922435259
INFO:root:current train perplexity4.58250617980957
INFO:root:current mean train loss 3860.958653289708
INFO:root:current train perplexity4.576889514923096
INFO:root:current mean train loss 3864.9352193692835
INFO:root:current train perplexity4.582030773162842
INFO:root:current mean train loss 3861.520895956216
INFO:root:current train perplexity4.579453945159912
INFO:root:current mean train loss 3858.5932103404616
INFO:root:current train perplexity4.573175430297852
INFO:root:current mean train loss 3850.793419646201
INFO:root:current train perplexity4.565140724182129
INFO:root:current mean train loss 3849.893403785069
INFO:root:current train perplexity4.562857151031494
INFO:root:current mean train loss 3849.674344388719
INFO:root:current train perplexity4.561615943908691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.29s/it]
INFO:root:final mean train loss: 3848.721460342407
INFO:root:final train perplexity: 4.565061569213867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 3839.4085251828456
INFO:root:eval perplexity: 4.7234721183776855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it]
INFO:root:eval mean loss: 4756.203943996565
INFO:root:eval perplexity: 6.992772579193115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [8:24:07<15:33:17, 430.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3854.165676310911
INFO:root:current train perplexity4.564967632293701
INFO:root:current mean train loss 3863.760240086969
INFO:root:current train perplexity4.569624423980713
INFO:root:current mean train loss 3854.5951761960064
INFO:root:current train perplexity4.565324306488037
INFO:root:current mean train loss 3847.378966775113
INFO:root:current train perplexity4.558393478393555
INFO:root:current mean train loss 3846.593681917211
INFO:root:current train perplexity4.563044548034668
INFO:root:current mean train loss 3846.605521596182
INFO:root:current train perplexity4.563684463500977
INFO:root:current mean train loss 3838.56525778879
INFO:root:current train perplexity4.550117015838623
INFO:root:current mean train loss 3845.7506114773755
INFO:root:current train perplexity4.550090312957764
INFO:root:current mean train loss 3843.9806244997817
INFO:root:current train perplexity4.550354957580566
INFO:root:current mean train loss 3846.713899518949
INFO:root:current train perplexity4.554797172546387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.64s/it]
INFO:root:final mean train loss: 3842.5145145539313
INFO:root:final train perplexity: 4.553896903991699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 3843.511407081117
INFO:root:eval perplexity: 4.731315612792969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 4755.118068830341
INFO:root:eval perplexity: 6.989668369293213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [8:31:12<15:22:56, 429.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3831.1872339960355
INFO:root:current train perplexity4.530759334564209
INFO:root:current mean train loss 3829.8656451744946
INFO:root:current train perplexity4.518854141235352
INFO:root:current mean train loss 3846.032304285171
INFO:root:current train perplexity4.540904521942139
INFO:root:current mean train loss 3836.6054627629
INFO:root:current train perplexity4.537712574005127
INFO:root:current mean train loss 3838.4011596418295
INFO:root:current train perplexity4.538421154022217
INFO:root:current mean train loss 3840.1885480392966
INFO:root:current train perplexity4.54144287109375
INFO:root:current mean train loss 3842.777493821449
INFO:root:current train perplexity4.545077323913574
INFO:root:current mean train loss 3842.4892606772532
INFO:root:current train perplexity4.547974586486816
INFO:root:current mean train loss 3843.357413990412
INFO:root:current train perplexity4.547606945037842
INFO:root:current mean train loss 3841.962096094962
INFO:root:current train perplexity4.547677993774414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.12s/it]
INFO:root:final mean train loss: 3839.1091749745033
INFO:root:final train perplexity: 4.547781944274902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it]
INFO:root:eval mean loss: 3843.24111051086
INFO:root:eval perplexity: 4.730797290802002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 4761.663511884974
INFO:root:eval perplexity: 7.008401870727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:38:21<15:15:04, 428.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.911357421875
INFO:root:current train perplexity4.587025165557861
INFO:root:current mean train loss 3846.501841517857
INFO:root:current train perplexity4.562985897064209
INFO:root:current mean train loss 3848.7594770951705
INFO:root:current train perplexity4.553674221038818
INFO:root:current mean train loss 3844.1026640625
INFO:root:current train perplexity4.543451309204102
INFO:root:current mean train loss 3837.4745518092104
INFO:root:current train perplexity4.538228988647461
INFO:root:current mean train loss 3839.791345533288
INFO:root:current train perplexity4.54010534286499
INFO:root:current mean train loss 3834.7016156684026
INFO:root:current train perplexity4.5356221199035645
INFO:root:current mean train loss 3832.340748172883
INFO:root:current train perplexity4.533287525177002
INFO:root:current mean train loss 3837.5242455357143
INFO:root:current train perplexity4.538258075714111
INFO:root:current mean train loss 3836.142530799279
INFO:root:current train perplexity4.537524223327637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.41s/it]
INFO:root:final mean train loss: 3833.2619716890395
INFO:root:final train perplexity: 4.537302494049072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 3840.4342292082224
INFO:root:eval perplexity: 4.725430965423584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4757.211529670878
INFO:root:eval perplexity: 6.995654106140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:45:28<15:06:57, 428.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.515866199172
INFO:root:current train perplexity4.494403839111328
INFO:root:current mean train loss 3819.1638503778177
INFO:root:current train perplexity4.503468036651611
INFO:root:current mean train loss 3832.616158313549
INFO:root:current train perplexity4.5238423347473145
INFO:root:current mean train loss 3838.743742223197
INFO:root:current train perplexity4.525223255157471
INFO:root:current mean train loss 3842.0107335945586
INFO:root:current train perplexity4.531534194946289
INFO:root:current mean train loss 3842.793128718643
INFO:root:current train perplexity4.534465312957764
INFO:root:current mean train loss 3841.8658377562224
INFO:root:current train perplexity4.534722328186035
INFO:root:current mean train loss 3840.3175465083214
INFO:root:current train perplexity4.532027721405029
INFO:root:current mean train loss 3837.599184686438
INFO:root:current train perplexity4.531274318695068
INFO:root:current mean train loss 3830.4085950414865
INFO:root:current train perplexity4.526825428009033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.88s/it]
INFO:root:final mean train loss: 3826.4350162629157
INFO:root:final train perplexity: 4.5250983238220215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 3828.705471174091
INFO:root:eval perplexity: 4.703073501586914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it]
INFO:root:eval mean loss: 4745.782108820922
INFO:root:eval perplexity: 6.963034629821777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:52:36<14:59:31, 428.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3815.4700726519573
INFO:root:current train perplexity4.465288162231445
INFO:root:current mean train loss 3831.2560894551702
INFO:root:current train perplexity4.4943060874938965
INFO:root:current mean train loss 3828.4423467367374
INFO:root:current train perplexity4.502472400665283
INFO:root:current mean train loss 3831.3138905400815
INFO:root:current train perplexity4.510079860687256
INFO:root:current mean train loss 3829.029952723237
INFO:root:current train perplexity4.510547161102295
INFO:root:current mean train loss 3827.952753212246
INFO:root:current train perplexity4.509426116943359
INFO:root:current mean train loss 3824.4758435040926
INFO:root:current train perplexity4.508683681488037
INFO:root:current mean train loss 3823.3654133908817
INFO:root:current train perplexity4.50744104385376
INFO:root:current mean train loss 3822.7683195891204
INFO:root:current train perplexity4.5099897384643555
INFO:root:current mean train loss 3821.6751454004007
INFO:root:current train perplexity4.511444091796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.23s/it]
INFO:root:final mean train loss: 3818.78912648847
INFO:root:final train perplexity: 4.51146936416626
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 3829.7978550254875
INFO:root:eval perplexity: 4.705150604248047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it]
INFO:root:eval mean loss: 4738.589748517841
INFO:root:eval perplexity: 6.942588806152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:59:42<14:50:52, 427.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3798.859498303346
INFO:root:current train perplexity4.471814155578613
INFO:root:current mean train loss 3805.7496675270886
INFO:root:current train perplexity4.499077796936035
INFO:root:current mean train loss 3803.9345237706416
INFO:root:current train perplexity4.491581439971924
INFO:root:current mean train loss 3801.140021073191
INFO:root:current train perplexity4.486477375030518
INFO:root:current mean train loss 3808.1591346756013
INFO:root:current train perplexity4.491331577301025
INFO:root:current mean train loss 3810.4767133047267
INFO:root:current train perplexity4.495684623718262
INFO:root:current mean train loss 3817.9491984922656
INFO:root:current train perplexity4.504430770874023
INFO:root:current mean train loss 3823.170188321339
INFO:root:current train perplexity4.510217189788818
INFO:root:current mean train loss 3820.6457780237592
INFO:root:current train perplexity4.508275032043457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.44s/it]
INFO:root:final mean train loss: 3817.1113892216836
INFO:root:final train perplexity: 4.50848388671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 3830.7123729083555
INFO:root:eval perplexity: 4.70689058303833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 4751.516115012744
INFO:root:eval perplexity: 6.9793806076049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [9:06:48<14:42:34, 427.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3747.4393484933034
INFO:root:current train perplexity4.445910453796387
INFO:root:current mean train loss 3860.7798353533876
INFO:root:current train perplexity4.537188529968262
INFO:root:current mean train loss 3827.6104152513585
INFO:root:current train perplexity4.509160995483398
INFO:root:current mean train loss 3818.21990231194
INFO:root:current train perplexity4.507430076599121
INFO:root:current mean train loss 3812.0537403303515
INFO:root:current train perplexity4.503305435180664
INFO:root:current mean train loss 3813.816401434603
INFO:root:current train perplexity4.5034332275390625
INFO:root:current mean train loss 3810.489803609581
INFO:root:current train perplexity4.494006156921387
INFO:root:current mean train loss 3813.4083550654173
INFO:root:current train perplexity4.494875431060791
INFO:root:current mean train loss 3815.9367488213484
INFO:root:current train perplexity4.496293067932129
INFO:root:current mean train loss 3815.6328698340167
INFO:root:current train perplexity4.497173309326172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.78s/it]
INFO:root:final mean train loss: 3810.358349769346
INFO:root:final train perplexity: 4.496487617492676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it]
INFO:root:eval mean loss: 3822.105664408799
INFO:root:eval perplexity: 4.690537929534912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 4739.746440048759
INFO:root:eval perplexity: 6.945872783660889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [9:13:53<14:34:12, 426.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3794.9138997395835
INFO:root:current train perplexity4.5030903816223145
INFO:root:current mean train loss 3807.3064346976903
INFO:root:current train perplexity4.489963054656982
INFO:root:current mean train loss 3802.2880666333576
INFO:root:current train perplexity4.4808831214904785
INFO:root:current mean train loss 3807.177576264881
INFO:root:current train perplexity4.473762035369873
INFO:root:current mean train loss 3797.1123370434866
INFO:root:current train perplexity4.4653096199035645
INFO:root:current mean train loss 3804.7706182683555
INFO:root:current train perplexity4.473931789398193
INFO:root:current mean train loss 3810.4101868172
INFO:root:current train perplexity4.482606410980225
INFO:root:current mean train loss 3805.354621599104
INFO:root:current train perplexity4.4766764640808105
INFO:root:current mean train loss 3804.4980510688265
INFO:root:current train perplexity4.481232643127441
INFO:root:current mean train loss 3809.036989839481
INFO:root:current train perplexity4.487117290496826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.89s/it]
INFO:root:final mean train loss: 3805.838985689225
INFO:root:final train perplexity: 4.488478183746338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.65s/it]
INFO:root:eval mean loss: 3828.6352348598184
INFO:root:eval perplexity: 4.702939510345459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 4744.562733751663
INFO:root:eval perplexity: 6.959563732147217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [9:21:01<14:28:24, 427.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3748.8614448879075
INFO:root:current train perplexity4.403390407562256
INFO:root:current mean train loss 3781.1985260257875
INFO:root:current train perplexity4.459235191345215
INFO:root:current mean train loss 3777.874166856432
INFO:root:current train perplexity4.4672722816467285
INFO:root:current mean train loss 3782.1294905246227
INFO:root:current train perplexity4.468688011169434
INFO:root:current mean train loss 3785.4883741735002
INFO:root:current train perplexity4.468120574951172
INFO:root:current mean train loss 3789.169821978071
INFO:root:current train perplexity4.467641353607178
INFO:root:current mean train loss 3792.8230125463983
INFO:root:current train perplexity4.470374584197998
INFO:root:current mean train loss 3795.7870438656205
INFO:root:current train perplexity4.472211837768555
INFO:root:current mean train loss 3800.46279718114
INFO:root:current train perplexity4.47682523727417
INFO:root:current mean train loss 3803.2251672217803
INFO:root:current train perplexity4.47791862487793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.84s/it]
INFO:root:final mean train loss: 3798.828426545666
INFO:root:final train perplexity: 4.476080417633057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 3848.0341987339316
INFO:root:eval perplexity: 4.739976406097412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 4760.286988170435
INFO:root:eval perplexity: 7.004456996917725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [9:28:11<14:22:46, 427.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3809.384781376008
INFO:root:current train perplexity4.498782157897949
INFO:root:current mean train loss 3797.8736674767415
INFO:root:current train perplexity4.48061466217041
INFO:root:current mean train loss 3801.406688607616
INFO:root:current train perplexity4.457414627075195
INFO:root:current mean train loss 3796.676926719458
INFO:root:current train perplexity4.459011077880859
INFO:root:current mean train loss 3788.4372054451856
INFO:root:current train perplexity4.4514594078063965
INFO:root:current mean train loss 3788.360002593132
INFO:root:current train perplexity4.450911521911621
INFO:root:current mean train loss 3791.068043268993
INFO:root:current train perplexity4.454266548156738
INFO:root:current mean train loss 3797.688225742241
INFO:root:current train perplexity4.464840412139893
INFO:root:current mean train loss 3797.436908891772
INFO:root:current train perplexity4.467245578765869
INFO:root:current mean train loss 3795.4240360772187
INFO:root:current train perplexity4.465970039367676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.93s/it]
INFO:root:final mean train loss: 3794.0597246231573
INFO:root:final train perplexity: 4.467667102813721
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 3826.97893984098
INFO:root:eval perplexity: 4.699790954589844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 4749.156554742908
INFO:root:eval perplexity: 6.97265100479126
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [9:35:16<14:14:00, 427.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3785.4591033153047
INFO:root:current train perplexity4.43159818649292
INFO:root:current mean train loss 3802.3547345717175
INFO:root:current train perplexity4.46307373046875
INFO:root:current mean train loss 3796.1946097018827
INFO:root:current train perplexity4.4632768630981445
INFO:root:current mean train loss 3813.985291067478
INFO:root:current train perplexity4.4742841720581055
INFO:root:current mean train loss 3811.479257501068
INFO:root:current train perplexity4.475719451904297
INFO:root:current mean train loss 3804.9547370528467
INFO:root:current train perplexity4.4725847244262695
INFO:root:current mean train loss 3797.5812888943906
INFO:root:current train perplexity4.464482307434082
INFO:root:current mean train loss 3791.8327435195365
INFO:root:current train perplexity4.4588117599487305
INFO:root:current mean train loss 3790.6800532744523
INFO:root:current train perplexity4.458878040313721
INFO:root:current mean train loss 3791.2086115340453
INFO:root:current train perplexity4.457307815551758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.66s/it]
INFO:root:final mean train loss: 3787.538419538929
INFO:root:final train perplexity: 4.456186771392822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 3823.8430158466313
INFO:root:eval perplexity: 4.6938347816467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 4740.174776983599
INFO:root:eval perplexity: 6.947088718414307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [9:42:23<14:06:56, 427.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3726.425241023936
INFO:root:current train perplexity4.421186447143555
INFO:root:current mean train loss 3758.102906103848
INFO:root:current train perplexity4.444042205810547
INFO:root:current mean train loss 3766.468823143345
INFO:root:current train perplexity4.444886684417725
INFO:root:current mean train loss 3772.1603011865095
INFO:root:current train perplexity4.4455952644348145
INFO:root:current mean train loss 3780.403767630558
INFO:root:current train perplexity4.443530559539795
INFO:root:current mean train loss 3782.8619436093177
INFO:root:current train perplexity4.444823265075684
INFO:root:current mean train loss 3784.5315224413157
INFO:root:current train perplexity4.4441609382629395
INFO:root:current mean train loss 3785.3986986356886
INFO:root:current train perplexity4.443209648132324
INFO:root:current mean train loss 3783.2837427132526
INFO:root:current train perplexity4.442812442779541
INFO:root:current mean train loss 3784.5576393586657
INFO:root:current train perplexity4.4461493492126465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.39s/it]
INFO:root:final mean train loss: 3782.225897142964
INFO:root:final train perplexity: 4.44685697555542
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 3817.771325077571
INFO:root:eval perplexity: 4.682324409484863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4739.782442999224
INFO:root:eval perplexity: 6.9459733963012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:49:28<13:58:38, 426.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3755.463955965909
INFO:root:current train perplexity4.4407958984375
INFO:root:current mean train loss 3771.3179561491934
INFO:root:current train perplexity4.450018882751465
INFO:root:current mean train loss 3770.766238702512
INFO:root:current train perplexity4.444388389587402
INFO:root:current mean train loss 3770.487841796875
INFO:root:current train perplexity4.433982849121094
INFO:root:current mean train loss 3779.100591303228
INFO:root:current train perplexity4.4396843910217285
INFO:root:current mean train loss 3783.604758762669
INFO:root:current train perplexity4.444481372833252
INFO:root:current mean train loss 3779.6326604246183
INFO:root:current train perplexity4.441534996032715
INFO:root:current mean train loss 3781.948522221647
INFO:root:current train perplexity4.445522785186768
INFO:root:current mean train loss 3786.333284505208
INFO:root:current train perplexity4.448019504547119
INFO:root:current mean train loss 3785.7444946928176
INFO:root:current train perplexity4.448093414306641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.69s/it]
INFO:root:final mean train loss: 3781.7685339527748
INFO:root:final train perplexity: 4.446054935455322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 3825.1330687610816
INFO:root:eval perplexity: 4.69628381729126
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4746.571685574579
INFO:root:eval perplexity: 6.965282917022705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:56:31<13:49:20, 425.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3735.915259951637
INFO:root:current train perplexity4.3875908851623535
INFO:root:current mean train loss 3749.5858910683473
INFO:root:current train perplexity4.4095845222473145
INFO:root:current mean train loss 3758.526525925321
INFO:root:current train perplexity4.413877964019775
INFO:root:current mean train loss 3775.3721416042526
INFO:root:current train perplexity4.432069778442383
INFO:root:current mean train loss 3775.766354785367
INFO:root:current train perplexity4.434752941131592
INFO:root:current mean train loss 3779.4745148409747
INFO:root:current train perplexity4.439997673034668
INFO:root:current mean train loss 3775.4192211214413
INFO:root:current train perplexity4.434114456176758
INFO:root:current mean train loss 3776.89110912158
INFO:root:current train perplexity4.435060977935791
INFO:root:current mean train loss 3775.897345798179
INFO:root:current train perplexity4.433182716369629
INFO:root:current mean train loss 3776.4269730517426
INFO:root:current train perplexity4.431437015533447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.08s/it]
INFO:root:final mean train loss: 3774.108538104642
INFO:root:final train perplexity: 4.432638168334961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 3813.7136680657136
INFO:root:eval perplexity: 4.674647808074951
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it]
INFO:root:eval mean loss: 4738.985628601507
INFO:root:eval perplexity: 6.943711280822754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [10:03:38<13:43:10, 425.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3731.179460552377
INFO:root:current train perplexity4.380773067474365
INFO:root:current mean train loss 3753.8228395696274
INFO:root:current train perplexity4.416292190551758
INFO:root:current mean train loss 3756.130626945918
INFO:root:current train perplexity4.420187473297119
INFO:root:current mean train loss 3771.06851336127
INFO:root:current train perplexity4.429056644439697
INFO:root:current mean train loss 3772.819401249005
INFO:root:current train perplexity4.435842990875244
INFO:root:current mean train loss 3766.5764981084444
INFO:root:current train perplexity4.42412805557251
INFO:root:current mean train loss 3768.2900314217354
INFO:root:current train perplexity4.4255523681640625
INFO:root:current mean train loss 3772.1321852074216
INFO:root:current train perplexity4.4278459548950195
INFO:root:current mean train loss 3772.5973863218464
INFO:root:current train perplexity4.428387641906738
INFO:root:current mean train loss 3771.167823422213
INFO:root:current train perplexity4.425802707672119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.74s/it]
INFO:root:final mean train loss: 3770.3596027743433
INFO:root:final train perplexity: 4.426086902618408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it]
INFO:root:eval mean loss: 3834.7219099761746
INFO:root:eval perplexity: 4.7145280838012695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 4761.631654130651
INFO:root:eval perplexity: 7.008309841156006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [10:10:43<13:35:54, 425.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3734.8927141020567
INFO:root:current train perplexity4.396390438079834
INFO:root:current mean train loss 3740.3699712486905
INFO:root:current train perplexity4.396263122558594
INFO:root:current mean train loss 3759.4996884800626
INFO:root:current train perplexity4.413009166717529
INFO:root:current mean train loss 3758.2353406116013
INFO:root:current train perplexity4.406192302703857
INFO:root:current mean train loss 3757.8584968073133
INFO:root:current train perplexity4.404462814331055
INFO:root:current mean train loss 3762.806999456903
INFO:root:current train perplexity4.409529685974121
INFO:root:current mean train loss 3761.4622815318944
INFO:root:current train perplexity4.411744594573975
INFO:root:current mean train loss 3762.3283365467546
INFO:root:current train perplexity4.4116530418396
INFO:root:current mean train loss 3766.8094575467508
INFO:root:current train perplexity4.416550636291504
INFO:root:current mean train loss 3769.328465649738
INFO:root:current train perplexity4.419931411743164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.26s/it]
INFO:root:final mean train loss: 3766.4913032900904
INFO:root:final train perplexity: 4.419336795806885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 3814.707813885195
INFO:root:eval perplexity: 4.676527976989746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 4739.538785460993
INFO:root:eval perplexity: 6.945281028747559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [10:17:49<13:28:54, 425.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3761.9744213586564
INFO:root:current train perplexity4.400254249572754
INFO:root:current mean train loss 3752.156589446858
INFO:root:current train perplexity4.393042087554932
INFO:root:current mean train loss 3756.8819907583843
INFO:root:current train perplexity4.3940839767456055
INFO:root:current mean train loss 3759.6944040697676
INFO:root:current train perplexity4.398656845092773
INFO:root:current mean train loss 3763.2763255783175
INFO:root:current train perplexity4.404539108276367
INFO:root:current mean train loss 3763.928788297221
INFO:root:current train perplexity4.4078049659729
INFO:root:current mean train loss 3763.771012085494
INFO:root:current train perplexity4.41017484664917
INFO:root:current mean train loss 3766.118242237135
INFO:root:current train perplexity4.413395404815674
INFO:root:current mean train loss 3766.12867944969
INFO:root:current train perplexity4.4135284423828125
INFO:root:current mean train loss 3764.5413646446777
INFO:root:current train perplexity4.411114692687988

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.61s/it]
INFO:root:final mean train loss: 3761.671001865018
INFO:root:final train perplexity: 4.410940647125244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 3824.700179729056
INFO:root:eval perplexity: 4.695462226867676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4750.157875872673
INFO:root:eval perplexity: 6.975505352020264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [10:24:52<13:20:11, 424.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3784.1625719572367
INFO:root:current train perplexity4.425842761993408
INFO:root:current mean train loss 3772.9478340344554
INFO:root:current train perplexity4.4088826179504395
INFO:root:current mean train loss 3765.538300284693
INFO:root:current train perplexity4.403311729431152
INFO:root:current mean train loss 3762.7927054489714
INFO:root:current train perplexity4.402316570281982
INFO:root:current mean train loss 3763.9883567116476
INFO:root:current train perplexity4.401177883148193
INFO:root:current mean train loss 3761.3617511653097
INFO:root:current train perplexity4.40054988861084
INFO:root:current mean train loss 3762.6133880395682
INFO:root:current train perplexity4.402669906616211
INFO:root:current mean train loss 3760.9404290733096
INFO:root:current train perplexity4.400691509246826
INFO:root:current mean train loss 3759.857626462116
INFO:root:current train perplexity4.400989055633545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.68s/it]
INFO:root:final mean train loss: 3755.87973231654
INFO:root:final train perplexity: 4.400874137878418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 3814.5117793522827
INFO:root:eval perplexity: 4.676156520843506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 4742.115554701352
INFO:root:eval perplexity: 6.952603816986084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:31:56<13:12:42, 424.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3912.7827962239585
INFO:root:current train perplexity4.5863118171691895
INFO:root:current mean train loss 3715.015949730734
INFO:root:current train perplexity4.336113929748535
INFO:root:current mean train loss 3721.574239195274
INFO:root:current train perplexity4.35231876373291
INFO:root:current mean train loss 3737.7669593131186
INFO:root:current train perplexity4.376915454864502
INFO:root:current mean train loss 3738.1150980681996
INFO:root:current train perplexity4.381601810455322
INFO:root:current mean train loss 3754.130925870558
INFO:root:current train perplexity4.400477886199951
INFO:root:current mean train loss 3754.3518641331107
INFO:root:current train perplexity4.3977532386779785
INFO:root:current mean train loss 3756.3562893820013
INFO:root:current train perplexity4.397218227386475
INFO:root:current mean train loss 3754.878826896696
INFO:root:current train perplexity4.39500617980957
INFO:root:current mean train loss 3754.101493556634
INFO:root:current train perplexity4.394315242767334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.20s/it]
INFO:root:final mean train loss: 3752.742658861222
INFO:root:final train perplexity: 4.395430088043213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 3818.221258934508
INFO:root:eval perplexity: 4.683176040649414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 4745.244649684176
INFO:root:eval perplexity: 6.9615044593811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:38:59<13:04:44, 424.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3867.9504838423295
INFO:root:current train perplexity4.575144290924072
INFO:root:current mean train loss 3764.621870161177
INFO:root:current train perplexity4.391280174255371
INFO:root:current mean train loss 3747.1473128332345
INFO:root:current train perplexity4.374208927154541
INFO:root:current mean train loss 3735.8036355757636
INFO:root:current train perplexity4.359170436859131
INFO:root:current mean train loss 3740.9928925971335
INFO:root:current train perplexity4.366029739379883
INFO:root:current mean train loss 3745.3791589904904
INFO:root:current train perplexity4.3708109855651855
INFO:root:current mean train loss 3750.4369589747853
INFO:root:current train perplexity4.378386974334717
INFO:root:current mean train loss 3751.1510914562455
INFO:root:current train perplexity4.381321907043457
INFO:root:current mean train loss 3748.1472375683957
INFO:root:current train perplexity4.378357410430908
INFO:root:current mean train loss 3751.3077026769174
INFO:root:current train perplexity4.384372234344482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.63s/it]
INFO:root:final mean train loss: 3747.346213863742
INFO:root:final train perplexity: 4.386082649230957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 3807.925973445811
INFO:root:eval perplexity: 4.663720607757568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4731.31317528258
INFO:root:eval perplexity: 6.921958923339844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:46:03<12:57:37, 424.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3750.7458753083883
INFO:root:current train perplexity4.437966823577881
INFO:root:current mean train loss 3737.264777688419
INFO:root:current train perplexity4.364119052886963
INFO:root:current mean train loss 3721.316111943493
INFO:root:current train perplexity4.33502721786499
INFO:root:current mean train loss 3816.3473547095414
INFO:root:current train perplexity4.499929904937744
INFO:root:current mean train loss 4910.729002740901
INFO:root:current train perplexity6.938372611999512
INFO:root:current mean train loss 5481.714597257346
INFO:root:current train perplexity8.698955535888672
INFO:root:current mean train loss 6396.140262930382
INFO:root:current train perplexity12.466363906860352
INFO:root:current mean train loss 8100.126356185892
INFO:root:current train perplexity24.38300323486328
INFO:root:current mean train loss 9101.873989454556
INFO:root:current train perplexity36.19791030883789
INFO:root:current mean train loss 9507.41941765421
INFO:root:current train perplexity42.436241149902344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.45s/it]
INFO:root:final mean train loss: 9516.887793756301
INFO:root:final train perplexity: 42.72087860107422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 8513.96016179078
INFO:root:eval perplexity: 31.274263381958008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 9177.872638242465
INFO:root:eval perplexity: 42.64706802368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:53:08<12:50:47, 424.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10088.492476851852
INFO:root:current train perplexity54.45832824707031
INFO:root:current mean train loss 10576.683739849901
INFO:root:current train perplexity63.9923095703125
INFO:root:current mean train loss 10722.750249518172
INFO:root:current train perplexity68.13134765625
INFO:root:current mean train loss 10992.232654816513
INFO:root:current train perplexity75.18003845214844
INFO:root:current mean train loss 11095.7922597702
INFO:root:current train perplexity78.53231048583984
INFO:root:current mean train loss 11132.760786660934
INFO:root:current train perplexity79.83012390136719
INFO:root:current mean train loss 11247.637770073266
INFO:root:current train perplexity83.52027130126953
INFO:root:current mean train loss 11406.961693765044
INFO:root:current train perplexity89.25275421142578
INFO:root:current mean train loss 11558.13133879988
INFO:root:current train perplexity95.10977935791016
INFO:root:current mean train loss 11732.921535784115
INFO:root:current train perplexity101.89232635498047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.17s/it]
INFO:root:final mean train loss: 11848.492243859077
INFO:root:final train perplexity: 107.18678283691406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it]
INFO:root:eval mean loss: 12295.709850121897
INFO:root:eval perplexity: 144.31875610351562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 12680.060816988032
INFO:root:eval perplexity: 178.58255004882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [11:00:11<12:43:04, 423.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13916.890457589287
INFO:root:current train perplexity237.6170196533203
INFO:root:current mean train loss 13377.764337384258
INFO:root:current train perplexity190.1470947265625
INFO:root:current mean train loss 13425.071139461435
INFO:root:current train perplexity196.8153839111328
INFO:root:current mean train loss 13527.891374183768
INFO:root:current train perplexity205.708740234375
INFO:root:current mean train loss 13443.12574308549
INFO:root:current train perplexity198.2093505859375
INFO:root:current mean train loss 13404.667525189836
INFO:root:current train perplexity196.822509765625
INFO:root:current mean train loss 13457.825728961614
INFO:root:current train perplexity201.82196044921875
INFO:root:current mean train loss 13525.582536139456
INFO:root:current train perplexity207.02804565429688
INFO:root:current mean train loss 13576.49934505988
INFO:root:current train perplexity211.3839874267578
INFO:root:current mean train loss 13619.778639914774
INFO:root:current train perplexity214.87985229492188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.11s/it]
INFO:root:final mean train loss: 13627.302787288543
INFO:root:final train perplexity: 216.23497009277344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it]
INFO:root:eval mean loss: 11917.931578291224
INFO:root:eval perplexity: 123.87358093261719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it]
INFO:root:eval mean loss: 12289.118427249557
INFO:root:eval perplexity: 152.19908142089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [11:07:14<12:35:46, 423.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14014.25753997093
INFO:root:current train perplexity248.40249633789062
INFO:root:current mean train loss 13883.031413898601
INFO:root:current train perplexity237.50125122070312
INFO:root:current mean train loss 13834.35298112783
INFO:root:current train perplexity231.95474243164062
INFO:root:current mean train loss 13677.756366162537
INFO:root:current train perplexity217.49905395507812
INFO:root:current mean train loss 13661.511813540492
INFO:root:current train perplexity216.28323364257812
INFO:root:current mean train loss 13634.947477843001
INFO:root:current train perplexity214.80291748046875
INFO:root:current mean train loss 13600.517717850895
INFO:root:current train perplexity211.9829559326172
INFO:root:current mean train loss 13631.449275267076
INFO:root:current train perplexity213.82125854492188
INFO:root:current mean train loss 13619.845919752743
INFO:root:current train perplexity213.64718627929688
INFO:root:current mean train loss 13587.893264721964
INFO:root:current train perplexity211.45042419433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.19s/it]
INFO:root:final mean train loss: 13548.672030787315
INFO:root:final train perplexity: 209.6298065185547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 11329.109278036347
INFO:root:eval perplexity: 97.62748718261719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 11790.277322972075
INFO:root:eval perplexity: 124.11475372314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [11:14:20<12:29:58, 424.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13296.088541666666
INFO:root:current train perplexity190.5352783203125
INFO:root:current mean train loss 13074.167412562087
INFO:root:current train perplexity175.47425842285156
INFO:root:current mean train loss 12997.144138290587
INFO:root:current train perplexity169.2035675048828
INFO:root:current mean train loss 12885.75713641827
INFO:root:current train perplexity161.02369689941406
INFO:root:current mean train loss 12753.408038560145
INFO:root:current train perplexity152.78945922851562
INFO:root:current mean train loss 12622.320418840744
INFO:root:current train perplexity145.17239379882812
INFO:root:current mean train loss 12506.274864091301
INFO:root:current train perplexity138.4415283203125
INFO:root:current mean train loss 12422.830563155376
INFO:root:current train perplexity133.904541015625
INFO:root:current mean train loss 12346.697995464894
INFO:root:current train perplexity130.22535705566406
INFO:root:current mean train loss 12296.182396408385
INFO:root:current train perplexity127.36061096191406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.01s/it]
INFO:root:final mean train loss: 12258.815612054641
INFO:root:final train perplexity: 126.0220947265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 9607.56379169437
INFO:root:eval perplexity: 48.66777801513672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 10114.37580341312
INFO:root:eval perplexity: 62.54630661010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [11:21:25<12:22:56, 424.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11708.81496623411
INFO:root:current train perplexity103.00308227539062
INFO:root:current mean train loss 11823.514322916666
INFO:root:current train perplexity106.46107482910156
INFO:root:current mean train loss 11774.703502051158
INFO:root:current train perplexity104.94953155517578
INFO:root:current mean train loss 11751.660259618733
INFO:root:current train perplexity103.21592712402344
INFO:root:current mean train loss 11701.483658003131
INFO:root:current train perplexity101.26290130615234
INFO:root:current mean train loss 11650.09811745304
INFO:root:current train perplexity98.6211929321289
INFO:root:current mean train loss 11548.728812002086
INFO:root:current train perplexity94.8864974975586
INFO:root:current mean train loss 11498.554503509964
INFO:root:current train perplexity93.20612335205078
INFO:root:current mean train loss 11495.804490823268
INFO:root:current train perplexity93.1490707397461
INFO:root:current mean train loss 11449.048978835375
INFO:root:current train perplexity91.35185241699219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.74s/it]
INFO:root:final mean train loss: 11422.858311806956
INFO:root:final train perplexity: 90.61760711669922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 8276.767733959441
INFO:root:eval perplexity: 28.413997650146484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 8841.933036208999
INFO:root:eval perplexity: 37.17320251464844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:28:30<12:16:04, 424.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10697.036001632463
INFO:root:current train perplexity68.99934387207031
INFO:root:current mean train loss 10675.6337890625
INFO:root:current train perplexity66.93879699707031
INFO:root:current mean train loss 10504.648360691714
INFO:root:current train perplexity62.858028411865234
INFO:root:current mean train loss 10394.3339684094
INFO:root:current train perplexity60.21381378173828
INFO:root:current mean train loss 10327.338310944191
INFO:root:current train perplexity58.789268493652344
INFO:root:current mean train loss 10275.623994157848
INFO:root:current train perplexity57.569026947021484
INFO:root:current mean train loss 10181.66913564702
INFO:root:current train perplexity55.42416000366211
INFO:root:current mean train loss 10039.42749373574
INFO:root:current train perplexity52.4110221862793
INFO:root:current mean train loss 9887.595596119882
INFO:root:current train perplexity49.43248748779297
INFO:root:current mean train loss 9775.127383337642
INFO:root:current train perplexity47.20997619628906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.51s/it]
INFO:root:final mean train loss: 9746.05049970073
INFO:root:final train perplexity: 46.76331329345703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 6577.958676169104
INFO:root:eval perplexity: 14.29533576965332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 7284.045420545212
INFO:root:eval perplexity: 19.65921401977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:35:40<12:11:44, 426.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8639.398717447917
INFO:root:current train perplexity30.339313507080078
INFO:root:current mean train loss 8476.11783203125
INFO:root:current train perplexity28.312318801879883
INFO:root:current mean train loss 8404.185964133523
INFO:root:current train perplexity27.341432571411133
INFO:root:current mean train loss 8301.500432291667
INFO:root:current train perplexity26.273414611816406
INFO:root:current mean train loss 8191.446455592105
INFO:root:current train perplexity25.173904418945312
INFO:root:current mean train loss 8096.096818953804
INFO:root:current train perplexity24.263002395629883
INFO:root:current mean train loss 8017.184624565973
INFO:root:current train perplexity23.482982635498047
INFO:root:current mean train loss 7929.212218371976
INFO:root:current train perplexity22.724082946777344
INFO:root:current mean train loss 7838.961218191965
INFO:root:current train perplexity21.982542037963867
INFO:root:current mean train loss 7749.976433293269
INFO:root:current train perplexity21.234867095947266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.73s/it]
INFO:root:final mean train loss: 7729.38380149103
INFO:root:final train perplexity: 21.10405921936035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 5270.724567819149
INFO:root:eval perplexity: 8.42603588104248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 6082.389021636746
INFO:root:eval perplexity: 12.027222633361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:42:45<12:03:47, 425.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6777.994975997741
INFO:root:current train perplexity14.44632339477539
INFO:root:current mean train loss 6738.324037312159
INFO:root:current train perplexity14.26382064819336
INFO:root:current mean train loss 6726.435445077849
INFO:root:current train perplexity14.161067962646484
INFO:root:current mean train loss 6685.309812540796
INFO:root:current train perplexity13.944854736328125
INFO:root:current mean train loss 6649.7159850947855
INFO:root:current train perplexity13.726654052734375
INFO:root:current mean train loss 6588.538566680961
INFO:root:current train perplexity13.428328514099121
INFO:root:current mean train loss 6549.60064170022
INFO:root:current train perplexity13.206120491027832
INFO:root:current mean train loss 6512.797284707256
INFO:root:current train perplexity13.004518508911133
INFO:root:current mean train loss 6474.685139328815
INFO:root:current train perplexity12.832119941711426
INFO:root:current mean train loss 6438.048053729813
INFO:root:current train perplexity12.649813652038574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.57s/it]
INFO:root:final mean train loss: 6429.677956857989
INFO:root:final train perplexity: 12.637822151184082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 4936.373330839982
INFO:root:eval perplexity: 7.360474586486816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 5777.823436114805
INFO:root:eval perplexity: 10.61885929107666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:49:49<11:55:48, 425.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5988.882318853022
INFO:root:current train perplexity10.71073055267334
INFO:root:current mean train loss 5945.654621543685
INFO:root:current train perplexity10.54732608795166
INFO:root:current mean train loss 5914.160808969609
INFO:root:current train perplexity10.38381290435791
INFO:root:current mean train loss 5905.481750019981
INFO:root:current train perplexity10.321257591247559
INFO:root:current mean train loss 5887.324323168597
INFO:root:current train perplexity10.242431640625
INFO:root:current mean train loss 5864.091946416296
INFO:root:current train perplexity10.129735946655273
INFO:root:current mean train loss 5842.902736636215
INFO:root:current train perplexity10.039493560791016
INFO:root:current mean train loss 5828.205038618047
INFO:root:current train perplexity9.969315528869629
INFO:root:current mean train loss 5810.158747851781
INFO:root:current train perplexity9.895895004272461
INFO:root:current mean train loss 5797.47029712727
INFO:root:current train perplexity9.831006050109863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.68s/it]
INFO:root:final mean train loss: 5793.165157810335
INFO:root:final train perplexity: 9.83130168914795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it]
INFO:root:eval mean loss: 4667.09239943484
INFO:root:eval perplexity: 6.601093292236328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 5529.023813234154
INFO:root:eval perplexity: 9.591658592224121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:56:55<11:49:09, 425.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5569.66647924558
INFO:root:current train perplexity8.916165351867676
INFO:root:current mean train loss 5567.54303254554
INFO:root:current train perplexity8.898082733154297
INFO:root:current mean train loss 5526.741044366639
INFO:root:current train perplexity8.82580852508545
INFO:root:current mean train loss 5518.037441014646
INFO:root:current train perplexity8.780721664428711
INFO:root:current mean train loss 5496.9218407518165
INFO:root:current train perplexity8.7343168258667
INFO:root:current mean train loss 5481.791042525302
INFO:root:current train perplexity8.678621292114258
INFO:root:current mean train loss 5459.441883354569
INFO:root:current train perplexity8.612882614135742
INFO:root:current mean train loss 5445.176640478332
INFO:root:current train perplexity8.562139511108398
INFO:root:current mean train loss 5433.589265850946
INFO:root:current train perplexity8.51561450958252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.16s/it]
INFO:root:final mean train loss: 5410.987285121794
INFO:root:final train perplexity: 8.455280303955078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 4515.144915641622
INFO:root:eval perplexity: 6.207710266113281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it]
INFO:root:eval mean loss: 5389.5385707557625
INFO:root:eval perplexity: 9.059883117675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [12:03:56<11:40:14, 424.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5324.25
INFO:root:current train perplexity7.8442840576171875
INFO:root:current mean train loss 5205.822192610981
INFO:root:current train perplexity7.725382328033447
INFO:root:current mean train loss 5174.697376490791
INFO:root:current train perplexity7.708115577697754
INFO:root:current mean train loss 5164.83284081077
INFO:root:current train perplexity7.666677474975586
INFO:root:current mean train loss 5154.245209565034
INFO:root:current train perplexity7.621423721313477
INFO:root:current mean train loss 5137.849759615385
INFO:root:current train perplexity7.582860946655273
INFO:root:current mean train loss 5126.140418264776
INFO:root:current train perplexity7.554094314575195
INFO:root:current mean train loss 5109.309069599762
INFO:root:current train perplexity7.509764671325684
INFO:root:current mean train loss 5091.417920345415
INFO:root:current train perplexity7.460099220275879
INFO:root:current mean train loss 5081.522614366559
INFO:root:current train perplexity7.416918754577637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.62s/it]
INFO:root:final mean train loss: 5068.9425048828125
INFO:root:final train perplexity: 7.3879075050354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 4434.039727393617
INFO:root:eval perplexity: 6.007419586181641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it]
INFO:root:eval mean loss: 5313.990059494126
INFO:root:eval perplexity: 8.784278869628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [12:11:02<11:33:39, 424.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4947.12822265625
INFO:root:current train perplexity7.052116394042969
INFO:root:current mean train loss 4927.161510699728
INFO:root:current train perplexity7.0086140632629395
INFO:root:current mean train loss 4925.505214389535
INFO:root:current train perplexity6.97523307800293
INFO:root:current mean train loss 4908.01986297123
INFO:root:current train perplexity6.942877769470215
INFO:root:current mean train loss 4912.64317347515
INFO:root:current train perplexity6.931656360626221
INFO:root:current mean train loss 4912.740899006371
INFO:root:current train perplexity6.919204235076904
INFO:root:current mean train loss 4904.6376508511175
INFO:root:current train perplexity6.892002105712891
INFO:root:current mean train loss 4892.963335199956
INFO:root:current train perplexity6.875295639038086
INFO:root:current mean train loss 4886.894412025498
INFO:root:current train perplexity6.8589887619018555
INFO:root:current mean train loss 4878.551413080601
INFO:root:current train perplexity6.841287136077881

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.55s/it]
INFO:root:final mean train loss: 4870.496360532699
INFO:root:final train perplexity: 6.831552505493164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 4382.263775764628
INFO:root:eval perplexity: 5.88295316696167
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 5270.378371218418
INFO:root:eval perplexity: 8.629013061523438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [12:18:10<11:28:28, 425.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4872.526961616848
INFO:root:current train perplexity6.737170219421387
INFO:root:current mean train loss 4816.704260353151
INFO:root:current train perplexity6.640835762023926
INFO:root:current mean train loss 4807.832379396721
INFO:root:current train perplexity6.6263747215271
INFO:root:current mean train loss 4797.077411474458
INFO:root:current train perplexity6.619170665740967
INFO:root:current mean train loss 4785.73575326906
INFO:root:current train perplexity6.608073711395264
INFO:root:current mean train loss 4788.292969683616
INFO:root:current train perplexity6.61081075668335
INFO:root:current mean train loss 4784.19910745636
INFO:root:current train perplexity6.597609043121338
INFO:root:current mean train loss 4781.677729647519
INFO:root:current train perplexity6.590293884277344
INFO:root:current mean train loss 4778.875635418249
INFO:root:current train perplexity6.584925651550293
INFO:root:current mean train loss 4777.568116027898
INFO:root:current train perplexity6.577276229858398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.17s/it]
INFO:root:final mean train loss: 4774.092069195163
INFO:root:final train perplexity: 6.576597213745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 4362.516222365359
INFO:root:eval perplexity: 5.836163520812988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 5253.695733252992
INFO:root:eval perplexity: 8.57034969329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:25:16<11:21:04, 425.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4663.986107610887
INFO:root:current train perplexity6.463353157043457
INFO:root:current mean train loss 4745.986179031489
INFO:root:current train perplexity6.499220848083496
INFO:root:current mean train loss 4734.241401176948
INFO:root:current train perplexity6.49049711227417
INFO:root:current mean train loss 4731.186182673244
INFO:root:current train perplexity6.481367588043213
INFO:root:current mean train loss 4738.367194297419
INFO:root:current train perplexity6.491130352020264
INFO:root:current mean train loss 4743.405343323328
INFO:root:current train perplexity6.496062755584717
INFO:root:current mean train loss 4737.758734895008
INFO:root:current train perplexity6.479882717132568
INFO:root:current mean train loss 4739.471129285654
INFO:root:current train perplexity6.472674369812012
INFO:root:current mean train loss 4739.083460838786
INFO:root:current train perplexity6.463373184204102
INFO:root:current mean train loss 4730.073469282861
INFO:root:current train perplexity6.455753326416016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.08s/it]
INFO:root:final mean train loss: 4726.214906077231
INFO:root:final train perplexity: 6.45353889465332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 4335.116453346631
INFO:root:eval perplexity: 5.771857261657715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 5227.931161001219
INFO:root:eval perplexity: 8.480530738830566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:32:20<11:13:24, 425.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4672.6248121995195
INFO:root:current train perplexity6.313940525054932
INFO:root:current mean train loss 4696.486359740333
INFO:root:current train perplexity6.400875091552734
INFO:root:current mean train loss 4695.857109293279
INFO:root:current train perplexity6.423032283782959
INFO:root:current mean train loss 4701.95151179941
INFO:root:current train perplexity6.426994323730469
INFO:root:current mean train loss 4712.983905071006
INFO:root:current train perplexity6.432023048400879
INFO:root:current mean train loss 4710.166001583517
INFO:root:current train perplexity6.421463489532471
INFO:root:current mean train loss 4709.349303339569
INFO:root:current train perplexity6.412358283996582
INFO:root:current mean train loss 4709.406894544464
INFO:root:current train perplexity6.412411212921143
INFO:root:current mean train loss 4705.652753172955
INFO:root:current train perplexity6.398804664611816
INFO:root:current mean train loss 4705.042743329423
INFO:root:current train perplexity6.392963886260986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 362.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 362.00s/it]
INFO:root:final mean train loss: 4702.728743768507
INFO:root:final train perplexity: 6.394015789031982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 4324.065131870568
INFO:root:eval perplexity: 5.746121883392334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 5218.7762823443045
INFO:root:eval perplexity: 8.44884204864502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:39:23<11:05:08, 424.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4665.300656582447
INFO:root:current train perplexity6.35861349105835
INFO:root:current mean train loss 4687.711910740859
INFO:root:current train perplexity6.394669055938721
INFO:root:current mean train loss 4679.6975166845905
INFO:root:current train perplexity6.351147651672363
INFO:root:current mean train loss 4684.055208145714
INFO:root:current train perplexity6.344522953033447
INFO:root:current mean train loss 4690.874693049147
INFO:root:current train perplexity6.352641582489014
INFO:root:current mean train loss 4688.657505962923
INFO:root:current train perplexity6.3491106033325195
INFO:root:current mean train loss 4686.471206877294
INFO:root:current train perplexity6.337920188903809
INFO:root:current mean train loss 4686.6728865331115
INFO:root:current train perplexity6.336658954620361
INFO:root:current mean train loss 4684.010007459692
INFO:root:current train perplexity6.337440490722656
INFO:root:current mean train loss 4683.512964202333
INFO:root:current train perplexity6.341488361358643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.30s/it]
INFO:root:final mean train loss: 4681.039470672607
INFO:root:final train perplexity: 6.339536666870117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4326.32063628934
INFO:root:eval perplexity: 5.751363754272461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 5220.853986591312
INFO:root:eval perplexity: 8.456024169921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [12:46:25<10:57:07, 423.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4656.838742897728
INFO:root:current train perplexity6.345200538635254
INFO:root:current mean train loss 4682.045953566028
INFO:root:current train perplexity6.321714401245117
INFO:root:current mean train loss 4690.008925972733
INFO:root:current train perplexity6.325843334197998
INFO:root:current mean train loss 4693.3533457581425
INFO:root:current train perplexity6.331711292266846
INFO:root:current mean train loss 4688.919974995707
INFO:root:current train perplexity6.324852466583252
INFO:root:current mean train loss 4691.477943324184
INFO:root:current train perplexity6.331788539886475
INFO:root:current mean train loss 4691.529974132276
INFO:root:current train perplexity6.341235160827637
INFO:root:current mean train loss 4686.100398062396
INFO:root:current train perplexity6.333311557769775
INFO:root:current mean train loss 4684.826764380025
INFO:root:current train perplexity6.335122585296631
INFO:root:current mean train loss 4683.160535370991
INFO:root:current train perplexity6.333668231964111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.83s/it]
INFO:root:final mean train loss: 4679.846775670206
INFO:root:final train perplexity: 6.33655309677124
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 4322.637269365026
INFO:root:eval perplexity: 5.742804527282715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it]
INFO:root:eval mean loss: 5216.932237990359
INFO:root:eval perplexity: 8.442475318908691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [12:53:32<10:51:07, 424.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4709.023003472223
INFO:root:current train perplexity6.343088150024414
INFO:root:current mean train loss 4685.332616887941
INFO:root:current train perplexity6.347157001495361
INFO:root:current mean train loss 4687.832163995663
INFO:root:current train perplexity6.335330009460449
INFO:root:current mean train loss 4676.728540509857
INFO:root:current train perplexity6.3271074295043945
INFO:root:current mean train loss 4681.8980298958895
INFO:root:current train perplexity6.331672191619873
INFO:root:current mean train loss 4681.173777388849
INFO:root:current train perplexity6.335175514221191
INFO:root:current mean train loss 4690.2562567018995
INFO:root:current train perplexity6.3489298820495605
INFO:root:current mean train loss 4691.701237469794
INFO:root:current train perplexity6.35219669342041
INFO:root:current mean train loss 4687.302616972498
INFO:root:current train perplexity6.347722053527832
INFO:root:current mean train loss 4686.864815304955
INFO:root:current train perplexity6.3488640785217285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.47s/it]
INFO:root:final mean train loss: 4685.689131213772
INFO:root:final train perplexity: 6.351175308227539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 4329.753442209663
INFO:root:eval perplexity: 5.7593536376953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 5227.30924652316
INFO:root:eval perplexity: 8.478373527526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [13:00:37<10:44:19, 424.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4643.111486300616
INFO:root:current train perplexity6.370144367218018
INFO:root:current mean train loss 4671.6417871664835
INFO:root:current train perplexity6.378655910491943
INFO:root:current mean train loss 4677.372529765336
INFO:root:current train perplexity6.372257232666016
INFO:root:current mean train loss 4704.053362165178
INFO:root:current train perplexity6.393736839294434
INFO:root:current mean train loss 4743.992109748208
INFO:root:current train perplexity6.489048957824707
INFO:root:current mean train loss 4877.766980386657
INFO:root:current train perplexity6.84935998916626
INFO:root:current mean train loss 4955.032608600736
INFO:root:current train perplexity7.055230140686035
INFO:root:current mean train loss 5008.878637726978
INFO:root:current train perplexity7.1943159103393555
INFO:root:current mean train loss 5048.149355760262
INFO:root:current train perplexity7.316934585571289
INFO:root:current mean train loss 5041.603561888517
INFO:root:current train perplexity7.297731876373291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.48s/it]
INFO:root:final mean train loss: 5054.1554537127095
INFO:root:final train perplexity: 7.344931125640869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it]
INFO:root:eval mean loss: 6550.168089954565
INFO:root:eval perplexity: 14.13559341430664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it]
INFO:root:eval mean loss: 7223.262840757979
INFO:root:eval perplexity: 19.176612854003906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [13:07:41<10:36:39, 424.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6158.855258603639
INFO:root:current train perplexity11.389029502868652
INFO:root:current mean train loss 5744.9036449240575
INFO:root:current train perplexity9.609847068786621
INFO:root:current mean train loss 5650.2509923135085
INFO:root:current train perplexity9.280593872070312
INFO:root:current mean train loss 5546.980245867002
INFO:root:current train perplexity8.904854774475098
INFO:root:current mean train loss 5495.9615776683195
INFO:root:current train perplexity8.74056625366211
INFO:root:current mean train loss 5533.078815677623
INFO:root:current train perplexity8.871840476989746
INFO:root:current mean train loss 5528.258899087583
INFO:root:current train perplexity8.839503288269043
INFO:root:current mean train loss 5502.7495480734515
INFO:root:current train perplexity8.740118026733398
INFO:root:current mean train loss 5472.788318134954
INFO:root:current train perplexity8.644180297851562
INFO:root:current mean train loss 5469.973272212557
INFO:root:current train perplexity8.642189979553223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it]
INFO:root:final mean train loss: 5464.861449580038
INFO:root:final train perplexity: 8.636917114257812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 4530.1253514932405
INFO:root:eval perplexity: 6.24542760848999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 5395.431370511968
INFO:root:eval perplexity: 9.081741333007812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [13:14:47<10:30:29, 425.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5513.25830078125
INFO:root:current train perplexity8.786096572875977
INFO:root:current mean train loss 5660.099857432319
INFO:root:current train perplexity9.350690841674805
INFO:root:current mean train loss 5699.701932368794
INFO:root:current train perplexity9.46662712097168
INFO:root:current mean train loss 5710.831429414971
INFO:root:current train perplexity9.498438835144043
INFO:root:current mean train loss 5701.465949651886
INFO:root:current train perplexity9.452513694763184
INFO:root:current mean train loss 5622.405787505324
INFO:root:current train perplexity9.182836532592773
INFO:root:current mean train loss 5549.432664096616
INFO:root:current train perplexity8.914881706237793
INFO:root:current mean train loss 5508.719217186507
INFO:root:current train perplexity8.776782035827637
INFO:root:current mean train loss 5507.126596409949
INFO:root:current train perplexity8.772200584411621
INFO:root:current mean train loss 5495.237903784353
INFO:root:current train perplexity8.72496509552002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.89s/it]
INFO:root:final mean train loss: 5490.081503960394
INFO:root:final train perplexity: 8.723286628723145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 4639.228699163342
INFO:root:eval perplexity: 6.527133464813232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 5502.457588791001
INFO:root:eval perplexity: 9.488025665283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [13:21:52<10:23:11, 424.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5324.003962787829
INFO:root:current train perplexity8.125975608825684
INFO:root:current mean train loss 5260.445798277244
INFO:root:current train perplexity7.94401216506958
INFO:root:current mean train loss 5199.346360235699
INFO:root:current train perplexity7.794672966003418
INFO:root:current mean train loss 5210.943593008307
INFO:root:current train perplexity7.818562030792236
INFO:root:current mean train loss 5258.7837279040405
INFO:root:current train perplexity7.973514556884766
INFO:root:current mean train loss 5286.375167410714
INFO:root:current train perplexity8.056236267089844
INFO:root:current mean train loss 5315.23707846223
INFO:root:current train perplexity8.156280517578125
INFO:root:current mean train loss 5327.090425388168
INFO:root:current train perplexity8.180261611938477
INFO:root:current mean train loss 5341.657150728875
INFO:root:current train perplexity8.215447425842285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.73s/it]
INFO:root:final mean train loss: 5347.401294831307
INFO:root:final train perplexity: 8.245803833007812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 4728.513432928857
INFO:root:eval perplexity: 6.76709508895874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 5572.580829593307
INFO:root:eval perplexity: 9.764026641845703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [13:28:55<10:15:26, 424.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5668.083821614583
INFO:root:current train perplexity9.391069412231445
INFO:root:current mean train loss 5473.2899489912015
INFO:root:current train perplexity8.739020347595215
INFO:root:current mean train loss 5457.462310941349
INFO:root:current train perplexity8.687870979309082
INFO:root:current mean train loss 5438.7666321807965
INFO:root:current train perplexity8.576285362243652
INFO:root:current mean train loss 5454.514506678427
INFO:root:current train perplexity8.624305725097656
INFO:root:current mean train loss 5441.336517030629
INFO:root:current train perplexity8.57286548614502
INFO:root:current mean train loss 5409.404995692113
INFO:root:current train perplexity8.455703735351562
INFO:root:current mean train loss 5377.646162790052
INFO:root:current train perplexity8.346047401428223
INFO:root:current mean train loss 5350.223617610718
INFO:root:current train perplexity8.242524147033691
INFO:root:current mean train loss 5326.7938350031145
INFO:root:current train perplexity8.163948059082031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.46s/it]
INFO:root:final mean train loss: 5305.228841350925
INFO:root:final train perplexity: 8.109743118286133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 4484.649195894282
INFO:root:eval perplexity: 6.131629943847656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 5361.140095162899
INFO:root:eval perplexity: 8.955286979675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [13:35:59<10:08:12, 424.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5271.272238991477
INFO:root:current train perplexity7.981790542602539
INFO:root:current mean train loss 5130.887664519989
INFO:root:current train perplexity7.556232452392578
INFO:root:current mean train loss 5167.553488781102
INFO:root:current train perplexity7.682109355926514
INFO:root:current mean train loss 5235.0319062751205
INFO:root:current train perplexity7.888948440551758
INFO:root:current mean train loss 5290.762274749088
INFO:root:current train perplexity8.056480407714844
INFO:root:current mean train loss 5315.40324195817
INFO:root:current train perplexity8.128771781921387
INFO:root:current mean train loss 5332.586869310045
INFO:root:current train perplexity8.172085762023926
INFO:root:current mean train loss 5373.683414507515
INFO:root:current train perplexity8.304542541503906
INFO:root:current mean train loss 5371.405806272156
INFO:root:current train perplexity8.311012268066406
INFO:root:current mean train loss 5370.112501929541
INFO:root:current train perplexity8.30738639831543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.39s/it]
INFO:root:final mean train loss: 5366.940550281155
INFO:root:final train perplexity: 8.309613227844238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.92s/it]
INFO:root:eval mean loss: 4538.564529310727
INFO:root:eval perplexity: 6.266777515411377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 5401.562529435395
INFO:root:eval perplexity: 9.10453987121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [13:43:03<10:00:58, 424.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5352.058542351973
INFO:root:current train perplexity8.208664894104004
INFO:root:current mean train loss 5581.2078518907565
INFO:root:current train perplexity8.892892837524414
INFO:root:current mean train loss 5577.878553974029
INFO:root:current train perplexity8.953310012817383
INFO:root:current mean train loss 5612.706579704643
INFO:root:current train perplexity9.11193561553955
INFO:root:current mean train loss 5569.104591242169
INFO:root:current train perplexity9.013763427734375
INFO:root:current mean train loss 5557.704316067558
INFO:root:current train perplexity8.943954467773438
INFO:root:current mean train loss 5588.247422916246
INFO:root:current train perplexity9.054996490478516
INFO:root:current mean train loss 5602.12778232028
INFO:root:current train perplexity9.097025871276855
INFO:root:current mean train loss 5581.679310110462
INFO:root:current train perplexity9.025375366210938
INFO:root:current mean train loss 5581.500524410874
INFO:root:current train perplexity9.034158706665039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.97s/it]
INFO:root:final mean train loss: 5575.484943636002
INFO:root:final train perplexity: 9.02221965789795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 4611.415258962212
INFO:root:eval perplexity: 6.454133987426758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 5450.899265154034
INFO:root:eval perplexity: 9.290084838867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [13:50:07<9:54:01, 424.30s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5596.354275173611
INFO:root:current train perplexity8.941497802734375
INFO:root:current mean train loss 5642.275794322097
INFO:root:current train perplexity9.135537147521973
INFO:root:current mean train loss 5615.742557475221
INFO:root:current train perplexity9.125036239624023
INFO:root:current mean train loss 5636.416002186066
INFO:root:current train perplexity9.198079109191895
INFO:root:current mean train loss 5611.130074923156
INFO:root:current train perplexity9.157097816467285
INFO:root:current mean train loss 5598.402081542043
INFO:root:current train perplexity9.072147369384766
INFO:root:current mean train loss 5579.351331987639
INFO:root:current train perplexity9.022942543029785
INFO:root:current mean train loss 5558.217559184792
INFO:root:current train perplexity8.943621635437012
INFO:root:current mean train loss 5563.985634375945
INFO:root:current train perplexity8.962976455688477
INFO:root:current mean train loss 5576.103319680421
INFO:root:current train perplexity9.010028839111328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.71s/it]
INFO:root:final mean train loss: 5568.738020250874
INFO:root:final train perplexity: 8.9982328414917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 4661.882016012854
INFO:root:eval perplexity: 6.5871992111206055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it]
INFO:root:eval mean loss: 5489.319578346631
INFO:root:eval perplexity: 9.437187194824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [13:57:13<9:47:20, 424.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5519.295493861607
INFO:root:current train perplexity8.664027214050293
INFO:root:current mean train loss 5633.436295572917
INFO:root:current train perplexity9.133071899414062
INFO:root:current mean train loss 5559.669178025266
INFO:root:current train perplexity8.917158126831055
INFO:root:current mean train loss 5599.279640858209
INFO:root:current train perplexity9.05694580078125
INFO:root:current mean train loss 5626.186489762931
INFO:root:current train perplexity9.17872428894043
INFO:root:current mean train loss 5628.568231600468
INFO:root:current train perplexity9.200089454650879
INFO:root:current mean train loss 5643.400834307333
INFO:root:current train perplexity9.273343086242676
INFO:root:current mean train loss 5644.83721832483
INFO:root:current train perplexity9.265456199645996
INFO:root:current mean train loss 5651.327804547156
INFO:root:current train perplexity9.274434089660645
INFO:root:current mean train loss 5668.577778764205
INFO:root:current train perplexity9.340330123901367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.66s/it]
INFO:root:final mean train loss: 5674.73597532703
INFO:root:final train perplexity: 9.382512092590332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 4739.105399490249
INFO:root:eval perplexity: 6.796141624450684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 5555.99337876773
INFO:root:eval perplexity: 9.698023796081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [14:04:10<9:37:17, 422.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5635.701762354651
INFO:root:current train perplexity9.442262649536133
INFO:root:current mean train loss 5596.847400158435
INFO:root:current train perplexity9.187676429748535
INFO:root:current mean train loss 5650.1730645576135
INFO:root:current train perplexity9.3326997756958
INFO:root:current mean train loss 5667.695641342474
INFO:root:current train perplexity9.367743492126465
INFO:root:current mean train loss 5687.595872866112
INFO:root:current train perplexity9.44875717163086
INFO:root:current mean train loss 5717.0077423601515
INFO:root:current train perplexity9.559550285339355
INFO:root:current mean train loss 5711.214188405181
INFO:root:current train perplexity9.534662246704102
INFO:root:current mean train loss 5708.995272938047
INFO:root:current train perplexity9.499367713928223
INFO:root:current mean train loss 5698.711652834927
INFO:root:current train perplexity9.459773063659668
INFO:root:current mean train loss 5685.901405504374
INFO:root:current train perplexity9.410351753234863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.90s/it]
INFO:root:final mean train loss: 5685.797544417843
INFO:root:final train perplexity: 9.423543930053711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it]
INFO:root:eval mean loss: 4768.1850724457
INFO:root:eval perplexity: 6.876530170440674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 5585.07009779477
INFO:root:eval perplexity: 9.814018249511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [14:11:08<9:28:15, 420.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5672.695839077819
INFO:root:current train perplexity9.414249420166016
INFO:root:current mean train loss 5753.145123008071
INFO:root:current train perplexity9.608763694763184
INFO:root:current mean train loss 5725.1910774869275
INFO:root:current train perplexity9.577910423278809
INFO:root:current mean train loss 5682.621317719462
INFO:root:current train perplexity9.4058837890625
INFO:root:current mean train loss 5694.543947477827
INFO:root:current train perplexity9.458527565002441
INFO:root:current mean train loss 5718.458813343636
INFO:root:current train perplexity9.558782577514648
INFO:root:current mean train loss 5760.30664812548
INFO:root:current train perplexity9.699359893798828
INFO:root:current mean train loss 5817.091168806175
INFO:root:current train perplexity9.900237083435059
INFO:root:current mean train loss 5864.928595609026
INFO:root:current train perplexity10.087318420410156
INFO:root:current mean train loss 5899.39219150483
INFO:root:current train perplexity10.222343444824219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.23s/it]
INFO:root:final mean train loss: 5898.82931112474
INFO:root:final train perplexity: 10.24980640411377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 4965.023995041001
INFO:root:eval perplexity: 7.4462456703186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 5752.5327009918
INFO:root:eval perplexity: 10.509605407714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [14:18:11<9:22:27, 421.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6246.383598715572
INFO:root:current train perplexity11.693411827087402
INFO:root:current mean train loss 6264.161224941037
INFO:root:current train perplexity11.919001579284668
INFO:root:current mean train loss 6368.4950945644305
INFO:root:current train perplexity12.379188537597656
INFO:root:current mean train loss 6435.53285357547
INFO:root:current train perplexity12.61489486694336
INFO:root:current mean train loss 6442.898070491217
INFO:root:current train perplexity12.64626407623291
INFO:root:current mean train loss 6416.388031606384
INFO:root:current train perplexity12.516752243041992
INFO:root:current mean train loss 6422.644570519964
INFO:root:current train perplexity12.58078384399414
INFO:root:current mean train loss 6418.8931268785
INFO:root:current train perplexity12.568069458007812
INFO:root:current mean train loss 6451.70230987158
INFO:root:current train perplexity12.736977577209473
INFO:root:current mean train loss 6448.0626364539885
INFO:root:current train perplexity12.708985328674316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.43s/it]
INFO:root:final mean train loss: 6458.156049051592
INFO:root:final train perplexity: 12.780614852905273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it]
INFO:root:eval mean loss: 5852.61593736148
INFO:root:eval perplexity: 10.661362648010254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 6627.0693913453015
INFO:root:eval perplexity: 15.02777099609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [14:25:17<9:16:58, 423.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6642.7816289645525
INFO:root:current train perplexity13.642783164978027
INFO:root:current mean train loss 6562.346562733907
INFO:root:current train perplexity13.382994651794434
INFO:root:current mean train loss 6468.2814310481035
INFO:root:current train perplexity12.832661628723145
INFO:root:current mean train loss 6430.523068960746
INFO:root:current train perplexity12.629851341247559
INFO:root:current mean train loss 6446.275689658057
INFO:root:current train perplexity12.67969799041748
INFO:root:current mean train loss 6485.682154741236
INFO:root:current train perplexity12.88001537322998
INFO:root:current mean train loss 6507.622027853261
INFO:root:current train perplexity13.009794235229492
INFO:root:current mean train loss 6561.659622132701
INFO:root:current train perplexity13.313413619995117
INFO:root:current mean train loss 6602.867472471526
INFO:root:current train perplexity13.531115531921387
INFO:root:current mean train loss 6623.250636229964
INFO:root:current train perplexity13.620088577270508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.62s/it]
INFO:root:final mean train loss: 6621.941792518862
INFO:root:final train perplexity: 13.633740425109863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 5295.868513824246
INFO:root:eval perplexity: 8.5121431350708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 6041.4545413619235
INFO:root:eval perplexity: 11.8275785446167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [14:32:21<9:10:22, 423.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6555.835006510417
INFO:root:current train perplexity13.52387809753418
INFO:root:current mean train loss 6589.0233984375
INFO:root:current train perplexity13.526268005371094
INFO:root:current mean train loss 6620.092478693182
INFO:root:current train perplexity13.644901275634766
INFO:root:current mean train loss 6602.8753359375
INFO:root:current train perplexity13.527068138122559
INFO:root:current mean train loss 6591.380033922697
INFO:root:current train perplexity13.461047172546387
INFO:root:current mean train loss 6599.5082175611415
INFO:root:current train perplexity13.474124908447266
INFO:root:current mean train loss 6632.127154947917
INFO:root:current train perplexity13.65231704711914
INFO:root:current mean train loss 6682.422685231855
INFO:root:current train perplexity13.909724235534668
INFO:root:current mean train loss 6700.213211495536
INFO:root:current train perplexity14.030689239501953
INFO:root:current mean train loss 6684.723738481571
INFO:root:current train perplexity13.951083183288574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.02s/it]
INFO:root:final mean train loss: 6677.786689635246
INFO:root:final train perplexity: 13.937458992004395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it]
INFO:root:eval mean loss: 5227.780176473848
INFO:root:eval perplexity: 8.280975341796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 5974.776062444592
INFO:root:eval perplexity: 11.509444236755371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [14:39:27<9:04:04, 423.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6730.6293709996235
INFO:root:current train perplexity13.990668296813965
INFO:root:current mean train loss 6677.090070547302
INFO:root:current train perplexity13.814122200012207
INFO:root:current mean train loss 6584.995037820229
INFO:root:current train perplexity13.375527381896973
INFO:root:current mean train loss 6580.773951278966
INFO:root:current train perplexity13.350959777832031
INFO:root:current mean train loss 6577.235881292055
INFO:root:current train perplexity13.364660263061523
INFO:root:current mean train loss 6574.3329257343485
INFO:root:current train perplexity13.361159324645996
INFO:root:current mean train loss 6570.349276943402
INFO:root:current train perplexity13.33619499206543
INFO:root:current mean train loss 6559.410008456059
INFO:root:current train perplexity13.280930519104004
INFO:root:current mean train loss 6541.9166659293605
INFO:root:current train perplexity13.188569068908691
INFO:root:current mean train loss 6537.271582726666
INFO:root:current train perplexity13.15976619720459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it]
INFO:root:final mean train loss: 6532.362352678852
INFO:root:final train perplexity: 13.16031551361084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 5143.30625277039
INFO:root:eval perplexity: 8.002884864807129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 5898.052810560727
INFO:root:eval perplexity: 11.153963088989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [14:46:32<8:57:19, 424.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6529.984670115041
INFO:root:current train perplexity13.083033561706543
INFO:root:current mean train loss 6485.897466050393
INFO:root:current train perplexity12.95835018157959
INFO:root:current mean train loss 6508.392683835374
INFO:root:current train perplexity13.008702278137207
INFO:root:current mean train loss 6484.068453035086
INFO:root:current train perplexity12.841641426086426
INFO:root:current mean train loss 6539.744429019221
INFO:root:current train perplexity13.16090202331543
INFO:root:current mean train loss 6575.371363089573
INFO:root:current train perplexity13.362452507019043
INFO:root:current mean train loss 6556.145808836831
INFO:root:current train perplexity13.254833221435547
INFO:root:current mean train loss 6561.925921993521
INFO:root:current train perplexity13.296832084655762
INFO:root:current mean train loss 6544.011446386609
INFO:root:current train perplexity13.197404861450195
INFO:root:current mean train loss 6529.549520390547
INFO:root:current train perplexity13.119226455688477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it]
INFO:root:final mean train loss: 6524.445755866266
INFO:root:final train perplexity: 13.11927604675293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5165.032437804743
INFO:root:eval perplexity: 8.073503494262695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 5912.009415863254
INFO:root:eval perplexity: 11.217799186706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [14:53:33<8:49:10, 423.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6563.522495462437
INFO:root:current train perplexity13.274612426757812
INFO:root:current mean train loss 6573.199662865107
INFO:root:current train perplexity13.233664512634277
INFO:root:current mean train loss 6562.574994447638
INFO:root:current train perplexity13.176770210266113
INFO:root:current mean train loss 6538.1102365288225
INFO:root:current train perplexity13.101762771606445
INFO:root:current mean train loss 6524.158485917147
INFO:root:current train perplexity13.05880355834961
INFO:root:current mean train loss 6507.5172724397435
INFO:root:current train perplexity12.974902153015137
INFO:root:current mean train loss 6503.838741449839
INFO:root:current train perplexity12.994003295898438
INFO:root:current mean train loss 6500.282648232165
INFO:root:current train perplexity12.96054458618164
INFO:root:current mean train loss 6504.716035938369
INFO:root:current train perplexity12.977420806884766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.29s/it]
INFO:root:final mean train loss: 6507.7062203191945
INFO:root:final train perplexity: 13.032919883728027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 5342.190744819371
INFO:root:eval perplexity: 8.673089981079102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 6084.392114084663
INFO:root:eval perplexity: 12.037075996398926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [15:00:36<8:42:07, 423.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6695.303989955357
INFO:root:current train perplexity14.140703201293945
INFO:root:current mean train loss 6681.924905081775
INFO:root:current train perplexity13.795397758483887
INFO:root:current mean train loss 6701.957118527325
INFO:root:current train perplexity14.074573516845703
INFO:root:current mean train loss 6654.781674661544
INFO:root:current train perplexity13.787900924682617
INFO:root:current mean train loss 6655.818231006219
INFO:root:current train perplexity13.779675483703613
INFO:root:current mean train loss 6657.047824596277
INFO:root:current train perplexity13.817218780517578
INFO:root:current mean train loss 6627.370698781147
INFO:root:current train perplexity13.614887237548828
INFO:root:current mean train loss 6612.590762989525
INFO:root:current train perplexity13.538744926452637
INFO:root:current mean train loss 6606.969437345106
INFO:root:current train perplexity13.50247573852539
INFO:root:current mean train loss 6601.016737764437
INFO:root:current train perplexity13.479507446289062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.21s/it]
INFO:root:final mean train loss: 6605.342469123102
INFO:root:final train perplexity: 13.544746398925781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it]
INFO:root:eval mean loss: 5612.253272523271
INFO:root:eval perplexity: 9.673891067504883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 6323.407150376773
INFO:root:eval perplexity: 13.272944450378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [15:07:43<8:36:26, 424.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6862.923470052084
INFO:root:current train perplexity14.745237350463867
INFO:root:current mean train loss 6898.773246433424
INFO:root:current train perplexity15.293034553527832
INFO:root:current mean train loss 6807.86953125
INFO:root:current train perplexity14.73388957977295
INFO:root:current mean train loss 6736.6515516493055
INFO:root:current train perplexity14.281733512878418
INFO:root:current mean train loss 6705.055109892696
INFO:root:current train perplexity14.033703804016113
INFO:root:current mean train loss 6667.301351069478
INFO:root:current train perplexity13.848830223083496
INFO:root:current mean train loss 6636.246990123222
INFO:root:current train perplexity13.68669319152832
INFO:root:current mean train loss 6666.751843176355
INFO:root:current train perplexity13.823699951171875
INFO:root:current mean train loss 6630.535633148006
INFO:root:current train perplexity13.647054672241211
INFO:root:current mean train loss 6609.4271916623975
INFO:root:current train perplexity13.52558708190918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.53s/it]
INFO:root:final mean train loss: 6610.503097780289
INFO:root:final train perplexity: 13.572349548339844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 5160.065665170656
INFO:root:eval perplexity: 8.057304382324219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 5907.72667677859
INFO:root:eval perplexity: 11.198171615600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [15:14:50<8:30:14, 425.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6507.620690387228
INFO:root:current train perplexity13.288475036621094
INFO:root:current mean train loss 6484.870470496697
INFO:root:current train perplexity12.910538673400879
INFO:root:current mean train loss 6462.854141851177
INFO:root:current train perplexity12.782869338989258
INFO:root:current mean train loss 6496.257271309017
INFO:root:current train perplexity12.928826332092285
INFO:root:current mean train loss 6563.292560117465
INFO:root:current train perplexity13.263811111450195
INFO:root:current mean train loss 6618.120752046487
INFO:root:current train perplexity13.569473266601562
INFO:root:current mean train loss 6622.11675878436
INFO:root:current train perplexity13.629817962646484
INFO:root:current mean train loss 6606.0913025155605
INFO:root:current train perplexity13.542838096618652
INFO:root:current mean train loss 6587.781979752051
INFO:root:current train perplexity13.445717811584473
INFO:root:current mean train loss 6611.536800958999
INFO:root:current train perplexity13.542724609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.12s/it]
INFO:root:final mean train loss: 6611.5305089642925
INFO:root:final train perplexity: 13.577852249145508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 5166.776751579122
INFO:root:eval perplexity: 8.079198837280273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 5920.065658244681
INFO:root:eval perplexity: 11.254814147949219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [15:21:53<8:22:27, 424.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6613.596474924395
INFO:root:current train perplexity13.803382873535156
INFO:root:current mean train loss 6548.825411498092
INFO:root:current train perplexity13.321128845214844
INFO:root:current mean train loss 6612.670777952516
INFO:root:current train perplexity13.569231033325195
INFO:root:current mean train loss 6607.368003268976
INFO:root:current train perplexity13.547669410705566
INFO:root:current mean train loss 6620.544502700841
INFO:root:current train perplexity13.600566864013672
INFO:root:current mean train loss 6618.1040949417375
INFO:root:current train perplexity13.592219352722168
INFO:root:current mean train loss 6618.329457520305
INFO:root:current train perplexity13.606206893920898
INFO:root:current mean train loss 6623.576602043434
INFO:root:current train perplexity13.632124900817871
INFO:root:current mean train loss 6622.097103922232
INFO:root:current train perplexity13.600126266479492
INFO:root:current mean train loss 6619.826712078746
INFO:root:current train perplexity13.586799621582031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.44s/it]
INFO:root:final mean train loss: 6598.033629263601
INFO:root:final train perplexity: 13.505746841430664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 5029.030609347296
INFO:root:eval perplexity: 7.641487121582031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 5791.591062721631
INFO:root:eval perplexity: 10.67880916595459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [15:28:58<8:15:20, 424.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6122.731783353365
INFO:root:current train perplexity11.15228271484375
INFO:root:current mean train loss 6194.890814691997
INFO:root:current train perplexity11.519030570983887
INFO:root:current mean train loss 6295.2315699365845
INFO:root:current train perplexity11.958744049072266
INFO:root:current mean train loss 6347.793504563053
INFO:root:current train perplexity12.250906944274902
INFO:root:current mean train loss 6304.233825544561
INFO:root:current train perplexity12.043716430664062
INFO:root:current mean train loss 6328.9726363201535
INFO:root:current train perplexity12.169082641601562
INFO:root:current mean train loss 6378.737123587882
INFO:root:current train perplexity12.409208297729492
INFO:root:current mean train loss 6421.985102466382
INFO:root:current train perplexity12.588624000549316
INFO:root:current mean train loss 6434.751652823302
INFO:root:current train perplexity12.651982307434082
INFO:root:current mean train loss 6426.304344819123
INFO:root:current train perplexity12.608298301696777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.20s/it]
INFO:root:final mean train loss: 6415.697085472845
INFO:root:final train perplexity: 12.568305969238281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it]
INFO:root:eval mean loss: 5061.488201601285
INFO:root:eval perplexity: 7.742444038391113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 5822.163165586215
INFO:root:eval perplexity: 10.813142776489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [15:36:03<8:08:26, 424.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6253.98779296875
INFO:root:current train perplexity11.797713279724121
INFO:root:current mean train loss 6468.400407233205
INFO:root:current train perplexity12.855813026428223
INFO:root:current mean train loss 6441.109910725582
INFO:root:current train perplexity12.617364883422852
INFO:root:current mean train loss 6338.14882728071
INFO:root:current train perplexity12.143661499023438
INFO:root:current mean train loss 6292.376425519085
INFO:root:current train perplexity11.958130836486816
INFO:root:current mean train loss 6330.445176816727
INFO:root:current train perplexity12.148002624511719
INFO:root:current mean train loss 6376.451399035211
INFO:root:current train perplexity12.372797012329102
INFO:root:current mean train loss 6381.733663821955
INFO:root:current train perplexity12.398796081542969
INFO:root:current mean train loss 6360.165926270108
INFO:root:current train perplexity12.305534362792969
INFO:root:current mean train loss 6349.058840726471
INFO:root:current train perplexity12.223974227905273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.42s/it]
INFO:root:final mean train loss: 6355.943866114462
INFO:root:final train perplexity: 12.275481224060059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 5240.90253075133
INFO:root:eval perplexity: 8.325035095214844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 5995.737754875887
INFO:root:eval perplexity: 11.608522415161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [15:43:12<8:02:55, 426.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6709.059810014204
INFO:root:current train perplexity13.83602523803711
INFO:root:current mean train loss 6553.958237777218
INFO:root:current train perplexity13.1770658493042
INFO:root:current mean train loss 6391.033304610907
INFO:root:current train perplexity12.357756614685059
INFO:root:current mean train loss 6400.847903829225
INFO:root:current train perplexity12.408507347106934
INFO:root:current mean train loss 6343.980287388393
INFO:root:current train perplexity12.165563583374023
INFO:root:current mean train loss 6349.999661282376
INFO:root:current train perplexity12.187723159790039
INFO:root:current mean train loss 6373.024382007395
INFO:root:current train perplexity12.335793495178223
INFO:root:current mean train loss 6392.405327116101
INFO:root:current train perplexity12.43533706665039
INFO:root:current mean train loss 6393.460773026316
INFO:root:current train perplexity12.435484886169434
INFO:root:current mean train loss 6380.821104998364
INFO:root:current train perplexity12.376423835754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.33s/it]
INFO:root:final mean train loss: 6371.837976024997
INFO:root:final train perplexity: 12.35269546508789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 5030.094217503324
INFO:root:eval perplexity: 7.644776344299316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 5819.847884807181
INFO:root:eval perplexity: 10.802910804748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [15:50:22<7:57:04, 427.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6332.357049851191
INFO:root:current train perplexity12.33484935760498
INFO:root:current mean train loss 6301.409341449386
INFO:root:current train perplexity12.113454818725586
INFO:root:current mean train loss 6304.035739216968
INFO:root:current train perplexity12.085631370544434
INFO:root:current mean train loss 6308.303219965996
INFO:root:current train perplexity12.0790376663208
INFO:root:current mean train loss 6358.5235049946
INFO:root:current train perplexity12.257460594177246
INFO:root:current mean train loss 6345.905467709258
INFO:root:current train perplexity12.20689582824707
INFO:root:current mean train loss 6330.059643223275
INFO:root:current train perplexity12.120223999023438
INFO:root:current mean train loss 6327.925177777892
INFO:root:current train perplexity12.110209465026855
INFO:root:current mean train loss 6334.803859741635
INFO:root:current train perplexity12.14362907409668
INFO:root:current mean train loss 6330.939529688311
INFO:root:current train perplexity12.12381649017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.14s/it]
INFO:root:final mean train loss: 6325.111292439123
INFO:root:final train perplexity: 12.127059936523438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 4986.336328817598
INFO:root:eval perplexity: 7.510697364807129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 5801.763218223626
INFO:root:eval perplexity: 10.723320007324219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [15:57:33<7:51:07, 428.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6308.475077024648
INFO:root:current train perplexity12.118657112121582
INFO:root:current mean train loss 6350.514725534539
INFO:root:current train perplexity12.327284812927246
INFO:root:current mean train loss 6381.949748472094
INFO:root:current train perplexity12.393357276916504
INFO:root:current mean train loss 6385.429834905661
INFO:root:current train perplexity12.38979721069336
INFO:root:current mean train loss 6385.378761113323
INFO:root:current train perplexity12.422375679016113
INFO:root:current mean train loss 6393.566432759139
INFO:root:current train perplexity12.4374418258667
INFO:root:current mean train loss 6397.684244306539
INFO:root:current train perplexity12.4721097946167
INFO:root:current mean train loss 6414.404710425786
INFO:root:current train perplexity12.561820030212402
INFO:root:current mean train loss 6443.349301045852
INFO:root:current train perplexity12.691967964172363
INFO:root:current mean train loss 6459.6641952561795
INFO:root:current train perplexity12.766733169555664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.71s/it]
INFO:root:final mean train loss: 6458.782944956133
INFO:root:final train perplexity: 12.783774375915527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it]
INFO:root:eval mean loss: 5165.520978778812
INFO:root:eval perplexity: 8.075095176696777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 5926.202518977172
INFO:root:eval perplexity: 11.283097267150879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [16:04:44<7:44:50, 429.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6708.1399142108385
INFO:root:current train perplexity14.093034744262695
INFO:root:current mean train loss 6689.431875218226
INFO:root:current train perplexity14.010736465454102
INFO:root:current mean train loss 6759.439013846886
INFO:root:current train perplexity14.403008460998535
INFO:root:current mean train loss 6746.964378658889
INFO:root:current train perplexity14.3045072555542
INFO:root:current mean train loss 6725.031009427192
INFO:root:current train perplexity14.212601661682129
INFO:root:current mean train loss 6711.369456026015
INFO:root:current train perplexity14.12217903137207
INFO:root:current mean train loss 6695.385694006582
INFO:root:current train perplexity13.999980926513672
INFO:root:current mean train loss 6708.8733026115215
INFO:root:current train perplexity14.089567184448242
INFO:root:current mean train loss 6699.120621022646
INFO:root:current train perplexity14.022074699401855
INFO:root:current mean train loss 6694.806793244063
INFO:root:current train perplexity14.000361442565918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.65s/it]
INFO:root:final mean train loss: 6692.885577909408
INFO:root:final train perplexity: 14.020734786987305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 5320.411191683289
INFO:root:eval perplexity: 8.597040176391602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 6066.253397190824
INFO:root:eval perplexity: 11.948124885559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [16:11:55<7:38:23, 429.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6776.851214529454
INFO:root:current train perplexity14.700267791748047
INFO:root:current mean train loss 6767.640695500501
INFO:root:current train perplexity14.500082015991211
INFO:root:current mean train loss 6724.472719199151
INFO:root:current train perplexity14.196538925170898
INFO:root:current mean train loss 6658.440946988049
INFO:root:current train perplexity13.838812828063965
INFO:root:current mean train loss 6642.249813510652
INFO:root:current train perplexity13.763586044311523
INFO:root:current mean train loss 6643.668838007081
INFO:root:current train perplexity13.726568222045898
INFO:root:current mean train loss 6627.759683178675
INFO:root:current train perplexity13.669200897216797
INFO:root:current mean train loss 6638.852883403153
INFO:root:current train perplexity13.715893745422363
INFO:root:current mean train loss 6682.277381733547
INFO:root:current train perplexity13.936569213867188
INFO:root:current mean train loss 6734.262899134055
INFO:root:current train perplexity14.22403621673584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.21s/it]
INFO:root:final mean train loss: 6730.157645810035
INFO:root:final train perplexity: 14.228428840637207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 5374.19081754211
INFO:root:eval perplexity: 8.786046981811523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 6103.922532967642
INFO:root:eval perplexity: 12.133589744567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [16:19:05<7:31:22, 429.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6951.685562294408
INFO:root:current train perplexity15.638720512390137
INFO:root:current mean train loss 6912.963403946314
INFO:root:current train perplexity15.200462341308594
INFO:root:current mean train loss 6853.480232057733
INFO:root:current train perplexity14.927356719970703
INFO:root:current mean train loss 6818.7617657238925
INFO:root:current train perplexity14.706582069396973
INFO:root:current mean train loss 6822.495295730745
INFO:root:current train perplexity14.724120140075684
INFO:root:current mean train loss 6848.464375164128
INFO:root:current train perplexity14.863393783569336
INFO:root:current mean train loss 6831.430591698516
INFO:root:current train perplexity14.772926330566406
INFO:root:current mean train loss 6781.39204070853
INFO:root:current train perplexity14.469073295593262
INFO:root:current mean train loss 6757.42293285178
INFO:root:current train perplexity14.32742691040039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.29s/it]
INFO:root:final mean train loss: 6724.56229302191
INFO:root:final train perplexity: 14.197053909301758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 5184.486307347074
INFO:root:eval perplexity: 8.1372652053833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it]
INFO:root:eval mean loss: 5934.064982962101
INFO:root:eval perplexity: 11.319428443908691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [16:26:14<7:23:45, 429.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6575.897786458333
INFO:root:current train perplexity13.75320816040039
INFO:root:current mean train loss 6677.509286824939
INFO:root:current train perplexity13.908119201660156
INFO:root:current mean train loss 6719.995477986453
INFO:root:current train perplexity14.022225379943848
INFO:root:current mean train loss 6705.088240318172
INFO:root:current train perplexity14.000054359436035
INFO:root:current mean train loss 6690.031008888415
INFO:root:current train perplexity13.95212173461914
INFO:root:current mean train loss 6655.691773188991
INFO:root:current train perplexity13.747710227966309
INFO:root:current mean train loss 6636.247190965744
INFO:root:current train perplexity13.6422758102417
INFO:root:current mean train loss 6671.331968044319
INFO:root:current train perplexity13.852627754211426
INFO:root:current mean train loss 6695.674089595657
INFO:root:current train perplexity13.997594833374023
INFO:root:current mean train loss 6744.567294673138
INFO:root:current train perplexity14.255120277404785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.16s/it]
INFO:root:final mean train loss: 6729.161993826589
INFO:root:final train perplexity: 14.22283935546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 5266.801595052083
INFO:root:eval perplexity: 8.412679672241211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 5998.533767591977
INFO:root:eval perplexity: 11.621804237365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [16:33:22<7:16:09, 429.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6472.641068892045
INFO:root:current train perplexity13.000556945800781
INFO:root:current mean train loss 6526.834089949324
INFO:root:current train perplexity13.091036796569824
INFO:root:current mean train loss 6568.886274437204
INFO:root:current train perplexity13.240544319152832
INFO:root:current mean train loss 6607.447348836918
INFO:root:current train perplexity13.475589752197266
INFO:root:current mean train loss 6585.514390634505
INFO:root:current train perplexity13.400012016296387
INFO:root:current mean train loss 6591.564664299474
INFO:root:current train perplexity13.443551063537598
INFO:root:current mean train loss 6641.059967490538
INFO:root:current train perplexity13.711823463439941
INFO:root:current mean train loss 6670.011518218179
INFO:root:current train perplexity13.866949081420898
INFO:root:current mean train loss 6666.817203996802
INFO:root:current train perplexity13.838621139526367
INFO:root:current mean train loss 6665.438510865464
INFO:root:current train perplexity13.83325481414795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.72s/it]
INFO:root:final mean train loss: 6660.08746141003
INFO:root:final train perplexity: 13.840476036071777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 5318.5374383588205
INFO:root:eval perplexity: 8.590530395507812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 6043.129519198803
INFO:root:eval perplexity: 11.83568000793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [16:40:31<7:09:11, 429.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6622.879831414473
INFO:root:current train perplexity13.797045707702637
INFO:root:current mean train loss 6621.353864397322
INFO:root:current train perplexity13.652987480163574
INFO:root:current mean train loss 6678.916555186929
INFO:root:current train perplexity14.011631965637207
INFO:root:current mean train loss 6723.926762404487
INFO:root:current train perplexity14.228224754333496
INFO:root:current mean train loss 6769.957949545048
INFO:root:current train perplexity14.471954345703125
INFO:root:current mean train loss 6786.25474074994
INFO:root:current train perplexity14.492101669311523
INFO:root:current mean train loss 6783.2958589963655
INFO:root:current train perplexity14.464072227478027
INFO:root:current mean train loss 6792.094353051113
INFO:root:current train perplexity14.518336296081543
INFO:root:current mean train loss 6811.642913781097
INFO:root:current train perplexity14.622293472290039
INFO:root:current mean train loss 6824.50830078125
INFO:root:current train perplexity14.724888801574707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.85s/it]
INFO:root:final mean train loss: 6823.708814067225
INFO:root:final train perplexity: 14.763391494750977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it]
INFO:root:eval mean loss: 5346.993988253546
INFO:root:eval perplexity: 8.689950942993164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 6084.66045752992
INFO:root:eval perplexity: 12.038396835327148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [16:47:42<7:02:27, 429.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7182.140516493056
INFO:root:current train perplexity16.609846115112305
INFO:root:current mean train loss 6974.903827817421
INFO:root:current train perplexity15.611797332763672
INFO:root:current mean train loss 6926.511755317319
INFO:root:current train perplexity15.35746955871582
INFO:root:current mean train loss 6991.433566872133
INFO:root:current train perplexity15.73039722442627
INFO:root:current mean train loss 6996.590328600702
INFO:root:current train perplexity15.802562713623047
INFO:root:current mean train loss 6995.421578510436
INFO:root:current train perplexity15.811637878417969
INFO:root:current mean train loss 6992.595572293661
INFO:root:current train perplexity15.820491790771484
INFO:root:current mean train loss 6993.754288412354
INFO:root:current train perplexity15.76710033416748
INFO:root:current mean train loss 7001.566311191619
INFO:root:current train perplexity15.815200805664062
INFO:root:current mean train loss 7001.989181962986
INFO:root:current train perplexity15.798102378845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.18s/it]
INFO:root:final mean train loss: 6986.26372134301
INFO:root:final train perplexity: 15.74122428894043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it]
INFO:root:eval mean loss: 5424.92940007203
INFO:root:eval perplexity: 8.968174934387207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 6144.22081740359
INFO:root:eval perplexity: 12.335193634033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [16:54:52<6:55:25, 429.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7055.632603236607
INFO:root:current train perplexity16.04111099243164
INFO:root:current mean train loss 6989.77162181713
INFO:root:current train perplexity15.811841011047363
INFO:root:current mean train loss 7048.444579039228
INFO:root:current train perplexity16.0435733795166
INFO:root:current mean train loss 7011.4978122084885
INFO:root:current train perplexity15.937956809997559
INFO:root:current mean train loss 7020.388477684985
INFO:root:current train perplexity15.97351360321045
INFO:root:current mean train loss 7055.951619085865
INFO:root:current train perplexity16.120208740234375
INFO:root:current mean train loss 7067.038059793307
INFO:root:current train perplexity16.217878341674805
INFO:root:current mean train loss 7090.905965003189
INFO:root:current train perplexity16.335193634033203
INFO:root:current mean train loss 7085.132693792103
INFO:root:current train perplexity16.335819244384766
INFO:root:current mean train loss 7069.185452352106
INFO:root:current train perplexity16.230607986450195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.30s/it]
INFO:root:final mean train loss: 7046.975238307829
INFO:root:final train perplexity: 16.122817993164062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 5233.892823997119
INFO:root:eval perplexity: 8.301468849182129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 5987.953530169548
INFO:root:eval perplexity: 11.571630477905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [17:02:02<6:48:17, 429.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6778.92550872093
INFO:root:current train perplexity14.632787704467773
INFO:root:current mean train loss 6777.959131200831
INFO:root:current train perplexity14.521327018737793
INFO:root:current mean train loss 6804.459689670139
INFO:root:current train perplexity14.69853687286377
INFO:root:current mean train loss 6801.2512128735425
INFO:root:current train perplexity14.66952133178711
INFO:root:current mean train loss 6869.873769928047
INFO:root:current train perplexity15.03180980682373
INFO:root:current mean train loss 6894.851041846512
INFO:root:current train perplexity15.146137237548828
INFO:root:current mean train loss 6900.945718768226
INFO:root:current train perplexity15.176711082458496
INFO:root:current mean train loss 6900.699049855947
INFO:root:current train perplexity15.185053825378418
INFO:root:current mean train loss 6926.834029554048
INFO:root:current train perplexity15.346569061279297
INFO:root:current mean train loss 6966.8392860841395
INFO:root:current train perplexity15.587190628051758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.92s/it]
INFO:root:final mean train loss: 6980.666250413464
INFO:root:final train perplexity: 15.706506729125977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 5651.449277620789
INFO:root:eval perplexity: 9.828437805175781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 6356.947719276374
INFO:root:eval perplexity: 13.4562406539917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [17:09:10<6:40:30, 429.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7200.67542700674
INFO:root:current train perplexity17.114229202270508
INFO:root:current mean train loss 7030.149847371688
INFO:root:current train perplexity16.02298927307129
INFO:root:current mean train loss 7035.8018609157125
INFO:root:current train perplexity16.064361572265625
INFO:root:current mean train loss 7027.732750178063
INFO:root:current train perplexity15.98406982421875
INFO:root:current mean train loss 6995.802038222353
INFO:root:current train perplexity15.756596565246582
INFO:root:current mean train loss 7010.711309692604
INFO:root:current train perplexity15.852782249450684
INFO:root:current mean train loss 7001.965512042771
INFO:root:current train perplexity15.829550743103027
INFO:root:current mean train loss 6993.756065480401
INFO:root:current train perplexity15.783682823181152
INFO:root:current mean train loss 7012.065560507858
INFO:root:current train perplexity15.8908052444458
INFO:root:current mean train loss 7023.627126154212
INFO:root:current train perplexity15.948515892028809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.86s/it]
INFO:root:final mean train loss: 7023.7725212343275
INFO:root:final train perplexity: 15.97590160369873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 5380.625678745568
INFO:root:eval perplexity: 8.808940887451172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 6103.671552942154
INFO:root:eval perplexity: 12.132343292236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [17:16:20<6:33:35, 429.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7110.711061639301
INFO:root:current train perplexity16.287933349609375
INFO:root:current mean train loss 7074.802697523585
INFO:root:current train perplexity16.229637145996094
INFO:root:current mean train loss 7058.960094790661
INFO:root:current train perplexity16.146886825561523
INFO:root:current mean train loss 7090.907947423399
INFO:root:current train perplexity16.35881996154785
INFO:root:current mean train loss 7084.1252031845725
INFO:root:current train perplexity16.327585220336914
INFO:root:current mean train loss 7061.904606964166
INFO:root:current train perplexity16.22264289855957
INFO:root:current mean train loss 7057.984057135574
INFO:root:current train perplexity16.179365158081055
INFO:root:current mean train loss 7060.843391669755
INFO:root:current train perplexity16.178802490234375
INFO:root:current mean train loss 7034.856692579489
INFO:root:current train perplexity16.026962280273438
INFO:root:current mean train loss 7042.145352519715
INFO:root:current train perplexity16.068506240844727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.78s/it]
INFO:root:final mean train loss: 7037.5255360757155
INFO:root:final train perplexity: 16.06282615661621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 5324.505509613254
INFO:root:eval perplexity: 8.611287117004395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 6056.768495816711
INFO:root:eval perplexity: 11.901875495910645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [17:23:24<6:25:06, 427.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6931.795002040579
INFO:root:current train perplexity15.723666191101074
INFO:root:current mean train loss 6945.069297927583
INFO:root:current train perplexity15.538694381713867
INFO:root:current mean train loss 6954.316526948736
INFO:root:current train perplexity15.431315422058105
INFO:root:current mean train loss 6953.428524672173
INFO:root:current train perplexity15.427924156188965
INFO:root:current mean train loss 6971.881645643736
INFO:root:current train perplexity15.542662620544434
INFO:root:current mean train loss 6938.058370707948
INFO:root:current train perplexity15.365577697753906
INFO:root:current mean train loss 6920.713641714299
INFO:root:current train perplexity15.299062728881836
INFO:root:current mean train loss 6920.192969768579
INFO:root:current train perplexity15.285386085510254
INFO:root:current mean train loss 6913.797719777249
INFO:root:current train perplexity15.261283874511719
INFO:root:current mean train loss 6902.284852778406
INFO:root:current train perplexity15.191568374633789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.18s/it]
INFO:root:final mean train loss: 6898.615526383923
INFO:root:final train perplexity: 15.20620059967041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 5431.340574440381
INFO:root:eval perplexity: 8.991453170776367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it]
INFO:root:eval mean loss: 6155.463053385417
INFO:root:eval perplexity: 12.392030715942383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [17:30:32<6:17:59, 427.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6926.90318359375
INFO:root:current train perplexity15.173877716064453
INFO:root:current mean train loss 6909.289143415179
INFO:root:current train perplexity15.282576560974121
INFO:root:current mean train loss 6969.825490056818
INFO:root:current train perplexity15.553794860839844
INFO:root:current mean train loss 6935.92330078125
INFO:root:current train perplexity15.354734420776367
INFO:root:current mean train loss 6923.583038651316
INFO:root:current train perplexity15.279596328735352
INFO:root:current mean train loss 6928.207698709239
INFO:root:current train perplexity15.31964111328125
INFO:root:current mean train loss 6874.012890625
INFO:root:current train perplexity15.009198188781738
INFO:root:current mean train loss 6836.914846270161
INFO:root:current train perplexity14.809959411621094
INFO:root:current mean train loss 6819.305743861607
INFO:root:current train perplexity14.713950157165527
INFO:root:current mean train loss 6801.321134314904
INFO:root:current train perplexity14.602651596069336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.79s/it]
INFO:root:final mean train loss: 6794.4828995735415
INFO:root:final train perplexity: 14.594141960144043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it]
INFO:root:eval mean loss: 5301.157150376773
INFO:root:eval perplexity: 8.530364990234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 6032.326376191268
INFO:root:eval perplexity: 11.783512115478516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [17:37:41<6:11:10, 428.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6944.052110786897
INFO:root:current train perplexity15.360197067260742
INFO:root:current mean train loss 7036.193399398053
INFO:root:current train perplexity15.956731796264648
INFO:root:current mean train loss 7126.641185747018
INFO:root:current train perplexity16.49507713317871
INFO:root:current mean train loss 7109.617438652497
INFO:root:current train perplexity16.405529022216797
INFO:root:current mean train loss 7076.573164345562
INFO:root:current train perplexity16.236045837402344
INFO:root:current mean train loss 7049.411026445916
INFO:root:current train perplexity16.05548095703125
INFO:root:current mean train loss 7021.474698738332
INFO:root:current train perplexity15.909072875976562
INFO:root:current mean train loss 7017.984411792585
INFO:root:current train perplexity15.894617080688477
INFO:root:current mean train loss 7033.973713547565
INFO:root:current train perplexity15.998321533203125
INFO:root:current mean train loss 7061.349808065234
INFO:root:current train perplexity16.17827033996582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.91s/it]
INFO:root:final mean train loss: 7057.216203997212
INFO:root:final train perplexity: 16.188093185424805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 5787.115625692598
INFO:root:eval perplexity: 10.382686614990234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 6502.200132978724
INFO:root:eval perplexity: 14.27970027923584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [17:44:48<6:03:43, 427.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7277.018511761676
INFO:root:current train perplexity17.597328186035156
INFO:root:current mean train loss 7076.615830026996
INFO:root:current train perplexity16.042484283447266
INFO:root:current mean train loss 7003.926148719394
INFO:root:current train perplexity15.69196891784668
INFO:root:current mean train loss 6898.354148767184
INFO:root:current train perplexity15.16016960144043
INFO:root:current mean train loss 6894.216562181772
INFO:root:current train perplexity15.1652193069458
INFO:root:current mean train loss 6923.900777284264
INFO:root:current train perplexity15.344106674194336
INFO:root:current mean train loss 6932.760463068696
INFO:root:current train perplexity15.44379997253418
INFO:root:current mean train loss 6958.215149311592
INFO:root:current train perplexity15.575318336486816
INFO:root:current mean train loss 6968.738639651726
INFO:root:current train perplexity15.60533332824707
INFO:root:current mean train loss 6976.294830229882
INFO:root:current train perplexity15.644973754882812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.99s/it]
INFO:root:final mean train loss: 6970.853364390711
INFO:root:final train perplexity: 15.64581298828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it]
INFO:root:eval mean loss: 5351.319678773271
INFO:root:eval perplexity: 8.705167770385742
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 6075.532984956782
INFO:root:eval perplexity: 11.993547439575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [17:51:56<5:56:40, 428.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6741.559733072917
INFO:root:current train perplexity14.397504806518555
INFO:root:current mean train loss 6842.886281995917
INFO:root:current train perplexity14.968377113342285
INFO:root:current mean train loss 6865.510454771112
INFO:root:current train perplexity15.006782531738281
INFO:root:current mean train loss 6916.461489416902
INFO:root:current train perplexity15.240056991577148
INFO:root:current mean train loss 6956.7439429640535
INFO:root:current train perplexity15.523431777954102
INFO:root:current mean train loss 6960.614789297267
INFO:root:current train perplexity15.544808387756348
INFO:root:current mean train loss 6950.062749379695
INFO:root:current train perplexity15.452919960021973
INFO:root:current mean train loss 6931.837341232204
INFO:root:current train perplexity15.337621688842773
INFO:root:current mean train loss 6913.361998900688
INFO:root:current train perplexity15.23132038116455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.56s/it]
INFO:root:final mean train loss: 6888.292270045126
INFO:root:final train perplexity: 15.144396781921387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it]
INFO:root:eval mean loss: 5175.953769115691
INFO:root:eval perplexity: 8.109236717224121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it]
INFO:root:eval mean loss: 5952.616041251108
INFO:root:eval perplexity: 11.405624389648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [17:59:10<5:50:52, 429.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6866.646902901785
INFO:root:current train perplexity14.475263595581055
INFO:root:current mean train loss 6652.088880877628
INFO:root:current train perplexity13.615747451782227
INFO:root:current mean train loss 6634.095568670743
INFO:root:current train perplexity13.586475372314453
INFO:root:current mean train loss 6590.381454219259
INFO:root:current train perplexity13.40257740020752
INFO:root:current mean train loss 6597.54703096207
INFO:root:current train perplexity13.449104309082031
INFO:root:current mean train loss 6559.040707439595
INFO:root:current train perplexity13.219672203063965
INFO:root:current mean train loss 6551.286197970295
INFO:root:current train perplexity13.212166786193848
INFO:root:current mean train loss 6563.105669035095
INFO:root:current train perplexity13.283977508544922
INFO:root:current mean train loss 6568.289648195477
INFO:root:current train perplexity13.33262825012207
INFO:root:current mean train loss 6583.805350205864
INFO:root:current train perplexity13.388008117675781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.82s/it]
INFO:root:final mean train loss: 6579.0754698476485
INFO:root:final train perplexity: 13.405105590820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 5243.140780834441
INFO:root:eval perplexity: 8.332572937011719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5992.72321725399
INFO:root:eval perplexity: 11.594220161437988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [18:06:18<5:43:18, 429.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6738.859244791666
INFO:root:current train perplexity14.566974639892578
INFO:root:current mean train loss 6651.989465862772
INFO:root:current train perplexity13.897697448730469
INFO:root:current mean train loss 6661.590706758721
INFO:root:current train perplexity13.8331880569458
INFO:root:current mean train loss 6667.398527405754
INFO:root:current train perplexity13.888299942016602
INFO:root:current mean train loss 6675.694848926958
INFO:root:current train perplexity13.90904712677002
INFO:root:current mean train loss 6651.192987712378
INFO:root:current train perplexity13.783933639526367
INFO:root:current mean train loss 6639.188411458334
INFO:root:current train perplexity13.728325843811035
INFO:root:current mean train loss 6640.4307678649475
INFO:root:current train perplexity13.755064010620117
INFO:root:current mean train loss 6637.319337734854
INFO:root:current train perplexity13.710947036743164
INFO:root:current mean train loss 6631.6278037482925
INFO:root:current train perplexity13.669647216796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.32s/it]
INFO:root:final mean train loss: 6632.481182959772
INFO:root:final train perplexity: 13.690550804138184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 5162.023517148715
INFO:root:eval perplexity: 8.063684463500977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5919.841540613918
INFO:root:eval perplexity: 11.253783226013184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [18:13:25<5:35:44, 428.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6679.671981148098
INFO:root:current train perplexity13.351656913757324
INFO:root:current mean train loss 6707.318843686484
INFO:root:current train perplexity13.976478576660156
INFO:root:current mean train loss 6661.840064899804
INFO:root:current train perplexity13.78067684173584
INFO:root:current mean train loss 6668.07332381966
INFO:root:current train perplexity13.842894554138184
INFO:root:current mean train loss 6679.623054955305
INFO:root:current train perplexity13.936518669128418
INFO:root:current mean train loss 6684.122215023004
INFO:root:current train perplexity14.008849143981934
INFO:root:current mean train loss 6710.128709526735
INFO:root:current train perplexity14.128358840942383
INFO:root:current mean train loss 6734.122623427775
INFO:root:current train perplexity14.274025917053223
INFO:root:current mean train loss 6773.769455308323
INFO:root:current train perplexity14.498726844787598
INFO:root:current mean train loss 6789.557167524377
INFO:root:current train perplexity14.546862602233887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.88s/it]
INFO:root:final mean train loss: 6784.155715942383
INFO:root:final train perplexity: 14.534797668457031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 5316.715463624779
INFO:root:eval perplexity: 8.58420181274414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 6035.744892093307
INFO:root:eval perplexity: 11.799992561340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [18:20:33<5:28:26, 428.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6723.325053553427
INFO:root:current train perplexity13.9637451171875
INFO:root:current mean train loss 6758.638429598044
INFO:root:current train perplexity14.28592586517334
INFO:root:current mean train loss 6731.398811637581
INFO:root:current train perplexity14.211955070495605
INFO:root:current mean train loss 6700.808561296261
INFO:root:current train perplexity14.07341194152832
INFO:root:current mean train loss 6719.785199300319
INFO:root:current train perplexity14.208617210388184
INFO:root:current mean train loss 6743.551340336629
INFO:root:current train perplexity14.327225685119629
INFO:root:current mean train loss 6743.663578861678
INFO:root:current train perplexity14.332066535949707
INFO:root:current mean train loss 6736.80413643019
INFO:root:current train perplexity14.258862495422363
INFO:root:current mean train loss 6734.749921263914
INFO:root:current train perplexity14.213591575622559
INFO:root:current mean train loss 6726.203564505572
INFO:root:current train perplexity14.176813125610352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.52s/it]
INFO:root:final mean train loss: 6716.34697108115
INFO:root:final train perplexity: 14.151114463806152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 5163.658459386082
INFO:root:eval perplexity: 8.069019317626953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 5921.01569772274
INFO:root:eval perplexity: 11.259193420410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [18:27:43<5:21:39, 428.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6600.964518229167
INFO:root:current train perplexity13.408950805664062
INFO:root:current mean train loss 6563.864549376124
INFO:root:current train perplexity13.288836479187012
INFO:root:current mean train loss 6495.103983476072
INFO:root:current train perplexity12.925821304321289
INFO:root:current mean train loss 6441.880021086837
INFO:root:current train perplexity12.661738395690918
INFO:root:current mean train loss 6435.313836934083
INFO:root:current train perplexity12.64950942993164
INFO:root:current mean train loss 6421.315639856795
INFO:root:current train perplexity12.58898639678955
INFO:root:current mean train loss 6422.271047290688
INFO:root:current train perplexity12.588497161865234
INFO:root:current mean train loss 6425.281486542202
INFO:root:current train perplexity12.573074340820312
INFO:root:current mean train loss 6419.572823161874
INFO:root:current train perplexity12.554657936096191
INFO:root:current mean train loss 6417.504600451777
INFO:root:current train perplexity12.552347183227539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.17s/it]
INFO:root:final mean train loss: 6413.0064550830475
INFO:root:final train perplexity: 12.554972648620605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it]
INFO:root:eval mean loss: 5222.585920185062
INFO:root:eval perplexity: 8.263599395751953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 5961.156004127881
INFO:root:eval perplexity: 11.445523262023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [18:34:54<5:14:57, 429.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6501.41259765625
INFO:root:current train perplexity13.066509246826172
INFO:root:current mean train loss 6529.319950441114
INFO:root:current train perplexity13.1284818649292
INFO:root:current mean train loss 6514.247801745952
INFO:root:current train perplexity13.06901741027832
INFO:root:current mean train loss 6490.432134534853
INFO:root:current train perplexity12.956277847290039
INFO:root:current mean train loss 6488.1350856840745
INFO:root:current train perplexity12.889495849609375
INFO:root:current mean train loss 6445.2555148109
INFO:root:current train perplexity12.695830345153809
INFO:root:current mean train loss 6419.656136042552
INFO:root:current train perplexity12.592198371887207
INFO:root:current mean train loss 6397.623526658718
INFO:root:current train perplexity12.486201286315918
INFO:root:current mean train loss 6390.5779670436095
INFO:root:current train perplexity12.426344871520996
INFO:root:current mean train loss 6374.644750899221
INFO:root:current train perplexity12.354471206665039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.30s/it]
INFO:root:final mean train loss: 6367.448681246849
INFO:root:final train perplexity: 12.331323623657227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.05s/it]
INFO:root:eval mean loss: 5097.562641982491
INFO:root:eval perplexity: 7.856212139129639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it]
INFO:root:eval mean loss: 5859.64354083555
INFO:root:eval perplexity: 10.980147361755371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [18:42:05<5:08:03, 429.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6413.603844105113
INFO:root:current train perplexity12.333807945251465
INFO:root:current mean train loss 6357.431297253024
INFO:root:current train perplexity12.19755744934082
INFO:root:current mean train loss 6321.641544117647
INFO:root:current train perplexity12.078043937683105
INFO:root:current mean train loss 6288.356109705106
INFO:root:current train perplexity11.9735107421875
INFO:root:current mean train loss 6280.187062156593
INFO:root:current train perplexity11.931113243103027
INFO:root:current mean train loss 6272.965080412444
INFO:root:current train perplexity11.883230209350586
INFO:root:current mean train loss 6267.013991680582
INFO:root:current train perplexity11.837302207946777
INFO:root:current mean train loss 6262.725250931291
INFO:root:current train perplexity11.807694435119629
INFO:root:current mean train loss 6264.2195832191155
INFO:root:current train perplexity11.802687644958496
INFO:root:current mean train loss 6261.707958217441
INFO:root:current train perplexity11.79437255859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.10s/it]
INFO:root:final mean train loss: 6255.087468054987
INFO:root:final train perplexity: 11.796619415283203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it]
INFO:root:eval mean loss: 5116.159834192154
INFO:root:eval perplexity: 7.915514945983887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 5865.197511497119
INFO:root:eval perplexity: 11.00511360168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [18:49:17<5:01:20, 430.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6360.868946862599
INFO:root:current train perplexity12.389850616455078
INFO:root:current mean train loss 6302.922947421395
INFO:root:current train perplexity12.002790451049805
INFO:root:current mean train loss 6319.082901987286
INFO:root:current train perplexity12.037300109863281
INFO:root:current mean train loss 6292.790168194731
INFO:root:current train perplexity11.901796340942383
INFO:root:current mean train loss 6259.178682463215
INFO:root:current train perplexity11.770096778869629
INFO:root:current mean train loss 6255.247849134103
INFO:root:current train perplexity11.766070365905762
INFO:root:current mean train loss 6246.426352016167
INFO:root:current train perplexity11.707756042480469
INFO:root:current mean train loss 6237.569508723787
INFO:root:current train perplexity11.67071533203125
INFO:root:current mean train loss 6237.900562060943
INFO:root:current train perplexity11.672401428222656
INFO:root:current mean train loss 6238.9495539046275
INFO:root:current train perplexity11.68942928314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.20s/it]
INFO:root:final mean train loss: 6233.99760313957
INFO:root:final train perplexity: 11.698875427246094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 5135.379650792332
INFO:root:eval perplexity: 7.977275848388672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 5889.527883976064
INFO:root:eval perplexity: 11.11514949798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [18:56:30<4:54:44, 431.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6290.9866032130285
INFO:root:current train perplexity11.980823516845703
INFO:root:current mean train loss 6301.539373743603
INFO:root:current train perplexity12.020270347595215
INFO:root:current mean train loss 6302.041680480282
INFO:root:current train perplexity11.951053619384766
INFO:root:current mean train loss 6259.314932193396
INFO:root:current train perplexity11.829789161682129
INFO:root:current mean train loss 6261.637689092357
INFO:root:current train perplexity11.831055641174316
INFO:root:current mean train loss 6257.707716211964
INFO:root:current train perplexity11.830928802490234
INFO:root:current mean train loss 6255.020121408113
INFO:root:current train perplexity11.81099796295166
INFO:root:current mean train loss 6265.392271603437
INFO:root:current train perplexity11.866621971130371
INFO:root:current mean train loss 6282.082721346692
INFO:root:current train perplexity11.91501235961914
INFO:root:current mean train loss 6303.8477704002
INFO:root:current train perplexity12.004060745239258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.14s/it]
INFO:root:final mean train loss: 6301.534972898422
INFO:root:final train perplexity: 12.01478385925293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it]
INFO:root:eval mean loss: 5150.130876689938
INFO:root:eval perplexity: 8.025002479553223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it]
INFO:root:eval mean loss: 5892.960411125887
INFO:root:eval perplexity: 11.13076400756836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [19:03:44<4:48:09, 432.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6372.977094046677
INFO:root:current train perplexity12.248459815979004
INFO:root:current mean train loss 6322.800620308136
INFO:root:current train perplexity12.043044090270996
INFO:root:current mean train loss 6323.40869140625
INFO:root:current train perplexity12.137860298156738
INFO:root:current mean train loss 6370.271211246702
INFO:root:current train perplexity12.33577823638916
INFO:root:current mean train loss 6388.334090390135
INFO:root:current train perplexity12.393464088439941
INFO:root:current mean train loss 6378.165023882772
INFO:root:current train perplexity12.355239868164062
INFO:root:current mean train loss 6366.173860485318
INFO:root:current train perplexity12.307605743408203
INFO:root:current mean train loss 6345.915641422296
INFO:root:current train perplexity12.20812702178955
INFO:root:current mean train loss 6334.047058869276
INFO:root:current train perplexity12.149438858032227
INFO:root:current mean train loss 6329.402521805573
INFO:root:current train perplexity12.121417045593262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.33s/it]
INFO:root:final mean train loss: 6322.920063387963
INFO:root:final train perplexity: 12.11658000946045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it]
INFO:root:eval mean loss: 5105.602289727393
INFO:root:eval perplexity: 7.8817949295043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it]
INFO:root:eval mean loss: 5853.149895417775
INFO:root:eval perplexity: 10.951027870178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [19:10:54<4:40:30, 431.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6301.5270406788795
INFO:root:current train perplexity11.782258987426758
INFO:root:current mean train loss 6280.6732562876
INFO:root:current train perplexity11.812895774841309
INFO:root:current mean train loss 6271.0108833977565
INFO:root:current train perplexity11.795489311218262
INFO:root:current mean train loss 6249.13990204094
INFO:root:current train perplexity11.749614715576172
INFO:root:current mean train loss 6248.944279790169
INFO:root:current train perplexity11.749600410461426
INFO:root:current mean train loss 6255.84188754392
INFO:root:current train perplexity11.784964561462402
INFO:root:current mean train loss 6251.447557030113
INFO:root:current train perplexity11.778175354003906
INFO:root:current mean train loss 6253.74148082612
INFO:root:current train perplexity11.766878128051758
INFO:root:current mean train loss 6247.471762810915
INFO:root:current train perplexity11.73582649230957
INFO:root:current mean train loss 6240.590031246043
INFO:root:current train perplexity11.706424713134766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:18<00:00, 378.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:18<00:00, 378.04s/it]
INFO:root:final mean train loss: 6235.1670570373535
INFO:root:final train perplexity: 11.704273223876953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 5084.944079676418
INFO:root:eval perplexity: 7.816230773925781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 5849.038068622562
INFO:root:eval perplexity: 10.932631492614746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [19:18:13<4:34:45, 433.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6220.3189504523025
INFO:root:current train perplexity11.689077377319336
INFO:root:current mean train loss 6234.222763922276
INFO:root:current train perplexity11.727706909179688
INFO:root:current mean train loss 6244.202532441737
INFO:root:current train perplexity11.759592056274414
INFO:root:current mean train loss 6251.26308099288
INFO:root:current train perplexity11.75228214263916
INFO:root:current mean train loss 6252.189606021149
INFO:root:current train perplexity11.770222663879395
INFO:root:current mean train loss 6258.738665309874
INFO:root:current train perplexity11.775162696838379
INFO:root:current mean train loss 6266.613679603192
INFO:root:current train perplexity11.783955574035645
INFO:root:current mean train loss 6260.2207074243315
INFO:root:current train perplexity11.78300666809082
INFO:root:current mean train loss 6255.045125370984
INFO:root:current train perplexity11.767038345336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.76s/it]
INFO:root:final mean train loss: 6243.729867258379
INFO:root:final train perplexity: 11.743879318237305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 5047.140663092863
INFO:root:eval perplexity: 7.697651386260986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 5836.51476271609
INFO:root:eval perplexity: 10.876788139343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [19:25:25<4:27:08, 433.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6181.6181640625
INFO:root:current train perplexity11.332273483276367
INFO:root:current mean train loss 6235.76088440534
INFO:root:current train perplexity11.614770889282227
INFO:root:current mean train loss 6227.795376481681
INFO:root:current train perplexity11.59607219696045
INFO:root:current mean train loss 6228.059971573329
INFO:root:current train perplexity11.598886489868164
INFO:root:current mean train loss 6228.773312703552
INFO:root:current train perplexity11.616413116455078
INFO:root:current mean train loss 6207.058230693961
INFO:root:current train perplexity11.564352035522461
INFO:root:current mean train loss 6212.855195053379
INFO:root:current train perplexity11.56934642791748
INFO:root:current mean train loss 6214.007559677276
INFO:root:current train perplexity11.570609092712402
INFO:root:current mean train loss 6210.846075872704
INFO:root:current train perplexity11.5590181350708
INFO:root:current mean train loss 6209.530169616902
INFO:root:current train perplexity11.560415267944336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.82s/it]
INFO:root:final mean train loss: 6205.506464681318
INFO:root:final train perplexity: 11.56810474395752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 5109.536357906693
INFO:root:eval perplexity: 7.894344329833984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 5862.0357518838655
INFO:root:eval perplexity: 10.990893363952637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [19:32:42<4:20:34, 434.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6339.009543678977
INFO:root:current train perplexity11.796029090881348
INFO:root:current mean train loss 6272.346024246903
INFO:root:current train perplexity11.91169548034668
INFO:root:current mean train loss 6266.569537266736
INFO:root:current train perplexity11.846131324768066
INFO:root:current mean train loss 6254.687749635752
INFO:root:current train perplexity11.788775444030762
INFO:root:current mean train loss 6263.779263610098
INFO:root:current train perplexity11.829894065856934
INFO:root:current mean train loss 6258.509842068249
INFO:root:current train perplexity11.813264846801758
INFO:root:current mean train loss 6259.531941265599
INFO:root:current train perplexity11.81508731842041
INFO:root:current mean train loss 6261.4773481452185
INFO:root:current train perplexity11.810806274414062
INFO:root:current mean train loss 6270.102412627158
INFO:root:current train perplexity11.829244613647461
INFO:root:current mean train loss 6274.250039662802
INFO:root:current train perplexity11.850747108459473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.72s/it]
INFO:root:final mean train loss: 6274.235616007159
INFO:root:final train perplexity: 11.886075019836426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 5210.819817292775
INFO:root:eval perplexity: 8.22437572479248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it]
INFO:root:eval mean loss: 5924.616474124557
INFO:root:eval perplexity: 11.275782585144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [19:39:47<4:11:40, 431.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6236.128083881579
INFO:root:current train perplexity11.899733543395996
INFO:root:current mean train loss 6364.151646205357
INFO:root:current train perplexity12.23767375946045
INFO:root:current mean train loss 6380.865575502997
INFO:root:current train perplexity12.294836044311523
INFO:root:current mean train loss 6385.790968174471
INFO:root:current train perplexity12.38306713104248
INFO:root:current mean train loss 6371.327374515215
INFO:root:current train perplexity12.349947929382324
INFO:root:current mean train loss 6361.7763436672085
INFO:root:current train perplexity12.278566360473633
INFO:root:current mean train loss 6356.5208761927
INFO:root:current train perplexity12.2842378616333
INFO:root:current mean train loss 6347.522835807111
INFO:root:current train perplexity12.235634803771973
INFO:root:current mean train loss 6336.4436276614015
INFO:root:current train perplexity12.182421684265137
INFO:root:current mean train loss 6334.610802120172
INFO:root:current train perplexity12.147034645080566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.11s/it]
INFO:root:final mean train loss: 6326.76790138983
INFO:root:final train perplexity: 12.134990692138672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 5147.059812721631
INFO:root:eval perplexity: 8.015040397644043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 5883.462710549646
INFO:root:eval perplexity: 11.087615013122559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [19:46:53<4:03:34, 429.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6192.142849392361
INFO:root:current train perplexity11.774901390075684
INFO:root:current mean train loss 6306.868917630413
INFO:root:current train perplexity12.115799903869629
INFO:root:current mean train loss 6319.656596314015
INFO:root:current train perplexity12.139999389648438
INFO:root:current mean train loss 6323.355182052752
INFO:root:current train perplexity12.16201114654541
INFO:root:current mean train loss 6327.342238272102
INFO:root:current train perplexity12.139429092407227
INFO:root:current mean train loss 6341.798233292813
INFO:root:current train perplexity12.183385848999023
INFO:root:current mean train loss 6330.406897926635
INFO:root:current train perplexity12.128786087036133
INFO:root:current mean train loss 6329.269587667641
INFO:root:current train perplexity12.108366966247559
INFO:root:current mean train loss 6331.7076677278565
INFO:root:current train perplexity12.131200790405273
INFO:root:current mean train loss 6345.184422827333
INFO:root:current train perplexity12.19113826751709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.79s/it]
INFO:root:final mean train loss: 6339.2708993727165
INFO:root:final train perplexity: 12.194995880126953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5187.6627569536795
INFO:root:eval perplexity: 8.147725105285645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 5921.985611286569
INFO:root:eval perplexity: 11.263655662536621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [19:53:57<3:55:25, 428.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6450.213518415178
INFO:root:current train perplexity12.7196044921875
INFO:root:current mean train loss 6389.175600405092
INFO:root:current train perplexity12.542096138000488
INFO:root:current mean train loss 6442.7388152426865
INFO:root:current train perplexity12.713692665100098
INFO:root:current mean train loss 6456.776403626399
INFO:root:current train perplexity12.752037048339844
INFO:root:current mean train loss 6460.4432763110635
INFO:root:current train perplexity12.754746437072754
INFO:root:current mean train loss 6471.518871385806
INFO:root:current train perplexity12.805732727050781
INFO:root:current mean train loss 6465.30119878814
INFO:root:current train perplexity12.793943405151367
INFO:root:current mean train loss 6461.367883051658
INFO:root:current train perplexity12.761362075805664
INFO:root:current mean train loss 6457.158724153256
INFO:root:current train perplexity12.736063957214355
INFO:root:current mean train loss 6451.956655247326
INFO:root:current train perplexity12.722151756286621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.01s/it]
INFO:root:final mean train loss: 6450.016865391885
INFO:root:final train perplexity: 12.739638328552246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 5302.566676363032
INFO:root:eval perplexity: 8.535229682922363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 6024.994784740691
INFO:root:eval perplexity: 11.748236656188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [20:00:59<3:47:24, 426.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6528.007074400436
INFO:root:current train perplexity12.985554695129395
INFO:root:current mean train loss 6479.169740903628
INFO:root:current train perplexity12.763701438903809
INFO:root:current mean train loss 6458.3824889885545
INFO:root:current train perplexity12.712370872497559
INFO:root:current mean train loss 6443.383713613794
INFO:root:current train perplexity12.641190528869629
INFO:root:current mean train loss 6460.866910844032
INFO:root:current train perplexity12.71733283996582
INFO:root:current mean train loss 6464.635973289307
INFO:root:current train perplexity12.743192672729492
INFO:root:current mean train loss 6450.735631014289
INFO:root:current train perplexity12.711082458496094
INFO:root:current mean train loss 6441.1203202546685
INFO:root:current train perplexity12.677663803100586
INFO:root:current mean train loss 6439.061512432348
INFO:root:current train perplexity12.663495063781738
INFO:root:current mean train loss 6439.372164551299
INFO:root:current train perplexity12.664237976074219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.20s/it]
INFO:root:final mean train loss: 6440.667752050585
INFO:root:final train perplexity: 12.692736625671387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5380.23272315492
INFO:root:eval perplexity: 8.807541847229004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 6113.796781499335
INFO:root:eval perplexity: 12.182682991027832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [20:07:56<3:38:44, 423.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6581.310518152573
INFO:root:current train perplexity13.256439208984375
INFO:root:current mean train loss 6554.840920555671
INFO:root:current train perplexity13.218118667602539
INFO:root:current mean train loss 6516.396603040961
INFO:root:current train perplexity12.932313919067383
INFO:root:current mean train loss 6502.014435596955
INFO:root:current train perplexity12.88762092590332
INFO:root:current mean train loss 6487.204973106638
INFO:root:current train perplexity12.87453842163086
INFO:root:current mean train loss 6486.668640469034
INFO:root:current train perplexity12.875069618225098
INFO:root:current mean train loss 6481.090632050451
INFO:root:current train perplexity12.865177154541016
INFO:root:current mean train loss 6484.226140536576
INFO:root:current train perplexity12.874734878540039
INFO:root:current mean train loss 6478.963977352012
INFO:root:current train perplexity12.842541694641113
INFO:root:current mean train loss 6478.261271030494
INFO:root:current train perplexity12.85623836517334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.30s/it]
INFO:root:final mean train loss: 6472.254198135868
INFO:root:final train perplexity: 12.851899147033691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5243.899182042332
INFO:root:eval perplexity: 8.335127830505371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 5978.445388685727
INFO:root:eval perplexity: 11.526728630065918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [20:14:59<3:31:41, 423.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6485.359937764831
INFO:root:current train perplexity12.85611343383789
INFO:root:current mean train loss 6470.112009876179
INFO:root:current train perplexity12.83268928527832
INFO:root:current mean train loss 6482.823611697635
INFO:root:current train perplexity12.893851280212402
INFO:root:current mean train loss 6498.55636860202
INFO:root:current train perplexity12.923945426940918
INFO:root:current mean train loss 6508.090041615605
INFO:root:current train perplexity12.956768989562988
INFO:root:current mean train loss 6512.39118490748
INFO:root:current train perplexity12.979206085205078
INFO:root:current mean train loss 6499.943781712348
INFO:root:current train perplexity12.955036163330078
INFO:root:current mean train loss 6493.543990988348
INFO:root:current train perplexity12.935526847839355
INFO:root:current mean train loss 6489.814560558244
INFO:root:current train perplexity12.90401554107666
INFO:root:current mean train loss 6490.490086719565
INFO:root:current train perplexity12.911443710327148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.77s/it]
INFO:root:final mean train loss: 6483.8615490082775
INFO:root:final train perplexity: 12.910886764526367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5224.736667497784
INFO:root:eval perplexity: 8.270792007446289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5959.071199024823
INFO:root:eval perplexity: 11.435771942138672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [20:22:03<3:24:46, 423.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6446.356102786847
INFO:root:current train perplexity12.836441040039062
INFO:root:current mean train loss 6502.454855913174
INFO:root:current train perplexity13.033162117004395
INFO:root:current mean train loss 6520.204831241222
INFO:root:current train perplexity13.072962760925293
INFO:root:current mean train loss 6533.49072664765
INFO:root:current train perplexity13.087291717529297
INFO:root:current mean train loss 6507.425040986349
INFO:root:current train perplexity12.981393814086914
INFO:root:current mean train loss 6510.149645716215
INFO:root:current train perplexity12.966827392578125
INFO:root:current mean train loss 6512.731978981213
INFO:root:current train perplexity12.983628273010254
INFO:root:current mean train loss 6506.038536658654
INFO:root:current train perplexity12.967267036437988
INFO:root:current mean train loss 6493.127150239691
INFO:root:current train perplexity12.937796592712402
INFO:root:current mean train loss 6494.759673725116
INFO:root:current train perplexity12.949773788452148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.43s/it]
INFO:root:final mean train loss: 6493.826510644728
INFO:root:final train perplexity: 12.961746215820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it]
INFO:root:eval mean loss: 5365.478131233378
INFO:root:eval perplexity: 8.755146980285645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 6079.278292608599
INFO:root:eval perplexity: 12.011931419372559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [20:29:08<3:17:49, 423.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6606.0987890625
INFO:root:current train perplexity13.31756591796875
INFO:root:current mean train loss 6583.498657924107
INFO:root:current train perplexity13.378981590270996
INFO:root:current mean train loss 6591.6569744318185
INFO:root:current train perplexity13.437898635864258
INFO:root:current mean train loss 6591.514591145833
INFO:root:current train perplexity13.405680656433105
INFO:root:current mean train loss 6582.7518924753285
INFO:root:current train perplexity13.35654067993164
INFO:root:current mean train loss 6595.45618970788
INFO:root:current train perplexity13.431133270263672
INFO:root:current mean train loss 6584.6005230034725
INFO:root:current train perplexity13.411706924438477
INFO:root:current mean train loss 6582.130613659274
INFO:root:current train perplexity13.406649589538574
INFO:root:current mean train loss 6588.522251674107
INFO:root:current train perplexity13.42286205291748
INFO:root:current mean train loss 6587.688102964744
INFO:root:current train perplexity13.43190860748291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.59s/it]
INFO:root:final mean train loss: 6584.0120251563285
INFO:root:final train perplexity: 13.431239128112793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it]
INFO:root:eval mean loss: 5373.957450271499
INFO:root:eval perplexity: 8.78521728515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 6075.557173925089
INFO:root:eval perplexity: 11.993667602539062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [20:36:13<3:10:55, 424.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6752.766666274473
INFO:root:current train perplexity13.94672679901123
INFO:root:current mean train loss 6739.736029286202
INFO:root:current train perplexity14.030983924865723
INFO:root:current mean train loss 6720.288582845627
INFO:root:current train perplexity14.029167175292969
INFO:root:current mean train loss 6704.648262840649
INFO:root:current train perplexity13.969202995300293
INFO:root:current mean train loss 6717.831283158644
INFO:root:current train perplexity14.042204856872559
INFO:root:current mean train loss 6724.2269419020695
INFO:root:current train perplexity14.06716251373291
INFO:root:current mean train loss 6709.239369337939
INFO:root:current train perplexity14.018949508666992
INFO:root:current mean train loss 6698.865408360273
INFO:root:current train perplexity13.998869895935059
INFO:root:current mean train loss 6711.339432885936
INFO:root:current train perplexity14.051146507263184
INFO:root:current mean train loss 6709.658627825375
INFO:root:current train perplexity14.075570106506348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.28s/it]
INFO:root:final mean train loss: 6703.293942482241
INFO:root:final train perplexity: 14.078425407409668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5543.735919492465
INFO:root:eval perplexity: 9.409539222717285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.04s/it]
INFO:root:eval mean loss: 6245.964005707004
INFO:root:eval perplexity: 12.859211921691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [20:43:16<3:03:42, 423.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6711.664405906594
INFO:root:current train perplexity14.095827102661133
INFO:root:current mean train loss 6692.804802540085
INFO:root:current train perplexity13.926152229309082
INFO:root:current mean train loss 6647.195055774807
INFO:root:current train perplexity13.777135848999023
INFO:root:current mean train loss 6663.561598365569
INFO:root:current train perplexity13.842023849487305
INFO:root:current mean train loss 6651.2037256555495
INFO:root:current train perplexity13.788739204406738
INFO:root:current mean train loss 6645.126294647578
INFO:root:current train perplexity13.777056694030762
INFO:root:current mean train loss 6665.573828690304
INFO:root:current train perplexity13.872544288635254
INFO:root:current mean train loss 6708.433770296697
INFO:root:current train perplexity14.061924934387207
INFO:root:current mean train loss 6710.83827423541
INFO:root:current train perplexity14.087689399719238
INFO:root:current mean train loss 6718.515467823694
INFO:root:current train perplexity14.133810043334961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.83s/it]
INFO:root:final mean train loss: 6713.399193548387
INFO:root:final train perplexity: 14.134666442871094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 5542.810467226285
INFO:root:eval perplexity: 9.406020164489746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 6238.833045905363
INFO:root:eval perplexity: 12.821771621704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [20:50:20<2:56:39, 423.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6889.703726720329
INFO:root:current train perplexity15.015092849731445
INFO:root:current mean train loss 6866.412018589039
INFO:root:current train perplexity14.95707893371582
INFO:root:current mean train loss 6825.29928864444
INFO:root:current train perplexity14.699689865112305
INFO:root:current mean train loss 6801.2069774044485
INFO:root:current train perplexity14.573325157165527
INFO:root:current mean train loss 6776.24524537356
INFO:root:current train perplexity14.414464950561523
INFO:root:current mean train loss 6751.391893390025
INFO:root:current train perplexity14.265191078186035
INFO:root:current mean train loss 6734.882901214905
INFO:root:current train perplexity14.177938461303711
INFO:root:current mean train loss 6727.534601357165
INFO:root:current train perplexity14.16923713684082
INFO:root:current mean train loss 6724.474979795259
INFO:root:current train perplexity14.155159950256348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it]
INFO:root:final mean train loss: 6712.916534546883
INFO:root:final train perplexity: 14.131967544555664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5426.508054909131
INFO:root:eval perplexity: 8.97390079498291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 6121.958890874335
INFO:root:eval perplexity: 12.223411560058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [20:57:22<2:49:20, 423.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6787.024623325893
INFO:root:current train perplexity14.147741317749023
INFO:root:current mean train loss 6727.3625556731895
INFO:root:current train perplexity14.130339622497559
INFO:root:current mean train loss 6745.140030570652
INFO:root:current train perplexity14.268571853637695
INFO:root:current mean train loss 6752.997658794789
INFO:root:current train perplexity14.363821983337402
INFO:root:current mean train loss 6741.047880355498
INFO:root:current train perplexity14.289103507995605
INFO:root:current mean train loss 6708.248226970845
INFO:root:current train perplexity14.139732360839844
INFO:root:current mean train loss 6703.581271880148
INFO:root:current train perplexity14.096535682678223
INFO:root:current mean train loss 6695.082759873365
INFO:root:current train perplexity14.014986038208008
INFO:root:current mean train loss 6690.8397203183085
INFO:root:current train perplexity13.963722229003906
INFO:root:current mean train loss 6687.922988302784
INFO:root:current train perplexity13.962357521057129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.31s/it]
INFO:root:final mean train loss: 6679.132928663685
INFO:root:final train perplexity: 13.94486141204834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 5462.94178025266
INFO:root:eval perplexity: 9.10708999633789
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 6161.033542497784
INFO:root:eval perplexity: 12.420287132263184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [21:04:27<2:42:25, 423.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6848.915885416666
INFO:root:current train perplexity14.706791877746582
INFO:root:current mean train loss 6762.334999150815
INFO:root:current train perplexity14.407026290893555
INFO:root:current mean train loss 6744.757871547965
INFO:root:current train perplexity14.34842586517334
INFO:root:current mean train loss 6762.59072110615
INFO:root:current train perplexity14.365301132202148
INFO:root:current mean train loss 6761.074896460844
INFO:root:current train perplexity14.323744773864746
INFO:root:current mean train loss 6752.113417779126
INFO:root:current train perplexity14.302484512329102
INFO:root:current mean train loss 6740.888517848069
INFO:root:current train perplexity14.28135871887207
INFO:root:current mean train loss 6737.038959380463
INFO:root:current train perplexity14.248147964477539
INFO:root:current mean train loss 6734.74578819977
INFO:root:current train perplexity14.230603218078613
INFO:root:current mean train loss 6747.705200862363
INFO:root:current train perplexity14.294668197631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.35s/it]
INFO:root:final mean train loss: 6745.704404523296
INFO:root:final train perplexity: 14.315971374511719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 5653.71590688719
INFO:root:eval perplexity: 9.837449073791504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 6343.891231022828
INFO:root:eval perplexity: 13.38459300994873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [21:11:31<2:35:24, 423.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6938.431024966033
INFO:root:current train perplexity15.311888694763184
INFO:root:current mean train loss 6921.034259082825
INFO:root:current train perplexity15.232093811035156
INFO:root:current mean train loss 6871.394145880045
INFO:root:current train perplexity15.09776782989502
INFO:root:current mean train loss 6845.6665447223295
INFO:root:current train perplexity14.909491539001465
INFO:root:current mean train loss 6814.938702811022
INFO:root:current train perplexity14.682408332824707
INFO:root:current mean train loss 6786.52604415631
INFO:root:current train perplexity14.512903213500977
INFO:root:current mean train loss 6758.9683800662115
INFO:root:current train perplexity14.354551315307617
INFO:root:current mean train loss 6746.000483553769
INFO:root:current train perplexity14.289107322692871
INFO:root:current mean train loss 6743.25325837257
INFO:root:current train perplexity14.300694465637207
INFO:root:current mean train loss 6742.3264892842635
INFO:root:current train perplexity14.28604793548584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.75s/it]
INFO:root:final mean train loss: 6739.578394859068
INFO:root:final train perplexity: 14.281410217285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5451.78672152039
INFO:root:eval perplexity: 9.066102027893066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 6138.09181072695
INFO:root:eval perplexity: 12.304316520690918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [21:18:35<2:28:23, 423.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6619.670693674395
INFO:root:current train perplexity13.711111068725586
INFO:root:current mean train loss 6708.293744036259
INFO:root:current train perplexity14.137372970581055
INFO:root:current mean train loss 6690.366314512311
INFO:root:current train perplexity14.062967300415039
INFO:root:current mean train loss 6678.710505275208
INFO:root:current train perplexity13.969259262084961
INFO:root:current mean train loss 6713.2788584414875
INFO:root:current train perplexity14.130464553833008
INFO:root:current mean train loss 6759.272443466043
INFO:root:current train perplexity14.403901100158691
INFO:root:current mean train loss 6782.808805003219
INFO:root:current train perplexity14.5596342086792
INFO:root:current mean train loss 6811.563310907575
INFO:root:current train perplexity14.688934326171875
INFO:root:current mean train loss 6810.598864907679
INFO:root:current train perplexity14.674355506896973
INFO:root:current mean train loss 6801.145861829518
INFO:root:current train perplexity14.608317375183105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.61s/it]
INFO:root:final mean train loss: 6789.510113254671
INFO:root:final train perplexity: 14.565536499023438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 5389.544932263962
INFO:root:eval perplexity: 8.840767860412598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 6085.624445921986
INFO:root:eval perplexity: 12.04314136505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [21:25:38<2:21:12, 423.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6687.715607471955
INFO:root:current train perplexity13.832832336425781
INFO:root:current mean train loss 6695.371694441322
INFO:root:current train perplexity14.045958518981934
INFO:root:current mean train loss 6714.458696309493
INFO:root:current train perplexity14.116850852966309
INFO:root:current mean train loss 6703.458821614583
INFO:root:current train perplexity14.071053504943848
INFO:root:current mean train loss 6711.487934225513
INFO:root:current train perplexity14.110184669494629
INFO:root:current mean train loss 6710.340074755044
INFO:root:current train perplexity14.099967956542969
INFO:root:current mean train loss 6709.228341402582
INFO:root:current train perplexity14.087823867797852
INFO:root:current mean train loss 6708.4424806008965
INFO:root:current train perplexity14.072335243225098
INFO:root:current mean train loss 6700.145316923048
INFO:root:current train perplexity14.023519515991211
INFO:root:current mean train loss 6699.154081594449
INFO:root:current train perplexity14.032716751098633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.43s/it]
INFO:root:final mean train loss: 6693.9721957791235
INFO:root:final train perplexity: 14.026739120483398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 5366.610562804743
INFO:root:eval perplexity: 8.759157180786133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 6070.6176896332
INFO:root:eval perplexity: 11.96946907043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [21:32:40<2:14:01, 423.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6653.222936751995
INFO:root:current train perplexity13.849837303161621
INFO:root:current mean train loss 6684.22802734375
INFO:root:current train perplexity13.908629417419434
INFO:root:current mean train loss 6683.255556917384
INFO:root:current train perplexity13.931472778320312
INFO:root:current mean train loss 6715.6217410392655
INFO:root:current train perplexity14.064895629882812
INFO:root:current mean train loss 6708.473371740422
INFO:root:current train perplexity14.04674243927002
INFO:root:current mean train loss 6703.529055858661
INFO:root:current train perplexity14.009343147277832
INFO:root:current mean train loss 6708.675346551391
INFO:root:current train perplexity14.048871994018555
INFO:root:current mean train loss 6699.727393950803
INFO:root:current train perplexity14.014167785644531
INFO:root:current mean train loss 6706.781354919938
INFO:root:current train perplexity14.044897079467773
INFO:root:current mean train loss 6706.091472041645
INFO:root:current train perplexity14.060113906860352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.27s/it]
INFO:root:final mean train loss: 6700.8099781159435
INFO:root:final train perplexity: 14.0646333694458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 5457.363748753324
INFO:root:eval perplexity: 9.086572647094727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 6145.924233294548
INFO:root:eval perplexity: 12.34378719329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [21:39:46<2:07:09, 423.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6736.577734375
INFO:root:current train perplexity14.179229736328125
INFO:root:current mean train loss 6747.408971774194
INFO:root:current train perplexity14.192694664001465
INFO:root:current mean train loss 6735.753839231005
INFO:root:current train perplexity14.199213027954102
INFO:root:current mean train loss 6729.957351727553
INFO:root:current train perplexity14.232730865478516
INFO:root:current mean train loss 6721.471280477335
INFO:root:current train perplexity14.18017292022705
INFO:root:current mean train loss 6713.507616307714
INFO:root:current train perplexity14.133587837219238
INFO:root:current mean train loss 6712.746886182013
INFO:root:current train perplexity14.139749526977539
INFO:root:current mean train loss 6713.52749249793
INFO:root:current train perplexity14.14733600616455
INFO:root:current mean train loss 6723.883682839913
INFO:root:current train perplexity14.187666893005371
INFO:root:current mean train loss 6736.415958360602
INFO:root:current train perplexity14.238435745239258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.39s/it]
INFO:root:final mean train loss: 6736.039666944935
INFO:root:final train perplexity: 14.261484146118164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 5581.248171542553
INFO:root:eval perplexity: 9.553359985351562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.93s/it]
INFO:root:eval mean loss: 6269.519479305186
INFO:root:eval perplexity: 12.983672142028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [21:46:51<2:00:14, 424.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6763.611273871527
INFO:root:current train perplexity14.430027961730957
INFO:root:current mean train loss 6764.1835398293715
INFO:root:current train perplexity14.307116508483887
INFO:root:current mean train loss 6750.946545270913
INFO:root:current train perplexity14.274767875671387
INFO:root:current mean train loss 6741.338797240875
INFO:root:current train perplexity14.264674186706543
INFO:root:current mean train loss 6751.729984687163
INFO:root:current train perplexity14.304132461547852
INFO:root:current mean train loss 6768.00120118922
INFO:root:current train perplexity14.381856918334961
INFO:root:current mean train loss 6781.805548436321
INFO:root:current train perplexity14.454733848571777
INFO:root:current mean train loss 6786.261097999262
INFO:root:current train perplexity14.460366249084473
INFO:root:current mean train loss 6789.401622926926
INFO:root:current train perplexity14.499528884887695
INFO:root:current mean train loss 6786.983872014538
INFO:root:current train perplexity14.53316593170166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.26s/it]
INFO:root:final mean train loss: 6783.349321426884
INFO:root:final train perplexity: 14.530172348022461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 5680.732719691932
INFO:root:eval perplexity: 9.945513725280762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 6369.307104665337
INFO:root:eval perplexity: 13.524426460266113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [21:53:56<1:53:10, 424.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6825.643520301496
INFO:root:current train perplexity14.596908569335938
INFO:root:current mean train loss 6808.819961280154
INFO:root:current train perplexity14.674036979675293
INFO:root:current mean train loss 6815.807653223017
INFO:root:current train perplexity14.664897918701172
INFO:root:current mean train loss 6820.46453577746
INFO:root:current train perplexity14.716286659240723
INFO:root:current mean train loss 6830.6333515790875
INFO:root:current train perplexity14.768056869506836
INFO:root:current mean train loss 6832.904256683723
INFO:root:current train perplexity14.788358688354492
INFO:root:current mean train loss 6841.300032455058
INFO:root:current train perplexity14.8386869430542
INFO:root:current mean train loss 6842.336570175706
INFO:root:current train perplexity14.838608741760254
INFO:root:current mean train loss 6834.425647827569
INFO:root:current train perplexity14.799334526062012
INFO:root:current mean train loss 6825.084946857299
INFO:root:current train perplexity14.745732307434082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.61s/it]
INFO:root:final mean train loss: 6819.281823804302
INFO:root:final train perplexity: 14.737631797790527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it]
INFO:root:eval mean loss: 5528.4309930463205
INFO:root:eval perplexity: 9.351482391357422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it]
INFO:root:eval mean loss: 6214.189692071143
INFO:root:eval perplexity: 12.693215370178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [22:01:01<1:46:10, 424.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6816.255241297468
INFO:root:current train perplexity14.680755615234375
INFO:root:current mean train loss 6813.260499410789
INFO:root:current train perplexity14.477124214172363
INFO:root:current mean train loss 6780.8847848762325
INFO:root:current train perplexity14.375812530517578
INFO:root:current mean train loss 6772.758227345811
INFO:root:current train perplexity14.381006240844727
INFO:root:current mean train loss 6762.730235312826
INFO:root:current train perplexity14.37397575378418
INFO:root:current mean train loss 6767.049219424654
INFO:root:current train perplexity14.375699996948242
INFO:root:current mean train loss 6765.292278396539
INFO:root:current train perplexity14.372588157653809
INFO:root:current mean train loss 6767.542364509788
INFO:root:current train perplexity14.399127960205078
INFO:root:current mean train loss 6760.782184900278
INFO:root:current train perplexity14.379243850708008
INFO:root:current mean train loss 6761.764754173582
INFO:root:current train perplexity14.379144668579102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.99s/it]
INFO:root:final mean train loss: 6757.891503241754
INFO:root:final train perplexity: 14.384963989257812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5570.5038577681735
INFO:root:eval perplexity: 9.511943817138672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 6260.447508034131
INFO:root:eval perplexity: 12.935600280761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [22:08:02<1:38:50, 423.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6781.038748204023
INFO:root:current train perplexity14.528419494628906
INFO:root:current mean train loss 6795.644800196357
INFO:root:current train perplexity14.64073371887207
INFO:root:current mean train loss 6812.5247985627175
INFO:root:current train perplexity14.678802490234375
INFO:root:current mean train loss 6819.718594809835
INFO:root:current train perplexity14.734940528869629
INFO:root:current mean train loss 6821.48104526277
INFO:root:current train perplexity14.74512767791748
INFO:root:current mean train loss 6835.245205360946
INFO:root:current train perplexity14.809267044067383
INFO:root:current mean train loss 6829.538358863264
INFO:root:current train perplexity14.788506507873535
INFO:root:current mean train loss 6838.607274211801
INFO:root:current train perplexity14.821951866149902
INFO:root:current mean train loss 6847.325587258667
INFO:root:current train perplexity14.880701065063477
INFO:root:current mean train loss 6853.671562341692
INFO:root:current train perplexity14.909199714660645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.38s/it]
INFO:root:final mean train loss: 6848.699258619739
INFO:root:final train perplexity: 14.909668922424316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.08s/it]
INFO:root:eval mean loss: 5618.176148326685
INFO:root:eval perplexity: 9.697087287902832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 6304.103872312721
INFO:root:eval perplexity: 13.16859245300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [22:15:07<1:31:53, 424.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6862.469896175987
INFO:root:current train perplexity14.71124267578125
INFO:root:current mean train loss 6819.957081330128
INFO:root:current train perplexity14.598432540893555
INFO:root:current mean train loss 6809.463216697563
INFO:root:current train perplexity14.601858139038086
INFO:root:current mean train loss 6813.287338063687
INFO:root:current train perplexity14.6111421585083
INFO:root:current mean train loss 6824.452986900253
INFO:root:current train perplexity14.688142776489258
INFO:root:current mean train loss 6836.265486311712
INFO:root:current train perplexity14.743707656860352
INFO:root:current mean train loss 6843.317581637814
INFO:root:current train perplexity14.807209014892578
INFO:root:current mean train loss 6841.4831779432
INFO:root:current train perplexity14.838700294494629
INFO:root:current mean train loss 6841.383114743366
INFO:root:current train perplexity14.850546836853027

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.96s/it]
INFO:root:final mean train loss: 6827.749939457063
INFO:root:final train perplexity: 14.786948204040527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 5555.37487186946
INFO:root:eval perplexity: 9.453930854797363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 6239.213676723182
INFO:root:eval perplexity: 12.82376766204834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [22:22:12<1:24:50, 424.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6677.89013671875
INFO:root:current train perplexity14.670496940612793
INFO:root:current mean train loss 6809.2736413455705
INFO:root:current train perplexity14.51469898223877
INFO:root:current mean train loss 6809.892178840825
INFO:root:current train perplexity14.702143669128418
INFO:root:current mean train loss 6805.21655192863
INFO:root:current train perplexity14.69435977935791
INFO:root:current mean train loss 6806.335486778846
INFO:root:current train perplexity14.64546012878418
INFO:root:current mean train loss 6800.133269717631
INFO:root:current train perplexity14.604952812194824
INFO:root:current mean train loss 6803.060962278451
INFO:root:current train perplexity14.604921340942383
INFO:root:current mean train loss 6798.18893150449
INFO:root:current train perplexity14.598042488098145
INFO:root:current mean train loss 6798.364777105386
INFO:root:current train perplexity14.591556549072266
INFO:root:current mean train loss 6789.986367057724
INFO:root:current train perplexity14.534808158874512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.03s/it]
INFO:root:final mean train loss: 6783.271365011892
INFO:root:final train perplexity: 14.529732704162598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 5484.360981826241
INFO:root:eval perplexity: 9.186311721801758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 6186.504404920212
INFO:root:eval perplexity: 12.55032730102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [22:29:14<1:17:40, 423.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6663.811878551136
INFO:root:current train perplexity13.994414329528809
INFO:root:current mean train loss 6716.161999401746
INFO:root:current train perplexity14.181082725524902
INFO:root:current mean train loss 6744.877404380184
INFO:root:current train perplexity14.34118938446045
INFO:root:current mean train loss 6770.713545330084
INFO:root:current train perplexity14.462910652160645
INFO:root:current mean train loss 6768.4725208143245
INFO:root:current train perplexity14.435884475708008
INFO:root:current mean train loss 6785.078887521404
INFO:root:current train perplexity14.505828857421875
INFO:root:current mean train loss 6799.760453693995
INFO:root:current train perplexity14.569169998168945
INFO:root:current mean train loss 6801.089776448224
INFO:root:current train perplexity14.594218254089355
INFO:root:current mean train loss 6802.472249850686
INFO:root:current train perplexity14.594465255737305
INFO:root:current mean train loss 6807.574180695149
INFO:root:current train perplexity14.618521690368652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.92s/it]
INFO:root:final mean train loss: 6804.298426228185
INFO:root:final train perplexity: 14.650769233703613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it]
INFO:root:eval mean loss: 5729.77957045102
INFO:root:eval perplexity: 10.144732475280762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 6429.638391373005
INFO:root:eval perplexity: 13.862225532531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [22:36:21<1:10:45, 424.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6856.848607113487
INFO:root:current train perplexity15.307188034057617
INFO:root:current mean train loss 6993.368861607143
INFO:root:current train perplexity15.665570259094238
INFO:root:current mean train loss 6939.8356989333615
INFO:root:current train perplexity15.49113941192627
INFO:root:current mean train loss 6917.94225882886
INFO:root:current train perplexity15.503335952758789
INFO:root:current mean train loss 6914.470936194809
INFO:root:current train perplexity15.44031047821045
INFO:root:current mean train loss 6914.791018447435
INFO:root:current train perplexity15.41199016571045
INFO:root:current mean train loss 6917.6891052541905
INFO:root:current train perplexity15.376744270324707
INFO:root:current mean train loss 6919.625689298287
INFO:root:current train perplexity15.351410865783691
INFO:root:current mean train loss 6911.948276170444
INFO:root:current train perplexity15.285645484924316
INFO:root:current mean train loss 6907.350707078006
INFO:root:current train perplexity15.236347198486328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.59s/it]
INFO:root:final mean train loss: 6894.806291764782
INFO:root:final train perplexity: 15.183366775512695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 5587.735088375443
INFO:root:eval perplexity: 9.57845401763916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it]
INFO:root:eval mean loss: 6282.638394835993
INFO:root:eval perplexity: 13.053512573242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [22:43:19<1:03:22, 422.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6771.449869791667
INFO:root:current train perplexity14.424410820007324
INFO:root:current mean train loss 6756.803238035187
INFO:root:current train perplexity14.49219799041748
INFO:root:current mean train loss 6736.430072532351
INFO:root:current train perplexity14.332674980163574
INFO:root:current mean train loss 6754.808580311066
INFO:root:current train perplexity14.370234489440918
INFO:root:current mean train loss 6755.156955549253
INFO:root:current train perplexity14.364657402038574
INFO:root:current mean train loss 6751.863882567896
INFO:root:current train perplexity14.336447715759277
INFO:root:current mean train loss 6747.334809079695
INFO:root:current train perplexity14.327413558959961
INFO:root:current mean train loss 6750.829374919404
INFO:root:current train perplexity14.322126388549805
INFO:root:current mean train loss 6744.843275888943
INFO:root:current train perplexity14.294187545776367
INFO:root:current mean train loss 6739.571112607032
INFO:root:current train perplexity14.265445709228516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.23s/it]
INFO:root:final mean train loss: 6736.183417289488
INFO:root:final train perplexity: 14.262293815612793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it]
INFO:root:eval mean loss: 5481.095935145168
INFO:root:eval perplexity: 9.174193382263184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 6174.378161707668
INFO:root:eval perplexity: 12.488248825073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [22:50:22<56:22, 422.86s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6735.693303571428
INFO:root:current train perplexity14.105690956115723
INFO:root:current mean train loss 6723.322153501157
INFO:root:current train perplexity14.086742401123047
INFO:root:current mean train loss 6713.803866771941
INFO:root:current train perplexity14.11225700378418
INFO:root:current mean train loss 6735.305283640392
INFO:root:current train perplexity14.189988136291504
INFO:root:current mean train loss 6740.368375089799
INFO:root:current train perplexity14.221638679504395
INFO:root:current mean train loss 6738.8024788259345
INFO:root:current train perplexity14.229914665222168
INFO:root:current mean train loss 6746.390891824557
INFO:root:current train perplexity14.279458999633789
INFO:root:current mean train loss 6749.68879211841
INFO:root:current train perplexity14.30402946472168
INFO:root:current mean train loss 6753.410579037238
INFO:root:current train perplexity14.323140144348145
INFO:root:current mean train loss 6758.176065340909
INFO:root:current train perplexity14.343767166137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.87s/it]
INFO:root:final mean train loss: 6752.66771488805
INFO:root:final train perplexity: 14.355351448059082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 5530.128383338874
INFO:root:eval perplexity: 9.357906341552734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 6227.282462045656
INFO:root:eval perplexity: 12.76134967803955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [22:57:27<49:23, 423.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6767.721906795058
INFO:root:current train perplexity14.606927871704102
INFO:root:current mean train loss 6759.845436789773
INFO:root:current train perplexity14.432639122009277
INFO:root:current mean train loss 6742.885701999743
INFO:root:current train perplexity14.389765739440918
INFO:root:current mean train loss 6750.818174312136
INFO:root:current train perplexity14.357381820678711
INFO:root:current mean train loss 6759.804330382336
INFO:root:current train perplexity14.361167907714844
INFO:root:current mean train loss 6769.2029478519225
INFO:root:current train perplexity14.403450965881348
INFO:root:current mean train loss 6767.518671631999
INFO:root:current train perplexity14.385025024414062
INFO:root:current mean train loss 6759.463365762744
INFO:root:current train perplexity14.355813980102539
INFO:root:current mean train loss 6757.688055470603
INFO:root:current train perplexity14.36470890045166
INFO:root:current mean train loss 6758.759030355249
INFO:root:current train perplexity14.369099617004395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.70s/it]
INFO:root:final mean train loss: 6753.683136601602
INFO:root:final train perplexity: 14.361105918884277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 5517.458918578236
INFO:root:eval perplexity: 9.310089111328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 6215.89489140071
INFO:root:eval perplexity: 12.702067375183105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [23:04:30<42:19, 423.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6692.605976179534
INFO:root:current train perplexity14.184700965881348
INFO:root:current mean train loss 6740.448471776697
INFO:root:current train perplexity14.40035343170166
INFO:root:current mean train loss 6755.25011282993
INFO:root:current train perplexity14.368644714355469
INFO:root:current mean train loss 6768.658333889779
INFO:root:current train perplexity14.428162574768066
INFO:root:current mean train loss 6761.64105806541
INFO:root:current train perplexity14.39273738861084
INFO:root:current mean train loss 6753.481924732021
INFO:root:current train perplexity14.347649574279785
INFO:root:current mean train loss 6753.1733315932215
INFO:root:current train perplexity14.328021049499512
INFO:root:current mean train loss 6755.948437890105
INFO:root:current train perplexity14.336130142211914
INFO:root:current mean train loss 6750.08840357851
INFO:root:current train perplexity14.326101303100586
INFO:root:current mean train loss 6747.625355813781
INFO:root:current train perplexity14.297455787658691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.45s/it]
INFO:root:final mean train loss: 6740.767012442312
INFO:root:final train perplexity: 14.288108825683594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 5451.743600398936
INFO:root:eval perplexity: 9.065946578979492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 6152.873472822474
INFO:root:eval perplexity: 12.378913879394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [23:11:34<35:18, 423.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6728.756579382945
INFO:root:current train perplexity14.128554344177246
INFO:root:current mean train loss 6731.84599486537
INFO:root:current train perplexity14.099688529968262
INFO:root:current mean train loss 6759.232216382119
INFO:root:current train perplexity14.198349952697754
INFO:root:current mean train loss 6736.106302500435
INFO:root:current train perplexity14.152143478393555
INFO:root:current mean train loss 6734.429849196623
INFO:root:current train perplexity14.174453735351562
INFO:root:current mean train loss 6728.4504329019455
INFO:root:current train perplexity14.159727096557617
INFO:root:current mean train loss 6724.565036246918
INFO:root:current train perplexity14.160452842712402
INFO:root:current mean train loss 6715.97396798316
INFO:root:current train perplexity14.138053894042969
INFO:root:current mean train loss 6719.024406672912
INFO:root:current train perplexity14.125143051147461
INFO:root:current mean train loss 6716.18601988155
INFO:root:current train perplexity14.12922477722168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.54s/it]
INFO:root:final mean train loss: 6710.404816412157
INFO:root:final train perplexity: 14.1179780960083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it]
INFO:root:eval mean loss: 5464.214667137633
INFO:root:eval perplexity: 9.11177921295166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 6165.375290890957
INFO:root:eval perplexity: 12.44235610961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [23:18:40<28:17, 424.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6702.336731868004
INFO:root:current train perplexity14.003900527954102
INFO:root:current mean train loss 6686.022697768525
INFO:root:current train perplexity14.019120216369629
INFO:root:current mean train loss 6700.272947389982
INFO:root:current train perplexity14.08439826965332
INFO:root:current mean train loss 6726.184161859247
INFO:root:current train perplexity14.14993667602539
INFO:root:current mean train loss 6722.581271120516
INFO:root:current train perplexity14.159882545471191
INFO:root:current mean train loss 6713.4675702022705
INFO:root:current train perplexity14.125853538513184
INFO:root:current mean train loss 6712.540162047882
INFO:root:current train perplexity14.114764213562012
INFO:root:current mean train loss 6707.772036954042
INFO:root:current train perplexity14.101178169250488
INFO:root:current mean train loss 6708.436145540477
INFO:root:current train perplexity14.105424880981445
INFO:root:current mean train loss 6708.741000880623
INFO:root:current train perplexity14.094969749450684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.40s/it]
INFO:root:final mean train loss: 6705.106971002394
INFO:root:final train perplexity: 14.088496208190918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 5436.37929410461
INFO:root:eval perplexity: 9.009794235229492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 6138.85976285461
INFO:root:eval perplexity: 12.308177947998047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [23:25:44<21:12, 424.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6703.777799479167
INFO:root:current train perplexity13.962324142456055
INFO:root:current mean train loss 6684.897737165179
INFO:root:current train perplexity14.007586479187012
INFO:root:current mean train loss 6690.032860440341
INFO:root:current train perplexity14.018752098083496
INFO:root:current mean train loss 6701.5236484375
INFO:root:current train perplexity14.04263687133789
INFO:root:current mean train loss 6699.4548046875
INFO:root:current train perplexity14.057931900024414
INFO:root:current mean train loss 6707.773215862771
INFO:root:current train perplexity14.098697662353516
INFO:root:current mean train loss 6711.749487847223
INFO:root:current train perplexity14.11400318145752
INFO:root:current mean train loss 6718.158952242944
INFO:root:current train perplexity14.119250297546387
INFO:root:current mean train loss 6714.767082589286
INFO:root:current train perplexity14.107402801513672
INFO:root:current mean train loss 6713.924472155449
INFO:root:current train perplexity14.112832069396973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.39s/it]
INFO:root:final mean train loss: 6709.631933396862
INFO:root:final train perplexity: 14.113673210144043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 5454.791095273715
INFO:root:eval perplexity: 9.077123641967773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 6156.226791057181
INFO:root:eval perplexity: 12.395898818969727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [23:32:49<14:08, 424.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6784.459919757153
INFO:root:current train perplexity14.313650131225586
INFO:root:current mean train loss 6764.518087751879
INFO:root:current train perplexity14.286041259765625
INFO:root:current mean train loss 6733.3068217894215
INFO:root:current train perplexity14.208173751831055
INFO:root:current mean train loss 6721.914919223238
INFO:root:current train perplexity14.165778160095215
INFO:root:current mean train loss 6728.866686076604
INFO:root:current train perplexity14.183916091918945
INFO:root:current mean train loss 6723.625923797974
INFO:root:current train perplexity14.190498352050781
INFO:root:current mean train loss 6727.402423819546
INFO:root:current train perplexity14.186960220336914
INFO:root:current mean train loss 6723.39124673232
INFO:root:current train perplexity14.154391288757324
INFO:root:current mean train loss 6720.156800214999
INFO:root:current train perplexity14.155025482177734
INFO:root:current mean train loss 6725.868746721611
INFO:root:current train perplexity14.172443389892578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.09s/it]
INFO:root:final mean train loss: 6720.803575946438
INFO:root:final train perplexity: 14.176018714904785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it]
INFO:root:eval mean loss: 5475.253847379211
INFO:root:eval perplexity: 9.152544975280762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 6176.802838264628
INFO:root:eval perplexity: 12.500635147094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [23:39:54<07:04, 424.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6719.987959306319
INFO:root:current train perplexity14.293700218200684
INFO:root:current mean train loss 6756.8542774460075
INFO:root:current train perplexity14.30222225189209
INFO:root:current mean train loss 6724.770316527062
INFO:root:current train perplexity14.175751686096191
INFO:root:current mean train loss 6717.4006691076565
INFO:root:current train perplexity14.128402709960938
INFO:root:current mean train loss 6713.0518701867995
INFO:root:current train perplexity14.137635231018066
INFO:root:current mean train loss 6710.781087239583
INFO:root:current train perplexity14.1367826461792
INFO:root:current mean train loss 6705.711130409958
INFO:root:current train perplexity14.134875297546387
INFO:root:current mean train loss 6710.768870743126
INFO:root:current train perplexity14.144220352172852
INFO:root:current mean train loss 6716.217296116547
INFO:root:current train perplexity14.14430046081543
INFO:root:current mean train loss 6724.246212494481
INFO:root:current train perplexity14.16576099395752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.23s/it]
INFO:root:final mean train loss: 6718.838503806822
INFO:root:final train perplexity: 14.165032386779785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 5472.112121149158
INFO:root:eval perplexity: 9.140923500061035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 6173.851718334441
INFO:root:eval perplexity: 12.48556137084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_minilml6_not_concat_200e_128/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [23:46:59<00:00, 424.66s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [23:46:59<00:00, 428.10s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.74s/it]
INFO:root:eval mean loss: 5472.112121149158
INFO:root:eval perplexity: 9.140923500061035
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it]
INFO:root:eval mean loss: 6173.851718334441
INFO:root:eval perplexity: 12.48556137084961
INFO:root:evalaution complete
INFO:root:save model final: multiqal6_minilml6_not_concat_200e_128/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14a11739cf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14a1173948e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14a1172b9e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14a11739da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14a1172b7948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14a11739da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14a117272b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14a116cd746a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14a213533a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14a213533be0]
python(+0x24a989) [0x56178889c989]
python(+0x24a9bd) [0x56178889c9bd]
python(+0x24aa14) [0x56178889ca14]
python(+0x108f75) [0x56178875af75]
python(Py_RunMain+0x313) [0x56178889f983]
python(Py_BytesMain+0x39) [0x56178889fbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14a2135110b3]
python(+0x1d6e13) [0x561788828e13]
/opt/slurm/data/slurmd/job30005404/slurm_script: line 255: 2051259 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path nreimers/MiniLM-L6-H384-uncased --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected --output multiqal6_minilml6_not_concat_200e_128 --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self --batch_size 128
"
