INFO:root:Output: mpnet_gpt2_not_concat_1e-5
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Using pad_token, but it is not set yet.
INFO:root:pad token is not set, adding [PAD] to tokenizer and embedding
Some weights of RetrievalGenerationModelGPT2 were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.6.crossattention.c_proj.weight', 'h.3.ln_cross_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.10.crossattention.q_attn.weight', 'h.4.ln_cross_attn.weight', 'h.8.crossattention.c_attn_v.bias', 'h.4.crossattention.c_attn_v.weight', 'h.9.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.10.crossattention.bias', 'h.7.crossattention.c_attn.weight', 'h.0.crossattention.bias', 'h.9.crossattention.c_attn_v.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.7.crossattention.c_proj.weight', 'h.10.crossattention.c_attn_v.bias', 'h.5.crossattention.c_attn_v.weight', 'h.1.crossattention.c_attn_v.bias', 'h.2.crossattention.bias', 'h.2.crossattention.q_attn.weight', 'h.9.crossattention.bias', 'h.6.crossattention.c_attn_v.weight', 'h.3.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.bias', 'h.3.crossattention.bias', 'h.6.crossattention.c_attn.weight', 'h.11.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.3.crossattention.c_attn_v.weight', 'h.5.crossattention.c_attn.weight', 'h.0.crossattention.c_attn_v.bias', 'h.6.crossattention.bias', 'h.4.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.7.ln_cross_attn.weight', 'h.7.crossattention.c_attn_v.weight', 'h.9.crossattention.masked_bias', 'h.9.crossattention.c_proj.bias', 'h.5.crossattention.c_attn_v.bias', 'h.10.crossattention.c_proj.bias', 'h.3.crossattention.c_attn_v.bias', 'h.9.crossattention.c_attn_v.bias', 'h.0.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.5.crossattention.bias', 'h.5.ln_cross_attn.weight', 'h.0.crossattention.c_attn_v.weight', 'h.9.crossattention.c_proj.weight', 'h.0.crossattention.c_proj.weight', 'h.8.ln_cross_attn.weight', 'h.1.crossattention.c_proj.weight', 'h.11.crossattention.bias', 'h.6.ln_cross_attn.weight', 'h.4.crossattention.bias', 'h.0.crossattention.c_proj.bias', 'h.1.crossattention.c_attn_v.weight', 'h.9.crossattention.q_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.bias', 'h.10.ln_cross_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.2.crossattention.c_attn_v.bias', 'h.3.crossattention.c_proj.bias', 'h.1.crossattention.q_attn.weight', 'h.10.crossattention.masked_bias', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn_v.bias', 'h.6.crossattention.q_attn.weight', 'h.10.crossattention.c_attn_v.weight', 'h.2.crossattention.masked_bias', 'h.11.crossattention.c_attn_v.weight', 'h.11.ln_cross_attn.weight', 'h.1.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.7.crossattention.masked_bias', 'h.4.crossattention.masked_bias', 'h.11.crossattention.c_proj.weight', 'h.8.crossattention.c_attn_v.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.q_attn.weight', 'h.0.crossattention.q_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.5.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_attn_v.weight', 'h.4.crossattention.c_attn.weight', 'h.11.crossattention.c_attn_v.bias', 'h.6.crossattention.c_attn_v.bias', 'h.0.crossattention.masked_bias', 'h.3.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.5.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.4.crossattention.c_attn_v.bias', 'h.9.crossattention.c_attn.weight', 'h.6.crossattention.masked_bias', 'h.5.crossattention.c_proj.bias', 'h.1.ln_cross_attn.weight', 'h.1.crossattention.c_attn.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 108446.49013573233
INFO:root:current train perplexity1.3796088674150865e+37
INFO:root:current mean train loss 61213.36846341081
INFO:root:current train perplexity9.513745844954139e+20
INFO:root:current mean train loss 42311.68699130565
INFO:root:current train perplexity344100331061248.0
INFO:root:current mean train loss 32714.67034223743
INFO:root:current train perplexity171792072704.0
INFO:root:current mean train loss 26901.810018963708
INFO:root:current train perplexity1690707840.0
INFO:root:current mean train loss 22992.69321672188
INFO:root:current train perplexity78891064.0
INFO:root:current mean train loss 20185.19637568178
INFO:root:current train perplexity8549219.0
INFO:root:current mean train loss 18075.907116867274
INFO:root:current train perplexity1591022.125
INFO:root:current mean train loss 16426.168312556485
INFO:root:current train perplexity429921.25
INFO:root:current mean train loss 15098.270580639233
INFO:root:current train perplexity151129.0
INFO:root:current mean train loss 14008.514415404274
INFO:root:current train perplexity63840.99609375
INFO:root:current mean train loss 13095.230557935649
INFO:root:current train perplexity31118.66015625
INFO:root:current mean train loss 12322.590111383757
INFO:root:current train perplexity16767.369140625
INFO:root:current mean train loss 11656.90093928699
INFO:root:current train perplexity9894.6171875
INFO:root:current mean train loss 11076.924802081596
INFO:root:current train perplexity6241.39111328125
INFO:root:current mean train loss 10568.119901598655
INFO:root:current train perplexity4180.564453125
INFO:root:current mean train loss 10114.942572348395
INFO:root:current train perplexity2935.055908203125
INFO:root:current mean train loss 9710.92469910584
INFO:root:current train perplexity2137.95166015625
INFO:root:current mean train loss 9350.765305778741
INFO:root:current train perplexity1604.0802001953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.03s/it]
INFO:root:final mean train loss: 9073.916673068741
INFO:root:final train perplexity: 1290.9283447265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it]
INFO:root:eval mean loss: 2608.9891032766786
INFO:root:eval perplexity: 8.262116432189941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it]
INFO:root:eval mean loss: 2830.198294132314
INFO:root:eval perplexity: 10.2511625289917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/1
  0%|          | 1/200 [09:11<30:29:52, 551.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2819.081527709961
INFO:root:current train perplexity9.171953201293945
INFO:root:current mean train loss 2793.6969520305765
INFO:root:current train perplexity9.084426879882812
INFO:root:current mean train loss 2794.0142053674767
INFO:root:current train perplexity9.059401512145996
INFO:root:current mean train loss 2775.2042050904865
INFO:root:current train perplexity8.943988800048828
INFO:root:current mean train loss 2767.6496822650615
INFO:root:current train perplexity8.869391441345215
INFO:root:current mean train loss 2761.760123319404
INFO:root:current train perplexity8.815053939819336
INFO:root:current mean train loss 2749.528772527521
INFO:root:current train perplexity8.748490333557129
INFO:root:current mean train loss 2743.209528576728
INFO:root:current train perplexity8.69642162322998
INFO:root:current mean train loss 2734.4199508966185
INFO:root:current train perplexity8.64820671081543
INFO:root:current mean train loss 2726.2406608215065
INFO:root:current train perplexity8.599588394165039
INFO:root:current mean train loss 2719.714700533649
INFO:root:current train perplexity8.552425384521484
INFO:root:current mean train loss 2714.3296801932825
INFO:root:current train perplexity8.511587142944336
INFO:root:current mean train loss 2706.119828876696
INFO:root:current train perplexity8.462430000305176
INFO:root:current mean train loss 2699.217987431581
INFO:root:current train perplexity8.42253303527832
INFO:root:current mean train loss 2693.4564316744186
INFO:root:current train perplexity8.383503913879395
INFO:root:current mean train loss 2687.899625591993
INFO:root:current train perplexity8.341625213623047
INFO:root:current mean train loss 2681.3944149961567
INFO:root:current train perplexity8.304560661315918
INFO:root:current mean train loss 2676.630498214757
INFO:root:current train perplexity8.267206192016602
INFO:root:current mean train loss 2670.0132300423106
INFO:root:current train perplexity8.22793960571289
INFO:root:current mean train loss 2665.7235309385806
INFO:root:current train perplexity8.196465492248535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.18s/it]
INFO:root:final mean train loss: 2661.1930185261244
INFO:root:final train perplexity: 8.172662734985352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.64s/it]
INFO:root:eval mean loss: 2396.0266130596187
INFO:root:eval perplexity: 6.953964710235596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.78s/it]
INFO:root:eval mean loss: 2660.4405794617132
INFO:root:eval perplexity: 8.915506362915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/2
  1%|          | 2/200 [18:38<30:49:16, 560.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2539.6861165364585
INFO:root:current train perplexity7.512327194213867
INFO:root:current mean train loss 2516.2014582354323
INFO:root:current train perplexity7.335955619812012
INFO:root:current mean train loss 2522.4195582835973
INFO:root:current train perplexity7.312604904174805
INFO:root:current mean train loss 2525.142235008446
INFO:root:current train perplexity7.3393473625183105
INFO:root:current mean train loss 2520.621270794241
INFO:root:current train perplexity7.340029716491699
INFO:root:current mean train loss 2515.6635595611515
INFO:root:current train perplexity7.315540790557861
INFO:root:current mean train loss 2516.4088842503456
INFO:root:current train perplexity7.298923015594482
INFO:root:current mean train loss 2511.9962186514113
INFO:root:current train perplexity7.264010429382324
INFO:root:current mean train loss 2506.425164890175
INFO:root:current train perplexity7.246427536010742
INFO:root:current mean train loss 2505.589291882285
INFO:root:current train perplexity7.229372024536133
INFO:root:current mean train loss 2502.507128055421
INFO:root:current train perplexity7.214133262634277
INFO:root:current mean train loss 2500.8970694074774
INFO:root:current train perplexity7.205111503601074
INFO:root:current mean train loss 2498.0155111469103
INFO:root:current train perplexity7.193216800689697
INFO:root:current mean train loss 2496.9554325226813
INFO:root:current train perplexity7.182831287384033
INFO:root:current mean train loss 2494.8410806383026
INFO:root:current train perplexity7.166694164276123
INFO:root:current mean train loss 2493.0903983616936
INFO:root:current train perplexity7.152574062347412
INFO:root:current mean train loss 2490.922272457349
INFO:root:current train perplexity7.144102096557617
INFO:root:current mean train loss 2487.944021780781
INFO:root:current train perplexity7.130124092102051
INFO:root:current mean train loss 2487.2043956500615
INFO:root:current train perplexity7.117691516876221
INFO:root:current mean train loss 2485.1228109439667
INFO:root:current train perplexity7.106152534484863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.78s/it]
INFO:root:final mean train loss: 2482.5650139836066
INFO:root:final train perplexity: 7.097784042358398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.85s/it]
INFO:root:eval mean loss: 2307.8845825195312
INFO:root:eval perplexity: 6.475144863128662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 2593.4436792684787
INFO:root:eval perplexity: 8.437597274780273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/3
  2%|â–         | 3/200 [27:48<30:25:11, 555.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2364.1267041015626
INFO:root:current train perplexity6.529631614685059
INFO:root:current mean train loss 2372.856510416667
INFO:root:current train perplexity6.6171722412109375
INFO:root:current mean train loss 2388.735501953125
INFO:root:current train perplexity6.630327224731445
INFO:root:current mean train loss 2389.8755147879465
INFO:root:current train perplexity6.668606281280518
INFO:root:current mean train loss 2391.68883734809
INFO:root:current train perplexity6.668463230133057
INFO:root:current mean train loss 2395.835242808949
INFO:root:current train perplexity6.674178600311279
INFO:root:current mean train loss 2397.6672513521635
INFO:root:current train perplexity6.673228740692139
INFO:root:current mean train loss 2396.242735026042
INFO:root:current train perplexity6.6757073402404785
INFO:root:current mean train loss 2396.6185653147977
INFO:root:current train perplexity6.669012546539307
INFO:root:current mean train loss 2397.278195415296
INFO:root:current train perplexity6.668339252471924
INFO:root:current mean train loss 2396.55369140625
INFO:root:current train perplexity6.657192230224609
INFO:root:current mean train loss 2396.76212274966
INFO:root:current train perplexity6.65306282043457
INFO:root:current mean train loss 2396.4888060546873
INFO:root:current train perplexity6.645636558532715
INFO:root:current mean train loss 2394.5768287037035
INFO:root:current train perplexity6.635485649108887
INFO:root:current mean train loss 2393.98349845097
INFO:root:current train perplexity6.627805233001709
INFO:root:current mean train loss 2393.0214636624246
INFO:root:current train perplexity6.619935035705566
INFO:root:current mean train loss 2391.569865426728
INFO:root:current train perplexity6.610509872436523
INFO:root:current mean train loss 2390.094686314174
INFO:root:current train perplexity6.598972797393799
INFO:root:current mean train loss 2389.302527779244
INFO:root:current train perplexity6.592097282409668
INFO:root:current mean train loss 2389.269087101863
INFO:root:current train perplexity6.588432312011719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.69s/it]
INFO:root:final mean train loss: 2387.18983965021
INFO:root:final train perplexity: 6.583006381988525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it]
INFO:root:eval mean loss: 2253.54115241301
INFO:root:eval perplexity: 6.196507453918457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 2560.570870041002
INFO:root:eval perplexity: 8.212564468383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/4
  2%|â–         | 4/200 [36:56<30:05:30, 552.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2325.321819248484
INFO:root:current train perplexity6.309709548950195
INFO:root:current mean train loss 2327.399786852077
INFO:root:current train perplexity6.3113179206848145
INFO:root:current mean train loss 2331.8507281242687
INFO:root:current train perplexity6.306924819946289
INFO:root:current mean train loss 2331.1847056874785
INFO:root:current train perplexity6.301724910736084
INFO:root:current mean train loss 2333.970856301024
INFO:root:current train perplexity6.315686225891113
INFO:root:current mean train loss 2332.1150391055585
INFO:root:current train perplexity6.316681385040283
INFO:root:current mean train loss 2331.3243931623056
INFO:root:current train perplexity6.3215107917785645
INFO:root:current mean train loss 2333.625875182071
INFO:root:current train perplexity6.32296085357666
INFO:root:current mean train loss 2333.100515820988
INFO:root:current train perplexity6.31857967376709
INFO:root:current mean train loss 2332.430222362372
INFO:root:current train perplexity6.317265033721924
INFO:root:current mean train loss 2331.9047028989353
INFO:root:current train perplexity6.314164161682129
INFO:root:current mean train loss 2330.8687368620126
INFO:root:current train perplexity6.305000305175781
INFO:root:current mean train loss 2330.483905891593
INFO:root:current train perplexity6.294442176818848
INFO:root:current mean train loss 2328.3819514890615
INFO:root:current train perplexity6.289439678192139
INFO:root:current mean train loss 2326.9563878637314
INFO:root:current train perplexity6.289046764373779
INFO:root:current mean train loss 2326.66434582465
INFO:root:current train perplexity6.283394813537598
INFO:root:current mean train loss 2326.4517942358793
INFO:root:current train perplexity6.279604911804199
INFO:root:current mean train loss 2326.99735044556
INFO:root:current train perplexity6.277438163757324
INFO:root:current mean train loss 2324.371484937295
INFO:root:current train perplexity6.266400337219238
INFO:root:current mean train loss 2324.5591246038143
INFO:root:current train perplexity6.26452112197876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.74s/it]
INFO:root:final mean train loss: 2324.256295700958
INFO:root:final train perplexity: 6.263948440551758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it]
INFO:root:eval mean loss: 2215.672769316545
INFO:root:eval perplexity: 6.009466171264648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 2538.0739529657026
INFO:root:eval perplexity: 8.062026023864746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/5
  2%|â–Ž         | 5/200 [46:00<29:45:54, 549.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2271.8126089913503
INFO:root:current train perplexity6.063022613525391
INFO:root:current mean train loss 2280.698035198709
INFO:root:current train perplexity6.08811092376709
INFO:root:current mean train loss 2276.49599403059
INFO:root:current train perplexity6.068153381347656
INFO:root:current mean train loss 2280.018099784851
INFO:root:current train perplexity6.0731353759765625
INFO:root:current mean train loss 2280.8855242768595
INFO:root:current train perplexity6.068096160888672
INFO:root:current mean train loss 2283.1883833375696
INFO:root:current train perplexity6.067235946655273
INFO:root:current mean train loss 2285.076291803728
INFO:root:current train perplexity6.06749963760376
INFO:root:current mean train loss 2281.067721931302
INFO:root:current train perplexity6.0540876388549805
INFO:root:current mean train loss 2280.8327823138343
INFO:root:current train perplexity6.050476551055908
INFO:root:current mean train loss 2278.27936014315
INFO:root:current train perplexity6.045780658721924
INFO:root:current mean train loss 2278.200334837516
INFO:root:current train perplexity6.044033050537109
INFO:root:current mean train loss 2276.6544845168655
INFO:root:current train perplexity6.042492389678955
INFO:root:current mean train loss 2277.1176209256655
INFO:root:current train perplexity6.039949893951416
INFO:root:current mean train loss 2275.0111814289426
INFO:root:current train perplexity6.031710624694824
INFO:root:current mean train loss 2274.0760461030945
INFO:root:current train perplexity6.021854400634766
INFO:root:current mean train loss 2272.984761247731
INFO:root:current train perplexity6.015068054199219
INFO:root:current mean train loss 2271.8971102390606
INFO:root:current train perplexity6.008497714996338
INFO:root:current mean train loss 2270.710326532612
INFO:root:current train perplexity6.001953125
INFO:root:current mean train loss 2268.2018103467935
INFO:root:current train perplexity5.991528034210205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.87s/it]
INFO:root:final mean train loss: 2265.732503501442
INFO:root:final train perplexity: 5.981137752532959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it]
INFO:root:eval mean loss: 2158.4101558171265
INFO:root:eval perplexity: 5.737297058105469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it]
INFO:root:eval mean loss: 2495.2845467641846
INFO:root:eval perplexity: 7.7832746505737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/6
  3%|â–Ž         | 6/200 [55:07<29:34:29, 548.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2229.369873046875
INFO:root:current train perplexity6.036829471588135
INFO:root:current mean train loss 2223.546362546411
INFO:root:current train perplexity5.784381866455078
INFO:root:current mean train loss 2224.6760891586987
INFO:root:current train perplexity5.791346549987793
INFO:root:current mean train loss 2218.783628140573
INFO:root:current train perplexity5.784021854400635
INFO:root:current mean train loss 2218.344394750429
INFO:root:current train perplexity5.764462947845459
INFO:root:current mean train loss 2217.0843795806823
INFO:root:current train perplexity5.750077724456787
INFO:root:current mean train loss 2215.096428844179
INFO:root:current train perplexity5.7491068840026855
INFO:root:current mean train loss 2211.7266643703747
INFO:root:current train perplexity5.7474684715271
INFO:root:current mean train loss 2214.650357402368
INFO:root:current train perplexity5.752349376678467
INFO:root:current mean train loss 2212.3716939403266
INFO:root:current train perplexity5.747339725494385
INFO:root:current mean train loss 2212.138966502248
INFO:root:current train perplexity5.748183727264404
INFO:root:current mean train loss 2210.3992242492623
INFO:root:current train perplexity5.739537715911865
INFO:root:current mean train loss 2212.8909762697754
INFO:root:current train perplexity5.743065357208252
INFO:root:current mean train loss 2213.420307039207
INFO:root:current train perplexity5.738486289978027
INFO:root:current mean train loss 2212.816829008855
INFO:root:current train perplexity5.735795974731445
INFO:root:current mean train loss 2214.0814284617545
INFO:root:current train perplexity5.738089084625244
INFO:root:current mean train loss 2213.4978062417044
INFO:root:current train perplexity5.73711633682251
INFO:root:current mean train loss 2213.745203519414
INFO:root:current train perplexity5.73417854309082
INFO:root:current mean train loss 2213.1441186103207
INFO:root:current train perplexity5.728499412536621
INFO:root:current mean train loss 2211.3300196262862
INFO:root:current train perplexity5.726349830627441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it]
INFO:root:final mean train loss: 2209.454419265416
INFO:root:final train perplexity: 5.721230506896973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.95s/it]
INFO:root:eval mean loss: 2125.7625606888573
INFO:root:eval perplexity: 5.587676525115967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it]
INFO:root:eval mean loss: 2474.5819234645114
INFO:root:eval perplexity: 7.651889801025391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/7
  4%|â–Ž         | 7/200 [1:04:20<29:29:08, 549.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2189.6136135525176
INFO:root:current train perplexity5.627881050109863
INFO:root:current mean train loss 2191.8834466449284
INFO:root:current train perplexity5.636948108673096
INFO:root:current mean train loss 2195.774560770857
INFO:root:current train perplexity5.618004322052002
INFO:root:current mean train loss 2191.951453634778
INFO:root:current train perplexity5.612245082855225
INFO:root:current mean train loss 2186.4396806196733
INFO:root:current train perplexity5.599952697753906
INFO:root:current mean train loss 2185.301143454769
INFO:root:current train perplexity5.5886969566345215
INFO:root:current mean train loss 2184.6522767891006
INFO:root:current train perplexity5.579170227050781
INFO:root:current mean train loss 2183.332613209164
INFO:root:current train perplexity5.578690052032471
INFO:root:current mean train loss 2180.5039971311985
INFO:root:current train perplexity5.575634479522705
INFO:root:current mean train loss 2178.5087205807886
INFO:root:current train perplexity5.571168899536133
INFO:root:current mean train loss 2178.5330345288708
INFO:root:current train perplexity5.574858665466309
INFO:root:current mean train loss 2177.923827797441
INFO:root:current train perplexity5.572604656219482
INFO:root:current mean train loss 2175.3232880891446
INFO:root:current train perplexity5.562291622161865
INFO:root:current mean train loss 2175.526591600525
INFO:root:current train perplexity5.563455104827881
INFO:root:current mean train loss 2174.6041841708725
INFO:root:current train perplexity5.5612311363220215
INFO:root:current mean train loss 2173.9392331089425
INFO:root:current train perplexity5.557807445526123
INFO:root:current mean train loss 2172.920950570124
INFO:root:current train perplexity5.552773952484131
INFO:root:current mean train loss 2171.5727986701013
INFO:root:current train perplexity5.5480265617370605
INFO:root:current mean train loss 2170.1792535393674
INFO:root:current train perplexity5.544589996337891
INFO:root:current mean train loss 2169.039684498521
INFO:root:current train perplexity5.540674686431885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.95s/it]
INFO:root:final mean train loss: 2168.2793611727516
INFO:root:final train perplexity: 5.53825569152832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.34s/it]
INFO:root:eval mean loss: 2099.022625862284
INFO:root:eval perplexity: 5.468042850494385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 2461.945473528923
INFO:root:eval perplexity: 7.572786808013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/8
  4%|â–         | 8/200 [1:13:31<29:21:22, 550.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2120.115059988839
INFO:root:current train perplexity5.395134925842285
INFO:root:current mean train loss 2123.2866274233215
INFO:root:current train perplexity5.399240493774414
INFO:root:current mean train loss 2120.0356128449134
INFO:root:current train perplexity5.392346382141113
INFO:root:current mean train loss 2127.364725323577
INFO:root:current train perplexity5.397609710693359
INFO:root:current mean train loss 2129.1285316204203
INFO:root:current train perplexity5.3835296630859375
INFO:root:current mean train loss 2135.439729209258
INFO:root:current train perplexity5.399777889251709
INFO:root:current mean train loss 2137.2305921659695
INFO:root:current train perplexity5.397377014160156
INFO:root:current mean train loss 2132.1351085844494
INFO:root:current train perplexity5.385526180267334
INFO:root:current mean train loss 2131.621322979042
INFO:root:current train perplexity5.3777923583984375
INFO:root:current mean train loss 2134.5053750104444
INFO:root:current train perplexity5.384284496307373
INFO:root:current mean train loss 2134.12641271324
INFO:root:current train perplexity5.384078025817871
INFO:root:current mean train loss 2135.8330114692317
INFO:root:current train perplexity5.386758804321289
INFO:root:current mean train loss 2133.5985355516195
INFO:root:current train perplexity5.379572868347168
INFO:root:current mean train loss 2132.272031542603
INFO:root:current train perplexity5.3784685134887695
INFO:root:current mean train loss 2134.461832653936
INFO:root:current train perplexity5.380115985870361
INFO:root:current mean train loss 2133.8981321254073
INFO:root:current train perplexity5.379401683807373
INFO:root:current mean train loss 2134.6292596192898
INFO:root:current train perplexity5.382352352142334
INFO:root:current mean train loss 2134.6259790250133
INFO:root:current train perplexity5.384138584136963
INFO:root:current mean train loss 2134.525608621956
INFO:root:current train perplexity5.384800434112549
INFO:root:current mean train loss 2132.974929596657
INFO:root:current train perplexity5.381982803344727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.33s/it]
INFO:root:final mean train loss: 2131.564146871947
INFO:root:final train perplexity: 5.380041122436523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it]
INFO:root:eval mean loss: 2067.8018837786735
INFO:root:eval perplexity: 5.331599235534668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it]
INFO:root:eval mean loss: 2456.6285603841147
INFO:root:eval perplexity: 7.539750099182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/9
  4%|â–         | 9/200 [1:22:39<29:09:15, 549.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2170.912393423227
INFO:root:current train perplexity5.405984401702881
INFO:root:current mean train loss 2140.3966658742806
INFO:root:current train perplexity5.353294849395752
INFO:root:current mean train loss 2131.8233269585503
INFO:root:current train perplexity5.333698749542236
INFO:root:current mean train loss 2120.45644309304
INFO:root:current train perplexity5.2926459312438965
INFO:root:current mean train loss 2114.222108013862
INFO:root:current train perplexity5.293736457824707
INFO:root:current mean train loss 2112.2779963396597
INFO:root:current train perplexity5.2782673835754395
INFO:root:current mean train loss 2112.6703371387316
INFO:root:current train perplexity5.281846523284912
INFO:root:current mean train loss 2110.0145240946017
INFO:root:current train perplexity5.2748703956604
INFO:root:current mean train loss 2107.383147190434
INFO:root:current train perplexity5.270303726196289
INFO:root:current mean train loss 2106.2414826465256
INFO:root:current train perplexity5.268397331237793
INFO:root:current mean train loss 2106.6688396033223
INFO:root:current train perplexity5.271416664123535
INFO:root:current mean train loss 2105.335269504123
INFO:root:current train perplexity5.266965866088867
INFO:root:current mean train loss 2104.364318067654
INFO:root:current train perplexity5.263765335083008
INFO:root:current mean train loss 2104.7277562970944
INFO:root:current train perplexity5.266737937927246
INFO:root:current mean train loss 2104.160018794793
INFO:root:current train perplexity5.26382303237915
INFO:root:current mean train loss 2104.340114239565
INFO:root:current train perplexity5.262228488922119
INFO:root:current mean train loss 2103.512997606476
INFO:root:current train perplexity5.260189533233643
INFO:root:current mean train loss 2102.62242920758
INFO:root:current train perplexity5.257817268371582
INFO:root:current mean train loss 2099.883796181071
INFO:root:current train perplexity5.25240421295166
INFO:root:current mean train loss 2101.0319234504072
INFO:root:current train perplexity5.249039649963379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.45s/it]
INFO:root:final mean train loss: 2100.243631198439
INFO:root:final train perplexity: 5.248650074005127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it]
INFO:root:eval mean loss: 2060.7097077065328
INFO:root:eval perplexity: 5.30108118057251
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 2471.824259007231
INFO:root:eval perplexity: 7.634556293487549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/10
  5%|â–Œ         | 10/200 [1:31:46<28:57:40, 548.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2085.8910000566125
INFO:root:current train perplexity5.155752658843994
INFO:root:current mean train loss 2081.283957216161
INFO:root:current train perplexity5.16539192199707
INFO:root:current mean train loss 2079.5446378005927
INFO:root:current train perplexity5.16632604598999
INFO:root:current mean train loss 2077.893915274602
INFO:root:current train perplexity5.168083190917969
INFO:root:current mean train loss 2080.0274775328157
INFO:root:current train perplexity5.1672844886779785
INFO:root:current mean train loss 2076.060391122721
INFO:root:current train perplexity5.161442279815674
INFO:root:current mean train loss 2075.700171226878
INFO:root:current train perplexity5.161346912384033
INFO:root:current mean train loss 2076.471502376006
INFO:root:current train perplexity5.157494068145752
INFO:root:current mean train loss 2075.878966933976
INFO:root:current train perplexity5.155235767364502
INFO:root:current mean train loss 2076.3240609026298
INFO:root:current train perplexity5.153389930725098
INFO:root:current mean train loss 2075.7056940719276
INFO:root:current train perplexity5.151496887207031
INFO:root:current mean train loss 2075.910815993571
INFO:root:current train perplexity5.150650978088379
INFO:root:current mean train loss 2073.988663621546
INFO:root:current train perplexity5.1439433097839355
INFO:root:current mean train loss 2074.852685118871
INFO:root:current train perplexity5.145869255065918
INFO:root:current mean train loss 2074.190997908601
INFO:root:current train perplexity5.145862579345703
INFO:root:current mean train loss 2073.584072679528
INFO:root:current train perplexity5.1401824951171875
INFO:root:current mean train loss 2073.0726655533817
INFO:root:current train perplexity5.137332439422607
INFO:root:current mean train loss 2072.1980402090917
INFO:root:current train perplexity5.1332268714904785
INFO:root:current mean train loss 2071.6355177061387
INFO:root:current train perplexity5.131518363952637
INFO:root:current mean train loss 2071.1494164803476
INFO:root:current train perplexity5.12820291519165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.76s/it]
INFO:root:final mean train loss: 2070.7621948734654
INFO:root:final train perplexity: 5.127908229827881
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it]
INFO:root:eval mean loss: 2024.536613302028
INFO:root:eval perplexity: 5.148126602172852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it]
INFO:root:eval mean loss: 2462.5063857491136
INFO:root:eval perplexity: 7.576279640197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/11
  6%|â–Œ         | 11/200 [1:40:53<28:46:47, 548.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2059.833542934684
INFO:root:current train perplexity4.9776530265808105
INFO:root:current mean train loss 2053.369894704511
INFO:root:current train perplexity5.006162166595459
INFO:root:current mean train loss 2053.618521737052
INFO:root:current train perplexity5.039728164672852
INFO:root:current mean train loss 2047.1833673190577
INFO:root:current train perplexity5.038115978240967
INFO:root:current mean train loss 2054.4911365901494
INFO:root:current train perplexity5.050745010375977
INFO:root:current mean train loss 2051.504622215297
INFO:root:current train perplexity5.0523681640625
INFO:root:current mean train loss 2050.6806578344226
INFO:root:current train perplexity5.047297477722168
INFO:root:current mean train loss 2050.089556434379
INFO:root:current train perplexity5.04543399810791
INFO:root:current mean train loss 2050.5820718941786
INFO:root:current train perplexity5.043433666229248
INFO:root:current mean train loss 2048.071587181478
INFO:root:current train perplexity5.038900375366211
INFO:root:current mean train loss 2048.8599454482837
INFO:root:current train perplexity5.037120342254639
INFO:root:current mean train loss 2048.861955665215
INFO:root:current train perplexity5.034229278564453
INFO:root:current mean train loss 2050.610494420836
INFO:root:current train perplexity5.034441947937012
INFO:root:current mean train loss 2048.4332441850142
INFO:root:current train perplexity5.030815601348877
INFO:root:current mean train loss 2048.9256966386797
INFO:root:current train perplexity5.032037258148193
INFO:root:current mean train loss 2047.1486385388753
INFO:root:current train perplexity5.026675224304199
INFO:root:current mean train loss 2046.1193920782594
INFO:root:current train perplexity5.0251970291137695
INFO:root:current mean train loss 2045.575491739681
INFO:root:current train perplexity5.023555755615234
INFO:root:current mean train loss 2045.4165180809046
INFO:root:current train perplexity5.024000644683838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.70s/it]
INFO:root:final mean train loss: 2044.060189928602
INFO:root:final train perplexity: 5.0209479331970215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.04s/it]
INFO:root:eval mean loss: 2005.2693832072805
INFO:root:eval perplexity: 5.068465232849121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 2471.333898233184
INFO:root:eval perplexity: 7.631478786468506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/12
  6%|â–Œ         | 12/200 [1:50:03<28:39:20, 548.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2120.4698079427085
INFO:root:current train perplexity5.144097328186035
INFO:root:current mean train loss 2021.1084908790958
INFO:root:current train perplexity4.890281677246094
INFO:root:current mean train loss 2024.9454868861608
INFO:root:current train perplexity4.9184489250183105
INFO:root:current mean train loss 2020.6130858569256
INFO:root:current train perplexity4.908051013946533
INFO:root:current mean train loss 2027.486800352338
INFO:root:current train perplexity4.941211223602295
INFO:root:current mean train loss 2023.9844929446756
INFO:root:current train perplexity4.927513599395752
INFO:root:current mean train loss 2025.57372318097
INFO:root:current train perplexity4.935867786407471
INFO:root:current mean train loss 2024.3445232277404
INFO:root:current train perplexity4.927321910858154
INFO:root:current mean train loss 2025.6127716862547
INFO:root:current train perplexity4.927837371826172
INFO:root:current mean train loss 2026.2391042445322
INFO:root:current train perplexity4.9324750900268555
INFO:root:current mean train loss 2024.5313311773664
INFO:root:current train perplexity4.927042007446289
INFO:root:current mean train loss 2024.0108062661138
INFO:root:current train perplexity4.927018165588379
INFO:root:current mean train loss 2025.594730925778
INFO:root:current train perplexity4.929015636444092
INFO:root:current mean train loss 2022.9092242811062
INFO:root:current train perplexity4.928661346435547
INFO:root:current mean train loss 2022.0892056433202
INFO:root:current train perplexity4.9296722412109375
INFO:root:current mean train loss 2021.171419611948
INFO:root:current train perplexity4.928080081939697
INFO:root:current mean train loss 2019.9113459596022
INFO:root:current train perplexity4.923793315887451
INFO:root:current mean train loss 2020.0171031761506
INFO:root:current train perplexity4.924496650695801
INFO:root:current mean train loss 2019.5388682572232
INFO:root:current train perplexity4.92150354385376
INFO:root:current mean train loss 2019.4428645508326
INFO:root:current train perplexity4.918590545654297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.72s/it]
INFO:root:final mean train loss: 2018.1043520190171
INFO:root:final train perplexity: 4.91911506652832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.52s/it]
INFO:root:eval mean loss: 1984.492928579344
INFO:root:eval perplexity: 4.983945846557617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.69s/it]
INFO:root:eval mean loss: 2477.9694019074136
INFO:root:eval perplexity: 7.6732354164123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/13
  6%|â–‹         | 13/200 [1:59:02<28:21:26, 545.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1973.192822265625
INFO:root:current train perplexity4.806112766265869
INFO:root:current mean train loss 2006.1100413004558
INFO:root:current train perplexity4.858017921447754
INFO:root:current mean train loss 2004.002596768466
INFO:root:current train perplexity4.848268985748291
INFO:root:current mean train loss 1998.7720989227296
INFO:root:current train perplexity4.845759391784668
INFO:root:current mean train loss 2000.4623895554316
INFO:root:current train perplexity4.841532230377197
INFO:root:current mean train loss 1998.119863656851
INFO:root:current train perplexity4.844123840332031
INFO:root:current mean train loss 1998.3579830046624
INFO:root:current train perplexity4.840787410736084
INFO:root:current mean train loss 1999.4486999511719
INFO:root:current train perplexity4.849878311157227
INFO:root:current mean train loss 1999.5320808224562
INFO:root:current train perplexity4.849631309509277
INFO:root:current mean train loss 1998.5128833273184
INFO:root:current train perplexity4.847041130065918
INFO:root:current mean train loss 1999.3820594937195
INFO:root:current train perplexity4.843163013458252
INFO:root:current mean train loss 1998.6158612932477
INFO:root:current train perplexity4.840011119842529
INFO:root:current mean train loss 1996.1406923387872
INFO:root:current train perplexity4.835668087005615
INFO:root:current mean train loss 1997.0145849979285
INFO:root:current train perplexity4.836971759796143
INFO:root:current mean train loss 1999.0445554921325
INFO:root:current train perplexity4.8407206535339355
INFO:root:current mean train loss 1999.1874070820056
INFO:root:current train perplexity4.8405070304870605
INFO:root:current mean train loss 1999.4577814549575
INFO:root:current train perplexity4.837449073791504
INFO:root:current mean train loss 1998.0230135895486
INFO:root:current train perplexity4.835066318511963
INFO:root:current mean train loss 1996.5867206950763
INFO:root:current train perplexity4.831972122192383
INFO:root:current mean train loss 1995.9830027898154
INFO:root:current train perplexity4.832531929016113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.35s/it]
INFO:root:final mean train loss: 1994.9831964643809
INFO:root:final train perplexity: 4.830144882202148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it]
INFO:root:eval mean loss: 1970.2744465280086
INFO:root:eval perplexity: 4.926918029785156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 2490.506051137938
INFO:root:eval perplexity: 7.752753257751465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/14
  7%|â–‹         | 14/200 [2:07:57<28:02:06, 542.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1954.5201317039696
INFO:root:current train perplexity4.76945161819458
INFO:root:current mean train loss 1958.0526310161952
INFO:root:current train perplexity4.756111145019531
INFO:root:current mean train loss 1966.8635681409876
INFO:root:current train perplexity4.7591938972473145
INFO:root:current mean train loss 1964.7954061717592
INFO:root:current train perplexity4.751892566680908
INFO:root:current mean train loss 1968.343508373409
INFO:root:current train perplexity4.7456488609313965
INFO:root:current mean train loss 1970.161030064304
INFO:root:current train perplexity4.74582576751709
INFO:root:current mean train loss 1967.8247208288362
INFO:root:current train perplexity4.737016201019287
INFO:root:current mean train loss 1971.6136304009074
INFO:root:current train perplexity4.743702411651611
INFO:root:current mean train loss 1972.4387527885117
INFO:root:current train perplexity4.746185779571533
INFO:root:current mean train loss 1970.6614409195322
INFO:root:current train perplexity4.746527194976807
INFO:root:current mean train loss 1973.305404618943
INFO:root:current train perplexity4.752521514892578
INFO:root:current mean train loss 1972.7033633430904
INFO:root:current train perplexity4.7497239112854
INFO:root:current mean train loss 1972.7342348707812
INFO:root:current train perplexity4.750211715698242
INFO:root:current mean train loss 1973.4605062822843
INFO:root:current train perplexity4.750463008880615
INFO:root:current mean train loss 1974.454493087949
INFO:root:current train perplexity4.752590656280518
INFO:root:current mean train loss 1974.5770995934909
INFO:root:current train perplexity4.752423286437988
INFO:root:current mean train loss 1975.5156872655534
INFO:root:current train perplexity4.753749847412109
INFO:root:current mean train loss 1974.2768061346342
INFO:root:current train perplexity4.75243616104126
INFO:root:current mean train loss 1974.6505855919554
INFO:root:current train perplexity4.755517959594727
INFO:root:current mean train loss 1974.9493336359988
INFO:root:current train perplexity4.754096984863281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.04s/it]
INFO:root:final mean train loss: 1975.212772125075
INFO:root:final train perplexity: 4.755344867706299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it]
INFO:root:eval mean loss: 1955.6990473321143
INFO:root:eval perplexity: 4.869137287139893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it]
INFO:root:eval mean loss: 2487.7658029109875
INFO:root:eval perplexity: 7.735300064086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/15
  8%|â–Š         | 15/200 [2:17:01<27:54:06, 542.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1963.4028455946182
INFO:root:current train perplexity4.676373481750488
INFO:root:current mean train loss 1964.0137772993608
INFO:root:current train perplexity4.692556381225586
INFO:root:current mean train loss 1962.1846548966535
INFO:root:current train perplexity4.685855388641357
INFO:root:current mean train loss 1958.6293693585585
INFO:root:current train perplexity4.695301532745361
INFO:root:current mean train loss 1952.447247341341
INFO:root:current train perplexity4.687186241149902
INFO:root:current mean train loss 1953.9992367300315
INFO:root:current train perplexity4.687056064605713
INFO:root:current mean train loss 1951.9531815555117
INFO:root:current train perplexity4.683345794677734
INFO:root:current mean train loss 1953.7931638358443
INFO:root:current train perplexity4.685903549194336
INFO:root:current mean train loss 1956.320919421015
INFO:root:current train perplexity4.687074184417725
INFO:root:current mean train loss 1954.1379725938073
INFO:root:current train perplexity4.686140060424805
INFO:root:current mean train loss 1955.1421361702444
INFO:root:current train perplexity4.68453311920166
INFO:root:current mean train loss 1955.246606678029
INFO:root:current train perplexity4.682432651519775
INFO:root:current mean train loss 1955.4322832950184
INFO:root:current train perplexity4.681831359863281
INFO:root:current mean train loss 1954.9331659629743
INFO:root:current train perplexity4.685268878936768
INFO:root:current mean train loss 1955.3658586630631
INFO:root:current train perplexity4.685691833496094
INFO:root:current mean train loss 1955.9020766720962
INFO:root:current train perplexity4.684061050415039
INFO:root:current mean train loss 1956.3195502616763
INFO:root:current train perplexity4.681440353393555
INFO:root:current mean train loss 1955.1537014168507
INFO:root:current train perplexity4.681196212768555
INFO:root:current mean train loss 1955.440425012747
INFO:root:current train perplexity4.683475017547607
INFO:root:current mean train loss 1956.493767542141
INFO:root:current train perplexity4.68287467956543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.21s/it]
INFO:root:final mean train loss: 1955.6791928474554
INFO:root:final train perplexity: 4.682579040527344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it]
INFO:root:eval mean loss: 1944.1501317666778
INFO:root:eval perplexity: 4.823834419250488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 2501.5647431502107
INFO:root:eval perplexity: 7.8235764503479
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/16
  8%|â–Š         | 16/200 [2:26:11<27:51:56, 545.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1938.3367386938821
INFO:root:current train perplexity4.671182632446289
INFO:root:current mean train loss 1945.1555525573374
INFO:root:current train perplexity4.639734268188477
INFO:root:current mean train loss 1946.2810220753574
INFO:root:current train perplexity4.637691020965576
INFO:root:current mean train loss 1941.960359064395
INFO:root:current train perplexity4.630951404571533
INFO:root:current mean train loss 1943.8443730510219
INFO:root:current train perplexity4.6354570388793945
INFO:root:current mean train loss 1943.479916547518
INFO:root:current train perplexity4.628058433532715
INFO:root:current mean train loss 1942.1496920407974
INFO:root:current train perplexity4.624551296234131
INFO:root:current mean train loss 1942.2221057461393
INFO:root:current train perplexity4.625203609466553
INFO:root:current mean train loss 1941.0592123703896
INFO:root:current train perplexity4.627536296844482
INFO:root:current mean train loss 1939.3941581246781
INFO:root:current train perplexity4.6206583976745605
INFO:root:current mean train loss 1940.4231367351629
INFO:root:current train perplexity4.625547409057617
INFO:root:current mean train loss 1941.1776944493556
INFO:root:current train perplexity4.6238627433776855
INFO:root:current mean train loss 1940.9683000398002
INFO:root:current train perplexity4.6232500076293945
INFO:root:current mean train loss 1941.3611090929294
INFO:root:current train perplexity4.624029159545898
INFO:root:current mean train loss 1940.1376007100823
INFO:root:current train perplexity4.625085353851318
INFO:root:current mean train loss 1939.459267133668
INFO:root:current train perplexity4.622615337371826
INFO:root:current mean train loss 1940.5922197744849
INFO:root:current train perplexity4.62526798248291
INFO:root:current mean train loss 1940.6398598376402
INFO:root:current train perplexity4.626417636871338
INFO:root:current mean train loss 1941.4950482252764
INFO:root:current train perplexity4.627810955047607
INFO:root:current mean train loss 1941.3633878370156
INFO:root:current train perplexity4.627567291259766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.72s/it]
INFO:root:final mean train loss: 1940.6611703939047
INFO:root:final train perplexity: 4.627392292022705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it]
INFO:root:eval mean loss: 1934.430385291999
INFO:root:eval perplexity: 4.786034107208252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it]
INFO:root:eval mean loss: 2497.1455779379985
INFO:root:eval perplexity: 7.795195579528809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/17
  8%|â–Š         | 17/200 [2:35:15<27:41:11, 544.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1940.1771642511542
INFO:root:current train perplexity4.589254379272461
INFO:root:current mean train loss 1940.040539031333
INFO:root:current train perplexity4.604766368865967
INFO:root:current mean train loss 1932.712826622857
INFO:root:current train perplexity4.5842604637146
INFO:root:current mean train loss 1935.9912949394934
INFO:root:current train perplexity4.594090938568115
INFO:root:current mean train loss 1934.9566585353164
INFO:root:current train perplexity4.590600967407227
INFO:root:current mean train loss 1933.7764894654151
INFO:root:current train perplexity4.586352348327637
INFO:root:current mean train loss 1932.6666396385015
INFO:root:current train perplexity4.593792915344238
INFO:root:current mean train loss 1932.8198370764098
INFO:root:current train perplexity4.5919270515441895
INFO:root:current mean train loss 1932.9619389439488
INFO:root:current train perplexity4.590462684631348
INFO:root:current mean train loss 1932.8249944154068
INFO:root:current train perplexity4.587697982788086
INFO:root:current mean train loss 1932.841983234181
INFO:root:current train perplexity4.589271545410156
INFO:root:current mean train loss 1935.122414431588
INFO:root:current train perplexity4.593494415283203
INFO:root:current mean train loss 1933.9588297020575
INFO:root:current train perplexity4.5918145179748535
INFO:root:current mean train loss 1932.537106472752
INFO:root:current train perplexity4.589897632598877
INFO:root:current mean train loss 1933.1920677923388
INFO:root:current train perplexity4.592430591583252
INFO:root:current mean train loss 1931.6425379986126
INFO:root:current train perplexity4.590451240539551
INFO:root:current mean train loss 1930.3061985540164
INFO:root:current train perplexity4.586949825286865
INFO:root:current mean train loss 1930.515385774958
INFO:root:current train perplexity4.590001583099365
INFO:root:current mean train loss 1931.255875345004
INFO:root:current train perplexity4.590775966644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.12s/it]
INFO:root:final mean train loss: 1930.9046612391853
INFO:root:final train perplexity: 4.591890335083008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.84s/it]
INFO:root:eval mean loss: 1927.7499658029976
INFO:root:eval perplexity: 4.760225296020508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it]
INFO:root:eval mean loss: 2501.1030143575467
INFO:root:eval perplexity: 7.820605278015137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/18
  9%|â–‰         | 18/200 [2:44:20<27:32:47, 544.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1962.9674560546875
INFO:root:current train perplexity4.80000638961792
INFO:root:current mean train loss 1938.840785435268
INFO:root:current train perplexity4.6135993003845215
INFO:root:current mean train loss 1927.197041134718
INFO:root:current train perplexity4.576159954071045
INFO:root:current mean train loss 1926.1601110239499
INFO:root:current train perplexity4.566823959350586
INFO:root:current mean train loss 1916.8371639298805
INFO:root:current train perplexity4.554265975952148
INFO:root:current mean train loss 1916.3783021832458
INFO:root:current train perplexity4.547940731048584
INFO:root:current mean train loss 1916.8907848011363
INFO:root:current train perplexity4.550159931182861
INFO:root:current mean train loss 1920.5348191281582
INFO:root:current train perplexity4.553213596343994
INFO:root:current mean train loss 1921.64395623059
INFO:root:current train perplexity4.559739589691162
INFO:root:current mean train loss 1925.3404236177055
INFO:root:current train perplexity4.563397407531738
INFO:root:current mean train loss 1924.568358403296
INFO:root:current train perplexity4.558380603790283
INFO:root:current mean train loss 1923.3149257193863
INFO:root:current train perplexity4.557341575622559
INFO:root:current mean train loss 1924.500886402684
INFO:root:current train perplexity4.561347007751465
INFO:root:current mean train loss 1924.8697563083692
INFO:root:current train perplexity4.56521463394165
INFO:root:current mean train loss 1925.2208509126167
INFO:root:current train perplexity4.564736366271973
INFO:root:current mean train loss 1926.025294509837
INFO:root:current train perplexity4.5684990882873535
INFO:root:current mean train loss 1925.5538505007544
INFO:root:current train perplexity4.568594932556152
INFO:root:current mean train loss 1925.8148320799348
INFO:root:current train perplexity4.571606636047363
INFO:root:current mean train loss 1926.266549150039
INFO:root:current train perplexity4.572299003601074
INFO:root:current mean train loss 1926.4213155270875
INFO:root:current train perplexity4.5748395919799805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.08s/it]
INFO:root:final mean train loss: 1926.4890020065577
INFO:root:final train perplexity: 4.575910568237305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it]
INFO:root:eval mean loss: 1924.301706733433
INFO:root:eval perplexity: 4.746957778930664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.56s/it]
INFO:root:eval mean loss: 2486.901303555103
INFO:root:eval perplexity: 7.729804039001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/19
 10%|â–‰         | 19/200 [2:53:22<27:21:31, 544.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1926.280106977983
INFO:root:current train perplexity4.607020854949951
INFO:root:current mean train loss 1914.8550775246542
INFO:root:current train perplexity4.55593729019165
INFO:root:current mean train loss 1918.4451052004154
INFO:root:current train perplexity4.5464982986450195
INFO:root:current mean train loss 1923.0956371615391
INFO:root:current train perplexity4.540221214294434
INFO:root:current mean train loss 1923.9632999365929
INFO:root:current train perplexity4.557887077331543
INFO:root:current mean train loss 1923.5708372620331
INFO:root:current train perplexity4.567073822021484
INFO:root:current mean train loss 1925.7033251796122
INFO:root:current train perplexity4.571547031402588
INFO:root:current mean train loss 1922.510561956263
INFO:root:current train perplexity4.569742202758789
INFO:root:current mean train loss 1923.1913654113919
INFO:root:current train perplexity4.574241638183594
INFO:root:current mean train loss 1921.1114638322347
INFO:root:current train perplexity4.571717262268066
INFO:root:current mean train loss 1922.718500245574
INFO:root:current train perplexity4.574717044830322
INFO:root:current mean train loss 1923.4640721611797
INFO:root:current train perplexity4.573636531829834
INFO:root:current mean train loss 1924.7287892343174
INFO:root:current train perplexity4.575077056884766
INFO:root:current mean train loss 1924.7525691091564
INFO:root:current train perplexity4.574889659881592
INFO:root:current mean train loss 1924.9865962161293
INFO:root:current train perplexity4.57520866394043
INFO:root:current mean train loss 1925.7270877552407
INFO:root:current train perplexity4.575031280517578
INFO:root:current mean train loss 1926.9564480669842
INFO:root:current train perplexity4.575555324554443
INFO:root:current mean train loss 1927.4781113468396
INFO:root:current train perplexity4.577061653137207
INFO:root:current mean train loss 1927.5025894047792
INFO:root:current train perplexity4.576436996459961
INFO:root:current mean train loss 1927.2549596621764
INFO:root:current train perplexity4.576396465301514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.90s/it]
INFO:root:final mean train loss: 1926.7023830365727
INFO:root:final train perplexity: 4.576682090759277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it]
INFO:root:eval mean loss: 1925.2233930006096
INFO:root:eval perplexity: 4.75050163269043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.47s/it]
INFO:root:eval mean loss: 2482.2329677284188
INFO:root:eval perplexity: 7.700186252593994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/20
 10%|â–ˆ         | 20/200 [3:02:29<27:14:42, 544.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1941.9977150941506
INFO:root:current train perplexity4.532812118530273
INFO:root:current mean train loss 1913.7229724033273
INFO:root:current train perplexity4.499332904815674
INFO:root:current mean train loss 1915.1282054949006
INFO:root:current train perplexity4.518179416656494
INFO:root:current mean train loss 1915.3609824391592
INFO:root:current train perplexity4.5244574546813965
INFO:root:current mean train loss 1914.2769650261603
INFO:root:current train perplexity4.532028675079346
INFO:root:current mean train loss 1917.2898495024785
INFO:root:current train perplexity4.535837173461914
INFO:root:current mean train loss 1916.671707654783
INFO:root:current train perplexity4.537275314331055
INFO:root:current mean train loss 1918.6479269190313
INFO:root:current train perplexity4.543633937835693
INFO:root:current mean train loss 1917.497104940312
INFO:root:current train perplexity4.542501926422119
INFO:root:current mean train loss 1916.978918366031
INFO:root:current train perplexity4.545019626617432
INFO:root:current mean train loss 1918.8979714240331
INFO:root:current train perplexity4.548126220703125
INFO:root:current mean train loss 1920.8785751918829
INFO:root:current train perplexity4.551258087158203
INFO:root:current mean train loss 1921.2551720767756
INFO:root:current train perplexity4.556136608123779
INFO:root:current mean train loss 1921.4148945655281
INFO:root:current train perplexity4.556479454040527
INFO:root:current mean train loss 1922.1820736819461
INFO:root:current train perplexity4.558801651000977
INFO:root:current mean train loss 1922.2999585643072
INFO:root:current train perplexity4.560057163238525
INFO:root:current mean train loss 1923.6260154402933
INFO:root:current train perplexity4.563772201538086
INFO:root:current mean train loss 1924.2408307576193
INFO:root:current train perplexity4.566899299621582
INFO:root:current mean train loss 1925.2945336263551
INFO:root:current train perplexity4.569241046905518
INFO:root:current mean train loss 1925.5125578181407
INFO:root:current train perplexity4.571352005004883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.40s/it]
INFO:root:final mean train loss: 1925.6741610636209
INFO:root:final train perplexity: 4.572968006134033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.75s/it]
INFO:root:eval mean loss: 1926.1938164893618
INFO:root:eval perplexity: 4.754232406616211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it]
INFO:root:eval mean loss: 2476.4349222386136
INFO:root:eval perplexity: 7.663558006286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/21
 10%|â–ˆ         | 21/200 [3:11:38<27:08:56, 546.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1915.843756539481
INFO:root:current train perplexity4.543266296386719
INFO:root:current mean train loss 1907.9671849959936
INFO:root:current train perplexity4.50584602355957
INFO:root:current mean train loss 1909.2305192947388
INFO:root:current train perplexity4.517043113708496
INFO:root:current mean train loss 1909.3170697501537
INFO:root:current train perplexity4.522235870361328
INFO:root:current mean train loss 1908.8253864489104
INFO:root:current train perplexity4.516937255859375
INFO:root:current mean train loss 1910.3192817084223
INFO:root:current train perplexity4.523345470428467
INFO:root:current mean train loss 1912.9095040298089
INFO:root:current train perplexity4.530525207519531
INFO:root:current mean train loss 1915.9619700921276
INFO:root:current train perplexity4.533682823181152
INFO:root:current mean train loss 1916.7128157571096
INFO:root:current train perplexity4.538020133972168
INFO:root:current mean train loss 1917.5937954571457
INFO:root:current train perplexity4.5415940284729
INFO:root:current mean train loss 1918.6977127537582
INFO:root:current train perplexity4.542637348175049
INFO:root:current mean train loss 1918.6732245316555
INFO:root:current train perplexity4.545185089111328
INFO:root:current mean train loss 1919.0371308539325
INFO:root:current train perplexity4.545556545257568
INFO:root:current mean train loss 1918.9418095501476
INFO:root:current train perplexity4.550018787384033
INFO:root:current mean train loss 1920.1744683234247
INFO:root:current train perplexity4.554096698760986
INFO:root:current mean train loss 1919.651352517096
INFO:root:current train perplexity4.553061008453369
INFO:root:current mean train loss 1920.4247392295063
INFO:root:current train perplexity4.5536885261535645
INFO:root:current mean train loss 1922.108099587686
INFO:root:current train perplexity4.559418201446533
INFO:root:current mean train loss 1922.9189151895457
INFO:root:current train perplexity4.56083345413208
INFO:root:current mean train loss 1922.5911077019628
INFO:root:current train perplexity4.559943199157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.63s/it]
INFO:root:final mean train loss: 1922.6262283979254
INFO:root:final train perplexity: 4.561979293823242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it]
INFO:root:eval mean loss: 1926.7323954697197
INFO:root:eval perplexity: 4.7563066482543945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it]
INFO:root:eval mean loss: 2466.5978696566103
INFO:root:eval perplexity: 7.601813316345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/22
 11%|â–ˆ         | 22/200 [3:20:41<26:57:26, 545.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1922.5890193573416
INFO:root:current train perplexity4.590590476989746
INFO:root:current mean train loss 1924.9714150842215
INFO:root:current train perplexity4.576199054718018
INFO:root:current mean train loss 1921.3397172082475
INFO:root:current train perplexity4.5464887619018555
INFO:root:current mean train loss 1918.9759145128185
INFO:root:current train perplexity4.541250228881836
INFO:root:current mean train loss 1919.2030452542779
INFO:root:current train perplexity4.548624515533447
INFO:root:current mean train loss 1916.9943915828153
INFO:root:current train perplexity4.542507171630859
INFO:root:current mean train loss 1917.7989251645502
INFO:root:current train perplexity4.534535884857178
INFO:root:current mean train loss 1915.0787006096882
INFO:root:current train perplexity4.528070449829102
INFO:root:current mean train loss 1916.3540292152152
INFO:root:current train perplexity4.531010627746582
INFO:root:current mean train loss 1913.8792380855361
INFO:root:current train perplexity4.527047634124756
INFO:root:current mean train loss 1916.3436019911683
INFO:root:current train perplexity4.532779216766357
INFO:root:current mean train loss 1917.6602812341819
INFO:root:current train perplexity4.533636093139648
INFO:root:current mean train loss 1919.9036474954585
INFO:root:current train perplexity4.539601802825928
INFO:root:current mean train loss 1919.8821794769665
INFO:root:current train perplexity4.54097318649292
INFO:root:current mean train loss 1920.1140720136943
INFO:root:current train perplexity4.5400590896606445
INFO:root:current mean train loss 1919.5758001542138
INFO:root:current train perplexity4.541547775268555
INFO:root:current mean train loss 1919.200380497469
INFO:root:current train perplexity4.544472694396973
INFO:root:current mean train loss 1919.1020312968178
INFO:root:current train perplexity4.546473026275635
INFO:root:current mean train loss 1920.0544522881698
INFO:root:current train perplexity4.5498809814453125
INFO:root:current mean train loss 1919.8407545442576
INFO:root:current train perplexity4.549419403076172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.16s/it]
INFO:root:final mean train loss: 1919.1705837201664
INFO:root:final train perplexity: 4.549550533294678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it]
INFO:root:eval mean loss: 1928.406221863226
INFO:root:eval perplexity: 4.762754440307617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2474.101285460993
INFO:root:eval perplexity: 7.648867607116699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/23
 12%|â–ˆâ–        | 23/200 [3:29:44<26:46:16, 544.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1886.450062391493
INFO:root:current train perplexity4.512823104858398
INFO:root:current mean train loss 1901.0949122378702
INFO:root:current train perplexity4.514329433441162
INFO:root:current mean train loss 1905.585982539736
INFO:root:current train perplexity4.510576248168945
INFO:root:current mean train loss 1907.983744929387
INFO:root:current train perplexity4.511980056762695
INFO:root:current mean train loss 1910.5029311822386
INFO:root:current train perplexity4.516268730163574
INFO:root:current mean train loss 1908.5549250198624
INFO:root:current train perplexity4.515496730804443
INFO:root:current mean train loss 1912.0122126924819
INFO:root:current train perplexity4.517777919769287
INFO:root:current mean train loss 1913.6764566542226
INFO:root:current train perplexity4.520358085632324
INFO:root:current mean train loss 1912.19026537263
INFO:root:current train perplexity4.518214225769043
INFO:root:current mean train loss 1912.1210849954625
INFO:root:current train perplexity4.515972137451172
INFO:root:current mean train loss 1912.0089417063862
INFO:root:current train perplexity4.5132269859313965
INFO:root:current mean train loss 1914.0527347853204
INFO:root:current train perplexity4.517303943634033
INFO:root:current mean train loss 1914.1714612857315
INFO:root:current train perplexity4.518237590789795
INFO:root:current mean train loss 1914.522536463017
INFO:root:current train perplexity4.523254871368408
INFO:root:current mean train loss 1914.3641857172818
INFO:root:current train perplexity4.521698474884033
INFO:root:current mean train loss 1913.7121682604904
INFO:root:current train perplexity4.523375511169434
INFO:root:current mean train loss 1914.366582493528
INFO:root:current train perplexity4.523251056671143
INFO:root:current mean train loss 1913.2928308582839
INFO:root:current train perplexity4.52372407913208
INFO:root:current mean train loss 1913.9484147006242
INFO:root:current train perplexity4.524148464202881

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.68s/it]
INFO:root:final mean train loss: 1912.513949965084
INFO:root:final train perplexity: 4.525706768035889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.79s/it]
INFO:root:eval mean loss: 1930.6747873725622
INFO:root:eval perplexity: 4.771507740020752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it]
INFO:root:eval mean loss: 2479.715218185533
INFO:root:eval perplexity: 7.68425989151001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/24
 12%|â–ˆâ–        | 24/200 [3:38:51<26:39:50, 545.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1867.6625279017858
INFO:root:current train perplexity4.372115612030029
INFO:root:current mean train loss 1895.6091696480723
INFO:root:current train perplexity4.514334678649902
INFO:root:current mean train loss 1901.9252021531552
INFO:root:current train perplexity4.490074157714844
INFO:root:current mean train loss 1904.7359973025245
INFO:root:current train perplexity4.484000205993652
INFO:root:current mean train loss 1902.454537656442
INFO:root:current train perplexity4.481537342071533
INFO:root:current mean train loss 1906.5493638379098
INFO:root:current train perplexity4.494948863983154
INFO:root:current mean train loss 1907.6767714875928
INFO:root:current train perplexity4.497307300567627
INFO:root:current mean train loss 1907.0060444660537
INFO:root:current train perplexity4.4916887283325195
INFO:root:current mean train loss 1907.6078172799528
INFO:root:current train perplexity4.493199348449707
INFO:root:current mean train loss 1907.4514419908955
INFO:root:current train perplexity4.498220920562744
INFO:root:current mean train loss 1905.6522757445925
INFO:root:current train perplexity4.495500087738037
INFO:root:current mean train loss 1908.2610897625902
INFO:root:current train perplexity4.499267578125
INFO:root:current mean train loss 1908.1468458325783
INFO:root:current train perplexity4.498364448547363
INFO:root:current mean train loss 1909.0464875878681
INFO:root:current train perplexity4.502345561981201
INFO:root:current mean train loss 1908.1392282622878
INFO:root:current train perplexity4.499243259429932
INFO:root:current mean train loss 1906.6415116500602
INFO:root:current train perplexity4.4975199699401855
INFO:root:current mean train loss 1905.8254487204417
INFO:root:current train perplexity4.496938705444336
INFO:root:current mean train loss 1905.86339430985
INFO:root:current train perplexity4.498551845550537
INFO:root:current mean train loss 1906.3632014010186
INFO:root:current train perplexity4.5000901222229
INFO:root:current mean train loss 1905.432182484043
INFO:root:current train perplexity4.50042724609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.30s/it]
INFO:root:final mean train loss: 1905.3158982085026
INFO:root:final train perplexity: 4.500062465667725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.25s/it]
INFO:root:eval mean loss: 1930.243968774241
INFO:root:eval perplexity: 4.7698445320129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.83s/it]
INFO:root:eval mean loss: 2487.3591602947695
INFO:root:eval perplexity: 7.732714653015137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/25
 12%|â–ˆâ–Ž        | 25/200 [3:48:02<26:35:31, 547.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1899.4768829345703
INFO:root:current train perplexity4.510129451751709
INFO:root:current mean train loss 1893.238037109375
INFO:root:current train perplexity4.441635608673096
INFO:root:current mean train loss 1896.631393977574
INFO:root:current train perplexity4.451296329498291
INFO:root:current mean train loss 1901.2182726447966
INFO:root:current train perplexity4.464140892028809
INFO:root:current mean train loss 1900.398362645563
INFO:root:current train perplexity4.46259069442749
INFO:root:current mean train loss 1896.4151115126283
INFO:root:current train perplexity4.454614639282227
INFO:root:current mean train loss 1897.9296428973857
INFO:root:current train perplexity4.462675094604492
INFO:root:current mean train loss 1897.699404890366
INFO:root:current train perplexity4.462645053863525
INFO:root:current mean train loss 1897.1079104525372
INFO:root:current train perplexity4.460969924926758
INFO:root:current mean train loss 1894.9807904396223
INFO:root:current train perplexity4.461672782897949
INFO:root:current mean train loss 1895.7925503253937
INFO:root:current train perplexity4.463149070739746
INFO:root:current mean train loss 1896.6831047085257
INFO:root:current train perplexity4.469396591186523
INFO:root:current mean train loss 1896.5039105384178
INFO:root:current train perplexity4.466671466827393
INFO:root:current mean train loss 1897.3477288099214
INFO:root:current train perplexity4.467398643493652
INFO:root:current mean train loss 1896.855680315682
INFO:root:current train perplexity4.4648003578186035
INFO:root:current mean train loss 1897.2271573925268
INFO:root:current train perplexity4.466393947601318
INFO:root:current mean train loss 1897.7220318423117
INFO:root:current train perplexity4.4664154052734375
INFO:root:current mean train loss 1897.277304523229
INFO:root:current train perplexity4.46590518951416
INFO:root:current mean train loss 1897.0681545190644
INFO:root:current train perplexity4.466099739074707
INFO:root:current mean train loss 1896.9875846117302
INFO:root:current train perplexity4.468640327453613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.85s/it]
INFO:root:final mean train loss: 1896.526876737178
INFO:root:final train perplexity: 4.468949317932129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.45s/it]
INFO:root:eval mean loss: 1925.6145162379487
INFO:root:eval perplexity: 4.752004146575928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 2487.287753057818
INFO:root:eval perplexity: 7.7322611808776855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/26
 13%|â–ˆâ–Ž        | 26/200 [3:57:14<26:30:53, 548.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.387656607279
INFO:root:current train perplexity4.401599407196045
INFO:root:current mean train loss 1872.0437998670213
INFO:root:current train perplexity4.435049533843994
INFO:root:current mean train loss 1872.228734439834
INFO:root:current train perplexity4.427698612213135
INFO:root:current mean train loss 1882.8231795414451
INFO:root:current train perplexity4.43075704574585
INFO:root:current mean train loss 1881.0629899420705
INFO:root:current train perplexity4.430660247802734
INFO:root:current mean train loss 1879.1850813832168
INFO:root:current train perplexity4.428657054901123
INFO:root:current mean train loss 1878.846299384202
INFO:root:current train perplexity4.427323341369629
INFO:root:current mean train loss 1880.2358283121416
INFO:root:current train perplexity4.427471160888672
INFO:root:current mean train loss 1880.7095514721593
INFO:root:current train perplexity4.424401760101318
INFO:root:current mean train loss 1882.1170642621712
INFO:root:current train perplexity4.427199363708496
INFO:root:current mean train loss 1883.9090813042221
INFO:root:current train perplexity4.429039001464844
INFO:root:current mean train loss 1884.7600633652978
INFO:root:current train perplexity4.429110527038574
INFO:root:current mean train loss 1884.9656544699965
INFO:root:current train perplexity4.429633140563965
INFO:root:current mean train loss 1885.0320223837446
INFO:root:current train perplexity4.427998065948486
INFO:root:current mean train loss 1886.8887030490978
INFO:root:current train perplexity4.433933734893799
INFO:root:current mean train loss 1888.390388147155
INFO:root:current train perplexity4.437812328338623
INFO:root:current mean train loss 1888.4957984305968
INFO:root:current train perplexity4.439434051513672
INFO:root:current mean train loss 1888.6293827519205
INFO:root:current train perplexity4.436769962310791
INFO:root:current mean train loss 1887.9404928776182
INFO:root:current train perplexity4.435315132141113
INFO:root:current mean train loss 1886.792355505478
INFO:root:current train perplexity4.43436861038208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.58s/it]
INFO:root:final mean train loss: 1886.6552062772828
INFO:root:final train perplexity: 4.434257507324219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.76s/it]
INFO:root:eval mean loss: 1923.7812222960993
INFO:root:eval perplexity: 4.744958877563477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2493.0330879806625
INFO:root:eval perplexity: 7.76887845993042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/27
 14%|â–ˆâ–Ž        | 27/200 [4:06:21<26:20:06, 548.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1835.5537319841055
INFO:root:current train perplexity4.3532304763793945
INFO:root:current mean train loss 1856.3105499653877
INFO:root:current train perplexity4.344621181488037
INFO:root:current mean train loss 1868.4933892774952
INFO:root:current train perplexity4.361944198608398
INFO:root:current mean train loss 1871.0415127716917
INFO:root:current train perplexity4.364954948425293
INFO:root:current mean train loss 1870.326071660071
INFO:root:current train perplexity4.368086814880371
INFO:root:current mean train loss 1875.659413546217
INFO:root:current train perplexity4.376910209655762
INFO:root:current mean train loss 1877.6770980510305
INFO:root:current train perplexity4.386594772338867
INFO:root:current mean train loss 1879.059876454537
INFO:root:current train perplexity4.388858318328857
INFO:root:current mean train loss 1879.4611853397255
INFO:root:current train perplexity4.3969573974609375
INFO:root:current mean train loss 1878.0633687634559
INFO:root:current train perplexity4.395821571350098
INFO:root:current mean train loss 1877.6161359415614
INFO:root:current train perplexity4.398105621337891
INFO:root:current mean train loss 1876.6979457611453
INFO:root:current train perplexity4.396395206451416
INFO:root:current mean train loss 1875.7802100734984
INFO:root:current train perplexity4.393823623657227
INFO:root:current mean train loss 1877.5912524126416
INFO:root:current train perplexity4.397725582122803
INFO:root:current mean train loss 1876.199742446711
INFO:root:current train perplexity4.395914077758789
INFO:root:current mean train loss 1875.6528344601202
INFO:root:current train perplexity4.394660949707031
INFO:root:current mean train loss 1876.2639400910123
INFO:root:current train perplexity4.394482612609863
INFO:root:current mean train loss 1875.981801663378
INFO:root:current train perplexity4.396945476531982
INFO:root:current mean train loss 1875.662832795996
INFO:root:current train perplexity4.3971734046936035
INFO:root:current mean train loss 1876.7643841596375
INFO:root:current train perplexity4.398275375366211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.77s/it]
INFO:root:final mean train loss: 1876.1702611849155
INFO:root:final train perplexity: 4.397707462310791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.49s/it]
INFO:root:eval mean loss: 1918.5596941143062
INFO:root:eval perplexity: 4.724947452545166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.26s/it]
INFO:root:eval mean loss: 2510.1679951552806
INFO:root:eval perplexity: 7.879123210906982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/28
 14%|â–ˆâ–        | 28/200 [4:15:30<26:11:43, 548.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.7174837239584
INFO:root:current train perplexity4.323123455047607
INFO:root:current mean train loss 1844.2030887276785
INFO:root:current train perplexity4.323355197906494
INFO:root:current mean train loss 1847.0310009765626
INFO:root:current train perplexity4.340890884399414
INFO:root:current mean train loss 1854.2878440755208
INFO:root:current train perplexity4.345139026641846
INFO:root:current mean train loss 1854.177829718339
INFO:root:current train perplexity4.347571849822998
INFO:root:current mean train loss 1854.6947225288723
INFO:root:current train perplexity4.341845989227295
INFO:root:current mean train loss 1856.4585876012732
INFO:root:current train perplexity4.341798782348633
INFO:root:current mean train loss 1860.3931226373488
INFO:root:current train perplexity4.34648323059082
INFO:root:current mean train loss 1861.0405147879464
INFO:root:current train perplexity4.349698066711426
INFO:root:current mean train loss 1862.0948571464344
INFO:root:current train perplexity4.352337837219238
INFO:root:current mean train loss 1862.9255517578124
INFO:root:current train perplexity4.356308937072754
INFO:root:current mean train loss 1863.7747071351396
INFO:root:current train perplexity4.356738567352295
INFO:root:current mean train loss 1865.3799759689032
INFO:root:current train perplexity4.35947322845459
INFO:root:current mean train loss 1866.0538254616476
INFO:root:current train perplexity4.358438968658447
INFO:root:current mean train loss 1866.0142862817797
INFO:root:current train perplexity4.359999656677246
INFO:root:current mean train loss 1865.0400159660219
INFO:root:current train perplexity4.360191345214844
INFO:root:current mean train loss 1867.2754291773554
INFO:root:current train perplexity4.3649749755859375
INFO:root:current mean train loss 1867.174367159991
INFO:root:current train perplexity4.36490535736084
INFO:root:current mean train loss 1867.2196953125
INFO:root:current train perplexity4.365149021148682
INFO:root:current mean train loss 1867.1028908104233
INFO:root:current train perplexity4.364648818969727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.03s/it]
INFO:root:final mean train loss: 1866.63249879838
INFO:root:final train perplexity: 4.364719867706299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it]
INFO:root:eval mean loss: 1918.0407541694372
INFO:root:eval perplexity: 4.722963333129883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 2527.9934116661125
INFO:root:eval perplexity: 7.995471477508545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/29
 14%|â–ˆâ–        | 29/200 [4:24:29<25:55:06, 545.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.1138770061991
INFO:root:current train perplexity4.308679580688477
INFO:root:current mean train loss 1849.293472290039
INFO:root:current train perplexity4.302002429962158
INFO:root:current mean train loss 1851.432455402531
INFO:root:current train perplexity4.301016807556152
INFO:root:current mean train loss 1856.6875650834063
INFO:root:current train perplexity4.317470073699951
INFO:root:current mean train loss 1854.4986584671144
INFO:root:current train perplexity4.309903621673584
INFO:root:current mean train loss 1854.9749607395481
INFO:root:current train perplexity4.308478832244873
INFO:root:current mean train loss 1855.0784490508152
INFO:root:current train perplexity4.318748474121094
INFO:root:current mean train loss 1856.2458523837004
INFO:root:current train perplexity4.327177047729492
INFO:root:current mean train loss 1858.5019889797331
INFO:root:current train perplexity4.334329605102539
INFO:root:current mean train loss 1857.9039488761655
INFO:root:current train perplexity4.331570625305176
INFO:root:current mean train loss 1857.6691356840588
INFO:root:current train perplexity4.32980489730835
INFO:root:current mean train loss 1858.0365918050677
INFO:root:current train perplexity4.331593990325928
INFO:root:current mean train loss 1857.3941464261743
INFO:root:current train perplexity4.33242130279541
INFO:root:current mean train loss 1857.6663115051972
INFO:root:current train perplexity4.331707000732422
INFO:root:current mean train loss 1857.2656679536958
INFO:root:current train perplexity4.330408096313477
INFO:root:current mean train loss 1857.9273519851454
INFO:root:current train perplexity4.3313727378845215
INFO:root:current mean train loss 1857.2394509462035
INFO:root:current train perplexity4.328772068023682
INFO:root:current mean train loss 1857.236569268363
INFO:root:current train perplexity4.330020427703857
INFO:root:current mean train loss 1856.6248778651684
INFO:root:current train perplexity4.330665588378906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.53s/it]
INFO:root:final mean train loss: 1856.9544541074722
INFO:root:final train perplexity: 4.331500053405762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.86s/it]
INFO:root:eval mean loss: 1914.2506999563664
INFO:root:eval perplexity: 4.708497524261475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it]
INFO:root:eval mean loss: 2528.9800670434397
INFO:root:eval perplexity: 8.001960754394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/30
 15%|â–ˆâ–Œ        | 30/200 [4:33:37<25:47:53, 546.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1862.8019205729167
INFO:root:current train perplexity4.317507266998291
INFO:root:current mean train loss 1840.8698069721188
INFO:root:current train perplexity4.289330959320068
INFO:root:current mean train loss 1847.039730674342
INFO:root:current train perplexity4.278633117675781
INFO:root:current mean train loss 1846.0086555357504
INFO:root:current train perplexity4.2841010093688965
INFO:root:current mean train loss 1843.5041077107846
INFO:root:current train perplexity4.292359828948975
INFO:root:current mean train loss 1845.7531517643356
INFO:root:current train perplexity4.291025638580322
INFO:root:current mean train loss 1848.3676986318503
INFO:root:current train perplexity4.296584606170654
INFO:root:current mean train loss 1849.355310006942
INFO:root:current train perplexity4.300803184509277
INFO:root:current mean train loss 1849.8132304603002
INFO:root:current train perplexity4.305568695068359
INFO:root:current mean train loss 1850.8849207308426
INFO:root:current train perplexity4.307809829711914
INFO:root:current mean train loss 1850.138959689939
INFO:root:current train perplexity4.305764198303223
INFO:root:current mean train loss 1849.6872542082888
INFO:root:current train perplexity4.306976318359375
INFO:root:current mean train loss 1849.8027966722564
INFO:root:current train perplexity4.309507846832275
INFO:root:current mean train loss 1848.943363944477
INFO:root:current train perplexity4.3074541091918945
INFO:root:current mean train loss 1849.2230012350847
INFO:root:current train perplexity4.305482864379883
INFO:root:current mean train loss 1849.2267306803708
INFO:root:current train perplexity4.304272174835205
INFO:root:current mean train loss 1849.3645451215575
INFO:root:current train perplexity4.303394794464111
INFO:root:current mean train loss 1849.1130883231924
INFO:root:current train perplexity4.30333137512207
INFO:root:current mean train loss 1848.779727596285
INFO:root:current train perplexity4.303779125213623
INFO:root:current mean train loss 1848.9459603870646
INFO:root:current train perplexity4.303300857543945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.99s/it]
INFO:root:final mean train loss: 1848.290767667754
INFO:root:final train perplexity: 4.301976680755615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it]
INFO:root:eval mean loss: 1910.7796050808954
INFO:root:eval perplexity: 4.695287227630615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it]
INFO:root:eval mean loss: 2546.162742668855
INFO:root:eval perplexity: 8.115832328796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/31
 16%|â–ˆâ–Œ        | 31/200 [4:42:41<25:36:38, 545.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1802.3887235201323
INFO:root:current train perplexity4.210848808288574
INFO:root:current mean train loss 1856.9851558624753
INFO:root:current train perplexity4.272085666656494
INFO:root:current mean train loss 1850.4083937923465
INFO:root:current train perplexity4.26453971862793
INFO:root:current mean train loss 1844.1159304753403
INFO:root:current train perplexity4.262818336486816
INFO:root:current mean train loss 1841.339608205876
INFO:root:current train perplexity4.253017902374268
INFO:root:current mean train loss 1839.2409426612999
INFO:root:current train perplexity4.252320766448975
INFO:root:current mean train loss 1836.8790766804364
INFO:root:current train perplexity4.250539302825928
INFO:root:current mean train loss 1837.681225485053
INFO:root:current train perplexity4.254669189453125
INFO:root:current mean train loss 1836.9644459130977
INFO:root:current train perplexity4.25540018081665
INFO:root:current mean train loss 1836.6710263081297
INFO:root:current train perplexity4.2566022872924805
INFO:root:current mean train loss 1836.9927005284478
INFO:root:current train perplexity4.253655433654785
INFO:root:current mean train loss 1836.1926801827194
INFO:root:current train perplexity4.252462387084961
INFO:root:current mean train loss 1835.7731115145161
INFO:root:current train perplexity4.252182960510254
INFO:root:current mean train loss 1836.7149980409831
INFO:root:current train perplexity4.256698131561279
INFO:root:current mean train loss 1836.602017310358
INFO:root:current train perplexity4.257026672363281
INFO:root:current mean train loss 1837.4440948366337
INFO:root:current train perplexity4.260165214538574
INFO:root:current mean train loss 1837.731307701871
INFO:root:current train perplexity4.262379169464111
INFO:root:current mean train loss 1838.4672006405933
INFO:root:current train perplexity4.2675371170043945
INFO:root:current mean train loss 1838.9183236630827
INFO:root:current train perplexity4.269017696380615
INFO:root:current mean train loss 1839.5172375196732
INFO:root:current train perplexity4.271084308624268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.01s/it]
INFO:root:final mean train loss: 1839.233304591715
INFO:root:final train perplexity: 4.271326541900635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.01s/it]
INFO:root:eval mean loss: 1915.0487155779033
INFO:root:eval perplexity: 4.7115397453308105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 2577.9290407870676
INFO:root:eval perplexity: 8.330634117126465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/32
 16%|â–ˆâ–Œ        | 32/200 [4:51:49<25:29:49, 546.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1829.7324048419332
INFO:root:current train perplexity4.212798595428467
INFO:root:current mean train loss 1830.465419102382
INFO:root:current train perplexity4.232652187347412
INFO:root:current mean train loss 1824.7100558810764
INFO:root:current train perplexity4.2159223556518555
INFO:root:current mean train loss 1826.5772235303161
INFO:root:current train perplexity4.2362213134765625
INFO:root:current mean train loss 1830.5465346911153
INFO:root:current train perplexity4.243804931640625
INFO:root:current mean train loss 1830.842309210621
INFO:root:current train perplexity4.242718696594238
INFO:root:current mean train loss 1830.735275624514
INFO:root:current train perplexity4.241194248199463
INFO:root:current mean train loss 1830.6172027793257
INFO:root:current train perplexity4.236711025238037
INFO:root:current mean train loss 1831.1489033365306
INFO:root:current train perplexity4.238852500915527
INFO:root:current mean train loss 1830.3910270682827
INFO:root:current train perplexity4.2393364906311035
INFO:root:current mean train loss 1829.8491992749282
INFO:root:current train perplexity4.238972187042236
INFO:root:current mean train loss 1829.7273740593216
INFO:root:current train perplexity4.235843181610107
INFO:root:current mean train loss 1831.0519501984552
INFO:root:current train perplexity4.237940788269043
INFO:root:current mean train loss 1832.0692986710606
INFO:root:current train perplexity4.241109371185303
INFO:root:current mean train loss 1830.9397126618805
INFO:root:current train perplexity4.238992691040039
INFO:root:current mean train loss 1830.9198686324075
INFO:root:current train perplexity4.238077640533447
INFO:root:current mean train loss 1832.0628929579323
INFO:root:current train perplexity4.239619255065918
INFO:root:current mean train loss 1832.6347914677683
INFO:root:current train perplexity4.241419315338135
INFO:root:current mean train loss 1831.856644943494
INFO:root:current train perplexity4.2411322593688965
INFO:root:current mean train loss 1830.9282192636629
INFO:root:current train perplexity4.239402770996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.54s/it]
INFO:root:final mean train loss: 1829.30548640495
INFO:root:final train perplexity: 4.237982273101807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.96s/it]
INFO:root:eval mean loss: 1907.2468768180686
INFO:root:eval perplexity: 4.681881904602051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 2578.000170985012
INFO:root:eval perplexity: 8.331120491027832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/33
 16%|â–ˆâ–‹        | 33/200 [5:00:57<25:21:37, 546.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.1300048828125
INFO:root:current train perplexity4.255523204803467
INFO:root:current mean train loss 1825.2467414855957
INFO:root:current train perplexity4.207296848297119
INFO:root:current mean train loss 1821.0476477989785
INFO:root:current train perplexity4.208983421325684
INFO:root:current mean train loss 1821.9201178656683
INFO:root:current train perplexity4.2048749923706055
INFO:root:current mean train loss 1822.1723367442255
INFO:root:current train perplexity4.201368808746338
INFO:root:current mean train loss 1821.3256075177874
INFO:root:current train perplexity4.2007832527160645
INFO:root:current mean train loss 1818.2473801121566
INFO:root:current train perplexity4.194773197174072
INFO:root:current mean train loss 1821.4652422453228
INFO:root:current train perplexity4.198180675506592
INFO:root:current mean train loss 1822.441707593341
INFO:root:current train perplexity4.2005228996276855
INFO:root:current mean train loss 1822.7227294921875
INFO:root:current train perplexity4.20067024230957
INFO:root:current mean train loss 1819.7693748618071
INFO:root:current train perplexity4.196155548095703
INFO:root:current mean train loss 1821.360801854627
INFO:root:current train perplexity4.201285362243652
INFO:root:current mean train loss 1821.4871077280195
INFO:root:current train perplexity4.202188968658447
INFO:root:current mean train loss 1821.11166974236
INFO:root:current train perplexity4.2024383544921875
INFO:root:current mean train loss 1822.2200572392712
INFO:root:current train perplexity4.203563213348389
INFO:root:current mean train loss 1823.5430466871994
INFO:root:current train perplexity4.20648717880249
INFO:root:current mean train loss 1822.6183131206467
INFO:root:current train perplexity4.205935001373291
INFO:root:current mean train loss 1824.002132207697
INFO:root:current train perplexity4.2095232009887695
INFO:root:current mean train loss 1822.7564129573043
INFO:root:current train perplexity4.210249900817871
INFO:root:current mean train loss 1821.4808687171158
INFO:root:current train perplexity4.2097978591918945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.76s/it]
INFO:root:final mean train loss: 1820.906471056224
INFO:root:final train perplexity: 4.209976673126221
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 1903.4670423142454
INFO:root:eval perplexity: 4.667580604553223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 2585.256651966284
INFO:root:eval perplexity: 8.380982398986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/34
 17%|â–ˆâ–‹        | 34/200 [5:10:03<25:12:07, 546.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1799.13623046875
INFO:root:current train perplexity4.1693220138549805
INFO:root:current mean train loss 1808.0202050505384
INFO:root:current train perplexity4.179871559143066
INFO:root:current mean train loss 1807.1874766435865
INFO:root:current train perplexity4.175639629364014
INFO:root:current mean train loss 1807.055286518775
INFO:root:current train perplexity4.172557830810547
INFO:root:current mean train loss 1810.7474830995316
INFO:root:current train perplexity4.1781415939331055
INFO:root:current mean train loss 1812.2255302971323
INFO:root:current train perplexity4.181534290313721
INFO:root:current mean train loss 1812.1668109752932
INFO:root:current train perplexity4.184957981109619
INFO:root:current mean train loss 1811.3416000228744
INFO:root:current train perplexity4.179327964782715
INFO:root:current mean train loss 1810.053324961472
INFO:root:current train perplexity4.178778171539307
INFO:root:current mean train loss 1810.037646884196
INFO:root:current train perplexity4.177096366882324
INFO:root:current mean train loss 1811.675898899939
INFO:root:current train perplexity4.179400444030762
INFO:root:current mean train loss 1813.1924731466056
INFO:root:current train perplexity4.180726051330566
INFO:root:current mean train loss 1812.5896840166467
INFO:root:current train perplexity4.178773880004883
INFO:root:current mean train loss 1812.4933949057054
INFO:root:current train perplexity4.180714130401611
INFO:root:current mean train loss 1813.5455094985084
INFO:root:current train perplexity4.181159496307373
INFO:root:current mean train loss 1813.7232243375229
INFO:root:current train perplexity4.1837310791015625
INFO:root:current mean train loss 1813.7858030697953
INFO:root:current train perplexity4.183932304382324
INFO:root:current mean train loss 1813.5258643429938
INFO:root:current train perplexity4.182392120361328
INFO:root:current mean train loss 1812.9739789927203
INFO:root:current train perplexity4.182632923126221
INFO:root:current mean train loss 1812.7267373624811
INFO:root:current train perplexity4.1814680099487305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.43s/it]
INFO:root:final mean train loss: 1812.278241887095
INFO:root:final train perplexity: 4.181398391723633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.20s/it]
INFO:root:eval mean loss: 1905.514000858821
INFO:root:eval perplexity: 4.675319194793701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it]
INFO:root:eval mean loss: 2608.7201919014574
INFO:root:eval perplexity: 8.544267654418945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/35
 18%|â–ˆâ–Š        | 35/200 [5:19:14<25:06:25, 547.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1819.627534906915
INFO:root:current train perplexity4.171762466430664
INFO:root:current mean train loss 1809.6562795737354
INFO:root:current train perplexity4.165020942687988
INFO:root:current mean train loss 1807.1211448202328
INFO:root:current train perplexity4.159346580505371
INFO:root:current mean train loss 1802.4050791783986
INFO:root:current train perplexity4.150078296661377
INFO:root:current mean train loss 1806.8584587313385
INFO:root:current train perplexity4.159576892852783
INFO:root:current mean train loss 1807.5846220588041
INFO:root:current train perplexity4.160835266113281
INFO:root:current mean train loss 1807.7822569921311
INFO:root:current train perplexity4.158435344696045
INFO:root:current mean train loss 1806.163100696631
INFO:root:current train perplexity4.158778667449951
INFO:root:current mean train loss 1805.1551098578195
INFO:root:current train perplexity4.159162521362305
INFO:root:current mean train loss 1806.2900646063883
INFO:root:current train perplexity4.158316135406494
INFO:root:current mean train loss 1807.0715993710367
INFO:root:current train perplexity4.1584672927856445
INFO:root:current mean train loss 1806.7801181403436
INFO:root:current train perplexity4.159813404083252
INFO:root:current mean train loss 1807.4200118711965
INFO:root:current train perplexity4.15733528137207
INFO:root:current mean train loss 1807.0902528694405
INFO:root:current train perplexity4.156715393066406
INFO:root:current mean train loss 1806.2854594648124
INFO:root:current train perplexity4.15546178817749
INFO:root:current mean train loss 1806.6463851258627
INFO:root:current train perplexity4.156709671020508
INFO:root:current mean train loss 1805.8756105677437
INFO:root:current train perplexity4.156643867492676
INFO:root:current mean train loss 1806.233780026303
INFO:root:current train perplexity4.1573920249938965
INFO:root:current mean train loss 1805.8345681727246
INFO:root:current train perplexity4.156826972961426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.69s/it]
INFO:root:final mean train loss: 1804.327349641139
INFO:root:final train perplexity: 4.155235290527344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it]
INFO:root:eval mean loss: 1899.7187062797816
INFO:root:eval perplexity: 4.653440475463867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.75s/it]
INFO:root:eval mean loss: 2600.131388346354
INFO:root:eval perplexity: 8.484130859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/36
 18%|â–ˆâ–Š        | 36/200 [5:28:23<24:58:53, 548.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.4105113636363
INFO:root:current train perplexity4.103759765625
INFO:root:current mean train loss 1787.5031749278576
INFO:root:current train perplexity4.100160598754883
INFO:root:current mean train loss 1783.3781923411582
INFO:root:current train perplexity4.114107131958008
INFO:root:current mean train loss 1783.5785909082344
INFO:root:current train perplexity4.111311435699463
INFO:root:current mean train loss 1789.756825542218
INFO:root:current train perplexity4.120576858520508
INFO:root:current mean train loss 1790.1970047624143
INFO:root:current train perplexity4.117028713226318
INFO:root:current mean train loss 1787.0814328857023
INFO:root:current train perplexity4.111809253692627
INFO:root:current mean train loss 1790.9368137622516
INFO:root:current train perplexity4.122180461883545
INFO:root:current mean train loss 1791.7958719462854
INFO:root:current train perplexity4.121557235717773
INFO:root:current mean train loss 1791.9064075792398
INFO:root:current train perplexity4.12216329574585
INFO:root:current mean train loss 1791.4748166892696
INFO:root:current train perplexity4.120028495788574
INFO:root:current mean train loss 1792.1407754178738
INFO:root:current train perplexity4.120728492736816
INFO:root:current mean train loss 1793.5900459573054
INFO:root:current train perplexity4.124259948730469
INFO:root:current mean train loss 1792.9413186312631
INFO:root:current train perplexity4.12383508682251
INFO:root:current mean train loss 1793.5844226515437
INFO:root:current train perplexity4.125201225280762
INFO:root:current mean train loss 1794.50667113046
INFO:root:current train perplexity4.12694787979126
INFO:root:current mean train loss 1794.3717298643844
INFO:root:current train perplexity4.126193046569824
INFO:root:current mean train loss 1796.1321360834993
INFO:root:current train perplexity4.126201629638672
INFO:root:current mean train loss 1797.0259939664506
INFO:root:current train perplexity4.1267852783203125
INFO:root:current mean train loss 1796.8379338702127
INFO:root:current train perplexity4.127307415008545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.96s/it]
INFO:root:final mean train loss: 1795.7444629447964
INFO:root:final train perplexity: 4.1271772384643555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.61s/it]
INFO:root:eval mean loss: 1896.5404321115914
INFO:root:eval perplexity: 4.64148473739624
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.85s/it]
INFO:root:eval mean loss: 2607.4309480274824
INFO:root:eval perplexity: 8.535210609436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/37
 18%|â–ˆâ–Š        | 37/200 [5:37:34<24:51:50, 549.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1803.3423941476005
INFO:root:current train perplexity4.093385696411133
INFO:root:current mean train loss 1795.087978363037
INFO:root:current train perplexity4.107702732086182
INFO:root:current mean train loss 1786.8920721756785
INFO:root:current train perplexity4.101545810699463
INFO:root:current mean train loss 1787.3093310100276
INFO:root:current train perplexity4.103951454162598
INFO:root:current mean train loss 1788.903670551621
INFO:root:current train perplexity4.105444431304932
INFO:root:current mean train loss 1790.1580995501895
INFO:root:current train perplexity4.1149115562438965
INFO:root:current mean train loss 1788.846082942501
INFO:root:current train perplexity4.114403247833252
INFO:root:current mean train loss 1788.0078924828833
INFO:root:current train perplexity4.107179164886475
INFO:root:current mean train loss 1789.9773036201218
INFO:root:current train perplexity4.111934661865234
INFO:root:current mean train loss 1788.9392530507055
INFO:root:current train perplexity4.107132911682129
INFO:root:current mean train loss 1791.3168280338034
INFO:root:current train perplexity4.106667518615723
INFO:root:current mean train loss 1789.1342061360676
INFO:root:current train perplexity4.102554798126221
INFO:root:current mean train loss 1789.7204229000724
INFO:root:current train perplexity4.104687690734863
INFO:root:current mean train loss 1790.2281481271766
INFO:root:current train perplexity4.106494903564453
INFO:root:current mean train loss 1790.338772813813
INFO:root:current train perplexity4.108182907104492
INFO:root:current mean train loss 1789.77364481182
INFO:root:current train perplexity4.106847763061523
INFO:root:current mean train loss 1790.070020895918
INFO:root:current train perplexity4.106310844421387
INFO:root:current mean train loss 1789.487925140946
INFO:root:current train perplexity4.105429172515869
INFO:root:current mean train loss 1789.2996112982084
INFO:root:current train perplexity4.103769302368164
INFO:root:current mean train loss 1789.2558106228523
INFO:root:current train perplexity4.103775501251221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.69s/it]
INFO:root:final mean train loss: 1788.773189204183
INFO:root:final train perplexity: 4.104526996612549
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.01s/it]
INFO:root:eval mean loss: 1896.6547275840812
INFO:root:eval perplexity: 4.6419148445129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.52s/it]
INFO:root:eval mean loss: 2616.344682409408
INFO:root:eval perplexity: 8.598005294799805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/38
 19%|â–ˆâ–‰        | 38/200 [5:46:50<24:48:08, 551.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.7004801432292
INFO:root:current train perplexity4.066748142242432
INFO:root:current mean train loss 1784.276216493804
INFO:root:current train perplexity4.115659713745117
INFO:root:current mean train loss 1786.6525006975446
INFO:root:current train perplexity4.104341506958008
INFO:root:current mean train loss 1780.294976364357
INFO:root:current train perplexity4.089855194091797
INFO:root:current mean train loss 1779.69039868987
INFO:root:current train perplexity4.090446472167969
INFO:root:current mean train loss 1778.2003998082712
INFO:root:current train perplexity4.08518123626709
INFO:root:current mean train loss 1777.9019124348958
INFO:root:current train perplexity4.078531265258789
INFO:root:current mean train loss 1776.432774322305
INFO:root:current train perplexity4.077271461486816
INFO:root:current mean train loss 1775.6037795569064
INFO:root:current train perplexity4.076727390289307
INFO:root:current mean train loss 1774.7142746052414
INFO:root:current train perplexity4.07467794418335
INFO:root:current mean train loss 1774.481976230749
INFO:root:current train perplexity4.072451114654541
INFO:root:current mean train loss 1775.5221626381688
INFO:root:current train perplexity4.074509143829346
INFO:root:current mean train loss 1774.4715643825302
INFO:root:current train perplexity4.070684909820557
INFO:root:current mean train loss 1776.5384732951904
INFO:root:current train perplexity4.072959899902344
INFO:root:current mean train loss 1776.4520141179173
INFO:root:current train perplexity4.07469367980957
INFO:root:current mean train loss 1776.751850965185
INFO:root:current train perplexity4.072442531585693
INFO:root:current mean train loss 1777.4495612147368
INFO:root:current train perplexity4.073859691619873
INFO:root:current mean train loss 1778.7047936207243
INFO:root:current train perplexity4.075806140899658
INFO:root:current mean train loss 1780.1078102504657
INFO:root:current train perplexity4.0784502029418945
INFO:root:current mean train loss 1781.0197386753896
INFO:root:current train perplexity4.079386234283447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.34s/it]
INFO:root:final mean train loss: 1780.9265251525171
INFO:root:final train perplexity: 4.079180717468262
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.28s/it]
INFO:root:eval mean loss: 1899.1123947251774
INFO:root:eval perplexity: 4.651157379150391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.21s/it]
INFO:root:eval mean loss: 2619.4838997049533
INFO:root:eval perplexity: 8.620230674743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/39
 20%|â–ˆâ–‰        | 39/200 [5:56:01<24:38:23, 550.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1747.4509237966229
INFO:root:current train perplexity4.025038242340088
INFO:root:current mean train loss 1760.460270634404
INFO:root:current train perplexity4.05184268951416
INFO:root:current mean train loss 1759.687470647215
INFO:root:current train perplexity4.033599853515625
INFO:root:current mean train loss 1769.0341860945055
INFO:root:current train perplexity4.047407627105713
INFO:root:current mean train loss 1768.3410311612215
INFO:root:current train perplexity4.0426344871521
INFO:root:current mean train loss 1770.6885586667315
INFO:root:current train perplexity4.051425933837891
INFO:root:current mean train loss 1770.4776679554734
INFO:root:current train perplexity4.049574375152588
INFO:root:current mean train loss 1774.6684595944062
INFO:root:current train perplexity4.056814670562744
INFO:root:current mean train loss 1774.846281472049
INFO:root:current train perplexity4.059409141540527
INFO:root:current mean train loss 1775.084992533662
INFO:root:current train perplexity4.05959939956665
INFO:root:current mean train loss 1772.5388357158884
INFO:root:current train perplexity4.056803226470947
INFO:root:current mean train loss 1772.8830398323203
INFO:root:current train perplexity4.058528423309326
INFO:root:current mean train loss 1774.700633682275
INFO:root:current train perplexity4.0586161613464355
INFO:root:current mean train loss 1774.3873406632881
INFO:root:current train perplexity4.058272838592529
INFO:root:current mean train loss 1774.2021367481404
INFO:root:current train perplexity4.056054592132568
INFO:root:current mean train loss 1774.9271428575894
INFO:root:current train perplexity4.056162357330322
INFO:root:current mean train loss 1774.866944240749
INFO:root:current train perplexity4.057107925415039
INFO:root:current mean train loss 1774.4829686973476
INFO:root:current train perplexity4.056750297546387
INFO:root:current mean train loss 1774.677607256667
INFO:root:current train perplexity4.05698823928833
INFO:root:current mean train loss 1775.7373798459798
INFO:root:current train perplexity4.059839725494385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.97s/it]
INFO:root:final mean train loss: 1774.9466467168195
INFO:root:final train perplexity: 4.059969425201416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 1893.9638810394504
INFO:root:eval perplexity: 4.631816387176514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 2632.024885028812
INFO:root:eval perplexity: 8.70959186553955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/40
 20%|â–ˆâ–ˆ        | 40/200 [6:05:09<24:27:13, 550.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.0362378856803
INFO:root:current train perplexity3.9961934089660645
INFO:root:current mean train loss 1760.1907870329958
INFO:root:current train perplexity4.017586708068848
INFO:root:current mean train loss 1762.4434061904963
INFO:root:current train perplexity4.0249714851379395
INFO:root:current mean train loss 1761.963224949497
INFO:root:current train perplexity4.023330211639404
INFO:root:current mean train loss 1763.2681742052941
INFO:root:current train perplexity4.030906677246094
INFO:root:current mean train loss 1764.315790838528
INFO:root:current train perplexity4.036619663238525
INFO:root:current mean train loss 1766.0660916357924
INFO:root:current train perplexity4.036402702331543
INFO:root:current mean train loss 1768.111722855574
INFO:root:current train perplexity4.035676956176758
INFO:root:current mean train loss 1768.8653856088683
INFO:root:current train perplexity4.03764533996582
INFO:root:current mean train loss 1769.3004782562723
INFO:root:current train perplexity4.0385966300964355
INFO:root:current mean train loss 1768.0770893821682
INFO:root:current train perplexity4.0384416580200195
INFO:root:current mean train loss 1768.9148583901544
INFO:root:current train perplexity4.038975715637207
INFO:root:current mean train loss 1767.81471664035
INFO:root:current train perplexity4.039957523345947
INFO:root:current mean train loss 1767.86964475149
INFO:root:current train perplexity4.040184020996094
INFO:root:current mean train loss 1767.3428635664934
INFO:root:current train perplexity4.039506435394287
INFO:root:current mean train loss 1767.9703104745142
INFO:root:current train perplexity4.038990497589111
INFO:root:current mean train loss 1767.4499731285364
INFO:root:current train perplexity4.0386433601379395
INFO:root:current mean train loss 1767.8286804576614
INFO:root:current train perplexity4.038665771484375
INFO:root:current mean train loss 1768.217868936893
INFO:root:current train perplexity4.0371270179748535
INFO:root:current mean train loss 1767.9735586080603
INFO:root:current train perplexity4.035642147064209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.79s/it]
INFO:root:final mean train loss: 1767.5004155499973
INFO:root:final train perplexity: 4.036174774169922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it]
INFO:root:eval mean loss: 1891.8248178468527
INFO:root:eval perplexity: 4.623803615570068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.39s/it]
INFO:root:eval mean loss: 2652.424335885555
INFO:root:eval perplexity: 8.856928825378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/41
 20%|â–ˆâ–ˆ        | 41/200 [6:14:17<24:16:30, 549.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1769.3300717671711
INFO:root:current train perplexity4.0387396812438965
INFO:root:current mean train loss 1770.0107066874602
INFO:root:current train perplexity4.023913383483887
INFO:root:current mean train loss 1768.8071070490657
INFO:root:current train perplexity4.037252426147461
INFO:root:current mean train loss 1765.752876358803
INFO:root:current train perplexity4.021319389343262
INFO:root:current mean train loss 1764.3939991612588
INFO:root:current train perplexity4.01414680480957
INFO:root:current mean train loss 1764.8204134742687
INFO:root:current train perplexity4.016402244567871
INFO:root:current mean train loss 1762.607059522607
INFO:root:current train perplexity4.016612529754639
INFO:root:current mean train loss 1760.6398037857746
INFO:root:current train perplexity4.014087677001953
INFO:root:current mean train loss 1758.518997328622
INFO:root:current train perplexity4.013132572174072
INFO:root:current mean train loss 1759.7294847113062
INFO:root:current train perplexity4.0152153968811035
INFO:root:current mean train loss 1760.9359838109817
INFO:root:current train perplexity4.014898300170898
INFO:root:current mean train loss 1760.4281521290043
INFO:root:current train perplexity4.011806488037109
INFO:root:current mean train loss 1760.6572479436427
INFO:root:current train perplexity4.0122551918029785
INFO:root:current mean train loss 1761.1548314135532
INFO:root:current train perplexity4.013027191162109
INFO:root:current mean train loss 1760.8825105881308
INFO:root:current train perplexity4.014660358428955
INFO:root:current mean train loss 1760.7815711611793
INFO:root:current train perplexity4.0152668952941895
INFO:root:current mean train loss 1759.6585930158508
INFO:root:current train perplexity4.013994216918945
INFO:root:current mean train loss 1759.7092469349204
INFO:root:current train perplexity4.012905597686768
INFO:root:current mean train loss 1760.758786615943
INFO:root:current train perplexity4.013349533081055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.90s/it]
INFO:root:final mean train loss: 1761.0599611467985
INFO:root:final train perplexity: 4.0157060623168945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.77s/it]
INFO:root:eval mean loss: 1891.1318441620956
INFO:root:eval perplexity: 4.621211051940918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it]
INFO:root:eval mean loss: 2657.3956337786735
INFO:root:eval perplexity: 8.893211364746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/42
 21%|â–ˆâ–ˆ        | 42/200 [6:23:22<24:03:32, 548.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.0720778245193
INFO:root:current train perplexity3.940110206604004
INFO:root:current mean train loss 1760.8745830164546
INFO:root:current train perplexity4.015483379364014
INFO:root:current mean train loss 1752.429776903609
INFO:root:current train perplexity3.992882013320923
INFO:root:current mean train loss 1747.9385463726787
INFO:root:current train perplexity3.991600275039673
INFO:root:current mean train loss 1753.335888730989
INFO:root:current train perplexity3.9952688217163086
INFO:root:current mean train loss 1754.0998347172729
INFO:root:current train perplexity3.993408441543579
INFO:root:current mean train loss 1754.55320513229
INFO:root:current train perplexity3.9918994903564453
INFO:root:current mean train loss 1754.0143330749254
INFO:root:current train perplexity3.99220609664917
INFO:root:current mean train loss 1755.508768642374
INFO:root:current train perplexity3.9955031871795654
INFO:root:current mean train loss 1754.7894169451242
INFO:root:current train perplexity3.9956741333007812
INFO:root:current mean train loss 1754.7813576098608
INFO:root:current train perplexity3.9973368644714355
INFO:root:current mean train loss 1755.9575199699573
INFO:root:current train perplexity3.996105194091797
INFO:root:current mean train loss 1754.2148043010613
INFO:root:current train perplexity3.9944252967834473
INFO:root:current mean train loss 1755.4479414278192
INFO:root:current train perplexity3.9982833862304688
INFO:root:current mean train loss 1754.632225387584
INFO:root:current train perplexity3.9950945377349854
INFO:root:current mean train loss 1754.8460572337915
INFO:root:current train perplexity3.995030164718628
INFO:root:current mean train loss 1753.8349825817093
INFO:root:current train perplexity3.9948039054870605
INFO:root:current mean train loss 1754.1781046478218
INFO:root:current train perplexity3.995476484298706
INFO:root:current mean train loss 1753.9869487108083
INFO:root:current train perplexity3.995009660720825
INFO:root:current mean train loss 1753.946018695582
INFO:root:current train perplexity3.9935622215270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it]
INFO:root:final mean train loss: 1754.3592122088041
INFO:root:final train perplexity: 3.9945201873779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it]
INFO:root:eval mean loss: 1891.6601441295434
INFO:root:eval perplexity: 4.623187065124512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it]
INFO:root:eval mean loss: 2645.255753321005
INFO:root:eval perplexity: 8.804871559143066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/43
 22%|â–ˆâ–ˆâ–       | 43/200 [6:32:31<23:55:08, 548.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.4512247721354
INFO:root:current train perplexity3.888575315475464
INFO:root:current mean train loss 1743.6029803936299
INFO:root:current train perplexity3.9374821186065674
INFO:root:current mean train loss 1743.8038404381793
INFO:root:current train perplexity3.95326566696167
INFO:root:current mean train loss 1741.1840553977272
INFO:root:current train perplexity3.9437966346740723
INFO:root:current mean train loss 1745.6915870843932
INFO:root:current train perplexity3.9561665058135986
INFO:root:current mean train loss 1745.3610745412
INFO:root:current train perplexity3.956648588180542
INFO:root:current mean train loss 1746.5237798781623
INFO:root:current train perplexity3.964902400970459
INFO:root:current mean train loss 1748.3857045630887
INFO:root:current train perplexity3.9707236289978027
INFO:root:current mean train loss 1745.9254419533604
INFO:root:current train perplexity3.965196371078491
INFO:root:current mean train loss 1746.4568309496808
INFO:root:current train perplexity3.9701831340789795
INFO:root:current mean train loss 1747.7713851780568
INFO:root:current train perplexity3.9725823402404785
INFO:root:current mean train loss 1746.7653058887583
INFO:root:current train perplexity3.9707703590393066
INFO:root:current mean train loss 1748.2881663252667
INFO:root:current train perplexity3.972059488296509
INFO:root:current mean train loss 1749.4570390514862
INFO:root:current train perplexity3.9738214015960693
INFO:root:current mean train loss 1748.5474022071678
INFO:root:current train perplexity3.9716126918792725
INFO:root:current mean train loss 1749.4264414668862
INFO:root:current train perplexity3.972226619720459
INFO:root:current mean train loss 1748.4279629385544
INFO:root:current train perplexity3.9715142250061035
INFO:root:current mean train loss 1748.70880762001
INFO:root:current train perplexity3.9724714756011963
INFO:root:current mean train loss 1748.9965795631617
INFO:root:current train perplexity3.973855495452881
INFO:root:current mean train loss 1748.3777100241864
INFO:root:current train perplexity3.974069595336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.36s/it]
INFO:root:final mean train loss: 1748.0805277783522
INFO:root:final train perplexity: 3.9747698307037354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.08s/it]
INFO:root:eval mean loss: 1889.4401249445923
INFO:root:eval perplexity: 4.614887714385986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.68s/it]
INFO:root:eval mean loss: 2653.046006655862
INFO:root:eval perplexity: 8.861458778381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/44
 22%|â–ˆâ–ˆâ–       | 44/200 [6:41:36<23:42:57, 547.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.559949509641
INFO:root:current train perplexity3.948928117752075
INFO:root:current mean train loss 1735.7884413531037
INFO:root:current train perplexity3.943268299102783
INFO:root:current mean train loss 1739.8183613518472
INFO:root:current train perplexity3.956498146057129
INFO:root:current mean train loss 1741.9401310197902
INFO:root:current train perplexity3.9639997482299805
INFO:root:current mean train loss 1741.7410394382691
INFO:root:current train perplexity3.9645378589630127
INFO:root:current mean train loss 1743.119698979519
INFO:root:current train perplexity3.9616281986236572
INFO:root:current mean train loss 1741.5114031029632
INFO:root:current train perplexity3.9570772647857666
INFO:root:current mean train loss 1742.115005758712
INFO:root:current train perplexity3.960789442062378
INFO:root:current mean train loss 1740.9697976140515
INFO:root:current train perplexity3.9586985111236572
INFO:root:current mean train loss 1741.1212453388991
INFO:root:current train perplexity3.959279775619507
INFO:root:current mean train loss 1742.3435375720064
INFO:root:current train perplexity3.9596309661865234
INFO:root:current mean train loss 1743.5564374582812
INFO:root:current train perplexity3.9602456092834473
INFO:root:current mean train loss 1743.8305059094953
INFO:root:current train perplexity3.9607834815979004
INFO:root:current mean train loss 1744.5868660318647
INFO:root:current train perplexity3.9625236988067627
INFO:root:current mean train loss 1744.5565210855164
INFO:root:current train perplexity3.962622880935669
INFO:root:current mean train loss 1742.9936686776573
INFO:root:current train perplexity3.956450939178467
INFO:root:current mean train loss 1743.19213237195
INFO:root:current train perplexity3.957819700241089
INFO:root:current mean train loss 1743.2405418915687
INFO:root:current train perplexity3.9572672843933105
INFO:root:current mean train loss 1741.6525413624713
INFO:root:current train perplexity3.952852487564087
INFO:root:current mean train loss 1741.8949532609263
INFO:root:current train perplexity3.953512668609619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.77s/it]
INFO:root:final mean train loss: 1741.4909241061227
INFO:root:final train perplexity: 3.9541471004486084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it]
INFO:root:eval mean loss: 1889.334102116578
INFO:root:eval perplexity: 4.614491939544678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 2674.004154286486
INFO:root:eval perplexity: 9.01550579071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [6:51:11<23:55:26, 555.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1732.693660736084
INFO:root:current train perplexity3.9425175189971924
INFO:root:current mean train loss 1727.6540021198552
INFO:root:current train perplexity3.934101104736328
INFO:root:current mean train loss 1734.0410831335819
INFO:root:current train perplexity3.945124864578247
INFO:root:current mean train loss 1736.7678668682393
INFO:root:current train perplexity3.947298765182495
INFO:root:current mean train loss 1734.6473180836645
INFO:root:current train perplexity3.9370310306549072
INFO:root:current mean train loss 1733.4967794215424
INFO:root:current train perplexity3.9311251640319824
INFO:root:current mean train loss 1733.2581996687923
INFO:root:current train perplexity3.9257588386535645
INFO:root:current mean train loss 1733.0120990213923
INFO:root:current train perplexity3.9287195205688477
INFO:root:current mean train loss 1731.3845106054234
INFO:root:current train perplexity3.922337532043457
INFO:root:current mean train loss 1730.6941610629133
INFO:root:current train perplexity3.9223268032073975
INFO:root:current mean train loss 1731.3730759011175
INFO:root:current train perplexity3.9243650436401367
INFO:root:current mean train loss 1732.8636000590636
INFO:root:current train perplexity3.925729274749756
INFO:root:current mean train loss 1734.68477814107
INFO:root:current train perplexity3.9302663803100586
INFO:root:current mean train loss 1734.7714457134348
INFO:root:current train perplexity3.926640272140503
INFO:root:current mean train loss 1735.8434089702334
INFO:root:current train perplexity3.9304378032684326
INFO:root:current mean train loss 1735.7930373560132
INFO:root:current train perplexity3.9311702251434326
INFO:root:current mean train loss 1735.7376246085535
INFO:root:current train perplexity3.9312405586242676
INFO:root:current mean train loss 1736.5591847945234
INFO:root:current train perplexity3.9339632987976074
INFO:root:current mean train loss 1736.0090017687098
INFO:root:current train perplexity3.9348347187042236
INFO:root:current mean train loss 1736.1147683448557
INFO:root:current train perplexity3.9357030391693115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.26s/it]
INFO:root:final mean train loss: 1735.8761114369602
INFO:root:final train perplexity: 3.936659336090088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.99s/it]
INFO:root:eval mean loss: 1887.216157088043
INFO:root:eval perplexity: 4.606588363647461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.10s/it]
INFO:root:eval mean loss: 2668.667428523936
INFO:root:eval perplexity: 8.976027488708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [7:00:26<23:45:29, 555.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.7806622540509
INFO:root:current train perplexity3.923767566680908
INFO:root:current mean train loss 1727.4766879424205
INFO:root:current train perplexity3.9019615650177
INFO:root:current mean train loss 1730.8448316906695
INFO:root:current train perplexity3.894181251525879
INFO:root:current mean train loss 1730.5362212413877
INFO:root:current train perplexity3.8971517086029053
INFO:root:current mean train loss 1728.473241730688
INFO:root:current train perplexity3.9035279750823975
INFO:root:current mean train loss 1729.5319286353001
INFO:root:current train perplexity3.9086575508117676
INFO:root:current mean train loss 1729.071386933852
INFO:root:current train perplexity3.910703659057617
INFO:root:current mean train loss 1729.0351904797035
INFO:root:current train perplexity3.9121761322021484
INFO:root:current mean train loss 1726.843135630232
INFO:root:current train perplexity3.907860040664673
INFO:root:current mean train loss 1726.0957486680525
INFO:root:current train perplexity3.9076383113861084
INFO:root:current mean train loss 1727.673836368416
INFO:root:current train perplexity3.91003155708313
INFO:root:current mean train loss 1726.994517688929
INFO:root:current train perplexity3.9080729484558105
INFO:root:current mean train loss 1727.762033693312
INFO:root:current train perplexity3.9084553718566895
INFO:root:current mean train loss 1728.2494458661918
INFO:root:current train perplexity3.9083986282348633
INFO:root:current mean train loss 1728.8759903273497
INFO:root:current train perplexity3.909937858581543
INFO:root:current mean train loss 1729.3326063934269
INFO:root:current train perplexity3.913076400756836
INFO:root:current mean train loss 1730.3827473619451
INFO:root:current train perplexity3.9158151149749756
INFO:root:current mean train loss 1729.8647965394266
INFO:root:current train perplexity3.914813995361328
INFO:root:current mean train loss 1729.7201441065672
INFO:root:current train perplexity3.9149794578552246
INFO:root:current mean train loss 1729.9827519146738
INFO:root:current train perplexity3.91703724861145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.11s/it]
INFO:root:final mean train loss: 1729.5985413674928
INFO:root:final train perplexity: 3.9171993732452393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.01s/it]
INFO:root:eval mean loss: 1890.4327033293162
INFO:root:eval perplexity: 4.618596076965332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2682.012396196947
INFO:root:eval perplexity: 9.075074195861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:09:08<23:10:51, 545.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.1311944455517
INFO:root:current train perplexity3.8923823833465576
INFO:root:current mean train loss 1722.8461451674953
INFO:root:current train perplexity3.911287784576416
INFO:root:current mean train loss 1722.0943865680053
INFO:root:current train perplexity3.906085968017578
INFO:root:current mean train loss 1718.7644831211724
INFO:root:current train perplexity3.8898260593414307
INFO:root:current mean train loss 1717.3212069469284
INFO:root:current train perplexity3.88632869720459
INFO:root:current mean train loss 1718.3185002253606
INFO:root:current train perplexity3.889578104019165
INFO:root:current mean train loss 1722.2154021604697
INFO:root:current train perplexity3.897852659225464
INFO:root:current mean train loss 1721.2388167990778
INFO:root:current train perplexity3.8968451023101807
INFO:root:current mean train loss 1721.4881386533878
INFO:root:current train perplexity3.8957576751708984
INFO:root:current mean train loss 1719.6399767308053
INFO:root:current train perplexity3.892683506011963
INFO:root:current mean train loss 1722.5570607558843
INFO:root:current train perplexity3.8949005603790283
INFO:root:current mean train loss 1722.550936232425
INFO:root:current train perplexity3.894049644470215
INFO:root:current mean train loss 1723.8259743806577
INFO:root:current train perplexity3.8955774307250977
INFO:root:current mean train loss 1723.4734045637183
INFO:root:current train perplexity3.895085334777832
INFO:root:current mean train loss 1724.2993283036235
INFO:root:current train perplexity3.89758038520813
INFO:root:current mean train loss 1725.23078217584
INFO:root:current train perplexity3.8996894359588623
INFO:root:current mean train loss 1725.7513082659286
INFO:root:current train perplexity3.8997020721435547
INFO:root:current mean train loss 1726.560407016911
INFO:root:current train perplexity3.902076005935669
INFO:root:current mean train loss 1724.9752279589125
INFO:root:current train perplexity3.900120973587036

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.60s/it]
INFO:root:final mean train loss: 1724.3878179983965
INFO:root:final train perplexity: 3.901118755340576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 1886.9168558323638
INFO:root:eval perplexity: 4.605473041534424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.86s/it]
INFO:root:eval mean loss: 2670.8253888069316
INFO:root:eval perplexity: 8.991971969604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/48
 24%|â–ˆâ–ˆâ–       | 48/200 [7:18:11<22:59:31, 544.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.9694254557292
INFO:root:current train perplexity3.8867084980010986
INFO:root:current mean train loss 1713.788434103261
INFO:root:current train perplexity3.8696510791778564
INFO:root:current mean train loss 1709.7568830623184
INFO:root:current train perplexity3.861266851425171
INFO:root:current mean train loss 1717.3723512679812
INFO:root:current train perplexity3.868238687515259
INFO:root:current mean train loss 1715.706615622647
INFO:root:current train perplexity3.861349105834961
INFO:root:current mean train loss 1716.2449820805523
INFO:root:current train perplexity3.8678126335144043
INFO:root:current mean train loss 1718.1026200457318
INFO:root:current train perplexity3.870549201965332
INFO:root:current mean train loss 1714.260355659965
INFO:root:current train perplexity3.8671436309814453
INFO:root:current mean train loss 1714.36825857338
INFO:root:current train perplexity3.8683650493621826
INFO:root:current mean train loss 1715.4521073471653
INFO:root:current train perplexity3.870488405227661
INFO:root:current mean train loss 1715.889294493727
INFO:root:current train perplexity3.871828556060791
INFO:root:current mean train loss 1715.5946144548766
INFO:root:current train perplexity3.8717660903930664
INFO:root:current mean train loss 1717.3364002620242
INFO:root:current train perplexity3.874239921569824
INFO:root:current mean train loss 1717.3547586999466
INFO:root:current train perplexity3.876004695892334
INFO:root:current mean train loss 1718.5153174518275
INFO:root:current train perplexity3.8813717365264893
INFO:root:current mean train loss 1719.1195825759335
INFO:root:current train perplexity3.8833096027374268
INFO:root:current mean train loss 1718.6048205301859
INFO:root:current train perplexity3.8818414211273193
INFO:root:current mean train loss 1718.4158929140854
INFO:root:current train perplexity3.880659818649292
INFO:root:current mean train loss 1718.5310667936467
INFO:root:current train perplexity3.8807272911071777
INFO:root:current mean train loss 1718.498098125408
INFO:root:current train perplexity3.8823626041412354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it]
INFO:root:final mean train loss: 1718.2309738982524
INFO:root:final train perplexity: 3.88220477104187
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it]
INFO:root:eval mean loss: 1886.2590267100234
INFO:root:eval perplexity: 4.603020191192627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2675.9919740933897
INFO:root:eval perplexity: 9.030255317687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/49
 24%|â–ˆâ–ˆâ–       | 49/200 [7:27:07<22:44:31, 542.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.577953338623
INFO:root:current train perplexity3.8434042930603027
INFO:root:current mean train loss 1699.0559220747514
INFO:root:current train perplexity3.819676399230957
INFO:root:current mean train loss 1707.2516832022832
INFO:root:current train perplexity3.846572160720825
INFO:root:current mean train loss 1710.5985078007343
INFO:root:current train perplexity3.844034433364868
INFO:root:current mean train loss 1710.5572410866066
INFO:root:current train perplexity3.8503952026367188
INFO:root:current mean train loss 1706.1350987943492
INFO:root:current train perplexity3.846247911453247
INFO:root:current mean train loss 1708.1616112431393
INFO:root:current train perplexity3.8486764430999756
INFO:root:current mean train loss 1711.1276673697382
INFO:root:current train perplexity3.850137710571289
INFO:root:current mean train loss 1710.9879192939172
INFO:root:current train perplexity3.8515422344207764
INFO:root:current mean train loss 1712.3477176780864
INFO:root:current train perplexity3.8575010299682617
INFO:root:current mean train loss 1713.2310200772545
INFO:root:current train perplexity3.8580896854400635
INFO:root:current mean train loss 1714.5489628121204
INFO:root:current train perplexity3.861999988555908
INFO:root:current mean train loss 1715.3090068272181
INFO:root:current train perplexity3.862213611602783
INFO:root:current mean train loss 1716.109073764927
INFO:root:current train perplexity3.865496873855591
INFO:root:current mean train loss 1714.9545545524725
INFO:root:current train perplexity3.865183115005493
INFO:root:current mean train loss 1715.486678081144
INFO:root:current train perplexity3.866508960723877
INFO:root:current mean train loss 1715.2813248727837
INFO:root:current train perplexity3.8666837215423584
INFO:root:current mean train loss 1714.5532664239545
INFO:root:current train perplexity3.866800308227539
INFO:root:current mean train loss 1714.8373772233854
INFO:root:current train perplexity3.867243766784668
INFO:root:current mean train loss 1714.6734564171074
INFO:root:current train perplexity3.868265390396118

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.12s/it]
INFO:root:final mean train loss: 1713.6049443647469
INFO:root:final train perplexity: 3.8680524826049805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.10s/it]
INFO:root:eval mean loss: 1885.3329861688276
INFO:root:eval perplexity: 4.59957218170166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 2677.473093452183
INFO:root:eval perplexity: 9.041261672973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [7:36:09<22:34:54, 541.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.7441630460778
INFO:root:current train perplexity3.8451902866363525
INFO:root:current mean train loss 1701.2320032311766
INFO:root:current train perplexity3.821096420288086
INFO:root:current mean train loss 1699.722815578721
INFO:root:current train perplexity3.811511516571045
INFO:root:current mean train loss 1701.5025960053276
INFO:root:current train perplexity3.8258779048919678
INFO:root:current mean train loss 1702.0613986484723
INFO:root:current train perplexity3.828003168106079
INFO:root:current mean train loss 1704.3191024696891
INFO:root:current train perplexity3.8381738662719727
INFO:root:current mean train loss 1704.8516027512278
INFO:root:current train perplexity3.8426265716552734
INFO:root:current mean train loss 1703.9159359288947
INFO:root:current train perplexity3.843282461166382
INFO:root:current mean train loss 1703.8712221466892
INFO:root:current train perplexity3.8404159545898438
INFO:root:current mean train loss 1704.7034162193756
INFO:root:current train perplexity3.8432600498199463
INFO:root:current mean train loss 1704.5372701959454
INFO:root:current train perplexity3.8427574634552
INFO:root:current mean train loss 1705.1505124828316
INFO:root:current train perplexity3.8458728790283203
INFO:root:current mean train loss 1705.3066529395392
INFO:root:current train perplexity3.847622871398926
INFO:root:current mean train loss 1704.9956826562789
INFO:root:current train perplexity3.846174955368042
INFO:root:current mean train loss 1704.82477931305
INFO:root:current train perplexity3.845315933227539
INFO:root:current mean train loss 1705.0356566673559
INFO:root:current train perplexity3.845672130584717
INFO:root:current mean train loss 1705.793065503122
INFO:root:current train perplexity3.846925735473633
INFO:root:current mean train loss 1706.6613134402694
INFO:root:current train perplexity3.8468432426452637
INFO:root:current mean train loss 1708.0207242908962
INFO:root:current train perplexity3.8486857414245605
INFO:root:current mean train loss 1708.9896594106754
INFO:root:current train perplexity3.8510913848876953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.56s/it]
INFO:root:final mean train loss: 1708.1435203686906
INFO:root:final train perplexity: 3.851411819458008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it]
INFO:root:eval mean loss: 1887.289925216783
INFO:root:eval perplexity: 4.606863021850586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it]
INFO:root:eval mean loss: 2677.7346195734985
INFO:root:eval perplexity: 9.043206214904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [7:45:10<22:25:03, 541.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1695.7016878995028
INFO:root:current train perplexity3.8097970485687256
INFO:root:current mean train loss 1685.0316000329442
INFO:root:current train perplexity3.7755589485168457
INFO:root:current mean train loss 1697.4360195532777
INFO:root:current train perplexity3.805657386779785
INFO:root:current mean train loss 1695.3728127401382
INFO:root:current train perplexity3.8057680130004883
INFO:root:current mean train loss 1695.5188967987192
INFO:root:current train perplexity3.81005859375
INFO:root:current mean train loss 1698.4801163420661
INFO:root:current train perplexity3.8132107257843018
INFO:root:current mean train loss 1699.1366263724663
INFO:root:current train perplexity3.817531108856201
INFO:root:current mean train loss 1700.2382740787675
INFO:root:current train perplexity3.818272113800049
INFO:root:current mean train loss 1698.693325826808
INFO:root:current train perplexity3.8167619705200195
INFO:root:current mean train loss 1698.3745205644248
INFO:root:current train perplexity3.821552038192749
INFO:root:current mean train loss 1699.4223950012092
INFO:root:current train perplexity3.823496103286743
INFO:root:current mean train loss 1699.2053260345197
INFO:root:current train perplexity3.8238630294799805
INFO:root:current mean train loss 1699.57053851328
INFO:root:current train perplexity3.8249497413635254
INFO:root:current mean train loss 1698.5763007369258
INFO:root:current train perplexity3.8239986896514893
INFO:root:current mean train loss 1699.1468031234012
INFO:root:current train perplexity3.825535774230957
INFO:root:current mean train loss 1700.9962606417873
INFO:root:current train perplexity3.8313205242156982
INFO:root:current mean train loss 1701.5002126338816
INFO:root:current train perplexity3.83101224899292
INFO:root:current mean train loss 1701.4874653281604
INFO:root:current train perplexity3.831226348876953
INFO:root:current mean train loss 1702.531533260693
INFO:root:current train perplexity3.8334803581237793
INFO:root:current mean train loss 1703.0246005829572
INFO:root:current train perplexity3.834808349609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.21s/it]
INFO:root:final mean train loss: 1702.7110121703424
INFO:root:final train perplexity: 3.834930181503296
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.03s/it]
INFO:root:eval mean loss: 1886.8023153535019
INFO:root:eval perplexity: 4.605045318603516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2664.9989368628103
INFO:root:eval perplexity: 8.948990821838379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [7:54:12<22:16:24, 541.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1661.3180961149285
INFO:root:current train perplexity3.7502803802490234
INFO:root:current mean train loss 1665.7206104049267
INFO:root:current train perplexity3.770812749862671
INFO:root:current mean train loss 1676.8294656167182
INFO:root:current train perplexity3.7771453857421875
INFO:root:current mean train loss 1677.8624229331551
INFO:root:current train perplexity3.7814695835113525
INFO:root:current mean train loss 1685.9453751779245
INFO:root:current train perplexity3.792332887649536
INFO:root:current mean train loss 1686.2058658239976
INFO:root:current train perplexity3.793671131134033
INFO:root:current mean train loss 1686.9468066549232
INFO:root:current train perplexity3.7939231395721436
INFO:root:current mean train loss 1688.7383562382763
INFO:root:current train perplexity3.8004908561706543
INFO:root:current mean train loss 1689.5504842997948
INFO:root:current train perplexity3.8026537895202637
INFO:root:current mean train loss 1690.1461009028485
INFO:root:current train perplexity3.8051021099090576
INFO:root:current mean train loss 1690.5441282488962
INFO:root:current train perplexity3.8067774772644043
INFO:root:current mean train loss 1691.1764074923724
INFO:root:current train perplexity3.8089582920074463
INFO:root:current mean train loss 1693.4532732350326
INFO:root:current train perplexity3.812713384628296
INFO:root:current mean train loss 1694.1360963944155
INFO:root:current train perplexity3.813079357147217
INFO:root:current mean train loss 1695.6142124579874
INFO:root:current train perplexity3.8168609142303467
INFO:root:current mean train loss 1696.1690415498658
INFO:root:current train perplexity3.8179757595062256
INFO:root:current mean train loss 1697.125956543839
INFO:root:current train perplexity3.8187618255615234
INFO:root:current mean train loss 1697.8393913435923
INFO:root:current train perplexity3.8184053897857666
INFO:root:current mean train loss 1698.5605279453498
INFO:root:current train perplexity3.8213884830474854
INFO:root:current mean train loss 1698.3699704630471
INFO:root:current train perplexity3.8218111991882324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.77s/it]
INFO:root:final mean train loss: 1698.3699704630471
INFO:root:final train perplexity: 3.8218111991882324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it]
INFO:root:eval mean loss: 1882.9389657094969
INFO:root:eval perplexity: 4.590668201446533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2663.1487465716423
INFO:root:eval perplexity: 8.935383796691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [8:03:11<22:05:18, 540.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.3351403808595
INFO:root:current train perplexity3.7830660343170166
INFO:root:current mean train loss 1697.8582299804686
INFO:root:current train perplexity3.808732271194458
INFO:root:current mean train loss 1689.6876623535156
INFO:root:current train perplexity3.7979278564453125
INFO:root:current mean train loss 1690.5700390625
INFO:root:current train perplexity3.80157732963562
INFO:root:current mean train loss 1689.328244873047
INFO:root:current train perplexity3.800743579864502
INFO:root:current mean train loss 1689.0065207926432
INFO:root:current train perplexity3.8052313327789307
INFO:root:current mean train loss 1688.117977294922
INFO:root:current train perplexity3.8031022548675537
INFO:root:current mean train loss 1688.6359616088866
INFO:root:current train perplexity3.8020410537719727
INFO:root:current mean train loss 1689.7362489149305
INFO:root:current train perplexity3.8008155822753906
INFO:root:current mean train loss 1690.0803782958985
INFO:root:current train perplexity3.799410343170166
INFO:root:current mean train loss 1690.410645751953
INFO:root:current train perplexity3.800410270690918
INFO:root:current mean train loss 1691.8054784138997
INFO:root:current train perplexity3.8037705421447754
INFO:root:current mean train loss 1690.9956036846454
INFO:root:current train perplexity3.801643133163452
INFO:root:current mean train loss 1691.0630959647042
INFO:root:current train perplexity3.801992893218994
INFO:root:current mean train loss 1692.175285563151
INFO:root:current train perplexity3.803022861480713
INFO:root:current mean train loss 1690.5610158538818
INFO:root:current train perplexity3.802603006362915
INFO:root:current mean train loss 1691.5472320915671
INFO:root:current train perplexity3.804949998855591
INFO:root:current mean train loss 1692.5455730523004
INFO:root:current train perplexity3.805711269378662
INFO:root:current mean train loss 1692.5990480443052
INFO:root:current train perplexity3.8066728115081787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.36s/it]
INFO:root:final mean train loss: 1693.7020685654725
INFO:root:final train perplexity: 3.807753801345825
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.02s/it]
INFO:root:eval mean loss: 1888.2407183275154
INFO:root:eval perplexity: 4.610409736633301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 2658.436342929272
INFO:root:eval perplexity: 8.900826454162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:11:56<21:45:14, 536.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.6239372702205
INFO:root:current train perplexity3.7646408081054688
INFO:root:current mean train loss 1689.4304460052751
INFO:root:current train perplexity3.7852470874786377
INFO:root:current mean train loss 1681.3439114478326
INFO:root:current train perplexity3.7752532958984375
INFO:root:current mean train loss 1686.9238519999508
INFO:root:current train perplexity3.7833375930786133
INFO:root:current mean train loss 1687.1111085740783
INFO:root:current train perplexity3.783768892288208
INFO:root:current mean train loss 1685.204845317789
INFO:root:current train perplexity3.784470319747925
INFO:root:current mean train loss 1689.2592581527933
INFO:root:current train perplexity3.784897565841675
INFO:root:current mean train loss 1689.111181197971
INFO:root:current train perplexity3.7857837677001953
INFO:root:current mean train loss 1686.7838520250823
INFO:root:current train perplexity3.7833704948425293
INFO:root:current mean train loss 1687.484022100983
INFO:root:current train perplexity3.784954786300659
INFO:root:current mean train loss 1688.6066114337511
INFO:root:current train perplexity3.786618232727051
INFO:root:current mean train loss 1686.3555166164251
INFO:root:current train perplexity3.7828054428100586
INFO:root:current mean train loss 1685.588771898431
INFO:root:current train perplexity3.7844417095184326
INFO:root:current mean train loss 1685.3674612081495
INFO:root:current train perplexity3.784282922744751
INFO:root:current mean train loss 1685.697518294179
INFO:root:current train perplexity3.7855865955352783
INFO:root:current mean train loss 1686.32894609787
INFO:root:current train perplexity3.7898178100585938
INFO:root:current mean train loss 1686.4950504527094
INFO:root:current train perplexity3.791430950164795
INFO:root:current mean train loss 1687.4578469953499
INFO:root:current train perplexity3.7926900386810303
INFO:root:current mean train loss 1689.334745215005
INFO:root:current train perplexity3.79624080657959
INFO:root:current mean train loss 1689.9794995741229
INFO:root:current train perplexity3.7956697940826416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.20s/it]
INFO:root:final mean train loss: 1689.401302982086
INFO:root:final train perplexity: 3.7948482036590576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it]
INFO:root:eval mean loss: 1886.4149767287233
INFO:root:eval perplexity: 4.603601455688477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 2665.6319839802195
INFO:root:eval perplexity: 8.953651428222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [8:20:54<21:37:00, 536.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1682.866954130285
INFO:root:current train perplexity3.798757314682007
INFO:root:current mean train loss 1674.015914689249
INFO:root:current train perplexity3.757443428039551
INFO:root:current mean train loss 1673.8174845377605
INFO:root:current train perplexity3.759801149368286
INFO:root:current mean train loss 1675.289762759637
INFO:root:current train perplexity3.770571231842041
INFO:root:current mean train loss 1674.7757208336334
INFO:root:current train perplexity3.764777898788452
INFO:root:current mean train loss 1675.8166115292895
INFO:root:current train perplexity3.7634167671203613
INFO:root:current mean train loss 1676.8652640261485
INFO:root:current train perplexity3.7651100158691406
INFO:root:current mean train loss 1678.5592273847283
INFO:root:current train perplexity3.7696099281311035
INFO:root:current mean train loss 1681.4227930155876
INFO:root:current train perplexity3.774446964263916
INFO:root:current mean train loss 1681.754150390625
INFO:root:current train perplexity3.7748875617980957
INFO:root:current mean train loss 1680.6815481868427
INFO:root:current train perplexity3.7699429988861084
INFO:root:current mean train loss 1680.8118036394608
INFO:root:current train perplexity3.7694602012634277
INFO:root:current mean train loss 1681.218506947522
INFO:root:current train perplexity3.767731189727783
INFO:root:current mean train loss 1680.49477257221
INFO:root:current train perplexity3.765206813812256
INFO:root:current mean train loss 1681.4407827039477
INFO:root:current train perplexity3.768399953842163
INFO:root:current mean train loss 1682.416996564206
INFO:root:current train perplexity3.771106719970703
INFO:root:current mean train loss 1682.8788015115801
INFO:root:current train perplexity3.7723848819732666
INFO:root:current mean train loss 1683.5788103959414
INFO:root:current train perplexity3.7735633850097656
INFO:root:current mean train loss 1684.4210195094186
INFO:root:current train perplexity3.7765402793884277
INFO:root:current mean train loss 1684.1663486989603
INFO:root:current train perplexity3.776989221572876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.51s/it]
INFO:root:final mean train loss: 1683.5488488086232
INFO:root:final train perplexity: 3.7773561477661133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.89s/it]
INFO:root:eval mean loss: 1886.6608475488974
INFO:root:eval perplexity: 4.604517459869385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 2655.726899275543
INFO:root:eval perplexity: 8.881014823913574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [8:29:52<21:29:10, 537.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1680.7074070350798
INFO:root:current train perplexity3.760982036590576
INFO:root:current mean train loss 1688.7776202271316
INFO:root:current train perplexity3.7437517642974854
INFO:root:current mean train loss 1685.2271354036977
INFO:root:current train perplexity3.7415642738342285
INFO:root:current mean train loss 1678.796221176104
INFO:root:current train perplexity3.7348806858062744
INFO:root:current mean train loss 1674.9044533198794
INFO:root:current train perplexity3.7374069690704346
INFO:root:current mean train loss 1678.0026857684181
INFO:root:current train perplexity3.7477951049804688
INFO:root:current mean train loss 1677.4923483852967
INFO:root:current train perplexity3.7468159198760986
INFO:root:current mean train loss 1677.3692662712738
INFO:root:current train perplexity3.7489895820617676
INFO:root:current mean train loss 1678.0931228655625
INFO:root:current train perplexity3.7522377967834473
INFO:root:current mean train loss 1677.9272199083202
INFO:root:current train perplexity3.752972364425659
INFO:root:current mean train loss 1678.7896335939358
INFO:root:current train perplexity3.7554869651794434
INFO:root:current mean train loss 1678.1707406263574
INFO:root:current train perplexity3.7547054290771484
INFO:root:current mean train loss 1678.2571194021345
INFO:root:current train perplexity3.756129503250122
INFO:root:current mean train loss 1680.3447313513427
INFO:root:current train perplexity3.7594542503356934
INFO:root:current mean train loss 1680.6021327223143
INFO:root:current train perplexity3.762756109237671
INFO:root:current mean train loss 1681.5650394717622
INFO:root:current train perplexity3.7643089294433594
INFO:root:current mean train loss 1681.1249040295181
INFO:root:current train perplexity3.7644739151000977
INFO:root:current mean train loss 1679.7454780304113
INFO:root:current train perplexity3.7629547119140625
INFO:root:current mean train loss 1680.1359046181751
INFO:root:current train perplexity3.7641074657440186
INFO:root:current mean train loss 1679.9328705881999
INFO:root:current train perplexity3.764671802520752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.60s/it]
INFO:root:final mean train loss: 1678.963163821191
INFO:root:final train perplexity: 3.763706684112549
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.81s/it]
INFO:root:eval mean loss: 1888.117954551751
INFO:root:eval perplexity: 4.609951496124268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 2658.054328647911
INFO:root:eval perplexity: 8.898029327392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:38:34<21:09:31, 532.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1672.0200123506434
INFO:root:current train perplexity3.7584331035614014
INFO:root:current mean train loss 1663.4173649379186
INFO:root:current train perplexity3.7486042976379395
INFO:root:current mean train loss 1668.4495849609375
INFO:root:current train perplexity3.7403008937835693
INFO:root:current mean train loss 1670.3160241168478
INFO:root:current train perplexity3.738905906677246
INFO:root:current mean train loss 1670.7518493130676
INFO:root:current train perplexity3.7357869148254395
INFO:root:current mean train loss 1670.1163459025638
INFO:root:current train perplexity3.740063190460205
INFO:root:current mean train loss 1671.3566856155853
INFO:root:current train perplexity3.741837739944458
INFO:root:current mean train loss 1669.941000143687
INFO:root:current train perplexity3.737863302230835
INFO:root:current mean train loss 1671.1835407309818
INFO:root:current train perplexity3.73962140083313
INFO:root:current mean train loss 1670.2963637675136
INFO:root:current train perplexity3.7363181114196777
INFO:root:current mean train loss 1670.5234949919168
INFO:root:current train perplexity3.736889600753784
INFO:root:current mean train loss 1669.8949862963532
INFO:root:current train perplexity3.7378907203674316
INFO:root:current mean train loss 1670.4097036849062
INFO:root:current train perplexity3.7409465312957764
INFO:root:current mean train loss 1670.6413598311574
INFO:root:current train perplexity3.7409207820892334
INFO:root:current mean train loss 1671.6812325043638
INFO:root:current train perplexity3.743886947631836
INFO:root:current mean train loss 1672.5125447487344
INFO:root:current train perplexity3.7458338737487793
INFO:root:current mean train loss 1672.6524620879468
INFO:root:current train perplexity3.7482552528381348
INFO:root:current mean train loss 1673.4488393516024
INFO:root:current train perplexity3.749748945236206
INFO:root:current mean train loss 1674.0411989918614
INFO:root:current train perplexity3.748462677001953
INFO:root:current mean train loss 1674.655449719933
INFO:root:current train perplexity3.7491343021392822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.28s/it]
INFO:root:final mean train loss: 1674.2695176148138
INFO:root:final train perplexity: 3.7497873306274414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it]
INFO:root:eval mean loss: 1884.301855209026
INFO:root:eval perplexity: 4.595734596252441
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2666.669440086852
INFO:root:eval perplexity: 8.96129035949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:47:32<21:04:20, 534.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1661.866858628217
INFO:root:current train perplexity3.724616765975952
INFO:root:current mean train loss 1664.3020897117822
INFO:root:current train perplexity3.7209980487823486
INFO:root:current mean train loss 1661.8844807942708
INFO:root:current train perplexity3.7265236377716064
INFO:root:current mean train loss 1663.964540635146
INFO:root:current train perplexity3.7219619750976562
INFO:root:current mean train loss 1663.2497825386597
INFO:root:current train perplexity3.725836992263794
INFO:root:current mean train loss 1665.052099400708
INFO:root:current train perplexity3.7234132289886475
INFO:root:current mean train loss 1666.662314488766
INFO:root:current train perplexity3.728945255279541
INFO:root:current mean train loss 1667.1814437574642
INFO:root:current train perplexity3.7353932857513428
INFO:root:current mean train loss 1668.9220366569562
INFO:root:current train perplexity3.738300323486328
INFO:root:current mean train loss 1670.5059788427982
INFO:root:current train perplexity3.7432899475097656
INFO:root:current mean train loss 1671.4025333246327
INFO:root:current train perplexity3.7445592880249023
INFO:root:current mean train loss 1673.013273214992
INFO:root:current train perplexity3.7457480430603027
INFO:root:current mean train loss 1671.5516346972277
INFO:root:current train perplexity3.74104905128479
INFO:root:current mean train loss 1671.4366381924076
INFO:root:current train perplexity3.741537570953369
INFO:root:current mean train loss 1671.4173458214962
INFO:root:current train perplexity3.741560697555542
INFO:root:current mean train loss 1670.6392484165517
INFO:root:current train perplexity3.739595651626587
INFO:root:current mean train loss 1671.8519625428876
INFO:root:current train perplexity3.741361379623413
INFO:root:current mean train loss 1672.4162632533482
INFO:root:current train perplexity3.741719961166382
INFO:root:current mean train loss 1672.9741248497596
INFO:root:current train perplexity3.741442918777466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.26s/it]
INFO:root:final mean train loss: 1671.2302251326214
INFO:root:final train perplexity: 3.7408015727996826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.89s/it]
INFO:root:eval mean loss: 1883.34592908494
INFO:root:eval perplexity: 4.592180252075195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2659.12916857131
INFO:root:eval perplexity: 8.90589714050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [8:56:21<20:51:51, 532.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1622.147216796875
INFO:root:current train perplexity3.6916615962982178
INFO:root:current mean train loss 1668.0522700291053
INFO:root:current train perplexity3.710211992263794
INFO:root:current mean train loss 1662.820841269918
INFO:root:current train perplexity3.7132046222686768
INFO:root:current mean train loss 1664.5350657077815
INFO:root:current train perplexity3.712736129760742
INFO:root:current mean train loss 1662.903418090213
INFO:root:current train perplexity3.7064836025238037
INFO:root:current mean train loss 1667.4283172485839
INFO:root:current train perplexity3.7179195880889893
INFO:root:current mean train loss 1668.0181613047653
INFO:root:current train perplexity3.7183685302734375
INFO:root:current mean train loss 1670.1651919112246
INFO:root:current train perplexity3.7238805294036865
INFO:root:current mean train loss 1667.1876203960314
INFO:root:current train perplexity3.7224082946777344
INFO:root:current mean train loss 1666.9201558656544
INFO:root:current train perplexity3.723933458328247
INFO:root:current mean train loss 1667.2919891418335
INFO:root:current train perplexity3.7250494956970215
INFO:root:current mean train loss 1667.7057927126461
INFO:root:current train perplexity3.7258641719818115
INFO:root:current mean train loss 1667.1101439820352
INFO:root:current train perplexity3.7251553535461426
INFO:root:current mean train loss 1666.7222912578904
INFO:root:current train perplexity3.726438522338867
INFO:root:current mean train loss 1665.6577514996711
INFO:root:current train perplexity3.726395845413208
INFO:root:current mean train loss 1667.2549684730257
INFO:root:current train perplexity3.727633237838745
INFO:root:current mean train loss 1667.8451526656133
INFO:root:current train perplexity3.7294399738311768
INFO:root:current mean train loss 1667.6251879108218
INFO:root:current train perplexity3.729914903640747
INFO:root:current mean train loss 1667.4635987953923
INFO:root:current train perplexity3.728785991668701
INFO:root:current mean train loss 1667.3062774947014
INFO:root:current train perplexity3.727437734603882

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.03s/it]
INFO:root:final mean train loss: 1666.7069215529264
INFO:root:final train perplexity: 3.7274670600891113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.68s/it]
INFO:root:eval mean loss: 1889.7279823249114
INFO:root:eval perplexity: 4.615962505340576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 2659.2411892938276
INFO:root:eval perplexity: 8.906719207763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [9:05:23<20:49:07, 535.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.9055368523848
INFO:root:current train perplexity3.6499922275543213
INFO:root:current mean train loss 1648.3218553046217
INFO:root:current train perplexity3.6900200843811035
INFO:root:current mean train loss 1665.932754307577
INFO:root:current train perplexity3.7227625846862793
INFO:root:current mean train loss 1663.1265681634502
INFO:root:current train perplexity3.727405548095703
INFO:root:current mean train loss 1667.877236304818
INFO:root:current train perplexity3.729094982147217
INFO:root:current mean train loss 1665.0187569620064
INFO:root:current train perplexity3.7220795154571533
INFO:root:current mean train loss 1663.0114888081835
INFO:root:current train perplexity3.7148780822753906
INFO:root:current mean train loss 1663.316518473194
INFO:root:current train perplexity3.715738296508789
INFO:root:current mean train loss 1661.8272351834364
INFO:root:current train perplexity3.713468313217163
INFO:root:current mean train loss 1662.059653862257
INFO:root:current train perplexity3.7122790813446045
INFO:root:current mean train loss 1662.8699093445243
INFO:root:current train perplexity3.712392807006836
INFO:root:current mean train loss 1662.6676639560294
INFO:root:current train perplexity3.7113046646118164
INFO:root:current mean train loss 1663.1231016514241
INFO:root:current train perplexity3.7126986980438232
INFO:root:current mean train loss 1662.37486265933
INFO:root:current train perplexity3.7123820781707764
INFO:root:current mean train loss 1662.227775460822
INFO:root:current train perplexity3.7123193740844727
INFO:root:current mean train loss 1661.7592797546185
INFO:root:current train perplexity3.7115063667297363
INFO:root:current mean train loss 1661.9792659917387
INFO:root:current train perplexity3.7098731994628906
INFO:root:current mean train loss 1663.396431612788
INFO:root:current train perplexity3.7130038738250732
INFO:root:current mean train loss 1663.8875329771038
INFO:root:current train perplexity3.713887929916382
INFO:root:current mean train loss 1663.0354052887042
INFO:root:current train perplexity3.713801622390747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.98s/it]
INFO:root:final mean train loss: 1661.7122717168195
INFO:root:final train perplexity: 3.712799549102783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it]
INFO:root:eval mean loss: 1888.2790211346132
INFO:root:eval perplexity: 4.61055326461792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2665.895199606605
INFO:root:eval perplexity: 8.955587387084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [9:14:17<20:39:20, 534.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.3429022894966
INFO:root:current train perplexity3.7573280334472656
INFO:root:current mean train loss 1641.2263623405906
INFO:root:current train perplexity3.675240993499756
INFO:root:current mean train loss 1655.7785608323954
INFO:root:current train perplexity3.7048544883728027
INFO:root:current mean train loss 1655.7099816458565
INFO:root:current train perplexity3.709958553314209
INFO:root:current mean train loss 1656.7078857421875
INFO:root:current train perplexity3.700416326522827
INFO:root:current mean train loss 1655.802952097423
INFO:root:current train perplexity3.6988096237182617
INFO:root:current mean train loss 1656.044054523204
INFO:root:current train perplexity3.7014594078063965
INFO:root:current mean train loss 1656.3810811250107
INFO:root:current train perplexity3.7023026943206787
INFO:root:current mean train loss 1654.020414215526
INFO:root:current train perplexity3.6987996101379395
INFO:root:current mean train loss 1654.3514283009065
INFO:root:current train perplexity3.6969096660614014
INFO:root:current mean train loss 1653.9268977927425
INFO:root:current train perplexity3.696307897567749
INFO:root:current mean train loss 1655.311526338819
INFO:root:current train perplexity3.697298049926758
INFO:root:current mean train loss 1655.8517936039898
INFO:root:current train perplexity3.698326826095581
INFO:root:current mean train loss 1656.6134398683103
INFO:root:current train perplexity3.6993069648742676
INFO:root:current mean train loss 1656.8263425694204
INFO:root:current train perplexity3.698580741882324
INFO:root:current mean train loss 1657.1606182257335
INFO:root:current train perplexity3.6977555751800537
INFO:root:current mean train loss 1657.9988745803646
INFO:root:current train perplexity3.7002415657043457
INFO:root:current mean train loss 1658.3811915525093
INFO:root:current train perplexity3.7018158435821533
INFO:root:current mean train loss 1659.10894423009
INFO:root:current train perplexity3.702158212661743
INFO:root:current mean train loss 1658.7845895940607
INFO:root:current train perplexity3.7026402950286865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.82s/it]
INFO:root:final mean train loss: 1658.0441073342158
INFO:root:final train perplexity: 3.702063798904419
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.51s/it]
INFO:root:eval mean loss: 1885.2472542837156
INFO:root:eval perplexity: 4.599252223968506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it]
INFO:root:eval mean loss: 2664.749119968279
INFO:root:eval perplexity: 8.947153091430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [9:23:17<20:34:07, 536.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.0798685325767
INFO:root:current train perplexity3.686342716217041
INFO:root:current mean train loss 1648.2941870595894
INFO:root:current train perplexity3.673027753829956
INFO:root:current mean train loss 1650.308375663908
INFO:root:current train perplexity3.679048776626587
INFO:root:current mean train loss 1652.6221920370042
INFO:root:current train perplexity3.6864209175109863
INFO:root:current mean train loss 1651.297484273679
INFO:root:current train perplexity3.6768155097961426
INFO:root:current mean train loss 1652.8551179910007
INFO:root:current train perplexity3.6787383556365967
INFO:root:current mean train loss 1653.1925860137706
INFO:root:current train perplexity3.6811459064483643
INFO:root:current mean train loss 1656.6287793163285
INFO:root:current train perplexity3.689345598220825
INFO:root:current mean train loss 1657.411303539209
INFO:root:current train perplexity3.693769693374634
INFO:root:current mean train loss 1656.3187606827535
INFO:root:current train perplexity3.691237688064575
INFO:root:current mean train loss 1655.6630249603068
INFO:root:current train perplexity3.6910784244537354
INFO:root:current mean train loss 1653.8696530450454
INFO:root:current train perplexity3.6871821880340576
INFO:root:current mean train loss 1653.9123652063174
INFO:root:current train perplexity3.6889116764068604
INFO:root:current mean train loss 1653.7181488510776
INFO:root:current train perplexity3.6901769638061523
INFO:root:current mean train loss 1654.7530549502915
INFO:root:current train perplexity3.690401315689087
INFO:root:current mean train loss 1655.4485592716214
INFO:root:current train perplexity3.69040584564209
INFO:root:current mean train loss 1655.103325762463
INFO:root:current train perplexity3.690037488937378
INFO:root:current mean train loss 1654.1175364414353
INFO:root:current train perplexity3.6887331008911133
INFO:root:current mean train loss 1654.4044105789176
INFO:root:current train perplexity3.6902527809143066
INFO:root:current mean train loss 1654.2295508162522
INFO:root:current train perplexity3.6912105083465576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.80s/it]
INFO:root:final mean train loss: 1654.2983209453205
INFO:root:final train perplexity: 3.6911330223083496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.26s/it]
INFO:root:eval mean loss: 1887.24787112838
INFO:root:eval perplexity: 4.606705665588379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 2658.5491276734265
INFO:root:eval perplexity: 8.901651382446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [9:32:23<20:31:12, 539.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1625.4050920758928
INFO:root:current train perplexity3.639671802520752
INFO:root:current mean train loss 1631.033205279182
INFO:root:current train perplexity3.644880771636963
INFO:root:current mean train loss 1641.2687242296006
INFO:root:current train perplexity3.676168203353882
INFO:root:current mean train loss 1646.9746687605575
INFO:root:current train perplexity3.6895079612731934
INFO:root:current mean train loss 1649.18974609375
INFO:root:current train perplexity3.6862964630126953
INFO:root:current mean train loss 1647.697332870751
INFO:root:current train perplexity3.675708532333374
INFO:root:current mean train loss 1648.9519175970731
INFO:root:current train perplexity3.6791887283325195
INFO:root:current mean train loss 1647.4397546545251
INFO:root:current train perplexity3.6781630516052246
INFO:root:current mean train loss 1648.6473740851743
INFO:root:current train perplexity3.678719997406006
INFO:root:current mean train loss 1648.5234025149002
INFO:root:current train perplexity3.6758110523223877
INFO:root:current mean train loss 1649.4551375629746
INFO:root:current train perplexity3.6774370670318604
INFO:root:current mean train loss 1649.774991340311
INFO:root:current train perplexity3.675602436065674
INFO:root:current mean train loss 1649.532750984252
INFO:root:current train perplexity3.6738436222076416
INFO:root:current mean train loss 1650.0979591091184
INFO:root:current train perplexity3.6756703853607178
INFO:root:current mean train loss 1649.146797688802
INFO:root:current train perplexity3.6765730381011963
INFO:root:current mean train loss 1649.3392837038466
INFO:root:current train perplexity3.676814556121826
INFO:root:current mean train loss 1649.4455934810067
INFO:root:current train perplexity3.6768198013305664
INFO:root:current mean train loss 1649.827548235015
INFO:root:current train perplexity3.6783359050750732
INFO:root:current mean train loss 1650.271893865412
INFO:root:current train perplexity3.67848801612854
INFO:root:current mean train loss 1650.2104630368615
INFO:root:current train perplexity3.6784043312072754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.32s/it]
INFO:root:final mean train loss: 1649.8538706938666
INFO:root:final train perplexity: 3.6782052516937256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it]
INFO:root:eval mean loss: 1885.658132566628
INFO:root:eval perplexity: 4.600782871246338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2668.583188320728
INFO:root:eval perplexity: 8.97540283203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:41:11<20:15:03, 536.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1638.04296875
INFO:root:current train perplexity3.614187002182007
INFO:root:current mean train loss 1633.4500725894052
INFO:root:current train perplexity3.6095049381256104
INFO:root:current mean train loss 1635.1213731931891
INFO:root:current train perplexity3.626460552215576
INFO:root:current mean train loss 1639.0483622390786
INFO:root:current train perplexity3.64048433303833
INFO:root:current mean train loss 1639.6912568579953
INFO:root:current train perplexity3.6453192234039307
INFO:root:current mean train loss 1640.6200404516476
INFO:root:current train perplexity3.6455912590026855
INFO:root:current mean train loss 1641.4980482964884
INFO:root:current train perplexity3.6456029415130615
INFO:root:current mean train loss 1642.6360562820144
INFO:root:current train perplexity3.6483700275421143
INFO:root:current mean train loss 1642.3602387128312
INFO:root:current train perplexity3.6507885456085205
INFO:root:current mean train loss 1643.1516146674344
INFO:root:current train perplexity3.6566507816314697
INFO:root:current mean train loss 1642.7395243008639
INFO:root:current train perplexity3.6593780517578125
INFO:root:current mean train loss 1643.03715071642
INFO:root:current train perplexity3.6595664024353027
INFO:root:current mean train loss 1643.2951952290332
INFO:root:current train perplexity3.661113739013672
INFO:root:current mean train loss 1643.6131496745732
INFO:root:current train perplexity3.6630940437316895
INFO:root:current mean train loss 1643.6778640798377
INFO:root:current train perplexity3.6658389568328857
INFO:root:current mean train loss 1643.8121933242999
INFO:root:current train perplexity3.665681838989258
INFO:root:current mean train loss 1643.4166455136012
INFO:root:current train perplexity3.6653902530670166
INFO:root:current mean train loss 1644.9613439456405
INFO:root:current train perplexity3.666285753250122
INFO:root:current mean train loss 1645.0929114215894
INFO:root:current train perplexity3.666254997253418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.76s/it]
INFO:root:final mean train loss: 1646.0482002908511
INFO:root:final train perplexity: 3.6671717166900635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.47s/it]
INFO:root:eval mean loss: 1887.7636571573028
INFO:root:eval perplexity: 4.6086297035217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2670.30957161112
INFO:root:eval perplexity: 8.988155364990234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [9:49:55<19:57:37, 532.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1546.2363586425781
INFO:root:current train perplexity3.483268976211548
INFO:root:current mean train loss 1640.779812152569
INFO:root:current train perplexity3.6448442935943604
INFO:root:current mean train loss 1642.2249480602788
INFO:root:current train perplexity3.6519460678100586
INFO:root:current mean train loss 1638.956647772538
INFO:root:current train perplexity3.6488163471221924
INFO:root:current mean train loss 1635.3880143873762
INFO:root:current train perplexity3.6413955688476562
INFO:root:current mean train loss 1637.2992611839659
INFO:root:current train perplexity3.646656036376953
INFO:root:current mean train loss 1639.4275245919132
INFO:root:current train perplexity3.6492114067077637
INFO:root:current mean train loss 1639.823297327215
INFO:root:current train perplexity3.6471195220947266
INFO:root:current mean train loss 1640.0492811819806
INFO:root:current train perplexity3.6500566005706787
INFO:root:current mean train loss 1641.1764904461077
INFO:root:current train perplexity3.6499083042144775
INFO:root:current mean train loss 1641.7425713406142
INFO:root:current train perplexity3.650780439376831
INFO:root:current mean train loss 1641.3584687606149
INFO:root:current train perplexity3.652580738067627
INFO:root:current mean train loss 1642.4465200227755
INFO:root:current train perplexity3.655198574066162
INFO:root:current mean train loss 1643.0938314426164
INFO:root:current train perplexity3.6556413173675537
INFO:root:current mean train loss 1642.7876751239482
INFO:root:current train perplexity3.6555237770080566
INFO:root:current mean train loss 1642.6476123890977
INFO:root:current train perplexity3.6538991928100586
INFO:root:current mean train loss 1640.4207023944045
INFO:root:current train perplexity3.6518380641937256
INFO:root:current mean train loss 1641.8699513466704
INFO:root:current train perplexity3.654172658920288
INFO:root:current mean train loss 1642.7326895635567
INFO:root:current train perplexity3.6550393104553223
INFO:root:current mean train loss 1642.395621099392
INFO:root:current train perplexity3.656379222869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.06s/it]
INFO:root:final mean train loss: 1642.4394494007167
INFO:root:final train perplexity: 3.6567392349243164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.04s/it]
INFO:root:eval mean loss: 1884.8454654774766
INFO:root:eval perplexity: 4.597756385803223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2666.3124619071364
INFO:root:eval perplexity: 8.958658218383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [9:59:02<19:59:03, 536.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1675.424781436012
INFO:root:current train perplexity3.6642918586730957
INFO:root:current mean train loss 1652.275121263236
INFO:root:current train perplexity3.6396312713623047
INFO:root:current mean train loss 1643.8617981785562
INFO:root:current train perplexity3.6338319778442383
INFO:root:current mean train loss 1646.903241594261
INFO:root:current train perplexity3.643481969833374
INFO:root:current mean train loss 1646.8929562240203
INFO:root:current train perplexity3.652888774871826
INFO:root:current mean train loss 1639.9197196740793
INFO:root:current train perplexity3.643968343734741
INFO:root:current mean train loss 1642.3204953106128
INFO:root:current train perplexity3.648158311843872
INFO:root:current mean train loss 1641.4464209526157
INFO:root:current train perplexity3.6483774185180664
INFO:root:current mean train loss 1639.0327746150845
INFO:root:current train perplexity3.6482901573181152
INFO:root:current mean train loss 1639.2560840320898
INFO:root:current train perplexity3.649017333984375
INFO:root:current mean train loss 1638.4515015007116
INFO:root:current train perplexity3.645137071609497
INFO:root:current mean train loss 1636.3670645585346
INFO:root:current train perplexity3.6421382427215576
INFO:root:current mean train loss 1636.5137024675598
INFO:root:current train perplexity3.640352964401245
INFO:root:current mean train loss 1636.9141446502708
INFO:root:current train perplexity3.6410348415374756
INFO:root:current mean train loss 1637.0411554775467
INFO:root:current train perplexity3.6414992809295654
INFO:root:current mean train loss 1637.9785039877906
INFO:root:current train perplexity3.6423180103302
INFO:root:current mean train loss 1638.475804775457
INFO:root:current train perplexity3.643838405609131
INFO:root:current mean train loss 1639.3895259416083
INFO:root:current train perplexity3.645016670227051
INFO:root:current mean train loss 1638.4887539121491
INFO:root:current train perplexity3.6438562870025635
INFO:root:current mean train loss 1638.2793105372161
INFO:root:current train perplexity3.6440529823303223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.17s/it]
INFO:root:final mean train loss: 1638.2214380399903
INFO:root:final train perplexity: 3.6445834636688232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.35s/it]
INFO:root:eval mean loss: 1890.036257480053
INFO:root:eval perplexity: 4.617115020751953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.02s/it]
INFO:root:eval mean loss: 2671.639909893063
INFO:root:eval perplexity: 8.997994422912598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [10:08:02<19:51:40, 537.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1632.7945460269325
INFO:root:current train perplexity3.628293991088867
INFO:root:current mean train loss 1634.3622613436935
INFO:root:current train perplexity3.6383659839630127
INFO:root:current mean train loss 1630.9456012629662
INFO:root:current train perplexity3.639047861099243
INFO:root:current mean train loss 1630.568297978689
INFO:root:current train perplexity3.634819269180298
INFO:root:current mean train loss 1634.0541362326983
INFO:root:current train perplexity3.631312131881714
INFO:root:current mean train loss 1633.8972782858243
INFO:root:current train perplexity3.628870725631714
INFO:root:current mean train loss 1631.8190372670333
INFO:root:current train perplexity3.6239285469055176
INFO:root:current mean train loss 1632.58119627583
INFO:root:current train perplexity3.625281810760498
INFO:root:current mean train loss 1633.2358825246588
INFO:root:current train perplexity3.626793384552002
INFO:root:current mean train loss 1634.8839167287863
INFO:root:current train perplexity3.627730131149292
INFO:root:current mean train loss 1634.2393308430048
INFO:root:current train perplexity3.626406192779541
INFO:root:current mean train loss 1634.5924908951422
INFO:root:current train perplexity3.6307904720306396
INFO:root:current mean train loss 1634.0735386862316
INFO:root:current train perplexity3.6287789344787598
INFO:root:current mean train loss 1633.616081112347
INFO:root:current train perplexity3.6284921169281006
INFO:root:current mean train loss 1635.09900691811
INFO:root:current train perplexity3.6317965984344482
INFO:root:current mean train loss 1634.3599924948187
INFO:root:current train perplexity3.6307904720306396
INFO:root:current mean train loss 1635.0336064488897
INFO:root:current train perplexity3.633211612701416
INFO:root:current mean train loss 1634.7545030459985
INFO:root:current train perplexity3.633866310119629
INFO:root:current mean train loss 1635.0063918220594
INFO:root:current train perplexity3.633638858795166
INFO:root:current mean train loss 1635.1123345437065
INFO:root:current train perplexity3.6341872215270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.33s/it]
INFO:root:final mean train loss: 1634.8564496831466
INFO:root:final train perplexity: 3.6349151134490967
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it]
INFO:root:eval mean loss: 1888.8854963153813
INFO:root:eval perplexity: 4.612817287445068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.03s/it]
INFO:root:eval mean loss: 2666.059907088043
INFO:root:eval perplexity: 8.95680046081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [10:17:02<19:44:50, 538.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1627.0140735973011
INFO:root:current train perplexity3.5966901779174805
INFO:root:current mean train loss 1628.2817264679938
INFO:root:current train perplexity3.6036789417266846
INFO:root:current mean train loss 1621.5534155752146
INFO:root:current train perplexity3.596010208129883
INFO:root:current mean train loss 1626.5653867049955
INFO:root:current train perplexity3.607454776763916
INFO:root:current mean train loss 1629.4733250879979
INFO:root:current train perplexity3.604417562484741
INFO:root:current mean train loss 1628.9769480662303
INFO:root:current train perplexity3.6131367683410645
INFO:root:current mean train loss 1628.5829595434757
INFO:root:current train perplexity3.6136093139648438
INFO:root:current mean train loss 1626.982367873034
INFO:root:current train perplexity3.6169209480285645
INFO:root:current mean train loss 1628.4749538845485
INFO:root:current train perplexity3.617147207260132
INFO:root:current mean train loss 1628.8612267619028
INFO:root:current train perplexity3.6157021522521973
INFO:root:current mean train loss 1629.4423382655139
INFO:root:current train perplexity3.616572856903076
INFO:root:current mean train loss 1628.6916335861404
INFO:root:current train perplexity3.6161956787109375
INFO:root:current mean train loss 1628.6028805675735
INFO:root:current train perplexity3.616579294204712
INFO:root:current mean train loss 1628.7549595681503
INFO:root:current train perplexity3.6161017417907715
INFO:root:current mean train loss 1629.5089095387673
INFO:root:current train perplexity3.6185882091522217
INFO:root:current mean train loss 1629.8939113212168
INFO:root:current train perplexity3.6197004318237305
INFO:root:current mean train loss 1629.9389697855693
INFO:root:current train perplexity3.6199097633361816
INFO:root:current mean train loss 1629.864840341769
INFO:root:current train perplexity3.619218349456787
INFO:root:current mean train loss 1629.2302623162693
INFO:root:current train perplexity3.6177573204040527
INFO:root:current mean train loss 1629.9804553253875
INFO:root:current train perplexity3.6187379360198975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.40s/it]
INFO:root:final mean train loss: 1629.2742836818031
INFO:root:final train perplexity: 3.618932008743286
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.87s/it]
INFO:root:eval mean loss: 1895.263357176003
INFO:root:eval perplexity: 4.63668966293335
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it]
INFO:root:eval mean loss: 2675.8383546653367
INFO:root:eval perplexity: 9.029118537902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [10:25:46<19:26:04, 534.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.3890160454644
INFO:root:current train perplexity3.573563814163208
INFO:root:current mean train loss 1616.064775333848
INFO:root:current train perplexity3.5674095153808594
INFO:root:current mean train loss 1625.2410000071807
INFO:root:current train perplexity3.600693941116333
INFO:root:current mean train loss 1625.576163015058
INFO:root:current train perplexity3.5960166454315186
INFO:root:current mean train loss 1622.9832238666081
INFO:root:current train perplexity3.5959091186523438
INFO:root:current mean train loss 1622.9309344525104
INFO:root:current train perplexity3.592015027999878
INFO:root:current mean train loss 1622.7550998869397
INFO:root:current train perplexity3.597128391265869
INFO:root:current mean train loss 1620.7205766272668
INFO:root:current train perplexity3.59409499168396
INFO:root:current mean train loss 1619.3625965643366
INFO:root:current train perplexity3.5924878120422363
INFO:root:current mean train loss 1619.2388706285767
INFO:root:current train perplexity3.5886149406433105
INFO:root:current mean train loss 1618.0142806323606
INFO:root:current train perplexity3.5869333744049072
INFO:root:current mean train loss 1620.6463477229095
INFO:root:current train perplexity3.59153413772583
INFO:root:current mean train loss 1622.3598304604584
INFO:root:current train perplexity3.592705011367798
INFO:root:current mean train loss 1622.9359164668938
INFO:root:current train perplexity3.590756893157959
INFO:root:current mean train loss 1620.2735438968825
INFO:root:current train perplexity3.5873968601226807
INFO:root:current mean train loss 1619.6473790137215
INFO:root:current train perplexity3.5864408016204834
INFO:root:current mean train loss 1618.8544429797305
INFO:root:current train perplexity3.5851802825927734
INFO:root:current mean train loss 1618.4064079611887
INFO:root:current train perplexity3.586728572845459
INFO:root:current mean train loss 1619.0911386603982
INFO:root:current train perplexity3.5885045528411865
INFO:root:current mean train loss 1619.274486797093
INFO:root:current train perplexity3.5891835689544678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.52s/it]
INFO:root:final mean train loss: 1618.847163813558
INFO:root:final train perplexity: 3.589265823364258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.58s/it]
INFO:root:eval mean loss: 1889.0674139793882
INFO:root:eval perplexity: 4.613495826721191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 2702.762166341146
INFO:root:eval perplexity: 9.231252670288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: mpnet_gpt2_not_concat_1e-5/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [10:34:44<19:19:50, 535.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.8189313224193
INFO:root:current train perplexity3.560145378112793
slurmstepd: error: *** JOB 29928011 ON ga015 CANCELLED AT 2023-02-08T03:15:57 ***
