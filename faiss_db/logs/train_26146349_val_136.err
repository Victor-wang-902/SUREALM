INFO:root:Output: small_val_136
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24455.797328756315
INFO:root:current train perplexity15506.083984375
INFO:root:current mean train loss 20545.02904660019
INFO:root:current train perplexity3284.718994140625
INFO:root:current mean train loss 17751.718240489132
INFO:root:current train perplexity1095.2373046875
INFO:root:current mean train loss 15857.084219337406
INFO:root:current train perplexity514.5716552734375
INFO:root:current mean train loss 14483.94295818199
INFO:root:current train perplexity299.48406982421875
INFO:root:current mean train loss 13439.321926518156
INFO:root:current train perplexity199.0333251953125
INFO:root:current mean train loss 12628.169710216604
INFO:root:current train perplexity144.5491943359375
INFO:root:current mean train loss 11976.940803079044
INFO:root:current train perplexity112.0889892578125
INFO:root:current mean train loss 11444.052111938612
INFO:root:current train perplexity90.89595794677734


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.31s/it]
INFO:root:final mean train loss: 11014.306119734241
INFO:root:final train perplexity: 77.12772369384766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 6413.12196988586
INFO:root:eval perplexity: 13.373543739318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/1

  0%|          | 1/200 [04:29<14:54:49, 269.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6823.911760602678
INFO:root:current train perplexity14.512276649475098
INFO:root:current mean train loss 6731.1618948963205
INFO:root:current train perplexity14.398859977722168
INFO:root:current mean train loss 6703.525345806915
INFO:root:current train perplexity14.166069030761719
INFO:root:current mean train loss 6630.78952692386
INFO:root:current train perplexity13.740428924560547
INFO:root:current mean train loss 6577.862407862408
INFO:root:current train perplexity13.443753242492676
INFO:root:current mean train loss 6527.954450197239
INFO:root:current train perplexity13.174056053161621
INFO:root:current mean train loss 6485.053413303131
INFO:root:current train perplexity12.902384757995605
INFO:root:current mean train loss 6437.6978188262465
INFO:root:current train perplexity12.66230297088623
INFO:root:current mean train loss 6393.390792600875
INFO:root:current train perplexity12.435730934143066
INFO:root:current mean train loss 6349.132983694529
INFO:root:current train perplexity12.232772827148438


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.65s/it]
INFO:root:final mean train loss: 6312.229764261553
INFO:root:final train perplexity: 12.065587997436523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it]
INFO:root:eval mean loss: 5543.303520473182
INFO:root:eval perplexity: 9.4078950881958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/2

  1%|          | 2/200 [08:43<14:18:25, 260.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5990.934440104166
INFO:root:current train perplexity10.653631210327148
INFO:root:current mean train loss 5884.577212126359
INFO:root:current train perplexity10.25207233428955
INFO:root:current mean train loss 5862.603174963663
INFO:root:current train perplexity10.112412452697754
INFO:root:current mean train loss 5842.188140190972
INFO:root:current train perplexity9.998543739318848
INFO:root:current mean train loss 5818.313421263178
INFO:root:current train perplexity9.910561561584473
INFO:root:current mean train loss 5792.995446184769
INFO:root:current train perplexity9.824384689331055
INFO:root:current mean train loss 5767.636236820376
INFO:root:current train perplexity9.741938591003418
INFO:root:current mean train loss 5748.989265324519
INFO:root:current train perplexity9.664619445800781
INFO:root:current mean train loss 5735.817366636311
INFO:root:current train perplexity9.593647956848145
INFO:root:current mean train loss 5716.66819448002
INFO:root:current train perplexity9.508737564086914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.61s/it]
INFO:root:final mean train loss: 5693.263959946171
INFO:root:final train perplexity: 9.451348304748535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 5179.97763948914
INFO:root:eval perplexity: 8.122441291809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/3

  2%|â–         | 3/200 [13:30<14:55:27, 272.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5567.222465183424
INFO:root:current train perplexity8.829510688781738
INFO:root:current mean train loss 5487.511647294207
INFO:root:current train perplexity8.724695205688477
INFO:root:current mean train loss 5486.89773244815
INFO:root:current train perplexity8.665731430053711
INFO:root:current mean train loss 5459.450447767512
INFO:root:current train perplexity8.583152770996094
INFO:root:current mean train loss 5446.872504340277
INFO:root:current train perplexity8.558165550231934
INFO:root:current mean train loss 5430.287838529219
INFO:root:current train perplexity8.50358772277832
INFO:root:current mean train loss 5420.373102521819
INFO:root:current train perplexity8.470624923706055
INFO:root:current mean train loss 5410.102953730117
INFO:root:current train perplexity8.434244155883789
INFO:root:current mean train loss 5399.222119318613
INFO:root:current train perplexity8.397704124450684
INFO:root:current mean train loss 5388.379277089823
INFO:root:current train perplexity8.362215995788574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.13s/it]
INFO:root:final mean train loss: 5377.177572804113
INFO:root:final train perplexity: 8.343243598937988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it]
INFO:root:eval mean loss: 4959.275040863254
INFO:root:eval perplexity: 7.428956508636475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/4

  2%|â–         | 4/200 [18:11<15:00:33, 275.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5320.909526209677
INFO:root:current train perplexity7.970184803009033
INFO:root:current mean train loss 5239.932020813454
INFO:root:current train perplexity7.882610321044922
INFO:root:current mean train loss 5242.552347554789
INFO:root:current train perplexity7.90536642074585
INFO:root:current mean train loss 5232.713194510007
INFO:root:current train perplexity7.861732006072998
INFO:root:current mean train loss 5226.202705825841
INFO:root:current train perplexity7.829736232757568
INFO:root:current mean train loss 5216.308871454214
INFO:root:current train perplexity7.80164909362793
INFO:root:current mean train loss 5208.253821129655
INFO:root:current train perplexity7.775903701782227
INFO:root:current mean train loss 5200.341982568827
INFO:root:current train perplexity7.759939193725586
INFO:root:current mean train loss 5187.11283174921
INFO:root:current train perplexity7.73543643951416
INFO:root:current mean train loss 5179.222284401014
INFO:root:current train perplexity7.706358909606934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.04s/it]
INFO:root:final mean train loss: 5169.806705967073
INFO:root:final train perplexity: 7.687828063964844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 4819.591779560062
INFO:root:eval perplexity: 7.020970344543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/5

  2%|â–Ž         | 5/200 [23:10<15:23:23, 284.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5078.094075520833
INFO:root:current train perplexity7.332457542419434
INFO:root:current mean train loss 5070.772805193345
INFO:root:current train perplexity7.3955488204956055
INFO:root:current mean train loss 5077.166865520398
INFO:root:current train perplexity7.402144908905029
INFO:root:current mean train loss 5060.680446568492
INFO:root:current train perplexity7.34181547164917
INFO:root:current mean train loss 5058.362627242312
INFO:root:current train perplexity7.331684112548828
INFO:root:current mean train loss 5045.902154416454
INFO:root:current train perplexity7.307406425476074
INFO:root:current mean train loss 5037.7449330313475
INFO:root:current train perplexity7.2862749099731445
INFO:root:current mean train loss 5037.378694154897
INFO:root:current train perplexity7.280496120452881
INFO:root:current mean train loss 5032.928436824903
INFO:root:current train perplexity7.2625203132629395
INFO:root:current mean train loss 5024.8575919154355
INFO:root:current train perplexity7.246854305267334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.33s/it]
INFO:root:final mean train loss: 5016.286858650946
INFO:root:final train perplexity: 7.236013412475586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4702.805144614362
INFO:root:eval perplexity: 6.6971116065979
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/6

  3%|â–Ž         | 6/200 [27:56<15:20:55, 284.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4886.801778590426
INFO:root:current train perplexity6.919363498687744
INFO:root:current mean train loss 4941.455034943665
INFO:root:current train perplexity6.998307704925537
INFO:root:current mean train loss 4922.500088958122
INFO:root:current train perplexity6.979138374328613
INFO:root:current mean train loss 4924.124174002612
INFO:root:current train perplexity6.975273132324219
INFO:root:current mean train loss 4920.970816729586
INFO:root:current train perplexity6.963917255401611
INFO:root:current mean train loss 4911.346940342208
INFO:root:current train perplexity6.940163612365723
INFO:root:current mean train loss 4911.275971732515
INFO:root:current train perplexity6.937944412231445
INFO:root:current mean train loss 4908.263103847682
INFO:root:current train perplexity6.926080226898193
INFO:root:current mean train loss 4904.7335512055415
INFO:root:current train perplexity6.917552471160889
INFO:root:current mean train loss 4902.237738829857
INFO:root:current train perplexity6.90593147277832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.19s/it]
INFO:root:final mean train loss: 4897.278560761482
INFO:root:final train perplexity: 6.904117107391357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]
INFO:root:eval mean loss: 4616.013000055408
INFO:root:eval perplexity: 6.466145992279053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/7

  4%|â–Ž         | 7/200 [32:54<15:30:22, 289.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4791.388165838068
INFO:root:current train perplexity6.709709167480469
INFO:root:current mean train loss 4839.167294606855
INFO:root:current train perplexity6.7595744132995605
INFO:root:current mean train loss 4833.335190716912
INFO:root:current train perplexity6.718930721282959
INFO:root:current mean train loss 4832.759244333187
INFO:root:current train perplexity6.7121381759643555
INFO:root:current mean train loss 4827.01171875
INFO:root:current train perplexity6.695350646972656
INFO:root:current mean train loss 4820.563357791385
INFO:root:current train perplexity6.676426887512207
INFO:root:current mean train loss 4819.566494960639
INFO:root:current train perplexity6.675475597381592
INFO:root:current mean train loss 4821.356949115273
INFO:root:current train perplexity6.670811653137207
INFO:root:current mean train loss 4813.0013631898755
INFO:root:current train perplexity6.655941963195801
INFO:root:current mean train loss 4804.851310945681
INFO:root:current train perplexity6.645508289337158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.62s/it]
INFO:root:final mean train loss: 4800.17929698575
INFO:root:final train perplexity: 6.644632816314697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 4542.405112408577
INFO:root:eval perplexity: 6.276517391204834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/8

  4%|â–         | 8/200 [37:44<15:25:39, 289.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4746.820529513889
INFO:root:current train perplexity6.448838710784912
INFO:root:current mean train loss 4734.2412109375
INFO:root:current train perplexity6.467047691345215
INFO:root:current mean train loss 4727.247220695699
INFO:root:current train perplexity6.463197231292725
INFO:root:current mean train loss 4737.544532460614
INFO:root:current train perplexity6.462203502655029
INFO:root:current mean train loss 4741.8219887916775
INFO:root:current train perplexity6.4716362953186035
INFO:root:current mean train loss 4734.450758613871
INFO:root:current train perplexity6.460134983062744
INFO:root:current mean train loss 4731.268361731712
INFO:root:current train perplexity6.456435203552246
INFO:root:current mean train loss 4729.705343703924
INFO:root:current train perplexity6.450047969818115
INFO:root:current mean train loss 4724.712072768051
INFO:root:current train perplexity6.4413299560546875
INFO:root:current mean train loss 4721.202659789152
INFO:root:current train perplexity6.432104587554932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.39s/it]
INFO:root:final mean train loss: 4718.896281888408
INFO:root:final train perplexity: 6.434930801391602
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.27s/it]
INFO:root:eval mean loss: 4486.551286846188
INFO:root:eval perplexity: 6.136347770690918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/9

  4%|â–         | 9/200 [42:33<15:20:35, 289.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4641.634071027729
INFO:root:current train perplexity6.213070869445801
INFO:root:current mean train loss 4652.184073464912
INFO:root:current train perplexity6.2621073722839355
INFO:root:current mean train loss 4674.594247290129
INFO:root:current train perplexity6.298396587371826
INFO:root:current mean train loss 4668.760630317132
INFO:root:current train perplexity6.286343574523926
INFO:root:current mean train loss 4662.121204675889
INFO:root:current train perplexity6.282200813293457
INFO:root:current mean train loss 4663.617739916265
INFO:root:current train perplexity6.280413627624512
INFO:root:current mean train loss 4664.811372805281
INFO:root:current train perplexity6.28481912612915
INFO:root:current mean train loss 4654.938608290775
INFO:root:current train perplexity6.270630836486816
INFO:root:current mean train loss 4657.283573119977
INFO:root:current train perplexity6.267732620239258
INFO:root:current mean train loss 4653.136824351506
INFO:root:current train perplexity6.26097297668457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.96s/it]
INFO:root:final mean train loss: 4648.824344019736
INFO:root:final train perplexity: 6.259471893310547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4439.788002825798
INFO:root:eval perplexity: 6.021401405334473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/10

  5%|â–Œ         | 10/200 [47:03<14:57:56, 283.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4638.008931220333
INFO:root:current train perplexity6.1447649002075195
INFO:root:current mean train loss 4600.328017250786
INFO:root:current train perplexity6.111677646636963
INFO:root:current mean train loss 4609.97287063872
INFO:root:current train perplexity6.124568462371826
INFO:root:current mean train loss 4603.316323152004
INFO:root:current train perplexity6.1251349449157715
INFO:root:current mean train loss 4606.7833300373495
INFO:root:current train perplexity6.123196125030518
INFO:root:current mean train loss 4600.840951026824
INFO:root:current train perplexity6.124139785766602
INFO:root:current mean train loss 4600.231558214055
INFO:root:current train perplexity6.12119197845459
INFO:root:current mean train loss 4598.14885338525
INFO:root:current train perplexity6.117578029632568
INFO:root:current mean train loss 4593.2299032547635
INFO:root:current train perplexity6.114898681640625
INFO:root:current mean train loss 4592.402723801391
INFO:root:current train perplexity6.114728927612305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.51s/it]
INFO:root:final mean train loss: 4589.449912532683
INFO:root:final train perplexity: 6.114546775817871
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 4392.317093653036
INFO:root:eval perplexity: 5.906916618347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/11

  6%|â–Œ         | 11/200 [51:53<14:58:41, 285.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4538.701968839799
INFO:root:current train perplexity5.975399494171143
INFO:root:current mean train loss 4561.073015019218
INFO:root:current train perplexity6.011180877685547
INFO:root:current mean train loss 4546.91103753811
INFO:root:current train perplexity5.982004642486572
INFO:root:current mean train loss 4546.9053169664485
INFO:root:current train perplexity5.994528770446777
INFO:root:current mean train loss 4543.700707155576
INFO:root:current train perplexity5.992048263549805
INFO:root:current mean train loss 4539.9940412219175
INFO:root:current train perplexity5.985227584838867
INFO:root:current mean train loss 4539.2308813369955
INFO:root:current train perplexity5.986055374145508
INFO:root:current mean train loss 4536.530094442404
INFO:root:current train perplexity5.980208873748779
INFO:root:current mean train loss 4537.654729832388
INFO:root:current train perplexity5.9820876121521
INFO:root:current mean train loss 4536.966984123686
INFO:root:current train perplexity5.981216907501221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.67s/it]
INFO:root:final mean train loss: 4533.528460471861
INFO:root:final train perplexity: 5.98112154006958
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 4358.404549673094
INFO:root:eval perplexity: 5.8264665603637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/12

  6%|â–Œ         | 12/200 [56:37<14:52:33, 284.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4502.611356393914
INFO:root:current train perplexity5.894370079040527
INFO:root:current mean train loss 4484.405462489984
INFO:root:current train perplexity5.88157320022583
INFO:root:current mean train loss 4488.112715174788
INFO:root:current train perplexity5.889346599578857
INFO:root:current mean train loss 4481.832768616495
INFO:root:current train perplexity5.874960899353027
INFO:root:current mean train loss 4488.324441682449
INFO:root:current train perplexity5.87738037109375
INFO:root:current mean train loss 4482.339584837841
INFO:root:current train perplexity5.872351169586182
INFO:root:current mean train loss 4480.364396568682
INFO:root:current train perplexity5.8695902824401855
INFO:root:current mean train loss 4484.236555068298
INFO:root:current train perplexity5.86376953125
INFO:root:current mean train loss 4485.910648622992
INFO:root:current train perplexity5.86617374420166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.74s/it]
INFO:root:final mean train loss: 4485.3072282114335
INFO:root:final train perplexity: 5.868409156799316
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4322.329047886193
INFO:root:eval perplexity: 5.7420878410339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/13

  6%|â–‹         | 13/200 [1:01:26<14:52:08, 286.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4704.011881510417
INFO:root:current train perplexity6.033055782318115
INFO:root:current mean train loss 4463.210565363319
INFO:root:current train perplexity5.772867679595947
INFO:root:current mean train loss 4458.988029893396
INFO:root:current train perplexity5.767729759216309
INFO:root:current mean train loss 4457.71744147071
INFO:root:current train perplexity5.774928569793701
INFO:root:current mean train loss 4458.903412395316
INFO:root:current train perplexity5.778241157531738
INFO:root:current mean train loss 4454.600263167091
INFO:root:current train perplexity5.7794013023376465
INFO:root:current mean train loss 4450.000859553145
INFO:root:current train perplexity5.778669834136963
INFO:root:current mean train loss 4446.617454908651
INFO:root:current train perplexity5.772265434265137
INFO:root:current mean train loss 4444.920828813337
INFO:root:current train perplexity5.769127368927002
INFO:root:current mean train loss 4444.817812424298
INFO:root:current train perplexity5.767683982849121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.28s/it]
INFO:root:final mean train loss: 4441.696420608028
INFO:root:final train perplexity: 5.768301486968994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.28s/it]
INFO:root:eval mean loss: 4298.142318400931
INFO:root:eval perplexity: 5.686202526092529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/14

  7%|â–‹         | 14/200 [1:06:15<14:49:41, 287.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4379.316938920455
INFO:root:current train perplexity5.569911003112793
INFO:root:current mean train loss 4392.946678367821
INFO:root:current train perplexity5.678895950317383
INFO:root:current mean train loss 4385.899869945942
INFO:root:current train perplexity5.679017066955566
INFO:root:current mean train loss 4389.615780747588
INFO:root:current train perplexity5.675207614898682
INFO:root:current mean train loss 4387.378308669784
INFO:root:current train perplexity5.670646667480469
INFO:root:current mean train loss 4390.383215738136
INFO:root:current train perplexity5.673994064331055
INFO:root:current mean train loss 4398.240467727087
INFO:root:current train perplexity5.680002689361572
INFO:root:current mean train loss 4399.183739341596
INFO:root:current train perplexity5.676220893859863
INFO:root:current mean train loss 4400.938619554851
INFO:root:current train perplexity5.679031848907471
INFO:root:current mean train loss 4403.419346764373
INFO:root:current train perplexity5.675833702087402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.58s/it]
INFO:root:final mean train loss: 4400.134037879206
INFO:root:final train perplexity: 5.674487113952637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4271.7021969193265
INFO:root:eval perplexity: 5.625731468200684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/15

  8%|â–Š         | 15/200 [1:10:23<14:08:45, 275.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4419.96480520148
INFO:root:current train perplexity5.660624980926514
INFO:root:current mean train loss 4364.256850298713
INFO:root:current train perplexity5.575024604797363
INFO:root:current mean train loss 4362.860615769478
INFO:root:current train perplexity5.59117317199707
INFO:root:current mean train loss 4361.453653078468
INFO:root:current train perplexity5.592121601104736
INFO:root:current mean train loss 4366.071722572345
INFO:root:current train perplexity5.597051620483398
INFO:root:current mean train loss 4363.741621601788
INFO:root:current train perplexity5.592709541320801
INFO:root:current mean train loss 4362.324548083477
INFO:root:current train perplexity5.591719150543213
INFO:root:current mean train loss 4364.730444981094
INFO:root:current train perplexity5.593630313873291
INFO:root:current mean train loss 4364.751773075015
INFO:root:current train perplexity5.595070838928223
INFO:root:current mean train loss 4365.135329087748
INFO:root:current train perplexity5.593249797821045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.75s/it]
INFO:root:final mean train loss: 4365.53250528151
INFO:root:final train perplexity: 5.597548961639404
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4249.5691402787015
INFO:root:eval perplexity: 5.575606346130371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/16

  8%|â–Š         | 16/200 [1:14:59<14:05:15, 275.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4361.146384910301
INFO:root:current train perplexity5.594489574432373
INFO:root:current mean train loss 4311.233834814838
INFO:root:current train perplexity5.526071548461914
INFO:root:current mean train loss 4324.124405243323
INFO:root:current train perplexity5.522976398468018
INFO:root:current mean train loss 4322.216677417813
INFO:root:current train perplexity5.515340805053711
INFO:root:current mean train loss 4328.7073565802475
INFO:root:current train perplexity5.518470764160156
INFO:root:current mean train loss 4327.92252357092
INFO:root:current train perplexity5.511709690093994
INFO:root:current mean train loss 4328.160018409839
INFO:root:current train perplexity5.509554386138916
INFO:root:current mean train loss 4327.256927616167
INFO:root:current train perplexity5.514855861663818
INFO:root:current mean train loss 4327.672217446342
INFO:root:current train perplexity5.51218843460083
INFO:root:current mean train loss 4329.952981465329
INFO:root:current train perplexity5.51746129989624


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.02s/it]
INFO:root:final mean train loss: 4330.232752277005
INFO:root:final train perplexity: 5.520133972167969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.96s/it]
INFO:root:eval mean loss: 4226.138573179854
INFO:root:eval perplexity: 5.523028373718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/17

  8%|â–Š         | 17/200 [1:19:10<13:37:58, 268.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4263.656263950893
INFO:root:current train perplexity5.42504358291626
INFO:root:current mean train loss 4299.259407552084
INFO:root:current train perplexity5.447263240814209
INFO:root:current mean train loss 4292.614541431183
INFO:root:current train perplexity5.447628021240234
INFO:root:current mean train loss 4296.02177369986
INFO:root:current train perplexity5.447474956512451
INFO:root:current mean train loss 4297.030549007723
INFO:root:current train perplexity5.4537272453308105
INFO:root:current mean train loss 4307.685390807535
INFO:root:current train perplexity5.455686092376709
INFO:root:current mean train loss 4302.443813438115
INFO:root:current train perplexity5.447780132293701
INFO:root:current mean train loss 4300.640494127339
INFO:root:current train perplexity5.4433674812316895
INFO:root:current mean train loss 4301.172108030034
INFO:root:current train perplexity5.449891567230225
INFO:root:current mean train loss 4300.253378540692
INFO:root:current train perplexity5.452428817749023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it]
INFO:root:final mean train loss: 4299.132036270634
INFO:root:final train perplexity: 5.45281457901001
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it]
INFO:root:eval mean loss: 4209.73567535184
INFO:root:eval perplexity: 5.486516952514648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/18

  9%|â–‰         | 18/200 [1:23:18<13:14:28, 261.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4272.016595884811
INFO:root:current train perplexity5.4127726554870605
INFO:root:current mean train loss 4283.12805944056
INFO:root:current train perplexity5.408222198486328
INFO:root:current mean train loss 4275.388496053562
INFO:root:current train perplexity5.39642333984375
INFO:root:current mean train loss 4280.690614750364
INFO:root:current train perplexity5.407952785491943
INFO:root:current mean train loss 4281.5110023102425
INFO:root:current train perplexity5.40405797958374
INFO:root:current mean train loss 4281.584132747756
INFO:root:current train perplexity5.401215553283691
INFO:root:current mean train loss 4278.119181251823
INFO:root:current train perplexity5.396486759185791
INFO:root:current mean train loss 4274.938907340911
INFO:root:current train perplexity5.392327308654785
INFO:root:current mean train loss 4271.242713140848
INFO:root:current train perplexity5.389538764953613
INFO:root:current mean train loss 4270.294259355531
INFO:root:current train perplexity5.3867363929748535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it]
INFO:root:final mean train loss: 4269.506197652509
INFO:root:final train perplexity: 5.3894524574279785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]
INFO:root:eval mean loss: 4193.054715203901
INFO:root:eval perplexity: 5.4496331214904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/19

 10%|â–‰         | 19/200 [1:28:05<13:33:40, 269.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4212.98424096201
INFO:root:current train perplexity5.250764846801758
INFO:root:current mean train loss 4210.248745343543
INFO:root:current train perplexity5.2603020668029785
INFO:root:current mean train loss 4240.780565239043
INFO:root:current train perplexity5.2911696434021
INFO:root:current mean train loss 4233.480187744836
INFO:root:current train perplexity5.3036417961120605
INFO:root:current mean train loss 4239.642175374169
INFO:root:current train perplexity5.308391094207764
INFO:root:current mean train loss 4238.3316001268995
INFO:root:current train perplexity5.314304828643799
INFO:root:current mean train loss 4245.083442465318
INFO:root:current train perplexity5.325456619262695
INFO:root:current mean train loss 4246.583043572112
INFO:root:current train perplexity5.327321529388428
INFO:root:current mean train loss 4247.054679180284
INFO:root:current train perplexity5.331579208374023
INFO:root:current mean train loss 4249.332516450611
INFO:root:current train perplexity5.3346662521362305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.63s/it]
INFO:root:final mean train loss: 4242.814828934208
INFO:root:final train perplexity: 5.332995891571045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4178.538240040448
INFO:root:eval perplexity: 5.4177374839782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/20

 10%|â–ˆ         | 20/200 [1:32:48<13:40:21, 273.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4250.256902145127
INFO:root:current train perplexity5.285714149475098
INFO:root:current mean train loss 4236.624611524666
INFO:root:current train perplexity5.271198749542236
INFO:root:current mean train loss 4229.029407162464
INFO:root:current train perplexity5.2724127769470215
INFO:root:current mean train loss 4227.798572423399
INFO:root:current train perplexity5.283303260803223
INFO:root:current mean train loss 4223.571048645153
INFO:root:current train perplexity5.278042316436768
INFO:root:current mean train loss 4220.853749720483
INFO:root:current train perplexity5.27593994140625
INFO:root:current mean train loss 4222.593741108687
INFO:root:current train perplexity5.2765278816223145
INFO:root:current mean train loss 4226.145695984128
INFO:root:current train perplexity5.285524368286133
INFO:root:current mean train loss 4224.136162541382
INFO:root:current train perplexity5.284361839294434
INFO:root:current mean train loss 4221.025787512627
INFO:root:current train perplexity5.279659748077393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.50s/it]
INFO:root:final mean train loss: 4216.606643492176
INFO:root:final train perplexity: 5.278138160705566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.84s/it]
INFO:root:eval mean loss: 4169.682807651818
INFO:root:eval perplexity: 5.398371696472168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/21

 10%|â–ˆ         | 21/200 [1:37:17<13:32:18, 272.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4165.024352116371
INFO:root:current train perplexity5.207347393035889
INFO:root:current mean train loss 4183.889861877807
INFO:root:current train perplexity5.238399505615234
INFO:root:current mean train loss 4187.653855227352
INFO:root:current train perplexity5.224918842315674
INFO:root:current mean train loss 4184.387115894287
INFO:root:current train perplexity5.214174270629883
INFO:root:current mean train loss 4189.6373628211995
INFO:root:current train perplexity5.2208476066589355
INFO:root:current mean train loss 4190.087984061535
INFO:root:current train perplexity5.217658996582031
INFO:root:current mean train loss 4192.340307507379
INFO:root:current train perplexity5.219696998596191
INFO:root:current mean train loss 4193.899143820791
INFO:root:current train perplexity5.2210917472839355
INFO:root:current mean train loss 4195.233486575927
INFO:root:current train perplexity5.221721649169922
INFO:root:current mean train loss 4193.933005742228
INFO:root:current train perplexity5.224430561065674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.70s/it]
INFO:root:final mean train loss: 4192.194694765152
INFO:root:final train perplexity: 5.227546215057373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4148.232813192598
INFO:root:eval perplexity: 5.351750373840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/22

 11%|â–ˆ         | 22/200 [1:41:27<13:08:03, 265.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.565296223958
INFO:root:current train perplexity5.172095775604248
INFO:root:current mean train loss 4170.972280970982
INFO:root:current train perplexity5.178887367248535
INFO:root:current mean train loss 4163.387233664773
INFO:root:current train perplexity5.1590962409973145
INFO:root:current mean train loss 4163.725259114583
INFO:root:current train perplexity5.166460037231445
INFO:root:current mean train loss 4164.669584703947
INFO:root:current train perplexity5.169593811035156
INFO:root:current mean train loss 4170.260318868886
INFO:root:current train perplexity5.176125526428223
INFO:root:current mean train loss 4168.587673611111
INFO:root:current train perplexity5.179050445556641
INFO:root:current mean train loss 4172.851446887601
INFO:root:current train perplexity5.181582927703857
INFO:root:current mean train loss 4172.86951953125
INFO:root:current train perplexity5.180999755859375
INFO:root:current mean train loss 4174.285207832532
INFO:root:current train perplexity5.181283473968506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.93s/it]
INFO:root:final mean train loss: 4169.253590306928
INFO:root:final train perplexity: 5.180446624755859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 4138.349457003546
INFO:root:eval perplexity: 5.330403804779053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/23

 12%|â–ˆâ–        | 23/200 [1:46:12<13:20:10, 271.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4156.979062735316
INFO:root:current train perplexity5.104048252105713
INFO:root:current mean train loss 4151.34590590847
INFO:root:current train perplexity5.120092391967773
INFO:root:current mean train loss 4151.2113084557195
INFO:root:current train perplexity5.121845722198486
INFO:root:current mean train loss 4155.952737434726
INFO:root:current train perplexity5.129433631896973
INFO:root:current mean train loss 4157.588073098635
INFO:root:current train perplexity5.134529113769531
INFO:root:current mean train loss 4151.190885723762
INFO:root:current train perplexity5.128532886505127
INFO:root:current mean train loss 4145.870602609123
INFO:root:current train perplexity5.122174263000488
INFO:root:current mean train loss 4150.866732269716
INFO:root:current train perplexity5.1326212882995605
INFO:root:current mean train loss 4150.318858715848
INFO:root:current train perplexity5.135985374450684
INFO:root:current mean train loss 4150.697317532824
INFO:root:current train perplexity5.136370658874512


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it]
INFO:root:final mean train loss: 4147.559490880659
INFO:root:final train perplexity: 5.136296272277832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it]
INFO:root:eval mean loss: 4128.852556377438
INFO:root:eval perplexity: 5.30997371673584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/24

 12%|â–ˆâ–        | 24/200 [1:51:09<13:38:34, 279.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4102.5603751717035
INFO:root:current train perplexity5.066145420074463
INFO:root:current mean train loss 4114.155374417131
INFO:root:current train perplexity5.082031726837158
INFO:root:current mean train loss 4110.0910761987225
INFO:root:current train perplexity5.068199157714844
INFO:root:current mean train loss 4119.857699108856
INFO:root:current train perplexity5.085665225982666
INFO:root:current mean train loss 4120.6013551545
INFO:root:current train perplexity5.089704990386963
INFO:root:current mean train loss 4126.128344437394
INFO:root:current train perplexity5.092784881591797
INFO:root:current mean train loss 4128.789918935419
INFO:root:current train perplexity5.096325397491455
INFO:root:current mean train loss 4132.010165324254
INFO:root:current train perplexity5.0957136154174805
INFO:root:current mean train loss 4130.682220698741
INFO:root:current train perplexity5.098062038421631
INFO:root:current mean train loss 4129.749578974442
INFO:root:current train perplexity5.093746662139893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.54s/it]
INFO:root:final mean train loss: 4126.420358411728
INFO:root:final train perplexity: 5.093637943267822
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4116.695909865359
INFO:root:eval perplexity: 5.283934116363525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/25

 12%|â–ˆâ–Ž        | 25/200 [1:55:59<13:43:35, 282.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4081.176656703756
INFO:root:current train perplexity5.064087867736816
INFO:root:current mean train loss 4089.618069596027
INFO:root:current train perplexity5.031644821166992
INFO:root:current mean train loss 4103.586945090406
INFO:root:current train perplexity5.0431084632873535
INFO:root:current mean train loss 4110.064128827929
INFO:root:current train perplexity5.053240776062012
INFO:root:current mean train loss 4109.475768431394
INFO:root:current train perplexity5.050072193145752
INFO:root:current mean train loss 4108.216282508608
INFO:root:current train perplexity5.045475006103516
INFO:root:current mean train loss 4108.640050798015
INFO:root:current train perplexity5.047086238861084
INFO:root:current mean train loss 4112.056900043512
INFO:root:current train perplexity5.05062198638916
INFO:root:current mean train loss 4112.025309697407
INFO:root:current train perplexity5.0551652908325195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.51s/it]
INFO:root:final mean train loss: 4106.422520299112
INFO:root:final train perplexity: 5.053607940673828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4110.993082682292
INFO:root:eval perplexity: 5.271764278411865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/26

 13%|â–ˆâ–Ž        | 26/200 [2:00:54<13:49:27, 286.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4139.300502232143
INFO:root:current train perplexity5.099264144897461
INFO:root:current mean train loss 4078.041996750876
INFO:root:current train perplexity5.0165581703186035
INFO:root:current mean train loss 4087.598828596769
INFO:root:current train perplexity5.025043487548828
INFO:root:current mean train loss 4089.554004383398
INFO:root:current train perplexity5.021255016326904
INFO:root:current mean train loss 4096.683753911049
INFO:root:current train perplexity5.0326056480407715
INFO:root:current mean train loss 4087.8978678385415
INFO:root:current train perplexity5.020815372467041
INFO:root:current mean train loss 4090.874974258649
INFO:root:current train perplexity5.0149126052856445
INFO:root:current mean train loss 4092.2297563566344
INFO:root:current train perplexity5.01871919631958
INFO:root:current mean train loss 4089.9231652847157
INFO:root:current train perplexity5.01531457901001
INFO:root:current mean train loss 4088.002625790294
INFO:root:current train perplexity5.012673854827881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.25s/it]
INFO:root:final mean train loss: 4086.4180637482673
INFO:root:final train perplexity: 5.013880252838135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4095.3489392869014
INFO:root:eval perplexity: 5.238519191741943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/27

 14%|â–ˆâ–Ž        | 27/200 [2:05:46<13:50:11, 287.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4089.094482421875
INFO:root:current train perplexity4.927805423736572
INFO:root:current mean train loss 4043.1155549422556
INFO:root:current train perplexity4.946033477783203
INFO:root:current mean train loss 4045.3947447311048
INFO:root:current train perplexity4.951647758483887
INFO:root:current mean train loss 4059.977234468006
INFO:root:current train perplexity4.968044757843018
INFO:root:current mean train loss 4071.344473597515
INFO:root:current train perplexity4.983423709869385
INFO:root:current mean train loss 4066.6318643810678
INFO:root:current train perplexity4.974257946014404
INFO:root:current mean train loss 4069.999178655361
INFO:root:current train perplexity4.9764533042907715
INFO:root:current mean train loss 4071.1230581430286
INFO:root:current train perplexity4.9757256507873535
INFO:root:current mean train loss 4074.421215970092
INFO:root:current train perplexity4.9792070388793945
INFO:root:current mean train loss 4071.279999679816
INFO:root:current train perplexity4.977774143218994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.88s/it]
INFO:root:final mean train loss: 4069.758082605177
INFO:root:final train perplexity: 4.981033802032471
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 4091.193688358821
INFO:root:eval perplexity: 5.229724407196045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/28

 14%|â–ˆâ–        | 28/200 [2:10:35<13:46:34, 288.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4086.4805961277175
INFO:root:current train perplexity4.962788105010986
INFO:root:current mean train loss 4054.0149799129827
INFO:root:current train perplexity4.928915977478027
INFO:root:current mean train loss 4062.1603368921665
INFO:root:current train perplexity4.952480316162109
INFO:root:current mean train loss 4052.1416695892995
INFO:root:current train perplexity4.942392826080322
INFO:root:current mean train loss 4063.435758117243
INFO:root:current train perplexity4.9507012367248535
INFO:root:current mean train loss 4064.29515994712
INFO:root:current train perplexity4.950096130371094
INFO:root:current mean train loss 4056.31704932346
INFO:root:current train perplexity4.94417142868042
INFO:root:current mean train loss 4053.3961791147995
INFO:root:current train perplexity4.94310998916626
INFO:root:current mean train loss 4056.648407241988
INFO:root:current train perplexity4.945255279541016
INFO:root:current mean train loss 4054.6510473976673
INFO:root:current train perplexity4.944564342498779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.95s/it]
INFO:root:final mean train loss: 4050.7704132449244
INFO:root:final train perplexity: 4.943859100341797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it]
INFO:root:eval mean loss: 4086.244402080563
INFO:root:eval perplexity: 5.219268798828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/29

 14%|â–ˆâ–        | 29/200 [2:15:28<13:45:17, 289.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4059.5767704133063
INFO:root:current train perplexity4.905717849731445
INFO:root:current mean train loss 4039.9762773586594
INFO:root:current train perplexity4.8998026847839355
INFO:root:current mean train loss 4055.659757804045
INFO:root:current train perplexity4.914646625518799
INFO:root:current mean train loss 4057.844801058582
INFO:root:current train perplexity4.914800643920898
INFO:root:current mean train loss 4054.046551556156
INFO:root:current train perplexity4.908821105957031
INFO:root:current mean train loss 4050.25086759578
INFO:root:current train perplexity4.91077995300293
INFO:root:current mean train loss 4044.9346542721128
INFO:root:current train perplexity4.9072980880737305
INFO:root:current mean train loss 4045.33090172388
INFO:root:current train perplexity4.911490440368652
INFO:root:current mean train loss 4042.468594878159
INFO:root:current train perplexity4.90874719619751
INFO:root:current mean train loss 4037.7900094299644
INFO:root:current train perplexity4.911624431610107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.71s/it]
INFO:root:final mean train loss: 4034.9028018828362
INFO:root:final train perplexity: 4.913005828857422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4073.7565796764184
INFO:root:eval perplexity: 5.192978382110596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/30

 15%|â–ˆâ–Œ        | 30/200 [2:20:17<13:39:59, 289.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4017.450915214343
INFO:root:current train perplexity4.898632049560547
INFO:root:current mean train loss 4013.4467141130845
INFO:root:current train perplexity4.885603904724121
INFO:root:current mean train loss 4017.825691765821
INFO:root:current train perplexity4.870838165283203
INFO:root:current mean train loss 4014.8900006049503
INFO:root:current train perplexity4.869498252868652
INFO:root:current mean train loss 4021.6619592201737
INFO:root:current train perplexity4.873274326324463
INFO:root:current mean train loss 4019.4685235244665
INFO:root:current train perplexity4.874927043914795
INFO:root:current mean train loss 4019.0218438997704
INFO:root:current train perplexity4.876816272735596
INFO:root:current mean train loss 4023.4450112060217
INFO:root:current train perplexity4.880282878875732
INFO:root:current mean train loss 4023.0070087855706
INFO:root:current train perplexity4.882994174957275
INFO:root:current mean train loss 4022.128619989267
INFO:root:current train perplexity4.882704257965088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.59s/it]
INFO:root:final mean train loss: 4018.1479660772507
INFO:root:final train perplexity: 4.880636692047119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4068.250180075355
INFO:root:eval perplexity: 5.181429386138916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/31

 16%|â–ˆâ–Œ        | 31/200 [2:25:01<13:30:58, 287.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3995.167563580452
INFO:root:current train perplexity4.827799320220947
INFO:root:current mean train loss 3993.3034385629253
INFO:root:current train perplexity4.823188304901123
INFO:root:current mean train loss 3984.864200483932
INFO:root:current train perplexity4.808804988861084
INFO:root:current mean train loss 3996.7058464292145
INFO:root:current train perplexity4.82413387298584
INFO:root:current mean train loss 4000.9607692778245
INFO:root:current train perplexity4.832168102264404
INFO:root:current mean train loss 4002.366168090151
INFO:root:current train perplexity4.841277122497559
INFO:root:current mean train loss 4006.7097254757537
INFO:root:current train perplexity4.847643852233887
INFO:root:current mean train loss 4002.1301730358937
INFO:root:current train perplexity4.847717761993408
INFO:root:current mean train loss 4004.305623996919
INFO:root:current train perplexity4.8509955406188965
INFO:root:current mean train loss 4004.337070807484
INFO:root:current train perplexity4.850106239318848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.03s/it]
INFO:root:final mean train loss: 4003.0119065930767
INFO:root:final train perplexity: 4.8515777587890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 4060.804739444814
INFO:root:eval perplexity: 5.165853500366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/32

 16%|â–ˆâ–Œ        | 32/200 [2:29:50<13:27:22, 288.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.788507634943
INFO:root:current train perplexity4.748180389404297
INFO:root:current mean train loss 4003.834009576613
INFO:root:current train perplexity4.812804698944092
INFO:root:current mean train loss 3982.5148102405024
INFO:root:current train perplexity4.800516128540039
INFO:root:current mean train loss 3975.424325346611
INFO:root:current train perplexity4.8058319091796875
INFO:root:current mean train loss 3985.1777059366414
INFO:root:current train perplexity4.817607879638672
INFO:root:current mean train loss 3986.7658326295045
INFO:root:current train perplexity4.819045066833496
INFO:root:current mean train loss 3990.840173992128
INFO:root:current train perplexity4.820783615112305
INFO:root:current mean train loss 3992.3003974156663
INFO:root:current train perplexity4.8207879066467285
INFO:root:current mean train loss 3993.132050667032
INFO:root:current train perplexity4.821681976318359
INFO:root:current mean train loss 3991.9242310209424
INFO:root:current train perplexity4.824272632598877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.26s/it]
INFO:root:final mean train loss: 3987.858402375252
INFO:root:final train perplexity: 4.822659015655518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.26s/it]
INFO:root:eval mean loss: 4056.20782081117
INFO:root:eval perplexity: 5.156259059906006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/33

 16%|â–ˆâ–‹        | 33/200 [2:34:13<13:01:08, 280.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3921.0218408978176
INFO:root:current train perplexity4.740057468414307
INFO:root:current mean train loss 3948.3415197828795
INFO:root:current train perplexity4.77776575088501
INFO:root:current mean train loss 3948.2877359716613
INFO:root:current train perplexity4.778687000274658
INFO:root:current mean train loss 3958.6456571216427
INFO:root:current train perplexity4.780951023101807
INFO:root:current mean train loss 3968.614227756311
INFO:root:current train perplexity4.7844367027282715
INFO:root:current mean train loss 3965.5166024297846
INFO:root:current train perplexity4.778897285461426
INFO:root:current mean train loss 3968.417881109776
INFO:root:current train perplexity4.7856340408325195
INFO:root:current mean train loss 3966.769483893758
INFO:root:current train perplexity4.782159328460693
INFO:root:current mean train loss 3968.9662899225086
INFO:root:current train perplexity4.7841105461120605
INFO:root:current mean train loss 3975.9727548696296
INFO:root:current train perplexity4.794196605682373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.44s/it]
INFO:root:final mean train loss: 3972.6458995572984
INFO:root:final train perplexity: 4.793801784515381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 4049.084060560727
INFO:root:eval perplexity: 5.141427040100098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/34

 17%|â–ˆâ–‹        | 34/200 [2:39:00<13:01:58, 282.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3997.9748947788294
INFO:root:current train perplexity4.7850189208984375
INFO:root:current mean train loss 3958.856755128381
INFO:root:current train perplexity4.755703926086426
INFO:root:current mean train loss 3953.1531239189344
INFO:root:current train perplexity4.7554473876953125
INFO:root:current mean train loss 3954.908809857227
INFO:root:current train perplexity4.749948978424072
INFO:root:current mean train loss 3953.5071878939425
INFO:root:current train perplexity4.748244285583496
INFO:root:current mean train loss 3957.222861909616
INFO:root:current train perplexity4.757289409637451
INFO:root:current mean train loss 3959.415743104392
INFO:root:current train perplexity4.7608466148376465
INFO:root:current mean train loss 3958.1673797726166
INFO:root:current train perplexity4.760097026824951
INFO:root:current mean train loss 3961.7109952416404
INFO:root:current train perplexity4.763916492462158
INFO:root:current mean train loss 3960.204771377768
INFO:root:current train perplexity4.764979362487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.69s/it]
INFO:root:final mean train loss: 3957.669578859883
INFO:root:final train perplexity: 4.765560150146484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4046.6624729886967
INFO:root:eval perplexity: 5.13639497756958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/35

 18%|â–ˆâ–Š        | 35/200 [2:43:50<13:03:13, 284.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3975.6149098842957
INFO:root:current train perplexity4.770550727844238
INFO:root:current mean train loss 3950.886811496159
INFO:root:current train perplexity4.731359958648682
INFO:root:current mean train loss 3953.4803016143032
INFO:root:current train perplexity4.7413787841796875
INFO:root:current mean train loss 3949.6875695704157
INFO:root:current train perplexity4.735186576843262
INFO:root:current mean train loss 3947.6181890372195
INFO:root:current train perplexity4.7373270988464355
INFO:root:current mean train loss 3950.0950719013117
INFO:root:current train perplexity4.735036373138428
INFO:root:current mean train loss 3950.4471685440444
INFO:root:current train perplexity4.738337993621826
INFO:root:current mean train loss 3948.117124192675
INFO:root:current train perplexity4.738062381744385
INFO:root:current mean train loss 3946.4323661031713
INFO:root:current train perplexity4.736908912658691
INFO:root:current mean train loss 3946.486358798439
INFO:root:current train perplexity4.739346027374268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.21s/it]
INFO:root:final mean train loss: 3943.4459853633757
INFO:root:final train perplexity: 4.738892078399658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4040.5840449772827
INFO:root:eval perplexity: 5.123785972595215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/36

 18%|â–ˆâ–Š        | 36/200 [2:48:37<13:00:04, 285.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.346780711207
INFO:root:current train perplexity4.689781665802002
INFO:root:current mean train loss 3905.76383637617
INFO:root:current train perplexity4.680257320404053
INFO:root:current mean train loss 3917.777057076165
INFO:root:current train perplexity4.6900458335876465
INFO:root:current mean train loss 3923.973376685643
INFO:root:current train perplexity4.7007904052734375
INFO:root:current mean train loss 3919.9194521424215
INFO:root:current train perplexity4.703271389007568
INFO:root:current mean train loss 3921.4246412338957
INFO:root:current train perplexity4.70648717880249
INFO:root:current mean train loss 3926.4253341919125
INFO:root:current train perplexity4.708900451660156
INFO:root:current mean train loss 3929.74649951358
INFO:root:current train perplexity4.711946487426758
INFO:root:current mean train loss 3931.14197424165
INFO:root:current train perplexity4.710518836975098
INFO:root:current mean train loss 3933.326596338336
INFO:root:current train perplexity4.714971542358398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.13s/it]
INFO:root:final mean train loss: 3930.4946337669126
INFO:root:final train perplexity: 4.714739799499512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it]
INFO:root:eval mean loss: 4036.427162982048
INFO:root:eval perplexity: 5.115180969238281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/37

 18%|â–ˆâ–Š        | 37/200 [2:53:31<13:02:14, 287.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3892.6805509868423
INFO:root:current train perplexity4.644140243530273
INFO:root:current mean train loss 3892.6986616085737
INFO:root:current train perplexity4.650164604187012
INFO:root:current mean train loss 3902.5628211069916
INFO:root:current train perplexity4.667608261108398
INFO:root:current mean train loss 3896.875119907041
INFO:root:current train perplexity4.670795917510986
INFO:root:current mean train loss 3904.077022668087
INFO:root:current train perplexity4.677234172821045
INFO:root:current mean train loss 3908.4888273864235
INFO:root:current train perplexity4.680838584899902
INFO:root:current mean train loss 3909.6736932329136
INFO:root:current train perplexity4.681760787963867
INFO:root:current mean train loss 3915.817378206073
INFO:root:current train perplexity4.687760829925537
INFO:root:current mean train loss 3921.6492651230797
INFO:root:current train perplexity4.692383766174316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.53s/it]
INFO:root:final mean train loss: 3918.407569700672
INFO:root:final train perplexity: 4.692310333251953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4031.685791015625
INFO:root:eval perplexity: 5.105383396148682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/38

 19%|â–ˆâ–‰        | 38/200 [2:57:39<12:25:24, 276.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3833.1411946614585
INFO:root:current train perplexity4.494254112243652
INFO:root:current mean train loss 3908.856703674909
INFO:root:current train perplexity4.654026508331299
INFO:root:current mean train loss 3900.7640964151014
INFO:root:current train perplexity4.649566650390625
INFO:root:current mean train loss 3903.453884011448
INFO:root:current train perplexity4.649979591369629
INFO:root:current mean train loss 3897.9487946843983
INFO:root:current train perplexity4.644700050354004
INFO:root:current mean train loss 3900.86468056893
INFO:root:current train perplexity4.645558834075928
INFO:root:current mean train loss 3906.5676941626502
INFO:root:current train perplexity4.65531063079834
INFO:root:current mean train loss 3904.069011226996
INFO:root:current train perplexity4.65895938873291
INFO:root:current mean train loss 3906.765119388718
INFO:root:current train perplexity4.6613383293151855
INFO:root:current mean train loss 3908.4385590241727
INFO:root:current train perplexity4.663791656494141


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.10s/it]
INFO:root:final mean train loss: 3905.1816895392635
INFO:root:final train perplexity: 4.667890548706055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it]
INFO:root:eval mean loss: 4028.9827456643397
INFO:root:eval perplexity: 5.0998053550720215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/39

 20%|â–ˆâ–‰        | 39/200 [3:02:19<12:23:54, 277.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.5737748579545
INFO:root:current train perplexity4.570751667022705
INFO:root:current mean train loss 3871.2166451119087
INFO:root:current train perplexity4.604037284851074
INFO:root:current mean train loss 3882.8844578458234
INFO:root:current train perplexity4.614706516265869
INFO:root:current mean train loss 3884.4821102228198
INFO:root:current train perplexity4.631642818450928
INFO:root:current mean train loss 3887.211301037865
INFO:root:current train perplexity4.638522624969482
INFO:root:current mean train loss 3891.5758651464653
INFO:root:current train perplexity4.640334606170654
INFO:root:current mean train loss 3890.0872592957244
INFO:root:current train perplexity4.6365556716918945
INFO:root:current mean train loss 3892.2622454894076
INFO:root:current train perplexity4.641406536102295
INFO:root:current mean train loss 3893.6741222376886
INFO:root:current train perplexity4.641973972320557
INFO:root:current mean train loss 3894.7515977677344
INFO:root:current train perplexity4.643542766571045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.32s/it]
INFO:root:final mean train loss: 3892.526565305648
INFO:root:final train perplexity: 4.644641876220703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.60s/it]
INFO:root:eval mean loss: 4024.8816731770835
INFO:root:eval perplexity: 5.091355323791504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/40

 20%|â–ˆâ–ˆ        | 40/200 [3:07:18<12:36:19, 283.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3883.6495811060854
INFO:root:current train perplexity4.623065948486328
INFO:root:current mean train loss 3872.3974486278885
INFO:root:current train perplexity4.611162185668945
INFO:root:current mean train loss 3872.627280875428
INFO:root:current train perplexity4.612375736236572
INFO:root:current mean train loss 3881.2390657143906
INFO:root:current train perplexity4.613673210144043
INFO:root:current mean train loss 3881.831223080437
INFO:root:current train perplexity4.616188049316406
INFO:root:current mean train loss 3885.602149096068
INFO:root:current train perplexity4.620173454284668
INFO:root:current mean train loss 3885.14439083956
INFO:root:current train perplexity4.620344638824463
INFO:root:current mean train loss 3890.0422074658813
INFO:root:current train perplexity4.627974510192871
INFO:root:current mean train loss 3886.272633535085
INFO:root:current train perplexity4.623615264892578
INFO:root:current mean train loss 3883.2526998924614
INFO:root:current train perplexity4.623044490814209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.87s/it]
INFO:root:final mean train loss: 3879.844563945647
INFO:root:final train perplexity: 4.621460437774658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]
INFO:root:eval mean loss: 4023.78579517121
INFO:root:eval perplexity: 5.089099884033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/41

 20%|â–ˆâ–ˆ        | 41/200 [3:12:17<12:44:21, 288.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3824.5854582609954
INFO:root:current train perplexity4.575472354888916
INFO:root:current mean train loss 3846.985474593996
INFO:root:current train perplexity4.565464019775391
INFO:root:current mean train loss 3853.89565945932
INFO:root:current train perplexity4.580234050750732
INFO:root:current mean train loss 3855.9684274655965
INFO:root:current train perplexity4.576104640960693
INFO:root:current mean train loss 3857.759180144906
INFO:root:current train perplexity4.583439826965332
INFO:root:current mean train loss 3858.752629491817
INFO:root:current train perplexity4.580206394195557
INFO:root:current mean train loss 3861.3080688671253
INFO:root:current train perplexity4.580075263977051
INFO:root:current mean train loss 3866.244303497356
INFO:root:current train perplexity4.588212966918945
INFO:root:current mean train loss 3871.3184060185536
INFO:root:current train perplexity4.595951080322266
INFO:root:current mean train loss 3871.561609558303
INFO:root:current train perplexity4.5977888107299805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.60s/it]
INFO:root:final mean train loss: 3867.974635647189
INFO:root:final train perplexity: 4.599869251251221
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 4016.5515067459
INFO:root:eval perplexity: 5.074233055114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/42

 21%|â–ˆâ–ˆ        | 42/200 [3:16:41<12:19:42, 280.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3799.4161063058036
INFO:root:current train perplexity4.545835018157959
INFO:root:current mean train loss 3822.157320601852
INFO:root:current train perplexity4.555670261383057
INFO:root:current mean train loss 3839.10648167387
INFO:root:current train perplexity4.557574272155762
INFO:root:current mean train loss 3851.436435255364
INFO:root:current train perplexity4.571352005004883
INFO:root:current mean train loss 3855.1513963721263
INFO:root:current train perplexity4.572775840759277
INFO:root:current mean train loss 3857.521115197868
INFO:root:current train perplexity4.574965476989746
INFO:root:current mean train loss 3857.7453670952264
INFO:root:current train perplexity4.57833194732666
INFO:root:current mean train loss 3862.027102266688
INFO:root:current train perplexity4.580180644989014
INFO:root:current mean train loss 3859.2140689324474
INFO:root:current train perplexity4.577861309051514
INFO:root:current mean train loss 3859.261993963068
INFO:root:current train perplexity4.578482627868652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.46s/it]
INFO:root:final mean train loss: 3858.1476695768297
INFO:root:final train perplexity: 4.5820698738098145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4012.7626831920434
INFO:root:eval perplexity: 5.066465854644775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:21:29<12:20:22, 282.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3884.3935206213664
INFO:root:current train perplexity4.560901641845703
INFO:root:current mean train loss 3864.320838341346
INFO:root:current train perplexity4.5689826011657715
INFO:root:current mean train loss 3854.5596798241386
INFO:root:current train perplexity4.549489498138428
INFO:root:current mean train loss 3850.4366885705176
INFO:root:current train perplexity4.54820442199707
INFO:root:current mean train loss 3850.5147614145385
INFO:root:current train perplexity4.5464982986450195
INFO:root:current mean train loss 3850.5089716059506
INFO:root:current train perplexity4.550346851348877
INFO:root:current mean train loss 3849.1198631749367
INFO:root:current train perplexity4.550293922424316
INFO:root:current mean train loss 3846.897328845264
INFO:root:current train perplexity4.552456378936768
INFO:root:current mean train loss 3848.0530517867733
INFO:root:current train perplexity4.556947708129883
INFO:root:current mean train loss 3847.277999797024
INFO:root:current train perplexity4.5569891929626465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.12s/it]
INFO:root:final mean train loss: 3844.4659559803627
INFO:root:final train perplexity: 4.557403564453125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it]
INFO:root:eval mean loss: 4014.927490234375
INFO:root:eval perplexity: 5.070901870727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/44

 22%|â–ˆâ–ˆâ–       | 44/200 [3:25:37<11:48:46, 272.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3780.829048904718
INFO:root:current train perplexity4.481123924255371
INFO:root:current mean train loss 3819.662929105443
INFO:root:current train perplexity4.502956390380859
INFO:root:current mean train loss 3825.6619556928536
INFO:root:current train perplexity4.519010543823242
INFO:root:current mean train loss 3824.720294137286
INFO:root:current train perplexity4.5183563232421875
INFO:root:current mean train loss 3831.9680803726096
INFO:root:current train perplexity4.520184516906738
INFO:root:current mean train loss 3835.779893712426
INFO:root:current train perplexity4.530139923095703
INFO:root:current mean train loss 3831.586670671923
INFO:root:current train perplexity4.528759479522705
INFO:root:current mean train loss 3834.2581902515394
INFO:root:current train perplexity4.532568454742432
INFO:root:current mean train loss 3832.7690710836514
INFO:root:current train perplexity4.533467769622803
INFO:root:current mean train loss 3835.3907756945814
INFO:root:current train perplexity4.535213470458984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.05s/it]
INFO:root:final mean train loss: 3833.517467621834
INFO:root:final train perplexity: 4.537759780883789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it]
INFO:root:eval mean loss: 4009.755438622008
INFO:root:eval perplexity: 5.060307502746582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:30:01<11:37:30, 270.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3820.6080798132944
INFO:root:current train perplexity4.489499568939209
INFO:root:current mean train loss 3829.584385134139
INFO:root:current train perplexity4.521071910858154
INFO:root:current mean train loss 3824.6781227376932
INFO:root:current train perplexity4.5200114250183105
INFO:root:current mean train loss 3821.8931697749827
INFO:root:current train perplexity4.516338348388672
INFO:root:current mean train loss 3822.0624638310187
INFO:root:current train perplexity4.518123626708984
INFO:root:current mean train loss 3823.087011456703
INFO:root:current train perplexity4.518026351928711
INFO:root:current mean train loss 3828.4217949781864
INFO:root:current train perplexity4.521243572235107
INFO:root:current mean train loss 3831.3632236726985
INFO:root:current train perplexity4.519821643829346
INFO:root:current mean train loss 3828.4879373499343
INFO:root:current train perplexity4.520817756652832
INFO:root:current mean train loss 3828.049434021442
INFO:root:current train perplexity4.5215840339660645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.57s/it]
INFO:root:final mean train loss: 3824.462223975889
INFO:root:final train perplexity: 4.521578311920166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.67s/it]
INFO:root:eval mean loss: 4007.744299922429
INFO:root:eval perplexity: 5.056195259094238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:34:11<11:17:44, 264.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3828.270278247435
INFO:root:current train perplexity4.497363090515137
INFO:root:current mean train loss 3817.6607497894834
INFO:root:current train perplexity4.477483749389648
INFO:root:current mean train loss 3811.842506437266
INFO:root:current train perplexity4.483880043029785
INFO:root:current mean train loss 3818.3674349667917
INFO:root:current train perplexity4.494107246398926
INFO:root:current mean train loss 3823.6152814256557
INFO:root:current train perplexity4.4985456466674805
INFO:root:current mean train loss 3821.680164586089
INFO:root:current train perplexity4.4989013671875
INFO:root:current mean train loss 3823.2877620027875
INFO:root:current train perplexity4.506124496459961
INFO:root:current mean train loss 3819.27717918585
INFO:root:current train perplexity4.502864837646484
INFO:root:current mean train loss 3818.645851355248
INFO:root:current train perplexity4.503110885620117
INFO:root:current mean train loss 3817.4619728885245
INFO:root:current train perplexity4.50262451171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.85s/it]
INFO:root:final mean train loss: 3813.6420517583047
INFO:root:final train perplexity: 4.502316951751709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4009.0630939023713
INFO:root:eval perplexity: 5.058891296386719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:38:18<11:00:33, 259.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3805.3362434895835
INFO:root:current train perplexity4.434500694274902
INFO:root:current mean train loss 3794.8968136160715
INFO:root:current train perplexity4.465930938720703
INFO:root:current mean train loss 3794.7740482954546
INFO:root:current train perplexity4.464015960693359
INFO:root:current mean train loss 3803.146119140625
INFO:root:current train perplexity4.476276874542236
INFO:root:current mean train loss 3802.4618349095394
INFO:root:current train perplexity4.47742223739624
INFO:root:current mean train loss 3804.5109171195654
INFO:root:current train perplexity4.479214668273926
INFO:root:current mean train loss 3804.0541279658564
INFO:root:current train perplexity4.481230735778809
INFO:root:current mean train loss 3803.3786592741935
INFO:root:current train perplexity4.483595848083496
INFO:root:current mean train loss 3804.899923828125
INFO:root:current train perplexity4.485745429992676
INFO:root:current mean train loss 3805.869873046875
INFO:root:current train perplexity4.484371662139893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it]
INFO:root:final mean train loss: 3803.1032636088707
INFO:root:final train perplexity: 4.483635425567627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4004.935858543883
INFO:root:eval perplexity: 5.0504560470581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:42:26<10:47:08, 255.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3796.9996029038025
INFO:root:current train perplexity4.441185474395752
INFO:root:current mean train loss 3800.0463987256658
INFO:root:current train perplexity4.441436767578125
INFO:root:current mean train loss 3787.8335409535116
INFO:root:current train perplexity4.437639236450195
INFO:root:current mean train loss 3786.421802331511
INFO:root:current train perplexity4.449527740478516
INFO:root:current mean train loss 3787.534648760999
INFO:root:current train perplexity4.454885482788086
INFO:root:current mean train loss 3791.6663259306656
INFO:root:current train perplexity4.449784278869629
INFO:root:current mean train loss 3792.578505330344
INFO:root:current train perplexity4.452955722808838
INFO:root:current mean train loss 3791.858792242876
INFO:root:current train perplexity4.4568047523498535
INFO:root:current mean train loss 3792.7302124438174
INFO:root:current train perplexity4.459092617034912
INFO:root:current mean train loss 3795.7863091500826
INFO:root:current train perplexity4.466583251953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.29s/it]
INFO:root:final mean train loss: 3793.2739281192903
INFO:root:final train perplexity: 4.466281890869141
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.98s/it]
INFO:root:eval mean loss: 4002.916251108156
INFO:root:eval perplexity: 5.046332359313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:47:09<11:04:13, 263.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.814903846154
INFO:root:current train perplexity4.396651268005371
INFO:root:current mean train loss 3779.9215324361912
INFO:root:current train perplexity4.415069580078125
INFO:root:current mean train loss 3771.370216186104
INFO:root:current train perplexity4.423048496246338
INFO:root:current mean train loss 3776.766574713275
INFO:root:current train perplexity4.43133020401001
INFO:root:current mean train loss 3777.660883699561
INFO:root:current train perplexity4.434698104858398
INFO:root:current mean train loss 3780.6517633480066
INFO:root:current train perplexity4.438418865203857
INFO:root:current mean train loss 3778.86462172689
INFO:root:current train perplexity4.436888694763184
INFO:root:current mean train loss 3781.719102784746
INFO:root:current train perplexity4.44007682800293
INFO:root:current mean train loss 3781.3922706886574
INFO:root:current train perplexity4.441966533660889
INFO:root:current mean train loss 3785.5797933353306
INFO:root:current train perplexity4.447589874267578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.77s/it]
INFO:root:final mean train loss: 3782.705788581602
INFO:root:final train perplexity: 4.447699069976807
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 4000.3360587045654
INFO:root:eval perplexity: 5.041070461273193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:51:26<10:54:25, 261.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.6982816445707
INFO:root:current train perplexity4.388094425201416
INFO:root:current mean train loss 3768.947593190562
INFO:root:current train perplexity4.4044718742370605
INFO:root:current mean train loss 3771.1748806242163
INFO:root:current train perplexity4.412083148956299
INFO:root:current mean train loss 3773.6185819774046
INFO:root:current train perplexity4.415416240692139
INFO:root:current mean train loss 3777.373276337832
INFO:root:current train perplexity4.426540374755859
INFO:root:current mean train loss 3775.7135321564588
INFO:root:current train perplexity4.430446147918701
INFO:root:current mean train loss 3771.0236697654013
INFO:root:current train perplexity4.4297590255737305
INFO:root:current mean train loss 3770.92379176363
INFO:root:current train perplexity4.429584503173828
INFO:root:current mean train loss 3772.3208952872983
INFO:root:current train perplexity4.4303693771362305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it]
INFO:root:final mean train loss: 3774.159931305916
INFO:root:final train perplexity: 4.4327287673950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.81s/it]
INFO:root:eval mean loss: 4002.08529857879
INFO:root:eval perplexity: 5.044637203216553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:55:33<10:39:14, 257.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3705.1610979352677
INFO:root:current train perplexity4.369868278503418
INFO:root:current mean train loss 3761.801422404352
INFO:root:current train perplexity4.393115043640137
INFO:root:current mean train loss 3760.705363545441
INFO:root:current train perplexity4.4012274742126465
INFO:root:current mean train loss 3769.809602122353
INFO:root:current train perplexity4.40146017074585
INFO:root:current mean train loss 3770.8139978357262
INFO:root:current train perplexity4.407592296600342
INFO:root:current mean train loss 3767.9923748189412
INFO:root:current train perplexity4.406661033630371
INFO:root:current mean train loss 3765.100278247915
INFO:root:current train perplexity4.407778263092041
INFO:root:current mean train loss 3762.2398085965124
INFO:root:current train perplexity4.40999698638916
INFO:root:current mean train loss 3765.5434152822954
INFO:root:current train perplexity4.413843154907227
INFO:root:current mean train loss 3766.219351334241
INFO:root:current train perplexity4.413331508636475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.41s/it]
INFO:root:final mean train loss: 3763.9100106762303
INFO:root:final train perplexity: 4.414839267730713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.58s/it]
INFO:root:eval mean loss: 3998.50902627715
INFO:root:eval perplexity: 5.03734827041626
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:59:48<10:33:09, 256.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.028662109375
INFO:root:current train perplexity4.4828081130981445
INFO:root:current mean train loss 3736.8355765964675
INFO:root:current train perplexity4.373615741729736
INFO:root:current mean train loss 3741.0879405886626
INFO:root:current train perplexity4.379842281341553
INFO:root:current mean train loss 3740.51595749628
INFO:root:current train perplexity4.38405179977417
INFO:root:current mean train loss 3746.684430887613
INFO:root:current train perplexity4.384465217590332
INFO:root:current mean train loss 3748.7178867377124
INFO:root:current train perplexity4.386524677276611
INFO:root:current mean train loss 3747.010798558181
INFO:root:current train perplexity4.391963958740234
INFO:root:current mean train loss 3751.4593695367134
INFO:root:current train perplexity4.396297454833984
INFO:root:current mean train loss 3757.2015957510544
INFO:root:current train perplexity4.398505210876465
INFO:root:current mean train loss 3758.1344128884903
INFO:root:current train perplexity4.399448871612549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:02<00:00, 242.66s/it]
INFO:root:final mean train loss: 3756.0398735538606
INFO:root:final train perplexity: 4.40115213394165
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.25s/it]
INFO:root:eval mean loss: 3995.462916597407
INFO:root:eval perplexity: 5.03114652633667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:04:54<11:05:03, 271.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3746.2903150475545
INFO:root:current train perplexity4.433628082275391
INFO:root:current mean train loss 3753.2646146944867
INFO:root:current train perplexity4.3990159034729
INFO:root:current mean train loss 3740.1939877907794
INFO:root:current train perplexity4.381608009338379
INFO:root:current mean train loss 3748.843376608456
INFO:root:current train perplexity4.385283470153809
INFO:root:current mean train loss 3743.6822731973994
INFO:root:current train perplexity4.383102893829346
INFO:root:current mean train loss 3750.282315256035
INFO:root:current train perplexity4.390193939208984
INFO:root:current mean train loss 3751.671262884982
INFO:root:current train perplexity4.3881916999816895
INFO:root:current mean train loss 3746.9061686197915
INFO:root:current train perplexity4.381667613983154
INFO:root:current mean train loss 3749.0240103256947
INFO:root:current train perplexity4.384241104125977
INFO:root:current mean train loss 3751.0653347292287
INFO:root:current train perplexity4.385536193847656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.22s/it]
INFO:root:final mean train loss: 3745.502156288393
INFO:root:final train perplexity: 4.382892608642578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.01s/it]
INFO:root:eval mean loss: 3997.837637826906
INFO:root:eval perplexity: 5.035980701446533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [4:09:48<11:16:52, 278.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3718.8738580519152
INFO:root:current train perplexity4.373626708984375
INFO:root:current mean train loss 3724.8388970062024
INFO:root:current train perplexity4.347068786621094
INFO:root:current mean train loss 3736.018512412067
INFO:root:current train perplexity4.361127853393555
INFO:root:current mean train loss 3726.5835373985083
INFO:root:current train perplexity4.351537704467773
INFO:root:current mean train loss 3731.276364355242
INFO:root:current train perplexity4.360543251037598
INFO:root:current mean train loss 3734.4822600341336
INFO:root:current train perplexity4.367292404174805
INFO:root:current mean train loss 3732.8948179507975
INFO:root:current train perplexity4.368823528289795
INFO:root:current mean train loss 3734.4872469086654
INFO:root:current train perplexity4.3687744140625
INFO:root:current mean train loss 3735.5767092194083
INFO:root:current train perplexity4.36822509765625
INFO:root:current mean train loss 3737.702440042629
INFO:root:current train perplexity4.367448806762695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.17s/it]
INFO:root:final mean train loss: 3736.2904840284777
INFO:root:final train perplexity: 4.366993427276611
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it]
INFO:root:eval mean loss: 3995.9988347046765
INFO:root:eval perplexity: 5.032237529754639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [4:14:40<11:22:04, 282.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.135967548077
INFO:root:current train perplexity4.308455944061279
INFO:root:current mean train loss 3728.3031032205486
INFO:root:current train perplexity4.336281776428223
INFO:root:current mean train loss 3730.6183673427695
INFO:root:current train perplexity4.341060638427734
INFO:root:current mean train loss 3725.332026208748
INFO:root:current train perplexity4.3341546058654785
INFO:root:current mean train loss 3722.337842241778
INFO:root:current train perplexity4.33519172668457
INFO:root:current mean train loss 3719.3328959335863
INFO:root:current train perplexity4.339418411254883
INFO:root:current mean train loss 3721.1430308740464
INFO:root:current train perplexity4.342674255371094
INFO:root:current mean train loss 3724.5384460366627
INFO:root:current train perplexity4.349036693572998
INFO:root:current mean train loss 3726.9461205792795
INFO:root:current train perplexity4.350645542144775
INFO:root:current mean train loss 3730.7454837884384
INFO:root:current train perplexity4.353301048278809


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.22s/it]
INFO:root:final mean train loss: 3728.3969542595646
INFO:root:final train perplexity: 4.353414535522461
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 3993.9684660350176
INFO:root:eval perplexity: 5.028107166290283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [4:18:48<10:53:11, 272.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.8695250166224
INFO:root:current train perplexity4.339302062988281
INFO:root:current mean train loss 3706.1591016289326
INFO:root:current train perplexity4.314662933349609
INFO:root:current mean train loss 3712.2432895922952
INFO:root:current train perplexity4.317460060119629
INFO:root:current mean train loss 3714.9481753478476
INFO:root:current train perplexity4.320882797241211
INFO:root:current mean train loss 3713.987458709102
INFO:root:current train perplexity4.327479839324951
INFO:root:current mean train loss 3716.6803413684015
INFO:root:current train perplexity4.329283714294434
INFO:root:current mean train loss 3721.378963983409
INFO:root:current train perplexity4.332844257354736
INFO:root:current mean train loss 3721.8009910736696
INFO:root:current train perplexity4.33505392074585
INFO:root:current mean train loss 3723.177593136622
INFO:root:current train perplexity4.336750030517578
INFO:root:current mean train loss 3722.8628037965286
INFO:root:current train perplexity4.336542129516602


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it]
INFO:root:final mean train loss: 3718.5555728174027
INFO:root:final train perplexity: 4.336544036865234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 3992.490797110483
INFO:root:eval perplexity: 5.025103569030762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [4:23:28<10:54:06, 274.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.736279296875
INFO:root:current train perplexity4.253453731536865
INFO:root:current mean train loss 3686.9153918850807
INFO:root:current train perplexity4.287361145019531
INFO:root:current mean train loss 3694.574795113358
INFO:root:current train perplexity4.289089202880859
INFO:root:current mean train loss 3692.924181613116
INFO:root:current train perplexity4.289546012878418
INFO:root:current mean train loss 3704.060132640797
INFO:root:current train perplexity4.302159309387207
INFO:root:current mean train loss 3704.9168329462273
INFO:root:current train perplexity4.307629108428955
INFO:root:current mean train loss 3705.531982421875
INFO:root:current train perplexity4.311801433563232
INFO:root:current mean train loss 3706.8954955246277
INFO:root:current train perplexity4.317870140075684
INFO:root:current mean train loss 3709.0316303453947
INFO:root:current train perplexity4.318406581878662
INFO:root:current mean train loss 3711.851048654287
INFO:root:current train perplexity4.320623397827148


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.88s/it]
INFO:root:final mean train loss: 3709.647467828566
INFO:root:final train perplexity: 4.3213300704956055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it]
INFO:root:eval mean loss: 3993.372122257314
INFO:root:eval perplexity: 5.0268940925598145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [4:27:44<10:36:30, 268.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3700.5237785218255
INFO:root:current train perplexity4.310340404510498
INFO:root:current mean train loss 3678.502889247028
INFO:root:current train perplexity4.26376485824585
INFO:root:current mean train loss 3688.1982171236336
INFO:root:current train perplexity4.273120880126953
INFO:root:current mean train loss 3680.7917258522725
INFO:root:current train perplexity4.274698734283447
INFO:root:current mean train loss 3687.975203116563
INFO:root:current train perplexity4.284700870513916
INFO:root:current mean train loss 3691.1407264723025
INFO:root:current train perplexity4.2876458168029785
INFO:root:current mean train loss 3693.7898604679253
INFO:root:current train perplexity4.291487693786621
INFO:root:current mean train loss 3695.9616670421037
INFO:root:current train perplexity4.298365116119385
INFO:root:current mean train loss 3698.245215635863
INFO:root:current train perplexity4.303070068359375
INFO:root:current mean train loss 3703.268192406136
INFO:root:current train perplexity4.307394027709961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.60s/it]
INFO:root:final mean train loss: 3702.2159856980848
INFO:root:final train perplexity: 4.30867862701416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]
INFO:root:eval mean loss: 3989.0697099401596
INFO:root:eval perplexity: 5.0181565284729
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [4:32:00<10:22:32, 264.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.013720015405
INFO:root:current train perplexity4.266321659088135
INFO:root:current mean train loss 3674.3611125388343
INFO:root:current train perplexity4.252861499786377
INFO:root:current mean train loss 3688.8362690267527
INFO:root:current train perplexity4.269075870513916
INFO:root:current mean train loss 3692.9719435699544
INFO:root:current train perplexity4.280525207519531
INFO:root:current mean train loss 3690.4658420830015
INFO:root:current train perplexity4.286210060119629
INFO:root:current mean train loss 3691.7152948329413
INFO:root:current train perplexity4.289405345916748
INFO:root:current mean train loss 3692.700297189363
INFO:root:current train perplexity4.291299819946289
INFO:root:current mean train loss 3694.5765597767713
INFO:root:current train perplexity4.290297508239746
INFO:root:current mean train loss 3695.171394567128
INFO:root:current train perplexity4.292019844055176
INFO:root:current mean train loss 3694.7235350053907
INFO:root:current train perplexity4.292219638824463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.09s/it]
INFO:root:final mean train loss: 3693.036345758746
INFO:root:final train perplexity: 4.293102741241455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.96s/it]
INFO:root:eval mean loss: 3992.96034879211
INFO:root:eval perplexity: 5.026057243347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:36:10<10:07:41, 260.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3677.5543104727058
INFO:root:current train perplexity4.27212381362915
INFO:root:current mean train loss 3690.7827421220322
INFO:root:current train perplexity4.280972957611084
INFO:root:current mean train loss 3688.1405024921596
INFO:root:current train perplexity4.2843732833862305
INFO:root:current mean train loss 3678.174684227614
INFO:root:current train perplexity4.277120590209961
INFO:root:current mean train loss 3678.799482564588
INFO:root:current train perplexity4.273375034332275
INFO:root:current mean train loss 3682.2405868820165
INFO:root:current train perplexity4.277998447418213
INFO:root:current mean train loss 3680.6601246088
INFO:root:current train perplexity4.274506568908691
INFO:root:current mean train loss 3683.5820462933248
INFO:root:current train perplexity4.277546405792236
INFO:root:current mean train loss 3684.7593737223583
INFO:root:current train perplexity4.276538372039795
INFO:root:current mean train loss 3689.156480175482
INFO:root:current train perplexity4.280858993530273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.12s/it]
INFO:root:final mean train loss: 3685.9024835401965
INFO:root:final train perplexity: 4.281035900115967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 3990.8060657690603
INFO:root:eval perplexity: 5.021681308746338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:40:19<9:55:14, 256.94s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3667.922427824174
INFO:root:current train perplexity4.230091571807861
INFO:root:current mean train loss 3674.9575965595754
INFO:root:current train perplexity4.255432605743408
INFO:root:current mean train loss 3680.2938840646775
INFO:root:current train perplexity4.2625579833984375
INFO:root:current mean train loss 3682.199164496528
INFO:root:current train perplexity4.265079498291016
INFO:root:current mean train loss 3683.3724959293186
INFO:root:current train perplexity4.268650054931641
INFO:root:current mean train loss 3682.6884008664288
INFO:root:current train perplexity4.265635967254639
INFO:root:current mean train loss 3681.499388760007
INFO:root:current train perplexity4.2652106285095215
INFO:root:current mean train loss 3679.9925783731733
INFO:root:current train perplexity4.26707649230957
INFO:root:current mean train loss 3678.7457948359993
INFO:root:current train perplexity4.265556812286377
INFO:root:current mean train loss 3680.165373735515
INFO:root:current train perplexity4.266509532928467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.75s/it]
INFO:root:final mean train loss: 3677.2647401748163
INFO:root:final train perplexity: 4.266471862792969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.59s/it]
INFO:root:eval mean loss: 3991.269808289007
INFO:root:eval perplexity: 5.022623538970947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:44:39<9:53:18, 257.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3644.9794407894738
INFO:root:current train perplexity4.218709945678711
INFO:root:current mean train loss 3658.9660619491187
INFO:root:current train perplexity4.237382411956787
INFO:root:current mean train loss 3663.685776118909
INFO:root:current train perplexity4.240424156188965
INFO:root:current mean train loss 3666.9505049693435
INFO:root:current train perplexity4.244357109069824
INFO:root:current mean train loss 3670.540715258049
INFO:root:current train perplexity4.243908405303955
INFO:root:current mean train loss 3671.970847557773
INFO:root:current train perplexity4.250284194946289
INFO:root:current mean train loss 3671.7185258824193
INFO:root:current train perplexity4.249864101409912
INFO:root:current mean train loss 3673.4678363920007
INFO:root:current train perplexity4.2557902336120605
INFO:root:current mean train loss 3673.2620152649265
INFO:root:current train perplexity4.254979133605957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.02s/it]
INFO:root:final mean train loss: 3669.8958476281937
INFO:root:final train perplexity: 4.254086971282959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 3991.476742575355
INFO:root:eval perplexity: 5.023043155670166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:49:24<10:07:28, 266.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.4244791666665
INFO:root:current train perplexity4.305830955505371
INFO:root:current mean train loss 3674.8361840109224
INFO:root:current train perplexity4.245936393737793
INFO:root:current mean train loss 3660.2047413793102
INFO:root:current train perplexity4.23306131362915
INFO:root:current mean train loss 3659.3539426696575
INFO:root:current train perplexity4.240452766418457
INFO:root:current mean train loss 3666.1728794296682
INFO:root:current train perplexity4.243501663208008
INFO:root:current mean train loss 3669.9998747747886
INFO:root:current train perplexity4.2403244972229
INFO:root:current mean train loss 3669.929857953073
INFO:root:current train perplexity4.239454746246338
INFO:root:current mean train loss 3666.222866009513
INFO:root:current train perplexity4.236480712890625
INFO:root:current mean train loss 3666.450679337251
INFO:root:current train perplexity4.23772668838501
INFO:root:current mean train loss 3666.3403996227853
INFO:root:current train perplexity4.238558292388916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.05s/it]
INFO:root:final mean train loss: 3662.2594782921574
INFO:root:final train perplexity: 4.241289138793945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it]
INFO:root:eval mean loss: 3987.800807222407
INFO:root:eval perplexity: 5.015583038330078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:53:32<9:50:40, 260.59s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3639.1059348366475
INFO:root:current train perplexity4.211042404174805
INFO:root:current mean train loss 3669.542427681588
INFO:root:current train perplexity4.225656509399414
INFO:root:current mean train loss 3644.6033362799913
INFO:root:current train perplexity4.213332176208496
INFO:root:current mean train loss 3633.9100887384448
INFO:root:current train perplexity4.207330703735352
INFO:root:current mean train loss 3640.440832430429
INFO:root:current train perplexity4.2083353996276855
INFO:root:current mean train loss 3646.9913786348766
INFO:root:current train perplexity4.214139461517334
INFO:root:current mean train loss 3651.1770894601577
INFO:root:current train perplexity4.219662666320801
INFO:root:current mean train loss 3653.4210958789336
INFO:root:current train perplexity4.223510265350342
INFO:root:current mean train loss 3657.7001212575137
INFO:root:current train perplexity4.227276802062988
INFO:root:current mean train loss 3655.941748743654
INFO:root:current train perplexity4.2263360023498535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.28s/it]
INFO:root:final mean train loss: 3653.9142648020097
INFO:root:final train perplexity: 4.227348327636719
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]
INFO:root:eval mean loss: 3987.4339088818706
INFO:root:eval perplexity: 5.014838695526123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/65
###################best#############
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:57:40<9:37:51, 256.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.0815943667762
INFO:root:current train perplexity4.1918253898620605
INFO:root:current mean train loss 3643.8599679129466
INFO:root:current train perplexity4.202054977416992
INFO:root:current mean train loss 3642.935406410531
INFO:root:current train perplexity4.199159622192383
INFO:root:current mean train loss 3645.673425560835
INFO:root:current train perplexity4.201109886169434
INFO:root:current mean train loss 3646.844464941639
INFO:root:current train perplexity4.205233097076416
INFO:root:current mean train loss 3643.169436416185
INFO:root:current train perplexity4.1996870040893555
INFO:root:current mean train loss 3648.6057053968093
INFO:root:current train perplexity4.207375526428223
INFO:root:current mean train loss 3646.67769227008
INFO:root:current train perplexity4.209467887878418
INFO:root:current mean train loss 3645.6540330600387
INFO:root:current train perplexity4.206823825836182
INFO:root:current mean train loss 3646.699753521576
INFO:root:current train perplexity4.212401390075684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.28s/it]
INFO:root:final mean train loss: 3646.5396618381624
INFO:root:final train perplexity: 4.215066909790039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.37s/it]
INFO:root:eval mean loss: 3988.5266234485816
INFO:root:eval perplexity: 5.017054557800293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [5:01:47<9:27:20, 254.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3608.4975314670137
INFO:root:current train perplexity4.114518642425537
INFO:root:current mean train loss 3624.106247308686
INFO:root:current train perplexity4.169758319854736
INFO:root:current mean train loss 3639.390014110683
INFO:root:current train perplexity4.1994709968566895
INFO:root:current mean train loss 3640.3185184023796
INFO:root:current train perplexity4.195892810821533
INFO:root:current mean train loss 3642.876727852386
INFO:root:current train perplexity4.194581985473633
INFO:root:current mean train loss 3637.522493366046
INFO:root:current train perplexity4.190859317779541
INFO:root:current mean train loss 3637.530150004361
INFO:root:current train perplexity4.1943206787109375
INFO:root:current mean train loss 3637.975905973285
INFO:root:current train perplexity4.198795318603516
INFO:root:current mean train loss 3638.524329631764
INFO:root:current train perplexity4.20046329498291
INFO:root:current mean train loss 3641.390466980178
INFO:root:current train perplexity4.202500820159912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.56s/it]
INFO:root:final mean train loss: 3640.12916761829
INFO:root:final train perplexity: 4.2044196128845215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 3989.15179140348
INFO:root:eval perplexity: 5.018322944641113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [5:05:58<9:21:03, 253.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3607.4174386160716
INFO:root:current train perplexity4.151066303253174
INFO:root:current mean train loss 3608.7080060040507
INFO:root:current train perplexity4.16399621963501
INFO:root:current mean train loss 3615.5706968916224
INFO:root:current train perplexity4.16874361038208
INFO:root:current mean train loss 3624.736266907649
INFO:root:current train perplexity4.174921035766602
INFO:root:current mean train loss 3624.492877828664
INFO:root:current train perplexity4.175253391265869
INFO:root:current mean train loss 3631.6922573196553
INFO:root:current train perplexity4.180829048156738
INFO:root:current mean train loss 3632.645553949311
INFO:root:current train perplexity4.17948055267334
INFO:root:current mean train loss 3633.487342222045
INFO:root:current train perplexity4.184018611907959
INFO:root:current mean train loss 3634.9704630777505
INFO:root:current train perplexity4.187767505645752
INFO:root:current mean train loss 3636.394175353025
INFO:root:current train perplexity4.189446449279785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.23s/it]
INFO:root:final mean train loss: 3631.679416102748
INFO:root:final train perplexity: 4.190426826477051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 3988.26722663176
INFO:root:eval perplexity: 5.016529083251953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [5:10:06<9:13:14, 251.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3616.1482955577762
INFO:root:current train perplexity4.154974937438965
INFO:root:current mean train loss 3631.44595955802
INFO:root:current train perplexity4.176718711853027
INFO:root:current mean train loss 3631.7650262024176
INFO:root:current train perplexity4.179164886474609
INFO:root:current mean train loss 3629.489835066281
INFO:root:current train perplexity4.173818588256836
INFO:root:current mean train loss 3622.586247222418
INFO:root:current train perplexity4.1677632331848145
INFO:root:current mean train loss 3624.9163721692275
INFO:root:current train perplexity4.170536518096924
INFO:root:current mean train loss 3628.5602670435214
INFO:root:current train perplexity4.1736602783203125
INFO:root:current mean train loss 3628.991537225038
INFO:root:current train perplexity4.176074028015137
INFO:root:current mean train loss 3630.689111675656
INFO:root:current train perplexity4.179389476776123
INFO:root:current mean train loss 3627.756968493173
INFO:root:current train perplexity4.177258491516113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.21s/it]
INFO:root:final mean train loss: 3624.561128124114
INFO:root:final train perplexity: 4.178675651550293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 3991.065133602061
INFO:root:eval perplexity: 5.022207260131836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [5:14:17<9:08:42, 251.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.6016486672793
INFO:root:current train perplexity4.148596286773682
INFO:root:current mean train loss 3598.4580773359894
INFO:root:current train perplexity4.1494460105896
INFO:root:current mean train loss 3603.779067324452
INFO:root:current train perplexity4.147972583770752
INFO:root:current mean train loss 3612.838056167646
INFO:root:current train perplexity4.159217357635498
INFO:root:current mean train loss 3605.6288207195817
INFO:root:current train perplexity4.156528472900391
INFO:root:current mean train loss 3606.66036494371
INFO:root:current train perplexity4.15960168838501
INFO:root:current mean train loss 3611.3355275987665
INFO:root:current train perplexity4.162105083465576
INFO:root:current mean train loss 3612.5314018158083
INFO:root:current train perplexity4.162949085235596
INFO:root:current mean train loss 3615.6488586497503
INFO:root:current train perplexity4.162806510925293
INFO:root:current mean train loss 3618.824412060085
INFO:root:current train perplexity4.164923667907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.09s/it]
INFO:root:final mean train loss: 3616.8530715204056
INFO:root:final train perplexity: 4.165987014770508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 3989.004250817265
INFO:root:eval perplexity: 5.018023490905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [5:19:08<9:30:08, 263.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.709211963718
INFO:root:current train perplexity4.146544933319092
INFO:root:current mean train loss 3585.032661102103
INFO:root:current train perplexity4.139164924621582
INFO:root:current mean train loss 3599.7480694980695
INFO:root:current train perplexity4.145873069763184
INFO:root:current mean train loss 3599.1610321639973
INFO:root:current train perplexity4.14686918258667
INFO:root:current mean train loss 3601.792762374047
INFO:root:current train perplexity4.143801212310791
INFO:root:current mean train loss 3602.2857633259728
INFO:root:current train perplexity4.144689083099365
INFO:root:current mean train loss 3604.193934717019
INFO:root:current train perplexity4.1464338302612305
INFO:root:current mean train loss 3605.0332838618865
INFO:root:current train perplexity4.149566650390625
INFO:root:current mean train loss 3607.7113356851173
INFO:root:current train perplexity4.151860237121582
INFO:root:current mean train loss 3613.500463332573
INFO:root:current train perplexity4.155284881591797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.65s/it]
INFO:root:final mean train loss: 3611.8119261341712
INFO:root:final train perplexity: 4.15770959854126
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it]
INFO:root:eval mean loss: 3989.051035779588
INFO:root:eval perplexity: 5.018118381500244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [5:23:49<9:37:24, 268.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3577.5876355527053
INFO:root:current train perplexity4.087106704711914
INFO:root:current mean train loss 3581.307663968937
INFO:root:current train perplexity4.101547718048096
INFO:root:current mean train loss 3582.0550367948267
INFO:root:current train perplexity4.112743377685547
INFO:root:current mean train loss 3596.5744189852267
INFO:root:current train perplexity4.12768030166626
INFO:root:current mean train loss 3596.79679239996
INFO:root:current train perplexity4.127469062805176
INFO:root:current mean train loss 3592.5537272996585
INFO:root:current train perplexity4.129106044769287
INFO:root:current mean train loss 3598.401232489224
INFO:root:current train perplexity4.132389068603516
INFO:root:current mean train loss 3601.421506083462
INFO:root:current train perplexity4.137856960296631
INFO:root:current mean train loss 3600.5790472151634
INFO:root:current train perplexity4.138295650482178
INFO:root:current mean train loss 3606.7015177619246
INFO:root:current train perplexity4.14532470703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.03s/it]
INFO:root:final mean train loss: 3604.1137481197234
INFO:root:final train perplexity: 4.1451005935668945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]
INFO:root:eval mean loss: 3989.671900972407
INFO:root:eval perplexity: 5.019379138946533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [5:28:43<9:49:13, 276.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.8251399739584
INFO:root:current train perplexity4.118358135223389
INFO:root:current mean train loss 3593.5763504464285
INFO:root:current train perplexity4.111935138702393
INFO:root:current mean train loss 3595.3430202414775
INFO:root:current train perplexity4.114691734313965
INFO:root:current mean train loss 3592.76462890625
INFO:root:current train perplexity4.122314929962158
INFO:root:current mean train loss 3595.780503700658
INFO:root:current train perplexity4.127481460571289
INFO:root:current mean train loss 3596.5417102581523
INFO:root:current train perplexity4.126600742340088
INFO:root:current mean train loss 3596.200419921875
INFO:root:current train perplexity4.126845836639404
INFO:root:current mean train loss 3597.760363218246
INFO:root:current train perplexity4.130777835845947
INFO:root:current mean train loss 3599.7095086495538
INFO:root:current train perplexity4.132079601287842
INFO:root:current mean train loss 3600.1686090244393
INFO:root:current train perplexity4.133825302124023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.58s/it]
INFO:root:final mean train loss: 3597.016973618538
INFO:root:final train perplexity: 4.133511543273926
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.91s/it]
INFO:root:eval mean loss: 3990.175909380541
INFO:root:eval perplexity: 5.020401477813721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:33:38<9:56:31, 281.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3558.73384259695
INFO:root:current train perplexity4.08854866027832
INFO:root:current mean train loss 3577.2321937435963
INFO:root:current train perplexity4.1058125495910645
INFO:root:current mean train loss 3586.4278672289092
INFO:root:current train perplexity4.115565299987793
INFO:root:current mean train loss 3584.779019587345
INFO:root:current train perplexity4.11005163192749
INFO:root:current mean train loss 3587.348872909388
INFO:root:current train perplexity4.117431163787842
INFO:root:current mean train loss 3587.7661250067003
INFO:root:current train perplexity4.120677947998047
INFO:root:current mean train loss 3590.192472175833
INFO:root:current train perplexity4.12186861038208
INFO:root:current mean train loss 3589.390561392481
INFO:root:current train perplexity4.119219779968262
INFO:root:current mean train loss 3591.24750578417
INFO:root:current train perplexity4.119962692260742
INFO:root:current mean train loss 3591.862817059941
INFO:root:current train perplexity4.121448993682861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.88s/it]
INFO:root:final mean train loss: 3589.8509531328755
INFO:root:final train perplexity: 4.1218414306640625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.33s/it]
INFO:root:eval mean loss: 3990.5590352809177
INFO:root:eval perplexity: 5.021179676055908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [5:37:59<9:38:51, 275.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.871386182177
INFO:root:current train perplexity4.106812953948975
INFO:root:current mean train loss 3575.0728651116656
INFO:root:current train perplexity4.090050220489502
INFO:root:current mean train loss 3581.4900825212094
INFO:root:current train perplexity4.097421646118164
INFO:root:current mean train loss 3577.579562994525
INFO:root:current train perplexity4.09769344329834
INFO:root:current mean train loss 3576.7096347536913
INFO:root:current train perplexity4.096510410308838
INFO:root:current mean train loss 3577.981974490403
INFO:root:current train perplexity4.09415864944458
INFO:root:current mean train loss 3579.601177740028
INFO:root:current train perplexity4.100559234619141
INFO:root:current mean train loss 3581.232023410339
INFO:root:current train perplexity4.105048656463623
INFO:root:current mean train loss 3582.9030104100907
INFO:root:current train perplexity4.107909679412842
INFO:root:current mean train loss 3586.0368622780807
INFO:root:current train perplexity4.1111249923706055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.37s/it]
INFO:root:final mean train loss: 3583.2481779283094
INFO:root:final train perplexity: 4.111117839813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.95s/it]
INFO:root:eval mean loss: 3989.675673897385
INFO:root:eval perplexity: 5.019386291503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [5:42:11<9:19:38, 268.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3560.9180550623423
INFO:root:current train perplexity4.07718563079834
INFO:root:current mean train loss 3573.049182680983
INFO:root:current train perplexity4.080830097198486
INFO:root:current mean train loss 3573.008765383309
INFO:root:current train perplexity4.0883469581604
INFO:root:current mean train loss 3573.0072905652805
INFO:root:current train perplexity4.091175556182861
INFO:root:current mean train loss 3577.2141866741295
INFO:root:current train perplexity4.093938827514648
INFO:root:current mean train loss 3577.0684547488
INFO:root:current train perplexity4.090919494628906
INFO:root:current mean train loss 3580.677995629918
INFO:root:current train perplexity4.099056243896484
INFO:root:current mean train loss 3578.7951171263885
INFO:root:current train perplexity4.099122047424316
INFO:root:current mean train loss 3579.2035108996974
INFO:root:current train perplexity4.101195812225342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.70s/it]
INFO:root:final mean train loss: 3577.3616540355065
INFO:root:final train perplexity: 4.101581573486328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 3990.1509066101507
INFO:root:eval perplexity: 5.020350456237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:46:18<9:01:46, 262.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.5577566964284
INFO:root:current train perplexity4.112514019012451
INFO:root:current mean train loss 3577.1237587616824
INFO:root:current train perplexity4.103301048278809
INFO:root:current mean train loss 3569.0178482129377
INFO:root:current train perplexity4.089137077331543
INFO:root:current mean train loss 3565.7671168821253
INFO:root:current train perplexity4.079008102416992
INFO:root:current mean train loss 3567.7820106150184
INFO:root:current train perplexity4.080565452575684
INFO:root:current mean train loss 3567.2494178185098
INFO:root:current train perplexity4.080291271209717
INFO:root:current mean train loss 3572.190943710101
INFO:root:current train perplexity4.085836887359619
INFO:root:current mean train loss 3572.580810892194
INFO:root:current train perplexity4.0877861976623535
INFO:root:current mean train loss 3572.7515208115515
INFO:root:current train perplexity4.088102340698242
INFO:root:current mean train loss 3572.061751427698
INFO:root:current train perplexity4.0882792472839355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.62s/it]
INFO:root:final mean train loss: 3571.0073113595286
INFO:root:final train perplexity: 4.091312408447266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 3991.298609956782
INFO:root:eval perplexity: 5.022682189941406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:51:00<9:09:23, 268.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3518.374462890625
INFO:root:current train perplexity4.002998352050781
INFO:root:current mean train loss 3555.192452870245
INFO:root:current train perplexity4.0497589111328125
INFO:root:current mean train loss 3561.7135072220203
INFO:root:current train perplexity4.058820724487305
INFO:root:current mean train loss 3554.8513144841268
INFO:root:current train perplexity4.054962635040283
INFO:root:current mean train loss 3560.6192253388554
INFO:root:current train perplexity4.066481590270996
INFO:root:current mean train loss 3562.881741125607
INFO:root:current train perplexity4.071315765380859
INFO:root:current mean train loss 3558.732400438262
INFO:root:current train perplexity4.067122459411621
INFO:root:current mean train loss 3562.9524721372377
INFO:root:current train perplexity4.073479175567627
INFO:root:current mean train loss 3563.669277223926
INFO:root:current train perplexity4.07548189163208
INFO:root:current mean train loss 3565.283637775359
INFO:root:current train perplexity4.077335834503174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.78s/it]
INFO:root:final mean train loss: 3564.341483208441
INFO:root:final train perplexity: 4.080566883087158
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.70s/it]
INFO:root:eval mean loss: 3992.1314203789893
INFO:root:eval perplexity: 5.024372577667236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:55:10<8:54:10, 262.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.381092900815
INFO:root:current train perplexity4.064795017242432
INFO:root:current mean train loss 3549.6705530678355
INFO:root:current train perplexity4.064142227172852
INFO:root:current mean train loss 3548.3375501418864
INFO:root:current train perplexity4.066230297088623
INFO:root:current mean train loss 3551.1690435734326
INFO:root:current train perplexity4.061144828796387
INFO:root:current mean train loss 3550.160579888815
INFO:root:current train perplexity4.05965518951416
INFO:root:current mean train loss 3549.4987933011175
INFO:root:current train perplexity4.061769485473633
INFO:root:current mean train loss 3554.321282792436
INFO:root:current train perplexity4.0639777183532715
INFO:root:current mean train loss 3554.54933700456
INFO:root:current train perplexity4.062793731689453
INFO:root:current mean train loss 3557.1829135380276
INFO:root:current train perplexity4.064233303070068
INFO:root:current mean train loss 3558.4726829652795
INFO:root:current train perplexity4.069068431854248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.36s/it]
INFO:root:final mean train loss: 3558.0071946420976
INFO:root:final train perplexity: 4.0703816413879395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.02s/it]
INFO:root:eval mean loss: 3993.496734402704
INFO:root:eval perplexity: 5.0271477699279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:59:58<9:05:15, 270.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3543.858217300907
INFO:root:current train perplexity4.032717704772949
INFO:root:current mean train loss 3544.6835303852577
INFO:root:current train perplexity4.041580677032471
INFO:root:current mean train loss 3552.5398889847133
INFO:root:current train perplexity4.047460556030273
INFO:root:current mean train loss 3556.852005050982
INFO:root:current train perplexity4.050503730773926
INFO:root:current mean train loss 3554.6578236024507
INFO:root:current train perplexity4.055235385894775
INFO:root:current mean train loss 3554.8685672853403
INFO:root:current train perplexity4.059483051300049
INFO:root:current mean train loss 3554.0148368629903
INFO:root:current train perplexity4.05804967880249
INFO:root:current mean train loss 3553.6432651253635
INFO:root:current train perplexity4.058040142059326
INFO:root:current mean train loss 3557.0924470352925
INFO:root:current train perplexity4.062798023223877
INFO:root:current mean train loss 3553.621341037443
INFO:root:current train perplexity4.0609211921691895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.29s/it]
INFO:root:final mean train loss: 3551.5741683590795
INFO:root:final train perplexity: 4.060064315795898
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 3993.2436661957004
INFO:root:eval perplexity: 5.026633262634277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [6:04:34<9:03:40, 271.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.584072015224
INFO:root:current train perplexity4.040950775146484
INFO:root:current mean train loss 3523.6696935420414
INFO:root:current train perplexity4.020545482635498
INFO:root:current mean train loss 3527.0490497924293
INFO:root:current train perplexity4.021871566772461
INFO:root:current mean train loss 3532.074344781296
INFO:root:current train perplexity4.021533012390137
INFO:root:current mean train loss 3534.9954675487616
INFO:root:current train perplexity4.033778667449951
INFO:root:current mean train loss 3535.203918570269
INFO:root:current train perplexity4.035736560821533
INFO:root:current mean train loss 3542.1810426906054
INFO:root:current train perplexity4.042311668395996
INFO:root:current mean train loss 3545.011482538164
INFO:root:current train perplexity4.047966480255127
INFO:root:current mean train loss 3546.5899330839356
INFO:root:current train perplexity4.049596786499023
INFO:root:current mean train loss 3546.380012032831
INFO:root:current train perplexity4.04888916015625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.24s/it]
INFO:root:final mean train loss: 3545.643827807519
INFO:root:final train perplexity: 4.050576210021973
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.96s/it]
INFO:root:eval mean loss: 3994.334865705341
INFO:root:eval perplexity: 5.0288519859313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [6:08:52<8:50:53, 267.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3549.29000270113
INFO:root:current train perplexity4.08029317855835
INFO:root:current mean train loss 3556.3957669005104
INFO:root:current train perplexity4.054387092590332
INFO:root:current mean train loss 3537.9211060064526
INFO:root:current train perplexity4.0344319343566895
INFO:root:current mean train loss 3535.8612099243514
INFO:root:current train perplexity4.031130313873291
INFO:root:current mean train loss 3542.0422013728676
INFO:root:current train perplexity4.0322041511535645
INFO:root:current mean train loss 3536.3995336780163
INFO:root:current train perplexity4.032209873199463
INFO:root:current mean train loss 3539.4687990545303
INFO:root:current train perplexity4.035952091217041
INFO:root:current mean train loss 3542.5235404508658
INFO:root:current train perplexity4.036094665527344
INFO:root:current mean train loss 3545.1759991606405
INFO:root:current train perplexity4.039567470550537
INFO:root:current mean train loss 3542.7593750515607
INFO:root:current train perplexity4.042078971862793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.47s/it]
INFO:root:final mean train loss: 3539.8602999410323
INFO:root:final train perplexity: 4.041344165802002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 3997.0132130291445
INFO:root:eval perplexity: 5.034301280975342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [6:13:38<8:57:28, 273.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3537.6073686079544
INFO:root:current train perplexity4.026463031768799
INFO:root:current mean train loss 3530.1161243069555
INFO:root:current train perplexity4.022538185119629
INFO:root:current mean train loss 3525.3925541896447
INFO:root:current train perplexity4.018985271453857
INFO:root:current mean train loss 3529.875543986576
INFO:root:current train perplexity4.027377128601074
INFO:root:current mean train loss 3527.4622091775414
INFO:root:current train perplexity4.031423091888428
INFO:root:current mean train loss 3530.452179669904
INFO:root:current train perplexity4.032037734985352
INFO:root:current mean train loss 3531.9291447996184
INFO:root:current train perplexity4.032017230987549
INFO:root:current mean train loss 3534.729853062914
INFO:root:current train perplexity4.032627582550049
INFO:root:current mean train loss 3535.4845674570543
INFO:root:current train perplexity4.031372547149658
INFO:root:current mean train loss 3538.192656096613
INFO:root:current train perplexity4.0331597328186035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.47s/it]
INFO:root:final mean train loss: 3533.7875788288734
INFO:root:final train perplexity: 4.031673431396484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it]
INFO:root:eval mean loss: 3996.2346901318706
INFO:root:eval perplexity: 5.032716274261475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [6:18:22<8:59:10, 276.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.3244435143847
INFO:root:current train perplexity3.981011390686035
INFO:root:current mean train loss 3524.965015996453
INFO:root:current train perplexity4.003926753997803
INFO:root:current mean train loss 3516.2346070728377
INFO:root:current train perplexity4.010744571685791
INFO:root:current mean train loss 3516.8180728628618
INFO:root:current train perplexity4.013075351715088
INFO:root:current mean train loss 3520.9385256015457
INFO:root:current train perplexity4.012628555297852
INFO:root:current mean train loss 3523.10005646023
INFO:root:current train perplexity4.015930652618408
INFO:root:current mean train loss 3527.536007980416
INFO:root:current train perplexity4.019924163818359
INFO:root:current mean train loss 3530.6865410361033
INFO:root:current train perplexity4.023460388183594
INFO:root:current mean train loss 3529.624545100666
INFO:root:current train perplexity4.021209716796875
INFO:root:current mean train loss 3529.7396355586384
INFO:root:current train perplexity4.02166223526001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.37s/it]
INFO:root:final mean train loss: 3527.543703140751
INFO:root:final train perplexity: 4.021753787994385
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.05s/it]
INFO:root:eval mean loss: 3996.9669353945037
INFO:root:eval perplexity: 5.034206867218018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [6:23:08<9:00:14, 279.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.1261966329225
INFO:root:current train perplexity3.9891390800476074
INFO:root:current mean train loss 3508.4602536207053
INFO:root:current train perplexity3.9925220012664795
INFO:root:current mean train loss 3505.443836845595
INFO:root:current train perplexity3.992614984512329
INFO:root:current mean train loss 3509.5461978552476
INFO:root:current train perplexity4.0007710456848145
INFO:root:current mean train loss 3512.201483918856
INFO:root:current train perplexity4.000515460968018
INFO:root:current mean train loss 3517.5327075751147
INFO:root:current train perplexity4.004090785980225
INFO:root:current mean train loss 3522.1151117589184
INFO:root:current train perplexity4.008991718292236
INFO:root:current mean train loss 3525.6966646147453
INFO:root:current train perplexity4.010422229766846
INFO:root:current mean train loss 3526.2576661838048
INFO:root:current train perplexity4.012805938720703
INFO:root:current mean train loss 3525.1053915603275
INFO:root:current train perplexity4.013607501983643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.61s/it]
INFO:root:final mean train loss: 3522.2800906396683
INFO:root:final train perplexity: 4.013411045074463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 3997.411588195368
INFO:root:eval perplexity: 5.035111904144287
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [6:27:51<8:57:21, 280.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.5178160848495
INFO:root:current train perplexity4.000572681427002
INFO:root:current mean train loss 3501.2258273502966
INFO:root:current train perplexity3.997591733932495
INFO:root:current mean train loss 3513.3882745995743
INFO:root:current train perplexity3.9983956813812256
INFO:root:current mean train loss 3516.466828439355
INFO:root:current train perplexity3.995687961578369
INFO:root:current mean train loss 3517.1447096408533
INFO:root:current train perplexity3.99849009513855
INFO:root:current mean train loss 3515.0978860542155
INFO:root:current train perplexity3.999178886413574
INFO:root:current mean train loss 3513.2224279299753
INFO:root:current train perplexity3.9992613792419434
INFO:root:current mean train loss 3516.1294145890165
INFO:root:current train perplexity4.000927925109863
INFO:root:current mean train loss 3517.5676322303398
INFO:root:current train perplexity4.000871658325195
INFO:root:current mean train loss 3518.479034080934
INFO:root:current train perplexity4.001655101776123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.43s/it]
INFO:root:final mean train loss: 3515.177505493164
INFO:root:final train perplexity: 4.0021796226501465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 3997.028581768063
INFO:root:eval perplexity: 5.034332275390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [6:32:44<8:59:46, 284.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.1461841100936
INFO:root:current train perplexity3.964071035385132
INFO:root:current mean train loss 3488.8667370801304
INFO:root:current train perplexity3.9713284969329834
INFO:root:current mean train loss 3491.6349561737807
INFO:root:current train perplexity3.9846596717834473
INFO:root:current mean train loss 3496.100766361838
INFO:root:current train perplexity3.9841105937957764
INFO:root:current mean train loss 3500.465243298415
INFO:root:current train perplexity3.985383987426758
INFO:root:current mean train loss 3507.061173239193
INFO:root:current train perplexity3.989938974380493
INFO:root:current mean train loss 3507.1420873561456
INFO:root:current train perplexity3.988955020904541
INFO:root:current mean train loss 3509.911125367297
INFO:root:current train perplexity3.9926838874816895
INFO:root:current mean train loss 3511.0302962826768
INFO:root:current train perplexity3.9929213523864746
INFO:root:current mean train loss 3512.8013857886904
INFO:root:current train perplexity3.993978261947632


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.59s/it]
INFO:root:final mean train loss: 3510.1407124919274
INFO:root:final train perplexity: 3.994234800338745
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]
INFO:root:eval mean loss: 3998.980056654477
INFO:root:eval perplexity: 5.0383076667785645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [6:37:18<8:49:27, 281.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.5243857935857
INFO:root:current train perplexity3.957512140274048
INFO:root:current mean train loss 3513.908710186298
INFO:root:current train perplexity3.976433277130127
INFO:root:current mean train loss 3511.40365052304
INFO:root:current train perplexity3.981412410736084
INFO:root:current mean train loss 3503.04658203125
INFO:root:current train perplexity3.977527618408203
INFO:root:current mean train loss 3502.7084053424874
INFO:root:current train perplexity3.9772491455078125
INFO:root:current mean train loss 3503.9140731683297
INFO:root:current train perplexity3.974606513977051
INFO:root:current mean train loss 3503.62810111286
INFO:root:current train perplexity3.977463483810425
INFO:root:current mean train loss 3505.769672820853
INFO:root:current train perplexity3.9825961589813232
INFO:root:current mean train loss 3507.979775881634
INFO:root:current train perplexity3.98660945892334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:04<00:00, 244.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:04<00:00, 244.31s/it]
INFO:root:final mean train loss: 3506.07830644423
INFO:root:final train perplexity: 3.9878387451171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.84s/it]
INFO:root:eval mean loss: 4000.630648132757
INFO:root:eval perplexity: 5.041671276092529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [6:42:21<8:57:19, 287.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.9695638020835
INFO:root:current train perplexity4.065760135650635
INFO:root:current mean train loss 3508.987949408374
INFO:root:current train perplexity3.971841335296631
INFO:root:current mean train loss 3499.5152076758773
INFO:root:current train perplexity3.9662911891937256
INFO:root:current mean train loss 3493.0132536935334
INFO:root:current train perplexity3.958231210708618
INFO:root:current mean train loss 3498.059319507987
INFO:root:current train perplexity3.9682719707489014
INFO:root:current mean train loss 3498.4502778252363
INFO:root:current train perplexity3.9715921878814697
INFO:root:current mean train loss 3499.502096856214
INFO:root:current train perplexity3.9709322452545166
INFO:root:current mean train loss 3495.910562572235
INFO:root:current train perplexity3.969712495803833
INFO:root:current mean train loss 3498.114380642902
INFO:root:current train perplexity3.970004081726074
INFO:root:current mean train loss 3499.1396200490553
INFO:root:current train perplexity3.9748423099517822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.37s/it]
INFO:root:final mean train loss: 3498.301294265255
INFO:root:final train perplexity: 3.975621461868286
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 4003.669426667775
INFO:root:eval perplexity: 5.047869682312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [6:46:40<8:36:21, 279.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.0146706321025
INFO:root:current train perplexity3.9221980571746826
INFO:root:current mean train loss 3487.8667608037726
INFO:root:current train perplexity3.959041118621826
INFO:root:current mean train loss 3485.3095656842415
INFO:root:current train perplexity3.9580440521240234
INFO:root:current mean train loss 3483.692571216841
INFO:root:current train perplexity3.959007978439331
INFO:root:current mean train loss 3482.019372647696
INFO:root:current train perplexity3.9525041580200195
INFO:root:current mean train loss 3484.2478524224866
INFO:root:current train perplexity3.9541282653808594
INFO:root:current mean train loss 3486.4060957638603
INFO:root:current train perplexity3.9605658054351807
INFO:root:current mean train loss 3491.807008724508
INFO:root:current train perplexity3.9611809253692627
INFO:root:current mean train loss 3492.253288824079
INFO:root:current train perplexity3.96356201171875
INFO:root:current mean train loss 3494.78525755094
INFO:root:current train perplexity3.9670114517211914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.41s/it]
INFO:root:final mean train loss: 3494.9708922601517
INFO:root:final train perplexity: 3.9704012870788574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]
INFO:root:eval mean loss: 4003.342621066046
INFO:root:eval perplexity: 5.047203063964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [6:50:50<8:15:41, 270.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.4443102384867
INFO:root:current train perplexity3.9994773864746094
INFO:root:current mean train loss 3485.0208176043857
INFO:root:current train perplexity3.9384078979492188
INFO:root:current mean train loss 3496.9622942084047
INFO:root:current train perplexity3.943525791168213
INFO:root:current mean train loss 3493.901654186667
INFO:root:current train perplexity3.9504146575927734
INFO:root:current mean train loss 3494.877481610792
INFO:root:current train perplexity3.95005202293396
INFO:root:current mean train loss 3493.0246455021675
INFO:root:current train perplexity3.9510109424591064
INFO:root:current mean train loss 3490.048720845113
INFO:root:current train perplexity3.952401876449585
INFO:root:current mean train loss 3486.983426620632
INFO:root:current train perplexity3.9558680057525635
INFO:root:current mean train loss 3487.6873440957916
INFO:root:current train perplexity3.956329584121704
INFO:root:current mean train loss 3491.8564285759826
INFO:root:current train perplexity3.9602088928222656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.00s/it]
INFO:root:final mean train loss: 3488.195214609946
INFO:root:final train perplexity: 3.959801435470581
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4002.6865944287456
INFO:root:eval perplexity: 5.045864582061768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:55:09<8:04:50, 266.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.4083839699074
INFO:root:current train perplexity3.960411310195923
INFO:root:current mean train loss 3471.1630263441193
INFO:root:current train perplexity3.933046579360962
INFO:root:current mean train loss 3472.846777558852
INFO:root:current train perplexity3.9399659633636475
INFO:root:current mean train loss 3476.707110390386
INFO:root:current train perplexity3.942544460296631
INFO:root:current mean train loss 3471.909595927254
INFO:root:current train perplexity3.9413094520568848
INFO:root:current mean train loss 3477.872053634962
INFO:root:current train perplexity3.9461607933044434
INFO:root:current mean train loss 3480.19860742499
INFO:root:current train perplexity3.9454710483551025
INFO:root:current mean train loss 3482.7232969932084
INFO:root:current train perplexity3.9478182792663574
INFO:root:current mean train loss 3483.625990437481
INFO:root:current train perplexity3.950082540512085
INFO:root:current mean train loss 3483.9395208101573
INFO:root:current train perplexity3.950241804122925


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.23s/it]
INFO:root:final mean train loss: 3482.270602072439
INFO:root:final train perplexity: 3.950557231903076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 4005.8844175947474
INFO:root:eval perplexity: 5.052392959594727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:59:16<7:49:59, 261.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.7764439174107
INFO:root:current train perplexity3.928008556365967
INFO:root:current mean train loss 3471.980564597801
INFO:root:current train perplexity3.9305901527404785
INFO:root:current mean train loss 3478.00537109375
INFO:root:current train perplexity3.9396140575408936
INFO:root:current mean train loss 3479.6880597014924
INFO:root:current train perplexity3.939262866973877
INFO:root:current mean train loss 3483.537020137392
INFO:root:current train perplexity3.9441463947296143
INFO:root:current mean train loss 3484.514225868867
INFO:root:current train perplexity3.9461517333984375
INFO:root:current mean train loss 3480.28443113312
INFO:root:current train perplexity3.940782308578491
INFO:root:current mean train loss 3476.972141395621
INFO:root:current train perplexity3.939016342163086
INFO:root:current mean train loss 3478.335468516093
INFO:root:current train perplexity3.9404149055480957
INFO:root:current mean train loss 3477.6209013097427
INFO:root:current train perplexity3.939321517944336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.46s/it]
INFO:root:final mean train loss: 3477.3458297483385
INFO:root:final train perplexity: 3.942888021469116
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4005.600998033023
INFO:root:eval perplexity: 5.051814556121826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [7:03:23<7:38:04, 256.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.2023130904795
INFO:root:current train perplexity3.916818380355835
INFO:root:current mean train loss 3474.2555384069055
INFO:root:current train perplexity3.9134573936462402
INFO:root:current mean train loss 3465.5129977253728
INFO:root:current train perplexity3.924736976623535
INFO:root:current mean train loss 3467.019859380694
INFO:root:current train perplexity3.9258534908294678
INFO:root:current mean train loss 3465.6379482708453
INFO:root:current train perplexity3.9249660968780518
INFO:root:current mean train loss 3466.0574382409645
INFO:root:current train perplexity3.925398588180542
INFO:root:current mean train loss 3468.546994982018
INFO:root:current train perplexity3.9306724071502686
INFO:root:current mean train loss 3474.8403090301144
INFO:root:current train perplexity3.9343619346618652
INFO:root:current mean train loss 3474.699717167575
INFO:root:current train perplexity3.9345734119415283
INFO:root:current mean train loss 3475.1028238500794
INFO:root:current train perplexity3.93513822555542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.78s/it]
INFO:root:final mean train loss: 3472.6015625
INFO:root:final train perplexity: 3.9355154037475586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it]
INFO:root:eval mean loss: 4007.2679694425974
INFO:root:eval perplexity: 5.0552215576171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [7:07:43<7:35:19, 257.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3465.3102692248776
INFO:root:current train perplexity3.945227861404419
INFO:root:current mean train loss 3475.737566613204
INFO:root:current train perplexity3.9327244758605957
INFO:root:current mean train loss 3474.9738574996886
INFO:root:current train perplexity3.9328103065490723
INFO:root:current mean train loss 3473.1079630186077
INFO:root:current train perplexity3.921039342880249
INFO:root:current mean train loss 3470.50391545264
INFO:root:current train perplexity3.9220316410064697
INFO:root:current mean train loss 3472.271606666856
INFO:root:current train perplexity3.9269955158233643
INFO:root:current mean train loss 3471.7518664944555
INFO:root:current train perplexity3.9298558235168457
INFO:root:current mean train loss 3471.32889903306
INFO:root:current train perplexity3.9279398918151855
INFO:root:current mean train loss 3470.9269603545463
INFO:root:current train perplexity3.9289448261260986
INFO:root:current mean train loss 3472.0394750488795
INFO:root:current train perplexity3.9316658973693848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.63s/it]
INFO:root:final mean train loss: 3468.479240540535
INFO:root:final train perplexity: 3.92911958694458
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4009.3312191794103
INFO:root:eval perplexity: 5.059439659118652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [7:11:50<7:25:22, 254.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3423.6153626522773
INFO:root:current train perplexity3.858144998550415
INFO:root:current mean train loss 3442.1145541592964
INFO:root:current train perplexity3.8763275146484375
INFO:root:current mean train loss 3446.208105845801
INFO:root:current train perplexity3.8860371112823486
INFO:root:current mean train loss 3455.9871387534818
INFO:root:current train perplexity3.898419141769409
INFO:root:current mean train loss 3457.9356798491967
INFO:root:current train perplexity3.903343915939331
INFO:root:current mean train loss 3462.467600923105
INFO:root:current train perplexity3.907721996307373
INFO:root:current mean train loss 3461.8972038303773
INFO:root:current train perplexity3.910421133041382
INFO:root:current mean train loss 3465.1933571233735
INFO:root:current train perplexity3.9150547981262207
INFO:root:current mean train loss 3467.287365452652
INFO:root:current train perplexity3.9185991287231445
INFO:root:current mean train loss 3467.786696194359
INFO:root:current train perplexity3.9206326007843018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.98s/it]
INFO:root:final mean train loss: 3463.387382753434
INFO:root:final train perplexity: 3.921234607696533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it]
INFO:root:eval mean loss: 4008.1455857297206
INFO:root:eval perplexity: 5.057015895843506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [7:16:07<7:22:05, 255.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3461.999325880364
INFO:root:current train perplexity3.937181234359741
INFO:root:current mean train loss 3462.551076557822
INFO:root:current train perplexity3.9177873134613037
INFO:root:current mean train loss 3466.6834319039676
INFO:root:current train perplexity3.917170524597168
INFO:root:current mean train loss 3465.1215640699506
INFO:root:current train perplexity3.9127891063690186
INFO:root:current mean train loss 3461.8963071508633
INFO:root:current train perplexity3.9110219478607178
INFO:root:current mean train loss 3458.777706300981
INFO:root:current train perplexity3.9098081588745117
INFO:root:current mean train loss 3459.255170510448
INFO:root:current train perplexity3.9089694023132324
INFO:root:current mean train loss 3457.492795145962
INFO:root:current train perplexity3.9114224910736084
INFO:root:current mean train loss 3460.8806315667352
INFO:root:current train perplexity3.9131221771240234
INFO:root:current mean train loss 3460.926065281234
INFO:root:current train perplexity3.914041519165039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.84s/it]
INFO:root:final mean train loss: 3458.478175563197
INFO:root:final train perplexity: 3.913646936416626
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.73s/it]
INFO:root:eval mean loss: 4010.293095149047
INFO:root:eval perplexity: 5.061407566070557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [7:20:26<7:20:08, 256.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.0818033854166
INFO:root:current train perplexity3.9139511585235596
INFO:root:current mean train loss 3445.789337332589
INFO:root:current train perplexity3.9007532596588135
INFO:root:current mean train loss 3456.378955965909
INFO:root:current train perplexity3.8976738452911377
INFO:root:current mean train loss 3459.5249837239585
INFO:root:current train perplexity3.8980116844177246
INFO:root:current mean train loss 3456.452294921875
INFO:root:current train perplexity3.900341272354126
INFO:root:current mean train loss 3453.370060716712
INFO:root:current train perplexity3.903459310531616
INFO:root:current mean train loss 3457.7757533998843
INFO:root:current train perplexity3.9051551818847656
INFO:root:current mean train loss 3456.138660534274
INFO:root:current train perplexity3.904714822769165
INFO:root:current mean train loss 3456.7506707589287
INFO:root:current train perplexity3.904658555984497
INFO:root:current mean train loss 3455.553803585737
INFO:root:current train perplexity3.9062485694885254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.05s/it]
INFO:root:final mean train loss: 3453.796228654923
INFO:root:final train perplexity: 3.9064249992370605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4009.6298689605496
INFO:root:eval perplexity: 5.060050010681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [7:25:20<7:35:12, 267.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3434.3875305911147
INFO:root:current train perplexity3.8782124519348145
INFO:root:current mean train loss 3437.1990079619195
INFO:root:current train perplexity3.889430046081543
INFO:root:current mean train loss 3451.745181889079
INFO:root:current train perplexity3.891623020172119
INFO:root:current mean train loss 3451.699719780108
INFO:root:current train perplexity3.8880465030670166
INFO:root:current mean train loss 3451.5597209417056
INFO:root:current train perplexity3.8909382820129395
INFO:root:current mean train loss 3450.6996366785484
INFO:root:current train perplexity3.8920962810516357
INFO:root:current mean train loss 3452.4635347559024
INFO:root:current train perplexity3.89613676071167
INFO:root:current mean train loss 3449.807828900762
INFO:root:current train perplexity3.8951210975646973
INFO:root:current mean train loss 3450.794801601872
INFO:root:current train perplexity3.8954875469207764
INFO:root:current mean train loss 3451.5491241734485
INFO:root:current train perplexity3.898366689682007


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.53s/it]
INFO:root:final mean train loss: 3448.797025680542
INFO:root:final train perplexity: 3.8987278938293457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 4011.867914727394
INFO:root:eval perplexity: 5.064632892608643
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [7:30:11<7:42:23, 274.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.136039985405
INFO:root:current train perplexity3.8451335430145264
INFO:root:current mean train loss 3428.4333815649543
INFO:root:current train perplexity3.854581594467163
INFO:root:current mean train loss 3434.2408317225086
INFO:root:current train perplexity3.868854284286499
INFO:root:current mean train loss 3440.3813894910886
INFO:root:current train perplexity3.877854108810425
INFO:root:current mean train loss 3441.253026647626
INFO:root:current train perplexity3.880164384841919
INFO:root:current mean train loss 3441.233761550206
INFO:root:current train perplexity3.8794705867767334
INFO:root:current mean train loss 3442.496889061935
INFO:root:current train perplexity3.881770610809326
INFO:root:current mean train loss 3443.031468522835
INFO:root:current train perplexity3.8835952281951904
INFO:root:current mean train loss 3441.6422046528655
INFO:root:current train perplexity3.884728193283081
INFO:root:current mean train loss 3445.3125948477705
INFO:root:current train perplexity3.88926100730896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.90s/it]
INFO:root:final mean train loss: 3442.583525442308
INFO:root:final train perplexity: 3.889181613922119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4012.2746962959886
INFO:root:eval perplexity: 5.065466403961182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [7:34:22<7:25:44, 267.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3416.1345954663825
INFO:root:current train perplexity3.845468044281006
INFO:root:current mean train loss 3422.453361779601
INFO:root:current train perplexity3.8667330741882324
INFO:root:current mean train loss 3426.90324355926
INFO:root:current train perplexity3.870223045349121
INFO:root:current mean train loss 3424.1679858826756
INFO:root:current train perplexity3.8659276962280273
INFO:root:current mean train loss 3429.230345945798
INFO:root:current train perplexity3.867772102355957
INFO:root:current mean train loss 3432.0247837378706
INFO:root:current train perplexity3.8722281455993652
INFO:root:current mean train loss 3437.405209870127
INFO:root:current train perplexity3.8769490718841553
INFO:root:current mean train loss 3441.036822456293
INFO:root:current train perplexity3.8797976970672607
INFO:root:current mean train loss 3440.635041267641
INFO:root:current train perplexity3.8811538219451904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.90s/it]
INFO:root:final mean train loss: 3437.832823353429
INFO:root:final train perplexity: 3.881898880004883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]
INFO:root:eval mean loss: 4013.0675473044103
INFO:root:eval perplexity: 5.067089557647705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [7:39:05<7:29:20, 272.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3374.8680594308034
INFO:root:current train perplexity3.826582431793213
INFO:root:current mean train loss 3455.7606281030958
INFO:root:current train perplexity3.8745744228363037
INFO:root:current mean train loss 3440.321535561972
INFO:root:current train perplexity3.8637163639068604
INFO:root:current mean train loss 3433.2409413489922
INFO:root:current train perplexity3.871229410171509
INFO:root:current mean train loss 3438.7633875441493
INFO:root:current train perplexity3.8740062713623047
INFO:root:current mean train loss 3437.8783442931767
INFO:root:current train perplexity3.875871419906616
INFO:root:current mean train loss 3436.075315572874
INFO:root:current train perplexity3.8723695278167725
INFO:root:current mean train loss 3435.128449392791
INFO:root:current train perplexity3.8731021881103516
INFO:root:current mean train loss 3436.5134749288454
INFO:root:current train perplexity3.875483989715576
INFO:root:current mean train loss 3435.924962961687
INFO:root:current train perplexity3.8766658306121826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.26s/it]
INFO:root:final mean train loss: 3434.6540016051263
INFO:root:final train perplexity: 3.8770341873168945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.09s/it]
INFO:root:eval mean loss: 4018.4462423121677
INFO:root:eval perplexity: 5.078123092651367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [7:44:00<7:35:53, 279.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3400.77734375
INFO:root:current train perplexity3.8015873432159424
INFO:root:current mean train loss 3409.5882451596467
INFO:root:current train perplexity3.8211073875427246
INFO:root:current mean train loss 3410.6200331577033
INFO:root:current train perplexity3.834838390350342
INFO:root:current mean train loss 3425.6930516803077
INFO:root:current train perplexity3.849785089492798
INFO:root:current mean train loss 3432.2245758424324
INFO:root:current train perplexity3.856538772583008
INFO:root:current mean train loss 3427.8030022185985
INFO:root:current train perplexity3.854017972946167
INFO:root:current mean train loss 3429.5299991266515
INFO:root:current train perplexity3.857400417327881
INFO:root:current mean train loss 3427.051537232299
INFO:root:current train perplexity3.858778238296509
INFO:root:current mean train loss 3427.4695537169287
INFO:root:current train perplexity3.861859083175659
INFO:root:current mean train loss 3428.921802958504
INFO:root:current train perplexity3.864877700805664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.63s/it]
INFO:root:final mean train loss: 3428.0796349433163
INFO:root:final train perplexity: 3.866990566253662
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4014.845382798648
INFO:root:eval perplexity: 5.070734024047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [7:48:55<7:38:31, 283.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.5046174422555
INFO:root:current train perplexity3.8077030181884766
INFO:root:current mean train loss 3413.740420954014
INFO:root:current train perplexity3.8290839195251465
INFO:root:current mean train loss 3419.031744850056
INFO:root:current train perplexity3.8424267768859863
INFO:root:current mean train loss 3415.9941292872
INFO:root:current train perplexity3.843233108520508
INFO:root:current mean train loss 3415.3155699384974
INFO:root:current train perplexity3.8459360599517822
INFO:root:current mean train loss 3419.6282527186904
INFO:root:current train perplexity3.854041814804077
INFO:root:current mean train loss 3422.957156651284
INFO:root:current train perplexity3.8582475185394287
INFO:root:current mean train loss 3424.3870554141813
INFO:root:current train perplexity3.8610682487487793
INFO:root:current mean train loss 3425.004050420527
INFO:root:current train perplexity3.860865354537964
INFO:root:current mean train loss 3425.942036571895
INFO:root:current train perplexity3.8599228858947754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.17s/it]
INFO:root:final mean train loss: 3425.234315995247
INFO:root:final train perplexity: 3.862652540206909
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it]
INFO:root:eval mean loss: 4016.178608779366
INFO:root:eval perplexity: 5.0734686851501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [7:53:50<7:39:37, 287.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.9025485131046
INFO:root:current train perplexity3.8057384490966797
INFO:root:current mean train loss 3394.8818396648376
INFO:root:current train perplexity3.824955701828003
INFO:root:current mean train loss 3391.65991845069
INFO:root:current train perplexity3.832120180130005
INFO:root:current mean train loss 3402.148576165974
INFO:root:current train perplexity3.842560052871704
INFO:root:current mean train loss 3403.2199270863543
INFO:root:current train perplexity3.8417906761169434
INFO:root:current mean train loss 3408.660049122381
INFO:root:current train perplexity3.8451833724975586
INFO:root:current mean train loss 3414.1079399483706
INFO:root:current train perplexity3.8483288288116455
INFO:root:current mean train loss 3415.843086378356
INFO:root:current train perplexity3.849527597427368
INFO:root:current mean train loss 3421.9715492441337
INFO:root:current train perplexity3.8555150032043457
INFO:root:current mean train loss 3422.13047808556
INFO:root:current train perplexity3.8542351722717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.72s/it]
INFO:root:final mean train loss: 3420.9860586350965
INFO:root:final train perplexity: 3.8561837673187256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4016.193350717531
INFO:root:eval perplexity: 5.073498725891113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [7:58:43<7:37:27, 288.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3403.3333708934297
INFO:root:current train perplexity3.846895456314087
INFO:root:current mean train loss 3416.619741316322
INFO:root:current train perplexity3.840001344680786
INFO:root:current mean train loss 3411.6775923852642
INFO:root:current train perplexity3.8415839672088623
INFO:root:current mean train loss 3421.46843456167
INFO:root:current train perplexity3.844020128250122
INFO:root:current mean train loss 3418.0573096481708
INFO:root:current train perplexity3.8414087295532227
INFO:root:current mean train loss 3417.396056336242
INFO:root:current train perplexity3.84196138381958
INFO:root:current mean train loss 3420.548041449653
INFO:root:current train perplexity3.8440661430358887
INFO:root:current mean train loss 3421.264221273998
INFO:root:current train perplexity3.845466375350952
INFO:root:current mean train loss 3419.199449505084
INFO:root:current train perplexity3.845407485961914
INFO:root:current mean train loss 3418.5620709989016
INFO:root:current train perplexity3.8468265533447266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.36s/it]
INFO:root:final mean train loss: 3415.200564661334
INFO:root:final train perplexity: 3.8473916053771973
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 4018.6954371675533
INFO:root:eval perplexity: 5.078633785247803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [8:03:41<7:36:39, 291.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.335418051862
INFO:root:current train perplexity3.790625810623169
INFO:root:current mean train loss 3387.9757486979165
INFO:root:current train perplexity3.8208205699920654
INFO:root:current mean train loss 3389.251585431427
INFO:root:current train perplexity3.816490888595581
INFO:root:current mean train loss 3394.166401887833
INFO:root:current train perplexity3.824007034301758
INFO:root:current mean train loss 3400.627291207879
INFO:root:current train perplexity3.823803186416626
INFO:root:current mean train loss 3407.4206359974864
INFO:root:current train perplexity3.829441547393799
INFO:root:current mean train loss 3410.11139340526
INFO:root:current train perplexity3.8324506282806396
INFO:root:current mean train loss 3409.0462824605715
INFO:root:current train perplexity3.8332602977752686
INFO:root:current mean train loss 3412.0760041183958
INFO:root:current train perplexity3.838491439819336
INFO:root:current mean train loss 3411.6556134813063
INFO:root:current train perplexity3.8389132022857666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.39s/it]
INFO:root:final mean train loss: 3410.461688626197
INFO:root:final train perplexity: 3.840205430984497
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it]
INFO:root:eval mean loss: 4020.0622939522386
INFO:root:eval perplexity: 5.081442832946777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [8:08:32<7:31:36, 291.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3397.017618075284
INFO:root:current train perplexity3.822822332382202
INFO:root:current mean train loss 3401.0648295740925
INFO:root:current train perplexity3.8188705444335938
INFO:root:current mean train loss 3393.187849456189
INFO:root:current train perplexity3.818953037261963
INFO:root:current mean train loss 3403.0550361740757
INFO:root:current train perplexity3.825314998626709
INFO:root:current mean train loss 3406.2245406936813
INFO:root:current train perplexity3.8236567974090576
INFO:root:current mean train loss 3405.254181623029
INFO:root:current train perplexity3.827996015548706
INFO:root:current mean train loss 3405.353293475668
INFO:root:current train perplexity3.830470085144043
INFO:root:current mean train loss 3408.386126991929
INFO:root:current train perplexity3.830125331878662
INFO:root:current mean train loss 3407.6397483781066
INFO:root:current train perplexity3.830038547515869
INFO:root:current mean train loss 3410.52430260144
INFO:root:current train perplexity3.835052013397217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.12s/it]
INFO:root:final mean train loss: 3406.7080460825273
INFO:root:final train perplexity: 3.834521532058716
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4021.4483616605717
INFO:root:eval perplexity: 5.084291934967041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [8:13:21<7:25:59, 290.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.5524088541665
INFO:root:current train perplexity3.810269832611084
INFO:root:current mean train loss 3376.895495830138
INFO:root:current train perplexity3.8227057456970215
INFO:root:current mean train loss 3383.6219069332224
INFO:root:current train perplexity3.816502332687378
INFO:root:current mean train loss 3392.469863765496
INFO:root:current train perplexity3.824174642562866
INFO:root:current mean train loss 3396.2782754918667
INFO:root:current train perplexity3.818202495574951
INFO:root:current mean train loss 3400.070762187084
INFO:root:current train perplexity3.8219096660614014
INFO:root:current mean train loss 3401.8948070589413
INFO:root:current train perplexity3.8215670585632324
INFO:root:current mean train loss 3402.6941151550213
INFO:root:current train perplexity3.822362184524536
INFO:root:current mean train loss 3402.152774037243
INFO:root:current train perplexity3.8238766193389893
INFO:root:current mean train loss 3404.3854361877757
INFO:root:current train perplexity3.8275368213653564


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.55s/it]
INFO:root:final mean train loss: 3402.0532337311774
INFO:root:final train perplexity: 3.827486753463745
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.81s/it]
INFO:root:eval mean loss: 4021.2240016206783
INFO:root:eval perplexity: 5.083829879760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [8:18:13<7:21:24, 291.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3380.8036215338907
INFO:root:current train perplexity3.791752815246582
INFO:root:current mean train loss 3376.6516327439695
INFO:root:current train perplexity3.801074743270874
INFO:root:current mean train loss 3381.0776502320687
INFO:root:current train perplexity3.806173086166382
INFO:root:current mean train loss 3386.9670640477593
INFO:root:current train perplexity3.803877115249634
INFO:root:current mean train loss 3390.9770595931195
INFO:root:current train perplexity3.812471628189087
INFO:root:current mean train loss 3394.447397315565
INFO:root:current train perplexity3.8182082176208496
INFO:root:current mean train loss 3395.8931948438662
INFO:root:current train perplexity3.819554567337036
INFO:root:current mean train loss 3397.7003530064444
INFO:root:current train perplexity3.8202812671661377
INFO:root:current mean train loss 3399.0063810118577
INFO:root:current train perplexity3.8212368488311768
INFO:root:current mean train loss 3401.2982591340274
INFO:root:current train perplexity3.8240270614624023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.97s/it]
INFO:root:final mean train loss: 3399.358074126705
INFO:root:final train perplexity: 3.823418617248535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.11s/it]
INFO:root:eval mean loss: 4024.2341429798316
INFO:root:eval perplexity: 5.090022087097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [8:23:05<7:16:59, 291.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.6954515674447
INFO:root:current train perplexity3.788963556289673
INFO:root:current mean train loss 3388.42495744588
INFO:root:current train perplexity3.791002035140991
INFO:root:current mean train loss 3395.9193592139895
INFO:root:current train perplexity3.8051369190216064
INFO:root:current mean train loss 3397.232365832165
INFO:root:current train perplexity3.80898380279541
INFO:root:current mean train loss 3398.973592037448
INFO:root:current train perplexity3.806689977645874
INFO:root:current mean train loss 3395.2013004810287
INFO:root:current train perplexity3.8031773567199707
INFO:root:current mean train loss 3396.9512498993236
INFO:root:current train perplexity3.8062331676483154
INFO:root:current mean train loss 3394.1453006533816
INFO:root:current train perplexity3.808154582977295
INFO:root:current mean train loss 3394.087822854451
INFO:root:current train perplexity3.8119900226593018
INFO:root:current mean train loss 3395.5723429320415
INFO:root:current train perplexity3.814281463623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it]
INFO:root:final mean train loss: 3393.113984323317
INFO:root:final train perplexity: 3.814011812210083
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4021.6609942929963
INFO:root:eval perplexity: 5.084728240966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [8:27:54<7:11:03, 290.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3396.984902568247
INFO:root:current train perplexity3.794130325317383
INFO:root:current mean train loss 3391.727237477022
INFO:root:current train perplexity3.7956018447875977
INFO:root:current mean train loss 3390.5607195598323
INFO:root:current train perplexity3.801424264907837
INFO:root:current mean train loss 3386.958776823926
INFO:root:current train perplexity3.7962725162506104
INFO:root:current mean train loss 3386.674023638026
INFO:root:current train perplexity3.800543785095215
INFO:root:current mean train loss 3386.93555186595
INFO:root:current train perplexity3.803678512573242
INFO:root:current mean train loss 3391.4234382818186
INFO:root:current train perplexity3.808122396469116
INFO:root:current mean train loss 3389.6927736856733
INFO:root:current train perplexity3.808818817138672
INFO:root:current mean train loss 3391.5280896587865
INFO:root:current train perplexity3.8094024658203125
INFO:root:current mean train loss 3392.312566786189
INFO:root:current train perplexity3.8085482120513916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.44s/it]
INFO:root:final mean train loss: 3389.408714048324
INFO:root:final train perplexity: 3.808440685272217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4026.971132535461
INFO:root:eval perplexity: 5.095657825469971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [8:32:47<7:07:29, 291.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.0484940378287
INFO:root:current train perplexity3.7828943729400635
INFO:root:current mean train loss 3360.714594601362
INFO:root:current train perplexity3.788115978240967
INFO:root:current mean train loss 3368.742316604873
INFO:root:current train perplexity3.7887842655181885
INFO:root:current mean train loss 3378.831968206092
INFO:root:current train perplexity3.7977304458618164
INFO:root:current mean train loss 3379.3412050189395
INFO:root:current train perplexity3.7975122928619385
INFO:root:current mean train loss 3378.046991120667
INFO:root:current train perplexity3.7960033416748047
INFO:root:current mean train loss 3381.4089390596896
INFO:root:current train perplexity3.798673152923584
INFO:root:current mean train loss 3384.996068875295
INFO:root:current train perplexity3.801668405532837
INFO:root:current mean train loss 3386.2661018243716
INFO:root:current train perplexity3.8033878803253174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.81s/it]
INFO:root:final mean train loss: 3386.225892343829
INFO:root:final train perplexity: 3.803661346435547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4028.755615234375
INFO:root:eval perplexity: 5.09933614730835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [8:37:34<7:00:30, 290.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.77783203125
INFO:root:current train perplexity3.780724048614502
INFO:root:current mean train loss 3356.6451854520633
INFO:root:current train perplexity3.7643206119537354
INFO:root:current mean train loss 3374.7187524053265
INFO:root:current train perplexity3.7849597930908203
INFO:root:current mean train loss 3374.1093653310645
INFO:root:current train perplexity3.7863128185272217
INFO:root:current mean train loss 3374.600891870541
INFO:root:current train perplexity3.7887661457061768
INFO:root:current mean train loss 3379.6700781638297
INFO:root:current train perplexity3.7933523654937744
INFO:root:current mean train loss 3381.029346674829
INFO:root:current train perplexity3.7940900325775146
INFO:root:current mean train loss 3381.8844867559787
INFO:root:current train perplexity3.795102834701538
INFO:root:current mean train loss 3385.2724071231905
INFO:root:current train perplexity3.7983005046844482
INFO:root:current mean train loss 3383.885747865189
INFO:root:current train perplexity3.7954182624816895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.81s/it]
INFO:root:final mean train loss: 3381.154983274398
INFO:root:final train perplexity: 3.7960593700408936
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4025.8125190464316
INFO:root:eval perplexity: 5.093271732330322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [8:42:28<6:57:37, 291.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3337.86181640625
INFO:root:current train perplexity3.7657065391540527
INFO:root:current mean train loss 3369.851610888232
INFO:root:current train perplexity3.7974071502685547
INFO:root:current mean train loss 3368.721030574274
INFO:root:current train perplexity3.794893264770508
INFO:root:current mean train loss 3376.3396333651526
INFO:root:current train perplexity3.792365789413452
INFO:root:current mean train loss 3377.219857246046
INFO:root:current train perplexity3.7911386489868164
INFO:root:current mean train loss 3374.914796355186
INFO:root:current train perplexity3.789005994796753
INFO:root:current mean train loss 3380.274969072857
INFO:root:current train perplexity3.787970542907715
INFO:root:current mean train loss 3379.024930157239
INFO:root:current train perplexity3.7883241176605225
INFO:root:current mean train loss 3377.067276546605
INFO:root:current train perplexity3.7870047092437744
INFO:root:current mean train loss 3378.8178228552074
INFO:root:current train perplexity3.7886505126953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.30s/it]
INFO:root:final mean train loss: 3378.344067911948
INFO:root:final train perplexity: 3.791851758956909
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4029.6191181155805
INFO:root:eval perplexity: 5.10111665725708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [8:46:56<6:42:37, 284.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.9400827508225
INFO:root:current train perplexity3.7366812229156494
INFO:root:current mean train loss 3341.5772387079833
INFO:root:current train perplexity3.7644200325012207
INFO:root:current mean train loss 3359.8775618043665
INFO:root:current train perplexity3.7714569568634033
INFO:root:current mean train loss 3366.4767844460225
INFO:root:current train perplexity3.7751457691192627
INFO:root:current mean train loss 3366.6848208625447
INFO:root:current train perplexity3.772265672683716
INFO:root:current mean train loss 3369.4493180056297
INFO:root:current train perplexity3.7725932598114014
INFO:root:current mean train loss 3371.464347186112
INFO:root:current train perplexity3.7768003940582275
INFO:root:current mean train loss 3375.616200071714
INFO:root:current train perplexity3.779848337173462
INFO:root:current mean train loss 3375.777626941201
INFO:root:current train perplexity3.7804031372070312
INFO:root:current mean train loss 3373.8219978407237
INFO:root:current train perplexity3.7821435928344727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.26s/it]
INFO:root:final mean train loss: 3373.3369628537084
INFO:root:final train perplexity: 3.7843682765960693
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4029.1286603778813
INFO:root:eval perplexity: 5.1001057624816895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [8:51:09<6:24:58, 274.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.7488154658563
INFO:root:current train perplexity3.786362409591675
INFO:root:current mean train loss 3376.1929537555366
INFO:root:current train perplexity3.7728662490844727
INFO:root:current mean train loss 3373.2438878803
INFO:root:current train perplexity3.7676351070404053
INFO:root:current mean train loss 3367.5571587705467
INFO:root:current train perplexity3.767242431640625
INFO:root:current mean train loss 3371.496927373024
INFO:root:current train perplexity3.772874593734741
INFO:root:current mean train loss 3371.444474916983
INFO:root:current train perplexity3.772418260574341
INFO:root:current mean train loss 3371.759610262784
INFO:root:current train perplexity3.7725939750671387
INFO:root:current mean train loss 3372.1050912891164
INFO:root:current train perplexity3.7748968601226807
INFO:root:current mean train loss 3371.7090510929943
INFO:root:current train perplexity3.7753212451934814
INFO:root:current mean train loss 3372.526702452889
INFO:root:current train perplexity3.7790825366973877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.89s/it]
INFO:root:final mean train loss: 3369.6390728489046
INFO:root:final train perplexity: 3.778851270675659
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4030.8679805241577
INFO:root:eval perplexity: 5.103694438934326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [8:56:00<6:27:03, 279.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.0637137276785
INFO:root:current train perplexity3.7470080852508545
INFO:root:current mean train loss 3358.7385344328704
INFO:root:current train perplexity3.745657444000244
INFO:root:current mean train loss 3357.6321122839095
INFO:root:current train perplexity3.755608320236206
INFO:root:current mean train loss 3364.1435233500465
INFO:root:current train perplexity3.761476993560791
INFO:root:current mean train loss 3366.9078534707255
INFO:root:current train perplexity3.7633957862854004
INFO:root:current mean train loss 3366.4429870035046
INFO:root:current train perplexity3.7641186714172363
INFO:root:current mean train loss 3366.2721564345475
INFO:root:current train perplexity3.767885208129883
INFO:root:current mean train loss 3368.0696993250426
INFO:root:current train perplexity3.7685635089874268
INFO:root:current mean train loss 3368.005805283963
INFO:root:current train perplexity3.770289421081543
INFO:root:current mean train loss 3368.376628822694
INFO:root:current train perplexity3.7729384899139404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.61s/it]
INFO:root:final mean train loss: 3365.3222223097277
INFO:root:final train perplexity: 3.772421360015869
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4034.155112408577
INFO:root:eval perplexity: 5.110482692718506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [9:00:52<6:27:18, 283.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.5047862917877
INFO:root:current train perplexity3.7510879039764404
INFO:root:current mean train loss 3351.2965898847247
INFO:root:current train perplexity3.745670795440674
INFO:root:current mean train loss 3351.653419777199
INFO:root:current train perplexity3.7521438598632812
INFO:root:current mean train loss 3356.0476714820975
INFO:root:current train perplexity3.754939556121826
INFO:root:current mean train loss 3361.627953385123
INFO:root:current train perplexity3.7559597492218018
INFO:root:current mean train loss 3361.371141858742
INFO:root:current train perplexity3.756070852279663
INFO:root:current mean train loss 3363.846880923163
INFO:root:current train perplexity3.761247396469116
INFO:root:current mean train loss 3364.6971236751347
INFO:root:current train perplexity3.7636518478393555
INFO:root:current mean train loss 3362.9350501950807
INFO:root:current train perplexity3.766842842102051
INFO:root:current mean train loss 3363.735175770894
INFO:root:current train perplexity3.766547918319702


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.73s/it]
INFO:root:final mean train loss: 3361.7727283970003
INFO:root:final train perplexity: 3.767141819000244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 4034.5083406056074
INFO:root:eval perplexity: 5.111212253570557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [9:05:49<6:28:08, 287.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.582103056066
INFO:root:current train perplexity3.7579050064086914
INFO:root:current mean train loss 3350.7577413596855
INFO:root:current train perplexity3.748126268386841
INFO:root:current mean train loss 3348.0086256536356
INFO:root:current train perplexity3.7515923976898193
INFO:root:current mean train loss 3343.922034978187
INFO:root:current train perplexity3.7518317699432373
INFO:root:current mean train loss 3346.166538551483
INFO:root:current train perplexity3.7523581981658936
INFO:root:current mean train loss 3350.241628768007
INFO:root:current train perplexity3.7530417442321777
INFO:root:current mean train loss 3355.0844550301217
INFO:root:current train perplexity3.756922721862793
INFO:root:current mean train loss 3359.186953203021
INFO:root:current train perplexity3.7605340480804443
INFO:root:current mean train loss 3358.384842797536
INFO:root:current train perplexity3.760617971420288
INFO:root:current mean train loss 3360.5591112973184
INFO:root:current train perplexity3.762058734893799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.63s/it]
INFO:root:final mean train loss: 3358.5832673349687
INFO:root:final train perplexity: 3.7624049186706543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.60s/it]
INFO:root:eval mean loss: 4037.631500027704
INFO:root:eval perplexity: 5.117672443389893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [9:10:49<6:28:06, 291.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.3020102290784
INFO:root:current train perplexity3.7311270236968994
INFO:root:current mean train loss 3339.531968602594
INFO:root:current train perplexity3.733832359313965
INFO:root:current mean train loss 3340.866472988055
INFO:root:current train perplexity3.7314276695251465
INFO:root:current mean train loss 3347.421736948337
INFO:root:current train perplexity3.74251127243042
INFO:root:current mean train loss 3349.341336252383
INFO:root:current train perplexity3.7467145919799805
INFO:root:current mean train loss 3347.60811848376
INFO:root:current train perplexity3.7498114109039307
INFO:root:current mean train loss 3352.8800124774752
INFO:root:current train perplexity3.7533822059631348
INFO:root:current mean train loss 3355.8213469614625
INFO:root:current train perplexity3.756695032119751
INFO:root:current mean train loss 3357.855863808753
INFO:root:current train perplexity3.7576401233673096
INFO:root:current mean train loss 3357.561761468245
INFO:root:current train perplexity3.7573719024658203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it]
INFO:root:final mean train loss: 3355.6066131591797
INFO:root:final train perplexity: 3.757988691329956
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4036.088463749446
INFO:root:eval perplexity: 5.114479064941406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [9:15:48<6:26:39, 293.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.976668172808
INFO:root:current train perplexity3.749189853668213
INFO:root:current mean train loss 3348.4776092346556
INFO:root:current train perplexity3.7461202144622803
INFO:root:current mean train loss 3342.751009480337
INFO:root:current train perplexity3.7368760108947754
INFO:root:current mean train loss 3341.083652423578
INFO:root:current train perplexity3.7379024028778076
INFO:root:current mean train loss 3345.530280756491
INFO:root:current train perplexity3.737841844558716
INFO:root:current mean train loss 3344.5388713210978
INFO:root:current train perplexity3.7378101348876953
INFO:root:current mean train loss 3347.589638408335
INFO:root:current train perplexity3.739952802658081
INFO:root:current mean train loss 3347.3013191869704
INFO:root:current train perplexity3.7408194541931152
INFO:root:current mean train loss 3349.437309925119
INFO:root:current train perplexity3.742905855178833
INFO:root:current mean train loss 3352.1758822388833
INFO:root:current train perplexity3.7479894161224365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.42s/it]
INFO:root:final mean train loss: 3350.00434155618
INFO:root:final train perplexity: 3.7496912479400635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4035.824615262079
INFO:root:eval perplexity: 5.113934516906738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [9:20:40<6:21:10, 293.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.0724479166665
INFO:root:current train perplexity3.732980489730835
INFO:root:current mean train loss 3334.0871595982144
INFO:root:current train perplexity3.7431774139404297
INFO:root:current mean train loss 3343.130830078125
INFO:root:current train perplexity3.745875358581543
INFO:root:current mean train loss 3343.8583756510416
INFO:root:current train perplexity3.742229461669922
INFO:root:current mean train loss 3347.9646895559213
INFO:root:current train perplexity3.745420455932617
INFO:root:current mean train loss 3349.074884935462
INFO:root:current train perplexity3.743367910385132
INFO:root:current mean train loss 3349.9483156105325
INFO:root:current train perplexity3.744032144546509
INFO:root:current mean train loss 3350.9991006174396
INFO:root:current train perplexity3.7455544471740723
INFO:root:current mean train loss 3349.9370571986606
INFO:root:current train perplexity3.7452926635742188
INFO:root:current mean train loss 3349.836719501202
INFO:root:current train perplexity3.7457940578460693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.98s/it]
INFO:root:final mean train loss: 3347.702741622925
INFO:root:final train perplexity: 3.7462880611419678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4038.7062780501997
INFO:root:eval perplexity: 5.119897365570068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [9:25:29<6:14:26, 291.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.9208278426204
INFO:root:current train perplexity3.7332701683044434
INFO:root:current mean train loss 3320.9205729166665
INFO:root:current train perplexity3.7276570796966553
INFO:root:current mean train loss 3327.2555306909785
INFO:root:current train perplexity3.7266454696655273
INFO:root:current mean train loss 3337.191227128549
INFO:root:current train perplexity3.7360758781433105
INFO:root:current mean train loss 3338.9928658368917
INFO:root:current train perplexity3.7398576736450195
INFO:root:current mean train loss 3348.0532293565075
INFO:root:current train perplexity3.7418735027313232
INFO:root:current mean train loss 3349.639677748673
INFO:root:current train perplexity3.742340564727783
INFO:root:current mean train loss 3347.561439562879
INFO:root:current train perplexity3.738950252532959
INFO:root:current mean train loss 3347.6762435411947
INFO:root:current train perplexity3.7410500049591064
INFO:root:current mean train loss 3347.8287285215856
INFO:root:current train perplexity3.742450714111328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.54s/it]
INFO:root:final mean train loss: 3345.0716082049953
INFO:root:final train perplexity: 3.742401599884033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it]
INFO:root:eval mean loss: 4038.1046064660904
INFO:root:eval perplexity: 5.118650436401367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [9:29:36<5:52:43, 278.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.382740062672
INFO:root:current train perplexity3.681091070175171
INFO:root:current mean train loss 3335.9225038857985
INFO:root:current train perplexity3.7195162773132324
INFO:root:current mean train loss 3339.5831168787586
INFO:root:current train perplexity3.7240989208221436
INFO:root:current mean train loss 3340.9615631493766
INFO:root:current train perplexity3.7236673831939697
INFO:root:current mean train loss 3339.6915633751273
INFO:root:current train perplexity3.7245562076568604
INFO:root:current mean train loss 3342.690871288732
INFO:root:current train perplexity3.7310945987701416
INFO:root:current mean train loss 3344.079172932118
INFO:root:current train perplexity3.7324776649475098
INFO:root:current mean train loss 3346.1388978053888
INFO:root:current train perplexity3.7327487468719482
INFO:root:current mean train loss 3344.513528843119
INFO:root:current train perplexity3.7356812953948975
INFO:root:current mean train loss 3343.89468103557
INFO:root:current train perplexity3.736736536026001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.44s/it]
INFO:root:final mean train loss: 3341.178233854232
INFO:root:final train perplexity: 3.7366576194763184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4039.6881458471853
INFO:root:eval perplexity: 5.12192964553833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [9:33:43<5:36:11, 268.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.307582662563
INFO:root:current train perplexity3.731496810913086
INFO:root:current mean train loss 3331.141393000157
INFO:root:current train perplexity3.725832462310791
INFO:root:current mean train loss 3335.056709213002
INFO:root:current train perplexity3.727921485900879
INFO:root:current mean train loss 3333.682792185542
INFO:root:current train perplexity3.725191354751587
INFO:root:current mean train loss 3334.285724769852
INFO:root:current train perplexity3.7241570949554443
INFO:root:current mean train loss 3336.0286292583996
INFO:root:current train perplexity3.723656415939331
INFO:root:current mean train loss 3335.5347629705384
INFO:root:current train perplexity3.725224018096924
INFO:root:current mean train loss 3338.381156377112
INFO:root:current train perplexity3.7272515296936035
INFO:root:current mean train loss 3340.1541632630006
INFO:root:current train perplexity3.731238842010498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.39s/it]
INFO:root:final mean train loss: 3337.4654363816785
INFO:root:final train perplexity: 3.731187582015991
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4041.244597739362
INFO:root:eval perplexity: 5.125154972076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [9:37:51<5:23:54, 262.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.0359933035716
INFO:root:current train perplexity3.7702229022979736
INFO:root:current mean train loss 3324.4785064982475
INFO:root:current train perplexity3.712003469467163
INFO:root:current mean train loss 3329.0430914100243
INFO:root:current train perplexity3.712877035140991
INFO:root:current mean train loss 3330.091105010688
INFO:root:current train perplexity3.716259479522705
INFO:root:current mean train loss 3323.618825101735
INFO:root:current train perplexity3.716848850250244
INFO:root:current mean train loss 3328.662208572177
INFO:root:current train perplexity3.7208104133605957
INFO:root:current mean train loss 3330.514085345449
INFO:root:current train perplexity3.7198598384857178
INFO:root:current mean train loss 3334.3679054184713
INFO:root:current train perplexity3.723869562149048
INFO:root:current mean train loss 3336.0418012919185
INFO:root:current train perplexity3.7255873680114746
INFO:root:current mean train loss 3336.138750473746
INFO:root:current train perplexity3.724212169647217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.96s/it]
INFO:root:final mean train loss: 3333.9081694079982
INFO:root:final train perplexity: 3.7259552478790283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4043.75419367797
INFO:root:eval perplexity: 5.130358695983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [9:41:58<5:13:58, 258.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3296.314013671875
INFO:root:current train perplexity3.733968496322632
INFO:root:current mean train loss 3311.582612941576
INFO:root:current train perplexity3.7265801429748535
INFO:root:current mean train loss 3319.8242380541424
INFO:root:current train perplexity3.7272706031799316
INFO:root:current mean train loss 3324.9059663318453
INFO:root:current train perplexity3.719289779663086
INFO:root:current mean train loss 3326.8559770331326
INFO:root:current train perplexity3.7169313430786133
INFO:root:current mean train loss 3326.2250350804006
INFO:root:current train perplexity3.7178831100463867
INFO:root:current mean train loss 3328.0163216939786
INFO:root:current train perplexity3.716399669647217
INFO:root:current mean train loss 3329.367370520105
INFO:root:current train perplexity3.717862844467163
INFO:root:current mean train loss 3329.606468977665
INFO:root:current train perplexity3.7175276279449463
INFO:root:current mean train loss 3332.078682387722
INFO:root:current train perplexity3.7209038734436035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.70s/it]
INFO:root:final mean train loss: 3331.4089167810257
INFO:root:final train perplexity: 3.722282886505127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4043.5515742741577
INFO:root:eval perplexity: 5.129937171936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [9:46:07<5:06:06, 255.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3278.4517769191575
INFO:root:current train perplexity3.6902852058410645
INFO:root:current mean train loss 3330.3006681116617
INFO:root:current train perplexity3.709972858428955
INFO:root:current mean train loss 3328.749554415989
INFO:root:current train perplexity3.7103583812713623
INFO:root:current mean train loss 3331.1430671621033
INFO:root:current train perplexity3.720494508743286
INFO:root:current mean train loss 3328.70940108784
INFO:root:current train perplexity3.713916778564453
INFO:root:current mean train loss 3327.4487155308916
INFO:root:current train perplexity3.715973377227783
INFO:root:current mean train loss 3328.9143270183336
INFO:root:current train perplexity3.717376708984375
INFO:root:current mean train loss 3329.87776490102
INFO:root:current train perplexity3.7179646492004395
INFO:root:current mean train loss 3328.1533989240015
INFO:root:current train perplexity3.71592378616333
INFO:root:current mean train loss 3328.9910924380415
INFO:root:current train perplexity3.7156894207000732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it]
INFO:root:final mean train loss: 3327.7397879323653
INFO:root:final train perplexity: 3.7168989181518555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.94s/it]
INFO:root:eval mean loss: 4044.054739444814
INFO:root:eval perplexity: 5.1309814453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [9:50:14<4:59:15, 252.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.303466796875
INFO:root:current train perplexity3.6770219802856445
INFO:root:current mean train loss 3316.832713352815
INFO:root:current train perplexity3.700042724609375
INFO:root:current mean train loss 3328.9942515980115
INFO:root:current train perplexity3.7116940021514893
INFO:root:current mean train loss 3328.397024287198
INFO:root:current train perplexity3.711430311203003
INFO:root:current mean train loss 3325.685357680177
INFO:root:current train perplexity3.712862014770508
INFO:root:current mean train loss 3327.6914398135887
INFO:root:current train perplexity3.716076612472534
INFO:root:current mean train loss 3326.8667170166405
INFO:root:current train perplexity3.712303400039673
INFO:root:current mean train loss 3328.0863903791897
INFO:root:current train perplexity3.7122011184692383
INFO:root:current mean train loss 3325.0131841813327
INFO:root:current train perplexity3.709944009780884
INFO:root:current mean train loss 3324.5319268280914
INFO:root:current train perplexity3.7089004516601562


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.75s/it]
INFO:root:final mean train loss: 3323.2282653931647
INFO:root:final train perplexity: 3.7102890014648438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4047.119512896166
INFO:root:eval perplexity: 5.137344837188721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [9:54:22<4:53:17, 251.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3321.45843349359
INFO:root:current train perplexity3.701913833618164
INFO:root:current mean train loss 3326.979230482801
INFO:root:current train perplexity3.712573289871216
INFO:root:current mean train loss 3324.150953476399
INFO:root:current train perplexity3.704855442047119
INFO:root:current mean train loss 3324.4989247729995
INFO:root:current train perplexity3.7053182125091553
INFO:root:current mean train loss 3324.196562677961
INFO:root:current train perplexity3.7075014114379883
INFO:root:current mean train loss 3317.984206502203
INFO:root:current train perplexity3.7047295570373535
INFO:root:current mean train loss 3318.070080203443
INFO:root:current train perplexity3.7052979469299316
INFO:root:current mean train loss 3318.5083308445746
INFO:root:current train perplexity3.703411817550659
INFO:root:current mean train loss 3323.1185126685414
INFO:root:current train perplexity3.7070019245147705
INFO:root:current mean train loss 3323.29753514169
INFO:root:current train perplexity3.707880973815918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.98s/it]
INFO:root:final mean train loss: 3321.3249002887355
INFO:root:final train perplexity: 3.7075040340423584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4046.906906236148
INFO:root:eval perplexity: 5.136903285980225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [9:58:33<4:48:47, 251.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.271796043883
INFO:root:current train perplexity3.698390245437622
INFO:root:current mean train loss 3314.662443199936
INFO:root:current train perplexity3.6907052993774414
INFO:root:current mean train loss 3316.2260070059465
INFO:root:current train perplexity3.70241379737854
INFO:root:current mean train loss 3312.992014420479
INFO:root:current train perplexity3.6924538612365723
INFO:root:current mean train loss 3315.608159758634
INFO:root:current train perplexity3.694017171859741
INFO:root:current mean train loss 3316.456559929159
INFO:root:current train perplexity3.695138454437256
INFO:root:current mean train loss 3316.986610377222
INFO:root:current train perplexity3.6980957984924316
INFO:root:current mean train loss 3317.722576177104
INFO:root:current train perplexity3.699385643005371
INFO:root:current mean train loss 3316.979395050085
INFO:root:current train perplexity3.6987030506134033
INFO:root:current mean train loss 3318.5509021601933
INFO:root:current train perplexity3.6998023986816406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.38s/it]
INFO:root:final mean train loss: 3317.288261536629
INFO:root:final train perplexity: 3.701603651046753
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 4047.3886701435063
INFO:root:eval perplexity: 5.137904644012451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [10:02:40<4:43:28, 250.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3287.935702237216
INFO:root:current train perplexity3.6789638996124268
INFO:root:current mean train loss 3293.054778855847
INFO:root:current train perplexity3.6874942779541016
INFO:root:current mean train loss 3294.916260723039
INFO:root:current train perplexity3.6901743412017822
INFO:root:current mean train loss 3296.073094327685
INFO:root:current train perplexity3.6837332248687744
INFO:root:current mean train loss 3301.821093213427
INFO:root:current train perplexity3.6852736473083496
INFO:root:current mean train loss 3305.1254847621058
INFO:root:current train perplexity3.6870901584625244
INFO:root:current mean train loss 3307.2931569805583
INFO:root:current train perplexity3.690722942352295
INFO:root:current mean train loss 3309.4984391168255
INFO:root:current train perplexity3.692075729370117
INFO:root:current mean train loss 3312.8712522272476
INFO:root:current train perplexity3.6937806606292725
INFO:root:current mean train loss 3315.0529902752783
INFO:root:current train perplexity3.696498155593872


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.92s/it]
INFO:root:final mean train loss: 3314.7605169973067
INFO:root:final train perplexity: 3.6979146003723145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4050.011727407469
INFO:root:eval perplexity: 5.1433563232421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [10:06:48<4:38:19, 249.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.8842579675097
INFO:root:current train perplexity3.691228151321411
INFO:root:current mean train loss 3298.683574278662
INFO:root:current train perplexity3.6839852333068848
INFO:root:current mean train loss 3304.640656561906
INFO:root:current train perplexity3.6900806427001953
INFO:root:current mean train loss 3308.3158648362173
INFO:root:current train perplexity3.692901849746704
INFO:root:current mean train loss 3310.339569025884
INFO:root:current train perplexity3.691603422164917
INFO:root:current mean train loss 3316.7977401164244
INFO:root:current train perplexity3.6934852600097656
INFO:root:current mean train loss 3313.3661726409314
INFO:root:current train perplexity3.6895182132720947
INFO:root:current mean train loss 3311.9781594932624
INFO:root:current train perplexity3.6890430450439453
INFO:root:current mean train loss 3311.823512354704
INFO:root:current train perplexity3.689772844314575
INFO:root:current mean train loss 3313.765413817092
INFO:root:current train perplexity3.6922130584716797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.54s/it]
INFO:root:final mean train loss: 3311.026828888924
INFO:root:final train perplexity: 3.6924710273742676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.18s/it]
INFO:root:eval mean loss: 4051.0136839954566
INFO:root:eval perplexity: 5.145440101623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [10:10:58<4:34:37, 249.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.922394228653
INFO:root:current train perplexity3.691483736038208
INFO:root:current mean train loss 3293.4904471057202
INFO:root:current train perplexity3.667290210723877
INFO:root:current mean train loss 3294.6568157576107
INFO:root:current train perplexity3.6701459884643555
INFO:root:current mean train loss 3298.342895178782
INFO:root:current train perplexity3.6744003295898438
INFO:root:current mean train loss 3302.6754521007497
INFO:root:current train perplexity3.678950548171997
INFO:root:current mean train loss 3308.6306370402804
INFO:root:current train perplexity3.6816790103912354
INFO:root:current mean train loss 3312.4232230492034
INFO:root:current train perplexity3.6879501342773438
INFO:root:current mean train loss 3310.1853423161883
INFO:root:current train perplexity3.6863725185394287
INFO:root:current mean train loss 3310.8418560181367
INFO:root:current train perplexity3.6877195835113525
INFO:root:current mean train loss 3309.4931502337313
INFO:root:current train perplexity3.686479330062866


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.76s/it]
INFO:root:final mean train loss: 3307.765501883722
INFO:root:final train perplexity: 3.687723159790039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4050.0690900653813
INFO:root:eval perplexity: 5.143475532531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [10:15:06<4:29:43, 248.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.9437302215188
INFO:root:current train perplexity3.6755244731903076
INFO:root:current mean train loss 3301.8238041201116
INFO:root:current train perplexity3.688336133956909
INFO:root:current mean train loss 3301.5783980174733
INFO:root:current train perplexity3.6829490661621094
INFO:root:current mean train loss 3306.291755776921
INFO:root:current train perplexity3.684795618057251
INFO:root:current mean train loss 3308.5817244177324
INFO:root:current train perplexity3.685512065887451
INFO:root:current mean train loss 3309.7382403490665
INFO:root:current train perplexity3.684993267059326
INFO:root:current mean train loss 3312.3289850653537
INFO:root:current train perplexity3.6850953102111816
INFO:root:current mean train loss 3312.2784748199815
INFO:root:current train perplexity3.6839659214019775
INFO:root:current mean train loss 3311.024211584098
INFO:root:current train perplexity3.684229850769043
INFO:root:current mean train loss 3308.138545689958
INFO:root:current train perplexity3.683960199356079


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.75s/it]
INFO:root:final mean train loss: 3305.506195683633
INFO:root:final train perplexity: 3.6844377517700195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4052.0115784990026
INFO:root:eval perplexity: 5.147517204284668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [10:19:14<4:25:17, 248.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.211220927622
INFO:root:current train perplexity3.665971040725708
INFO:root:current mean train loss 3298.3857709099266
INFO:root:current train perplexity3.6746761798858643
INFO:root:current mean train loss 3297.971314752559
INFO:root:current train perplexity3.6730785369873047
INFO:root:current mean train loss 3305.096860111838
INFO:root:current train perplexity3.677786111831665
INFO:root:current mean train loss 3308.5007018416322
INFO:root:current train perplexity3.679819107055664
INFO:root:current mean train loss 3307.7941071024543
INFO:root:current train perplexity3.6780779361724854
INFO:root:current mean train loss 3307.336072896766
INFO:root:current train perplexity3.678454637527466
INFO:root:current mean train loss 3304.2787043609037
INFO:root:current train perplexity3.6765823364257812
INFO:root:current mean train loss 3304.0455802564825
INFO:root:current train perplexity3.677152633666992
INFO:root:current mean train loss 3305.0808884640956
INFO:root:current train perplexity3.6802995204925537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.48s/it]
INFO:root:final mean train loss: 3302.7816931201564
INFO:root:final train perplexity: 3.6804792881011963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4054.0531083776596
INFO:root:eval perplexity: 5.151768684387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [10:23:21<4:20:49, 248.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.6075478001644
INFO:root:current train perplexity3.656243324279785
INFO:root:current mean train loss 3293.406554236779
INFO:root:current train perplexity3.6606414318084717
INFO:root:current mean train loss 3296.2115805415783
INFO:root:current train perplexity3.666954517364502
INFO:root:current mean train loss 3297.4746668562107
INFO:root:current train perplexity3.672041416168213
INFO:root:current mean train loss 3296.7488197403723
INFO:root:current train perplexity3.673408269882202
INFO:root:current mean train loss 3299.0859268316703
INFO:root:current train perplexity3.6754894256591797
INFO:root:current mean train loss 3297.170787432554
INFO:root:current train perplexity3.6736390590667725
INFO:root:current mean train loss 3301.2367301125196
INFO:root:current train perplexity3.6774239540100098
INFO:root:current mean train loss 3301.2910549057265
INFO:root:current train perplexity3.6761436462402344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.63s/it]
INFO:root:final mean train loss: 3300.018256095148
INFO:root:final train perplexity: 3.6764683723449707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4055.6659532912236
INFO:root:eval perplexity: 5.155129432678223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [10:27:31<4:17:12, 248.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.776123046875
INFO:root:current train perplexity3.530327320098877
INFO:root:current mean train loss 3269.5533909473606
INFO:root:current train perplexity3.632093667984009
INFO:root:current mean train loss 3274.198819465825
INFO:root:current train perplexity3.640357255935669
INFO:root:current mean train loss 3282.6122531198434
INFO:root:current train perplexity3.6533756256103516
INFO:root:current mean train loss 3288.9346193829483
INFO:root:current train perplexity3.6537528038024902
INFO:root:current mean train loss 3290.769181298925
INFO:root:current train perplexity3.6553142070770264
INFO:root:current mean train loss 3292.5676411238082
INFO:root:current train perplexity3.657627820968628
INFO:root:current mean train loss 3293.320520870377
INFO:root:current train perplexity3.6608452796936035
INFO:root:current mean train loss 3296.354296692579
INFO:root:current train perplexity3.6646742820739746
INFO:root:current mean train loss 3297.0145300171303
INFO:root:current train perplexity3.667450189590454


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.21s/it]
INFO:root:final mean train loss: 3296.3386998330393
INFO:root:final train perplexity: 3.671135902404785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.68s/it]
INFO:root:eval mean loss: 4056.1037943955007
INFO:root:eval perplexity: 5.156042098999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [10:31:39<4:12:43, 248.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.5658957741475
INFO:root:current train perplexity3.5952939987182617
INFO:root:current mean train loss 3287.5444072001687
INFO:root:current train perplexity3.65779972076416
INFO:root:current mean train loss 3286.1560290006664
INFO:root:current train perplexity3.65139102935791
INFO:root:current mean train loss 3276.1871804976386
INFO:root:current train perplexity3.640845537185669
INFO:root:current mean train loss 3282.15627138458
INFO:root:current train perplexity3.647731304168701
INFO:root:current mean train loss 3284.4504853190742
INFO:root:current train perplexity3.656055450439453
INFO:root:current mean train loss 3287.11970602432
INFO:root:current train perplexity3.6569201946258545
INFO:root:current mean train loss 3290.6644954976487
INFO:root:current train perplexity3.6587977409362793
INFO:root:current mean train loss 3293.147992869047
INFO:root:current train perplexity3.663914680480957
INFO:root:current mean train loss 3296.168153932406
INFO:root:current train perplexity3.666165828704834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.18s/it]
INFO:root:final mean train loss: 3294.0460002653062
INFO:root:final train perplexity: 3.667816162109375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it]
INFO:root:eval mean loss: 4056.8259900681514
INFO:root:eval perplexity: 5.157547473907471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [10:35:47<4:08:14, 248.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.481072676809
INFO:root:current train perplexity3.6464040279388428
INFO:root:current mean train loss 3268.0993016347165
INFO:root:current train perplexity3.641155958175659
INFO:root:current mean train loss 3271.1175576127284
INFO:root:current train perplexity3.655440092086792
INFO:root:current mean train loss 3278.9158633241086
INFO:root:current train perplexity3.6561155319213867
INFO:root:current mean train loss 3282.0717767610754
INFO:root:current train perplexity3.656461715698242
INFO:root:current mean train loss 3285.5191704487297
INFO:root:current train perplexity3.658588409423828
INFO:root:current mean train loss 3284.3019755275645
INFO:root:current train perplexity3.657648801803589
INFO:root:current mean train loss 3287.427888533336
INFO:root:current train perplexity3.659154176712036
INFO:root:current mean train loss 3289.3050437247216
INFO:root:current train perplexity3.6602370738983154
INFO:root:current mean train loss 3290.8419857585523
INFO:root:current train perplexity3.660174608230591


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.08s/it]
INFO:root:final mean train loss: 3291.177449933944
INFO:root:final train perplexity: 3.663667678833008
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it]
INFO:root:eval mean loss: 4056.75532088043
INFO:root:eval perplexity: 5.157400608062744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [10:39:53<4:03:34, 247.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.5337366174767
INFO:root:current train perplexity3.657421112060547
INFO:root:current mean train loss 3281.778024267963
INFO:root:current train perplexity3.6574642658233643
INFO:root:current mean train loss 3282.317683955121
INFO:root:current train perplexity3.656801223754883
INFO:root:current mean train loss 3283.7601508744265
INFO:root:current train perplexity3.6605849266052246
INFO:root:current mean train loss 3287.8674693766466
INFO:root:current train perplexity3.659743070602417
INFO:root:current mean train loss 3288.108832980017
INFO:root:current train perplexity3.6578004360198975
INFO:root:current mean train loss 3289.1855515475477
INFO:root:current train perplexity3.6599085330963135
INFO:root:current mean train loss 3288.839887406508
INFO:root:current train perplexity3.659475803375244
INFO:root:current mean train loss 3289.707997184855
INFO:root:current train perplexity3.6609089374542236
INFO:root:current mean train loss 3289.1824375716355
INFO:root:current train perplexity3.658313274383545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.20s/it]
INFO:root:final mean train loss: 3287.5547913582095
INFO:root:final train perplexity: 3.6584348678588867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4060.223541043329
INFO:root:eval perplexity: 5.164639472961426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [10:44:04<4:00:17, 248.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.9033551897323
INFO:root:current train perplexity3.64998459815979
INFO:root:current mean train loss 3312.042677589699
INFO:root:current train perplexity3.6447360515594482
INFO:root:current mean train loss 3300.648452044548
INFO:root:current train perplexity3.6462862491607666
INFO:root:current mean train loss 3299.329154034515
INFO:root:current train perplexity3.6493918895721436
INFO:root:current mean train loss 3291.387704853628
INFO:root:current train perplexity3.649860382080078
INFO:root:current mean train loss 3295.376290979118
INFO:root:current train perplexity3.653756618499756
INFO:root:current mean train loss 3291.1959061269686
INFO:root:current train perplexity3.6497857570648193
INFO:root:current mean train loss 3288.2750036538055
INFO:root:current train perplexity3.6504013538360596
INFO:root:current mean train loss 3286.1543155875747
INFO:root:current train perplexity3.6519217491149902
INFO:root:current mean train loss 3286.6409056964403
INFO:root:current train perplexity3.6542158126831055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.08s/it]
INFO:root:final mean train loss: 3285.7562042974655
INFO:root:final train perplexity: 3.6558401584625244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it]
INFO:root:eval mean loss: 4060.3580244348404
INFO:root:eval perplexity: 5.164920330047607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [10:48:11<3:55:37, 248.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.3710312954213
INFO:root:current train perplexity3.6253817081451416
INFO:root:current mean train loss 3268.2744601589816
INFO:root:current train perplexity3.624340295791626
INFO:root:current mean train loss 3266.778013880851
INFO:root:current train perplexity3.6273958683013916
INFO:root:current mean train loss 3273.134625404291
INFO:root:current train perplexity3.630664110183716
INFO:root:current mean train loss 3275.8934593459016
INFO:root:current train perplexity3.6363794803619385
INFO:root:current mean train loss 3278.075323452607
INFO:root:current train perplexity3.639833927154541
INFO:root:current mean train loss 3281.05669378159
INFO:root:current train perplexity3.64310359954834
INFO:root:current mean train loss 3278.5357733376095
INFO:root:current train perplexity3.6439578533172607
INFO:root:current mean train loss 3280.793485702569
INFO:root:current train perplexity3.646618366241455
INFO:root:current mean train loss 3282.6547173250265
INFO:root:current train perplexity3.6505393981933594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.81s/it]
INFO:root:final mean train loss: 3282.548095210906
INFO:root:final train perplexity: 3.6512155532836914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.99s/it]
INFO:root:eval mean loss: 4062.071825825576
INFO:root:eval perplexity: 5.168499946594238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [10:52:18<3:51:24, 247.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.6745988434436
INFO:root:current train perplexity3.6142148971557617
INFO:root:current mean train loss 3272.3451582548632
INFO:root:current train perplexity3.630927801132202
INFO:root:current mean train loss 3274.092305582358
INFO:root:current train perplexity3.631507396697998
INFO:root:current mean train loss 3270.155758240963
INFO:root:current train perplexity3.6324996948242188
INFO:root:current mean train loss 3274.6692982608092
INFO:root:current train perplexity3.635490655899048
INFO:root:current mean train loss 3276.770836582634
INFO:root:current train perplexity3.640740394592285
INFO:root:current mean train loss 3281.430184781826
INFO:root:current train perplexity3.644409656524658
INFO:root:current mean train loss 3283.873369036597
INFO:root:current train perplexity3.647794008255005
INFO:root:current mean train loss 3282.8013796957625
INFO:root:current train perplexity3.6471738815307617
INFO:root:current mean train loss 3281.316305615799
INFO:root:current train perplexity3.6471951007843018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.22s/it]
INFO:root:final mean train loss: 3279.965960656443
INFO:root:final train perplexity: 3.6474978923797607
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4063.0241993572695
INFO:root:eval perplexity: 5.170490741729736
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [10:56:25<3:46:54, 247.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.565988314354
INFO:root:current train perplexity3.634286403656006
INFO:root:current mean train loss 3275.1321353552476
INFO:root:current train perplexity3.6307342052459717
INFO:root:current mean train loss 3268.47310871139
INFO:root:current train perplexity3.6307191848754883
INFO:root:current mean train loss 3270.2171110615423
INFO:root:current train perplexity3.634582757949829
INFO:root:current mean train loss 3273.0724549802558
INFO:root:current train perplexity3.635939598083496
INFO:root:current mean train loss 3275.659857516212
INFO:root:current train perplexity3.6394400596618652
INFO:root:current mean train loss 3280.5397367578717
INFO:root:current train perplexity3.6419620513916016
INFO:root:current mean train loss 3279.677928336524
INFO:root:current train perplexity3.6428444385528564
INFO:root:current mean train loss 3279.8851612521826
INFO:root:current train perplexity3.6430656909942627
INFO:root:current mean train loss 3279.3816849725463
INFO:root:current train perplexity3.643514394760132


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.80s/it]
INFO:root:final mean train loss: 3277.6447754521523
INFO:root:final train perplexity: 3.6441590785980225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4064.079664297983
INFO:root:eval perplexity: 5.172698974609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [11:00:31<3:42:24, 247.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.017148145989
INFO:root:current train perplexity3.6269235610961914
INFO:root:current mean train loss 3284.3200478924964
INFO:root:current train perplexity3.626774787902832
INFO:root:current mean train loss 3280.6565279728466
INFO:root:current train perplexity3.6325697898864746
INFO:root:current mean train loss 3282.502745417873
INFO:root:current train perplexity3.6315388679504395
INFO:root:current mean train loss 3278.4387583436496
INFO:root:current train perplexity3.631885290145874
INFO:root:current mean train loss 3275.8705581046074
INFO:root:current train perplexity3.6339211463928223
INFO:root:current mean train loss 3277.209993880013
INFO:root:current train perplexity3.6354005336761475
INFO:root:current mean train loss 3276.8929502245965
INFO:root:current train perplexity3.6350975036621094
INFO:root:current mean train loss 3277.886251869774
INFO:root:current train perplexity3.638583183288574
INFO:root:current mean train loss 3278.7059067387863
INFO:root:current train perplexity3.640636682510376


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.03s/it]
INFO:root:final mean train loss: 3275.651170299899
INFO:root:final train perplexity: 3.641294240951538
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it]
INFO:root:eval mean loss: 4064.4214750249334
INFO:root:eval perplexity: 5.1734137535095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [11:04:42<3:39:13, 248.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.5517578125
INFO:root:current train perplexity3.6119115352630615
INFO:root:current mean train loss 3267.3449135044643
INFO:root:current train perplexity3.629201650619507
INFO:root:current mean train loss 3274.8271608664772
INFO:root:current train perplexity3.6376216411590576
INFO:root:current mean train loss 3268.301798177083
INFO:root:current train perplexity3.630631685256958
INFO:root:current mean train loss 3269.133576274671
INFO:root:current train perplexity3.6297285556793213
INFO:root:current mean train loss 3269.982789572011
INFO:root:current train perplexity3.6290571689605713
INFO:root:current mean train loss 3272.791861255787
INFO:root:current train perplexity3.630908727645874
INFO:root:current mean train loss 3273.7284110383066
INFO:root:current train perplexity3.6309144496917725
INFO:root:current mean train loss 3277.111591238839
INFO:root:current train perplexity3.635345935821533
INFO:root:current mean train loss 3275.104616135817
INFO:root:current train perplexity3.6357879638671875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.61s/it]
INFO:root:final mean train loss: 3272.2681042455856
INFO:root:final train perplexity: 3.636437177658081
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4064.8623323914007
INFO:root:eval perplexity: 5.174335956573486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [11:08:50<3:35:04, 248.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.7907008894954
INFO:root:current train perplexity3.635849952697754
INFO:root:current mean train loss 3265.681038945099
INFO:root:current train perplexity3.6304521560668945
INFO:root:current mean train loss 3267.6470209667623
INFO:root:current train perplexity3.628347158432007
INFO:root:current mean train loss 3270.321635193987
INFO:root:current train perplexity3.628314256668091
INFO:root:current mean train loss 3271.060726315832
INFO:root:current train perplexity3.6281723976135254
INFO:root:current mean train loss 3270.312599666327
INFO:root:current train perplexity3.631314754486084
INFO:root:current mean train loss 3270.6264991592698
INFO:root:current train perplexity3.6310484409332275
INFO:root:current mean train loss 3270.5751940652935
INFO:root:current train perplexity3.6311752796173096
INFO:root:current mean train loss 3271.273172899119
INFO:root:current train perplexity3.6323533058166504
INFO:root:current mean train loss 3272.6065575724824
INFO:root:current train perplexity3.6331658363342285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.86s/it]
INFO:root:final mean train loss: 3270.3722018580283
INFO:root:final train perplexity: 3.633718490600586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.37s/it]
INFO:root:eval mean loss: 4065.927765541888
INFO:root:eval perplexity: 5.1765666007995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [11:13:01<3:31:41, 249.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.018112014938
INFO:root:current train perplexity3.6151375770568848
INFO:root:current mean train loss 3259.254735816836
INFO:root:current train perplexity3.6136281490325928
INFO:root:current mean train loss 3261.794661793922
INFO:root:current train perplexity3.61881947517395
INFO:root:current mean train loss 3263.092077855259
INFO:root:current train perplexity3.618974208831787
INFO:root:current mean train loss 3264.0213138246245
INFO:root:current train perplexity3.621422529220581
INFO:root:current mean train loss 3263.4017740885415
INFO:root:current train perplexity3.6222760677337646
INFO:root:current mean train loss 3266.989128852546
INFO:root:current train perplexity3.624844551086426
INFO:root:current mean train loss 3267.280791966261
INFO:root:current train perplexity3.628373146057129
INFO:root:current mean train loss 3269.007806197829
INFO:root:current train perplexity3.629194736480713
INFO:root:current mean train loss 3270.6765119473703
INFO:root:current train perplexity3.630537748336792


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.34s/it]
INFO:root:final mean train loss: 3268.1463731335057
INFO:root:final train perplexity: 3.630528688430786
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.19s/it]
INFO:root:eval mean loss: 4070.216317251219
INFO:root:eval perplexity: 5.185550689697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [11:17:10<3:27:25, 248.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.9386146622473
INFO:root:current train perplexity3.634230613708496
INFO:root:current mean train loss 3263.883360896278
INFO:root:current train perplexity3.6212575435638428
INFO:root:current mean train loss 3263.6854676721887
INFO:root:current train perplexity3.620626449584961
INFO:root:current mean train loss 3260.9360174116932
INFO:root:current train perplexity3.6178393363952637
INFO:root:current mean train loss 3263.035005068731
INFO:root:current train perplexity3.61918044090271
INFO:root:current mean train loss 3264.681949163319
INFO:root:current train perplexity3.623849391937256
INFO:root:current mean train loss 3263.646368067664
INFO:root:current train perplexity3.6252360343933105
INFO:root:current mean train loss 3261.7272784217575
INFO:root:current train perplexity3.6245737075805664
INFO:root:current mean train loss 3266.094989712962
INFO:root:current train perplexity3.626262664794922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.57s/it]
INFO:root:final mean train loss: 3266.329049879505
INFO:root:final train perplexity: 3.627926826477051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4067.6206245151816
INFO:root:eval perplexity: 5.180109977722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [11:21:17<3:23:02, 248.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.1943708147323
INFO:root:current train perplexity3.6174702644348145
INFO:root:current mean train loss 3265.2514785338785
INFO:root:current train perplexity3.622677803039551
INFO:root:current mean train loss 3260.8361521550423
INFO:root:current train perplexity3.621123790740967
INFO:root:current mean train loss 3258.090125267203
INFO:root:current train perplexity3.622908353805542
INFO:root:current mean train loss 3257.8677771565954
INFO:root:current train perplexity3.6209676265716553
INFO:root:current mean train loss 3259.9626618936454
INFO:root:current train perplexity3.618481159210205
INFO:root:current mean train loss 3259.3920279036242
INFO:root:current train perplexity3.618509292602539
INFO:root:current mean train loss 3264.4526612364084
INFO:root:current train perplexity3.6194992065429688
INFO:root:current mean train loss 3265.685087636501
INFO:root:current train perplexity3.6212399005889893
INFO:root:current mean train loss 3268.154386509871
INFO:root:current train perplexity3.6231579780578613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.05s/it]
INFO:root:final mean train loss: 3262.261146053191
INFO:root:final train perplexity: 3.6221089363098145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it]
INFO:root:eval mean loss: 4068.6587052582004
INFO:root:eval perplexity: 5.182285308837891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [11:25:29<3:19:32, 249.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3273.910205078125
INFO:root:current train perplexity3.610281229019165
INFO:root:current mean train loss 3259.896248726223
INFO:root:current train perplexity3.6128485202789307
INFO:root:current mean train loss 3260.376422828852
INFO:root:current train perplexity3.6172537803649902
INFO:root:current mean train loss 3253.350828528026
INFO:root:current train perplexity3.6120433807373047
INFO:root:current mean train loss 3258.7399531720635
INFO:root:current train perplexity3.61395525932312
INFO:root:current mean train loss 3261.845112446905
INFO:root:current train perplexity3.6182055473327637
INFO:root:current mean train loss 3261.874456538999
INFO:root:current train perplexity3.614152193069458
INFO:root:current mean train loss 3264.4648546765734
INFO:root:current train perplexity3.6181459426879883
INFO:root:current mean train loss 3263.0905306388995
INFO:root:current train perplexity3.6194398403167725
INFO:root:current mean train loss 3263.7628964950477
INFO:root:current train perplexity3.621006727218628


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.02s/it]
INFO:root:final mean train loss: 3261.0729227373677
INFO:root:final train perplexity: 3.6204111576080322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4070.832116093196
INFO:root:eval perplexity: 5.1868414878845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [11:29:39<3:15:40, 249.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.302978515625
INFO:root:current train perplexity3.5650007724761963
INFO:root:current mean train loss 3249.7106020547512
INFO:root:current train perplexity3.604814052581787
INFO:root:current mean train loss 3250.17105061484
INFO:root:current train perplexity3.6007258892059326
INFO:root:current mean train loss 3250.8233056791796
INFO:root:current train perplexity3.600860118865967
INFO:root:current mean train loss 3252.9172022754137
INFO:root:current train perplexity3.6058409214019775
INFO:root:current mean train loss 3255.0270174511534
INFO:root:current train perplexity3.6065454483032227
INFO:root:current mean train loss 3255.4117974393057
INFO:root:current train perplexity3.6102302074432373
INFO:root:current mean train loss 3258.4259180092713
INFO:root:current train perplexity3.6132400035858154
INFO:root:current mean train loss 3260.9927282877998
INFO:root:current train perplexity3.6139094829559326
INFO:root:current mean train loss 3261.8643331972
INFO:root:current train perplexity3.6163814067840576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.85s/it]
INFO:root:final mean train loss: 3259.20743326987
INFO:root:final train perplexity: 3.6177480220794678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.04s/it]
INFO:root:eval mean loss: 4071.88613004211
INFO:root:eval perplexity: 5.189053058624268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [11:33:46<3:10:48, 248.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.3680538054437
INFO:root:current train perplexity3.6332268714904785
INFO:root:current mean train loss 3252.986083984375
INFO:root:current train perplexity3.613342523574829
INFO:root:current mean train loss 3250.6374553994183
INFO:root:current train perplexity3.6031484603881836
INFO:root:current mean train loss 3253.3505741361405
INFO:root:current train perplexity3.60819673538208
INFO:root:current mean train loss 3250.815528816524
INFO:root:current train perplexity3.6116950511932373
INFO:root:current mean train loss 3250.214714093397
INFO:root:current train perplexity3.610999345779419
INFO:root:current mean train loss 3254.857676075302
INFO:root:current train perplexity3.6150918006896973
INFO:root:current mean train loss 3258.210521358798
INFO:root:current train perplexity3.6183724403381348
INFO:root:current mean train loss 3260.591496620224
INFO:root:current train perplexity3.615532875061035
INFO:root:current mean train loss 3258.851978666672
INFO:root:current train perplexity3.6146888732910156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it]
INFO:root:final mean train loss: 3257.126625676309
INFO:root:final train perplexity: 3.614778995513916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4072.203926681627
INFO:root:eval perplexity: 5.189720153808594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [11:37:54<3:06:24, 248.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.4444486177886
INFO:root:current train perplexity3.6134159564971924
INFO:root:current mean train loss 3250.194016271358
INFO:root:current train perplexity3.591714382171631
INFO:root:current mean train loss 3255.036167543802
INFO:root:current train perplexity3.601604461669922
INFO:root:current mean train loss 3253.909620436947
INFO:root:current train perplexity3.6071956157684326
INFO:root:current mean train loss 3250.3506009529824
INFO:root:current train perplexity3.6101160049438477
INFO:root:current mean train loss 3251.5652172534496
INFO:root:current train perplexity3.6073856353759766
INFO:root:current mean train loss 3251.1548130471197
INFO:root:current train perplexity3.6051247119903564
INFO:root:current mean train loss 3252.9710559561063
INFO:root:current train perplexity3.605163097381592
INFO:root:current mean train loss 3253.7403580457576
INFO:root:current train perplexity3.6042850017547607
INFO:root:current mean train loss 3255.5948791828905
INFO:root:current train perplexity3.6089026927948


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.60s/it]
INFO:root:final mean train loss: 3252.9738862437584
INFO:root:final train perplexity: 3.6088614463806152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4072.5756593528367
INFO:root:eval perplexity: 5.190501689910889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [11:42:02<3:02:08, 248.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.415174119016
INFO:root:current train perplexity3.553251266479492
INFO:root:current mean train loss 3253.234587585034
INFO:root:current train perplexity3.584855794906616
INFO:root:current mean train loss 3243.451928019041
INFO:root:current train perplexity3.585721731185913
INFO:root:current mean train loss 3245.855951402648
INFO:root:current train perplexity3.5897622108459473
INFO:root:current mean train loss 3248.8770110196447
INFO:root:current train perplexity3.59578275680542
INFO:root:current mean train loss 3244.986176373972
INFO:root:current train perplexity3.5958285331726074
INFO:root:current mean train loss 3246.0154631200494
INFO:root:current train perplexity3.5986287593841553
INFO:root:current mean train loss 3249.536652142424
INFO:root:current train perplexity3.601411819458008
INFO:root:current mean train loss 3253.49104029848
INFO:root:current train perplexity3.6045565605163574
INFO:root:current mean train loss 3254.719244468552
INFO:root:current train perplexity3.6064698696136475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.49s/it]
INFO:root:final mean train loss: 3252.1152710453157
INFO:root:final train perplexity: 3.6076393127441406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4074.7054348127217
INFO:root:eval perplexity: 5.194971561431885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [11:46:10<2:57:52, 248.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.9685413707384
INFO:root:current train perplexity3.622159957885742
INFO:root:current mean train loss 3224.0972608996976
INFO:root:current train perplexity3.5955679416656494
INFO:root:current mean train loss 3235.3755974264704
INFO:root:current train perplexity3.5956003665924072
INFO:root:current mean train loss 3241.538678064481
INFO:root:current train perplexity3.60026216506958
INFO:root:current mean train loss 3243.7849566449177
INFO:root:current train perplexity3.6010873317718506
INFO:root:current mean train loss 3247.182575837556
INFO:root:current train perplexity3.6006510257720947
INFO:root:current mean train loss 3252.157998866889
INFO:root:current train perplexity3.6053569316864014
INFO:root:current mean train loss 3252.4048566199294
INFO:root:current train perplexity3.6051595211029053
INFO:root:current mean train loss 3254.389254957054
INFO:root:current train perplexity3.607325315475464
INFO:root:current mean train loss 3253.3902369314465
INFO:root:current train perplexity3.605504274368286


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.40s/it]
INFO:root:final mean train loss: 3250.8236907220657
INFO:root:final train perplexity: 3.6058013439178467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it]
INFO:root:eval mean loss: 4074.969922221299
INFO:root:eval perplexity: 5.19552755355835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [11:50:21<2:54:19, 249.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.4618326822915
INFO:root:current train perplexity3.599299669265747
INFO:root:current mean train loss 3256.532361364072
INFO:root:current train perplexity3.591919183731079
INFO:root:current mean train loss 3252.6274794661954
INFO:root:current train perplexity3.592123508453369
INFO:root:current mean train loss 3244.1835930774364
INFO:root:current train perplexity3.5934622287750244
INFO:root:current mean train loss 3248.1911600001686
INFO:root:current train perplexity3.601395606994629
INFO:root:current mean train loss 3249.7030720956373
INFO:root:current train perplexity3.6011223793029785
INFO:root:current mean train loss 3248.644030816954
INFO:root:current train perplexity3.60420298576355
INFO:root:current mean train loss 3252.229929912762
INFO:root:current train perplexity3.6033499240875244
INFO:root:current mean train loss 3250.928903307865
INFO:root:current train perplexity3.6029953956604004
INFO:root:current mean train loss 3250.5630194643204
INFO:root:current train perplexity3.6016650199890137


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.57s/it]
INFO:root:final mean train loss: 3247.9920326355964
INFO:root:final train perplexity: 3.6017754077911377
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 4074.511914408799
INFO:root:eval perplexity: 5.194565773010254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [11:54:28<2:49:49, 248.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.9683442451583
INFO:root:current train perplexity3.599984645843506
INFO:root:current mean train loss 3235.056218019006
INFO:root:current train perplexity3.580312490463257
INFO:root:current mean train loss 3237.580622261301
INFO:root:current train perplexity3.5830819606781006
INFO:root:current mean train loss 3236.070582963064
INFO:root:current train perplexity3.5908446311950684
INFO:root:current mean train loss 3240.923815166368
INFO:root:current train perplexity3.5930378437042236
INFO:root:current mean train loss 3241.067223757662
INFO:root:current train perplexity3.594905376434326
INFO:root:current mean train loss 3243.2978944963206
INFO:root:current train perplexity3.5930256843566895
INFO:root:current mean train loss 3245.932711550543
INFO:root:current train perplexity3.5949699878692627
INFO:root:current mean train loss 3247.9390315549654
INFO:root:current train perplexity3.5995006561279297
INFO:root:current mean train loss 3247.559251496524
INFO:root:current train perplexity3.5985660552978516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.79s/it]
INFO:root:final mean train loss: 3245.816531212099
INFO:root:final train perplexity: 3.5986850261688232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 4074.901400085882
INFO:root:eval perplexity: 5.195383071899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [11:58:38<2:46:03, 249.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.9665558247625
INFO:root:current train perplexity3.5779497623443604
INFO:root:current mean train loss 3235.788045020077
INFO:root:current train perplexity3.593111038208008
INFO:root:current mean train loss 3242.066212862623
INFO:root:current train perplexity3.5958328247070312
INFO:root:current mean train loss 3246.991145876278
INFO:root:current train perplexity3.5932095050811768
INFO:root:current mean train loss 3245.381725335171
INFO:root:current train perplexity3.592573404312134
INFO:root:current mean train loss 3247.9749471239475
INFO:root:current train perplexity3.594248056411743
INFO:root:current mean train loss 3244.386191276809
INFO:root:current train perplexity3.595418691635132
INFO:root:current mean train loss 3245.9805740532734
INFO:root:current train perplexity3.596391439437866
INFO:root:current mean train loss 3244.9089272144306
INFO:root:current train perplexity3.597327470779419
INFO:root:current mean train loss 3247.043591695129
INFO:root:current train perplexity3.5979974269866943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.41s/it]
INFO:root:final mean train loss: 3245.2586146939184
INFO:root:final train perplexity: 3.597892999649048
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 4076.61585944426
INFO:root:eval perplexity: 5.198987007141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [12:02:47<2:41:42, 248.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.778224901221
INFO:root:current train perplexity3.5679328441619873
INFO:root:current mean train loss 3230.973550561915
INFO:root:current train perplexity3.5712409019470215
INFO:root:current mean train loss 3237.6387773573606
INFO:root:current train perplexity3.5758066177368164
INFO:root:current mean train loss 3242.727256439761
INFO:root:current train perplexity3.5841455459594727
INFO:root:current mean train loss 3240.5141060141814
INFO:root:current train perplexity3.5848870277404785
INFO:root:current mean train loss 3242.4343744177227
INFO:root:current train perplexity3.5855417251586914
INFO:root:current mean train loss 3241.081025191617
INFO:root:current train perplexity3.585636615753174
INFO:root:current mean train loss 3242.4651393866147
INFO:root:current train perplexity3.588228225708008
INFO:root:current mean train loss 3242.5807948580186
INFO:root:current train perplexity3.5900416374206543
INFO:root:current mean train loss 3244.6530573727996
INFO:root:current train perplexity3.5935492515563965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.13s/it]
INFO:root:final mean train loss: 3241.8694263581306
INFO:root:final train perplexity: 3.593085289001465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4077.096832058954
INFO:root:eval perplexity: 5.1999993324279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [12:06:57<2:37:53, 249.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.243431332237
INFO:root:current train perplexity3.585664987564087
INFO:root:current mean train loss 3243.3063176081732
INFO:root:current train perplexity3.5939724445343018
INFO:root:current mean train loss 3240.075250761388
INFO:root:current train perplexity3.58502459526062
INFO:root:current mean train loss 3244.6754066950157
INFO:root:current train perplexity3.5843653678894043
INFO:root:current mean train loss 3247.1821525804926
INFO:root:current train perplexity3.5887951850891113
INFO:root:current mean train loss 3246.5782218356094
INFO:root:current train perplexity3.5888538360595703
INFO:root:current mean train loss 3245.5682315085432
INFO:root:current train perplexity3.587611675262451
INFO:root:current mean train loss 3243.223076049037
INFO:root:current train perplexity3.5884828567504883
INFO:root:current mean train loss 3243.1712852435403
INFO:root:current train perplexity3.5892999172210693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.53s/it]
INFO:root:final mean train loss: 3240.491654303766
INFO:root:final train perplexity: 3.5911331176757812
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4077.1641282967644
INFO:root:eval perplexity: 5.20013952255249
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [12:11:04<2:33:17, 248.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.1691080729165
INFO:root:current train perplexity3.588789939880371
INFO:root:current mean train loss 3214.7763434845265
INFO:root:current train perplexity3.5876996517181396
INFO:root:current mean train loss 3236.095689895705
INFO:root:current train perplexity3.5963845252990723
INFO:root:current mean train loss 3234.3520588386964
INFO:root:current train perplexity3.5930891036987305
INFO:root:current mean train loss 3233.7345537133606
INFO:root:current train perplexity3.5942771434783936
INFO:root:current mean train loss 3235.372418322099
INFO:root:current train perplexity3.592482805252075
INFO:root:current mean train loss 3237.643686272414
INFO:root:current train perplexity3.5898280143737793
INFO:root:current mean train loss 3237.1837517642025
INFO:root:current train perplexity3.586988925933838
INFO:root:current mean train loss 3237.498371889107
INFO:root:current train perplexity3.5876026153564453
INFO:root:current mean train loss 3241.8944587918745
INFO:root:current train perplexity3.589538335800171


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.04s/it]
INFO:root:final mean train loss: 3239.634923996464
INFO:root:final train perplexity: 3.5899195671081543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it]
INFO:root:eval mean loss: 4079.403936724291
INFO:root:eval perplexity: 5.2048516273498535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [12:15:14<2:29:22, 248.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.971368963068
INFO:root:current train perplexity3.5769753456115723
INFO:root:current mean train loss 3238.8058400197074
INFO:root:current train perplexity3.5710458755493164
INFO:root:current mean train loss 3241.7411044875594
INFO:root:current train perplexity3.5786962509155273
INFO:root:current mean train loss 3241.9178133164187
INFO:root:current train perplexity3.5865345001220703
INFO:root:current mean train loss 3246.644468284291
INFO:root:current train perplexity3.5928878784179688
INFO:root:current mean train loss 3243.14517671768
INFO:root:current train perplexity3.592979907989502
INFO:root:current mean train loss 3240.50913109912
INFO:root:current train perplexity3.589617967605591
INFO:root:current mean train loss 3239.910560060654
INFO:root:current train perplexity3.5892486572265625
INFO:root:current mean train loss 3241.2241713668504
INFO:root:current train perplexity3.5890257358551025
INFO:root:current mean train loss 3241.098114516157
INFO:root:current train perplexity3.588618516921997


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.44s/it]
INFO:root:final mean train loss: 3237.4201258997764
INFO:root:final train perplexity: 3.5867841243743896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 4078.1394856770835
INFO:root:eval perplexity: 5.202191352844238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [12:19:21<2:24:50, 248.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.4220677425988
INFO:root:current train perplexity3.6016499996185303
INFO:root:current mean train loss 3241.125469816833
INFO:root:current train perplexity3.589559316635132
INFO:root:current mean train loss 3243.2958159424943
INFO:root:current train perplexity3.594050884246826
INFO:root:current mean train loss 3242.952528041732
INFO:root:current train perplexity3.58921217918396
INFO:root:current mean train loss 3239.6649306850386
INFO:root:current train perplexity3.5884461402893066
INFO:root:current mean train loss 3237.5306855130057
INFO:root:current train perplexity3.587761640548706
INFO:root:current mean train loss 3240.0169076257066
INFO:root:current train perplexity3.5883052349090576
INFO:root:current mean train loss 3241.8375840061067
INFO:root:current train perplexity3.5877556800842285
INFO:root:current mean train loss 3241.6854207803913
INFO:root:current train perplexity3.5889546871185303
INFO:root:current mean train loss 3239.813160428285
INFO:root:current train perplexity3.5858840942382812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.18s/it]
INFO:root:final mean train loss: 3236.1572174564485
INFO:root:final train perplexity: 3.5849969387054443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.57s/it]
INFO:root:eval mean loss: 4079.5056186973625
INFO:root:eval perplexity: 5.2050652503967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [12:23:31<2:21:06, 249.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3233.870704933449
INFO:root:current train perplexity3.5935020446777344
INFO:root:current mean train loss 3234.835847148745
INFO:root:current train perplexity3.575279474258423
INFO:root:current mean train loss 3239.763264256952
INFO:root:current train perplexity3.584272861480713
INFO:root:current mean train loss 3233.942568717747
INFO:root:current train perplexity3.5798251628875732
INFO:root:current mean train loss 3236.5528910366656
INFO:root:current train perplexity3.5791513919830322
INFO:root:current mean train loss 3239.1305702976756
INFO:root:current train perplexity3.5782065391540527
INFO:root:current mean train loss 3239.2521209473434
INFO:root:current train perplexity3.580366373062134
INFO:root:current mean train loss 3240.3099497882995
INFO:root:current train perplexity3.582247734069824
INFO:root:current mean train loss 3237.1907384796327
INFO:root:current train perplexity3.5823516845703125
INFO:root:current mean train loss 3237.5694850028653
INFO:root:current train perplexity3.5832467079162598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.80s/it]
INFO:root:final mean train loss: 3234.6223729041317
INFO:root:final train perplexity: 3.582826614379883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4080.117095730829
INFO:root:eval perplexity: 5.206352710723877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [12:27:39<2:16:50, 248.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.5796107700894
INFO:root:current train perplexity3.5834453105926514
INFO:root:current mean train loss 3233.904615162037
INFO:root:current train perplexity3.578254222869873
INFO:root:current mean train loss 3224.1052152593084
INFO:root:current train perplexity3.5723185539245605
INFO:root:current mean train loss 3230.251011543843
INFO:root:current train perplexity3.573483467102051
INFO:root:current mean train loss 3232.334564700072
INFO:root:current train perplexity3.57531476020813
INFO:root:current mean train loss 3235.893911087179
INFO:root:current train perplexity3.576570510864258
INFO:root:current mean train loss 3235.3438353531005
INFO:root:current train perplexity3.5786845684051514
INFO:root:current mean train loss 3236.2202912414964
INFO:root:current train perplexity3.577622890472412
INFO:root:current mean train loss 3236.1008429430203
INFO:root:current train perplexity3.577714681625366
INFO:root:current mean train loss 3235.524862132353
INFO:root:current train perplexity3.5793004035949707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.10s/it]
INFO:root:final mean train loss: 3232.723809396067
INFO:root:final train perplexity: 3.580143928527832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 4080.4846226036125
INFO:root:eval perplexity: 5.207127571105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [12:31:48<2:12:39, 248.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.8538278978926
INFO:root:current train perplexity3.556812047958374
INFO:root:current mean train loss 3250.308405949519
INFO:root:current train perplexity3.5867652893066406
INFO:root:current mean train loss 3234.0668874983926
INFO:root:current train perplexity3.581087827682495
INFO:root:current mean train loss 3228.3169728270773
INFO:root:current train perplexity3.573669910430908
INFO:root:current mean train loss 3229.6694484736527
INFO:root:current train perplexity3.574709177017212
INFO:root:current mean train loss 3227.9092992849332
INFO:root:current train perplexity3.5706546306610107
INFO:root:current mean train loss 3232.3937464309147
INFO:root:current train perplexity3.5716142654418945
INFO:root:current mean train loss 3234.2149212966856
INFO:root:current train perplexity3.5767364501953125
INFO:root:current mean train loss 3235.5675562884603
INFO:root:current train perplexity3.577812910079956
INFO:root:current mean train loss 3233.9053580970804
INFO:root:current train perplexity3.5774600505828857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.46s/it]
INFO:root:final mean train loss: 3230.7523624051
INFO:root:final train perplexity: 3.5773606300354004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it]
INFO:root:eval mean loss: 4080.795604083555
INFO:root:eval perplexity: 5.207781791687012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [12:35:59<2:08:54, 249.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.022762522978
INFO:root:current train perplexity3.574383497238159
INFO:root:current mean train loss 3226.603691858961
INFO:root:current train perplexity3.5647311210632324
INFO:root:current mean train loss 3228.8160638695217
INFO:root:current train perplexity3.5754077434539795
INFO:root:current mean train loss 3226.803976640402
INFO:root:current train perplexity3.5715911388397217
INFO:root:current mean train loss 3221.4130415482955
INFO:root:current train perplexity3.566803216934204
INFO:root:current mean train loss 3221.9497389334733
INFO:root:current train perplexity3.5682144165039062
INFO:root:current mean train loss 3226.0643638692877
INFO:root:current train perplexity3.5706512928009033
INFO:root:current mean train loss 3228.692497243259
INFO:root:current train perplexity3.573321580886841
INFO:root:current mean train loss 3230.2693453473853
INFO:root:current train perplexity3.572906970977783
INFO:root:current mean train loss 3231.290593834204
INFO:root:current train perplexity3.5744478702545166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.67s/it]
INFO:root:final mean train loss: 3229.517770459575
INFO:root:final train perplexity: 3.5756187438964844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4083.30692805297
INFO:root:eval perplexity: 5.213073253631592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [12:40:07<2:04:31, 249.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.7393033302437
INFO:root:current train perplexity3.566598415374756
INFO:root:current mean train loss 3209.732570816136
INFO:root:current train perplexity3.549503803253174
INFO:root:current mean train loss 3211.0796577129586
INFO:root:current train perplexity3.5601894855499268
INFO:root:current mean train loss 3220.457738509749
INFO:root:current train perplexity3.5696229934692383
INFO:root:current mean train loss 3219.347406790407
INFO:root:current train perplexity3.5667531490325928
INFO:root:current mean train loss 3222.5427997295674
INFO:root:current train perplexity3.5706984996795654
INFO:root:current mean train loss 3226.621583883607
INFO:root:current train perplexity3.573061227798462
INFO:root:current mean train loss 3228.3967236907115
INFO:root:current train perplexity3.573167324066162
INFO:root:current mean train loss 3229.2187878005857
INFO:root:current train perplexity3.5737900733947754
INFO:root:current mean train loss 3229.086943339009
INFO:root:current train perplexity3.5727601051330566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.49s/it]
INFO:root:final mean train loss: 3227.53736323695
INFO:root:final train perplexity: 3.5728261470794678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4082.8099339261967
INFO:root:eval perplexity: 5.212024688720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [12:44:14<2:00:02, 248.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.680270522388
INFO:root:current train perplexity3.564500331878662
INFO:root:current mean train loss 3242.164017180483
INFO:root:current train perplexity3.5771324634552
INFO:root:current mean train loss 3233.226632907596
INFO:root:current train perplexity3.5799131393432617
INFO:root:current mean train loss 3232.238487472326
INFO:root:current train perplexity3.5796711444854736
INFO:root:current mean train loss 3224.1180459130755
INFO:root:current train perplexity3.5737802982330322
INFO:root:current mean train loss 3222.7673542217813
INFO:root:current train perplexity3.57000732421875
INFO:root:current mean train loss 3223.0124211575853
INFO:root:current train perplexity3.570164680480957
INFO:root:current mean train loss 3225.4937615226736
INFO:root:current train perplexity3.570824146270752
INFO:root:current mean train loss 3228.738570163819
INFO:root:current train perplexity3.5718252658843994
INFO:root:current mean train loss 3228.946155504702
INFO:root:current train perplexity3.571866989135742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.11s/it]
INFO:root:final mean train loss: 3226.8589793174497
INFO:root:final train perplexity: 3.5718700885772705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it]
INFO:root:eval mean loss: 4084.228010028812
INFO:root:eval perplexity: 5.215014457702637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [12:48:25<1:56:14, 249.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.5833333333335
INFO:root:current train perplexity3.5686566829681396
INFO:root:current mean train loss 3215.164031808036
INFO:root:current train perplexity3.5603973865509033
INFO:root:current mean train loss 3227.5284037642045
INFO:root:current train perplexity3.5676329135894775
INFO:root:current mean train loss 3224.023919921875
INFO:root:current train perplexity3.565074920654297
INFO:root:current mean train loss 3224.3339756373357
INFO:root:current train perplexity3.565603017807007
INFO:root:current mean train loss 3225.421456351902
INFO:root:current train perplexity3.565274238586426
INFO:root:current mean train loss 3223.4099363425926
INFO:root:current train perplexity3.5659475326538086
INFO:root:current mean train loss 3225.001062563004
INFO:root:current train perplexity3.5667531490325928
INFO:root:current mean train loss 3227.2096216517857
INFO:root:current train perplexity3.567714214324951
INFO:root:current mean train loss 3226.4093411959134
INFO:root:current train perplexity3.567005157470703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.38s/it]
INFO:root:final mean train loss: 3223.3469056775493
INFO:root:final train perplexity: 3.5669240951538086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.90s/it]
INFO:root:eval mean loss: 4083.861343708444
INFO:root:eval perplexity: 5.2142415046691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [12:52:33<1:51:58, 248.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.387995340738
INFO:root:current train perplexity3.5856833457946777
INFO:root:current mean train loss 3227.479378788849
INFO:root:current train perplexity3.5639288425445557
INFO:root:current mean train loss 3225.0990865862414
INFO:root:current train perplexity3.5662734508514404
INFO:root:current mean train loss 3225.868924531862
INFO:root:current train perplexity3.5618841648101807
INFO:root:current mean train loss 3232.7843308221727
INFO:root:current train perplexity3.5661566257476807
INFO:root:current mean train loss 3226.395596590909
INFO:root:current train perplexity3.564164638519287
INFO:root:current mean train loss 3225.228642163479
INFO:root:current train perplexity3.5640859603881836
INFO:root:current mean train loss 3226.476860270494
INFO:root:current train perplexity3.5656745433807373
INFO:root:current mean train loss 3227.8081151458982
INFO:root:current train perplexity3.567401170730591
INFO:root:current mean train loss 3225.834175862713
INFO:root:current train perplexity3.5667977333068848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.08s/it]
INFO:root:final mean train loss: 3223.5251443309166
INFO:root:final train perplexity: 3.5671749114990234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it]
INFO:root:eval mean loss: 4085.081877147052
INFO:root:eval perplexity: 5.216814994812012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [12:56:42<1:47:49, 248.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.561461731628
INFO:root:current train perplexity3.5515599250793457
INFO:root:current mean train loss 3203.693322306528
INFO:root:current train perplexity3.5460119247436523
INFO:root:current mean train loss 3215.2186384168276
INFO:root:current train perplexity3.5558063983917236
INFO:root:current mean train loss 3219.8342928288844
INFO:root:current train perplexity3.558807134628296
INFO:root:current mean train loss 3216.203698307822
INFO:root:current train perplexity3.5541117191314697
INFO:root:current mean train loss 3217.659622114927
INFO:root:current train perplexity3.55424165725708
INFO:root:current mean train loss 3220.52218499853
INFO:root:current train perplexity3.557584524154663
INFO:root:current mean train loss 3220.5216448719975
INFO:root:current train perplexity3.5580973625183105
INFO:root:current mean train loss 3223.278164950284
INFO:root:current train perplexity3.56158185005188
INFO:root:current mean train loss 3223.6702832819597
INFO:root:current train perplexity3.5638480186462402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it]
INFO:root:final mean train loss: 3221.1149938029625
INFO:root:final train perplexity: 3.5637848377227783
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it]
INFO:root:eval mean loss: 4087.235394849845
INFO:root:eval perplexity: 5.221360683441162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [13:00:50<1:43:32, 248.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.6720920138887
INFO:root:current train perplexity3.5650510787963867
INFO:root:current mean train loss 3216.95066519119
INFO:root:current train perplexity3.5565474033355713
INFO:root:current mean train loss 3217.022059207776
INFO:root:current train perplexity3.5562052726745605
INFO:root:current mean train loss 3217.9471811853855
INFO:root:current train perplexity3.556814432144165
INFO:root:current mean train loss 3219.6645434423535
INFO:root:current train perplexity3.5589101314544678
INFO:root:current mean train loss 3220.421714005765
INFO:root:current train perplexity3.56142520904541
INFO:root:current mean train loss 3222.0770296852647
INFO:root:current train perplexity3.5608372688293457
INFO:root:current mean train loss 3220.9558475193603
INFO:root:current train perplexity3.5606279373168945
INFO:root:current mean train loss 3221.1267228343995
INFO:root:current train perplexity3.56109619140625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.42s/it]
INFO:root:final mean train loss: 3221.149071908766
INFO:root:final train perplexity: 3.5638327598571777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.52s/it]
INFO:root:eval mean loss: 4085.093033161569
INFO:root:eval perplexity: 5.21683931350708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [13:04:59<1:39:27, 248.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.8984375
INFO:root:current train perplexity3.472097873687744
INFO:root:current mean train loss 3233.244925525701
INFO:root:current train perplexity3.5581533908843994
INFO:root:current mean train loss 3225.1603154721465
INFO:root:current train perplexity3.5541651248931885
INFO:root:current mean train loss 3219.1800135509975
INFO:root:current train perplexity3.552114963531494
INFO:root:current mean train loss 3220.4733118905483
INFO:root:current train perplexity3.550654888153076
INFO:root:current mean train loss 3218.0880630162105
INFO:root:current train perplexity3.551626682281494
INFO:root:current mean train loss 3217.2382128745367
INFO:root:current train perplexity3.553861618041992
INFO:root:current mean train loss 3218.5576468849454
INFO:root:current train perplexity3.557590961456299
INFO:root:current mean train loss 3220.032780794997
INFO:root:current train perplexity3.5593156814575195
INFO:root:current mean train loss 3222.9193837965995
INFO:root:current train perplexity3.5633785724639893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.15s/it]
INFO:root:final mean train loss: 3220.0911137365524
INFO:root:final train perplexity: 3.562345266342163
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it]
INFO:root:eval mean loss: 4086.46450610871
INFO:root:eval perplexity: 5.219733238220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [13:09:09<1:35:32, 249.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.7968587239584
INFO:root:current train perplexity3.523853302001953
INFO:root:current mean train loss 3210.716062330163
INFO:root:current train perplexity3.5315213203430176
INFO:root:current mean train loss 3216.6942791606107
INFO:root:current train perplexity3.5592966079711914
INFO:root:current mean train loss 3212.9660171750993
INFO:root:current train perplexity3.558192014694214
INFO:root:current mean train loss 3215.572476821348
INFO:root:current train perplexity3.5548787117004395
INFO:root:current mean train loss 3214.287720911711
INFO:root:current train perplexity3.551966905593872
INFO:root:current mean train loss 3217.6581812912855
INFO:root:current train perplexity3.553758382797241
INFO:root:current mean train loss 3220.0842380763766
INFO:root:current train perplexity3.556173086166382
INFO:root:current mean train loss 3220.203626761407
INFO:root:current train perplexity3.556316375732422
INFO:root:current mean train loss 3219.0785788614244
INFO:root:current train perplexity3.5578067302703857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.08s/it]
INFO:root:final mean train loss: 3217.374848642657
INFO:root:final train perplexity: 3.5585296154022217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.57s/it]
INFO:root:eval mean loss: 4088.0053260749114
INFO:root:eval perplexity: 5.222986698150635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [13:13:17<1:31:12, 248.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.8218410326085
INFO:root:current train perplexity3.556201457977295
INFO:root:current mean train loss 3234.0078343337145
INFO:root:current train perplexity3.55488657951355
INFO:root:current mean train loss 3226.772686466508
INFO:root:current train perplexity3.5490810871124268
INFO:root:current mean train loss 3227.6382727844425
INFO:root:current train perplexity3.553081750869751
INFO:root:current mean train loss 3229.0589648668365
INFO:root:current train perplexity3.555537700653076
INFO:root:current mean train loss 3223.2762033378644
INFO:root:current train perplexity3.5554652214050293
INFO:root:current mean train loss 3222.541104581536
INFO:root:current train perplexity3.5557937622070312
INFO:root:current mean train loss 3219.5582304093186
INFO:root:current train perplexity3.5567173957824707
INFO:root:current mean train loss 3218.4543424400063
INFO:root:current train perplexity3.555917501449585
INFO:root:current mean train loss 3219.2108843339483
INFO:root:current train perplexity3.5592589378356934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.31s/it]
INFO:root:final mean train loss: 3218.123318272252
INFO:root:final train perplexity: 3.559580087661743
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it]
INFO:root:eval mean loss: 4087.165702224623
INFO:root:eval perplexity: 5.2212138175964355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [13:17:25<1:26:59, 248.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3194.294709236391
INFO:root:current train perplexity3.5455660820007324
INFO:root:current mean train loss 3207.746062067629
INFO:root:current train perplexity3.548440456390381
INFO:root:current mean train loss 3207.9352699709143
INFO:root:current train perplexity3.556995153427124
INFO:root:current mean train loss 3207.4769681717335
INFO:root:current train perplexity3.5548574924468994
INFO:root:current mean train loss 3211.4720931971433
INFO:root:current train perplexity3.555553674697876
INFO:root:current mean train loss 3213.8553919675437
INFO:root:current train perplexity3.5534780025482178
INFO:root:current mean train loss 3214.97450916514
INFO:root:current train perplexity3.555210828781128
INFO:root:current mean train loss 3217.1005592189636
INFO:root:current train perplexity3.556655168533325
INFO:root:current mean train loss 3217.7709106004627
INFO:root:current train perplexity3.55557918548584
INFO:root:current mean train loss 3216.768945155159
INFO:root:current train perplexity3.5547170639038086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.80s/it]
INFO:root:final mean train loss: 3215.762894230504
INFO:root:final train perplexity: 3.556267499923706
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.00s/it]
INFO:root:eval mean loss: 4087.3661572611923
INFO:root:eval perplexity: 5.221636772155762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [13:21:33<1:22:46, 248.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.244572566106
INFO:root:current train perplexity3.583467721939087
INFO:root:current mean train loss 3212.375651627136
INFO:root:current train perplexity3.5579583644866943
INFO:root:current mean train loss 3208.6914726480777
INFO:root:current train perplexity3.5517852306365967
INFO:root:current mean train loss 3213.072998046875
INFO:root:current train perplexity3.549205780029297
INFO:root:current mean train loss 3212.6262841018292
INFO:root:current train perplexity3.5512397289276123
INFO:root:current mean train loss 3212.1036270509626
INFO:root:current train perplexity3.549619674682617
INFO:root:current mean train loss 3211.5442784746674
INFO:root:current train perplexity3.5487353801727295
INFO:root:current mean train loss 3214.2687760328567
INFO:root:current train perplexity3.550604820251465
INFO:root:current mean train loss 3216.3681736651706
INFO:root:current train perplexity3.5540354251861572
INFO:root:current mean train loss 3216.228525765026
INFO:root:current train perplexity3.5528526306152344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.72s/it]
INFO:root:final mean train loss: 3213.8495663058375
INFO:root:final train perplexity: 3.553584337234497
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4089.205237422429
INFO:root:eval perplexity: 5.225521087646484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [13:25:40<1:18:30, 247.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.6775681515956
INFO:root:current train perplexity3.533677577972412
INFO:root:current mean train loss 3212.1756849224066
INFO:root:current train perplexity3.5547969341278076
INFO:root:current mean train loss 3216.7656447684717
INFO:root:current train perplexity3.554095506668091
INFO:root:current mean train loss 3222.904707059393
INFO:root:current train perplexity3.5585997104644775
INFO:root:current mean train loss 3218.901845637584
INFO:root:current train perplexity3.5541751384735107
INFO:root:current mean train loss 3216.5157816606206
INFO:root:current train perplexity3.55422306060791
INFO:root:current mean train loss 3219.219516005361
INFO:root:current train perplexity3.555034637451172
INFO:root:current mean train loss 3217.62432313891
INFO:root:current train perplexity3.5547802448272705
INFO:root:current mean train loss 3217.4578645564306
INFO:root:current train perplexity3.554622173309326
INFO:root:current mean train loss 3217.1639052394075
INFO:root:current train perplexity3.554454803466797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.99s/it]
INFO:root:final mean train loss: 3213.6083807791433
INFO:root:final train perplexity: 3.553245782852173
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4088.321962613586
INFO:root:eval perplexity: 5.223654747009277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [13:29:47<1:14:19, 247.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.0130326704543
INFO:root:current train perplexity3.576920747756958
INFO:root:current mean train loss 3203.6332141507055
INFO:root:current train perplexity3.5587332248687744
INFO:root:current mean train loss 3203.166614966299
INFO:root:current train perplexity3.5451531410217285
INFO:root:current mean train loss 3209.607499587368
INFO:root:current train perplexity3.547004222869873
INFO:root:current mean train loss 3211.2701998197117
INFO:root:current train perplexity3.5447499752044678
INFO:root:current mean train loss 3209.395675851633
INFO:root:current train perplexity3.5479485988616943
INFO:root:current mean train loss 3211.2306044250954
INFO:root:current train perplexity3.546969175338745
INFO:root:current mean train loss 3213.2126296693914
INFO:root:current train perplexity3.5508275032043457
INFO:root:current mean train loss 3214.644821648849
INFO:root:current train perplexity3.5509355068206787
INFO:root:current mean train loss 3215.4461911506055
INFO:root:current train perplexity3.551217794418335


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.19s/it]
INFO:root:final mean train loss: 3212.0736694335938
INFO:root:final train perplexity: 3.5510950088500977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4088.5695402537676
INFO:root:eval perplexity: 5.224178314208984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [13:33:58<1:10:26, 248.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.323455326141
INFO:root:current train perplexity3.553774356842041
INFO:root:current mean train loss 3220.0104021879793
INFO:root:current train perplexity3.550581932067871
INFO:root:current mean train loss 3213.1335523482057
INFO:root:current train perplexity3.549818515777588
INFO:root:current mean train loss 3212.8843203878273
INFO:root:current train perplexity3.551436185836792
INFO:root:current mean train loss 3212.9099564027065
INFO:root:current train perplexity3.551006555557251
INFO:root:current mean train loss 3212.496761992812
INFO:root:current train perplexity3.5515058040618896
INFO:root:current mean train loss 3214.7283480775122
INFO:root:current train perplexity3.552117109298706
INFO:root:current mean train loss 3215.8945587678163
INFO:root:current train perplexity3.5507495403289795
INFO:root:current mean train loss 3213.3202994867106
INFO:root:current train perplexity3.550201892852783
INFO:root:current mean train loss 3213.080135927765
INFO:root:current train perplexity3.5505480766296387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.96s/it]
INFO:root:final mean train loss: 3211.8973306840467
INFO:root:final train perplexity: 3.5508482456207275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]
INFO:root:eval mean loss: 4089.0136909214316
INFO:root:eval perplexity: 5.225115776062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [13:38:05<1:06:08, 248.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.15703056228
INFO:root:current train perplexity3.5504021644592285
INFO:root:current mean train loss 3218.8823127969663
INFO:root:current train perplexity3.543985366821289
INFO:root:current mean train loss 3218.073995329797
INFO:root:current train perplexity3.545510768890381
INFO:root:current mean train loss 3214.9732846982397
INFO:root:current train perplexity3.5446972846984863
INFO:root:current mean train loss 3214.0617483993497
INFO:root:current train perplexity3.5446290969848633
INFO:root:current mean train loss 3214.285602629707
INFO:root:current train perplexity3.546074628829956
INFO:root:current mean train loss 3212.9522113828475
INFO:root:current train perplexity3.546477794647217
INFO:root:current mean train loss 3211.429475658135
INFO:root:current train perplexity3.546828031539917
INFO:root:current mean train loss 3214.716577681006
INFO:root:current train perplexity3.5478556156158447
INFO:root:current mean train loss 3213.862655686792
INFO:root:current train perplexity3.5492537021636963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.42s/it]
INFO:root:final mean train loss: 3210.5370673518028
INFO:root:final train perplexity: 3.5489423274993896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.21s/it]
INFO:root:eval mean loss: 4089.6347413840867
INFO:root:eval perplexity: 5.226428985595703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [13:42:15<1:02:12, 248.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.2730666534812
INFO:root:current train perplexity3.533196449279785
INFO:root:current mean train loss 3195.367696239962
INFO:root:current train perplexity3.5385782718658447
INFO:root:current mean train loss 3197.8220923639115
INFO:root:current train perplexity3.54510498046875
INFO:root:current mean train loss 3202.355989883946
INFO:root:current train perplexity3.541776418685913
INFO:root:current mean train loss 3206.0657864692066
INFO:root:current train perplexity3.5434563159942627
INFO:root:current mean train loss 3209.062034488342
INFO:root:current train perplexity3.543574571609497
INFO:root:current mean train loss 3210.9507587416006
INFO:root:current train perplexity3.54569673538208
INFO:root:current mean train loss 3211.73175150684
INFO:root:current train perplexity3.547597646713257
INFO:root:current mean train loss 3213.0320463039498
INFO:root:current train perplexity3.547818660736084
INFO:root:current mean train loss 3211.9866156573194
INFO:root:current train perplexity3.5468618869781494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.15s/it]
INFO:root:final mean train loss: 3208.980276907644
INFO:root:final train perplexity: 3.5467636585235596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4090.621279019836
INFO:root:eval perplexity: 5.228513240814209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [13:46:23<57:58, 248.43s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.8047043372844
INFO:root:current train perplexity3.5661909580230713
INFO:root:current mean train loss 3212.9750454336563
INFO:root:current train perplexity3.555554151535034
INFO:root:current mean train loss 3216.3707483803355
INFO:root:current train perplexity3.5496809482574463
INFO:root:current mean train loss 3216.331464111959
INFO:root:current train perplexity3.5473196506500244
INFO:root:current mean train loss 3216.265929799795
INFO:root:current train perplexity3.545896530151367
INFO:root:current mean train loss 3214.1547531309893
INFO:root:current train perplexity3.546774387359619
INFO:root:current mean train loss 3215.7245944493725
INFO:root:current train perplexity3.5481441020965576
INFO:root:current mean train loss 3213.102743185157
INFO:root:current train perplexity3.546898126602173
INFO:root:current mean train loss 3212.0606228420943
INFO:root:current train perplexity3.546861410140991
INFO:root:current mean train loss 3211.670853913374
INFO:root:current train perplexity3.5470244884490967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.94s/it]
INFO:root:final mean train loss: 3208.7350791192825
INFO:root:final train perplexity: 3.5464212894439697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 4090.155278631981
INFO:root:eval perplexity: 5.2275285720825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [13:50:33<53:57, 249.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.5589458264803
INFO:root:current train perplexity3.535442590713501
INFO:root:current mean train loss 3210.001519931891
INFO:root:current train perplexity3.541520595550537
INFO:root:current mean train loss 3206.9616732322565
INFO:root:current train perplexity3.539612293243408
INFO:root:current mean train loss 3204.937535230419
INFO:root:current train perplexity3.538818836212158
INFO:root:current mean train loss 3203.552262863005
INFO:root:current train perplexity3.53751540184021
INFO:root:current mean train loss 3207.148110064338
INFO:root:current train perplexity3.542259931564331
INFO:root:current mean train loss 3210.311555052833
INFO:root:current train perplexity3.5443434715270996
INFO:root:current mean train loss 3210.3821930891313
INFO:root:current train perplexity3.5444414615631104
INFO:root:current mean train loss 3209.338653325768
INFO:root:current train perplexity3.54435658454895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.06s/it]
INFO:root:final mean train loss: 3206.6795434028872
INFO:root:final train perplexity: 3.5435454845428467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]
INFO:root:eval mean loss: 4089.9344058205897
INFO:root:eval perplexity: 5.227062225341797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [13:54:41<49:43, 248.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3185.0135091145835
INFO:root:current train perplexity3.4978017807006836
INFO:root:current mean train loss 3207.5272394569174
INFO:root:current train perplexity3.526838541030884
INFO:root:current mean train loss 3205.3374805168564
INFO:root:current train perplexity3.5353620052337646
INFO:root:current mean train loss 3209.513443849268
INFO:root:current train perplexity3.542712926864624
INFO:root:current mean train loss 3206.5558548920208
INFO:root:current train perplexity3.542426586151123
INFO:root:current mean train loss 3207.42004273189
INFO:root:current train perplexity3.5450353622436523
INFO:root:current mean train loss 3204.1848719456107
INFO:root:current train perplexity3.5442004203796387
INFO:root:current mean train loss 3205.564552100929
INFO:root:current train perplexity3.540773391723633
INFO:root:current mean train loss 3205.770943495583
INFO:root:current train perplexity3.5410077571868896
INFO:root:current mean train loss 3210.5105048060286
INFO:root:current train perplexity3.543578863143921


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.85s/it]
INFO:root:final mean train loss: 3206.958033530943
INFO:root:final train perplexity: 3.5439350605010986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it]
INFO:root:eval mean loss: 4090.5393135666
INFO:root:eval perplexity: 5.228341579437256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [13:58:50<45:36, 248.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.8236194957385
INFO:root:current train perplexity3.5476605892181396
INFO:root:current mean train loss 3193.8557920713683
INFO:root:current train perplexity3.534060478210449
INFO:root:current mean train loss 3206.9862367168985
INFO:root:current train perplexity3.538811206817627
INFO:root:current mean train loss 3207.2764990705386
INFO:root:current train perplexity3.539132595062256
INFO:root:current mean train loss 3203.7904869506538
INFO:root:current train perplexity3.5410068035125732
INFO:root:current mean train loss 3202.9698598604145
INFO:root:current train perplexity3.540496587753296
INFO:root:current mean train loss 3201.2448059181925
INFO:root:current train perplexity3.5381357669830322
INFO:root:current mean train loss 3203.7601975925195
INFO:root:current train perplexity3.540686845779419
INFO:root:current mean train loss 3203.870652129412
INFO:root:current train perplexity3.5393967628479004
INFO:root:current mean train loss 3207.2332261187053
INFO:root:current train perplexity3.5415666103363037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.94s/it]
INFO:root:final mean train loss: 3206.0059232404155
INFO:root:final train perplexity: 3.542604446411133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4091.075010042664
INFO:root:eval perplexity: 5.22947359085083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [14:02:56<41:19, 247.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.278384560033
INFO:root:current train perplexity3.552403450012207
INFO:root:current mean train loss 3223.729133157169
INFO:root:current train perplexity3.5481255054473877
INFO:root:current mean train loss 3219.4749348958335
INFO:root:current train perplexity3.5442159175872803
INFO:root:current mean train loss 3218.5185018796533
INFO:root:current train perplexity3.544520616531372
INFO:root:current mean train loss 3210.0398712522374
INFO:root:current train perplexity3.541548490524292
INFO:root:current mean train loss 3210.999561111362
INFO:root:current train perplexity3.542100191116333
INFO:root:current mean train loss 3208.689132074162
INFO:root:current train perplexity3.542161464691162
INFO:root:current mean train loss 3207.714972441651
INFO:root:current train perplexity3.5412237644195557
INFO:root:current mean train loss 3205.1962216928036
INFO:root:current train perplexity3.5401992797851562
INFO:root:current mean train loss 3205.756350578499
INFO:root:current train perplexity3.539675235748291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.27s/it]
INFO:root:final mean train loss: 3204.653815484816
INFO:root:final train perplexity: 3.540715217590332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.58s/it]
INFO:root:eval mean loss: 4090.927336131427
INFO:root:eval perplexity: 5.229161262512207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [14:07:06<37:16, 248.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.5040690104165
INFO:root:current train perplexity3.552306890487671
INFO:root:current mean train loss 3222.2325487512303
INFO:root:current train perplexity3.5367319583892822
INFO:root:current mean train loss 3214.839715764386
INFO:root:current train perplexity3.5400989055633545
INFO:root:current mean train loss 3213.243239469849
INFO:root:current train perplexity3.5391321182250977
INFO:root:current mean train loss 3210.1542625695256
INFO:root:current train perplexity3.539365530014038
INFO:root:current mean train loss 3213.380999281013
INFO:root:current train perplexity3.5406746864318848
INFO:root:current mean train loss 3209.868280876196
INFO:root:current train perplexity3.5406699180603027
INFO:root:current mean train loss 3207.458329191562
INFO:root:current train perplexity3.539233922958374
INFO:root:current mean train loss 3206.290884845923
INFO:root:current train perplexity3.5398638248443604
INFO:root:current mean train loss 3206.29804381995
INFO:root:current train perplexity3.539940357208252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.98s/it]
INFO:root:final mean train loss: 3204.802156879056
INFO:root:final train perplexity: 3.540921926498413
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.65s/it]
INFO:root:eval mean loss: 4090.310536486037
INFO:root:eval perplexity: 5.227856636047363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [14:11:13<33:05, 248.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.5865792410714
INFO:root:current train perplexity3.5369622707366943
INFO:root:current mean train loss 3203.541136791088
INFO:root:current train perplexity3.535534381866455
INFO:root:current mean train loss 3198.905043841423
INFO:root:current train perplexity3.5353312492370605
INFO:root:current mean train loss 3201.818615904851
INFO:root:current train perplexity3.5374088287353516
INFO:root:current mean train loss 3206.3661969064296
INFO:root:current train perplexity3.537876844406128
INFO:root:current mean train loss 3201.5680148400993
INFO:root:current train perplexity3.533989667892456
INFO:root:current mean train loss 3203.477123062254
INFO:root:current train perplexity3.5367510318756104
INFO:root:current mean train loss 3202.2230448820155
INFO:root:current train perplexity3.5370428562164307
INFO:root:current mean train loss 3202.532423044536
INFO:root:current train perplexity3.536313056945801
INFO:root:current mean train loss 3203.4387750146225
INFO:root:current train perplexity3.5367543697357178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it]
INFO:root:final mean train loss: 3202.9623278340987
INFO:root:final train perplexity: 3.5383527278900146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.61s/it]
INFO:root:eval mean loss: 4091.6845495345747
INFO:root:eval perplexity: 5.230762958526611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [14:15:21<28:55, 247.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.1045148982557
INFO:root:current train perplexity3.5608530044555664
INFO:root:current mean train loss 3205.8103420017483
INFO:root:current train perplexity3.551727056503296
INFO:root:current mean train loss 3204.448944468557
INFO:root:current train perplexity3.5403809547424316
INFO:root:current mean train loss 3200.721357962828
INFO:root:current train perplexity3.5413200855255127
INFO:root:current mean train loss 3205.65261324157
INFO:root:current train perplexity3.539600133895874
INFO:root:current mean train loss 3206.0069555349332
INFO:root:current train perplexity3.538203716278076
INFO:root:current mean train loss 3205.0026061916797
INFO:root:current train perplexity3.538377046585083
INFO:root:current mean train loss 3204.0507970222075
INFO:root:current train perplexity3.53670072555542
INFO:root:current mean train loss 3207.266247659957
INFO:root:current train perplexity3.5388643741607666
INFO:root:current mean train loss 3206.900034899423
INFO:root:current train perplexity3.538403272628784


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.44s/it]
INFO:root:final mean train loss: 3203.5518111567344
INFO:root:final train perplexity: 3.5391762256622314
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.17s/it]
INFO:root:eval mean loss: 4091.475847393063
INFO:root:eval perplexity: 5.230321884155273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [14:19:31<24:52, 248.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3184.549689797794
INFO:root:current train perplexity3.5195560455322266
INFO:root:current mean train loss 3195.187472513969
INFO:root:current train perplexity3.5287935733795166
INFO:root:current mean train loss 3199.558360308765
INFO:root:current train perplexity3.538132429122925
INFO:root:current mean train loss 3199.6368432547633
INFO:root:current train perplexity3.537416696548462
INFO:root:current mean train loss 3202.0427224440477
INFO:root:current train perplexity3.5376534461975098
INFO:root:current mean train loss 3204.0334056155
INFO:root:current train perplexity3.5399608612060547
INFO:root:current mean train loss 3206.9604300925257
INFO:root:current train perplexity3.5417556762695312
INFO:root:current mean train loss 3204.234497883031
INFO:root:current train perplexity3.539358377456665
INFO:root:current mean train loss 3205.0943507408565
INFO:root:current train perplexity3.539767265319824
INFO:root:current mean train loss 3206.1178447029442
INFO:root:current train perplexity3.5404765605926514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.04s/it]
INFO:root:final mean train loss: 3203.627633802352
INFO:root:final train perplexity: 3.5392816066741943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.46s/it]
INFO:root:eval mean loss: 4091.894034311281
INFO:root:eval perplexity: 5.231205940246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [14:23:39<20:42, 248.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.528187897246
INFO:root:current train perplexity3.557685613632202
INFO:root:current mean train loss 3214.4656191651925
INFO:root:current train perplexity3.545064926147461
INFO:root:current mean train loss 3215.689336239141
INFO:root:current train perplexity3.542501926422119
INFO:root:current mean train loss 3212.8918314219186
INFO:root:current train perplexity3.540808916091919
INFO:root:current mean train loss 3209.3257096566927
INFO:root:current train perplexity3.539461851119995
INFO:root:current mean train loss 3204.077113934621
INFO:root:current train perplexity3.5377089977264404
INFO:root:current mean train loss 3202.9520869392545
INFO:root:current train perplexity3.537996768951416
INFO:root:current mean train loss 3203.8464181771865
INFO:root:current train perplexity3.5386533737182617
INFO:root:current mean train loss 3205.856303773465
INFO:root:current train perplexity3.538630723953247
INFO:root:current mean train loss 3206.3828893826576
INFO:root:current train perplexity3.5397183895111084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.69s/it]
INFO:root:final mean train loss: 3204.068863222676
INFO:root:final train perplexity: 3.5398976802825928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4091.4190249612147
INFO:root:eval perplexity: 5.230201721191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [14:27:47<16:33, 248.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.7924003031717
INFO:root:current train perplexity3.537536859512329
INFO:root:current mean train loss 3206.736031355258
INFO:root:current train perplexity3.5428476333618164
INFO:root:current mean train loss 3211.2707958435744
INFO:root:current train perplexity3.542907238006592
INFO:root:current mean train loss 3210.2417863643136
INFO:root:current train perplexity3.540350914001465
INFO:root:current mean train loss 3211.4046774625267
INFO:root:current train perplexity3.541903018951416
INFO:root:current mean train loss 3210.8458232576886
INFO:root:current train perplexity3.5424063205718994
INFO:root:current mean train loss 3207.755365969359
INFO:root:current train perplexity3.5404133796691895
INFO:root:current mean train loss 3207.6031371592853
INFO:root:current train perplexity3.541062116622925
INFO:root:current mean train loss 3206.176140843516
INFO:root:current train perplexity3.5398364067077637
INFO:root:current mean train loss 3205.150737774286
INFO:root:current train perplexity3.538764715194702


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.82s/it]
INFO:root:final mean train loss: 3202.6453362126504
INFO:root:final train perplexity: 3.5379106998443604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it]
INFO:root:eval mean loss: 4091.8014426806294
INFO:root:eval perplexity: 5.231010437011719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [14:31:54<12:23, 247.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.2410188802082
INFO:root:current train perplexity3.529533624649048
INFO:root:current mean train loss 3202.085853794643
INFO:root:current train perplexity3.530546188354492
INFO:root:current mean train loss 3202.447064098011
INFO:root:current train perplexity3.535844326019287
INFO:root:current mean train loss 3199.6704407552083
INFO:root:current train perplexity3.5348243713378906
INFO:root:current mean train loss 3202.1287484580594
INFO:root:current train perplexity3.532496929168701
INFO:root:current mean train loss 3203.5269862432065
INFO:root:current train perplexity3.5324249267578125
INFO:root:current mean train loss 3205.212410300926
INFO:root:current train perplexity3.535055637359619
INFO:root:current mean train loss 3203.0986312373993
INFO:root:current train perplexity3.5343246459960938
INFO:root:current mean train loss 3204.9802349330357
INFO:root:current train perplexity3.535083055496216
INFO:root:current mean train loss 3203.689918369391
INFO:root:current train perplexity3.5361549854278564


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.29s/it]
INFO:root:final mean train loss: 3201.487950171194
INFO:root:final train perplexity: 3.5362956523895264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4091.9548322528813
INFO:root:eval perplexity: 5.231334686279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [14:36:04<08:17, 248.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.4711796404367
INFO:root:current train perplexity3.545121431350708
INFO:root:current mean train loss 3211.489696731984
INFO:root:current train perplexity3.5429582595825195
INFO:root:current mean train loss 3213.0531648561728
INFO:root:current train perplexity3.548111915588379
INFO:root:current mean train loss 3209.7318985343913
INFO:root:current train perplexity3.545466423034668
INFO:root:current mean train loss 3202.738703820523
INFO:root:current train perplexity3.543349027633667
INFO:root:current mean train loss 3206.2009968307784
INFO:root:current train perplexity3.5459210872650146
INFO:root:current mean train loss 3206.2533125200175
INFO:root:current train perplexity3.541261672973633
INFO:root:current mean train loss 3205.970862143798
INFO:root:current train perplexity3.5388715267181396
INFO:root:current mean train loss 3205.644238447144
INFO:root:current train perplexity3.536548137664795
INFO:root:current mean train loss 3205.1252816434067
INFO:root:current train perplexity3.537278175354004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.60s/it]
INFO:root:final mean train loss: 3201.9840081122616
INFO:root:final train perplexity: 3.536987543106079
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4091.985973168772
INFO:root:eval perplexity: 5.231401443481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [14:40:12<04:08, 248.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3196.869910606971
INFO:root:current train perplexity3.539092540740967
INFO:root:current mean train loss 3195.403565731348
INFO:root:current train perplexity3.524730682373047
INFO:root:current mean train loss 3193.4195317533827
INFO:root:current train perplexity3.5277833938598633
INFO:root:current mean train loss 3196.755321141704
INFO:root:current train perplexity3.527994394302368
INFO:root:current mean train loss 3199.521012005155
INFO:root:current train perplexity3.5308921337127686
INFO:root:current mean train loss 3200.4581784217694
INFO:root:current train perplexity3.5350406169891357
INFO:root:current mean train loss 3200.1191310854965
INFO:root:current train perplexity3.534336805343628
INFO:root:current mean train loss 3201.400900820263
INFO:root:current train perplexity3.533606767654419
INFO:root:current mean train loss 3202.8074097638714
INFO:root:current train perplexity3.5349600315093994
INFO:root:current mean train loss 3202.7833073343686
INFO:root:current train perplexity3.5345609188079834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.62s/it]
INFO:root:final mean train loss: 3200.2353545773412
INFO:root:final train perplexity: 3.534547805786133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4091.946214608267
INFO:root:eval perplexity: 5.231316566467285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_136/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:44:22<00:00, 248.84s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:44:22<00:00, 265.31s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
INFO:root:eval mean loss: 4091.946214608267
INFO:root:eval perplexity: 5.231316566467285
INFO:root:evalaution complete
INFO:root:save model final: small_val_136/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14a0b7b73f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14a0b7b6b8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14a0b7a90e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14a0b7b74a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14a0b7a8e948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14a0b7b74a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14a0b7a49b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14a0b74ae46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14a1b3ccaa27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14a1b3ccabe0]
python(+0x24a989) [0x563a244f3989]
python(+0x24a9bd) [0x563a244f39bd]
python(+0x24aa14) [0x563a244f3a14]
python(+0x108f75) [0x563a243b1f75]
python(Py_RunMain+0x313) [0x563a244f6983]
python(Py_BytesMain+0x39) [0x563a244f6bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14a1b3ca80b3]
python(+0x1d6e13) [0x563a2447fe13]
/opt/slurm/data/slurmd/job26146349/slurm_script: line 138: 742661 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_136_final  --output small_val_136 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
