INFO:root:Output: small_val_120
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24442.085029987375
INFO:root:current train perplexity15422.419921875
INFO:root:current mean train loss 20525.396273358983
INFO:root:current train perplexity3259.3994140625
INFO:root:current mean train loss 17735.049778558736
INFO:root:current train perplexity1088.063232421875
INFO:root:current mean train loss 15844.519455376723
INFO:root:current train perplexity512.0322265625
INFO:root:current mean train loss 14473.840938713363
INFO:root:current train perplexity298.2952880859375
INFO:root:current mean train loss 13432.610358083786
INFO:root:current train perplexity198.5078582763672
INFO:root:current mean train loss 12623.807236481804
INFO:root:current train perplexity144.3010711669922
INFO:root:current mean train loss 11973.819376882235
INFO:root:current train perplexity111.95128631591797
INFO:root:current mean train loss 11441.115539075536
INFO:root:current train perplexity90.79078674316406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it]
INFO:root:eval mean loss: 6411.98933053524
INFO:root:eval perplexity: 13.367417335510254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/1

  0%|          | 1/200 [04:10<13:49:48, 250.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6826.085309709822
INFO:root:current train perplexity14.524643898010254
INFO:root:current mean train loss 6731.065694363318
INFO:root:current train perplexity14.398314476013184
INFO:root:current mean train loss 6704.553736884813
INFO:root:current train perplexity14.171834945678711
INFO:root:current mean train loss 6631.696805972618
INFO:root:current train perplexity13.745356559753418
INFO:root:current mean train loss 6577.3163546625465
INFO:root:current train perplexity13.440853118896484
INFO:root:current mean train loss 6527.829693856324
INFO:root:current train perplexity13.173409461975098
INFO:root:current mean train loss 6485.146181914127
INFO:root:current train perplexity12.902854919433594
INFO:root:current mean train loss 6437.748508221358
INFO:root:current train perplexity12.662556648254395
INFO:root:current mean train loss 6393.8664947093785
INFO:root:current train perplexity12.438064575195312
INFO:root:current mean train loss 6349.649110972816
INFO:root:current train perplexity12.235258102416992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.50s/it]
INFO:root:eval mean loss: 5546.510184646499
INFO:root:eval perplexity: 9.420103073120117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/2

  1%|          | 2/200 [08:32<14:09:14, 257.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6002.732682291667
INFO:root:current train perplexity10.703389167785645
INFO:root:current mean train loss 5889.525883152174
INFO:root:current train perplexity10.272159576416016
INFO:root:current mean train loss 5865.252402797965
INFO:root:current train perplexity10.122989654541016
INFO:root:current mean train loss 5845.6310546875
INFO:root:current train perplexity10.01211929321289
INFO:root:current mean train loss 5820.75688064759
INFO:root:current train perplexity9.920114517211914
INFO:root:current mean train loss 5794.931746814321
INFO:root:current train perplexity9.831890106201172
INFO:root:current mean train loss 5770.1845703125
INFO:root:current train perplexity9.751740455627441
INFO:root:current mean train loss 5751.325598229895
INFO:root:current train perplexity9.673531532287598
INFO:root:current mean train loss 5738.351872244057
INFO:root:current train perplexity9.60323715209961
INFO:root:current mean train loss 5719.511701139857
INFO:root:current train perplexity9.51939582824707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it]
INFO:root:eval mean loss: 5183.92858280696
INFO:root:eval perplexity: 8.135430335998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/3

  2%|â–         | 3/200 [12:50<14:06:15, 257.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5566.775178328804
INFO:root:current train perplexity8.82796573638916
INFO:root:current mean train loss 5485.299749110773
INFO:root:current train perplexity8.717082977294922
INFO:root:current mean train loss 5486.68035970782
INFO:root:current train perplexity8.664990425109863
INFO:root:current mean train loss 5459.622513242551
INFO:root:current train perplexity8.583733558654785
INFO:root:current mean train loss 5448.369968279034
INFO:root:current train perplexity8.563215255737305
INFO:root:current mean train loss 5432.024815517448
INFO:root:current train perplexity8.50941276550293
INFO:root:current mean train loss 5422.405157441312
INFO:root:current train perplexity8.477413177490234
INFO:root:current mean train loss 5412.5000398459115
INFO:root:current train perplexity8.442216873168945
INFO:root:current mean train loss 5402.550004034401
INFO:root:current train perplexity8.408724784851074
INFO:root:current mean train loss 5391.914324891658
INFO:root:current train perplexity8.37387752532959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it]
INFO:root:eval mean loss: 4965.914512688387
INFO:root:eval perplexity: 7.4489288330078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/4

  2%|â–         | 4/200 [17:11<14:05:49, 258.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5325.749165196573
INFO:root:current train perplexity7.985249042510986
INFO:root:current mean train loss 5247.73444209208
INFO:root:current train perplexity7.906882286071777
INFO:root:current mean train loss 5249.809650635822
INFO:root:current train perplexity7.928025722503662
INFO:root:current mean train loss 5239.227924081854
INFO:root:current train perplexity7.881941318511963
INFO:root:current mean train loss 5231.837567747607
INFO:root:current train perplexity7.847127437591553
INFO:root:current mean train loss 5221.61980086217
INFO:root:current train perplexity7.8179826736450195
INFO:root:current mean train loss 5213.123710039868
INFO:root:current train perplexity7.790831089019775
INFO:root:current mean train loss 5204.984625486278
INFO:root:current train perplexity7.774148464202881
INFO:root:current mean train loss 5191.63505177779
INFO:root:current train perplexity7.74924373626709
INFO:root:current mean train loss 5183.855672244226
INFO:root:current train perplexity7.720447540283203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it]
INFO:root:eval mean loss: 4827.06112173094
INFO:root:eval perplexity: 7.042208671569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/5

  2%|â–Ž         | 5/200 [21:28<13:58:48, 258.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5080.691506410257
INFO:root:current train perplexity7.339935302734375
INFO:root:current mean train loss 5076.389767873202
INFO:root:current train perplexity7.411960124969482
INFO:root:current mean train loss 5083.440008825837
INFO:root:current train perplexity7.420475482940674
INFO:root:current mean train loss 5067.0168392215155
INFO:root:current train perplexity7.360165596008301
INFO:root:current mean train loss 5065.299713482346
INFO:root:current train perplexity7.351739406585693
INFO:root:current mean train loss 5051.994424172368
INFO:root:current train perplexity7.324974060058594
INFO:root:current mean train loss 5044.165414252005
INFO:root:current train perplexity7.304740905761719
INFO:root:current mean train loss 5043.871786197565
INFO:root:current train perplexity7.299149513244629
INFO:root:current mean train loss 5039.957045217521
INFO:root:current train perplexity7.282654762268066
INFO:root:current mean train loss 5031.994632026258
INFO:root:current train perplexity7.267268180847168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it]
INFO:root:eval mean loss: 4712.072469941268
INFO:root:eval perplexity: 6.722256660461426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/6

  3%|â–Ž         | 6/200 [25:17<13:23:13, 248.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4892.076421210107
INFO:root:current train perplexity6.933825969696045
INFO:root:current mean train loss 4945.002770248724
INFO:root:current train perplexity7.008090496063232
INFO:root:current mean train loss 4928.34066018788
INFO:root:current train perplexity6.995245456695557
INFO:root:current mean train loss 4929.653268247928
INFO:root:current train perplexity6.99050235748291
INFO:root:current mean train loss 4926.575736026636
INFO:root:current train perplexity6.979327201843262
INFO:root:current mean train loss 4918.22032106947
INFO:root:current train perplexity6.9590067863464355
INFO:root:current mean train loss 4917.956173173058
INFO:root:current train perplexity6.956246376037598
INFO:root:current mean train loss 4914.993462129769
INFO:root:current train perplexity6.944486141204834
INFO:root:current mean train loss 4911.385153598178
INFO:root:current train perplexity6.935720443725586
INFO:root:current mean train loss 4908.919326347182
INFO:root:current train perplexity6.924144268035889


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.53s/it]
INFO:root:eval mean loss: 4623.564863489029
INFO:root:eval perplexity: 6.4859209060668945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/7

  4%|â–Ž         | 7/200 [29:01<12:52:57, 240.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4798.019069602273
INFO:root:current train perplexity6.727409362792969
INFO:root:current mean train loss 4847.818709047379
INFO:root:current train perplexity6.782708644866943
INFO:root:current mean train loss 4840.353971354167
INFO:root:current train perplexity6.737542152404785
INFO:root:current mean train loss 4839.382218309859
INFO:root:current train perplexity6.729672908782959
INFO:root:current mean train loss 4832.703208705357
INFO:root:current train perplexity6.710378646850586
INFO:root:current mean train loss 4827.455594559403
INFO:root:current train perplexity6.69457483291626
INFO:root:current mean train loss 4826.231127743321
INFO:root:current train perplexity6.693023681640625
INFO:root:current mean train loss 4827.6889512624175
INFO:root:current train perplexity6.687459945678711
INFO:root:current mean train loss 4818.64774020011
INFO:root:current train perplexity6.670759201049805
INFO:root:current mean train loss 4810.9205078125
INFO:root:current train perplexity6.661426067352295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it]
INFO:root:eval mean loss: 4551.318736840647
INFO:root:eval perplexity: 6.299180507659912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/8

  4%|â–         | 8/200 [32:46<12:33:43, 235.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4748.809554811508
INFO:root:current train perplexity6.45387601852417
INFO:root:current mean train loss 4741.455391164206
INFO:root:current train perplexity6.485469341278076
INFO:root:current mean train loss 4734.482586182569
INFO:root:current train perplexity6.481683731079102
INFO:root:current mean train loss 4744.644121658704
INFO:root:current train perplexity6.4802985191345215
INFO:root:current mean train loss 4748.87069985573
INFO:root:current train perplexity6.489625930786133
INFO:root:current mean train loss 4740.71055199198
INFO:root:current train perplexity6.476090908050537
INFO:root:current mean train loss 4737.278030510582
INFO:root:current train perplexity6.471749305725098
INFO:root:current mean train loss 4735.88111567466
INFO:root:current train perplexity6.465766906738281
INFO:root:current mean train loss 4730.810413064437
INFO:root:current train perplexity6.456836223602295
INFO:root:current mean train loss 4727.466970029774
INFO:root:current train perplexity6.448009014129639


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it]
INFO:root:eval mean loss: 4495.239482906693
INFO:root:eval perplexity: 6.157944679260254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/9

  4%|â–         | 9/200 [36:30<12:17:39, 231.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4646.317265900088
INFO:root:current train perplexity6.224532604217529
INFO:root:current mean train loss 4659.02622727065
INFO:root:current train perplexity6.279025554656982
INFO:root:current mean train loss 4680.558026190613
INFO:root:current train perplexity6.313201427459717
INFO:root:current mean train loss 4675.730731974393
INFO:root:current train perplexity6.303619861602783
INFO:root:current mean train loss 4669.086852897757
INFO:root:current train perplexity6.299473285675049
INFO:root:current mean train loss 4669.786598860278
INFO:root:current train perplexity6.295694828033447
INFO:root:current mean train loss 4671.031257640765
INFO:root:current train perplexity6.3002424240112305
INFO:root:current mean train loss 4661.1044361396525
INFO:root:current train perplexity6.285897731781006
INFO:root:current mean train loss 4663.461344214175
INFO:root:current train perplexity6.283011436462402
INFO:root:current mean train loss 4659.361565728389
INFO:root:current train perplexity6.276354789733887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4444.812292220745
INFO:root:eval perplexity: 6.033646106719971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/10

  5%|â–Œ         | 10/200 [40:52<12:43:24, 241.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4642.256437277492
INFO:root:current train perplexity6.1549906730651855
INFO:root:current mean train loss 4604.875375076379
INFO:root:current train perplexity6.122622489929199
INFO:root:current mean train loss 4614.405646211358
INFO:root:current train perplexity6.135250568389893
INFO:root:current mean train loss 4609.29343255277
INFO:root:current train perplexity6.139566421508789
INFO:root:current mean train loss 4613.042128783924
INFO:root:current train perplexity6.138290882110596
INFO:root:current mean train loss 4605.972103033247
INFO:root:current train perplexity6.136529922485352
INFO:root:current mean train loss 4605.387190131973
INFO:root:current train perplexity6.133633136749268
INFO:root:current mean train loss 4603.601185476673
INFO:root:current train perplexity6.130730152130127
INFO:root:current mean train loss 4598.057248615703
INFO:root:current train perplexity6.1265459060668945
INFO:root:current mean train loss 4597.679252336169
INFO:root:current train perplexity6.127464294433594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]
INFO:root:eval mean loss: 4399.367959746232
INFO:root:eval perplexity: 5.923782825469971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/11

  6%|â–Œ         | 11/200 [45:16<13:01:49, 248.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4544.296594378592
INFO:root:current train perplexity5.98858118057251
INFO:root:current mean train loss 4566.820255055147
INFO:root:current train perplexity6.024781227111816
INFO:root:current mean train loss 4553.7825736334935
INFO:root:current train perplexity5.998196601867676
INFO:root:current mean train loss 4553.590518764131
INFO:root:current train perplexity6.010333061218262
INFO:root:current mean train loss 4549.892469339547
INFO:root:current train perplexity6.006686687469482
INFO:root:current mean train loss 4546.296611727401
INFO:root:current train perplexity6.0001115798950195
INFO:root:current mean train loss 4546.086040557906
INFO:root:current train perplexity6.002254486083984
INFO:root:current mean train loss 4542.958834230067
INFO:root:current train perplexity5.99538516998291
INFO:root:current mean train loss 4544.266846804097
INFO:root:current train perplexity5.997699737548828
INFO:root:current mean train loss 4543.9231300856445
INFO:root:current train perplexity5.997641086578369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.92s/it]
INFO:root:eval mean loss: 4362.355042802526
INFO:root:eval perplexity: 5.835782051086426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/12

  6%|â–Œ         | 12/200 [49:40<13:13:09, 253.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4507.666424239309
INFO:root:current train perplexity5.906121253967285
INFO:root:current mean train loss 4490.899356470352
INFO:root:current train perplexity5.896683692932129
INFO:root:current mean train loss 4494.742252880032
INFO:root:current train perplexity5.904791355133057
INFO:root:current mean train loss 4488.576532832279
INFO:root:current train perplexity5.890634536743164
INFO:root:current mean train loss 4493.711075599747
INFO:root:current train perplexity5.889885902404785
INFO:root:current mean train loss 4488.46198997177
INFO:root:current train perplexity5.886568546295166
INFO:root:current mean train loss 4486.084776866007
INFO:root:current train perplexity5.882868766784668
INFO:root:current mean train loss 4490.252963467964
INFO:root:current train perplexity5.877702713012695
INFO:root:current mean train loss 4491.650445999912
INFO:root:current train perplexity5.879467010498047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.62s/it]
INFO:root:eval mean loss: 4329.898645279255
INFO:root:eval perplexity: 5.759690761566162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/13

  6%|â–‹         | 13/200 [53:25<12:41:55, 244.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4724.126302083333
INFO:root:current train perplexity6.079598426818848
INFO:root:current mean train loss 4460.992948365443
INFO:root:current train perplexity5.767840385437012
INFO:root:current mean train loss 4460.69499860491
INFO:root:current train perplexity5.771600246429443
INFO:root:current mean train loss 4460.042457102156
INFO:root:current train perplexity5.780212879180908
INFO:root:current mean train loss 4462.928745468556
INFO:root:current train perplexity5.787398815155029
INFO:root:current mean train loss 4459.821910334866
INFO:root:current train perplexity5.7912983894348145
INFO:root:current mean train loss 4455.693870329343
INFO:root:current train perplexity5.791653156280518
INFO:root:current mean train loss 4451.838467810944
INFO:root:current train perplexity5.784160137176514
INFO:root:current mean train loss 4450.758324191995
INFO:root:current train perplexity5.782421112060547
INFO:root:current mean train loss 4450.8476905865
INFO:root:current train perplexity5.7814106941223145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it]
INFO:root:eval mean loss: 4302.206613959996
INFO:root:eval perplexity: 5.695554256439209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/14

  7%|â–‹         | 14/200 [57:44<12:51:47, 248.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4389.784845525568
INFO:root:current train perplexity5.592824459075928
INFO:root:current mean train loss 4399.386120495496
INFO:root:current train perplexity5.6933722496032715
INFO:root:current mean train loss 4390.587320192165
INFO:root:current train perplexity5.689568042755127
INFO:root:current mean train loss 4395.0059331667
INFO:root:current train perplexity5.687318325042725
INFO:root:current mean train loss 4393.170784980422
INFO:root:current train perplexity5.683652877807617
INFO:root:current mean train loss 4396.98784074578
INFO:root:current train perplexity5.688830375671387
INFO:root:current mean train loss 4404.646613837459
INFO:root:current train perplexity5.694390296936035
INFO:root:current mean train loss 4406.074426836102
INFO:root:current train perplexity5.69167947769165
INFO:root:current mean train loss 4408.026028822442
INFO:root:current train perplexity5.6949381828308105
INFO:root:current mean train loss 4410.3246065342855
INFO:root:current train perplexity5.691308975219727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it]
INFO:root:eval mean loss: 4277.9272599457
INFO:root:eval perplexity: 5.639909744262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/15

  8%|â–Š         | 15/200 [1:02:09<13:02:41, 253.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4432.93802682977
INFO:root:current train perplexity5.689499855041504
INFO:root:current mean train loss 4369.197300502232
INFO:root:current train perplexity5.585878372192383
INFO:root:current mean train loss 4368.578096015268
INFO:root:current train perplexity5.603798866271973
INFO:root:current mean train loss 4365.662286166487
INFO:root:current train perplexity5.601418495178223
INFO:root:current mean train loss 4370.884867010367
INFO:root:current train perplexity5.607687950134277
INFO:root:current mean train loss 4368.296042381684
INFO:root:current train perplexity5.602766036987305
INFO:root:current mean train loss 4366.907954251439
INFO:root:current train perplexity5.601840972900391
INFO:root:current mean train loss 4369.321590248501
INFO:root:current train perplexity5.603769779205322
INFO:root:current mean train loss 4369.350895063053
INFO:root:current train perplexity5.605231761932373
INFO:root:current mean train loss 4369.310495071494
INFO:root:current train perplexity5.6024675369262695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4254.220999210439
INFO:root:eval perplexity: 5.586104393005371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/16

  8%|â–Š         | 16/200 [1:06:37<13:10:48, 257.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4367.937292028357
INFO:root:current train perplexity5.609508991241455
INFO:root:current mean train loss 4314.960877906619
INFO:root:current train perplexity5.534243106842041
INFO:root:current mean train loss 4328.308673337693
INFO:root:current train perplexity5.532118320465088
INFO:root:current mean train loss 4325.663619015195
INFO:root:current train perplexity5.522857189178467
INFO:root:current mean train loss 4332.724515034945
INFO:root:current train perplexity5.527224540710449
INFO:root:current mean train loss 4333.073824048269
INFO:root:current train perplexity5.522919654846191
INFO:root:current mean train loss 4333.577578311902
INFO:root:current train perplexity5.521336078643799
INFO:root:current mean train loss 4333.405416496518
INFO:root:current train perplexity5.528253078460693
INFO:root:current mean train loss 4333.622906353915
INFO:root:current train perplexity5.525140762329102
INFO:root:current mean train loss 4336.023460412875
INFO:root:current train perplexity5.530688285827637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it]
INFO:root:eval mean loss: 4231.588972808621
INFO:root:eval perplexity: 5.535213947296143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/17

  8%|â–Š         | 17/200 [1:10:37<12:50:20, 252.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4268.146540178572
INFO:root:current train perplexity5.434714317321777
INFO:root:current mean train loss 4303.546032262731
INFO:root:current train perplexity5.456477165222168
INFO:root:current mean train loss 4297.442630069814
INFO:root:current train perplexity5.458024024963379
INFO:root:current mean train loss 4299.958902023088
INFO:root:current train perplexity5.455945014953613
INFO:root:current mean train loss 4300.367470927622
INFO:root:current train perplexity5.460916996002197
INFO:root:current mean train loss 4312.012947210865
INFO:root:current train perplexity5.464992046356201
INFO:root:current mean train loss 4307.499129552165
INFO:root:current train perplexity5.45864200592041
INFO:root:current mean train loss 4305.9363703098425
INFO:root:current train perplexity5.454737186431885
INFO:root:current mean train loss 4307.367350942646
INFO:root:current train perplexity5.463217735290527
INFO:root:current mean train loss 4306.3473658923795
INFO:root:current train perplexity5.465549945831299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.99s/it]
INFO:root:eval mean loss: 4213.4282088043
INFO:root:eval perplexity: 5.494715213775635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/18

  9%|â–‰         | 18/200 [1:15:07<13:02:04, 257.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4269.2488247183865
INFO:root:current train perplexity5.406853675842285
INFO:root:current mean train loss 4285.864896334135
INFO:root:current train perplexity5.414059638977051
INFO:root:current mean train loss 4277.407723885995
INFO:root:current train perplexity5.400722503662109
INFO:root:current mean train loss 4284.43718468135
INFO:root:current train perplexity5.415947437286377
INFO:root:current mean train loss 4286.041623496579
INFO:root:current train perplexity5.41371488571167
INFO:root:current mean train loss 4286.339156289566
INFO:root:current train perplexity5.411343574523926
INFO:root:current mean train loss 4282.865542303533
INFO:root:current train perplexity5.406589031219482
INFO:root:current mean train loss 4279.688902740684
INFO:root:current train perplexity5.402433395385742
INFO:root:current mean train loss 4276.735613079682
INFO:root:current train perplexity5.4012274742126465
INFO:root:current mean train loss 4275.950808123592
INFO:root:current train perplexity5.3987650871276855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4196.505926903258
INFO:root:eval perplexity: 5.457243919372559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/19

 10%|â–‰         | 19/200 [1:20:08<13:36:52, 270.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4216.656752642463
INFO:root:current train perplexity5.258359432220459
INFO:root:current mean train loss 4214.3283675238
INFO:root:current train perplexity5.268770694732666
INFO:root:current mean train loss 4245.850323316111
INFO:root:current train perplexity5.301719665527344
INFO:root:current mean train loss 4237.597831530448
INFO:root:current train perplexity5.312255382537842
INFO:root:current mean train loss 4242.974814539738
INFO:root:current train perplexity5.315361976623535
INFO:root:current mean train loss 4241.09662385861
INFO:root:current train perplexity5.320099830627441
INFO:root:current mean train loss 4248.581625849054
INFO:root:current train perplexity5.332801342010498
INFO:root:current mean train loss 4249.639855843251
INFO:root:current train perplexity5.333740711212158
INFO:root:current mean train loss 4249.8785178053395
INFO:root:current train perplexity5.337515830993652
INFO:root:current mean train loss 4252.853761819384
INFO:root:current train perplexity5.3420729637146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it]
INFO:root:eval mean loss: 4182.617745041001
INFO:root:eval perplexity: 5.426681995391846
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/20

 10%|â–ˆ         | 20/200 [1:23:51<12:49:26, 256.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.899856826007
INFO:root:current train perplexity5.284975051879883
INFO:root:current mean train loss 4240.247612335397
INFO:root:current train perplexity5.278696060180664
INFO:root:current mean train loss 4233.624935901303
INFO:root:current train perplexity5.281947135925293
INFO:root:current mean train loss 4233.352581226062
INFO:root:current train perplexity5.2948689460754395
INFO:root:current mean train loss 4228.13310876651
INFO:root:current train perplexity5.287534713745117
INFO:root:current mean train loss 4224.4543705976075
INFO:root:current train perplexity5.2834296226501465
INFO:root:current mean train loss 4226.239550484873
INFO:root:current train perplexity5.2841105461120605
INFO:root:current mean train loss 4230.122770889946
INFO:root:current train perplexity5.293811321258545
INFO:root:current mean train loss 4227.819585762423
INFO:root:current train perplexity5.292038440704346
INFO:root:current mean train loss 4225.188553954315
INFO:root:current train perplexity5.288329601287842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.55s/it]
INFO:root:eval mean loss: 4171.26862741024
INFO:root:eval perplexity: 5.401834487915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/21

 10%|â–ˆ         | 21/200 [1:28:08<12:45:23, 256.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4174.294149370336
INFO:root:current train perplexity5.226506233215332
INFO:root:current mean train loss 4188.90233351656
INFO:root:current train perplexity5.248802661895752
INFO:root:current mean train loss 4193.428415591351
INFO:root:current train perplexity5.23684549331665
INFO:root:current mean train loss 4190.551166420087
INFO:root:current train perplexity5.226874351501465
INFO:root:current mean train loss 4195.6578654058485
INFO:root:current train perplexity5.233260631561279
INFO:root:current mean train loss 4195.796529672343
INFO:root:current train perplexity5.229415416717529
INFO:root:current mean train loss 4197.453296667096
INFO:root:current train perplexity5.230227947235107
INFO:root:current mean train loss 4198.567337613063
INFO:root:current train perplexity5.230706214904785
INFO:root:current mean train loss 4200.09311726184
INFO:root:current train perplexity5.231727600097656
INFO:root:current mean train loss 4198.8139852939985
INFO:root:current train perplexity5.234493732452393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.87s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it]
INFO:root:eval mean loss: 4151.759836616246
INFO:root:eval perplexity: 5.35938835144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/22

 11%|â–ˆ         | 22/200 [1:31:53<12:12:57, 247.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4189.320530598959
INFO:root:current train perplexity5.189927101135254
INFO:root:current mean train loss 4179.478854631697
INFO:root:current train perplexity5.196287631988525
INFO:root:current mean train loss 4169.51958540483
INFO:root:current train perplexity5.171579360961914
INFO:root:current mean train loss 4168.750380859375
INFO:root:current train perplexity5.176709175109863
INFO:root:current mean train loss 4169.045775596217
INFO:root:current train perplexity5.178524971008301
INFO:root:current mean train loss 4174.666637652853
INFO:root:current train perplexity5.18512487411499
INFO:root:current mean train loss 4172.43337962963
INFO:root:current train perplexity5.186916351318359
INFO:root:current mean train loss 4177.053766381048
INFO:root:current train perplexity5.190174102783203
INFO:root:current mean train loss 4176.937446986607
INFO:root:current train perplexity5.189315319061279
INFO:root:current mean train loss 4178.547927433894
INFO:root:current train perplexity5.189994812011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it]
INFO:root:eval mean loss: 4140.391355690381
INFO:root:eval perplexity: 5.334807872772217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/23

 12%|â–ˆâ–        | 23/200 [1:35:34<11:46:18, 239.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4158.249905873494
INFO:root:current train perplexity5.106592655181885
INFO:root:current mean train loss 4154.667363067793
INFO:root:current train perplexity5.126787185668945
INFO:root:current mean train loss 4154.670712096952
INFO:root:current train perplexity5.128821849822998
INFO:root:current mean train loss 4159.479161354642
INFO:root:current train perplexity5.13655424118042
INFO:root:current mean train loss 4161.374224107952
INFO:root:current train perplexity5.142185211181641
INFO:root:current mean train loss 4155.304114209235
INFO:root:current train perplexity5.136847496032715
INFO:root:current mean train loss 4149.85059880582
INFO:root:current train perplexity5.130213737487793
INFO:root:current mean train loss 4154.884360282967
INFO:root:current train perplexity5.140753269195557
INFO:root:current mean train loss 4154.647177811792
INFO:root:current train perplexity5.144757270812988
INFO:root:current mean train loss 4154.865050089808
INFO:root:current train perplexity5.144816875457764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it]
INFO:root:eval mean loss: 4129.935366799646
INFO:root:eval perplexity: 5.312298774719238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/24

 12%|â–ˆâ–        | 24/200 [1:39:17<11:27:17, 234.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4103.066543076065
INFO:root:current train perplexity5.067159652709961
INFO:root:current mean train loss 4115.485158550801
INFO:root:current train perplexity5.084702491760254
INFO:root:current mean train loss 4113.061386685191
INFO:root:current train perplexity5.0741472244262695
INFO:root:current mean train loss 4123.244057579724
INFO:root:current train perplexity5.092469215393066
INFO:root:current mean train loss 4123.608344736507
INFO:root:current train perplexity5.095751762390137
INFO:root:current mean train loss 4129.906650291482
INFO:root:current train perplexity5.1003828048706055
INFO:root:current mean train loss 4131.909141882801
INFO:root:current train perplexity5.102599143981934
INFO:root:current mean train loss 4135.734144748538
INFO:root:current train perplexity5.103199005126953
INFO:root:current mean train loss 4134.795343572443
INFO:root:current train perplexity5.106337070465088
INFO:root:current mean train loss 4133.953800266855
INFO:root:current train perplexity5.1021952629089355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it]
INFO:root:eval mean loss: 4118.91460099457
INFO:root:eval perplexity: 5.288676738739014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/25

 12%|â–ˆâ–Ž        | 25/200 [1:42:59<11:13:18, 230.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4087.295856514362
INFO:root:current train perplexity5.076419353485107
INFO:root:current mean train loss 4096.394808515232
INFO:root:current train perplexity5.045135498046875
INFO:root:current mean train loss 4109.166948911737
INFO:root:current train perplexity5.054216384887695
INFO:root:current mean train loss 4114.957366560933
INFO:root:current train perplexity5.0629963874816895
INFO:root:current mean train loss 4113.960305376378
INFO:root:current train perplexity5.059004783630371
INFO:root:current mean train loss 4111.842790148294
INFO:root:current train perplexity5.052690505981445
INFO:root:current mean train loss 4112.179053921897
INFO:root:current train perplexity5.054129123687744
INFO:root:current mean train loss 4115.578117361057
INFO:root:current train perplexity5.057631492614746
INFO:root:current mean train loss 4115.311095444591
INFO:root:current train perplexity5.0617146492004395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it]
INFO:root:eval mean loss: 4113.35230184785
INFO:root:eval perplexity: 5.276795387268066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/26

 13%|â–ˆâ–Ž        | 26/200 [1:46:42<11:02:10, 228.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4144.744977678572
INFO:root:current train perplexity5.110201358795166
INFO:root:current mean train loss 4080.0562709915303
INFO:root:current train perplexity5.020556449890137
INFO:root:current mean train loss 4091.224761520607
INFO:root:current train perplexity5.0322442054748535
INFO:root:current mean train loss 4093.491455078125
INFO:root:current train perplexity5.029062747955322
INFO:root:current mean train loss 4101.3270668573405
INFO:root:current train perplexity5.041829586029053
INFO:root:current mean train loss 4092.8236919455744
INFO:root:current train perplexity5.030587196350098
INFO:root:current mean train loss 4095.754954003424
INFO:root:current train perplexity5.024568557739258
INFO:root:current mean train loss 4096.6054217865985
INFO:root:current train perplexity5.027383804321289
INFO:root:current mean train loss 4094.446056417964
INFO:root:current train perplexity5.024264812469482
INFO:root:current mean train loss 4092.664447149342
INFO:root:current train perplexity5.021897315979004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.59s/it]
INFO:root:eval mean loss: 4100.531095897052
INFO:root:eval perplexity: 5.249507904052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/27

 14%|â–ˆâ–Ž        | 27/200 [1:51:06<11:29:23, 239.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4100.675862630208
INFO:root:current train perplexity4.950114727020264
INFO:root:current mean train loss 4049.6624872622283
INFO:root:current train perplexity4.958853244781494
INFO:root:current mean train loss 4049.7614178324857
INFO:root:current train perplexity4.960204601287842
INFO:root:current mean train loss 4063.483999875992
INFO:root:current train perplexity4.97492790222168
INFO:root:current mean train loss 4073.595415450866
INFO:root:current train perplexity4.987850666046143
INFO:root:current mean train loss 4068.577158392749
INFO:root:current train perplexity4.978076934814453
INFO:root:current mean train loss 4072.6498352547
INFO:root:current train perplexity4.981657028198242
INFO:root:current mean train loss 4073.1451499672203
INFO:root:current train perplexity4.97969388961792
INFO:root:current mean train loss 4076.2102706815567
INFO:root:current train perplexity4.982718467712402
INFO:root:current mean train loss 4072.9677584955602
INFO:root:current train perplexity4.981086730957031


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.25s/it]
INFO:root:eval mean loss: 4092.266994611591
INFO:root:eval perplexity: 5.23199462890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/28

 14%|â–ˆâ–        | 28/200 [1:54:51<11:13:27, 234.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4085.3159816576085
INFO:root:current train perplexity4.9605231285095215
INFO:root:current mean train loss 4057.4307156694613
INFO:root:current train perplexity4.935545444488525
INFO:root:current mean train loss 4064.219356519759
INFO:root:current train perplexity4.956499099731445
INFO:root:current mean train loss 4053.4590826359326
INFO:root:current train perplexity4.944960594177246
INFO:root:current mean train loss 4065.392727033466
INFO:root:current train perplexity4.954517364501953
INFO:root:current mean train loss 4066.792929071313
INFO:root:current train perplexity4.954963684082031
INFO:root:current mean train loss 4059.751342577498
INFO:root:current train perplexity4.950866222381592
INFO:root:current mean train loss 4057.040338582188
INFO:root:current train perplexity4.950216293334961
INFO:root:current mean train loss 4060.105423066335
INFO:root:current train perplexity4.951996326446533
INFO:root:current mean train loss 4058.121233410076
INFO:root:current train perplexity4.9513325691223145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.67s/it]
INFO:root:eval mean loss: 4085.014049340647
INFO:root:eval perplexity: 5.216672420501709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/29

 14%|â–ˆâ–        | 29/200 [1:59:12<11:31:44, 242.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4065.265199722782
INFO:root:current train perplexity4.916662216186523
INFO:root:current mean train loss 4044.774837115339
INFO:root:current train perplexity4.909060478210449
INFO:root:current mean train loss 4059.29970851089
INFO:root:current train perplexity4.921674728393555
INFO:root:current mean train loss 4061.3476791151343
INFO:root:current train perplexity4.921560764312744
INFO:root:current mean train loss 4058.5832423234483
INFO:root:current train perplexity4.917569160461426
INFO:root:current mean train loss 4054.219603802525
INFO:root:current train perplexity4.918444633483887
INFO:root:current mean train loss 4048.721007236777
INFO:root:current train perplexity4.914608955383301
INFO:root:current mean train loss 4049.144138821499
INFO:root:current train perplexity4.918864727020264
INFO:root:current mean train loss 4046.382831596439
INFO:root:current train perplexity4.91631555557251
INFO:root:current mean train loss 4041.4509560557362
INFO:root:current train perplexity4.918716907501221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.11s/it]
INFO:root:eval mean loss: 4077.7302263408687
INFO:root:eval perplexity: 5.201329708099365
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/30

 15%|â–ˆâ–Œ        | 30/200 [2:02:56<11:12:03, 237.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4025.3760579427085
INFO:root:current train perplexity4.914011001586914
INFO:root:current mean train loss 4014.5102574190646
INFO:root:current train perplexity4.88765811920166
INFO:root:current mean train loss 4018.7740647064593
INFO:root:current train perplexity4.872659206390381
INFO:root:current mean train loss 4014.9580099730365
INFO:root:current train perplexity4.86962890625
INFO:root:current mean train loss 4022.0355305248077
INFO:root:current train perplexity4.8739914894104
INFO:root:current mean train loss 4020.289768197762
INFO:root:current train perplexity4.876504421234131
INFO:root:current mean train loss 4020.3639131883315
INFO:root:current train perplexity4.879396915435791
INFO:root:current mean train loss 4024.7017159881384
INFO:root:current train perplexity4.882699966430664
INFO:root:current mean train loss 4024.5974036706643
INFO:root:current train perplexity4.886056423187256
INFO:root:current mean train loss 4023.796140238119
INFO:root:current train perplexity4.885915756225586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it]
INFO:root:eval mean loss: 4069.256742436835
INFO:root:eval perplexity: 5.183539390563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/31

 16%|â–ˆâ–Œ        | 31/200 [2:06:40<10:56:47, 233.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3992.7122049534573
INFO:root:current train perplexity4.823131561279297
INFO:root:current mean train loss 3993.3546649128402
INFO:root:current train perplexity4.8232855796813965
INFO:root:current mean train loss 3986.5780479029604
INFO:root:current train perplexity4.812054634094238
INFO:root:current mean train loss 3998.101401381259
INFO:root:current train perplexity4.826785087585449
INFO:root:current mean train loss 4002.1720191904365
INFO:root:current train perplexity4.83447265625
INFO:root:current mean train loss 4004.2171262639968
INFO:root:current train perplexity4.8448100090026855
INFO:root:current mean train loss 4008.7957795745992
INFO:root:current train perplexity4.851629257202148
INFO:root:current mean train loss 4004.325604828167
INFO:root:current train perplexity4.851917266845703
INFO:root:current mean train loss 4006.7177737257416
INFO:root:current train perplexity4.855613708496094
INFO:root:current mean train loss 4006.3184369740793
INFO:root:current train perplexity4.853896617889404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it]
INFO:root:eval mean loss: 4062.1649092004654
INFO:root:eval perplexity: 5.16869592666626
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/32

 16%|â–ˆâ–Œ        | 32/200 [2:10:24<10:44:34, 230.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3983.2551491477275
INFO:root:current train perplexity4.752765655517578
INFO:root:current mean train loss 4000.7922741305442
INFO:root:current train perplexity4.80706262588501
INFO:root:current mean train loss 3982.375576363358
INFO:root:current train perplexity4.800252437591553
INFO:root:current mean train loss 3976.515613996479
INFO:root:current train perplexity4.807903289794922
INFO:root:current mean train loss 3985.9478746351306
INFO:root:current train perplexity4.819072723388672
INFO:root:current mean train loss 3987.63234753308
INFO:root:current train perplexity4.820692539215088
INFO:root:current mean train loss 3992.268965812858
INFO:root:current train perplexity4.8234992027282715
INFO:root:current mean train loss 3993.992656702711
INFO:root:current train perplexity4.824003219604492
INFO:root:current mean train loss 3995.0004134685673
INFO:root:current train perplexity4.825232028961182
INFO:root:current mean train loss 3994.050841837778
INFO:root:current train perplexity4.828319549560547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it]
INFO:root:eval mean loss: 4054.6114008477393
INFO:root:eval perplexity: 5.1529316902160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/33

 16%|â–ˆâ–‹        | 33/200 [2:14:46<11:07:22, 239.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3926.6533706907244
INFO:root:current train perplexity4.7506632804870605
INFO:root:current mean train loss 3952.452075045533
INFO:root:current train perplexity4.785551071166992
INFO:root:current mean train loss 3952.4320035869177
INFO:root:current train perplexity4.786538124084473
INFO:root:current mean train loss 3962.0997116046833
INFO:root:current train perplexity4.787482261657715
INFO:root:current mean train loss 3971.501570831365
INFO:root:current train perplexity4.78988790512085
INFO:root:current mean train loss 3967.92166728533
INFO:root:current train perplexity4.783432960510254
INFO:root:current mean train loss 3970.7074893358786
INFO:root:current train perplexity4.789958953857422
INFO:root:current mean train loss 3969.223627692906
INFO:root:current train perplexity4.786790370941162
INFO:root:current mean train loss 3970.9927697032517
INFO:root:current train perplexity4.787935256958008
INFO:root:current mean train loss 3977.804372880565
INFO:root:current train perplexity4.7976603507995605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.56s/it]
INFO:root:eval mean loss: 4055.450363267398
INFO:root:eval perplexity: 5.154680252075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/34

 17%|â–ˆâ–‹        | 34/200 [2:19:05<11:19:28, 245.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3995.657704527949
INFO:root:current train perplexity4.780679225921631
INFO:root:current mean train loss 3959.0913814076207
INFO:root:current train perplexity4.7561421394348145
INFO:root:current mean train loss 3955.0935031567114
INFO:root:current train perplexity4.759088516235352
INFO:root:current mean train loss 3957.976200566459
INFO:root:current train perplexity4.755692005157471
INFO:root:current mean train loss 3958.1222066373075
INFO:root:current train perplexity4.756886959075928
INFO:root:current mean train loss 3961.8287402685805
INFO:root:current train perplexity4.765933513641357
INFO:root:current mean train loss 3964.1724673411886
INFO:root:current train perplexity4.769779205322266
INFO:root:current mean train loss 3962.761625653575
INFO:root:current train perplexity4.768725872039795
INFO:root:current mean train loss 3966.3374628883826
INFO:root:current train perplexity4.772608757019043
INFO:root:current mean train loss 3964.7704620518475
INFO:root:current train perplexity4.773562908172607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it]
INFO:root:eval mean loss: 4048.4190578595967
INFO:root:eval perplexity: 5.140044212341309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/35

 18%|â–ˆâ–Š        | 35/200 [2:22:50<10:58:52, 239.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3973.83154296875
INFO:root:current train perplexity4.767208576202393
INFO:root:current mean train loss 3951.3853834780903
INFO:root:current train perplexity4.732287406921387
INFO:root:current mean train loss 3955.486512761817
INFO:root:current train perplexity4.7451252937316895
INFO:root:current mean train loss 3952.724499221842
INFO:root:current train perplexity4.740850925445557
INFO:root:current mean train loss 3951.725101224067
INFO:root:current train perplexity4.744998455047607
INFO:root:current mean train loss 3954.854140945461
INFO:root:current train perplexity4.743916034698486
INFO:root:current mean train loss 3955.1972792882457
INFO:root:current train perplexity4.747209548950195
INFO:root:current mean train loss 3952.7995357880695
INFO:root:current train perplexity4.74681282043457
INFO:root:current mean train loss 3950.067213663876
INFO:root:current train perplexity4.743699550628662
INFO:root:current mean train loss 3949.6511781593144
INFO:root:current train perplexity4.745262622833252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.56s/it]
INFO:root:eval mean loss: 4043.032157302748
INFO:root:eval perplexity: 5.128860950469971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/36

 18%|â–ˆâ–Š        | 36/200 [2:26:33<10:41:02, 234.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3903.460760708513
INFO:root:current train perplexity4.697434902191162
INFO:root:current mean train loss 3909.9676872702207
INFO:root:current train perplexity4.688036918640137
INFO:root:current mean train loss 3921.6747902262086
INFO:root:current train perplexity4.697261810302734
INFO:root:current mean train loss 3927.351911993298
INFO:root:current train perplexity4.707058429718018
INFO:root:current mean train loss 3923.0953396712976
INFO:root:current train perplexity4.709174633026123
INFO:root:current mean train loss 3924.5058556317877
INFO:root:current train perplexity4.712218284606934
INFO:root:current mean train loss 3929.215361527133
INFO:root:current train perplexity4.714087009429932
INFO:root:current mean train loss 3932.0432293321155
INFO:root:current train perplexity4.716217517852783
INFO:root:current mean train loss 3933.6991535173865
INFO:root:current train perplexity4.715269565582275
INFO:root:current mean train loss 3936.0410749905013
INFO:root:current train perplexity4.720020294189453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it]
INFO:root:eval mean loss: 4037.248862408577
INFO:root:eval perplexity: 5.116879940032959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/37

 18%|â–ˆâ–Š        | 37/200 [2:30:21<10:31:52, 232.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.0677194695722
INFO:root:current train perplexity4.646681308746338
INFO:root:current mean train loss 3896.2039463141027
INFO:root:current train perplexity4.656605243682861
INFO:root:current mean train loss 3905.9648065082097
INFO:root:current train perplexity4.6738810539245605
INFO:root:current mean train loss 3898.502504450158
INFO:root:current train perplexity4.67380428314209
INFO:root:current mean train loss 3905.2988429214015
INFO:root:current train perplexity4.679492473602295
INFO:root:current mean train loss 3909.806034992122
INFO:root:current train perplexity4.683273792266846
INFO:root:current mean train loss 3910.8315907430306
INFO:root:current train perplexity4.683901309967041
INFO:root:current mean train loss 3917.546120774371
INFO:root:current train perplexity4.690958499908447
INFO:root:current mean train loss 3923.030870286313
INFO:root:current train perplexity4.694940567016602


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it]
INFO:root:eval mean loss: 4037.733169880319
INFO:root:eval perplexity: 5.117882251739502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/38

 19%|â–ˆâ–‰        | 38/200 [2:34:48<10:56:00, 242.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3853.3981119791665
INFO:root:current train perplexity4.530088901519775
INFO:root:current mean train loss 3909.9799852093447
INFO:root:current train perplexity4.656083106994629
INFO:root:current mean train loss 3902.621488223522
INFO:root:current train perplexity4.652971267700195
INFO:root:current mean train loss 3905.4550531469163
INFO:root:current train perplexity4.653644561767578
INFO:root:current mean train loss 3901.0206101940526
INFO:root:current train perplexity4.650324821472168
INFO:root:current mean train loss 3903.7664321687066
INFO:root:current train perplexity4.650869846343994
INFO:root:current mean train loss 3908.8869993295243
INFO:root:current train perplexity4.65956449508667
INFO:root:current mean train loss 3906.472645484197
INFO:root:current train perplexity4.663376331329346
INFO:root:current mean train loss 3909.2007492654498
INFO:root:current train perplexity4.665813446044922
INFO:root:current mean train loss 3911.0517607865277
INFO:root:current train perplexity4.668595790863037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.55s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it]
INFO:root:eval mean loss: 4031.263190519725
INFO:root:eval perplexity: 5.104510307312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/39

 20%|â–ˆâ–‰        | 39/200 [2:39:16<11:12:03, 250.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3857.6964222301135
INFO:root:current train perplexity4.598169326782227
INFO:root:current mean train loss 3877.360883833052
INFO:root:current train perplexity4.615208148956299
INFO:root:current mean train loss 3886.32718893476
INFO:root:current train perplexity4.620968341827393
INFO:root:current mean train loss 3887.426252260852
INFO:root:current train perplexity4.637027740478516
INFO:root:current mean train loss 3890.2656071795163
INFO:root:current train perplexity4.6441192626953125
INFO:root:current mean train loss 3894.7078004601885
INFO:root:current train perplexity4.6460700035095215
INFO:root:current mean train loss 3892.430092669548
INFO:root:current train perplexity4.640841484069824
INFO:root:current mean train loss 3894.5299613083466
INFO:root:current train perplexity4.645559310913086
INFO:root:current mean train loss 3895.826453043118
INFO:root:current train perplexity4.645913124084473
INFO:root:current mean train loss 3897.281065353578
INFO:root:current train perplexity4.648176670074463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 4026.4269309618794
INFO:root:eval perplexity: 5.094537258148193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/40

 20%|â–ˆâ–ˆ        | 40/200 [2:43:00<10:46:23, 242.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3897.631463301809
INFO:root:current train perplexity4.648618221282959
INFO:root:current mean train loss 3877.4584653197217
INFO:root:current train perplexity4.620382785797119
INFO:root:current mean train loss 3877.0415830568636
INFO:root:current train perplexity4.620419979095459
INFO:root:current mean train loss 3886.2635601366574
INFO:root:current train perplexity4.622815132141113
INFO:root:current mean train loss 3886.5160165572793
INFO:root:current train perplexity4.6247172355651855
INFO:root:current mean train loss 3889.458751053709
INFO:root:current train perplexity4.627197265625
INFO:root:current mean train loss 3888.112779558764
INFO:root:current train perplexity4.62575101852417
INFO:root:current mean train loss 3892.530292452625
INFO:root:current train perplexity4.632511138916016
INFO:root:current mean train loss 3888.679459754655
INFO:root:current train perplexity4.6280012130737305
INFO:root:current mean train loss 3885.3538516836406
INFO:root:current train perplexity4.626875877380371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]
INFO:root:eval mean loss: 4023.9914308372117
INFO:root:eval perplexity: 5.089521884918213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/41

 20%|â–ˆâ–ˆ        | 41/200 [2:46:43<10:26:36, 236.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3824.9969889322915
INFO:root:current train perplexity4.576220512390137
INFO:root:current mean train loss 3848.3846502829724
INFO:root:current train perplexity4.567986488342285
INFO:root:current mean train loss 3856.120814117566
INFO:root:current train perplexity4.584259510040283
INFO:root:current mean train loss 3858.6513231376625
INFO:root:current train perplexity4.580949306488037
INFO:root:current mean train loss 3860.5037770327135
INFO:root:current train perplexity4.588407516479492
INFO:root:current mean train loss 3861.652652284452
INFO:root:current train perplexity4.585447311401367
INFO:root:current mean train loss 3864.3548122570273
INFO:root:current train perplexity4.585577964782715
INFO:root:current mean train loss 3869.2467076276653
INFO:root:current train perplexity4.5936455726623535
INFO:root:current mean train loss 3874.723612442847
INFO:root:current train perplexity4.602121353149414
INFO:root:current mean train loss 3874.74368789821
INFO:root:current train perplexity4.603557586669922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it]
INFO:root:eval mean loss: 4018.8627271719856
INFO:root:eval perplexity: 5.078978061676025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/42

 21%|â–ˆâ–ˆ        | 42/200 [2:50:25<10:11:45, 232.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3804.9003976004465
INFO:root:current train perplexity4.555781841278076
INFO:root:current mean train loss 3823.250853587963
INFO:root:current train perplexity4.557645797729492
INFO:root:current mean train loss 3839.443535987367
INFO:root:current train perplexity4.558180809020996
INFO:root:current mean train loss 3850.340385232043
INFO:root:current train perplexity4.569375038146973
INFO:root:current mean train loss 3853.863506869612
INFO:root:current train perplexity4.5704545974731445
INFO:root:current mean train loss 3857.110708874854
INFO:root:current train perplexity4.574225425720215
INFO:root:current mean train loss 3857.467072926919
INFO:root:current train perplexity4.577828884124756
INFO:root:current mean train loss 3861.7414514243196
INFO:root:current train perplexity4.579665184020996
INFO:root:current mean train loss 3859.188951101703
INFO:root:current train perplexity4.577816009521484
INFO:root:current mean train loss 3859.7638611819016
INFO:root:current train perplexity4.579387664794922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.43s/it]
INFO:root:eval mean loss: 4014.035836727061
INFO:root:eval perplexity: 5.069075107574463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/43

 22%|â–ˆâ–ˆâ–       | 43/200 [2:54:08<10:00:19, 229.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3891.8680788971656
INFO:root:current train perplexity4.574240207672119
INFO:root:current mean train loss 3867.9817987188594
INFO:root:current train perplexity4.575562953948975
INFO:root:current mean train loss 3858.6244896154835
INFO:root:current train perplexity4.556763648986816
INFO:root:current mean train loss 3854.449402389304
INFO:root:current train perplexity4.555389404296875
INFO:root:current mean train loss 3853.744210615653
INFO:root:current train perplexity4.552276134490967
INFO:root:current mean train loss 3853.5796991000516
INFO:root:current train perplexity4.555849075317383
INFO:root:current mean train loss 3852.0629575263656
INFO:root:current train perplexity4.555568695068359
INFO:root:current mean train loss 3849.1952733980693
INFO:root:current train perplexity4.55657958984375
INFO:root:current mean train loss 3850.476166314502
INFO:root:current train perplexity4.561302185058594
INFO:root:current mean train loss 3850.018895397004
INFO:root:current train perplexity4.561915874481201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.81s/it]
INFO:root:eval mean loss: 4014.702425476507
INFO:root:eval perplexity: 5.070441246032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/44

 22%|â–ˆâ–ˆâ–       | 44/200 [2:58:31<10:22:30, 239.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.219611672794
INFO:root:current train perplexity4.49071741104126
INFO:root:current mean train loss 3824.783701107202
INFO:root:current train perplexity4.512048721313477
INFO:root:current mean train loss 3829.953746537288
INFO:root:current train perplexity4.526662826538086
INFO:root:current mean train loss 3828.8753032629984
INFO:root:current train perplexity4.525765419006348
INFO:root:current mean train loss 3835.7706891586404
INFO:root:current train perplexity4.526955604553223
INFO:root:current mean train loss 3839.3740925589836
INFO:root:current train perplexity4.536558151245117
INFO:root:current mean train loss 3835.3073164182506
INFO:root:current train perplexity4.535406589508057
INFO:root:current mean train loss 3838.061222406583
INFO:root:current train perplexity4.539367198944092
INFO:root:current mean train loss 3836.0741260855793
INFO:root:current train perplexity4.5393805503845215
INFO:root:current mean train loss 3838.4542158028557
INFO:root:current train perplexity4.540693759918213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it]
INFO:root:eval mean loss: 4009.771349318484
INFO:root:eval perplexity: 5.060340881347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:02:55<10:37:33, 246.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3817.6766957428495
INFO:root:current train perplexity4.484330177307129
INFO:root:current mean train loss 3829.5371600456956
INFO:root:current train perplexity4.520987033843994
INFO:root:current mean train loss 3826.3587462671935
INFO:root:current train perplexity4.523008346557617
INFO:root:current mean train loss 3823.473762023416
INFO:root:current train perplexity4.5191545486450195
INFO:root:current mean train loss 3823.477873093682
INFO:root:current train perplexity4.520646572113037
INFO:root:current mean train loss 3824.664740328712
INFO:root:current train perplexity4.520839214324951
INFO:root:current mean train loss 3829.6399759341807
INFO:root:current train perplexity4.52341365814209
INFO:root:current mean train loss 3832.651516116498
INFO:root:current train perplexity4.5221147537231445
INFO:root:current mean train loss 3829.9535186376784
INFO:root:current train perplexity4.523428916931152
INFO:root:current mean train loss 3829.3371403826413
INFO:root:current train perplexity4.523878574371338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it]
INFO:root:eval mean loss: 4008.5056342808066
INFO:root:eval perplexity: 5.057750701904297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:06:44<10:19:44, 241.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.2795592350744
INFO:root:current train perplexity4.507989883422852
INFO:root:current mean train loss 3820.051563377152
INFO:root:current train perplexity4.481689929962158
INFO:root:current mean train loss 3813.0764343033125
INFO:root:current train perplexity4.486057758331299
INFO:root:current mean train loss 3820.0201532431456
INFO:root:current train perplexity4.497031211853027
INFO:root:current mean train loss 3824.6751742965403
INFO:root:current train perplexity4.500420570373535
INFO:root:current mean train loss 3821.9342168037642
INFO:root:current train perplexity4.499350547790527
INFO:root:current mean train loss 3823.1498869705774
INFO:root:current train perplexity4.505880355834961
INFO:root:current mean train loss 3819.477598904009
INFO:root:current train perplexity4.503220081329346
INFO:root:current mean train loss 3819.0245362736086
INFO:root:current train perplexity4.503783226013184
INFO:root:current mean train loss 3818.360601762458
INFO:root:current train perplexity4.5042195320129395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]
INFO:root:eval mean loss: 4007.3756025598404
INFO:root:eval perplexity: 5.055440902709961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:10:43<10:14:09, 240.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3804.386103515625
INFO:root:current train perplexity4.432851314544678
INFO:root:current mean train loss 3796.806763392857
INFO:root:current train perplexity4.469295978546143
INFO:root:current mean train loss 3797.4980078125
INFO:root:current train perplexity4.468813419342041
INFO:root:current mean train loss 3805.5083372395834
INFO:root:current train perplexity4.4804463386535645
INFO:root:current mean train loss 3804.6426171875
INFO:root:current train perplexity4.481273651123047
INFO:root:current mean train loss 3806.8249469259513
INFO:root:current train perplexity4.483301162719727
INFO:root:current mean train loss 3805.825712890625
INFO:root:current train perplexity4.484362602233887
INFO:root:current mean train loss 3805.7453194304435
INFO:root:current train perplexity4.487783432006836
INFO:root:current mean train loss 3806.948059151786
INFO:root:current train perplexity4.4893717765808105
INFO:root:current mean train loss 3808.2088403946314
INFO:root:current train perplexity4.488508701324463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.28s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 4002.040123905696
INFO:root:eval perplexity: 5.0445451736450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:14:44<10:10:14, 240.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3802.26606915945
INFO:root:current train perplexity4.450379848480225
INFO:root:current mean train loss 3804.7065549756658
INFO:root:current train perplexity4.4495649337768555
INFO:root:current mean train loss 3792.955920970903
INFO:root:current train perplexity4.446590900421143
INFO:root:current mean train loss 3789.353771239597
INFO:root:current train perplexity4.454674243927002
INFO:root:current mean train loss 3789.9217936197915
INFO:root:current train perplexity4.459082126617432
INFO:root:current mean train loss 3793.4566589669544
INFO:root:current train perplexity4.452922344207764
INFO:root:current mean train loss 3794.735577473005
INFO:root:current train perplexity4.456739902496338
INFO:root:current mean train loss 3793.889187906589
INFO:root:current train perplexity4.4603729248046875
INFO:root:current mean train loss 3794.518575977226
INFO:root:current train perplexity4.462236404418945
INFO:root:current mean train loss 3797.5706952270634
INFO:root:current train perplexity4.469727039337158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it]
INFO:root:eval mean loss: 3999.6346790503103
INFO:root:eval perplexity: 5.0396409034729
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:18:28<9:53:43, 235.92s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3787.16654414921
INFO:root:current train perplexity4.402422904968262
INFO:root:current mean train loss 3785.3618688133997
INFO:root:current train perplexity4.424516677856445
INFO:root:current mean train loss 3775.218978200172
INFO:root:current train perplexity4.429765224456787
INFO:root:current mean train loss 3780.6118476262786
INFO:root:current train perplexity4.438050746917725
INFO:root:current mean train loss 3780.8827220038825
INFO:root:current train perplexity4.440335273742676
INFO:root:current mean train loss 3784.2777217342164
INFO:root:current train perplexity4.444766521453857
INFO:root:current mean train loss 3782.2531243640333
INFO:root:current train perplexity4.442820072174072
INFO:root:current mean train loss 3785.0635842806773
INFO:root:current train perplexity4.445934295654297
INFO:root:current mean train loss 3784.44916641458
INFO:root:current train perplexity4.447323322296143
INFO:root:current mean train loss 3788.810294850924
INFO:root:current train perplexity4.4532575607299805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.93s/it]
INFO:root:eval mean loss: 3999.3574668938386
INFO:root:eval perplexity: 5.03907585144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:22:37<9:59:10, 239.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.5032009548613
INFO:root:current train perplexity4.387758255004883
INFO:root:current mean train loss 3768.658670550016
INFO:root:current train perplexity4.403971195220947
INFO:root:current mean train loss 3772.323501842078
INFO:root:current train perplexity4.414079189300537
INFO:root:current mean train loss 3773.9377955386512
INFO:root:current train perplexity4.415970325469971
INFO:root:current mean train loss 3777.3755592239168
INFO:root:current train perplexity4.426544666290283
INFO:root:current mean train loss 3776.222569027807
INFO:root:current train perplexity4.431334495544434
INFO:root:current mean train loss 3771.1264445860156
INFO:root:current train perplexity4.429938793182373
INFO:root:current mean train loss 3771.02475842606
INFO:root:current train perplexity4.42976188659668
INFO:root:current mean train loss 3772.7287269057633
INFO:root:current train perplexity4.431082725524902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.07s/it]
INFO:root:eval mean loss: 4004.678726520944
INFO:root:eval perplexity: 5.049930572509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:27:03<10:14:42, 247.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.14404296875
INFO:root:current train perplexity4.3960065841674805
INFO:root:current mean train loss 3761.6355436806366
INFO:root:current train perplexity4.392827987670898
INFO:root:current mean train loss 3759.999313575634
INFO:root:current train perplexity4.400003910064697
INFO:root:current mean train loss 3770.163495489363
INFO:root:current train perplexity4.402072429656982
INFO:root:current mean train loss 3770.662931175138
INFO:root:current train perplexity4.407329559326172
INFO:root:current mean train loss 3767.7921876926157
INFO:root:current train perplexity4.406314373016357
INFO:root:current mean train loss 3764.9352717643123
INFO:root:current train perplexity4.4074907302856445
INFO:root:current mean train loss 3762.199869331241
INFO:root:current train perplexity4.409927845001221
INFO:root:current mean train loss 3765.4784738760454
INFO:root:current train perplexity4.413729667663574
INFO:root:current mean train loss 3766.5244818942942
INFO:root:current train perplexity4.413862705230713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it]
INFO:root:eval mean loss: 3996.870844414894
INFO:root:eval perplexity: 5.034011363983154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:31:31<10:26:10, 253.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.306689453125
INFO:root:current train perplexity4.454915523529053
INFO:root:current mean train loss 3736.9465565557066
INFO:root:current train perplexity4.373807907104492
INFO:root:current mean train loss 3741.300278206759
INFO:root:current train perplexity4.380209445953369
INFO:root:current mean train loss 3740.5247527591764
INFO:root:current train perplexity4.384067058563232
INFO:root:current mean train loss 3747.5105092243975
INFO:root:current train perplexity4.385894775390625
INFO:root:current mean train loss 3749.2134566520026
INFO:root:current train perplexity4.387381553649902
INFO:root:current mean train loss 3747.627587096672
INFO:root:current train perplexity4.3930344581604
INFO:root:current mean train loss 3751.780308265953
INFO:root:current train perplexity4.396853923797607
INFO:root:current mean train loss 3757.8075590730446
INFO:root:current train perplexity4.399555206298828
INFO:root:current mean train loss 3758.881713466957
INFO:root:current train perplexity4.400745391845703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.27s/it]
INFO:root:eval mean loss: 3997.28764786957
INFO:root:eval perplexity: 5.034860610961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [3:35:21<10:03:55, 246.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3749.7416779891305
INFO:root:current train perplexity4.439713954925537
INFO:root:current mean train loss 3748.8237999396597
INFO:root:current train perplexity4.391311168670654
INFO:root:current mean train loss 3738.0923990155547
INFO:root:current train perplexity4.377971649169922
INFO:root:current mean train loss 3747.0458863438466
INFO:root:current train perplexity4.382175922393799
INFO:root:current mean train loss 3742.8125958093233
INFO:root:current train perplexity4.381597995758057
INFO:root:current mean train loss 3749.1744312410374
INFO:root:current train perplexity4.388275623321533
INFO:root:current mean train loss 3752.5242177311147
INFO:root:current train perplexity4.38966703414917
INFO:root:current mean train loss 3747.8490694291363
INFO:root:current train perplexity4.383296966552734
INFO:root:current mean train loss 3750.017884561532
INFO:root:current train perplexity4.385959148406982
INFO:root:current mean train loss 3751.871890976266
INFO:root:current train perplexity4.386931419372559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.95s/it]
INFO:root:eval mean loss: 3996.953990746897
INFO:root:eval perplexity: 5.034181118011475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:39:45<10:12:55, 251.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.0130733366937
INFO:root:current train perplexity4.382554054260254
INFO:root:current mean train loss 3723.2231147125476
INFO:root:current train perplexity4.344297885894775
INFO:root:current mean train loss 3737.043172728964
INFO:root:current train perplexity4.362890243530273
INFO:root:current mean train loss 3728.5033301961384
INFO:root:current train perplexity4.354836463928223
INFO:root:current mean train loss 3732.1262042760295
INFO:root:current train perplexity4.362006187438965
INFO:root:current mean train loss 3735.00871549847
INFO:root:current train perplexity4.368200302124023
INFO:root:current mean train loss 3734.5396475089146
INFO:root:current train perplexity4.371662616729736
INFO:root:current mean train loss 3735.6747449047753
INFO:root:current train perplexity4.370823860168457
INFO:root:current mean train loss 3737.3449436743194
INFO:root:current train perplexity4.371274948120117
INFO:root:current mean train loss 3739.3753999081127
INFO:root:current train perplexity4.370331287384033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.37s/it]
INFO:root:eval mean loss: 3996.067027856272
INFO:root:eval perplexity: 5.032375812530518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:43:59<10:10:12, 252.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3696.346216446314
INFO:root:current train perplexity4.3190598487854
INFO:root:current mean train loss 3728.3474384554856
INFO:root:current train perplexity4.336357593536377
INFO:root:current mean train loss 3728.1048793393697
INFO:root:current train perplexity4.336769104003906
INFO:root:current mean train loss 3722.734841675885
INFO:root:current train perplexity4.329726219177246
INFO:root:current mean train loss 3720.112876944227
INFO:root:current train perplexity4.331393241882324
INFO:root:current mean train loss 3718.2624294302236
INFO:root:current train perplexity4.337585926055908
INFO:root:current mean train loss 3720.9960841983325
INFO:root:current train perplexity4.342421531677246
INFO:root:current mean train loss 3724.0167452717988
INFO:root:current train perplexity4.348141670227051
INFO:root:current mean train loss 3726.7029361474783
INFO:root:current train perplexity4.350228309631348
INFO:root:current mean train loss 3730.6535392330607
INFO:root:current train perplexity4.353143215179443


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it]
INFO:root:eval mean loss: 3992.7540776678857
INFO:root:eval perplexity: 5.025638580322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:47:44<9:46:13, 244.26s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.445322888963
INFO:root:current train perplexity4.331744194030762
INFO:root:current mean train loss 3706.4638372927297
INFO:root:current train perplexity4.315182685852051
INFO:root:current mean train loss 3712.3504119749496
INFO:root:current train perplexity4.317641735076904
INFO:root:current mean train loss 3715.70987580489
INFO:root:current train perplexity4.322179317474365
INFO:root:current mean train loss 3714.5468258441697
INFO:root:current train perplexity4.32843542098999
INFO:root:current mean train loss 3717.4262570341066
INFO:root:current train perplexity4.330557346343994
INFO:root:current mean train loss 3722.6352682452666
INFO:root:current train perplexity4.334989547729492
INFO:root:current mean train loss 3722.9676420525852
INFO:root:current train perplexity4.3370466232299805
INFO:root:current mean train loss 3724.1332353504094
INFO:root:current train perplexity4.338383674621582
INFO:root:current mean train loss 3724.467859028511
INFO:root:current train perplexity4.339285850524902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it]
INFO:root:eval mean loss: 3992.097406914894
INFO:root:eval perplexity: 5.024304389953613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:51:51<9:44:25, 245.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3676.4539994673296
INFO:root:current train perplexity4.25969123840332
INFO:root:current mean train loss 3689.156735131048
INFO:root:current train perplexity4.291156768798828
INFO:root:current mean train loss 3698.1410663679535
INFO:root:current train perplexity4.295122146606445
INFO:root:current mean train loss 3696.698420994718
INFO:root:current train perplexity4.295935153961182
INFO:root:current mean train loss 3706.622192651099
INFO:root:current train perplexity4.306503772735596
INFO:root:current mean train loss 3707.0915800077423
INFO:root:current train perplexity4.311323642730713
INFO:root:current mean train loss 3707.761353098163
INFO:root:current train perplexity4.31559419631958
INFO:root:current mean train loss 3709.158346699089
INFO:root:current train perplexity4.321727275848389
INFO:root:current mean train loss 3710.571954381396
INFO:root:current train perplexity4.321031093597412
INFO:root:current mean train loss 3713.312595355448
INFO:root:current train perplexity4.323114395141602


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.66s/it]
INFO:root:eval mean loss: 3993.755158120013
INFO:root:eval perplexity: 5.027674198150635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:56:16<9:53:47, 250.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3696.1398073226687
INFO:root:current train perplexity4.302886009216309
INFO:root:current mean train loss 3679.6962321462806
INFO:root:current train perplexity4.265770435333252
INFO:root:current mean train loss 3688.0280724587096
INFO:root:current train perplexity4.272834300994873
INFO:root:current mean train loss 3681.983191287879
INFO:root:current train perplexity4.276709079742432
INFO:root:current mean train loss 3689.329649428827
INFO:root:current train perplexity4.286990642547607
INFO:root:current mean train loss 3692.623401594416
INFO:root:current train perplexity4.2901530265808105
INFO:root:current mean train loss 3695.0288700892015
INFO:root:current train perplexity4.293585300445557
INFO:root:current mean train loss 3697.180103147014
INFO:root:current train perplexity4.300431251525879
INFO:root:current mean train loss 3699.61568503087
INFO:root:current train perplexity4.305397987365723
INFO:root:current mean train loss 3704.5373149804486
INFO:root:current train perplexity4.3095502853393555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.66s/it]
INFO:root:eval mean loss: 3990.308031014517
INFO:root:eval perplexity: 5.020669937133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [4:00:36<9:56:34, 253.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.3666373239435
INFO:root:current train perplexity4.275320053100586
INFO:root:current mean train loss 3674.0151509959796
INFO:root:current train perplexity4.252281188964844
INFO:root:current mean train loss 3689.895380787304
INFO:root:current train perplexity4.27085542678833
INFO:root:current mean train loss 3693.3098769689186
INFO:root:current train perplexity4.281094074249268
INFO:root:current mean train loss 3691.409005005142
INFO:root:current train perplexity4.287803649902344
INFO:root:current mean train loss 3693.024232346623
INFO:root:current train perplexity4.291620254516602
INFO:root:current mean train loss 3693.403208611797
INFO:root:current train perplexity4.292490005493164
INFO:root:current mean train loss 3695.6734114076685
INFO:root:current train perplexity4.2921528816223145
INFO:root:current mean train loss 3695.8460397643694
INFO:root:current train perplexity4.293161392211914
INFO:root:current mean train loss 3695.418400710447
INFO:root:current train perplexity4.293395519256592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it]
INFO:root:eval mean loss: 3990.1199977144283
INFO:root:eval perplexity: 5.020288944244385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:05:00<9:59:21, 256.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3681.1506873022154
INFO:root:current train perplexity4.278195381164551
INFO:root:current mean train loss 3692.545322865747
INFO:root:current train perplexity4.283946990966797
INFO:root:current mean train loss 3688.78912375392
INFO:root:current train perplexity4.285469055175781
INFO:root:current mean train loss 3679.3995763934695
INFO:root:current train perplexity4.2791900634765625
INFO:root:current mean train loss 3679.1478778624087
INFO:root:current train perplexity4.27396297454834
INFO:root:current mean train loss 3682.954838622625
INFO:root:current train perplexity4.279204845428467
INFO:root:current mean train loss 3682.358180904248
INFO:root:current train perplexity4.277372360229492
INFO:root:current mean train loss 3684.6604486546253
INFO:root:current train perplexity4.279366970062256
INFO:root:current mean train loss 3686.1190386914286
INFO:root:current train perplexity4.278831481933594
INFO:root:current mean train loss 3690.7076950930477
INFO:root:current train perplexity4.283477306365967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]
INFO:root:eval mean loss: 3989.5064290364585
INFO:root:eval perplexity: 5.019042491912842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:09:25<10:00:35, 259.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3671.384137033046
INFO:root:current train perplexity4.235852241516113
INFO:root:current mean train loss 3676.1866500772894
INFO:root:current train perplexity4.257494926452637
INFO:root:current mean train loss 3680.3238818869772
INFO:root:current train perplexity4.262608528137207
INFO:root:current mean train loss 3681.5024685329863
INFO:root:current train perplexity4.263909816741943
INFO:root:current mean train loss 3682.273725255069
INFO:root:current train perplexity4.2668023109436035
INFO:root:current mean train loss 3682.3420967478974
INFO:root:current train perplexity4.265053749084473
INFO:root:current mean train loss 3681.1755708697233
INFO:root:current train perplexity4.2646660804748535
INFO:root:current mean train loss 3679.718569143603
INFO:root:current train perplexity4.266615867614746
INFO:root:current mean train loss 3678.9363252624717
INFO:root:current train perplexity4.265877723693848
INFO:root:current mean train loss 3680.963214166983
INFO:root:current train perplexity4.26785135269165


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 3990.885833956671
INFO:root:eval perplexity: 5.021842956542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:13:47<9:58:19, 260.14s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.5575914884867
INFO:root:current train perplexity4.219673156738281
INFO:root:current mean train loss 3660.5448480068108
INFO:root:current train perplexity4.240023612976074
INFO:root:current mean train loss 3665.500234209481
INFO:root:current train perplexity4.2434587478637695
INFO:root:current mean train loss 3668.420967044106
INFO:root:current train perplexity4.246818542480469
INFO:root:current mean train loss 3671.4564315025254
INFO:root:current train perplexity4.245438098907471
INFO:root:current mean train loss 3673.6258378742123
INFO:root:current train perplexity4.25305700302124
INFO:root:current mean train loss 3672.935543713467
INFO:root:current train perplexity4.251903057098389
INFO:root:current mean train loss 3674.9263975899175
INFO:root:current train perplexity4.258238792419434
INFO:root:current mean train loss 3674.6955970124827
INFO:root:current train perplexity4.25738525390625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.04s/it]
INFO:root:eval mean loss: 3990.962582419105
INFO:root:eval perplexity: 5.021999835968018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:18:10<9:55:49, 260.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3662.83837890625
INFO:root:current train perplexity4.265797138214111
INFO:root:current mean train loss 3665.494996302336
INFO:root:current train perplexity4.230358600616455
INFO:root:current mean train loss 3655.7102014701354
INFO:root:current train perplexity4.2255682945251465
INFO:root:current mean train loss 3656.3385158828382
INFO:root:current train perplexity4.235407829284668
INFO:root:current mean train loss 3664.0958442782644
INFO:root:current train perplexity4.240028381347656
INFO:root:current mean train loss 3668.3942390578404
INFO:root:current train perplexity4.237645626068115
INFO:root:current mean train loss 3668.2399044005233
INFO:root:current train perplexity4.236636161804199
INFO:root:current mean train loss 3665.2144124233196
INFO:root:current train perplexity4.234797477722168
INFO:root:current mean train loss 3666.048795593186
INFO:root:current train perplexity4.23705530166626
INFO:root:current mean train loss 3666.103831412652
INFO:root:current train perplexity4.238163471221924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.70s/it]
INFO:root:eval mean loss: 3988.343152634641
INFO:root:eval perplexity: 5.0166826248168945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:22:41<9:58:32, 264.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.6360085227275
INFO:root:current train perplexity4.205272674560547
INFO:root:current mean train loss 3670.055622272663
INFO:root:current train perplexity4.226509094238281
INFO:root:current mean train loss 3647.1953981227784
INFO:root:current train perplexity4.217644214630127
INFO:root:current mean train loss 3635.264178211666
INFO:root:current train perplexity4.2095842361450195
INFO:root:current mean train loss 3641.8418794432405
INFO:root:current train perplexity4.210663795471191
INFO:root:current mean train loss 3648.23749388454
INFO:root:current train perplexity4.216211318969727
INFO:root:current mean train loss 3652.199231935991
INFO:root:current train perplexity4.221365451812744
INFO:root:current mean train loss 3654.1402620511385
INFO:root:current train perplexity4.224708080291748
INFO:root:current mean train loss 3658.239865605252
INFO:root:current train perplexity4.228176116943359
INFO:root:current mean train loss 3656.5805382671
INFO:root:current train perplexity4.227400779724121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]
INFO:root:eval mean loss: 3986.6504875886526
INFO:root:eval perplexity: 5.01324987411499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/65
#####################best##############
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:26:25<9:26:56, 251.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.5210860402963
INFO:root:current train perplexity4.199260711669922
INFO:root:current mean train loss 3645.6357565487133
INFO:root:current train perplexity4.204996109008789
INFO:root:current mean train loss 3644.563303768907
INFO:root:current train perplexity4.201852798461914
INFO:root:current mean train loss 3647.156299746522
INFO:root:current train perplexity4.203563690185547
INFO:root:current mean train loss 3649.9353901355535
INFO:root:current train perplexity4.210355281829834
INFO:root:current mean train loss 3646.3578725237835
INFO:root:current train perplexity4.2049641609191895
INFO:root:current mean train loss 3650.59019753698
INFO:root:current train perplexity4.210664749145508
INFO:root:current mean train loss 3648.7063742095143
INFO:root:current train perplexity4.21283483505249
INFO:root:current mean train loss 3647.047922509348
INFO:root:current train perplexity4.20913553237915
INFO:root:current mean train loss 3647.5311583476437
INFO:root:current train perplexity4.21378231048584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 3988.546462904477
INFO:root:eval perplexity: 5.01709508895874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:30:08<9:03:10, 243.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.3652253327546
INFO:root:current train perplexity4.107858657836914
INFO:root:current mean train loss 3624.1937938299707
INFO:root:current train perplexity4.169902324676514
INFO:root:current mean train loss 3639.447727018516
INFO:root:current train perplexity4.199566841125488
INFO:root:current mean train loss 3641.242492862433
INFO:root:current train perplexity4.197421073913574
INFO:root:current mean train loss 3643.4201025504976
INFO:root:current train perplexity4.195479393005371
INFO:root:current mean train loss 3637.07718874155
INFO:root:current train perplexity4.19012451171875
INFO:root:current mean train loss 3636.557807983204
INFO:root:current train perplexity4.192714214324951
INFO:root:current mean train loss 3637.379375053731
INFO:root:current train perplexity4.197808265686035
INFO:root:current mean train loss 3637.8875665999094
INFO:root:current train perplexity4.199408531188965
INFO:root:current mean train loss 3641.1027587100525
INFO:root:current train perplexity4.202024936676025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.03s/it]
INFO:root:eval mean loss: 3989.332393132203
INFO:root:eval perplexity: 5.01869010925293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:34:05<8:55:19, 241.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3605.2823660714284
INFO:root:current train perplexity4.147571086883545
INFO:root:current mean train loss 3604.9586353443287
INFO:root:current train perplexity4.157830238342285
INFO:root:current mean train loss 3617.088859915226
INFO:root:current train perplexity4.171243190765381
INFO:root:current mean train loss 3626.09649166278
INFO:root:current train perplexity4.177159786224365
INFO:root:current mean train loss 3625.0884782462285
INFO:root:current train perplexity4.176233768463135
INFO:root:current mean train loss 3632.8278096707068
INFO:root:current train perplexity4.182700157165527
INFO:root:current mean train loss 3633.2321427472934
INFO:root:current train perplexity4.180445671081543
INFO:root:current mean train loss 3634.4403788663903
INFO:root:current train perplexity4.185588359832764
INFO:root:current mean train loss 3635.6079981638286
INFO:root:current train perplexity4.188819408416748
INFO:root:current mean train loss 3637.379174674131
INFO:root:current train perplexity4.191072940826416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:38<00:00, 218.10s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.15s/it]
INFO:root:eval mean loss: 3989.700169340093
INFO:root:eval perplexity: 5.019436836242676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [4:38:48<9:18:22, 253.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.5377509538516
INFO:root:current train perplexity4.1588873863220215
INFO:root:current mean train loss 3630.4117696268577
INFO:root:current train perplexity4.175018787384033
INFO:root:current mean train loss 3629.4572281700102
INFO:root:current train perplexity4.175368785858154
INFO:root:current mean train loss 3626.3014375113885
INFO:root:current train perplexity4.168582439422607
INFO:root:current mean train loss 3621.0727880749155
INFO:root:current train perplexity4.165278911590576
INFO:root:current mean train loss 3623.9341634114585
INFO:root:current train perplexity4.1689229011535645
INFO:root:current mean train loss 3627.5146173029257
INFO:root:current train perplexity4.171943187713623
INFO:root:current mean train loss 3629.251325522586
INFO:root:current train perplexity4.176501274108887
INFO:root:current mean train loss 3631.0974086340634
INFO:root:current train perplexity4.180062294006348
INFO:root:current mean train loss 3627.9697066273693
INFO:root:current train perplexity4.177608489990234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.36s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.40s/it]
INFO:root:eval mean loss: 3991.0759260028813
INFO:root:eval perplexity: 5.022228717803955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [4:43:15<9:22:46, 257.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.7824324065564
INFO:root:current train perplexity4.145617961883545
INFO:root:current mean train loss 3597.953325486341
INFO:root:current train perplexity4.148617744445801
INFO:root:current mean train loss 3601.427728538969
INFO:root:current train perplexity4.144124507904053
INFO:root:current mean train loss 3611.9073079427085
INFO:root:current train perplexity4.157690048217773
INFO:root:current mean train loss 3604.7808277612253
INFO:root:current train perplexity4.155136585235596
INFO:root:current mean train loss 3606.6418341828776
INFO:root:current train perplexity4.159571647644043
INFO:root:current mean train loss 3610.713847686252
INFO:root:current train perplexity4.161082744598389
INFO:root:current mean train loss 3612.8242844176516
INFO:root:current train perplexity4.163430213928223
INFO:root:current mean train loss 3616.4113534284115
INFO:root:current train perplexity4.164059638977051
INFO:root:current mean train loss 3620.013229546612
INFO:root:current train perplexity4.166875839233398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]
INFO:root:eval mean loss: 3988.834086533134
INFO:root:eval perplexity: 5.017679214477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [4:47:46<9:26:56, 261.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3573.364787473517
INFO:root:current train perplexity4.14103364944458
INFO:root:current mean train loss 3585.3726230837265
INFO:root:current train perplexity4.13972282409668
INFO:root:current mean train loss 3600.8874662539215
INFO:root:current train perplexity4.147740364074707
INFO:root:current mean train loss 3600.591816596666
INFO:root:current train perplexity4.149214744567871
INFO:root:current mean train loss 3602.2361451525053
INFO:root:current train perplexity4.144526481628418
INFO:root:current mean train loss 3603.2207096761795
INFO:root:current train perplexity4.146218299865723
INFO:root:current mean train loss 3605.4908841817623
INFO:root:current train perplexity4.148556709289551
INFO:root:current mean train loss 3606.5588398205905
INFO:root:current train perplexity4.152066707611084
INFO:root:current mean train loss 3608.645799417018
INFO:root:current train perplexity4.153390884399414
INFO:root:current mean train loss 3614.314426648853
INFO:root:current train perplexity4.156618595123291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.34s/it]
INFO:root:eval mean loss: 3988.3961207613033
INFO:root:eval perplexity: 5.016790390014648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [4:51:59<9:17:25, 259.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3577.2578853777986
INFO:root:current train perplexity4.086576461791992
INFO:root:current mean train loss 3580.415071224738
INFO:root:current train perplexity4.100105285644531
INFO:root:current mean train loss 3582.0615929307114
INFO:root:current train perplexity4.112753391265869
INFO:root:current mean train loss 3595.604545406165
INFO:root:current train perplexity4.126102924346924
INFO:root:current mean train loss 3595.4032115732066
INFO:root:current train perplexity4.125202655792236
INFO:root:current mean train loss 3591.3514501178074
INFO:root:current train perplexity4.127147197723389
INFO:root:current mean train loss 3597.378611231494
INFO:root:current train perplexity4.130722999572754
INFO:root:current mean train loss 3599.9583961456974
INFO:root:current train perplexity4.135470867156982
INFO:root:current mean train loss 3599.4153071384803
INFO:root:current train perplexity4.136397361755371
INFO:root:current mean train loss 3605.517448101813
INFO:root:current train perplexity4.143389701843262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.91s/it]
INFO:root:eval mean loss: 3990.6810311391846
INFO:root:eval perplexity: 5.021428108215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [4:56:10<9:07:23, 256.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3614.2823893229165
INFO:root:current train perplexity4.119095325469971
INFO:root:current mean train loss 3593.80470703125
INFO:root:current train perplexity4.112304210662842
INFO:root:current mean train loss 3594.657303799716
INFO:root:current train perplexity4.113581657409668
INFO:root:current mean train loss 3591.4606380208334
INFO:root:current train perplexity4.120196342468262
INFO:root:current mean train loss 3594.643460629112
INFO:root:current train perplexity4.125630855560303
INFO:root:current mean train loss 3595.608833220109
INFO:root:current train perplexity4.1250834465026855
INFO:root:current mean train loss 3594.892908347801
INFO:root:current train perplexity4.124719619750977
INFO:root:current mean train loss 3597.950927104335
INFO:root:current train perplexity4.131089210510254
INFO:root:current mean train loss 3599.139425502232
INFO:root:current train perplexity4.13115119934082
INFO:root:current mean train loss 3599.607501252003
INFO:root:current train perplexity4.132910251617432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it]
INFO:root:eval mean loss: 3989.91025667664
INFO:root:eval perplexity: 5.019862651824951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:00:32<9:06:54, 258.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3557.8962931805345
INFO:root:current train perplexity4.087194442749023
INFO:root:current mean train loss 3577.031387412483
INFO:root:current train perplexity4.1054863929748535
INFO:root:current mean train loss 3586.7734366373124
INFO:root:current train perplexity4.116127014160156
INFO:root:current mean train loss 3585.441905367779
INFO:root:current train perplexity4.11112642288208
INFO:root:current mean train loss 3587.177616601158
INFO:root:current train perplexity4.117152690887451
INFO:root:current mean train loss 3587.351797009005
INFO:root:current train perplexity4.120004177093506
INFO:root:current mean train loss 3589.847399598508
INFO:root:current train perplexity4.121308326721191
INFO:root:current mean train loss 3589.667975921436
INFO:root:current train perplexity4.1196699142456055
INFO:root:current mean train loss 3591.430920092193
INFO:root:current train perplexity4.120260238647461
INFO:root:current mean train loss 3592.3989381993897
INFO:root:current train perplexity4.122320175170898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.27s/it]
INFO:root:eval mean loss: 3993.376118544991
INFO:root:eval perplexity: 5.02690315246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [5:04:58<9:07:20, 260.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.6077518672732
INFO:root:current train perplexity4.106385707855225
INFO:root:current mean train loss 3574.7030074034687
INFO:root:current train perplexity4.08945369720459
INFO:root:current mean train loss 3580.59267024404
INFO:root:current train perplexity4.095973968505859
INFO:root:current mean train loss 3576.2620709119246
INFO:root:current train perplexity4.095566272735596
INFO:root:current mean train loss 3575.5711314401415
INFO:root:current train perplexity4.094672203063965
INFO:root:current mean train loss 3577.64404792592
INFO:root:current train perplexity4.093613624572754
INFO:root:current mean train loss 3579.0572115819464
INFO:root:current train perplexity4.099679470062256
INFO:root:current mean train loss 3580.8966294395937
INFO:root:current train perplexity4.104506015777588
INFO:root:current mean train loss 3582.7227025572565
INFO:root:current train perplexity4.107617378234863
INFO:root:current mean train loss 3586.3509170424445
INFO:root:current train perplexity4.111634254455566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.01s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.43s/it]
INFO:root:eval mean loss: 3990.8599360039893
INFO:root:eval perplexity: 5.021790504455566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [5:08:58<8:50:09, 254.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.0263400607637
INFO:root:current train perplexity4.078969955444336
INFO:root:current mean train loss 3573.8321551605686
INFO:root:current train perplexity4.082087993621826
INFO:root:current mean train loss 3572.2769836629914
INFO:root:current train perplexity4.087168216705322
INFO:root:current mean train loss 3571.7550174263783
INFO:root:current train perplexity4.089156150817871
INFO:root:current mean train loss 3575.8384777367232
INFO:root:current train perplexity4.091720104217529
INFO:root:current mean train loss 3576.4328409491077
INFO:root:current train perplexity4.089895248413086
INFO:root:current mean train loss 3580.095338136512
INFO:root:current train perplexity4.098114967346191
INFO:root:current mean train loss 3577.9680081058355
INFO:root:current train perplexity4.097785949707031
INFO:root:current mean train loss 3578.53059796258
INFO:root:current train perplexity4.100106716156006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it]
INFO:root:eval mean loss: 3991.167203429743
INFO:root:eval perplexity: 5.022414684295654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:13:17<8:48:42, 255.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3568.0484444754466
INFO:root:current train perplexity4.089030742645264
INFO:root:current mean train loss 3567.7608174832067
INFO:root:current train perplexity4.088165283203125
INFO:root:current mean train loss 3562.7356806216035
INFO:root:current train perplexity4.079013347625732
INFO:root:current mean train loss 3562.149382252647
INFO:root:current train perplexity4.0731940269470215
INFO:root:current mean train loss 3565.851723260903
INFO:root:current train perplexity4.077462196350098
INFO:root:current mean train loss 3566.1342595267815
INFO:root:current train perplexity4.078497886657715
INFO:root:current mean train loss 3571.151365176457
INFO:root:current train perplexity4.084162712097168
INFO:root:current mean train loss 3571.8139002690727
INFO:root:current train perplexity4.086550235748291
INFO:root:current mean train loss 3571.4639403994347
INFO:root:current train perplexity4.086028575897217
INFO:root:current mean train loss 3570.3143274208414
INFO:root:current train perplexity4.085464000701904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.67s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it]
INFO:root:eval mean loss: 3989.8443577543217
INFO:root:eval perplexity: 5.019728660583496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:17:45<8:51:38, 259.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.644222005208
INFO:root:current train perplexity4.005002021789551
INFO:root:current mean train loss 3555.194091796875
INFO:root:current train perplexity4.049761772155762
INFO:root:current mean train loss 3560.1847599473112
INFO:root:current train perplexity4.0563812255859375
INFO:root:current mean train loss 3556.4122093563988
INFO:root:current train perplexity4.057456016540527
INFO:root:current mean train loss 3560.806074101092
INFO:root:current train perplexity4.0667805671691895
INFO:root:current mean train loss 3561.8478235929915
INFO:root:current train perplexity4.0696563720703125
INFO:root:current mean train loss 3559.1322376778458
INFO:root:current train perplexity4.067763328552246
INFO:root:current mean train loss 3562.509956157124
INFO:root:current train perplexity4.072768688201904
INFO:root:current mean train loss 3563.6178821774347
INFO:root:current train perplexity4.075399398803711
INFO:root:current mean train loss 3564.9962143528005
INFO:root:current train perplexity4.076874256134033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it]
INFO:root:eval mean loss: 3991.803896207336
INFO:root:eval perplexity: 5.023708343505859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:22:12<8:51:52, 261.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3558.0134065047555
INFO:root:current train perplexity4.070623874664307
INFO:root:current mean train loss 3547.626784409934
INFO:root:current train perplexity4.0608625411987305
INFO:root:current mean train loss 3546.266729654218
INFO:root:current train perplexity4.062902927398682
INFO:root:current mean train loss 3549.8899636283377
INFO:root:current train perplexity4.05909538269043
INFO:root:current mean train loss 3549.93405317302
INFO:root:current train perplexity4.059292793273926
INFO:root:current mean train loss 3549.12372468033
INFO:root:current train perplexity4.0611677169799805
INFO:root:current mean train loss 3554.187846029168
INFO:root:current train perplexity4.063763618469238
INFO:root:current mean train loss 3554.507764887513
INFO:root:current train perplexity4.062726974487305
INFO:root:current mean train loss 3556.687444526978
INFO:root:current train perplexity4.063440322875977
INFO:root:current mean train loss 3557.6007009983578
INFO:root:current train perplexity4.067669868469238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.81s/it]
INFO:root:eval mean loss: 3991.9109942929963
INFO:root:eval perplexity: 5.023926258087158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:26:47<8:55:32, 265.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3542.7366116431454
INFO:root:current train perplexity4.030938148498535
INFO:root:current mean train loss 3549.546054985687
INFO:root:current train perplexity4.049332141876221
INFO:root:current mean train loss 3554.491903197714
INFO:root:current train perplexity4.050571918487549
INFO:root:current mean train loss 3559.3577036324587
INFO:root:current train perplexity4.054497718811035
INFO:root:current mean train loss 3557.038388422636
INFO:root:current train perplexity4.059039115905762
INFO:root:current mean train loss 3556.257472726136
INFO:root:current train perplexity4.061705589294434
INFO:root:current mean train loss 3555.7308831313144
INFO:root:current train perplexity4.060794830322266
INFO:root:current mean train loss 3554.577816734888
INFO:root:current train perplexity4.059535503387451
INFO:root:current mean train loss 3557.9453465797983
INFO:root:current train perplexity4.064164638519287
INFO:root:current mean train loss 3554.383421409271
INFO:root:current train perplexity4.062141418457031


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:36<00:00, 216.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.92s/it]
INFO:root:eval mean loss: 3991.8732096354165
INFO:root:eval perplexity: 5.023848533630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:31:28<9:00:58, 270.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3509.2374048477564
INFO:root:current train perplexity4.053303241729736
INFO:root:current mean train loss 3525.3680692165017
INFO:root:current train perplexity4.023242473602295
INFO:root:current mean train loss 3527.8718435375263
INFO:root:current train perplexity4.023177623748779
INFO:root:current mean train loss 3533.314377506222
INFO:root:current train perplexity4.02349853515625
INFO:root:current mean train loss 3535.2894356625497
INFO:root:current train perplexity4.034246444702148
INFO:root:current mean train loss 3535.820183861897
INFO:root:current train perplexity4.036717891693115
INFO:root:current mean train loss 3542.6420099918087
INFO:root:current train perplexity4.043046951293945
INFO:root:current mean train loss 3544.753461577089
INFO:root:current train perplexity4.0475544929504395
INFO:root:current mean train loss 3546.4542988537323
INFO:root:current train perplexity4.049379348754883
INFO:root:current mean train loss 3546.1837817304813
INFO:root:current train perplexity4.048575401306152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it]
INFO:root:eval mean loss: 3993.3016868212544
INFO:root:eval perplexity: 5.026751518249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [5:36:03<8:59:08, 271.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3543.5135264295213
INFO:root:current train perplexity4.0709662437438965
INFO:root:current mean train loss 3554.767199457908
INFO:root:current train perplexity4.051789283752441
INFO:root:current mean train loss 3539.051866539094
INFO:root:current train perplexity4.03623104095459
INFO:root:current mean train loss 3535.770932771974
INFO:root:current train perplexity4.030986785888672
INFO:root:current mean train loss 3542.398189536144
INFO:root:current train perplexity4.032769680023193
INFO:root:current mean train loss 3536.8820881120027
INFO:root:current train perplexity4.032977104187012
INFO:root:current mean train loss 3539.3196317740535
INFO:root:current train perplexity4.035715579986572
INFO:root:current mean train loss 3542.614967683233
INFO:root:current train perplexity4.0362396240234375
INFO:root:current mean train loss 3545.2455028547447
INFO:root:current train perplexity4.039678573608398
INFO:root:current mean train loss 3542.6441886281514
INFO:root:current train perplexity4.041895389556885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it]
INFO:root:eval mean loss: 3995.8395009142287
INFO:root:eval perplexity: 5.0319132804870605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [5:40:29<8:50:58, 269.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3537.1044167258524
INFO:root:current train perplexity4.025666236877441
INFO:root:current mean train loss 3526.447820060484
INFO:root:current train perplexity4.016724586486816
INFO:root:current mean train loss 3523.7494638480393
INFO:root:current train perplexity4.016380786895752
INFO:root:current mean train loss 3529.395643981074
INFO:root:current train perplexity4.026614665985107
INFO:root:current mean train loss 3526.9837305760648
INFO:root:current train perplexity4.030660152435303
INFO:root:current mean train loss 3529.985033519848
INFO:root:current train perplexity4.031294345855713
INFO:root:current mean train loss 3531.2765546725905
INFO:root:current train perplexity4.030979156494141
INFO:root:current mean train loss 3533.6404368015315
INFO:root:current train perplexity4.030894756317139
INFO:root:current mean train loss 3534.4757940995064
INFO:root:current train perplexity4.029769420623779
INFO:root:current mean train loss 3537.308647435373
INFO:root:current train perplexity4.031754016876221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.42s/it]
INFO:root:eval mean loss: 3995.974467392509
INFO:root:eval perplexity: 5.032187461853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [5:44:54<8:43:13, 268.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.183907645089
INFO:root:current train perplexity3.9870424270629883
INFO:root:current mean train loss 3527.030969912289
INFO:root:current train perplexity4.007184028625488
INFO:root:current mean train loss 3518.990411678648
INFO:root:current train perplexity4.015113353729248
INFO:root:current mean train loss 3518.299416618242
INFO:root:current train perplexity4.015424728393555
INFO:root:current mean train loss 3521.1668782903616
INFO:root:current train perplexity4.0129899978637695
INFO:root:current mean train loss 3523.339884512378
INFO:root:current train perplexity4.016310691833496
INFO:root:current mean train loss 3527.7146099199895
INFO:root:current train perplexity4.020207405090332
INFO:root:current mean train loss 3530.709049009871
INFO:root:current train perplexity4.023496150970459
INFO:root:current mean train loss 3530.046583898374
INFO:root:current train perplexity4.021878242492676
INFO:root:current mean train loss 3529.8467630958753
INFO:root:current train perplexity4.021832466125488


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]
INFO:root:eval mean loss: 3997.7703260056514
INFO:root:eval perplexity: 5.035842418670654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [5:48:42<8:15:29, 256.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.475331481074
INFO:root:current train perplexity3.988111972808838
INFO:root:current mean train loss 3508.055298565424
INFO:root:current train perplexity3.99188494682312
INFO:root:current mean train loss 3504.7176229892184
INFO:root:current train perplexity3.9914698600769043
INFO:root:current mean train loss 3508.496464896395
INFO:root:current train perplexity3.9991116523742676
INFO:root:current mean train loss 3511.131830235702
INFO:root:current train perplexity3.998826742172241
INFO:root:current mean train loss 3516.5761487863947
INFO:root:current train perplexity4.0025811195373535
INFO:root:current mean train loss 3521.026069925368
INFO:root:current train perplexity4.0072712898254395
INFO:root:current mean train loss 3525.3275607216683
INFO:root:current train perplexity4.009839057922363
INFO:root:current mean train loss 3525.747648289502
INFO:root:current train perplexity4.011999130249023
INFO:root:current mean train loss 3524.680735972097
INFO:root:current train perplexity4.012936115264893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it]
INFO:root:eval mean loss: 3996.7672958915114
INFO:root:eval perplexity: 5.033801078796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [5:52:56<8:10:12, 255.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.628764092168
INFO:root:current train perplexity4.000749588012695
INFO:root:current mean train loss 3502.6376162054817
INFO:root:current train perplexity3.999825954437256
INFO:root:current mean train loss 3515.721442547323
INFO:root:current train perplexity4.002077102661133
INFO:root:current mean train loss 3518.542513321446
INFO:root:current train perplexity3.9989564418792725
INFO:root:current mean train loss 3517.6841977304607
INFO:root:current train perplexity3.999340534210205
INFO:root:current mean train loss 3516.654689861291
INFO:root:current train perplexity4.0016350746154785
INFO:root:current mean train loss 3514.491882953447
INFO:root:current train perplexity4.001264572143555
INFO:root:current mean train loss 3516.9143806036386
INFO:root:current train perplexity4.002167224884033
INFO:root:current mean train loss 3518.6427589390464
INFO:root:current train perplexity4.002568244934082
INFO:root:current mean train loss 3518.833402826545
INFO:root:current train perplexity4.002213954925537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.49s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it]
INFO:root:eval mean loss: 3999.297571060505
INFO:root:eval perplexity: 5.038954734802246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [5:57:21<8:10:52, 258.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3482.4511129445045
INFO:root:current train perplexity3.9692606925964355
INFO:root:current mean train loss 3489.7364364868818
INFO:root:current train perplexity3.972694158554077
INFO:root:current mean train loss 3493.1341454907993
INFO:root:current train perplexity3.987025022506714
INFO:root:current mean train loss 3497.4065067577117
INFO:root:current train perplexity3.986168146133423
INFO:root:current mean train loss 3501.0213961434806
INFO:root:current train perplexity3.986260175704956
INFO:root:current mean train loss 3507.3248575915673
INFO:root:current train perplexity3.990354299545288
INFO:root:current mean train loss 3507.6698181063502
INFO:root:current train perplexity3.989786386489868
INFO:root:current mean train loss 3510.4639013113483
INFO:root:current train perplexity3.9935545921325684
INFO:root:current mean train loss 3511.323749735767
INFO:root:current train perplexity3.993382692337036
INFO:root:current mean train loss 3512.4456758663405
INFO:root:current train perplexity3.9934189319610596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it]
INFO:root:eval mean loss: 4000.12367194426
INFO:root:eval perplexity: 5.040638446807861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [6:01:09<7:49:39, 249.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.694621196546
INFO:root:current train perplexity3.9531102180480957
INFO:root:current mean train loss 3511.533251953125
INFO:root:current train perplexity3.972723960876465
INFO:root:current mean train loss 3509.5874387579447
INFO:root:current train perplexity3.9785680770874023
INFO:root:current mean train loss 3501.178572488133
INFO:root:current train perplexity3.9746007919311523
INFO:root:current mean train loss 3500.956128176294
INFO:root:current train perplexity3.9745030403137207
INFO:root:current mean train loss 3502.8712915244223
INFO:root:current train perplexity3.9729740619659424
INFO:root:current mean train loss 3502.2764311207284
INFO:root:current train perplexity3.9753456115722656
INFO:root:current mean train loss 3503.135585568986
INFO:root:current train perplexity3.9784622192382812
INFO:root:current mean train loss 3505.520167925105
INFO:root:current train perplexity3.9827463626861572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.07s/it]
INFO:root:eval mean loss: 4000.0431678717864
INFO:root:eval perplexity: 5.0404744148254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [6:04:52<7:30:25, 241.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.8715006510415
INFO:root:current train perplexity4.085763931274414
INFO:root:current mean train loss 3512.430827613016
INFO:root:current train perplexity3.977219343185425
INFO:root:current mean train loss 3497.133720510699
INFO:root:current train perplexity3.962573289871216
INFO:root:current mean train loss 3490.597394382993
INFO:root:current train perplexity3.9544665813446045
INFO:root:current mean train loss 3497.024803597046
INFO:root:current train perplexity3.9666543006896973
INFO:root:current mean train loss 3497.9787641339462
INFO:root:current train perplexity3.970853805541992
INFO:root:current mean train loss 3499.082019508577
INFO:root:current train perplexity3.97027587890625
INFO:root:current mean train loss 3495.7932806109975
INFO:root:current train perplexity3.969529390335083
INFO:root:current mean train loss 3498.6031073051254
INFO:root:current train perplexity3.9707694053649902
INFO:root:current mean train loss 3499.8340352038344
INFO:root:current train perplexity3.975931406021118


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.62s/it]
INFO:root:eval mean loss: 4002.9991481050533
INFO:root:eval perplexity: 5.046502113342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [6:08:35<7:16:17, 235.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.4161265980115
INFO:root:current train perplexity3.919748306274414
INFO:root:current mean train loss 3485.7825498838683
INFO:root:current train perplexity3.955787420272827
INFO:root:current mean train loss 3483.420515449126
INFO:root:current train perplexity3.9550936222076416
INFO:root:current mean train loss 3481.179849213726
INFO:root:current train perplexity3.955080986022949
INFO:root:current mean train loss 3479.615318725289
INFO:root:current train perplexity3.9487555027008057
INFO:root:current mean train loss 3482.1287872851944
INFO:root:current train perplexity3.95082426071167
INFO:root:current mean train loss 3483.7974851517747
INFO:root:current train perplexity3.956489086151123
INFO:root:current mean train loss 3490.202728056874
INFO:root:current train perplexity3.9586758613586426
INFO:root:current mean train loss 3490.8083881420507
INFO:root:current train perplexity3.9613046646118164
INFO:root:current mean train loss 3493.233517157914
INFO:root:current train perplexity3.964585781097412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.07s/it]
INFO:root:eval mean loss: 4004.486664034796
INFO:root:eval perplexity: 5.049538612365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [6:12:25<7:09:06, 234.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.5831620065787
INFO:root:current train perplexity3.9772872924804688
INFO:root:current mean train loss 3481.0765534729517
INFO:root:current train perplexity3.9323019981384277
INFO:root:current mean train loss 3498.1967572773974
INFO:root:current train perplexity3.9454362392425537
INFO:root:current mean train loss 3494.467231583072
INFO:root:current train perplexity3.951293468475342
INFO:root:current mean train loss 3495.3778265541096
INFO:root:current train perplexity3.95082950592041
INFO:root:current mean train loss 3492.858461471881
INFO:root:current train perplexity3.9507522583007812
INFO:root:current mean train loss 3489.5565301898223
INFO:root:current train perplexity3.9516353607177734
INFO:root:current mean train loss 3486.42002306263
INFO:root:current train perplexity3.954989433288574
INFO:root:current mean train loss 3487.755324292678
INFO:root:current train perplexity3.956435203552246
INFO:root:current mean train loss 3491.5078767894793
INFO:root:current train perplexity3.9596645832061768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.68s/it]
INFO:root:eval mean loss: 4002.66800511137
INFO:root:eval perplexity: 5.045825958251953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:16:18<7:04:42, 233.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.247748480903
INFO:root:current train perplexity3.960158348083496
INFO:root:current mean train loss 3475.6147499384842
INFO:root:current train perplexity3.9399592876434326
INFO:root:current mean train loss 3475.780514351597
INFO:root:current train perplexity3.9445323944091797
INFO:root:current mean train loss 3477.666801802609
INFO:root:current train perplexity3.944037437438965
INFO:root:current mean train loss 3471.698344532165
INFO:root:current train perplexity3.9409804344177246
INFO:root:current mean train loss 3477.0948057808055
INFO:root:current train perplexity3.9449501037597656
INFO:root:current mean train loss 3479.7002615069277
INFO:root:current train perplexity3.9446961879730225
INFO:root:current mean train loss 3482.7874747463893
INFO:root:current train perplexity3.947918653488159
INFO:root:current mean train loss 3483.1584632070926
INFO:root:current train perplexity3.9493541717529297
INFO:root:current mean train loss 3483.271329778941
INFO:root:current train perplexity3.9492013454437256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it]
INFO:root:eval mean loss: 4004.1407496675533
INFO:root:eval perplexity: 5.048832893371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:20:33<7:12:31, 240.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3463.459912109375
INFO:root:current train perplexity3.9259676933288574
INFO:root:current mean train loss 3469.969059244792
INFO:root:current train perplexity3.9274749755859375
INFO:root:current mean train loss 3477.056793342753
INFO:root:current train perplexity3.938141107559204
INFO:root:current mean train loss 3479.4932332964086
INFO:root:current train perplexity3.938960552215576
INFO:root:current mean train loss 3482.332590247845
INFO:root:current train perplexity3.9422755241394043
INFO:root:current mean train loss 3482.8262485397195
INFO:root:current train perplexity3.943528652191162
INFO:root:current mean train loss 3478.286736051304
INFO:root:current train perplexity3.937682628631592
INFO:root:current mean train loss 3475.735575773278
INFO:root:current train perplexity3.9370968341827393
INFO:root:current mean train loss 3477.8833118918415
INFO:root:current train perplexity3.9397127628326416
INFO:root:current mean train loss 3477.1141643340575
INFO:root:current train perplexity3.9385340213775635


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it]
INFO:root:eval mean loss: 4005.5332152454566
INFO:root:eval perplexity: 5.051676273345947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:24:57<7:20:51, 247.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.8660008630086
INFO:root:current train perplexity3.911627769470215
INFO:root:current mean train loss 3472.120359620848
INFO:root:current train perplexity3.910177230834961
INFO:root:current mean train loss 3463.4283040364585
INFO:root:current train perplexity3.9215104579925537
INFO:root:current mean train loss 3465.630902793595
INFO:root:current train perplexity3.9237029552459717
INFO:root:current mean train loss 3464.4885997901383
INFO:root:current train perplexity3.923187255859375
INFO:root:current mean train loss 3465.6854304248677
INFO:root:current train perplexity3.9248225688934326
INFO:root:current mean train loss 3467.5941129835733
INFO:root:current train perplexity3.929194927215576
INFO:root:current mean train loss 3473.0372943698476
INFO:root:current train perplexity3.9315671920776367
INFO:root:current mean train loss 3473.3734676772874
INFO:root:current train perplexity3.9325168132781982
INFO:root:current mean train loss 3473.895763862424
INFO:root:current train perplexity3.9332659244537354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it]
INFO:root:eval mean loss: 4006.927012342088
INFO:root:eval perplexity: 5.0545244216918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [6:29:20<7:25:22, 252.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3454.1949582567404
INFO:root:current train perplexity3.927896738052368
INFO:root:current mean train loss 3467.655140857823
INFO:root:current train perplexity3.920222282409668
INFO:root:current mean train loss 3471.0002100971114
INFO:root:current train perplexity3.926656484603882
INFO:root:current mean train loss 3469.6898328993057
INFO:root:current train perplexity3.915771245956421
INFO:root:current mean train loss 3466.885137519921
INFO:root:current train perplexity3.9164466857910156
INFO:root:current mean train loss 3469.7848168457917
INFO:root:current train perplexity3.9231503009796143
INFO:root:current mean train loss 3468.8657575334823
INFO:root:current train perplexity3.925386905670166
INFO:root:current mean train loss 3469.217610568721
INFO:root:current train perplexity3.924673318862915
INFO:root:current mean train loss 3469.4828840495557
INFO:root:current train perplexity3.926708936691284
INFO:root:current mean train loss 3470.681802615257
INFO:root:current train perplexity3.9295616149902344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]
INFO:root:eval mean loss: 4008.524027939384
INFO:root:eval perplexity: 5.057788848876953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [6:33:45<7:28:06, 256.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3425.88817117982
INFO:root:current train perplexity3.861605644226074
INFO:root:current mean train loss 3441.846840912441
INFO:root:current train perplexity3.8759186267852783
INFO:root:current mean train loss 3445.4796316964284
INFO:root:current train perplexity3.8849217891693115
INFO:root:current mean train loss 3454.7151728978065
INFO:root:current train perplexity3.8964669704437256
INFO:root:current mean train loss 3456.260022531148
INFO:root:current train perplexity3.900768280029297
INFO:root:current mean train loss 3461.042585724368
INFO:root:current train perplexity3.9055299758911133
INFO:root:current mean train loss 3461.293266608972
INFO:root:current train perplexity3.9094903469085693
INFO:root:current mean train loss 3464.4614971899705
INFO:root:current train perplexity3.9139254093170166
INFO:root:current mean train loss 3466.966264824651
INFO:root:current train perplexity3.9181034564971924
INFO:root:current mean train loss 3467.0988868816803
INFO:root:current train perplexity3.9195709228515625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it]
INFO:root:eval mean loss: 4008.9755824745125
INFO:root:eval perplexity: 5.058712959289551
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [6:38:09<7:27:30, 258.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3460.3458816756065
INFO:root:current train perplexity3.9346048831939697
INFO:root:current mean train loss 3457.5438897595436
INFO:root:current train perplexity3.91005802154541
INFO:root:current mean train loss 3462.7570233862943
INFO:root:current train perplexity3.9111170768737793
INFO:root:current mean train loss 3461.242057114271
INFO:root:current train perplexity3.9068164825439453
INFO:root:current mean train loss 3458.6664521505286
INFO:root:current train perplexity3.90604829788208
INFO:root:current mean train loss 3456.163368830605
INFO:root:current train perplexity3.905780076980591
INFO:root:current mean train loss 3457.697677406414
INFO:root:current train perplexity3.9065706729888916
INFO:root:current mean train loss 3455.7299413171245
INFO:root:current train perplexity3.908703327178955
INFO:root:current mean train loss 3459.7505102454584
INFO:root:current train perplexity3.911379098892212
INFO:root:current mean train loss 3459.4704408063762
INFO:root:current train perplexity3.9117960929870605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.67s/it]
INFO:root:eval mean loss: 4009.6765413757757
INFO:root:eval perplexity: 5.060147285461426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [6:42:35<7:27:17, 260.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3440.025322265625
INFO:root:current train perplexity3.9061198234558105
INFO:root:current mean train loss 3442.5632170758927
INFO:root:current train perplexity3.895785093307495
INFO:root:current mean train loss 3453.483622159091
INFO:root:current train perplexity3.8932344913482666
INFO:root:current mean train loss 3455.8959583333335
INFO:root:current train perplexity3.8924520015716553
INFO:root:current mean train loss 3453.5735372121712
INFO:root:current train perplexity3.8959221839904785
INFO:root:current mean train loss 3449.273384425951
INFO:root:current train perplexity3.897158622741699
INFO:root:current mean train loss 3453.5555063657407
INFO:root:current train perplexity3.898667812347412
INFO:root:current mean train loss 3452.3094776965727
INFO:root:current train perplexity3.8988258838653564
INFO:root:current mean train loss 3453.034296316964
INFO:root:current train perplexity3.8989439010620117
INFO:root:current mean train loss 3452.1984189703526
INFO:root:current train perplexity3.9010839462280273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it]
INFO:root:eval mean loss: 4009.426937887855
INFO:root:eval perplexity: 5.059637069702148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [6:47:00<7:25:34, 262.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.5950883612577
INFO:root:current train perplexity3.8800604343414307
INFO:root:current mean train loss 3436.371291197063
INFO:root:current train perplexity3.8881585597991943
INFO:root:current mean train loss 3448.7431131639246
INFO:root:current train perplexity3.887026309967041
INFO:root:current mean train loss 3450.108744568987
INFO:root:current train perplexity3.885613441467285
INFO:root:current mean train loss 3449.814337373027
INFO:root:current train perplexity3.888266086578369
INFO:root:current mean train loss 3448.5633027745766
INFO:root:current train perplexity3.8888227939605713
INFO:root:current mean train loss 3449.5576943974193
INFO:root:current train perplexity3.891679525375366
INFO:root:current mean train loss 3447.615926886275
INFO:root:current train perplexity3.8917579650878906
INFO:root:current mean train loss 3448.9088415402925
INFO:root:current train perplexity3.8925936222076416
INFO:root:current mean train loss 3449.4160340038466
INFO:root:current train perplexity3.895089864730835


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.86s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it]
INFO:root:eval mean loss: 4013.869899019282
INFO:root:eval perplexity: 5.068734645843506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [6:51:23<7:21:41, 262.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.8915586366757
INFO:root:current train perplexity3.8462796211242676
INFO:root:current mean train loss 3430.6600833912794
INFO:root:current train perplexity3.8579604625701904
INFO:root:current mean train loss 3435.635514826299
INFO:root:current train perplexity3.870980739593506
INFO:root:current mean train loss 3441.2606248001916
INFO:root:current train perplexity3.879197835922241
INFO:root:current mean train loss 3441.117367000541
INFO:root:current train perplexity3.8799571990966797
INFO:root:current mean train loss 3440.895497071965
INFO:root:current train perplexity3.878953218460083
INFO:root:current mean train loss 3441.982799921988
INFO:root:current train perplexity3.880983591079712
INFO:root:current mean train loss 3443.218154309221
INFO:root:current train perplexity3.883880853652954
INFO:root:current mean train loss 3441.4528652409513
INFO:root:current train perplexity3.8844385147094727
INFO:root:current mean train loss 3445.504623890404
INFO:root:current train perplexity3.889554977416992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.32s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.17s/it]
INFO:root:eval mean loss: 4012.6245896359706
INFO:root:eval perplexity: 5.066182613372803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [6:55:52<7:20:27, 264.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.314327355587
INFO:root:current train perplexity3.8411943912506104
INFO:root:current mean train loss 3420.7898489027166
INFO:root:current train perplexity3.864191770553589
INFO:root:current mean train loss 3425.691133531041
INFO:root:current train perplexity3.86837100982666
INFO:root:current mean train loss 3424.397161727561
INFO:root:current train perplexity3.8662779331207275
INFO:root:current mean train loss 3429.7270992179674
INFO:root:current train perplexity3.8685312271118164
INFO:root:current mean train loss 3432.420204328177
INFO:root:current train perplexity3.8728325366973877
INFO:root:current mean train loss 3437.2201781702656
INFO:root:current train perplexity3.8766658306121826
INFO:root:current mean train loss 3441.376136369192
INFO:root:current train perplexity3.8803164958953857
INFO:root:current mean train loss 3441.0606832026906
INFO:root:current train perplexity3.881805896759033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.14s/it]
INFO:root:eval mean loss: 4014.686868004765
INFO:root:eval perplexity: 5.070409297943115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [7:00:17<7:16:27, 264.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3380.9137834821427
INFO:root:current train perplexity3.8357925415039062
INFO:root:current mean train loss 3448.5297965646905
INFO:root:current train perplexity3.8636090755462646
INFO:root:current mean train loss 3439.173828125
INFO:root:current train perplexity3.8619747161865234
INFO:root:current mean train loss 3431.0092852962134
INFO:root:current train perplexity3.8678250312805176
INFO:root:current mean train loss 3436.8062327242014
INFO:root:current train perplexity3.8710222244262695
INFO:root:current mean train loss 3435.7963761248766
INFO:root:current train perplexity3.872692584991455
INFO:root:current mean train loss 3433.8706448851935
INFO:root:current train perplexity3.869006633758545
INFO:root:current mean train loss 3432.677678087982
INFO:root:current train perplexity3.8693621158599854
INFO:root:current mean train loss 3434.347545827041
INFO:root:current train perplexity3.872175931930542
INFO:root:current mean train loss 3433.8319063533627
INFO:root:current train perplexity3.873467445373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.38s/it]
INFO:root:eval mean loss: 4017.5645777925533
INFO:root:eval perplexity: 5.076313495635986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [7:04:45<7:13:32, 265.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3402.53759765625
INFO:root:current train perplexity3.8042166233062744
INFO:root:current mean train loss 3411.5198136039403
INFO:root:current train perplexity3.824010133743286
INFO:root:current mean train loss 3410.3711119186046
INFO:root:current train perplexity3.8344626426696777
INFO:root:current mean train loss 3426.510544549851
INFO:root:current train perplexity3.8510234355926514
INFO:root:current mean train loss 3432.0094002964984
INFO:root:current train perplexity3.856212854385376
INFO:root:current mean train loss 3427.747140473301
INFO:root:current train perplexity3.8539328575134277
INFO:root:current mean train loss 3428.3559173335875
INFO:root:current train perplexity3.8556175231933594
INFO:root:current mean train loss 3426.5196319793486
INFO:root:current train perplexity3.857968807220459
INFO:root:current mean train loss 3426.709165608225
INFO:root:current train perplexity3.8607020378112793
INFO:root:current mean train loss 3427.91578295765
INFO:root:current train perplexity3.8633456230163574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.40s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.13s/it]
INFO:root:eval mean loss: 4017.14394254211
INFO:root:eval perplexity: 5.0754499435424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [7:08:34<6:51:38, 254.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.8319038722825
INFO:root:current train perplexity3.803658962249756
INFO:root:current mean train loss 3409.2380708523883
INFO:root:current train perplexity3.822310209274292
INFO:root:current mean train loss 3413.431052716858
INFO:root:current train perplexity3.83396315574646
INFO:root:current mean train loss 3410.6783050442627
INFO:root:current train perplexity3.835188627243042
INFO:root:current mean train loss 3411.1803991439497
INFO:root:current train perplexity3.8396685123443604
INFO:root:current mean train loss 3416.077744084608
INFO:root:current train perplexity3.848647117614746
INFO:root:current mean train loss 3420.1088197074387
INFO:root:current train perplexity3.853914976119995
INFO:root:current mean train loss 3422.847248335927
INFO:root:current train perplexity3.8587238788604736
INFO:root:current mean train loss 3423.546181438905
INFO:root:current train perplexity3.8586466312408447
INFO:root:current mean train loss 3424.0257445363286
INFO:root:current train perplexity3.8570077419281006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it]
INFO:root:eval mean loss: 4015.823275085882
INFO:root:eval perplexity: 5.07274055480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [7:12:59<6:52:17, 257.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3367.0997117565526
INFO:root:current train perplexity3.8015103340148926
INFO:root:current mean train loss 3389.0446702796994
INFO:root:current train perplexity3.816143274307251
INFO:root:current mean train loss 3387.3129935656793
INFO:root:current train perplexity3.8255276679992676
INFO:root:current mean train loss 3396.3904686319866
INFO:root:current train perplexity3.833815813064575
INFO:root:current mean train loss 3398.754396230605
INFO:root:current train perplexity3.8350117206573486
INFO:root:current mean train loss 3404.8388009798728
INFO:root:current train perplexity3.8393819332122803
INFO:root:current mean train loss 3410.9473240485095
INFO:root:current train perplexity3.8435308933258057
INFO:root:current mean train loss 3414.211447156079
INFO:root:current train perplexity3.8470494747161865
INFO:root:current mean train loss 3419.988489254287
INFO:root:current train perplexity3.8525006771087646
INFO:root:current mean train loss 3419.834137257905
INFO:root:current train perplexity3.8507471084594727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it]
INFO:root:eval mean loss: 4018.385785474845
INFO:root:eval perplexity: 5.077998161315918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [7:17:29<6:53:56, 261.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.3817545572915
INFO:root:current train perplexity3.8393619060516357
INFO:root:current mean train loss 3417.9287636297213
INFO:root:current train perplexity3.8419816493988037
INFO:root:current mean train loss 3410.9885570574006
INFO:root:current train perplexity3.840540647506714
INFO:root:current mean train loss 3421.7101733902564
INFO:root:current train perplexity3.844385862350464
INFO:root:current mean train loss 3417.3447482515303
INFO:root:current train perplexity3.8403303623199463
INFO:root:current mean train loss 3416.6114323037455
INFO:root:current train perplexity3.8407740592956543
INFO:root:current mean train loss 3419.2410306020147
INFO:root:current train perplexity3.842088222503662
INFO:root:current mean train loss 3420.358451626459
INFO:root:current train perplexity3.84409499168396
INFO:root:current mean train loss 3417.671142287135
INFO:root:current train perplexity3.8430933952331543
INFO:root:current mean train loss 3416.9899962143904
INFO:root:current train perplexity3.8444440364837646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it]
INFO:root:eval mean loss: 4022.045846492686
INFO:root:eval perplexity: 5.085519790649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [7:22:00<6:54:12, 264.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.8778517702794
INFO:root:current train perplexity3.8050780296325684
INFO:root:current mean train loss 3390.6458715322065
INFO:root:current train perplexity3.824859142303467
INFO:root:current mean train loss 3392.3147031961666
INFO:root:current train perplexity3.821113348007202
INFO:root:current mean train loss 3396.547501885582
INFO:root:current train perplexity3.8276071548461914
INFO:root:current mean train loss 3401.1435934659885
INFO:root:current train perplexity3.8245818614959717
INFO:root:current mean train loss 3406.940374789334
INFO:root:current train perplexity3.828716993331909
INFO:root:current mean train loss 3409.3051259720346
INFO:root:current train perplexity3.8312337398529053
INFO:root:current mean train loss 3408.087117022779
INFO:root:current train perplexity3.83181095123291
INFO:root:current mean train loss 3411.1195545399205
INFO:root:current train perplexity3.8370447158813477
INFO:root:current mean train loss 3411.029011227891
INFO:root:current train perplexity3.8379647731781006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.25s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.16s/it]
INFO:root:eval mean loss: 4022.534084455341
INFO:root:eval perplexity: 5.08652400970459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [7:26:28<6:51:23, 265.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3392.6104936079546
INFO:root:current train perplexity3.8161773681640625
INFO:root:current mean train loss 3399.5808546496974
INFO:root:current train perplexity3.816638708114624
INFO:root:current mean train loss 3392.395220588235
INFO:root:current train perplexity3.817758083343506
INFO:root:current mean train loss 3401.0873012488996
INFO:root:current train perplexity3.8223488330841064
INFO:root:current mean train loss 3404.192765388908
INFO:root:current train perplexity3.82059907913208
INFO:root:current mean train loss 3402.9218367293074
INFO:root:current train perplexity3.8244779109954834
INFO:root:current mean train loss 3403.3248326425332
INFO:root:current train perplexity3.827406883239746
INFO:root:current mean train loss 3406.3145957289944
INFO:root:current train perplexity3.827000856399536
INFO:root:current mean train loss 3405.4247695655154
INFO:root:current train perplexity3.8266966342926025
INFO:root:current mean train loss 3408.320874662549
INFO:root:current train perplexity3.8317222595214844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]
INFO:root:eval mean loss: 4022.4682842281695
INFO:root:eval perplexity: 5.086388111114502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [7:30:39<6:40:00, 260.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3351.5560399615574
INFO:root:current train perplexity3.8087549209594727
INFO:root:current mean train loss 3374.4175239048122
INFO:root:current train perplexity3.818946123123169
INFO:root:current mean train loss 3381.040193158864
INFO:root:current train perplexity3.8126039505004883
INFO:root:current mean train loss 3388.6503179881197
INFO:root:current train perplexity3.818403482437134
INFO:root:current mean train loss 3393.5611643451334
INFO:root:current train perplexity3.814112663269043
INFO:root:current mean train loss 3397.268398142623
INFO:root:current train perplexity3.817687749862671
INFO:root:current mean train loss 3399.956523083993
INFO:root:current train perplexity3.8186490535736084
INFO:root:current mean train loss 3400.6683498397565
INFO:root:current train perplexity3.8193118572235107
INFO:root:current mean train loss 3400.974789580768
INFO:root:current train perplexity3.822101593017578
INFO:root:current mean train loss 3402.7617347218165
INFO:root:current train perplexity3.825087547302246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it]
INFO:root:eval mean loss: 4024.1896435893173
INFO:root:eval perplexity: 5.089929580688477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [7:35:11<6:40:49, 264.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3376.1835490481953
INFO:root:current train perplexity3.7848527431488037
INFO:root:current mean train loss 3373.9612744426167
INFO:root:current train perplexity3.7970328330993652
INFO:root:current mean train loss 3377.1150244681157
INFO:root:current train perplexity3.800215721130371
INFO:root:current mean train loss 3382.616702509055
INFO:root:current train perplexity3.797353744506836
INFO:root:current mean train loss 3386.2938338682657
INFO:root:current train perplexity3.8054323196411133
INFO:root:current mean train loss 3390.519551773205
INFO:root:current train perplexity3.8122940063476562
INFO:root:current mean train loss 3392.271764172527
INFO:root:current train perplexity3.8141002655029297
INFO:root:current mean train loss 3394.2148348836736
INFO:root:current train perplexity3.8150317668914795
INFO:root:current mean train loss 3395.721072279079
INFO:root:current train perplexity3.8162894248962402
INFO:root:current mean train loss 3398.254292198362
INFO:root:current train perplexity3.819439172744751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.92s/it]
INFO:root:eval mean loss: 4026.6836751302085
INFO:root:eval perplexity: 5.095066070556641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [7:38:59<6:20:07, 253.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3381.8090480369856
INFO:root:current train perplexity3.7846620082855225
INFO:root:current mean train loss 3387.658945094274
INFO:root:current train perplexity3.789860248565674
INFO:root:current mean train loss 3395.5877628668236
INFO:root:current train perplexity3.804640293121338
INFO:root:current mean train loss 3398.327065983674
INFO:root:current train perplexity3.8106260299682617
INFO:root:current mean train loss 3399.22222862164
INFO:root:current train perplexity3.8070621490478516
INFO:root:current mean train loss 3395.148421055295
INFO:root:current train perplexity3.803097724914551
INFO:root:current mean train loss 3395.731297174153
INFO:root:current train perplexity3.804405927658081
INFO:root:current mean train loss 3392.644774450417
INFO:root:current train perplexity3.8059041500091553
INFO:root:current mean train loss 3392.4926330080348
INFO:root:current train perplexity3.809593677520752
INFO:root:current mean train loss 3394.360738845841
INFO:root:current train perplexity3.812459707260132


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it]
INFO:root:eval mean loss: 4025.1856247922206
INFO:root:eval perplexity: 5.091980934143066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [7:42:40<6:01:42, 243.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3393.520889457615
INFO:root:current train perplexity3.7889750003814697
INFO:root:current mean train loss 3389.0272249436
INFO:root:current train perplexity3.7915737628936768
INFO:root:current mean train loss 3388.347541410333
INFO:root:current train perplexity3.7981116771698
INFO:root:current mean train loss 3384.4997722615876
INFO:root:current train perplexity3.7925972938537598
INFO:root:current mean train loss 3384.0791562058844
INFO:root:current train perplexity3.7966580390930176
INFO:root:current mean train loss 3384.6693595613287
INFO:root:current train perplexity3.8002805709838867
INFO:root:current mean train loss 3388.6939087802493
INFO:root:current train perplexity3.8040266036987305
INFO:root:current mean train loss 3386.941903837754
INFO:root:current train perplexity3.8046875
INFO:root:current mean train loss 3388.9377303784704
INFO:root:current train perplexity3.8055121898651123
INFO:root:current mean train loss 3390.112582468576
INFO:root:current train perplexity3.8052468299865723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it]
INFO:root:eval mean loss: 4029.5475727919993
INFO:root:eval perplexity: 5.1009697914123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [7:47:04<6:06:10, 249.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.844731702303
INFO:root:current train perplexity3.778115749359131
INFO:root:current mean train loss 3357.5025503305287
INFO:root:current train perplexity3.783296585083008
INFO:root:current mean train loss 3366.0394299523305
INFO:root:current train perplexity3.7847368717193604
INFO:root:current mean train loss 3375.854333341574
INFO:root:current train perplexity3.7932677268981934
INFO:root:current mean train loss 3377.510118765783
INFO:root:current train perplexity3.7947680950164795
INFO:root:current mean train loss 3375.9535443474265
INFO:root:current train perplexity3.7928667068481445
INFO:root:current mean train loss 3379.7119853726394
INFO:root:current train perplexity3.796130418777466
INFO:root:current mean train loss 3382.6712896766903
INFO:root:current train perplexity3.798182725906372
INFO:root:current mean train loss 3383.9264441122555
INFO:root:current train perplexity3.799879312515259


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it]
INFO:root:eval mean loss: 4028.548802152593
INFO:root:eval perplexity: 5.098911285400391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [7:51:32<6:10:19, 255.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.5626627604165
INFO:root:current train perplexity3.7681734561920166
INFO:root:current mean train loss 3359.893353212227
INFO:root:current train perplexity3.7691516876220703
INFO:root:current mean train loss 3375.907289100985
INFO:root:current train perplexity3.7867348194122314
INFO:root:current mean train loss 3373.3994092280323
INFO:root:current train perplexity3.785252094268799
INFO:root:current mean train loss 3374.570522109569
INFO:root:current train perplexity3.7887210845947266
INFO:root:current mean train loss 3379.6614614073374
INFO:root:current train perplexity3.793339729309082
INFO:root:current mean train loss 3380.976275442449
INFO:root:current train perplexity3.7940104007720947
INFO:root:current mean train loss 3381.976354476907
INFO:root:current train perplexity3.795240879058838
INFO:root:current mean train loss 3385.0844635351805
INFO:root:current train perplexity3.798018455505371
INFO:root:current mean train loss 3383.7168271560076
INFO:root:current train perplexity3.795165777206421


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it]
INFO:root:eval mean loss: 4027.01234381926
INFO:root:eval perplexity: 5.095743656158447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [7:55:52<6:08:04, 256.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.384588068182
INFO:root:current train perplexity3.7709803581237793
INFO:root:current mean train loss 3366.604780317427
INFO:root:current train perplexity3.7925286293029785
INFO:root:current mean train loss 3361.5532133997335
INFO:root:current train perplexity3.784140110015869
INFO:root:current mean train loss 3372.262316148764
INFO:root:current train perplexity3.786266326904297
INFO:root:current mean train loss 3373.0002661192216
INFO:root:current train perplexity3.784832000732422
INFO:root:current mean train loss 3371.457018350202
INFO:root:current train perplexity3.7838382720947266
INFO:root:current mean train loss 3376.9469663429572
INFO:root:current train perplexity3.7830069065093994
INFO:root:current mean train loss 3375.8580736034196
INFO:root:current train perplexity3.783597946166992
INFO:root:current mean train loss 3374.0987773100337
INFO:root:current train perplexity3.7825751304626465
INFO:root:current mean train loss 3375.9885792569976
INFO:root:current train perplexity3.7844269275665283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it]
INFO:root:eval mean loss: 4030.462864652593
INFO:root:eval perplexity: 5.102858066558838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [8:00:22<6:09:03, 260.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.5718672902963
INFO:root:current train perplexity3.7272562980651855
INFO:root:current mean train loss 3339.8007750951942
INFO:root:current train perplexity3.7617688179016113
INFO:root:current mean train loss 3358.1270913598746
INFO:root:current train perplexity3.7688491344451904
INFO:root:current mean train loss 3365.0300201129016
INFO:root:current train perplexity3.772991180419922
INFO:root:current mean train loss 3365.178664906213
INFO:root:current train perplexity3.7700257301330566
INFO:root:current mean train loss 3368.3938171739524
INFO:root:current train perplexity3.771023988723755
INFO:root:current mean train loss 3370.2181863861824
INFO:root:current train perplexity3.7749454975128174
INFO:root:current mean train loss 3374.70002281815
INFO:root:current train perplexity3.778485059738159
INFO:root:current mean train loss 3375.5155886322877
INFO:root:current train perplexity3.780012845993042
INFO:root:current mean train loss 3373.633566174595
INFO:root:current train perplexity3.781862735748291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it]
INFO:root:eval mean loss: 4031.8477757230717
INFO:root:eval perplexity: 5.105716228485107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [8:04:53<6:09:06, 263.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3380.1804289641204
INFO:root:current train perplexity3.787006139755249
INFO:root:current mean train loss 3377.6332219641977
INFO:root:current train perplexity3.7750039100646973
INFO:root:current mean train loss 3374.3716637699613
INFO:root:current train perplexity3.7693066596984863
INFO:root:current mean train loss 3368.25112961702
INFO:root:current train perplexity3.768272876739502
INFO:root:current mean train loss 3372.3907519302547
INFO:root:current train perplexity3.7742035388946533
INFO:root:current mean train loss 3371.4120593423863
INFO:root:current train perplexity3.7723701000213623
INFO:root:current mean train loss 3371.6528670753587
INFO:root:current train perplexity3.7724361419677734
INFO:root:current mean train loss 3372.757382987126
INFO:root:current train perplexity3.775867223739624
INFO:root:current mean train loss 3371.8712416513945
INFO:root:current train perplexity3.7755625247955322
INFO:root:current mean train loss 3372.3682607179576
INFO:root:current train perplexity3.778846502304077


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.59s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.87s/it]
INFO:root:eval mean loss: 4032.2891023243574
INFO:root:eval perplexity: 5.106627941131592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [8:09:31<6:10:51, 268.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.822823660714
INFO:root:current train perplexity3.736363172531128
INFO:root:current mean train loss 3356.035579427083
INFO:root:current train perplexity3.7416789531707764
INFO:root:current mean train loss 3353.884011386303
INFO:root:current train perplexity3.7500650882720947
INFO:root:current mean train loss 3362.219544368004
INFO:root:current train perplexity3.7586276531219482
INFO:root:current mean train loss 3365.7943224676724
INFO:root:current train perplexity3.7617456912994385
INFO:root:current mean train loss 3366.046360251168
INFO:root:current train perplexity3.7635302543640137
INFO:root:current mean train loss 3366.094144469734
INFO:root:current train perplexity3.76762056350708
INFO:root:current mean train loss 3367.7273211628403
INFO:root:current train perplexity3.768054962158203
INFO:root:current mean train loss 3367.3853430833647
INFO:root:current train perplexity3.7693676948547363
INFO:root:current mean train loss 3367.309072631183
INFO:root:current train perplexity3.771350383758545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.86s/it]
INFO:root:eval mean loss: 4037.024483322252
INFO:root:eval perplexity: 5.116415977478027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [8:13:32<5:55:17, 259.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3366.251237736192
INFO:root:current train perplexity3.764028787612915
INFO:root:current mean train loss 3350.3861894940997
INFO:root:current train perplexity3.744326591491699
INFO:root:current mean train loss 3348.8465169270835
INFO:root:current train perplexity3.747990369796753
INFO:root:current mean train loss 3353.8792457691784
INFO:root:current train perplexity3.75173020362854
INFO:root:current mean train loss 3359.6664780041974
INFO:root:current train perplexity3.753060817718506
INFO:root:current mean train loss 3359.8044766308412
INFO:root:current train perplexity3.7537553310394287
INFO:root:current mean train loss 3361.8259721580966
INFO:root:current train perplexity3.7582547664642334
INFO:root:current mean train loss 3362.7105402375296
INFO:root:current train perplexity3.7607076168060303
INFO:root:current mean train loss 3361.897559404656
INFO:root:current train perplexity3.7653019428253174
INFO:root:current mean train loss 3362.5830210162876
INFO:root:current train perplexity3.7648370265960693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.49s/it]
INFO:root:eval mean loss: 4034.528590425532
INFO:root:eval perplexity: 5.111255645751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [8:17:52<5:50:50, 259.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.7290086933212
INFO:root:current train perplexity3.753685474395752
INFO:root:current mean train loss 3350.901140831954
INFO:root:current train perplexity3.748338460922241
INFO:root:current mean train loss 3348.231185609126
INFO:root:current train perplexity3.751922369003296
INFO:root:current mean train loss 3342.795819143964
INFO:root:current train perplexity3.750161647796631
INFO:root:current mean train loss 3344.696587877633
INFO:root:current train perplexity3.7501790523529053
INFO:root:current mean train loss 3349.9166027145247
INFO:root:current train perplexity3.7525603771209717
INFO:root:current mean train loss 3354.240950295819
INFO:root:current train perplexity3.7556724548339844
INFO:root:current mean train loss 3358.273163776423
INFO:root:current train perplexity3.75917911529541
INFO:root:current mean train loss 3357.820221843787
INFO:root:current train perplexity3.759780168533325
INFO:root:current mean train loss 3359.657521533665
INFO:root:current train perplexity3.760721445083618


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.08s/it]
INFO:root:eval mean loss: 4037.6616228252437
INFO:root:eval perplexity: 5.117734432220459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [8:22:16<5:48:08, 261.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.831936076536
INFO:root:current train perplexity3.7319064140319824
INFO:root:current mean train loss 3335.2484553115173
INFO:root:current train perplexity3.727527379989624
INFO:root:current mean train loss 3335.8380405028356
INFO:root:current train perplexity3.7240400314331055
INFO:root:current mean train loss 3342.2071767822945
INFO:root:current train perplexity3.7348246574401855
INFO:root:current mean train loss 3344.871164492273
INFO:root:current train perplexity3.7401154041290283
INFO:root:current mean train loss 3343.5850146571725
INFO:root:current train perplexity3.7438597679138184
INFO:root:current mean train loss 3349.356119297705
INFO:root:current train perplexity3.7481682300567627
INFO:root:current mean train loss 3352.683379202178
INFO:root:current train perplexity3.7520484924316406
INFO:root:current mean train loss 3354.396735905213
INFO:root:current train perplexity3.7525200843811035
INFO:root:current mean train loss 3354.2200951919317
INFO:root:current train perplexity3.752424716949463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it]
INFO:root:eval mean loss: 4038.2873985344636
INFO:root:eval perplexity: 5.119029521942139
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [8:26:43<5:46:11, 262.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.8757652168842
INFO:root:current train perplexity3.7520065307617188
INFO:root:current mean train loss 3346.010237825131
INFO:root:current train perplexity3.742475986480713
INFO:root:current mean train loss 3338.9858910492744
INFO:root:current train perplexity3.7313315868377686
INFO:root:current mean train loss 3338.5124684679413
INFO:root:current train perplexity3.7341110706329346
INFO:root:current mean train loss 3341.7886657061363
INFO:root:current train perplexity3.7323338985443115
INFO:root:current mean train loss 3341.677619839892
INFO:root:current train perplexity3.7335965633392334
INFO:root:current mean train loss 3345.3738923995033
INFO:root:current train perplexity3.736689329147339
INFO:root:current mean train loss 3345.540098904009
INFO:root:current train perplexity3.7382240295410156
INFO:root:current mean train loss 3347.638835480194
INFO:root:current train perplexity3.7402541637420654
INFO:root:current mean train loss 3350.3190425647945
INFO:root:current train perplexity3.7452476024627686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 14.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 14.00s/it]
INFO:root:eval mean loss: 4038.4150252105496
INFO:root:eval perplexity: 5.119293689727783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [8:31:10<5:43:23, 264.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.813515625
INFO:root:current train perplexity3.7296605110168457
INFO:root:current mean train loss 3332.579780970982
INFO:root:current train perplexity3.7409443855285645
INFO:root:current mean train loss 3341.13505859375
INFO:root:current train perplexity3.7429232597351074
INFO:root:current mean train loss 3342.408267578125
INFO:root:current train perplexity3.740089178085327
INFO:root:current mean train loss 3347.235186060855
INFO:root:current train perplexity3.744342803955078
INFO:root:current mean train loss 3347.701421110734
INFO:root:current train perplexity3.741342067718506
INFO:root:current mean train loss 3349.068093532986
INFO:root:current train perplexity3.742733955383301
INFO:root:current mean train loss 3349.6877784778226
INFO:root:current train perplexity3.7436187267303467
INFO:root:current mean train loss 3348.9723878348213
INFO:root:current train perplexity3.743868350982666
INFO:root:current mean train loss 3347.9932166466347
INFO:root:current train perplexity3.743072986602783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it]
INFO:root:eval mean loss: 4039.629851645612
INFO:root:eval perplexity: 5.121809005737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [8:35:35<5:39:24, 264.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.164953760354
INFO:root:current train perplexity3.72477650642395
INFO:root:current mean train loss 3314.426537685707
INFO:root:current train perplexity3.71807861328125
INFO:root:current mean train loss 3322.5897643827298
INFO:root:current train perplexity3.7197771072387695
INFO:root:current mean train loss 3332.367355147479
INFO:root:current train perplexity3.7289650440216064
INFO:root:current mean train loss 3335.6463211091163
INFO:root:current train perplexity3.734917163848877
INFO:root:current mean train loss 3344.3363194146655
INFO:root:current train perplexity3.736395835876465
INFO:root:current mean train loss 3347.0990528201637
INFO:root:current train perplexity3.738596200942993
INFO:root:current mean train loss 3344.8749510471544
INFO:root:current train perplexity3.734995126724243
INFO:root:current mean train loss 3344.9200534842157
INFO:root:current train perplexity3.7369885444641113
INFO:root:current mean train loss 3344.9846675713698
INFO:root:current train perplexity3.7382571697235107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4039.9527752382537
INFO:root:eval perplexity: 5.122478008270264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [8:40:00<5:34:59, 264.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.3560992230427
INFO:root:current train perplexity3.673815965652466
INFO:root:current mean train loss 3331.0145244498526
INFO:root:current train perplexity3.7123348712921143
INFO:root:current mean train loss 3334.72631500349
INFO:root:current train perplexity3.716984510421753
INFO:root:current mean train loss 3335.5542935032367
INFO:root:current train perplexity3.7157528400421143
INFO:root:current mean train loss 3334.7636112127675
INFO:root:current train perplexity3.717336654663086
INFO:root:current mean train loss 3336.709770912648
INFO:root:current train perplexity3.7223143577575684
INFO:root:current mean train loss 3338.1452103213187
INFO:root:current train perplexity3.7237656116485596
INFO:root:current mean train loss 3340.7097242044288
INFO:root:current train perplexity3.7247791290283203
INFO:root:current mean train loss 3339.675657946654
INFO:root:current train perplexity3.7285664081573486
INFO:root:current mean train loss 3339.300124952699
INFO:root:current train perplexity3.7299747467041016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.88s/it]
INFO:root:eval mean loss: 4041.225450880984
INFO:root:eval perplexity: 5.125115394592285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [8:44:03<5:22:51, 258.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.7869219539143
INFO:root:current train perplexity3.7248618602752686
INFO:root:current mean train loss 3328.00551708739
INFO:root:current train perplexity3.721221923828125
INFO:root:current mean train loss 3331.944848714465
INFO:root:current train perplexity3.7233469486236572
INFO:root:current mean train loss 3332.2990924577066
INFO:root:current train perplexity3.7231578826904297
INFO:root:current mean train loss 3332.430907713865
INFO:root:current train perplexity3.7214345932006836
INFO:root:current mean train loss 3333.7949842347925
INFO:root:current train perplexity3.720381021499634
INFO:root:current mean train loss 3333.170868749441
INFO:root:current train perplexity3.7217538356781006
INFO:root:current mean train loss 3336.1437841613542
INFO:root:current train perplexity3.723966598510742
INFO:root:current mean train loss 3337.530899947424
INFO:root:current train perplexity3.727382183074951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:37<00:00, 217.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.92s/it]
INFO:root:eval mean loss: 4042.2547945063166
INFO:root:eval perplexity: 5.127248764038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [8:48:36<5:24:00, 262.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.6357073102677
INFO:root:current train perplexity3.7952022552490234
INFO:root:current mean train loss 3323.320364978826
INFO:root:current train perplexity3.7103071212768555
INFO:root:current mean train loss 3326.7988186896137
INFO:root:current train perplexity3.7095947265625
INFO:root:current mean train loss 3327.156117193862
INFO:root:current train perplexity3.7119622230529785
INFO:root:current mean train loss 3321.0306807384445
INFO:root:current train perplexity3.7130508422851562
INFO:root:current mean train loss 3326.153547117696
INFO:root:current train perplexity3.717128038406372
INFO:root:current mean train loss 3327.5230437377727
INFO:root:current train perplexity3.7154734134674072
INFO:root:current mean train loss 3331.761914891266
INFO:root:current train perplexity3.7200448513031006
INFO:root:current mean train loss 3333.4200740469137
INFO:root:current train perplexity3.721738815307617
INFO:root:current mean train loss 3333.5200394501103
INFO:root:current train perplexity3.720369815826416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]
INFO:root:eval mean loss: 4044.3642110621677
INFO:root:eval perplexity: 5.131624221801758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [8:53:03<5:21:08, 263.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.4140462239584
INFO:root:current train perplexity3.7371039390563965
INFO:root:current mean train loss 3307.699552055027
INFO:root:current train perplexity3.7208361625671387
INFO:root:current mean train loss 3316.156201171875
INFO:root:current train perplexity3.721855878829956
INFO:root:current mean train loss 3323.1501379588294
INFO:root:current train perplexity3.7167110443115234
INFO:root:current mean train loss 3326.405219314759
INFO:root:current train perplexity3.7162697315216064
INFO:root:current mean train loss 3325.2098462151093
INFO:root:current train perplexity3.7163925170898438
INFO:root:current mean train loss 3326.6488039094256
INFO:root:current train perplexity3.714395523071289
INFO:root:current mean train loss 3327.8369949874345
INFO:root:current train perplexity3.7156200408935547
INFO:root:current mean train loss 3327.7247504673123
INFO:root:current train perplexity3.714770555496216
INFO:root:current mean train loss 3330.2559604999146
INFO:root:current train perplexity3.718231201171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it]
INFO:root:eval mean loss: 4045.3743056709886
INFO:root:eval perplexity: 5.1337199211120605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [8:57:27<5:16:35, 263.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.474418308424
INFO:root:current train perplexity3.697674512863159
INFO:root:current mean train loss 3327.5356127731197
INFO:root:current train perplexity3.7059361934661865
INFO:root:current mean train loss 3327.816188384599
INFO:root:current train perplexity3.7089951038360596
INFO:root:current mean train loss 3328.131188927051
INFO:root:current train perplexity3.7160770893096924
INFO:root:current mean train loss 3325.5046150081266
INFO:root:current train perplexity3.709228992462158
INFO:root:current mean train loss 3323.763391790153
INFO:root:current train perplexity3.7105748653411865
INFO:root:current mean train loss 3325.332614365971
INFO:root:current train perplexity3.7121291160583496
INFO:root:current mean train loss 3326.856374062608
INFO:root:current train perplexity3.7135379314422607
INFO:root:current mean train loss 3325.358879895865
INFO:root:current train perplexity3.7118313312530518
INFO:root:current mean train loss 3325.670044606582
INFO:root:current train perplexity3.7108263969421387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.79s/it]
INFO:root:eval mean loss: 4046.5195537594195
INFO:root:eval perplexity: 5.1360979080200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [9:01:58<5:14:39, 265.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3320.637388167843
INFO:root:current train perplexity3.6731832027435303
INFO:root:current mean train loss 3313.299571728888
INFO:root:current train perplexity3.694889545440674
INFO:root:current mean train loss 3325.813678427692
INFO:root:current train perplexity3.707045793533325
INFO:root:current mean train loss 3325.8957733430893
INFO:root:current train perplexity3.7077746391296387
INFO:root:current mean train loss 3324.195173152915
INFO:root:current train perplexity3.710679531097412
INFO:root:current mean train loss 3326.196196647687
INFO:root:current train perplexity3.71388578414917
INFO:root:current mean train loss 3324.946521982716
INFO:root:current train perplexity3.7094943523406982
INFO:root:current mean train loss 3325.7447805339434
INFO:root:current train perplexity3.708777666091919
INFO:root:current mean train loss 3321.829805780404
INFO:root:current train perplexity3.7052903175354004
INFO:root:current mean train loss 3321.6756781917124
INFO:root:current train perplexity3.704725980758667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.90s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it]
INFO:root:eval mean loss: 4046.991205743019
INFO:root:eval perplexity: 5.137077808380127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [9:06:21<5:09:23, 265.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.025697365785
INFO:root:current train perplexity3.7042009830474854
INFO:root:current mean train loss 3325.6113614967403
INFO:root:current train perplexity3.7105724811553955
INFO:root:current mean train loss 3322.230270577275
INFO:root:current train perplexity3.7020528316497803
INFO:root:current mean train loss 3323.248252125968
INFO:root:current train perplexity3.7034926414489746
INFO:root:current mean train loss 3323.060521293067
INFO:root:current train perplexity3.705841302871704
INFO:root:current mean train loss 3317.548185387436
INFO:root:current train perplexity3.7040932178497314
INFO:root:current mean train loss 3317.198574203467
INFO:root:current train perplexity3.704023838043213
INFO:root:current mean train loss 3317.1274764250675
INFO:root:current train perplexity3.70139479637146
INFO:root:current mean train loss 3321.147872397385
INFO:root:current train perplexity3.70412278175354
INFO:root:current mean train loss 3321.204534723609
INFO:root:current train perplexity3.704822301864624


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it]
INFO:root:eval mean loss: 4050.0008969137853
INFO:root:eval perplexity: 5.143333911895752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [9:10:24<4:57:22, 258.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.3691873753323
INFO:root:current train perplexity3.7000057697296143
INFO:root:current mean train loss 3316.507430511267
INFO:root:current train perplexity3.6933889389038086
INFO:root:current mean train loss 3316.165600487095
INFO:root:current train perplexity3.7023251056671143
INFO:root:current mean train loss 3313.262444136122
INFO:root:current train perplexity3.6928482055664062
INFO:root:current mean train loss 3314.8413320793134
INFO:root:current train perplexity3.692901134490967
INFO:root:current mean train loss 3315.4727709559243
INFO:root:current train perplexity3.6937062740325928
INFO:root:current mean train loss 3315.498542703101
INFO:root:current train perplexity3.695927143096924
INFO:root:current mean train loss 3315.7881996736946
INFO:root:current train perplexity3.6965646743774414
INFO:root:current mean train loss 3315.281272482844
INFO:root:current train perplexity3.6962265968322754
INFO:root:current mean train loss 3316.714971363104
INFO:root:current train perplexity3.6971256732940674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it]
INFO:root:eval mean loss: 4049.5365431765294
INFO:root:eval perplexity: 5.142367839813232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [9:14:50<4:55:34, 260.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.935431463068
INFO:root:current train perplexity3.676048994064331
INFO:root:current mean train loss 3290.8592552923387
INFO:root:current train perplexity3.6842870712280273
INFO:root:current mean train loss 3293.363036151961
INFO:root:current train perplexity3.687903881072998
INFO:root:current mean train loss 3295.027792143486
INFO:root:current train perplexity3.6822102069854736
INFO:root:current mean train loss 3299.4841737851993
INFO:root:current train perplexity3.681873083114624
INFO:root:current mean train loss 3303.5598813168635
INFO:root:current train perplexity3.684811592102051
INFO:root:current mean train loss 3305.5268476413407
INFO:root:current train perplexity3.688150405883789
INFO:root:current mean train loss 3307.608274265315
INFO:root:current train perplexity3.6893224716186523
INFO:root:current mean train loss 3310.4907814784356
INFO:root:current train perplexity3.690314769744873
INFO:root:current mean train loss 3312.0056832358473
INFO:root:current train perplexity3.692058563232422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.29s/it]
INFO:root:eval mean loss: 4050.475393741689
INFO:root:eval perplexity: 5.144320011138916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [9:19:21<4:54:34, 263.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.8415798611113
INFO:root:current train perplexity3.6897056102752686
INFO:root:current mean train loss 3295.8527996788725
INFO:root:current train perplexity3.6798646450042725
INFO:root:current mean train loss 3301.382690893833
INFO:root:current train perplexity3.685333728790283
INFO:root:current mean train loss 3305.7459209011276
INFO:root:current train perplexity3.689157009124756
INFO:root:current mean train loss 3307.532905726917
INFO:root:current train perplexity3.6875178813934326
INFO:root:current mean train loss 3314.401294769233
INFO:root:current train perplexity3.690000295639038
INFO:root:current mean train loss 3311.906198815163
INFO:root:current train perplexity3.6873960494995117
INFO:root:current mean train loss 3310.375294376638
INFO:root:current train perplexity3.686713457107544
INFO:root:current mean train loss 3310.435620428375
INFO:root:current train perplexity3.6877548694610596
INFO:root:current mean train loss 3312.6959381895767
INFO:root:current train perplexity3.690657377243042


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.64s/it]
INFO:root:eval mean loss: 4054.129913979388
INFO:root:eval perplexity: 5.151928901672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [9:23:52<4:52:24, 265.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.2583282900528
INFO:root:current train perplexity3.6876070499420166
INFO:root:current mean train loss 3290.4043268571822
INFO:root:current train perplexity3.662827491760254
INFO:root:current mean train loss 3294.5713827548434
INFO:root:current train perplexity3.6700217723846436
INFO:root:current mean train loss 3298.0912441037735
INFO:root:current train perplexity3.67403507232666
INFO:root:current mean train loss 3301.6626054314293
INFO:root:current train perplexity3.6774814128875732
INFO:root:current mean train loss 3307.5046125903023
INFO:root:current train perplexity3.680046319961548
INFO:root:current mean train loss 3311.0208403676884
INFO:root:current train perplexity3.685912847518921
INFO:root:current mean train loss 3309.40265850458
INFO:root:current train perplexity3.6852355003356934
INFO:root:current mean train loss 3309.8421713547646
INFO:root:current train perplexity3.6862666606903076
INFO:root:current mean train loss 3308.2163908120656
INFO:root:current train perplexity3.684624433517456


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it]
INFO:root:eval mean loss: 4053.294644835993
INFO:root:eval perplexity: 5.15018892288208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [9:27:40<4:35:55, 254.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3305.9159043710442
INFO:root:current train perplexity3.6711490154266357
INFO:root:current mean train loss 3300.5654351431563
INFO:root:current train perplexity3.6865012645721436
INFO:root:current mean train loss 3298.838192519321
INFO:root:current train perplexity3.678966522216797
INFO:root:current mean train loss 3303.781069632256
INFO:root:current train perplexity3.681147575378418
INFO:root:current mean train loss 3306.820339003784
INFO:root:current train perplexity3.6829543113708496
INFO:root:current mean train loss 3307.7910822471395
INFO:root:current train perplexity3.682166337966919
INFO:root:current mean train loss 3310.23738810521
INFO:root:current train perplexity3.6820619106292725
INFO:root:current mean train loss 3309.800094898307
INFO:root:current train perplexity3.6803741455078125
INFO:root:current mean train loss 3308.4227193543798
INFO:root:current train perplexity3.68045711517334
INFO:root:current mean train loss 3305.3064982304168
INFO:root:current train perplexity3.6798503398895264


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.10s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.58s/it]
INFO:root:eval mean loss: 4054.765715037677
INFO:root:eval perplexity: 5.153253078460693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [9:32:15<4:38:02, 260.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.477146192529
INFO:root:current train perplexity3.6591079235076904
INFO:root:current mean train loss 3294.7219760507187
INFO:root:current train perplexity3.669367790222168
INFO:root:current mean train loss 3292.3480484061956
INFO:root:current train perplexity3.6649398803710938
INFO:root:current mean train loss 3299.0974934895835
INFO:root:current train perplexity3.669102668762207
INFO:root:current mean train loss 3303.379642181083
INFO:root:current train perplexity3.672405958175659
INFO:root:current mean train loss 3302.666456076315
INFO:root:current train perplexity3.6706597805023193
INFO:root:current mean train loss 3301.857755214019
INFO:root:current train perplexity3.6705267429351807
INFO:root:current mean train loss 3298.9050153371186
INFO:root:current train perplexity3.6688058376312256
INFO:root:current mean train loss 3299.0649160838852
INFO:root:current train perplexity3.6699416637420654
INFO:root:current mean train loss 3300.2149988423726
INFO:root:current train perplexity3.673246383666992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.54s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.26s/it]
INFO:root:eval mean loss: 4056.272672179743
INFO:root:eval perplexity: 5.1563944816589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [9:36:41<4:35:34, 262.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.7120682565787
INFO:root:current train perplexity3.6549508571624756
INFO:root:current mean train loss 3292.3291403745993
INFO:root:current train perplexity3.659087896347046
INFO:root:current mean train loss 3295.3803164724577
INFO:root:current train perplexity3.6657533645629883
INFO:root:current mean train loss 3296.1016929143593
INFO:root:current train perplexity3.670053243637085
INFO:root:current mean train loss 3293.728943734217
INFO:root:current train perplexity3.6690328121185303
INFO:root:current mean train loss 3295.9167931821166
INFO:root:current train perplexity3.670896530151367
INFO:root:current mean train loss 3294.0307318598248
INFO:root:current train perplexity3.6690890789031982
INFO:root:current mean train loss 3297.9220807537345
INFO:root:current train perplexity3.672619342803955
INFO:root:current mean train loss 3297.7890439507682
INFO:root:current train perplexity3.6710705757141113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it]
INFO:root:eval mean loss: 4058.1320194758423
INFO:root:eval perplexity: 5.16027307510376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [9:41:06<4:31:47, 263.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.640380859375
INFO:root:current train perplexity3.5261645317077637
INFO:root:current mean train loss 3268.108742130613
INFO:root:current train perplexity3.630023717880249
INFO:root:current mean train loss 3274.110675078895
INFO:root:current train perplexity3.640230655670166
INFO:root:current mean train loss 3280.9259174208437
INFO:root:current train perplexity3.650944471359253
INFO:root:current mean train loss 3287.8687571485343
INFO:root:current train perplexity3.652219533920288
INFO:root:current mean train loss 3289.371339346732
INFO:root:current train perplexity3.653301954269409
INFO:root:current mean train loss 3291.4448238138734
INFO:root:current train perplexity3.656010627746582
INFO:root:current mean train loss 3292.612313369599
INFO:root:current train perplexity3.6598238945007324
INFO:root:current mean train loss 3295.142437356495
INFO:root:current train perplexity3.6629245281219482
INFO:root:current mean train loss 3295.1871231095997
INFO:root:current train perplexity3.6648099422454834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.47s/it]
INFO:root:eval mean loss: 4056.23248594027
INFO:root:eval perplexity: 5.156311511993408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [9:45:31<4:27:58, 263.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.1235573508525
INFO:root:current train perplexity3.6002020835876465
INFO:root:current mean train loss 3291.6114644918357
INFO:root:current train perplexity3.663672685623169
INFO:root:current mean train loss 3288.9397643753705
INFO:root:current train perplexity3.6553995609283447
INFO:root:current mean train loss 3277.8968941544413
INFO:root:current train perplexity3.6433019638061523
INFO:root:current mean train loss 3281.96803361656
INFO:root:current train perplexity3.647460460662842
INFO:root:current mean train loss 3283.621126238381
INFO:root:current train perplexity3.6548588275909424
INFO:root:current mean train loss 3285.778130913717
INFO:root:current train perplexity3.6549856662750244
INFO:root:current mean train loss 3288.6134979205126
INFO:root:current train perplexity3.655841112136841
INFO:root:current mean train loss 3290.8219835537725
INFO:root:current train perplexity3.660555601119995
INFO:root:current mean train loss 3293.359916343647
INFO:root:current train perplexity3.6621103286743164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it]
INFO:root:eval mean loss: 4058.329707585328
INFO:root:eval perplexity: 5.160685062408447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [9:49:57<4:24:17, 264.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3262.7741313733554
INFO:root:current train perplexity3.6281487941741943
INFO:root:current mean train loss 3265.1767270384717
INFO:root:current train perplexity3.6369500160217285
INFO:root:current mean train loss 3268.346283934432
INFO:root:current train perplexity3.6514272689819336
INFO:root:current mean train loss 3277.7597350117553
INFO:root:current train perplexity3.654444456100464
INFO:root:current mean train loss 3280.8778644279537
INFO:root:current train perplexity3.6547372341156006
INFO:root:current mean train loss 3283.5773093162934
INFO:root:current train perplexity3.6557843685150146
INFO:root:current mean train loss 3280.8849604642064
INFO:root:current train perplexity3.6527175903320312
INFO:root:current mean train loss 3284.5206246196976
INFO:root:current train perplexity3.654958963394165
INFO:root:current mean train loss 3286.157725575206
INFO:root:current train perplexity3.655695915222168
INFO:root:current mean train loss 3287.6103236683043
INFO:root:current train perplexity3.6555142402648926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 4058.8853577958776
INFO:root:eval perplexity: 5.161845684051514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [9:54:23<4:20:27, 264.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.962981047454
INFO:root:current train perplexity3.6653811931610107
INFO:root:current mean train loss 3282.689224363312
INFO:root:current train perplexity3.6587812900543213
INFO:root:current mean train loss 3281.182832289372
INFO:root:current train perplexity3.6551625728607178
INFO:root:current mean train loss 3281.0323318341457
INFO:root:current train perplexity3.6566412448883057
INFO:root:current mean train loss 3286.3563040882977
INFO:root:current train perplexity3.6575615406036377
INFO:root:current mean train loss 3286.786773971181
INFO:root:current train perplexity3.6558938026428223
INFO:root:current mean train loss 3287.616846404007
INFO:root:current train perplexity3.657644033432007
INFO:root:current mean train loss 3287.4940261106217
INFO:root:current train perplexity3.657533645629883
INFO:root:current mean train loss 3288.4741225698117
INFO:root:current train perplexity3.659127712249756
INFO:root:current mean train loss 3288.297430703041
INFO:root:current train perplexity3.6570374965667725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.89s/it]
INFO:root:eval mean loss: 4061.098547969304
INFO:root:eval perplexity: 5.16646671295166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [9:58:48<4:15:58, 264.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.7296177455355
INFO:root:current train perplexity3.651153802871704
INFO:root:current mean train loss 3307.611662688079
INFO:root:current train perplexity3.6384353637695312
INFO:root:current mean train loss 3295.461878740027
INFO:root:current train perplexity3.638880729675293
INFO:root:current mean train loss 3294.4240569612875
INFO:root:current train perplexity3.6423754692077637
INFO:root:current mean train loss 3287.8260237068966
INFO:root:current train perplexity3.644749879837036
INFO:root:current mean train loss 3292.8529908367404
INFO:root:current train perplexity3.6501340866088867
INFO:root:current mean train loss 3288.8168756920522
INFO:root:current train perplexity3.646371364593506
INFO:root:current mean train loss 3285.969140957164
INFO:root:current train perplexity3.6470882892608643
INFO:root:current mean train loss 3283.977129432541
INFO:root:current train perplexity3.6487889289855957
INFO:root:current mean train loss 3283.8754209141043
INFO:root:current train perplexity3.650233030319214


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it]
INFO:root:eval mean loss: 4061.215524227061
INFO:root:eval perplexity: 5.166711330413818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [10:02:58<4:07:33, 260.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.2499375454213
INFO:root:current train perplexity3.6266348361968994
INFO:root:current mean train loss 3266.8688879479896
INFO:root:current train perplexity3.6223340034484863
INFO:root:current mean train loss 3265.548471458655
INFO:root:current train perplexity3.6256375312805176
INFO:root:current mean train loss 3270.1812833113154
INFO:root:current train perplexity3.6264424324035645
INFO:root:current mean train loss 3270.8559608890027
INFO:root:current train perplexity3.629167318344116
INFO:root:current mean train loss 3274.3078019790228
INFO:root:current train perplexity3.6344337463378906
INFO:root:current mean train loss 3277.883286353033
INFO:root:current train perplexity3.6385512351989746
INFO:root:current mean train loss 3275.858603804782
INFO:root:current train perplexity3.6401126384735107
INFO:root:current mean train loss 3278.1663947235506
INFO:root:current train perplexity3.6428418159484863
INFO:root:current mean train loss 3279.5888229159764
INFO:root:current train perplexity3.646127462387085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.77s/it]
INFO:root:eval mean loss: 4063.597462322695
INFO:root:eval perplexity: 5.171689987182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [10:07:16<4:02:30, 259.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.3103170955883
INFO:root:current train perplexity3.6136984825134277
INFO:root:current mean train loss 3270.872241695985
INFO:root:current train perplexity3.6288204193115234
INFO:root:current mean train loss 3273.1422367171936
INFO:root:current train perplexity3.6301486492156982
INFO:root:current mean train loss 3267.794821019186
INFO:root:current train perplexity3.6291184425354004
INFO:root:current mean train loss 3271.6735163179046
INFO:root:current train perplexity3.6312005519866943
INFO:root:current mean train loss 3273.1653563123864
INFO:root:current train perplexity3.6355676651000977
INFO:root:current mean train loss 3278.0952965989823
INFO:root:current train perplexity3.6396231651306152
INFO:root:current mean train loss 3280.417623182111
INFO:root:current train perplexity3.642829656600952
INFO:root:current mean train loss 3280.00562097211
INFO:root:current train perplexity3.643156051635742
INFO:root:current mean train loss 3279.096266111741
INFO:root:current train perplexity3.64400315284729


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 14.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 14.00s/it]
INFO:root:eval mean loss: 4063.257829814938
INFO:root:eval perplexity: 5.170979976654053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [10:11:50<4:02:03, 264.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.5495812367585
INFO:root:current train perplexity3.6228625774383545
INFO:root:current mean train loss 3270.5490262013564
INFO:root:current train perplexity3.6241891384124756
INFO:root:current mean train loss 3264.7422355740227
INFO:root:current train perplexity3.6253790855407715
INFO:root:current mean train loss 3266.749900711612
INFO:root:current train perplexity3.6296138763427734
INFO:root:current mean train loss 3269.281259574142
INFO:root:current train perplexity3.630507469177246
INFO:root:current mean train loss 3271.2817858864883
INFO:root:current train perplexity3.6331615447998047
INFO:root:current mean train loss 3276.2237947084836
INFO:root:current train perplexity3.6357741355895996
INFO:root:current mean train loss 3275.574678081769
INFO:root:current train perplexity3.6369574069976807
INFO:root:current mean train loss 3276.5754781063556
INFO:root:current train perplexity3.6383163928985596
INFO:root:current mean train loss 3275.7460257775842
INFO:root:current train perplexity3.6382951736450195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.89s/it]
INFO:root:eval mean loss: 4065.020952806405
INFO:root:eval perplexity: 5.174668312072754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [10:16:17<3:58:17, 264.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.1711790170243
INFO:root:current train perplexity3.6300055980682373
INFO:root:current mean train loss 3284.653903618544
INFO:root:current train perplexity3.6272497177124023
INFO:root:current mean train loss 3278.4831451530313
INFO:root:current train perplexity3.6294667720794678
INFO:root:current mean train loss 3280.1332542149185
INFO:root:current train perplexity3.6281604766845703
INFO:root:current mean train loss 3275.1612441657185
INFO:root:current train perplexity3.6272051334381104
INFO:root:current mean train loss 3273.3250743186454
INFO:root:current train perplexity3.630279541015625
INFO:root:current mean train loss 3274.7402848868533
INFO:root:current train perplexity3.631866693496704
INFO:root:current mean train loss 3274.4483408623287
INFO:root:current train perplexity3.6316001415252686
INFO:root:current mean train loss 3275.247054261732
INFO:root:current train perplexity3.634801149368286
INFO:root:current mean train loss 3275.433189541995
INFO:root:current train perplexity3.6359434127807617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.09s/it]
INFO:root:eval mean loss: 4065.408616952017
INFO:root:eval perplexity: 5.175479412078857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [10:20:38<3:52:52, 263.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.7327766927083
INFO:root:current train perplexity3.6078929901123047
INFO:root:current mean train loss 3268.0341671316964
INFO:root:current train perplexity3.630188465118408
INFO:root:current mean train loss 3272.7766832386365
INFO:root:current train perplexity3.6346819400787354
INFO:root:current mean train loss 3266.748791666667
INFO:root:current train perplexity3.6284072399139404
INFO:root:current mean train loss 3266.377081620066
INFO:root:current train perplexity3.6257853507995605
INFO:root:current mean train loss 3267.91684655231
INFO:root:current train perplexity3.626103162765503
INFO:root:current mean train loss 3271.563666449653
INFO:root:current train perplexity3.629152297973633
INFO:root:current mean train loss 3272.3547385332663
INFO:root:current train perplexity3.628950595855713
INFO:root:current mean train loss 3276.589483258929
INFO:root:current train perplexity3.634598731994629
INFO:root:current mean train loss 3274.6705163261217
INFO:root:current train perplexity3.6351664066314697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it]
INFO:root:eval mean loss: 4064.5151557651816
INFO:root:eval perplexity: 5.173609256744385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [10:25:03<3:49:02, 264.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.7892801675453
INFO:root:current train perplexity3.6329824924468994
INFO:root:current mean train loss 3261.8081935194673
INFO:root:current train perplexity3.6249051094055176
INFO:root:current mean train loss 3264.8162544169613
INFO:root:current train perplexity3.6242988109588623
INFO:root:current mean train loss 3267.9538038766727
INFO:root:current train perplexity3.6249306201934814
INFO:root:current mean train loss 3268.8293401429864
INFO:root:current train perplexity3.6249840259552
INFO:root:current mean train loss 3267.7558773819414
INFO:root:current train perplexity3.627654790878296
INFO:root:current mean train loss 3268.229025710903
INFO:root:current train perplexity3.627617597579956
INFO:root:current mean train loss 3267.607036800068
INFO:root:current train perplexity3.6269278526306152
INFO:root:current mean train loss 3268.448881985242
INFO:root:current train perplexity3.628310441970825
INFO:root:current mean train loss 3269.7816347139656
INFO:root:current train perplexity3.629122495651245


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.60s/it]
INFO:root:eval mean loss: 4066.487287372562
INFO:root:eval perplexity: 5.177736759185791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [10:29:27<3:44:23, 263.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3262.947050995879
INFO:root:current train perplexity3.6136131286621094
INFO:root:current mean train loss 3259.491066498282
INFO:root:current train perplexity3.6139650344848633
INFO:root:current mean train loss 3261.5679558298434
INFO:root:current train perplexity3.6184961795806885
INFO:root:current mean train loss 3262.6724438289243
INFO:root:current train perplexity3.6183760166168213
INFO:root:current mean train loss 3262.479226665924
INFO:root:current train perplexity3.6192214488983154
INFO:root:current mean train loss 3262.185936012849
INFO:root:current train perplexity3.620539665222168
INFO:root:current mean train loss 3265.466380669998
INFO:root:current train perplexity3.622668981552124
INFO:root:current mean train loss 3265.355682643114
INFO:root:current train perplexity3.6256203651428223
INFO:root:current mean train loss 3267.415727643185
INFO:root:current train perplexity3.6269171237945557
INFO:root:current mean train loss 3268.724270632962
INFO:root:current train perplexity3.6277451515197754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.47s/it]
INFO:root:eval mean loss: 4069.126582585328
INFO:root:eval perplexity: 5.183265209197998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [10:33:59<3:41:57, 266.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.8165344854797
INFO:root:current train perplexity3.632617473602295
INFO:root:current mean train loss 3262.701813510914
INFO:root:current train perplexity3.6195714473724365
INFO:root:current mean train loss 3260.281465562291
INFO:root:current train perplexity3.6157703399658203
INFO:root:current mean train loss 3257.5485949982376
INFO:root:current train perplexity3.6130106449127197
INFO:root:current mean train loss 3258.9249504869113
INFO:root:current train perplexity3.613321542739868
INFO:root:current mean train loss 3260.488441021494
INFO:root:current train perplexity3.617861032485962
INFO:root:current mean train loss 3259.6166663872496
INFO:root:current train perplexity3.6194751262664795
INFO:root:current mean train loss 3257.5506828604116
INFO:root:current train perplexity3.6186020374298096
INFO:root:current mean train loss 3262.0336981954774
INFO:root:current train perplexity3.6204590797424316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.55s/it]
INFO:root:eval mean loss: 4068.8655166084886
INFO:root:eval perplexity: 5.182718276977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [10:38:32<3:39:20, 268.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.8458077566966
INFO:root:current train perplexity3.5970139503479004
INFO:root:current mean train loss 3263.7832464770736
INFO:root:current train perplexity3.6205811500549316
INFO:root:current mean train loss 3258.69448926253
INFO:root:current train perplexity3.6180648803710938
INFO:root:current mean train loss 3256.677118854336
INFO:root:current train perplexity3.62088680267334
INFO:root:current mean train loss 3256.641950077741
INFO:root:current train perplexity3.6192150115966797
INFO:root:current mean train loss 3258.122926971616
INFO:root:current train perplexity3.6158556938171387
INFO:root:current mean train loss 3258.3965905580726
INFO:root:current train perplexity3.6170880794525146
INFO:root:current mean train loss 3262.9745047433034
INFO:root:current train perplexity3.61739182472229
INFO:root:current mean train loss 3263.6349683191993
INFO:root:current train perplexity3.6183159351348877
INFO:root:current mean train loss 3266.674512633941
INFO:root:current train perplexity3.621046543121338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.46s/it]
INFO:root:eval mean loss: 4068.4889599955673
INFO:root:eval perplexity: 5.181929588317871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [10:43:05<3:35:44, 269.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.3820963541666
INFO:root:current train perplexity3.6222946643829346
INFO:root:current mean train loss 3256.6848271908966
INFO:root:current train perplexity3.6082801818847656
INFO:root:current mean train loss 3255.253445221657
INFO:root:current train perplexity3.6099534034729004
INFO:root:current mean train loss 3248.1501286582343
INFO:root:current train perplexity3.6046361923217773
INFO:root:current mean train loss 3253.560203901544
INFO:root:current train perplexity3.6065828800201416
INFO:root:current mean train loss 3256.026558707524
INFO:root:current train perplexity3.6099159717559814
INFO:root:current mean train loss 3257.10371331936
INFO:root:current train perplexity3.6073670387268066
INFO:root:current mean train loss 3259.718808388877
INFO:root:current train perplexity3.6113874912261963
INFO:root:current mean train loss 3259.0351059240797
INFO:root:current train perplexity3.6136579513549805
INFO:root:current mean train loss 3259.895860282189
INFO:root:current train perplexity3.615490198135376


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 4071.6492928579346
INFO:root:eval perplexity: 5.1885552406311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [10:47:30<3:30:07, 268.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.997516134511
INFO:root:current train perplexity3.567394733428955
INFO:root:current mean train loss 3247.263933879573
INFO:root:current train perplexity3.601335287094116
INFO:root:current mean train loss 3245.444089607273
INFO:root:current train perplexity3.594021797180176
INFO:root:current mean train loss 3245.878204062258
INFO:root:current train perplexity3.5938494205474854
INFO:root:current mean train loss 3248.131321683843
INFO:root:current train perplexity3.599043130874634
INFO:root:current mean train loss 3251.308503656041
INFO:root:current train perplexity3.601264476776123
INFO:root:current mean train loss 3251.405704896293
INFO:root:current train perplexity3.6045312881469727
INFO:root:current mean train loss 3254.5196703730116
INFO:root:current train perplexity3.6076793670654297
INFO:root:current mean train loss 3257.574859211251
INFO:root:current train perplexity3.609046459197998
INFO:root:current mean train loss 3258.239079005282
INFO:root:current train perplexity3.6112189292907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it]
INFO:root:eval mean loss: 4072.640496869459
INFO:root:eval perplexity: 5.190636157989502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [10:51:51<3:24:01, 266.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.6563445060483
INFO:root:current train perplexity3.636503219604492
INFO:root:current mean train loss 3251.8027958760736
INFO:root:current train perplexity3.6116554737091064
INFO:root:current mean train loss 3248.3029690036524
INFO:root:current train perplexity3.5998330116271973
INFO:root:current mean train loss 3251.534155347196
INFO:root:current train perplexity3.6056113243103027
INFO:root:current mean train loss 3248.6035841656394
INFO:root:current train perplexity3.6085407733917236
INFO:root:current mean train loss 3248.1395505053847
INFO:root:current train perplexity3.6080405712127686
INFO:root:current mean train loss 3252.25528287812
INFO:root:current train perplexity3.6113789081573486
INFO:root:current mean train loss 3255.3555729522914
INFO:root:current train perplexity3.61429762840271
INFO:root:current mean train loss 3257.8318952245977
INFO:root:current train perplexity3.611602306365967
INFO:root:current mean train loss 3256.011747595831
INFO:root:current train perplexity3.610642910003662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it]
INFO:root:eval mean loss: 4072.7955244348404
INFO:root:eval perplexity: 5.19096040725708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [10:56:14<3:19:03, 265.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.4324168669873
INFO:root:current train perplexity3.6091737747192383
INFO:root:current mean train loss 3252.163301975607
INFO:root:current train perplexity3.5944981575012207
INFO:root:current mean train loss 3255.860242261049
INFO:root:current train perplexity3.6027729511260986
INFO:root:current mean train loss 3252.9855452906068
INFO:root:current train perplexity3.6058812141418457
INFO:root:current mean train loss 3249.0092567669776
INFO:root:current train perplexity3.6082041263580322
INFO:root:current mean train loss 3250.303377565515
INFO:root:current train perplexity3.6055898666381836
INFO:root:current mean train loss 3250.7407834048563
INFO:root:current train perplexity3.6045360565185547
INFO:root:current mean train loss 3252.963120559878
INFO:root:current train perplexity3.605151414871216
INFO:root:current mean train loss 3253.575620448916
INFO:root:current train perplexity3.604050874710083
INFO:root:current mean train loss 3255.2433983231
INFO:root:current train perplexity3.608402729034424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it]
INFO:root:eval mean loss: 4073.531558205895
INFO:root:eval perplexity: 5.192506790161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [10:59:57<3:05:09, 252.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.1222521193486
INFO:root:current train perplexity3.551454544067383
INFO:root:current mean train loss 3253.4949843218537
INFO:root:current train perplexity3.585222005844116
INFO:root:current mean train loss 3245.866785211602
INFO:root:current train perplexity3.5891318321228027
INFO:root:current mean train loss 3248.2203063085376
INFO:root:current train perplexity3.593106269836426
INFO:root:current mean train loss 3250.8169283941556
INFO:root:current train perplexity3.598531723022461
INFO:root:current mean train loss 3245.7690460930357
INFO:root:current train perplexity3.596938371658325
INFO:root:current mean train loss 3246.3902706753524
INFO:root:current train perplexity3.599160671234131
INFO:root:current mean train loss 3248.962919385877
INFO:root:current train perplexity3.6005971431732178
INFO:root:current mean train loss 3251.9839639674956
INFO:root:current train perplexity3.6024169921875
INFO:root:current mean train loss 3253.0659519989113
INFO:root:current train perplexity3.6041204929351807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it]
INFO:root:eval mean loss: 4073.993583083998
INFO:root:eval perplexity: 5.193477153778076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [11:03:38<2:54:17, 243.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.7968971946025
INFO:root:current train perplexity3.6103885173797607
INFO:root:current mean train loss 3218.787522051411
INFO:root:current train perplexity3.5879976749420166
INFO:root:current mean train loss 3232.7047880284927
INFO:root:current train perplexity3.5918045043945312
INFO:root:current mean train loss 3238.714298387984
INFO:root:current train perplexity3.5962460041046143
INFO:root:current mean train loss 3240.773567887191
INFO:root:current train perplexity3.596806526184082
INFO:root:current mean train loss 3243.8726382143864
INFO:root:current train perplexity3.595952033996582
INFO:root:current mean train loss 3248.09560845062
INFO:root:current train perplexity3.599586009979248
INFO:root:current mean train loss 3248.240263801221
INFO:root:current train perplexity3.599245309829712
INFO:root:current mean train loss 3250.3260048314146
INFO:root:current train perplexity3.6015517711639404
INFO:root:current mean train loss 3249.532315271188
INFO:root:current train perplexity3.600024938583374


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it]
INFO:root:eval mean loss: 4075.2995640098625
INFO:root:eval perplexity: 5.196220874786377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [11:07:20<2:45:48, 236.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.525169735863
INFO:root:current train perplexity3.605041742324829
INFO:root:current mean train loss 3256.4757372148197
INFO:root:current train perplexity3.5918385982513428
INFO:root:current mean train loss 3251.230370351117
INFO:root:current train perplexity3.590151071548462
INFO:root:current mean train loss 3242.4699700305614
INFO:root:current train perplexity3.5910351276397705
INFO:root:current mean train loss 3246.1964229970977
INFO:root:current train perplexity3.598562717437744
INFO:root:current mean train loss 3247.9787237733126
INFO:root:current train perplexity3.598675489425659
INFO:root:current mean train loss 3247.12218188808
INFO:root:current train perplexity3.602039098739624
INFO:root:current mean train loss 3250.8664042021624
INFO:root:current train perplexity3.6014134883880615
INFO:root:current mean train loss 3249.085061083249
INFO:root:current train perplexity3.600376844406128
INFO:root:current mean train loss 3248.7981740410823
INFO:root:current train perplexity3.5991601943969727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.32s/it]
INFO:root:eval mean loss: 4075.6643031776375
INFO:root:eval perplexity: 5.196987152099609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [11:11:06<2:39:38, 233.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.866633885343
INFO:root:current train perplexity3.599839925765991
INFO:root:current mean train loss 3238.2340823167947
INFO:root:current train perplexity3.58480167388916
INFO:root:current mean train loss 3237.8815954004267
INFO:root:current train perplexity3.5835070610046387
INFO:root:current mean train loss 3234.6630510602677
INFO:root:current train perplexity3.588848114013672
INFO:root:current mean train loss 3239.330038730759
INFO:root:current train perplexity3.5907785892486572
INFO:root:current mean train loss 3238.9023339159644
INFO:root:current train perplexity3.5918335914611816
INFO:root:current mean train loss 3240.700320475503
INFO:root:current train perplexity3.5893471240997314
INFO:root:current mean train loss 3242.7866970908317
INFO:root:current train perplexity3.5905144214630127
INFO:root:current mean train loss 3244.428202474706
INFO:root:current train perplexity3.594520092010498
INFO:root:current mean train loss 3244.62344891502
INFO:root:current train perplexity3.594402313232422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4076.7091575243794
INFO:root:eval perplexity: 5.199182987213135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [11:14:47<2:33:13, 229.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.9056164705303
INFO:root:current train perplexity3.576455593109131
INFO:root:current mean train loss 3232.751875381896
INFO:root:current train perplexity3.588801622390747
INFO:root:current mean train loss 3240.666034876232
INFO:root:current train perplexity3.5938456058502197
INFO:root:current mean train loss 3246.5388299544443
INFO:root:current train perplexity3.592569589614868
INFO:root:current mean train loss 3244.8241560583574
INFO:root:current train perplexity3.5917842388153076
INFO:root:current mean train loss 3246.1180561177675
INFO:root:current train perplexity3.5916202068328857
INFO:root:current mean train loss 3242.1529478092784
INFO:root:current train perplexity3.5922539234161377
INFO:root:current mean train loss 3243.739983966323
INFO:root:current train perplexity3.5932154655456543
INFO:root:current mean train loss 3242.8384858392883
INFO:root:current train perplexity3.5943901538848877
INFO:root:current mean train loss 3244.453003303754
INFO:root:current train perplexity3.5943238735198975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4077.8717707640735
INFO:root:eval perplexity: 5.201627731323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [11:18:30<2:27:58, 227.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.26451093301
INFO:root:current train perplexity3.5630061626434326
INFO:root:current mean train loss 3227.979027406417
INFO:root:current train perplexity3.567030668258667
INFO:root:current mean train loss 3234.055197898519
INFO:root:current train perplexity3.5707669258117676
INFO:root:current mean train loss 3239.276837804829
INFO:root:current train perplexity3.5792806148529053
INFO:root:current mean train loss 3237.6702206590094
INFO:root:current train perplexity3.5808725357055664
INFO:root:current mean train loss 3239.6510506781037
INFO:root:current train perplexity3.581613302230835
INFO:root:current mean train loss 3238.750744504526
INFO:root:current train perplexity3.582345962524414
INFO:root:current mean train loss 3240.1250198538755
INFO:root:current train perplexity3.584920883178711
INFO:root:current mean train loss 3240.26575931863
INFO:root:current train perplexity3.5867679119110107
INFO:root:current mean train loss 3242.6657808839127
INFO:root:current train perplexity3.5907349586486816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]
INFO:root:eval mean loss: 4076.9872267702794
INFO:root:eval perplexity: 5.199767589569092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [11:22:14<2:23:25, 226.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.621127158717
INFO:root:current train perplexity3.5932857990264893
INFO:root:current mean train loss 3244.07353515625
INFO:root:current train perplexity3.595060110092163
INFO:root:current mean train loss 3240.2348376257946
INFO:root:current train perplexity3.585249900817871
INFO:root:current mean train loss 3243.2039563142803
INFO:root:current train perplexity3.5822901725769043
INFO:root:current mean train loss 3245.094197344539
INFO:root:current train perplexity3.5858473777770996
INFO:root:current mean train loss 3244.012447889312
INFO:root:current train perplexity3.5852315425872803
INFO:root:current mean train loss 3243.1355036673785
INFO:root:current train perplexity3.5841784477233887
INFO:root:current mean train loss 3241.060221661262
INFO:root:current train perplexity3.5854263305664062
INFO:root:current mean train loss 3241.83927036051
INFO:root:current train perplexity3.587416648864746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it]
INFO:root:eval mean loss: 4077.8928430435503
INFO:root:eval perplexity: 5.201672077178955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [11:25:57<2:19:05, 225.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.272216796875
INFO:root:current train perplexity3.5510857105255127
INFO:root:current mean train loss 3205.3857706310678
INFO:root:current train perplexity3.5743367671966553
INFO:root:current mean train loss 3230.608487434575
INFO:root:current train perplexity3.588587760925293
INFO:root:current mean train loss 3228.133238738913
INFO:root:current train perplexity3.584264039993286
INFO:root:current mean train loss 3229.216328585414
INFO:root:current train perplexity3.5878584384918213
INFO:root:current mean train loss 3231.690905834524
INFO:root:current train perplexity3.587258815765381
INFO:root:current mean train loss 3234.974217454395
INFO:root:current train perplexity3.586047410964966
INFO:root:current mean train loss 3234.3611982407983
INFO:root:current train perplexity3.5829966068267822
INFO:root:current mean train loss 3234.505355587932
INFO:root:current train perplexity3.5833685398101807
INFO:root:current mean train loss 3238.455148960929
INFO:root:current train perplexity3.5846750736236572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.38s/it]
INFO:root:eval mean loss: 4080.292793869127
INFO:root:eval perplexity: 5.206723213195801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [11:29:39<2:14:41, 224.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.899103338068
INFO:root:current train perplexity3.564298391342163
INFO:root:current mean train loss 3235.1228401252815
INFO:root:current train perplexity3.56588077545166
INFO:root:current mean train loss 3239.8635890291766
INFO:root:current train perplexity3.576054334640503
INFO:root:current mean train loss 3239.85765581039
INFO:root:current train perplexity3.5836243629455566
INFO:root:current mean train loss 3244.523248602874
INFO:root:current train perplexity3.5898866653442383
INFO:root:current mean train loss 3241.6902868341795
INFO:root:current train perplexity3.59091854095459
INFO:root:current mean train loss 3238.8601353921595
INFO:root:current train perplexity3.5872840881347656
INFO:root:current mean train loss 3237.9732829119416
INFO:root:current train perplexity3.5865070819854736
INFO:root:current mean train loss 3238.9660472940427
INFO:root:current train perplexity3.585832118988037
INFO:root:current mean train loss 3238.8266145976263
INFO:root:current train perplexity3.5854063034057617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.12s/it]
INFO:root:eval mean loss: 4079.3435023963875
INFO:root:eval perplexity: 5.204724311828613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [11:33:21<2:10:28, 223.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.0126824629933
INFO:root:current train perplexity3.5954062938690186
INFO:root:current mean train loss 3235.1239126509977
INFO:root:current train perplexity3.5810744762420654
INFO:root:current mean train loss 3239.106448656892
INFO:root:current train perplexity3.5881166458129883
INFO:root:current mean train loss 3238.8504328712775
INFO:root:current train perplexity3.5834150314331055
INFO:root:current mean train loss 3235.8347371904833
INFO:root:current train perplexity3.583029270172119
INFO:root:current mean train loss 3233.900544447706
INFO:root:current train perplexity3.5826261043548584
INFO:root:current mean train loss 3236.448818816892
INFO:root:current train perplexity3.5832595825195312
INFO:root:current mean train loss 3238.243329086622
INFO:root:current train perplexity3.5826783180236816
INFO:root:current mean train loss 3237.682594532204
INFO:root:current train perplexity3.583296298980713
INFO:root:current mean train loss 3236.490911008484
INFO:root:current train perplexity3.5811915397644043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.39s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4081.1349820617243
INFO:root:eval perplexity: 5.208497047424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [11:37:04<2:06:34, 223.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.301929615162
INFO:root:current train perplexity3.589853286743164
INFO:root:current mean train loss 3234.509035125492
INFO:root:current train perplexity3.5748190879821777
INFO:root:current mean train loss 3236.762993228593
INFO:root:current train perplexity3.580038070678711
INFO:root:current mean train loss 3231.734107714545
INFO:root:current train perplexity3.5767083168029785
INFO:root:current mean train loss 3234.4791451304523
INFO:root:current train perplexity3.576228141784668
INFO:root:current mean train loss 3237.1882602177716
INFO:root:current train perplexity3.5754716396331787
INFO:root:current mean train loss 3236.631864362166
INFO:root:current train perplexity3.576674222946167
INFO:root:current mean train loss 3237.466068818776
INFO:root:current train perplexity3.578238010406494
INFO:root:current mean train loss 3233.989000682531
INFO:root:current train perplexity3.577833652496338
INFO:root:current mean train loss 3234.680371462463
INFO:root:current train perplexity3.5791685581207275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.41s/it]
INFO:root:eval mean loss: 4081.4602171985816
INFO:root:eval perplexity: 5.209181308746338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [11:40:46<2:02:43, 223.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.3921944754466
INFO:root:current train perplexity3.58598256111145
INFO:root:current mean train loss 3234.111349826389
INFO:root:current train perplexity3.578545570373535
INFO:root:current mean train loss 3224.301533410904
INFO:root:current train perplexity3.5725958347320557
INFO:root:current mean train loss 3230.5128104594214
INFO:root:current train perplexity3.573852300643921
INFO:root:current mean train loss 3231.1535139412717
INFO:root:current train perplexity3.57365083694458
INFO:root:current mean train loss 3235.3612975503797
INFO:root:current train perplexity3.5758206844329834
INFO:root:current mean train loss 3234.3255436454233
INFO:root:current train perplexity3.577249050140381
INFO:root:current mean train loss 3235.180394677402
INFO:root:current train perplexity3.576157808303833
INFO:root:current mean train loss 3235.2113468375746
INFO:root:current train perplexity3.5764617919921875
INFO:root:current mean train loss 3234.1126739012366
INFO:root:current train perplexity3.577308177947998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.93s/it]
INFO:root:eval mean loss: 4081.0985462378103
INFO:root:eval perplexity: 5.2084197998046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [11:44:28<1:58:46, 222.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.9619935501455
INFO:root:current train perplexity3.552785873413086
INFO:root:current mean train loss 3247.5184607872598
INFO:root:current train perplexity3.5828347206115723
INFO:root:current mean train loss 3230.7731280542694
INFO:root:current train perplexity3.5764379501342773
INFO:root:current mean train loss 3225.9307793709
INFO:root:current train perplexity3.570307731628418
INFO:root:current mean train loss 3226.9082835866957
INFO:root:current train perplexity3.5708184242248535
INFO:root:current mean train loss 3225.4107965009207
INFO:root:current train perplexity3.567138671875
INFO:root:current mean train loss 3230.2025368602986
INFO:root:current train perplexity3.5685338973999023
INFO:root:current mean train loss 3231.359827136608
INFO:root:current train perplexity3.57271409034729
INFO:root:current mean train loss 3232.9135183241583
INFO:root:current train perplexity3.574073314666748
INFO:root:current mean train loss 3230.9896461591993
INFO:root:current train perplexity3.573350429534912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4081.8710227587544
INFO:root:eval perplexity: 5.210046768188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [11:48:10<1:54:56, 222.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.965691061581
INFO:root:current train perplexity3.568699359893799
INFO:root:current mean train loss 3220.2105882657283
INFO:root:current train perplexity3.55576491355896
INFO:root:current mean train loss 3225.8101743416955
INFO:root:current train perplexity3.571169376373291
INFO:root:current mean train loss 3224.616903712607
INFO:root:current train perplexity3.5685102939605713
INFO:root:current mean train loss 3219.6030554930016
INFO:root:current train perplexity3.564255952835083
INFO:root:current mean train loss 3220.171200179361
INFO:root:current train perplexity3.5657098293304443
INFO:root:current mean train loss 3224.2155517953147
INFO:root:current train perplexity3.568047523498535
INFO:root:current mean train loss 3227.2570768272512
INFO:root:current train perplexity3.571298360824585
INFO:root:current mean train loss 3228.2799879851827
INFO:root:current train perplexity3.5701065063476562
INFO:root:current mean train loss 3229.0542885572754
INFO:root:current train perplexity3.5712978839874268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it]
INFO:root:eval mean loss: 4083.5891736619014
INFO:root:eval perplexity: 5.213668346405029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [11:51:51<1:51:04, 222.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.339955475371
INFO:root:current train perplexity3.5604031085968018
INFO:root:current mean train loss 3209.505391054933
INFO:root:current train perplexity3.5491859912872314
INFO:root:current mean train loss 3207.5472218870655
INFO:root:current train perplexity3.555220127105713
INFO:root:current mean train loss 3217.390992911081
INFO:root:current train perplexity3.5652992725372314
INFO:root:current mean train loss 3217.438316993464
INFO:root:current train perplexity3.5640647411346436
INFO:root:current mean train loss 3219.6447142462825
INFO:root:current train perplexity3.5666141510009766
INFO:root:current mean train loss 3222.861811590122
INFO:root:current train perplexity3.5677638053894043
INFO:root:current mean train loss 3224.9654021533265
INFO:root:current train perplexity3.5683348178863525
INFO:root:current mean train loss 3225.833752739832
INFO:root:current train perplexity3.569021701812744
INFO:root:current mean train loss 3225.2778758187237
INFO:root:current train perplexity3.5673980712890625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it]
INFO:root:eval mean loss: 4082.9226939965647
INFO:root:eval perplexity: 5.212263584136963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [11:55:34<1:47:25, 222.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.993011019123
INFO:root:current train perplexity3.5565943717956543
INFO:root:current mean train loss 3239.7506900261974
INFO:root:current train perplexity3.5737407207489014
INFO:root:current mean train loss 3230.222130478991
INFO:root:current train perplexity3.5756728649139404
INFO:root:current mean train loss 3229.895717360993
INFO:root:current train perplexity3.5763638019561768
INFO:root:current mean train loss 3222.378369872524
INFO:root:current train perplexity3.5713255405426025
INFO:root:current mean train loss 3220.5074676029267
INFO:root:current train perplexity3.5668227672576904
INFO:root:current mean train loss 3220.909473607923
INFO:root:current train perplexity3.567202091217041
INFO:root:current mean train loss 3223.6753878239083
INFO:root:current train perplexity3.568262815475464
INFO:root:current mean train loss 3226.085810220228
INFO:root:current train perplexity3.5680909156799316
INFO:root:current mean train loss 3226.1335562831246
INFO:root:current train perplexity3.567909002304077


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it]
INFO:root:eval mean loss: 4084.1169208499555
INFO:root:eval perplexity: 5.214779853820801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [11:59:18<1:43:58, 222.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.5053548177084
INFO:root:current train perplexity3.567134141921997
INFO:root:current mean train loss 3214.801982421875
INFO:root:current train perplexity3.5598881244659424
INFO:root:current mean train loss 3226.9027805397727
INFO:root:current train perplexity3.566753387451172
INFO:root:current mean train loss 3221.7803619791666
INFO:root:current train perplexity3.561922788619995
INFO:root:current mean train loss 3222.9801608758225
INFO:root:current train perplexity3.5637006759643555
INFO:root:current mean train loss 3224.335807999321
INFO:root:current train perplexity3.563749074935913
INFO:root:current mean train loss 3221.720810185185
INFO:root:current train perplexity3.563572406768799
INFO:root:current mean train loss 3223.5236047757057
INFO:root:current train perplexity3.564676284790039
INFO:root:current mean train loss 3225.632517857143
INFO:root:current train perplexity3.565497398376465
INFO:root:current mean train loss 3224.748775040064
INFO:root:current train perplexity3.5646719932556152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it]
INFO:root:eval mean loss: 4084.3819813829787
INFO:root:eval perplexity: 5.215339660644531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [12:03:03<1:40:31, 223.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.1630918204064
INFO:root:current train perplexity3.5853631496429443
INFO:root:current mean train loss 3225.1799636590677
INFO:root:current train perplexity3.5607035160064697
INFO:root:current mean train loss 3223.5321247653487
INFO:root:current train perplexity3.5640711784362793
INFO:root:current mean train loss 3223.831421854602
INFO:root:current train perplexity3.5590271949768066
INFO:root:current mean train loss 3231.688443201669
INFO:root:current train perplexity3.564619302749634
INFO:root:current mean train loss 3225.2202437386095
INFO:root:current train perplexity3.5625147819519043
INFO:root:current mean train loss 3223.216794372827
INFO:root:current train perplexity3.5612614154815674
INFO:root:current mean train loss 3225.0818441690612
INFO:root:current train perplexity3.5637147426605225
INFO:root:current mean train loss 3226.573546326444
INFO:root:current train perplexity3.565666437149048
INFO:root:current mean train loss 3224.6722048257884
INFO:root:current train perplexity3.565164089202881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it]
INFO:root:eval mean loss: 4085.302019268063
INFO:root:eval perplexity: 5.217279434204102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [12:06:45<1:36:41, 223.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.638985770089
INFO:root:current train perplexity3.548858404159546
INFO:root:current mean train loss 3203.9007293541395
INFO:root:current train perplexity3.546302080154419
INFO:root:current mean train loss 3213.232687828877
INFO:root:current train perplexity3.5530216693878174
INFO:root:current mean train loss 3217.5382751308744
INFO:root:current train perplexity3.555586814880371
INFO:root:current mean train loss 3213.4101487915286
INFO:root:current train perplexity3.550199031829834
INFO:root:current mean train loss 3215.331332289023
INFO:root:current train perplexity3.5509815216064453
INFO:root:current mean train loss 3218.0999471440846
INFO:root:current train perplexity3.5541913509368896
INFO:root:current mean train loss 3218.4626542005767
INFO:root:current train perplexity3.555210828781128
INFO:root:current mean train loss 3220.940982908512
INFO:root:current train perplexity3.5583035945892334
INFO:root:current mean train loss 3221.6780445395275
INFO:root:current train perplexity3.5610499382019043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.96s/it]
INFO:root:eval mean loss: 4086.448550393395
INFO:root:eval perplexity: 5.219699382781982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [12:10:28<1:32:54, 222.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.720096472538
INFO:root:current train perplexity3.5679373741149902
INFO:root:current mean train loss 3216.150584465295
INFO:root:current train perplexity3.5554254055023193
INFO:root:current mean train loss 3216.032201250261
INFO:root:current train perplexity3.5548176765441895
INFO:root:current mean train loss 3217.72890722901
INFO:root:current train perplexity3.5565075874328613
INFO:root:current mean train loss 3219.3277986637336
INFO:root:current train perplexity3.5584380626678467
INFO:root:current mean train loss 3220.1219219532554
INFO:root:current train perplexity3.561004400253296
INFO:root:current mean train loss 3220.435800795221
INFO:root:current train perplexity3.5585339069366455
INFO:root:current mean train loss 3218.92650358847
INFO:root:current train perplexity3.5577800273895264
INFO:root:current mean train loss 3219.4036641189864
INFO:root:current train perplexity3.558678150177002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.37s/it]
INFO:root:eval mean loss: 4085.75533473238
INFO:root:eval perplexity: 5.218235969543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [12:14:11<1:29:17, 223.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.7022530691966
INFO:root:current train perplexity3.457031726837158
INFO:root:current mean train loss 3233.2104629088785
INFO:root:current train perplexity3.55810546875
INFO:root:current mean train loss 3222.326064547479
INFO:root:current train perplexity3.550206184387207
INFO:root:current mean train loss 3218.278360870063
INFO:root:current train perplexity3.550853729248047
INFO:root:current mean train loss 3219.5825423257065
INFO:root:current train perplexity3.549409866333008
INFO:root:current mean train loss 3216.3253397744083
INFO:root:current train perplexity3.549161911010742
INFO:root:current mean train loss 3215.5677669217207
INFO:root:current train perplexity3.5515222549438477
INFO:root:current mean train loss 3216.703701337628
INFO:root:current train perplexity3.5549912452697754
INFO:root:current mean train loss 3217.7473867574736
INFO:root:current train perplexity3.55610990524292
INFO:root:current mean train loss 3220.4885781486873
INFO:root:current train perplexity3.5599653720855713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4087.7231653091753
INFO:root:eval perplexity: 5.222390651702881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [12:17:55<1:25:38, 223.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.573421223958
INFO:root:current train perplexity3.509810209274292
INFO:root:current mean train loss 3208.2175250509513
INFO:root:current train perplexity3.5280559062957764
INFO:root:current mean train loss 3213.1849098382995
INFO:root:current train perplexity3.5543696880340576
INFO:root:current mean train loss 3210.5020949590776
INFO:root:current train perplexity3.5547306537628174
INFO:root:current mean train loss 3212.6954848691644
INFO:root:current train perplexity3.550847053527832
INFO:root:current mean train loss 3212.537953674909
INFO:root:current train perplexity3.5495169162750244
INFO:root:current mean train loss 3215.3065648024644
INFO:root:current train perplexity3.550466537475586
INFO:root:current mean train loss 3217.904092684659
INFO:root:current train perplexity3.5531203746795654
INFO:root:current mean train loss 3217.9742939393213
INFO:root:current train perplexity3.553194046020508
INFO:root:current mean train loss 3216.5274627518784
INFO:root:current train perplexity3.5542306900024414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.05s/it]
INFO:root:eval mean loss: 4087.637376717642
INFO:root:eval perplexity: 5.222209453582764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [12:21:37<1:21:41, 222.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.91357421875
INFO:root:current train perplexity3.5591180324554443
INFO:root:current mean train loss 3228.0329192867125
INFO:root:current train perplexity3.54656720161438
INFO:root:current mean train loss 3221.908439602018
INFO:root:current train perplexity3.5423102378845215
INFO:root:current mean train loss 3224.4090549717007
INFO:root:current train perplexity3.5485780239105225
INFO:root:current mean train loss 3226.3371431968453
INFO:root:current train perplexity3.5517373085021973
INFO:root:current mean train loss 3221.1917204118367
INFO:root:current train perplexity3.5525498390197754
INFO:root:current mean train loss 3220.657597280046
INFO:root:current train perplexity3.5531580448150635
INFO:root:current mean train loss 3218.055337528635
INFO:root:current train perplexity3.5546116828918457
INFO:root:current mean train loss 3215.9745696242785
INFO:root:current train perplexity3.552443265914917
INFO:root:current mean train loss 3216.0664506872968
INFO:root:current train perplexity3.5548477172851562


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]
INFO:root:eval mean loss: 4087.6116501828456
INFO:root:eval perplexity: 5.222155570983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [12:25:19<1:17:54, 222.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.6339229460687
INFO:root:current train perplexity3.544637680053711
INFO:root:current mean train loss 3204.9191931804626
INFO:root:current train perplexity3.5444817543029785
INFO:root:current mean train loss 3204.614144725717
INFO:root:current train perplexity3.5523250102996826
INFO:root:current mean train loss 3204.263131225217
INFO:root:current train perplexity3.5503432750701904
INFO:root:current mean train loss 3207.3895680013775
INFO:root:current train perplexity3.5498249530792236
INFO:root:current mean train loss 3209.122780665166
INFO:root:current train perplexity3.546849489212036
INFO:root:current mean train loss 3210.9398206901246
INFO:root:current train perplexity3.5495569705963135
INFO:root:current mean train loss 3213.4187475953318
INFO:root:current train perplexity3.551494598388672
INFO:root:current mean train loss 3213.729486605464
INFO:root:current train perplexity3.549919605255127
INFO:root:current mean train loss 3213.0807442014634
INFO:root:current train perplexity3.549551486968994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it]
INFO:root:eval mean loss: 4088.0735729028147
INFO:root:eval perplexity: 5.223130226135254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [12:29:01<1:14:08, 222.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.602501502404
INFO:root:current train perplexity3.5740785598754883
INFO:root:current mean train loss 3207.1249279872977
INFO:root:current train perplexity3.550584077835083
INFO:root:current mean train loss 3205.3802076523275
INFO:root:current train perplexity3.54714298248291
INFO:root:current mean train loss 3211.5361897066277
INFO:root:current train perplexity3.547055959701538
INFO:root:current mean train loss 3210.3685172044065
INFO:root:current train perplexity3.5480785369873047
INFO:root:current mean train loss 3209.9182165142333
INFO:root:current train perplexity3.5465617179870605
INFO:root:current mean train loss 3209.153967915566
INFO:root:current train perplexity3.54539155960083
INFO:root:current mean train loss 3212.211626313536
INFO:root:current train perplexity3.547727346420288
INFO:root:current mean train loss 3214.05110337595
INFO:root:current train perplexity3.550790786743164
INFO:root:current mean train loss 3214.191502710247
INFO:root:current train perplexity3.550001382827759


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.52s/it]
INFO:root:eval mean loss: 4088.7143520057625
INFO:root:eval perplexity: 5.224483966827393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [12:32:44<1:10:31, 222.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.328109416556
INFO:root:current train perplexity3.529042959213257
INFO:root:current mean train loss 3207.1127879862884
INFO:root:current train perplexity3.5476977825164795
INFO:root:current mean train loss 3211.1563893677253
INFO:root:current train perplexity3.5462448596954346
INFO:root:current mean train loss 3218.384624206367
INFO:root:current train perplexity3.55226993560791
INFO:root:current mean train loss 3215.3460395693514
INFO:root:current train perplexity3.5491995811462402
INFO:root:current mean train loss 3213.635665865659
INFO:root:current train perplexity3.550189733505249
INFO:root:current mean train loss 3216.6022077557477
INFO:root:current train perplexity3.551370143890381
INFO:root:current mean train loss 3215.3114619938087
INFO:root:current train perplexity3.5515408515930176
INFO:root:current mean train loss 3214.9360446682226
INFO:root:current train perplexity3.551091194152832
INFO:root:current mean train loss 3214.3937900627807
INFO:root:current train perplexity3.5505757331848145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.01s/it]
INFO:root:eval mean loss: 4088.5940322334886
INFO:root:eval perplexity: 5.2242302894592285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [12:36:27<1:06:50, 222.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3208.834042080966
INFO:root:current train perplexity3.568169593811035
INFO:root:current mean train loss 3197.3287581905242
INFO:root:current train perplexity3.5498545169830322
INFO:root:current mean train loss 3197.592431640625
INFO:root:current train perplexity3.537353515625
INFO:root:current mean train loss 3205.2948097766284
INFO:root:current train perplexity3.5409746170043945
INFO:root:current mean train loss 3207.190242423592
INFO:root:current train perplexity3.539055109024048
INFO:root:current mean train loss 3205.9111292933558
INFO:root:current train perplexity3.5430736541748047
INFO:root:current mean train loss 3208.22592624344
INFO:root:current train perplexity3.54276967048645
INFO:root:current mean train loss 3209.783531663907
INFO:root:current train perplexity3.5460286140441895
INFO:root:current mean train loss 3211.428121573465
INFO:root:current train perplexity3.5464351177215576
INFO:root:current mean train loss 3211.772681303174
INFO:root:current train perplexity3.546079635620117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.36s/it]
INFO:root:eval mean loss: 4088.7771965730276
INFO:root:eval perplexity: 5.2246174812316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [12:40:10<1:03:07, 222.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3196.3137478298613
INFO:root:current train perplexity3.546729564666748
INFO:root:current mean train loss 3217.2580671251917
INFO:root:current train perplexity3.546738862991333
INFO:root:current mean train loss 3211.303377680905
INFO:root:current train perplexity3.547257661819458
INFO:root:current mean train loss 3212.510940593793
INFO:root:current train perplexity3.5509135723114014
INFO:root:current mean train loss 3211.4222815495073
INFO:root:current train perplexity3.548923969268799
INFO:root:current mean train loss 3210.2361355878106
INFO:root:current train perplexity3.548339366912842
INFO:root:current mean train loss 3212.2777101450556
INFO:root:current train perplexity3.548687219619751
INFO:root:current mean train loss 3213.859197734068
INFO:root:current train perplexity3.547902822494507
INFO:root:current mean train loss 3210.856683795173
INFO:root:current train perplexity3.546754837036133
INFO:root:current mean train loss 3211.3548570040725
INFO:root:current train perplexity3.548133373260498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]
INFO:root:eval mean loss: 4089.117379695811
INFO:root:eval perplexity: 5.225335597991943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [12:43:51<59:16, 222.27s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.23945381272
INFO:root:current train perplexity3.5449283123016357
INFO:root:current mean train loss 3217.6393643206325
INFO:root:current train perplexity3.542254686355591
INFO:root:current mean train loss 3215.3559435179313
INFO:root:current train perplexity3.541722297668457
INFO:root:current mean train loss 3210.807853431393
INFO:root:current train perplexity3.5388901233673096
INFO:root:current mean train loss 3210.2354951441416
INFO:root:current train perplexity3.5392937660217285
INFO:root:current mean train loss 3210.074572347718
INFO:root:current train perplexity3.540198564529419
INFO:root:current mean train loss 3209.332691266533
INFO:root:current train perplexity3.541423797607422
INFO:root:current mean train loss 3207.9550638755472
INFO:root:current train perplexity3.5419726371765137
INFO:root:current mean train loss 3211.7339996793376
INFO:root:current train perplexity3.543689489364624
INFO:root:current mean train loss 3210.529543278514
INFO:root:current train perplexity3.5445940494537354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.00s/it]
INFO:root:eval mean loss: 4089.95780695922
INFO:root:eval perplexity: 5.22711181640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [12:47:33<55:32, 222.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3194.2798716871043
INFO:root:current train perplexity3.522082805633545
INFO:root:current mean train loss 3194.388415459148
INFO:root:current train perplexity3.537208080291748
INFO:root:current mean train loss 3198.7454724602376
INFO:root:current train perplexity3.546400547027588
INFO:root:current mean train loss 3202.431476361519
INFO:root:current train perplexity3.541881561279297
INFO:root:current mean train loss 3205.590058328712
INFO:root:current train perplexity3.5427911281585693
INFO:root:current mean train loss 3207.862909768324
INFO:root:current train perplexity3.5418996810913086
INFO:root:current mean train loss 3209.327740271769
INFO:root:current train perplexity3.543428897857666
INFO:root:current mean train loss 3209.385981627086
INFO:root:current train perplexity3.5443172454833984
INFO:root:current mean train loss 3210.6094869325048
INFO:root:current train perplexity3.5444319248199463
INFO:root:current mean train loss 3209.5123581540474
INFO:root:current train perplexity3.5434041023254395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.59s/it]
INFO:root:eval mean loss: 4090.5980787344856
INFO:root:eval perplexity: 5.228466033935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [12:51:15<51:48, 222.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.021585398707
INFO:root:current train perplexity3.555243492126465
INFO:root:current mean train loss 3206.9073336188167
INFO:root:current train perplexity3.547046184539795
INFO:root:current mean train loss 3211.1798695421385
INFO:root:current train perplexity3.542430877685547
INFO:root:current mean train loss 3211.7680897478604
INFO:root:current train perplexity3.540952682495117
INFO:root:current mean train loss 3212.9195985265337
INFO:root:current train perplexity3.541229724884033
INFO:root:current mean train loss 3211.1355022059997
INFO:root:current train perplexity3.542558431625366
INFO:root:current mean train loss 3212.6943384251044
INFO:root:current train perplexity3.5439116954803467
INFO:root:current mean train loss 3210.9197645950803
INFO:root:current train perplexity3.5438480377197266
INFO:root:current mean train loss 3209.5208873727274
INFO:root:current train perplexity3.5433127880096436
INFO:root:current mean train loss 3208.940120986892
INFO:root:current train perplexity3.5432076454162598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.42s/it]
INFO:root:eval mean loss: 4090.2886971548096
INFO:root:eval perplexity: 5.227810859680176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [12:54:58<48:10, 222.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.6427965666117
INFO:root:current train perplexity3.527237892150879
INFO:root:current mean train loss 3206.773626552484
INFO:root:current train perplexity3.537020444869995
INFO:root:current mean train loss 3206.423053495763
INFO:root:current train perplexity3.5388612747192383
INFO:root:current mean train loss 3204.237887534612
INFO:root:current train perplexity3.5378427505493164
INFO:root:current mean train loss 3202.8383374763257
INFO:root:current train perplexity3.5365195274353027
INFO:root:current mean train loss 3206.357130957852
INFO:root:current train perplexity3.5411548614501953
INFO:root:current mean train loss 3209.459238000225
INFO:root:current train perplexity3.5431530475616455
INFO:root:current mean train loss 3208.3955827437107
INFO:root:current train perplexity3.5416674613952637
INFO:root:current mean train loss 3207.324899070356
INFO:root:current train perplexity3.54154372215271


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it]
INFO:root:eval mean loss: 4089.8149794991136
INFO:root:eval perplexity: 5.226809024810791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [12:58:40<44:26, 222.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3174.704345703125
INFO:root:current train perplexity3.483654737472534
INFO:root:current mean train loss 3207.95204177412
INFO:root:current train perplexity3.5274271965026855
INFO:root:current mean train loss 3205.3836315136236
INFO:root:current train perplexity3.535426616668701
INFO:root:current mean train loss 3208.246521600402
INFO:root:current train perplexity3.540944814682007
INFO:root:current mean train loss 3205.0912286270936
INFO:root:current train perplexity3.5403809547424316
INFO:root:current mean train loss 3205.434065528703
INFO:root:current train perplexity3.5422585010528564
INFO:root:current mean train loss 3202.339370854063
INFO:root:current train perplexity3.541618585586548
INFO:root:current mean train loss 3204.3175585381846
INFO:root:current train perplexity3.5390326976776123
INFO:root:current mean train loss 3204.451786027008
INFO:root:current train perplexity3.5391664505004883
INFO:root:current mean train loss 3209.2892996111054
INFO:root:current train perplexity3.5418739318847656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.40s/it]
INFO:root:eval mean loss: 4090.239353044659
INFO:root:eval perplexity: 5.2277069091796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [13:02:21<40:42, 222.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.09619140625
INFO:root:current train perplexity3.5325756072998047
INFO:root:current mean train loss 3189.758883639499
INFO:root:current train perplexity3.5283422470092773
INFO:root:current mean train loss 3204.2810104876335
INFO:root:current train perplexity3.5350406169891357
INFO:root:current mean train loss 3207.940213022508
INFO:root:current train perplexity3.5400583744049072
INFO:root:current mean train loss 3204.320030342343
INFO:root:current train perplexity3.5417473316192627
INFO:root:current mean train loss 3202.3468884731224
INFO:root:current train perplexity3.539626359939575
INFO:root:current mean train loss 3200.14688315134
INFO:root:current train perplexity3.5366029739379883
INFO:root:current mean train loss 3201.4574151448223
INFO:root:current train perplexity3.537470817565918
INFO:root:current mean train loss 3201.0252656948405
INFO:root:current train perplexity3.535426139831543
INFO:root:current mean train loss 3203.9361367251818
INFO:root:current train perplexity3.5369656085968018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it]
INFO:root:eval mean loss: 4091.13360206117
INFO:root:eval perplexity: 5.229598045349121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [13:06:03<36:58, 221.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.9209369860196
INFO:root:current train perplexity3.554720878601074
INFO:root:current mean train loss 3224.0129640723476
INFO:root:current train perplexity3.5485212802886963
INFO:root:current mean train loss 3215.7830292166095
INFO:root:current train perplexity3.5390772819519043
INFO:root:current mean train loss 3216.1068578259697
INFO:root:current train perplexity3.541161298751831
INFO:root:current mean train loss 3208.3996803447567
INFO:root:current train perplexity3.5392603874206543
INFO:root:current mean train loss 3208.5445168555816
INFO:root:current train perplexity3.538677453994751
INFO:root:current mean train loss 3205.8413046496366
INFO:root:current train perplexity3.5381877422332764
INFO:root:current mean train loss 3205.1735232038855
INFO:root:current train perplexity3.537677764892578
INFO:root:current mean train loss 3203.0411014766482
INFO:root:current train perplexity3.5371906757354736
INFO:root:current mean train loss 3203.8214527084465
INFO:root:current train perplexity3.536975383758545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.57s/it]
INFO:root:eval mean loss: 4091.1493084413787
INFO:root:eval perplexity: 5.229630947113037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [13:09:46<33:19, 222.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.272822627315
INFO:root:current train perplexity3.5506043434143066
INFO:root:current mean train loss 3220.5015205923964
INFO:root:current train perplexity3.5343329906463623
INFO:root:current mean train loss 3212.3555763009363
INFO:root:current train perplexity3.53664231300354
INFO:root:current mean train loss 3210.4102973588015
INFO:root:current train perplexity3.535191297531128
INFO:root:current mean train loss 3207.9807237540253
INFO:root:current train perplexity3.5363378524780273
INFO:root:current mean train loss 3211.1099679791273
INFO:root:current train perplexity3.5375120639801025
INFO:root:current mean train loss 3206.305117763781
INFO:root:current train perplexity3.5357043743133545
INFO:root:current mean train loss 3204.4333640496047
INFO:root:current train perplexity3.535017251968384
INFO:root:current mean train loss 3203.0873291310836
INFO:root:current train perplexity3.5353965759277344
INFO:root:current mean train loss 3203.704382837783
INFO:root:current train perplexity3.5363223552703857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.08s/it]
INFO:root:eval mean loss: 4090.901007036791
INFO:root:eval perplexity: 5.229106426239014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [13:13:28<29:38, 222.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.097314453125
INFO:root:current train perplexity3.5390803813934326
INFO:root:current mean train loss 3205.5748137297455
INFO:root:current train perplexity3.538370370864868
INFO:root:current mean train loss 3200.180336810173
INFO:root:current train perplexity3.5371110439300537
INFO:root:current mean train loss 3202.4059759794777
INFO:root:current train perplexity3.538228750228882
INFO:root:current mean train loss 3207.482645249641
INFO:root:current train perplexity3.5394339561462402
INFO:root:current mean train loss 3201.642188869013
INFO:root:current train perplexity3.534092903137207
INFO:root:current mean train loss 3203.104452202264
INFO:root:current train perplexity3.536231517791748
INFO:root:current mean train loss 3201.902144783695
INFO:root:current train perplexity3.536595344543457
INFO:root:current mean train loss 3201.953324113492
INFO:root:current train perplexity3.535505771636963
INFO:root:current mean train loss 3203.1759888348097
INFO:root:current train perplexity3.536388397216797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.06s/it]
INFO:root:eval mean loss: 4091.395161513741
INFO:root:eval perplexity: 5.2301506996154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [13:17:10<25:54, 222.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.1935183502906
INFO:root:current train perplexity3.5567500591278076
INFO:root:current mean train loss 3205.847393329327
INFO:root:current train perplexity3.551778793334961
INFO:root:current mean train loss 3205.2855239679784
INFO:root:current train perplexity3.5415492057800293
INFO:root:current mean train loss 3199.3209794380923
INFO:root:current train perplexity3.5393617153167725
INFO:root:current mean train loss 3203.5031319439545
INFO:root:current train perplexity3.5366008281707764
INFO:root:current mean train loss 3204.0788632668623
INFO:root:current train perplexity3.5355162620544434
INFO:root:current mean train loss 3203.627717820519
INFO:root:current train perplexity3.5364596843719482
INFO:root:current mean train loss 3202.8937521686785
INFO:root:current train perplexity3.5350875854492188
INFO:root:current mean train loss 3205.7420261876296
INFO:root:current train perplexity3.5367391109466553
INFO:root:current mean train loss 3205.7119031887923
INFO:root:current train perplexity3.5367467403411865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.44s/it]
INFO:root:eval mean loss: 4091.352177180297
INFO:root:eval perplexity: 5.230059623718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [13:20:52<22:12, 222.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3173.7956064261643
INFO:root:current train perplexity3.5046324729919434
INFO:root:current mean train loss 3189.4189453125
INFO:root:current train perplexity3.5207695960998535
INFO:root:current mean train loss 3195.6579609297187
INFO:root:current train perplexity3.532686471939087
INFO:root:current mean train loss 3195.883176972044
INFO:root:current train perplexity3.532177686691284
INFO:root:current mean train loss 3199.109416141214
INFO:root:current train perplexity3.5335612297058105
INFO:root:current mean train loss 3201.010921194419
INFO:root:current train perplexity3.5357422828674316
INFO:root:current mean train loss 3204.2816220238096
INFO:root:current train perplexity3.5380165576934814
INFO:root:current mean train loss 3201.268762418338
INFO:root:current train perplexity3.535219669342041
INFO:root:current mean train loss 3202.2810755728556
INFO:root:current train perplexity3.535842180252075
INFO:root:current mean train loss 3202.690002248866
INFO:root:current train perplexity3.5356945991516113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4091.5303600121897
INFO:root:eval perplexity: 5.230435848236084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [13:24:34<18:31, 222.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.4751762778073
INFO:root:current train perplexity3.5646324157714844
INFO:root:current mean train loss 3215.664712006191
INFO:root:current train perplexity3.546738862991333
INFO:root:current mean train loss 3212.806224926098
INFO:root:current train perplexity3.5384867191314697
INFO:root:current mean train loss 3208.6075109625262
INFO:root:current train perplexity3.534843683242798
INFO:root:current mean train loss 3205.2442491319443
INFO:root:current train perplexity3.5337772369384766
INFO:root:current mean train loss 3199.6890124489883
INFO:root:current train perplexity3.531592607498169
INFO:root:current mean train loss 3198.4152072564966
INFO:root:current train perplexity3.531670331954956
INFO:root:current mean train loss 3199.2159895061345
INFO:root:current train perplexity3.532195806503296
INFO:root:current mean train loss 3200.805098474789
INFO:root:current train perplexity3.5315911769866943
INFO:root:current mean train loss 3201.1298833216565
INFO:root:current train perplexity3.532395362854004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.11s/it]
INFO:root:eval mean loss: 4091.734375
INFO:root:eval perplexity: 5.230867385864258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [13:28:16<14:47, 221.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.971821799207
INFO:root:current train perplexity3.5391790866851807
INFO:root:current mean train loss 3204.988035647455
INFO:root:current train perplexity3.540405750274658
INFO:root:current mean train loss 3207.947987988647
INFO:root:current train perplexity3.5382726192474365
INFO:root:current mean train loss 3207.4087432944484
INFO:root:current train perplexity3.5364036560058594
INFO:root:current mean train loss 3208.6107541069996
INFO:root:current train perplexity3.538007974624634
INFO:root:current mean train loss 3207.3521067570546
INFO:root:current train perplexity3.5375349521636963
INFO:root:current mean train loss 3203.7188693251032
INFO:root:current train perplexity3.534785509109497
INFO:root:current mean train loss 3204.155016246333
INFO:root:current train perplexity3.53625226020813
INFO:root:current mean train loss 3202.699804462226
INFO:root:current train perplexity3.5349879264831543
INFO:root:current mean train loss 3201.801265996639
INFO:root:current train perplexity3.5340945720672607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.45s/it]
INFO:root:eval mean loss: 4091.988229305186
INFO:root:eval perplexity: 5.231405258178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [13:32:00<11:08, 222.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3197.6700065104164
INFO:root:current train perplexity3.527348041534424
INFO:root:current mean train loss 3201.1508272879464
INFO:root:current train perplexity3.5292463302612305
INFO:root:current mean train loss 3199.6238236860795
INFO:root:current train perplexity3.531909465789795
INFO:root:current mean train loss 3195.921360026042
INFO:root:current train perplexity3.5295979976654053
INFO:root:current mean train loss 3199.5764437705593
INFO:root:current train perplexity3.528944969177246
INFO:root:current mean train loss 3201.2865327785325
INFO:root:current train perplexity3.529308557510376
INFO:root:current mean train loss 3202.7377007378473
INFO:root:current train perplexity3.5316109657287598
INFO:root:current mean train loss 3199.9068038054434
INFO:root:current train perplexity3.5298807621002197
INFO:root:current mean train loss 3201.7942156808035
INFO:root:current train perplexity3.5306484699249268
INFO:root:current mean train loss 3200.7887352263624
INFO:root:current train perplexity3.5321128368377686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.28s/it]
INFO:root:eval mean loss: 4091.9925615026596
INFO:root:eval perplexity: 5.231414318084717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [13:35:42<07:25, 222.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.779746917357
INFO:root:current train perplexity3.532961845397949
INFO:root:current mean train loss 3204.553972421448
INFO:root:current train perplexity3.533292055130005
INFO:root:current mean train loss 3207.8336815716098
INFO:root:current train perplexity3.5408201217651367
INFO:root:current mean train loss 3204.3826805493227
INFO:root:current train perplexity3.537996292114258
INFO:root:current mean train loss 3197.6082250622735
INFO:root:current train perplexity3.536175489425659
INFO:root:current mean train loss 3201.3272870490728
INFO:root:current train perplexity3.539104461669922
INFO:root:current mean train loss 3202.5608564295844
INFO:root:current train perplexity3.5361084938049316
INFO:root:current mean train loss 3201.585091894157
INFO:root:current train perplexity3.532758951187134
INFO:root:current mean train loss 3201.6092273543672
INFO:root:current train perplexity3.5309295654296875
INFO:root:current mean train loss 3201.4506160390706
INFO:root:current train perplexity3.532158374786377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.19s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.38s/it]
INFO:root:eval mean loss: 4092.1179753296765
INFO:root:eval perplexity: 5.231679439544678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [13:39:24<03:42, 222.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3194.6385779747598
INFO:root:current train perplexity3.5359723567962646
INFO:root:current mean train loss 3195.807844711224
INFO:root:current train perplexity3.525291919708252
INFO:root:current mean train loss 3192.980715407539
INFO:root:current train perplexity3.527172327041626
INFO:root:current mean train loss 3197.0214693893863
INFO:root:current train perplexity3.528364896774292
INFO:root:current mean train loss 3198.839929771035
INFO:root:current train perplexity3.5299441814422607
INFO:root:current mean train loss 3198.6266102540717
INFO:root:current train perplexity3.532487154006958
INFO:root:current mean train loss 3198.1889199727525
INFO:root:current train perplexity3.531647205352783
INFO:root:current mean train loss 3199.8594574090353
INFO:root:current train perplexity3.5314602851867676
INFO:root:current mean train loss 3200.6476598668983
INFO:root:current train perplexity3.5319511890411377
INFO:root:current mean train loss 3200.664284714777
INFO:root:current train perplexity3.5316097736358643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.95s/it]
INFO:root:eval mean loss: 4092.0149393284573
INFO:root:eval perplexity: 5.231462001800537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_120/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:43:06<00:00, 222.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:43:06<00:00, 246.93s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4092.0149393284573
INFO:root:eval perplexity: 5.231462001800537
INFO:root:evalaution complete
INFO:root:save model final: small_val_120/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x146344ae7f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x146344adf8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x146344a04e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x146344ae8a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x146344a02948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x146344ae8a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x1463449bdb46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14634442246a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x146440c3ea27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x146440c3ebe0]
python(+0x24a989) [0x55c14dd7c989]
python(+0x24a9bd) [0x55c14dd7c9bd]
python(+0x24aa14) [0x55c14dd7ca14]
python(+0x108f75) [0x55c14dc3af75]
python(Py_RunMain+0x313) [0x55c14dd7f983]
python(Py_BytesMain+0x39) [0x55c14dd7fbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x146440c1c0b3]
python(+0x1d6e13) [0x55c14dd08e13]
/opt/slurm/data/slurmd/job26146191/slurm_script: line 129: 1052577 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_120_final  --output small_val_120 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
