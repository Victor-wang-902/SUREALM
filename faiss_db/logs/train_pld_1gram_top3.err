INFO:root:Output: pld_13
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12241.750069049875
INFO:root:current train perplexity16748.17578125
INFO:root:current mean train loss 10568.3909537924
INFO:root:current train perplexity4191.61474609375
INFO:root:current mean train loss 9192.60648777174
INFO:root:current train perplexity1404.9793701171875
INFO:root:current mean train loss 8240.903066993656
INFO:root:current train perplexity662.6233520507812
INFO:root:current mean train loss 7546.0455931394035
INFO:root:current train perplexity383.8480529785156
INFO:root:current mean train loss 7018.201212633035
INFO:root:current train perplexity253.09884643554688
INFO:root:current mean train loss 6606.428271204958
INFO:root:current train perplexity182.33946228027344
INFO:root:current mean train loss 6278.856614897039
INFO:root:current train perplexity140.37298583984375
INFO:root:current mean train loss 6000.263036131726
INFO:root:current train perplexity113.25213623046875
INFO:root:current mean train loss 5774.656397364161
INFO:root:current train perplexity94.30215454101562
INFO:root:current mean train loss 5573.518372304012
INFO:root:current train perplexity80.65817260742188
INFO:root:current mean train loss 5402.3788123810855
INFO:root:current train perplexity70.5177993774414
INFO:root:current mean train loss 5254.047038512197
INFO:root:current train perplexity62.56211471557617
INFO:root:current mean train loss 5116.588793020405
INFO:root:current train perplexity56.27973175048828
INFO:root:current mean train loss 4996.244386394315
INFO:root:current train perplexity51.257476806640625
INFO:root:current mean train loss 4888.0007737990545
INFO:root:current train perplexity47.089847564697266
INFO:root:current mean train loss 4790.876289246432
INFO:root:current train perplexity43.58732604980469
INFO:root:current mean train loss 4700.712937308922
INFO:root:current train perplexity40.642425537109375
INFO:root:current mean train loss 4616.449067174541
INFO:root:current train perplexity38.08812713623047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.87s/it]
INFO:root:final mean train loss: 4550.908367916844
INFO:root:final train perplexity: 36.20221710205078
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 3508.3378283068223
INFO:root:eval perplexity: 17.793746948242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/1
  1%|          | 1/100 [05:58<9:52:12, 358.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3047.461471557617
INFO:root:current train perplexity10.982181549072266
INFO:root:current mean train loss 3037.9430941877695
INFO:root:current train perplexity10.998888969421387
INFO:root:current mean train loss 3019.431297019676
INFO:root:current train perplexity10.931380271911621
INFO:root:current mean train loss 3017.0066304267207
INFO:root:current train perplexity10.902538299560547
INFO:root:current mean train loss 3007.7750930786133
INFO:root:current train perplexity10.793502807617188
INFO:root:current mean train loss 2995.970472232316
INFO:root:current train perplexity10.646592140197754
INFO:root:current mean train loss 2975.7924887917256
INFO:root:current train perplexity10.503400802612305
INFO:root:current mean train loss 2963.1225660952778
INFO:root:current train perplexity10.393516540527344
INFO:root:current mean train loss 2952.1612345377603
INFO:root:current train perplexity10.303061485290527
INFO:root:current mean train loss 2943.9428332466227
INFO:root:current train perplexity10.213333129882812
INFO:root:current mean train loss 2929.484065018301
INFO:root:current train perplexity10.116015434265137
INFO:root:current mean train loss 2918.983070072735
INFO:root:current train perplexity10.013038635253906
INFO:root:current mean train loss 2909.99160846911
INFO:root:current train perplexity9.92805290222168
INFO:root:current mean train loss 2899.5016138140554
INFO:root:current train perplexity9.83915901184082
INFO:root:current mean train loss 2888.8827873273085
INFO:root:current train perplexity9.759420394897461
INFO:root:current mean train loss 2878.9646476000785
INFO:root:current train perplexity9.677183151245117
INFO:root:current mean train loss 2868.230986491288
INFO:root:current train perplexity9.597853660583496
INFO:root:current mean train loss 2859.079836687564
INFO:root:current train perplexity9.52692699432373
INFO:root:current mean train loss 2847.382223389747
INFO:root:current train perplexity9.449397087097168
INFO:root:current mean train loss 2837.846367376085
INFO:root:current train perplexity9.372401237487793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.48s/it]
INFO:root:final mean train loss: 2831.1029024417508
INFO:root:final train perplexity: 9.325737953186035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.88s/it]
INFO:root:eval mean loss: 3376.343303508587
INFO:root:eval perplexity: 15.967188835144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/2
  2%|â–         | 2/100 [12:04<9:52:15, 362.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2680.960870916193
INFO:root:current train perplexity8.262677192687988
INFO:root:current mean train loss 2626.5893719895444
INFO:root:current train perplexity8.000326156616211
INFO:root:current mean train loss 2622.485298123994
INFO:root:current train perplexity7.956958770751953
INFO:root:current mean train loss 2608.933584218985
INFO:root:current train perplexity7.884416580200195
INFO:root:current mean train loss 2610.5252569960667
INFO:root:current train perplexity7.849895000457764
INFO:root:current mean train loss 2604.6972527996013
INFO:root:current train perplexity7.800869464874268
INFO:root:current mean train loss 2598.8941906873274
INFO:root:current train perplexity7.75678014755249
INFO:root:current mean train loss 2591.9878632466107
INFO:root:current train perplexity7.718042373657227
INFO:root:current mean train loss 2586.509896634435
INFO:root:current train perplexity7.684216022491455
INFO:root:current mean train loss 2579.0873235802687
INFO:root:current train perplexity7.647297382354736
INFO:root:current mean train loss 2573.2193432168137
INFO:root:current train perplexity7.612641334533691
INFO:root:current mean train loss 2567.1416362550335
INFO:root:current train perplexity7.584168434143066
INFO:root:current mean train loss 2560.8419336967127
INFO:root:current train perplexity7.550079345703125
INFO:root:current mean train loss 2553.5682994845392
INFO:root:current train perplexity7.5102105140686035
INFO:root:current mean train loss 2551.644411820427
INFO:root:current train perplexity7.489627361297607
INFO:root:current mean train loss 2549.632630549143
INFO:root:current train perplexity7.464448928833008
INFO:root:current mean train loss 2544.46391585117
INFO:root:current train perplexity7.434140682220459
INFO:root:current mean train loss 2539.9855072320847
INFO:root:current train perplexity7.403388977050781
INFO:root:current mean train loss 2534.937338038734
INFO:root:current train perplexity7.370332717895508
INFO:root:current mean train loss 2529.2061377938276
INFO:root:current train perplexity7.341238021850586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.18s/it]
INFO:root:final mean train loss: 2524.847656680909
INFO:root:final train perplexity: 7.324660778045654
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 3352.555716849662
INFO:root:eval perplexity: 15.658546447753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/3
  3%|â–Ž         | 3/100 [18:10<9:48:38, 364.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2430.0268505859376
INFO:root:current train perplexity6.760044574737549
INFO:root:current mean train loss 2423.4040478515626
INFO:root:current train perplexity6.755712509155273
INFO:root:current mean train loss 2415.8004677734375
INFO:root:current train perplexity6.7305779457092285
INFO:root:current mean train loss 2408.1713940429686
INFO:root:current train perplexity6.680444717407227
INFO:root:current mean train loss 2410.7226662868925
INFO:root:current train perplexity6.667162895202637
INFO:root:current mean train loss 2402.418485440341
INFO:root:current train perplexity6.630527019500732
INFO:root:current mean train loss 2398.0704490309495
INFO:root:current train perplexity6.6133246421813965
INFO:root:current mean train loss 2394.0382526041667
INFO:root:current train perplexity6.594799518585205
INFO:root:current mean train loss 2390.816963752298
INFO:root:current train perplexity6.58579158782959
INFO:root:current mean train loss 2387.229535490337
INFO:root:current train perplexity6.565330982208252
INFO:root:current mean train loss 2382.9308726283484
INFO:root:current train perplexity6.544402122497559
INFO:root:current mean train loss 2381.828315005095
INFO:root:current train perplexity6.535211086273193
INFO:root:current mean train loss 2377.896367675781
INFO:root:current train perplexity6.51887845993042
INFO:root:current mean train loss 2374.611501464844
INFO:root:current train perplexity6.501009941101074
INFO:root:current mean train loss 2373.5316644497575
INFO:root:current train perplexity6.493885517120361
INFO:root:current mean train loss 2369.8550420551915
INFO:root:current train perplexity6.47746467590332
INFO:root:current mean train loss 2367.4470333214963
INFO:root:current train perplexity6.463510990142822
INFO:root:current mean train loss 2363.788433454241
INFO:root:current train perplexity6.444194793701172
INFO:root:current mean train loss 2361.8974226008236
INFO:root:current train perplexity6.434527397155762
INFO:root:current mean train loss 2359.1378449894833
INFO:root:current train perplexity6.422667980194092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.02s/it]
INFO:root:final mean train loss: 2357.38397675407
INFO:root:final train perplexity: 6.4184370040893555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it]
INFO:root:eval mean loss: 3308.734547291432
INFO:root:eval perplexity: 15.105487823486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/4
  4%|â–         | 4/100 [24:19<9:45:50, 366.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2321.9391907649256
INFO:root:current train perplexity6.123114585876465
INFO:root:current mean train loss 2284.7204662939744
INFO:root:current train perplexity6.035672664642334
INFO:root:current mean train loss 2282.27045340663
INFO:root:current train perplexity6.0409698486328125
INFO:root:current mean train loss 2281.279262282868
INFO:root:current train perplexity6.042037010192871
INFO:root:current mean train loss 2282.022083225291
INFO:root:current train perplexity6.049829483032227
INFO:root:current mean train loss 2276.265817685943
INFO:root:current train perplexity6.017806529998779
INFO:root:current mean train loss 2276.786023553165
INFO:root:current train perplexity6.014278411865234
INFO:root:current mean train loss 2273.008113776534
INFO:root:current train perplexity5.998106956481934
INFO:root:current mean train loss 2272.641855277267
INFO:root:current train perplexity5.986816883087158
INFO:root:current mean train loss 2268.4635567729206
INFO:root:current train perplexity5.970299243927002
INFO:root:current mean train loss 2267.222870187661
INFO:root:current train perplexity5.963264465332031
INFO:root:current mean train loss 2266.353016883569
INFO:root:current train perplexity5.956234455108643
INFO:root:current mean train loss 2262.811821339162
INFO:root:current train perplexity5.943694114685059
INFO:root:current mean train loss 2261.957251994559
INFO:root:current train perplexity5.93768310546875
INFO:root:current mean train loss 2258.957388557377
INFO:root:current train perplexity5.930628776550293
INFO:root:current mean train loss 2256.265731957587
INFO:root:current train perplexity5.923971652984619
INFO:root:current mean train loss 2252.256972799776
INFO:root:current train perplexity5.908264636993408
INFO:root:current mean train loss 2250.427137632861
INFO:root:current train perplexity5.896876811981201
INFO:root:current mean train loss 2248.098778355358
INFO:root:current train perplexity5.886651515960693
INFO:root:current mean train loss 2245.7280690474868
INFO:root:current train perplexity5.874166488647461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.64s/it]
INFO:root:final mean train loss: 2244.729692129192
INFO:root:final train perplexity: 5.872783184051514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it]
INFO:root:eval mean loss: 3274.176324517877
INFO:root:eval perplexity: 14.683150291442871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/5
  5%|â–Œ         | 5/100 [30:31<9:43:27, 368.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2198.1566961379276
INFO:root:current train perplexity5.615025997161865
INFO:root:current mean train loss 2191.0147353462553
INFO:root:current train perplexity5.616303443908691
INFO:root:current mean train loss 2187.895802242655
INFO:root:current train perplexity5.627889156341553
INFO:root:current mean train loss 2188.6104685465493
INFO:root:current train perplexity5.628462791442871
INFO:root:current mean train loss 2193.6400782057076
INFO:root:current train perplexity5.63655424118042
INFO:root:current mean train loss 2186.60349012401
INFO:root:current train perplexity5.605770587921143
INFO:root:current mean train loss 2184.3268509357295
INFO:root:current train perplexity5.587503433227539
INFO:root:current mean train loss 2184.131061631806
INFO:root:current train perplexity5.5914306640625
INFO:root:current mean train loss 2181.79285717442
INFO:root:current train perplexity5.578744411468506
INFO:root:current mean train loss 2176.791555389156
INFO:root:current train perplexity5.559866905212402
INFO:root:current mean train loss 2175.875087160906
INFO:root:current train perplexity5.558300018310547
INFO:root:current mean train loss 2173.7887871200974
INFO:root:current train perplexity5.550036907196045
INFO:root:current mean train loss 2172.1190055300513
INFO:root:current train perplexity5.543410778045654
INFO:root:current mean train loss 2171.7195199955404
INFO:root:current train perplexity5.539259433746338
INFO:root:current mean train loss 2171.7194509172054
INFO:root:current train perplexity5.5392303466796875
INFO:root:current mean train loss 2170.4370927907
INFO:root:current train perplexity5.530415058135986
INFO:root:current mean train loss 2169.0821735445506
INFO:root:current train perplexity5.523523330688477
INFO:root:current mean train loss 2165.678454001388
INFO:root:current train perplexity5.515993118286133
INFO:root:current mean train loss 2164.764688609259
INFO:root:current train perplexity5.50930118560791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.29s/it]
INFO:root:final mean train loss: 2161.9262087731067
INFO:root:final train perplexity: 5.501524448394775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.16s/it]
INFO:root:eval mean loss: 3297.712425071556
INFO:root:eval perplexity: 14.969483375549316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/6
  6%|â–Œ         | 6/100 [36:54<9:44:49, 373.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2242.712890625
INFO:root:current train perplexity5.176958084106445
INFO:root:current mean train loss 2094.043808738784
INFO:root:current train perplexity5.22811222076416
INFO:root:current mean train loss 2107.7721275215717
INFO:root:current train perplexity5.283902168273926
INFO:root:current mean train loss 2118.589707079916
INFO:root:current train perplexity5.305198669433594
INFO:root:current mean train loss 2114.4687956622115
INFO:root:current train perplexity5.2965407371521
INFO:root:current mean train loss 2111.233455208723
INFO:root:current train perplexity5.293721675872803
INFO:root:current mean train loss 2108.2399494088627
INFO:root:current train perplexity5.284428596496582
INFO:root:current mean train loss 2110.152598164731
INFO:root:current train perplexity5.286332607269287
INFO:root:current mean train loss 2110.0515273876404
INFO:root:current train perplexity5.284345626831055
INFO:root:current mean train loss 2108.454326600002
INFO:root:current train perplexity5.275416374206543
INFO:root:current mean train loss 2105.1044441398444
INFO:root:current train perplexity5.264718055725098
INFO:root:current mean train loss 2103.5380273969686
INFO:root:current train perplexity5.256195545196533
INFO:root:current mean train loss 2102.7805821198804
INFO:root:current train perplexity5.252000331878662
INFO:root:current mean train loss 2102.1505735897267
INFO:root:current train perplexity5.250260829925537
INFO:root:current mean train loss 2101.7850111771445
INFO:root:current train perplexity5.249261379241943
INFO:root:current mean train loss 2101.8810119425593
INFO:root:current train perplexity5.245375156402588
INFO:root:current mean train loss 2100.297774629992
INFO:root:current train perplexity5.238924026489258
INFO:root:current mean train loss 2099.830158644042
INFO:root:current train perplexity5.2376508712768555
INFO:root:current mean train loss 2099.3274883501135
INFO:root:current train perplexity5.233299255371094
INFO:root:current mean train loss 2098.5831092702033
INFO:root:current train perplexity5.230108737945557

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.95s/it]
INFO:root:final mean train loss: 2097.207016722217
INFO:root:final train perplexity: 5.2277631759643555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.59s/it]
INFO:root:eval mean loss: 3273.4088043121246
INFO:root:eval perplexity: 14.673911094665527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/7
  7%|â–‹         | 7/100 [43:10<9:39:49, 374.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2051.0787014431426
INFO:root:current train perplexity5.028711795806885
INFO:root:current mean train loss 2042.1340952727753
INFO:root:current train perplexity5.058547019958496
INFO:root:current mean train loss 2057.8341730800244
INFO:root:current train perplexity5.096014976501465
INFO:root:current mean train loss 2062.719649020981
INFO:root:current train perplexity5.1028032302856445
INFO:root:current mean train loss 2060.387440074574
INFO:root:current train perplexity5.078124046325684
INFO:root:current mean train loss 2060.296150354805
INFO:root:current train perplexity5.075469017028809
INFO:root:current mean train loss 2059.2949181220292
INFO:root:current train perplexity5.067504405975342
INFO:root:current mean train loss 2059.5749353605393
INFO:root:current train perplexity5.067601203918457
INFO:root:current mean train loss 2058.1019606462028
INFO:root:current train perplexity5.058409214019775
INFO:root:current mean train loss 2056.428928084363
INFO:root:current train perplexity5.0543532371521
INFO:root:current mean train loss 2053.835632084395
INFO:root:current train perplexity5.047320365905762
INFO:root:current mean train loss 2053.839742971021
INFO:root:current train perplexity5.042194843292236
INFO:root:current mean train loss 2053.512350448834
INFO:root:current train perplexity5.038882732391357
INFO:root:current mean train loss 2053.675305657394
INFO:root:current train perplexity5.042198657989502
INFO:root:current mean train loss 2053.333711481565
INFO:root:current train perplexity5.038393974304199
INFO:root:current mean train loss 2053.2122161825027
INFO:root:current train perplexity5.03489351272583
INFO:root:current mean train loss 2050.9763701902184
INFO:root:current train perplexity5.028307914733887
INFO:root:current mean train loss 2048.747936883822
INFO:root:current train perplexity5.020994663238525
INFO:root:current mean train loss 2047.3332330852713
INFO:root:current train perplexity5.0185675621032715
INFO:root:current mean train loss 2044.7696317447985
INFO:root:current train perplexity5.013682842254639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.06s/it]
INFO:root:final mean train loss: 2044.0269966221674
INFO:root:final train perplexity: 5.0130414962768555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.85s/it]
INFO:root:eval mean loss: 3269.5175627287445
INFO:root:eval perplexity: 14.627126693725586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/8
  8%|â–Š         | 8/100 [50:04<9:53:08, 386.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.8023018973215
INFO:root:current train perplexity4.850584983825684
INFO:root:current mean train loss 2014.8074309172455
INFO:root:current train perplexity4.864211082458496
INFO:root:current mean train loss 2005.2146250623339
INFO:root:current train perplexity4.85775899887085
INFO:root:current mean train loss 2007.8183688491138
INFO:root:current train perplexity4.8717122077941895
INFO:root:current mean train loss 2005.385536492008
INFO:root:current train perplexity4.875261306762695
INFO:root:current mean train loss 2004.1326158184872
INFO:root:current train perplexity4.865148067474365
INFO:root:current mean train loss 2006.9169529712105
INFO:root:current train perplexity4.863774299621582
INFO:root:current mean train loss 2008.7893151108099
INFO:root:current train perplexity4.865954399108887
INFO:root:current mean train loss 2008.8985696575598
INFO:root:current train perplexity4.867832660675049
INFO:root:current mean train loss 2010.3120820886948
INFO:root:current train perplexity4.869498252868652
INFO:root:current mean train loss 2008.906614913572
INFO:root:current train perplexity4.86790657043457
INFO:root:current mean train loss 2005.883221623761
INFO:root:current train perplexity4.8604936599731445
INFO:root:current mean train loss 2003.7322482089764
INFO:root:current train perplexity4.8559722900390625
INFO:root:current mean train loss 2004.2560015617685
INFO:root:current train perplexity4.856769561767578
INFO:root:current mean train loss 2003.6328306191474
INFO:root:current train perplexity4.854702949523926
INFO:root:current mean train loss 2004.2853783623016
INFO:root:current train perplexity4.853810787200928
INFO:root:current mean train loss 2003.1259109357081
INFO:root:current train perplexity4.851409435272217
INFO:root:current mean train loss 2001.3682524315561
INFO:root:current train perplexity4.845566749572754
INFO:root:current mean train loss 1999.759549623744
INFO:root:current train perplexity4.840290546417236
INFO:root:current mean train loss 1999.7202041192263
INFO:root:current train perplexity4.839809894561768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 334.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 334.00s/it]
INFO:root:final mean train loss: 2000.2579564543246
INFO:root:final train perplexity: 4.8429484367370605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.82s/it]
INFO:root:eval mean loss: 3270.264182884056
INFO:root:eval perplexity: 14.636088371276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/9
  9%|â–‰         | 9/100 [56:20<9:41:47, 383.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.8323082557092
INFO:root:current train perplexity4.686877727508545
INFO:root:current mean train loss 1958.833490472091
INFO:root:current train perplexity4.661264419555664
INFO:root:current mean train loss 1967.9724062965029
INFO:root:current train perplexity4.698960304260254
INFO:root:current mean train loss 1962.988973790949
INFO:root:current train perplexity4.700808525085449
INFO:root:current mean train loss 1968.7893660553789
INFO:root:current train perplexity4.713345527648926
INFO:root:current mean train loss 1971.61307669377
INFO:root:current train perplexity4.722248554229736
INFO:root:current mean train loss 1974.274869953928
INFO:root:current train perplexity4.728469371795654
INFO:root:current mean train loss 1971.246198938248
INFO:root:current train perplexity4.721930027008057
INFO:root:current mean train loss 1970.4938737036478
INFO:root:current train perplexity4.722171306610107
INFO:root:current mean train loss 1966.82873278706
INFO:root:current train perplexity4.713971138000488
INFO:root:current mean train loss 1967.6488929429436
INFO:root:current train perplexity4.715742111206055
INFO:root:current mean train loss 1966.7404542499119
INFO:root:current train perplexity4.709095001220703
INFO:root:current mean train loss 1966.328987097207
INFO:root:current train perplexity4.708627223968506
INFO:root:current mean train loss 1966.5729017991287
INFO:root:current train perplexity4.7118706703186035
INFO:root:current mean train loss 1965.2093698380736
INFO:root:current train perplexity4.707908630371094
INFO:root:current mean train loss 1962.2250613969627
INFO:root:current train perplexity4.69968843460083
INFO:root:current mean train loss 1961.9025259687594
INFO:root:current train perplexity4.696217060089111
INFO:root:current mean train loss 1963.2677599763217
INFO:root:current train perplexity4.699038505554199
INFO:root:current mean train loss 1961.4621917526872
INFO:root:current train perplexity4.6945881843566895
INFO:root:current mean train loss 1961.4518350695
INFO:root:current train perplexity4.69431734085083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.58s/it]
INFO:root:final mean train loss: 1960.600382302304
INFO:root:final train perplexity: 4.693822383880615
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.70s/it]
INFO:root:eval mean loss: 3269.6764975424644
INFO:root:eval perplexity: 14.629034042358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/10
 10%|â–ˆ         | 10/100 [1:02:35<9:31:10, 380.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.424606544384
INFO:root:current train perplexity4.594447135925293
INFO:root:current mean train loss 1948.9452272674741
INFO:root:current train perplexity4.595386028289795
INFO:root:current mean train loss 1932.1877382413163
INFO:root:current train perplexity4.56580114364624
INFO:root:current mean train loss 1931.0033021839008
INFO:root:current train perplexity4.568262577056885
INFO:root:current mean train loss 1932.5151580615338
INFO:root:current train perplexity4.5714640617370605
INFO:root:current mean train loss 1935.9951023845974
INFO:root:current train perplexity4.58115816116333
INFO:root:current mean train loss 1931.5737762679255
INFO:root:current train perplexity4.572728157043457
INFO:root:current mean train loss 1932.8539899372156
INFO:root:current train perplexity4.580961227416992
INFO:root:current mean train loss 1934.316908016578
INFO:root:current train perplexity4.579095363616943
INFO:root:current mean train loss 1933.3362015447626
INFO:root:current train perplexity4.579375743865967
INFO:root:current mean train loss 1931.7830856223325
INFO:root:current train perplexity4.579644680023193
INFO:root:current mean train loss 1931.65548332743
INFO:root:current train perplexity4.5795440673828125
INFO:root:current mean train loss 1930.7147751636069
INFO:root:current train perplexity4.575875282287598
INFO:root:current mean train loss 1931.2835614891972
INFO:root:current train perplexity4.577917575836182
INFO:root:current mean train loss 1932.0467189427864
INFO:root:current train perplexity4.579247951507568
INFO:root:current mean train loss 1930.017407428846
INFO:root:current train perplexity4.575419902801514
INFO:root:current mean train loss 1928.8532698021597
INFO:root:current train perplexity4.573208808898926
INFO:root:current mean train loss 1927.567521720097
INFO:root:current train perplexity4.57124137878418
INFO:root:current mean train loss 1926.522235737694
INFO:root:current train perplexity4.569633483886719
INFO:root:current mean train loss 1927.7907677026133
INFO:root:current train perplexity4.572408676147461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.89s/it]
INFO:root:final mean train loss: 1927.447212130748
INFO:root:final train perplexity: 4.572686195373535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.84s/it]
INFO:root:eval mean loss: 3281.343196467952
INFO:root:eval perplexity: 14.769753456115723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/11
 11%|â–ˆ         | 11/100 [1:08:52<9:23:06, 379.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.9253256154616
INFO:root:current train perplexity4.531968116760254
INFO:root:current mean train loss 1900.910424017137
INFO:root:current train perplexity4.476161479949951
INFO:root:current mean train loss 1900.2428947395379
INFO:root:current train perplexity4.469610214233398
INFO:root:current mean train loss 1909.1195798883784
INFO:root:current train perplexity4.492833614349365
INFO:root:current mean train loss 1903.0291519479006
INFO:root:current train perplexity4.472415924072266
INFO:root:current mean train loss 1902.190741529237
INFO:root:current train perplexity4.467372417449951
INFO:root:current mean train loss 1903.2263135548583
INFO:root:current train perplexity4.470406532287598
INFO:root:current mean train loss 1903.1869455585042
INFO:root:current train perplexity4.475684642791748
INFO:root:current mean train loss 1900.6742344290085
INFO:root:current train perplexity4.471655368804932
INFO:root:current mean train loss 1900.7686065611927
INFO:root:current train perplexity4.474383354187012
INFO:root:current mean train loss 1896.930133067881
INFO:root:current train perplexity4.4650774002075195
INFO:root:current mean train loss 1899.6380194266771
INFO:root:current train perplexity4.468790054321289
INFO:root:current mean train loss 1898.2797677854358
INFO:root:current train perplexity4.4665093421936035
INFO:root:current mean train loss 1898.2035644883545
INFO:root:current train perplexity4.466864585876465
INFO:root:current mean train loss 1897.4658562928478
INFO:root:current train perplexity4.464315414428711
INFO:root:current mean train loss 1896.680189096612
INFO:root:current train perplexity4.460869312286377
INFO:root:current mean train loss 1896.739568346053
INFO:root:current train perplexity4.460931301116943
INFO:root:current mean train loss 1897.137908354585
INFO:root:current train perplexity4.462997913360596
INFO:root:current mean train loss 1896.952201252651
INFO:root:current train perplexity4.4622087478637695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.11s/it]
INFO:root:final mean train loss: 1896.6849024816408
INFO:root:final train perplexity: 4.463082790374756
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it]
INFO:root:eval mean loss: 3294.0183728650527
INFO:root:eval perplexity: 14.924172401428223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/12
 12%|â–ˆâ–        | 12/100 [1:15:11<9:16:30, 379.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1765.7555338541667
INFO:root:current train perplexity4.082065105438232
INFO:root:current mean train loss 1871.4799816538987
INFO:root:current train perplexity4.3679986000061035
INFO:root:current mean train loss 1877.5192179562423
INFO:root:current train perplexity4.389379024505615
INFO:root:current mean train loss 1873.3440255646658
INFO:root:current train perplexity4.383885383605957
INFO:root:current mean train loss 1869.1028050122131
INFO:root:current train perplexity4.379753589630127
INFO:root:current mean train loss 1872.0691002908331
INFO:root:current train perplexity4.387247085571289
INFO:root:current mean train loss 1869.9111627733728
INFO:root:current train perplexity4.3841376304626465
INFO:root:current mean train loss 1868.2923033539296
INFO:root:current train perplexity4.380043983459473
INFO:root:current mean train loss 1867.667046609881
INFO:root:current train perplexity4.375051975250244
INFO:root:current mean train loss 1871.1255581708974
INFO:root:current train perplexity4.380280017852783
INFO:root:current mean train loss 1870.221303253326
INFO:root:current train perplexity4.376338481903076
INFO:root:current mean train loss 1869.0532421343778
INFO:root:current train perplexity4.373351573944092
INFO:root:current mean train loss 1867.795768959762
INFO:root:current train perplexity4.373659610748291
INFO:root:current mean train loss 1866.5500809617529
INFO:root:current train perplexity4.370450973510742
INFO:root:current mean train loss 1866.8258288948348
INFO:root:current train perplexity4.369970321655273
INFO:root:current mean train loss 1867.2873008052904
INFO:root:current train perplexity4.367105960845947
INFO:root:current mean train loss 1869.1798025644057
INFO:root:current train perplexity4.368553638458252
INFO:root:current mean train loss 1868.1736641938169
INFO:root:current train perplexity4.367228984832764
INFO:root:current mean train loss 1869.2943831542698
INFO:root:current train perplexity4.369757175445557
INFO:root:current mean train loss 1870.3218023607872
INFO:root:current train perplexity4.371629238128662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it]
INFO:root:final mean train loss: 1870.5370170681751
INFO:root:final train perplexity: 4.371988296508789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it]
INFO:root:eval mean loss: 3280.8851519977006
INFO:root:eval perplexity: 14.764204978942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/13
 13%|â–ˆâ–Ž        | 13/100 [1:21:30<9:10:12, 379.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1909.8332824707031
INFO:root:current train perplexity4.3554277420043945
INFO:root:current mean train loss 1853.7683634440104
INFO:root:current train perplexity4.284936904907227
INFO:root:current mean train loss 1860.1274741432883
INFO:root:current train perplexity4.307758808135986
INFO:root:current mean train loss 1850.4550506591797
INFO:root:current train perplexity4.291080951690674
INFO:root:current mean train loss 1852.621178327288
INFO:root:current train perplexity4.289715766906738
INFO:root:current mean train loss 1853.8039257342998
INFO:root:current train perplexity4.302144527435303
INFO:root:current mean train loss 1852.8160337386594
INFO:root:current train perplexity4.298554420471191
INFO:root:current mean train loss 1853.5318990071614
INFO:root:current train perplexity4.299550533294678
INFO:root:current mean train loss 1853.9022912002192
INFO:root:current train perplexity4.300923824310303
INFO:root:current mean train loss 1853.7915134595787
INFO:root:current train perplexity4.299526214599609
INFO:root:current mean train loss 1851.5475504557292
INFO:root:current train perplexity4.298020839691162
INFO:root:current mean train loss 1852.1660066877093
INFO:root:current train perplexity4.30031681060791
INFO:root:current mean train loss 1849.3082569560067
INFO:root:current train perplexity4.297806739807129
INFO:root:current mean train loss 1848.2626341848663
INFO:root:current train perplexity4.297027111053467
INFO:root:current mean train loss 1847.3377163739272
INFO:root:current train perplexity4.29136323928833
INFO:root:current mean train loss 1846.0678792853105
INFO:root:current train perplexity4.288856506347656
INFO:root:current mean train loss 1845.9881190923998
INFO:root:current train perplexity4.287303447723389
INFO:root:current mean train loss 1845.5183898925782
INFO:root:current train perplexity4.2854485511779785
INFO:root:current mean train loss 1845.829939890432
INFO:root:current train perplexity4.286880016326904
INFO:root:current mean train loss 1846.7310155868531
INFO:root:current train perplexity4.287869453430176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it]
INFO:root:final mean train loss: 1845.6363447519245
INFO:root:final train perplexity: 4.28696870803833
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.67s/it]
INFO:root:eval mean loss: 3294.295630102759
INFO:root:eval perplexity: 14.927570343017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/14
 14%|â–ˆâ–        | 14/100 [1:27:47<9:02:28, 378.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1800.670067039696
INFO:root:current train perplexity4.158395290374756
INFO:root:current mean train loss 1801.1765600051324
INFO:root:current train perplexity4.179539680480957
INFO:root:current mean train loss 1817.555937046743
INFO:root:current train perplexity4.205934524536133
INFO:root:current mean train loss 1814.7753279598248
INFO:root:current train perplexity4.20286750793457
INFO:root:current mean train loss 1813.486053536631
INFO:root:current train perplexity4.207356929779053
INFO:root:current mean train loss 1817.1421237142836
INFO:root:current train perplexity4.21158504486084
INFO:root:current mean train loss 1816.8065896505839
INFO:root:current train perplexity4.205962657928467
INFO:root:current mean train loss 1814.3232180053215
INFO:root:current train perplexity4.203815460205078
INFO:root:current mean train loss 1815.9822980545755
INFO:root:current train perplexity4.20660924911499
INFO:root:current mean train loss 1817.3589136862577
INFO:root:current train perplexity4.210464000701904
INFO:root:current mean train loss 1817.6619482233532
INFO:root:current train perplexity4.211055278778076
INFO:root:current mean train loss 1820.1491758267714
INFO:root:current train perplexity4.213493824005127
INFO:root:current mean train loss 1821.7230093361586
INFO:root:current train perplexity4.216218948364258
INFO:root:current mean train loss 1821.916734808135
INFO:root:current train perplexity4.2164435386657715
INFO:root:current mean train loss 1821.8852615515723
INFO:root:current train perplexity4.21242618560791
INFO:root:current mean train loss 1822.9934935014435
INFO:root:current train perplexity4.216862201690674
INFO:root:current mean train loss 1823.0568207849726
INFO:root:current train perplexity4.216159343719482
INFO:root:current mean train loss 1823.8998287642353
INFO:root:current train perplexity4.214653968811035
INFO:root:current mean train loss 1823.9722479091888
INFO:root:current train perplexity4.2135090827941895
INFO:root:current mean train loss 1825.0580622998475
INFO:root:current train perplexity4.215229511260986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.18s/it]
INFO:root:final mean train loss: 1823.9571019806046
INFO:root:final train perplexity: 4.214294910430908
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.85s/it]
INFO:root:eval mean loss: 3291.9390792159347
INFO:root:eval perplexity: 14.898735046386719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/15
 15%|â–ˆâ–Œ        | 15/100 [1:34:04<8:55:38, 378.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.0096322518807
INFO:root:current train perplexity4.138180255889893
INFO:root:current mean train loss 1804.6627807617188
INFO:root:current train perplexity4.112591743469238
INFO:root:current mean train loss 1801.7818603515625
INFO:root:current train perplexity4.133543491363525
INFO:root:current mean train loss 1798.3737641242938
INFO:root:current train perplexity4.1382341384887695
INFO:root:current mean train loss 1798.5667971976527
INFO:root:current train perplexity4.136300563812256
INFO:root:current mean train loss 1797.9240226883321
INFO:root:current train perplexity4.137585639953613
INFO:root:current mean train loss 1799.2130046692828
INFO:root:current train perplexity4.136883735656738
INFO:root:current mean train loss 1800.5390123119405
INFO:root:current train perplexity4.14204216003418
INFO:root:current mean train loss 1801.6876580910605
INFO:root:current train perplexity4.1422038078308105
INFO:root:current mean train loss 1800.0862898916569
INFO:root:current train perplexity4.139870643615723
INFO:root:current mean train loss 1800.5102512424767
INFO:root:current train perplexity4.13973331451416
INFO:root:current mean train loss 1799.8653521083256
INFO:root:current train perplexity4.140600204467773
INFO:root:current mean train loss 1801.7027608333021
INFO:root:current train perplexity4.144299030303955
INFO:root:current mean train loss 1803.762439812304
INFO:root:current train perplexity4.148923873901367
INFO:root:current mean train loss 1803.4113184366133
INFO:root:current train perplexity4.146638870239258
INFO:root:current mean train loss 1803.801921122783
INFO:root:current train perplexity4.148460865020752
INFO:root:current mean train loss 1803.1478760798868
INFO:root:current train perplexity4.1471333503723145
INFO:root:current mean train loss 1803.1076097129553
INFO:root:current train perplexity4.146387100219727
INFO:root:current mean train loss 1803.022187694891
INFO:root:current train perplexity4.146644115447998
INFO:root:current mean train loss 1804.5002081567459
INFO:root:current train perplexity4.148585796356201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.24s/it]
INFO:root:final mean train loss: 1804.3373508809254
INFO:root:final train perplexity: 4.149588108062744
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it]
INFO:root:eval mean loss: 3303.671354459929
INFO:root:eval perplexity: 15.042855262756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/16
 16%|â–ˆâ–Œ        | 16/100 [1:40:20<8:48:29, 377.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1800.1206467319541
INFO:root:current train perplexity4.142875671386719
INFO:root:current mean train loss 1778.4461591397112
INFO:root:current train perplexity4.087512016296387
INFO:root:current mean train loss 1777.0185727052583
INFO:root:current train perplexity4.090913772583008
INFO:root:current mean train loss 1777.8966804771733
INFO:root:current train perplexity4.085005283355713
INFO:root:current mean train loss 1779.8511483421244
INFO:root:current train perplexity4.084078788757324
INFO:root:current mean train loss 1781.052013069861
INFO:root:current train perplexity4.081244945526123
INFO:root:current mean train loss 1780.1821740231464
INFO:root:current train perplexity4.080331802368164
INFO:root:current mean train loss 1782.279521066391
INFO:root:current train perplexity4.079893112182617
INFO:root:current mean train loss 1781.3867820976247
INFO:root:current train perplexity4.080875873565674
INFO:root:current mean train loss 1782.6531561273011
INFO:root:current train perplexity4.081786155700684
INFO:root:current mean train loss 1782.0857520579846
INFO:root:current train perplexity4.078492641448975
INFO:root:current mean train loss 1783.4658851525805
INFO:root:current train perplexity4.079901695251465
INFO:root:current mean train loss 1781.8989241485235
INFO:root:current train perplexity4.077800273895264
INFO:root:current mean train loss 1782.4730535349995
INFO:root:current train perplexity4.081303119659424
INFO:root:current mean train loss 1782.2083999146255
INFO:root:current train perplexity4.081475257873535
INFO:root:current mean train loss 1783.037149857898
INFO:root:current train perplexity4.0837297439575195
INFO:root:current mean train loss 1782.8631509978354
INFO:root:current train perplexity4.080729961395264
INFO:root:current mean train loss 1783.7411794377074
INFO:root:current train perplexity4.083415985107422
INFO:root:current mean train loss 1783.6578204727377
INFO:root:current train perplexity4.0840349197387695
INFO:root:current mean train loss 1785.2040912196576
INFO:root:current train perplexity4.0864667892456055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.75s/it]
INFO:root:final mean train loss: 1785.127643964174
INFO:root:final train perplexity: 4.087195873260498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.95s/it]
INFO:root:eval mean loss: 3303.875927441113
INFO:root:eval perplexity: 15.045388221740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/17
 17%|â–ˆâ–‹        | 17/100 [1:46:51<8:47:48, 381.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.2163959849966
INFO:root:current train perplexity3.9948339462280273
INFO:root:current mean train loss 1758.6429105718084
INFO:root:current train perplexity4.006440162658691
INFO:root:current mean train loss 1766.8355577256943
INFO:root:current train perplexity4.019829750061035
INFO:root:current mean train loss 1759.2413490531371
INFO:root:current train perplexity4.010931491851807
INFO:root:current mean train loss 1762.0915592381211
INFO:root:current train perplexity4.021291255950928
INFO:root:current mean train loss 1764.0932974263924
INFO:root:current train perplexity4.0230560302734375
INFO:root:current mean train loss 1765.507583618164
INFO:root:current train perplexity4.028532981872559
INFO:root:current mean train loss 1763.431749063095
INFO:root:current train perplexity4.025888442993164
INFO:root:current mean train loss 1764.3027848252304
INFO:root:current train perplexity4.026556015014648
INFO:root:current mean train loss 1768.2584172916797
INFO:root:current train perplexity4.031562328338623
INFO:root:current mean train loss 1769.4607547311223
INFO:root:current train perplexity4.031130790710449
INFO:root:current mean train loss 1769.242515075889
INFO:root:current train perplexity4.028088569641113
INFO:root:current mean train loss 1767.1465772545855
INFO:root:current train perplexity4.025843620300293
INFO:root:current mean train loss 1766.480116698515
INFO:root:current train perplexity4.024259090423584
INFO:root:current mean train loss 1766.9887019331736
INFO:root:current train perplexity4.025192737579346
INFO:root:current mean train loss 1766.956066371812
INFO:root:current train perplexity4.027150630950928
INFO:root:current mean train loss 1767.9898666454153
INFO:root:current train perplexity4.030266761779785
INFO:root:current mean train loss 1767.8223220176612
INFO:root:current train perplexity4.031381130218506
INFO:root:current mean train loss 1767.801656432071
INFO:root:current train perplexity4.0316691398620605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.94s/it]
INFO:root:final mean train loss: 1767.9967126581805
INFO:root:final train perplexity: 4.032346725463867
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.64s/it]
INFO:root:eval mean loss: 3313.168237084741
INFO:root:eval perplexity: 15.16054916381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/18
 18%|â–ˆâ–Š        | 18/100 [1:53:08<8:39:30, 380.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1767.555078125
INFO:root:current train perplexity4.024631977081299
INFO:root:current mean train loss 1748.4460960751487
INFO:root:current train perplexity3.977498769760132
INFO:root:current mean train loss 1752.163779058689
INFO:root:current train perplexity3.978872537612915
INFO:root:current mean train loss 1756.411937275871
INFO:root:current train perplexity3.990783929824829
INFO:root:current mean train loss 1752.5709728853203
INFO:root:current train perplexity3.985950469970703
INFO:root:current mean train loss 1750.4439975247524
INFO:root:current train perplexity3.9802021980285645
INFO:root:current mean train loss 1754.1870395628873
INFO:root:current train perplexity3.986647605895996
INFO:root:current mean train loss 1753.5380597919436
INFO:root:current train perplexity3.9880478382110596
INFO:root:current mean train loss 1753.8346905631308
INFO:root:current train perplexity3.9849929809570312
INFO:root:current mean train loss 1755.6870157652797
INFO:root:current train perplexity3.99029803276062
INFO:root:current mean train loss 1758.4816756063433
INFO:root:current train perplexity3.9961276054382324
INFO:root:current mean train loss 1756.3425919338588
INFO:root:current train perplexity3.989995241165161
INFO:root:current mean train loss 1755.1297751272368
INFO:root:current train perplexity3.986042022705078
INFO:root:current mean train loss 1754.0984114957496
INFO:root:current train perplexity3.9847898483276367
INFO:root:current mean train loss 1753.6551886399022
INFO:root:current train perplexity3.9830026626586914
INFO:root:current mean train loss 1752.0834582154537
INFO:root:current train perplexity3.9812111854553223
INFO:root:current mean train loss 1751.1512410101489
INFO:root:current train perplexity3.9798216819763184
INFO:root:current mean train loss 1751.5875672281663
INFO:root:current train perplexity3.980241060256958
INFO:root:current mean train loss 1750.8103126082065
INFO:root:current train perplexity3.978621244430542
INFO:root:current mean train loss 1751.3040617695005
INFO:root:current train perplexity3.980219841003418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it]
INFO:root:final mean train loss: 1752.2094837059833
INFO:root:final train perplexity: 3.982451915740967
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it]
INFO:root:eval mean loss: 3303.7774874483857
INFO:root:eval perplexity: 15.044168472290039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/19
 19%|â–ˆâ–‰        | 19/100 [1:59:24<8:31:33, 378.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.8271761807528
INFO:root:current train perplexity3.8909859657287598
INFO:root:current mean train loss 1726.4726642546107
INFO:root:current train perplexity3.888845920562744
INFO:root:current mean train loss 1720.6210024721988
INFO:root:current train perplexity3.885159492492676
INFO:root:current mean train loss 1721.9362747476707
INFO:root:current train perplexity3.8882558345794678
INFO:root:current mean train loss 1731.4300597855265
INFO:root:current train perplexity3.899199962615967
INFO:root:current mean train loss 1732.6947723037895
INFO:root:current train perplexity3.9068105220794678
INFO:root:current mean train loss 1732.2947214991334
INFO:root:current train perplexity3.9108216762542725
INFO:root:current mean train loss 1730.869339116062
INFO:root:current train perplexity3.9126205444335938
INFO:root:current mean train loss 1733.1775024117055
INFO:root:current train perplexity3.914370536804199
INFO:root:current mean train loss 1734.4056089322635
INFO:root:current train perplexity3.9166858196258545
INFO:root:current mean train loss 1733.675389239466
INFO:root:current train perplexity3.919074296951294
INFO:root:current mean train loss 1733.8117314574977
INFO:root:current train perplexity3.921355724334717
INFO:root:current mean train loss 1734.8888854481
INFO:root:current train perplexity3.9240028858184814
INFO:root:current mean train loss 1736.592913790658
INFO:root:current train perplexity3.9284989833831787
INFO:root:current mean train loss 1736.5958894067005
INFO:root:current train perplexity3.927558183670044
INFO:root:current mean train loss 1737.5273989302727
INFO:root:current train perplexity3.9305713176727295
INFO:root:current mean train loss 1737.1322991574589
INFO:root:current train perplexity3.9296679496765137
INFO:root:current mean train loss 1737.1506669490873
INFO:root:current train perplexity3.931962251663208
INFO:root:current mean train loss 1737.6477422620017
INFO:root:current train perplexity3.933698892593384
INFO:root:current mean train loss 1737.9699212271762
INFO:root:current train perplexity3.934506893157959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.07s/it]
INFO:root:final mean train loss: 1736.2177931977474
INFO:root:final train perplexity: 3.9325406551361084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.62s/it]
INFO:root:eval mean loss: 3325.953633076436
INFO:root:eval perplexity: 15.32043743133545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/20
 20%|â–ˆâ–ˆ        | 20/100 [2:05:52<8:28:49, 381.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.278091821915
INFO:root:current train perplexity3.853187322616577
INFO:root:current mean train loss 1732.231784299123
INFO:root:current train perplexity3.881929874420166
INFO:root:current mean train loss 1727.5555302448352
INFO:root:current train perplexity3.8762221336364746
INFO:root:current mean train loss 1726.7077478279407
INFO:root:current train perplexity3.876997709274292
INFO:root:current mean train loss 1724.7899637070223
INFO:root:current train perplexity3.877734899520874
INFO:root:current mean train loss 1725.110514171933
INFO:root:current train perplexity3.8836796283721924
INFO:root:current mean train loss 1722.9495893547046
INFO:root:current train perplexity3.8854360580444336
INFO:root:current mean train loss 1724.3957565782518
INFO:root:current train perplexity3.8872900009155273
INFO:root:current mean train loss 1722.875046849393
INFO:root:current train perplexity3.886718273162842
INFO:root:current mean train loss 1722.852489792374
INFO:root:current train perplexity3.8847742080688477
INFO:root:current mean train loss 1722.7635575589134
INFO:root:current train perplexity3.8852548599243164
INFO:root:current mean train loss 1723.4074583782033
INFO:root:current train perplexity3.8866686820983887
INFO:root:current mean train loss 1721.8343462509142
INFO:root:current train perplexity3.883307695388794
INFO:root:current mean train loss 1723.137460835395
INFO:root:current train perplexity3.885862112045288
INFO:root:current mean train loss 1723.7001139605684
INFO:root:current train perplexity3.889137029647827
INFO:root:current mean train loss 1724.9760709667144
INFO:root:current train perplexity3.8928422927856445
INFO:root:current mean train loss 1723.6686055414411
INFO:root:current train perplexity3.890662670135498
INFO:root:current mean train loss 1723.9315376479165
INFO:root:current train perplexity3.89209246635437
INFO:root:current mean train loss 1723.7092591825551
INFO:root:current train perplexity3.890859365463257
INFO:root:current mean train loss 1722.778842778474
INFO:root:current train perplexity3.889846086502075

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.01s/it]
INFO:root:final mean train loss: 1721.8453040418756
INFO:root:final train perplexity: 3.888216972351074
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.67s/it]
INFO:root:eval mean loss: 3318.6265733506943
INFO:root:eval perplexity: 15.22860050201416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/21
 21%|â–ˆâ–ˆ        | 21/100 [2:12:23<8:26:08, 384.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1684.431889125279
INFO:root:current train perplexity3.8305110931396484
INFO:root:current mean train loss 1694.011463654347
INFO:root:current train perplexity3.833494186401367
INFO:root:current mean train loss 1699.0440459251404
INFO:root:current train perplexity3.8416197299957275
INFO:root:current mean train loss 1702.3221538415116
INFO:root:current train perplexity3.844275951385498
INFO:root:current mean train loss 1703.6759231299684
INFO:root:current train perplexity3.8449230194091797
INFO:root:current mean train loss 1703.4729096117637
INFO:root:current train perplexity3.836395740509033
INFO:root:current mean train loss 1702.3970147109612
INFO:root:current train perplexity3.8361868858337402
INFO:root:current mean train loss 1704.0771621623367
INFO:root:current train perplexity3.8371994495391846
INFO:root:current mean train loss 1704.485634349217
INFO:root:current train perplexity3.8393192291259766
INFO:root:current mean train loss 1706.351285543402
INFO:root:current train perplexity3.84098744392395
INFO:root:current mean train loss 1706.2050299210982
INFO:root:current train perplexity3.841221809387207
INFO:root:current mean train loss 1706.5772068327274
INFO:root:current train perplexity3.8411788940429688
INFO:root:current mean train loss 1706.3720942211758
INFO:root:current train perplexity3.839627742767334
INFO:root:current mean train loss 1707.5945761351459
INFO:root:current train perplexity3.843088388442993
INFO:root:current mean train loss 1707.8765407184978
INFO:root:current train perplexity3.842268228530884
INFO:root:current mean train loss 1708.419981105775
INFO:root:current train perplexity3.843724250793457
INFO:root:current mean train loss 1708.8841591065632
INFO:root:current train perplexity3.843256950378418
INFO:root:current mean train loss 1709.187757696269
INFO:root:current train perplexity3.8448140621185303
INFO:root:current mean train loss 1709.4890848357102
INFO:root:current train perplexity3.845961809158325
INFO:root:current mean train loss 1709.2087524039614
INFO:root:current train perplexity3.8477272987365723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it]
INFO:root:final mean train loss: 1708.8438531411036
INFO:root:final train perplexity: 3.8485522270202637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.33s/it]
INFO:root:eval mean loss: 3322.0497233072915
INFO:root:eval perplexity: 15.271438598632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:18:50<8:21:02, 385.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1691.6589221693066
INFO:root:current train perplexity3.812866687774658
INFO:root:current mean train loss 1696.9445313911217
INFO:root:current train perplexity3.806553840637207
INFO:root:current mean train loss 1695.6109297196945
INFO:root:current train perplexity3.805123805999756
INFO:root:current mean train loss 1693.3517568961545
INFO:root:current train perplexity3.8057942390441895
INFO:root:current mean train loss 1690.5087387375297
INFO:root:current train perplexity3.791602849960327
INFO:root:current mean train loss 1692.5098065281413
INFO:root:current train perplexity3.797372817993164
INFO:root:current mean train loss 1692.8758508645408
INFO:root:current train perplexity3.7999801635742188
INFO:root:current mean train loss 1691.1145196398973
INFO:root:current train perplexity3.798409938812256
INFO:root:current mean train loss 1691.0331076221094
INFO:root:current train perplexity3.7982430458068848
INFO:root:current mean train loss 1693.7254092931012
INFO:root:current train perplexity3.8027231693267822
INFO:root:current mean train loss 1695.8560778501428
INFO:root:current train perplexity3.807485580444336
INFO:root:current mean train loss 1695.967127391038
INFO:root:current train perplexity3.8079018592834473
INFO:root:current mean train loss 1695.7795970164595
INFO:root:current train perplexity3.80893874168396
INFO:root:current mean train loss 1694.8629689171464
INFO:root:current train perplexity3.807605504989624
INFO:root:current mean train loss 1695.6764624570392
INFO:root:current train perplexity3.80721378326416
INFO:root:current mean train loss 1697.5412204982517
INFO:root:current train perplexity3.813408851623535
INFO:root:current mean train loss 1697.5884456691526
INFO:root:current train perplexity3.812020778656006
INFO:root:current mean train loss 1696.9487936038186
INFO:root:current train perplexity3.810617685317993
INFO:root:current mean train loss 1697.0141211823861
INFO:root:current train perplexity3.810713529586792
INFO:root:current mean train loss 1697.3999510976305
INFO:root:current train perplexity3.812159299850464

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it]
INFO:root:final mean train loss: 1696.6345978475736
INFO:root:final train perplexity: 3.8116726875305176
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.62s/it]
INFO:root:eval mean loss: 3344.000265402121
INFO:root:eval perplexity: 15.548993110656738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:25:14<8:13:53, 384.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.751193576389
INFO:root:current train perplexity3.779794692993164
INFO:root:current mean train loss 1683.4002557051808
INFO:root:current train perplexity3.750056028366089
INFO:root:current mean train loss 1684.7153349777748
INFO:root:current train perplexity3.7606332302093506
INFO:root:current mean train loss 1688.4916018755007
INFO:root:current train perplexity3.7687795162200928
INFO:root:current mean train loss 1680.8002546037947
INFO:root:current train perplexity3.7580764293670654
INFO:root:current mean train loss 1683.625315520723
INFO:root:current train perplexity3.7649524211883545
INFO:root:current mean train loss 1686.227807440274
INFO:root:current train perplexity3.7723822593688965
INFO:root:current mean train loss 1686.9429380006427
INFO:root:current train perplexity3.77074933052063
INFO:root:current mean train loss 1686.5357642698823
INFO:root:current train perplexity3.7720255851745605
INFO:root:current mean train loss 1688.388709975734
INFO:root:current train perplexity3.7780239582061768
INFO:root:current mean train loss 1686.1548327524727
INFO:root:current train perplexity3.7761363983154297
INFO:root:current mean train loss 1684.4752049550289
INFO:root:current train perplexity3.769737958908081
INFO:root:current mean train loss 1683.213018751514
INFO:root:current train perplexity3.7656476497650146
INFO:root:current mean train loss 1682.8683979281418
INFO:root:current train perplexity3.7668404579162598
INFO:root:current mean train loss 1682.8537142145553
INFO:root:current train perplexity3.7678632736206055
INFO:root:current mean train loss 1684.570977130626
INFO:root:current train perplexity3.772315740585327
INFO:root:current mean train loss 1683.8134189221987
INFO:root:current train perplexity3.7726097106933594
INFO:root:current mean train loss 1684.1380240157996
INFO:root:current train perplexity3.773723840713501
INFO:root:current mean train loss 1684.7975148034475
INFO:root:current train perplexity3.7753748893737793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it]
INFO:root:final mean train loss: 1684.452745246214
INFO:root:final train perplexity: 3.7752277851104736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.46s/it]
INFO:root:eval mean loss: 3331.8094090183936
INFO:root:eval perplexity: 15.394227027893066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:31:32<8:05:03, 382.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1590.5477294921875
INFO:root:current train perplexity3.5968024730682373
INFO:root:current mean train loss 1645.3291597455461
INFO:root:current train perplexity3.68414044380188
INFO:root:current mean train loss 1654.41332477072
INFO:root:current train perplexity3.6999385356903076
INFO:root:current mean train loss 1660.3968128117365
INFO:root:current train perplexity3.715522527694702
INFO:root:current mean train loss 1661.3034886915502
INFO:root:current train perplexity3.7149901390075684
INFO:root:current mean train loss 1661.196350458811
INFO:root:current train perplexity3.7128119468688965
INFO:root:current mean train loss 1662.5381695968904
INFO:root:current train perplexity3.718125581741333
INFO:root:current mean train loss 1666.112387218772
INFO:root:current train perplexity3.726665496826172
INFO:root:current mean train loss 1665.0626452137546
INFO:root:current train perplexity3.724071979522705
INFO:root:current mean train loss 1666.4543739663727
INFO:root:current train perplexity3.7267844676971436
INFO:root:current mean train loss 1666.7959715342213
INFO:root:current train perplexity3.7295284271240234
INFO:root:current mean train loss 1667.6829629982499
INFO:root:current train perplexity3.7293403148651123
INFO:root:current mean train loss 1671.2750826679978
INFO:root:current train perplexity3.7385525703430176
INFO:root:current mean train loss 1670.9886931322326
INFO:root:current train perplexity3.737421751022339
INFO:root:current mean train loss 1671.2235739897055
INFO:root:current train perplexity3.738147497177124
INFO:root:current mean train loss 1672.3609346163219
INFO:root:current train perplexity3.7393062114715576
INFO:root:current mean train loss 1674.2935623900075
INFO:root:current train perplexity3.7421820163726807
INFO:root:current mean train loss 1673.7382726686071
INFO:root:current train perplexity3.7424309253692627
INFO:root:current mean train loss 1673.6424326134045
INFO:root:current train perplexity3.7423713207244873
INFO:root:current mean train loss 1673.2146614446774
INFO:root:current train perplexity3.7415356636047363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.64s/it]
INFO:root:final mean train loss: 1672.5932164425449
INFO:root:final train perplexity: 3.7400825023651123
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.79s/it]
INFO:root:eval mean loss: 3346.582317913617
INFO:root:eval perplexity: 15.581981658935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:38:15<8:06:07, 388.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1643.0952555338542
INFO:root:current train perplexity3.669464111328125
INFO:root:current mean train loss 1633.966075281943
INFO:root:current train perplexity3.680116891860962
INFO:root:current mean train loss 1647.6940378461566
INFO:root:current train perplexity3.6989901065826416
INFO:root:current mean train loss 1655.6240143952546
INFO:root:current train perplexity3.6987650394439697
INFO:root:current mean train loss 1652.5220503897037
INFO:root:current train perplexity3.6896119117736816
INFO:root:current mean train loss 1654.3229943195372
INFO:root:current train perplexity3.690295696258545
INFO:root:current mean train loss 1658.096998752692
INFO:root:current train perplexity3.698730707168579
INFO:root:current mean train loss 1660.280827643463
INFO:root:current train perplexity3.7042455673217773
INFO:root:current mean train loss 1661.5302946220324
INFO:root:current train perplexity3.705315589904785
INFO:root:current mean train loss 1660.4743289039247
INFO:root:current train perplexity3.7012147903442383
INFO:root:current mean train loss 1661.776188135147
INFO:root:current train perplexity3.7075092792510986
INFO:root:current mean train loss 1661.9583562124667
INFO:root:current train perplexity3.7044575214385986
INFO:root:current mean train loss 1660.6048559051712
INFO:root:current train perplexity3.7003934383392334
INFO:root:current mean train loss 1660.8159920960395
INFO:root:current train perplexity3.702629566192627
INFO:root:current mean train loss 1662.0947553656074
INFO:root:current train perplexity3.7052524089813232
INFO:root:current mean train loss 1662.5104335674775
INFO:root:current train perplexity3.7062392234802246
INFO:root:current mean train loss 1662.9694995598252
INFO:root:current train perplexity3.7062971591949463
INFO:root:current mean train loss 1663.9697926957203
INFO:root:current train perplexity3.708688259124756
INFO:root:current mean train loss 1663.2290572450872
INFO:root:current train perplexity3.709761381149292
INFO:root:current mean train loss 1663.425990875942
INFO:root:current train perplexity3.709730386734009

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.65s/it]
INFO:root:final mean train loss: 1661.912580666131
INFO:root:final train perplexity: 3.7087109088897705
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it]
INFO:root:eval mean loss: 3342.767927839949
INFO:root:eval perplexity: 15.533283233642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:44:53<8:03:05, 391.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1665.0351086128048
INFO:root:current train perplexity3.6891112327575684
INFO:root:current mean train loss 1645.0178343860816
INFO:root:current train perplexity3.669194221496582
INFO:root:current mean train loss 1645.7035003282222
INFO:root:current train perplexity3.673635959625244
INFO:root:current mean train loss 1655.4544777968063
INFO:root:current train perplexity3.685640573501587
INFO:root:current mean train loss 1647.9752424244436
INFO:root:current train perplexity3.6764726638793945
INFO:root:current mean train loss 1650.1771598999248
INFO:root:current train perplexity3.6786108016967773
INFO:root:current mean train loss 1650.3067040406227
INFO:root:current train perplexity3.679769992828369
INFO:root:current mean train loss 1650.2571729899419
INFO:root:current train perplexity3.6812868118286133
INFO:root:current mean train loss 1654.6977267633863
INFO:root:current train perplexity3.6890199184417725
INFO:root:current mean train loss 1652.7284323421725
INFO:root:current train perplexity3.6833205223083496
INFO:root:current mean train loss 1650.919250664175
INFO:root:current train perplexity3.6800358295440674
INFO:root:current mean train loss 1652.1790149899348
INFO:root:current train perplexity3.6793642044067383
INFO:root:current mean train loss 1652.0810168171774
INFO:root:current train perplexity3.6777780055999756
INFO:root:current mean train loss 1652.1882458031844
INFO:root:current train perplexity3.6785929203033447
INFO:root:current mean train loss 1652.30465776601
INFO:root:current train perplexity3.679581880569458
INFO:root:current mean train loss 1652.008198910762
INFO:root:current train perplexity3.679409980773926
INFO:root:current mean train loss 1651.2117751061662
INFO:root:current train perplexity3.677637815475464
INFO:root:current mean train loss 1651.218796346052
INFO:root:current train perplexity3.677462577819824
INFO:root:current mean train loss 1651.3566966142298
INFO:root:current train perplexity3.677077054977417
INFO:root:current mean train loss 1651.4060874282545
INFO:root:current train perplexity3.677128314971924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.06s/it]
INFO:root:final mean train loss: 1651.1711221715145
INFO:root:final train perplexity: 3.6774256229400635
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.81s/it]
INFO:root:eval mean loss: 3360.0783772053305
INFO:root:eval perplexity: 15.755499839782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:51:11<7:51:19, 387.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1657.449917497306
INFO:root:current train perplexity3.6411120891571045
INFO:root:current mean train loss 1637.1586388696599
INFO:root:current train perplexity3.6256113052368164
INFO:root:current mean train loss 1626.267786780069
INFO:root:current train perplexity3.6249780654907227
INFO:root:current mean train loss 1626.1927360662535
INFO:root:current train perplexity3.6219353675842285
INFO:root:current mean train loss 1630.207763405346
INFO:root:current train perplexity3.6316044330596924
INFO:root:current mean train loss 1635.299821532328
INFO:root:current train perplexity3.6386032104492188
INFO:root:current mean train loss 1637.1205208729104
INFO:root:current train perplexity3.6414005756378174
INFO:root:current mean train loss 1638.4829484843956
INFO:root:current train perplexity3.6436069011688232
INFO:root:current mean train loss 1639.5240135637475
INFO:root:current train perplexity3.6468048095703125
INFO:root:current mean train loss 1638.7328219801996
INFO:root:current train perplexity3.643669605255127
INFO:root:current mean train loss 1637.9484202163205
INFO:root:current train perplexity3.6421444416046143
INFO:root:current mean train loss 1639.1257348464148
INFO:root:current train perplexity3.643012285232544
INFO:root:current mean train loss 1640.575116713968
INFO:root:current train perplexity3.6452417373657227
INFO:root:current mean train loss 1639.7377934181989
INFO:root:current train perplexity3.642057180404663
INFO:root:current mean train loss 1640.1160027984074
INFO:root:current train perplexity3.643307685852051
INFO:root:current mean train loss 1640.8768666258825
INFO:root:current train perplexity3.644874095916748
INFO:root:current mean train loss 1640.6549697342195
INFO:root:current train perplexity3.644414186477661
INFO:root:current mean train loss 1639.9615314644216
INFO:root:current train perplexity3.642763614654541
INFO:root:current mean train loss 1640.6519224168924
INFO:root:current train perplexity3.645916223526001
INFO:root:current mean train loss 1641.024383887816
INFO:root:current train perplexity3.646739959716797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.47s/it]
INFO:root:final mean train loss: 1641.0144572986596
INFO:root:final train perplexity: 3.6480860710144043
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.35s/it]
INFO:root:eval mean loss: 3364.438212626689
INFO:root:eval perplexity: 15.811965942382812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:57:41<7:45:42, 388.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1654.9148193359374
INFO:root:current train perplexity3.66435170173645
INFO:root:current mean train loss 1640.0200983537945
INFO:root:current train perplexity3.621464729309082
INFO:root:current mean train loss 1635.5581431995738
INFO:root:current train perplexity3.620307683944702
INFO:root:current mean train loss 1635.420928059896
INFO:root:current train perplexity3.6236495971679688
INFO:root:current mean train loss 1634.7349884354442
INFO:root:current train perplexity3.623918294906616
INFO:root:current mean train loss 1630.621868418818
INFO:root:current train perplexity3.6155192852020264
INFO:root:current mean train loss 1630.3980282479745
INFO:root:current train perplexity3.6161320209503174
INFO:root:current mean train loss 1634.1409185987902
INFO:root:current train perplexity3.6232352256774902
INFO:root:current mean train loss 1634.152462751116
INFO:root:current train perplexity3.621932029724121
INFO:root:current mean train loss 1635.669971454327
INFO:root:current train perplexity3.6234474182128906
INFO:root:current mean train loss 1636.4410696765988
INFO:root:current train perplexity3.6246957778930664
INFO:root:current mean train loss 1634.589270383145
INFO:root:current train perplexity3.6236913204193115
INFO:root:current mean train loss 1632.761331284467
INFO:root:current train perplexity3.6209378242492676
INFO:root:current mean train loss 1631.8027633167615
INFO:root:current train perplexity3.6215333938598633
INFO:root:current mean train loss 1631.7665116856463
INFO:root:current train perplexity3.620396375656128
INFO:root:current mean train loss 1633.415267392113
INFO:root:current train perplexity3.62272047996521
INFO:root:current mean train loss 1633.7326167502333
INFO:root:current train perplexity3.6237635612487793
INFO:root:current mean train loss 1632.8445069734814
INFO:root:current train perplexity3.622553825378418
INFO:root:current mean train loss 1632.9688216145832
INFO:root:current train perplexity3.6233880519866943
INFO:root:current mean train loss 1632.4364676250989
INFO:root:current train perplexity3.6226093769073486

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.16s/it]
INFO:root:final mean train loss: 1632.204824073472
INFO:root:final train perplexity: 3.6228280067443848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it]
INFO:root:eval mean loss: 3373.533841703031
INFO:root:eval perplexity: 15.93042278289795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:04:03<7:37:17, 386.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1614.8456964907439
INFO:root:current train perplexity3.5692646503448486
INFO:root:current mean train loss 1615.3988698323567
INFO:root:current train perplexity3.5793588161468506
INFO:root:current mean train loss 1622.7182550299658
INFO:root:current train perplexity3.5838098526000977
INFO:root:current mean train loss 1623.952724846042
INFO:root:current train perplexity3.586379289627075
INFO:root:current mean train loss 1631.3419454931243
INFO:root:current train perplexity3.596816301345825
INFO:root:current mean train loss 1631.324684555466
INFO:root:current train perplexity3.601203203201294
INFO:root:current mean train loss 1630.5058196845082
INFO:root:current train perplexity3.596437692642212
INFO:root:current mean train loss 1628.2065702496152
INFO:root:current train perplexity3.5943922996520996
INFO:root:current mean train loss 1629.187788616916
INFO:root:current train perplexity3.5949220657348633
INFO:root:current mean train loss 1628.7725271409558
INFO:root:current train perplexity3.5960333347320557
INFO:root:current mean train loss 1627.5225686992044
INFO:root:current train perplexity3.59325909614563
INFO:root:current mean train loss 1626.8440678743707
INFO:root:current train perplexity3.5935847759246826
INFO:root:current mean train loss 1626.353077702478
INFO:root:current train perplexity3.593318223953247
INFO:root:current mean train loss 1625.7323602259844
INFO:root:current train perplexity3.594186305999756
INFO:root:current mean train loss 1626.8709585072208
INFO:root:current train perplexity3.5965778827667236
INFO:root:current mean train loss 1626.0764233766488
INFO:root:current train perplexity3.5956780910491943
INFO:root:current mean train loss 1624.8151194615284
INFO:root:current train perplexity3.5941498279571533
INFO:root:current mean train loss 1622.9698652539935
INFO:root:current train perplexity3.5938198566436768
INFO:root:current mean train loss 1622.9405842109663
INFO:root:current train perplexity3.5951554775238037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it]
INFO:root:final mean train loss: 1622.580909286553
INFO:root:final train perplexity: 3.5954346656799316
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.05s/it]
INFO:root:eval mean loss: 3371.488869240334
INFO:root:eval perplexity: 15.903717994689941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:10:44<7:35:50, 390.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1574.6009250217014
INFO:root:current train perplexity3.593903064727783
INFO:root:current mean train loss 1603.128409009461
INFO:root:current train perplexity3.5690720081329346
INFO:root:current mean train loss 1612.5114156184584
INFO:root:current train perplexity3.5738489627838135
INFO:root:current mean train loss 1611.3830254317102
INFO:root:current train perplexity3.5741803646087646
INFO:root:current mean train loss 1614.480821231758
INFO:root:current train perplexity3.56974458694458
INFO:root:current mean train loss 1609.5516345430685
INFO:root:current train perplexity3.5568203926086426
INFO:root:current mean train loss 1609.7404033491764
INFO:root:current train perplexity3.556090831756592
INFO:root:current mean train loss 1608.9019005779487
INFO:root:current train perplexity3.5561883449554443
INFO:root:current mean train loss 1610.3883779405517
INFO:root:current train perplexity3.5573084354400635
INFO:root:current mean train loss 1610.834559005217
INFO:root:current train perplexity3.5591964721679688
INFO:root:current mean train loss 1612.2672897051536
INFO:root:current train perplexity3.5620930194854736
INFO:root:current mean train loss 1611.8837216981797
INFO:root:current train perplexity3.5619826316833496
INFO:root:current mean train loss 1612.4427671976775
INFO:root:current train perplexity3.5650088787078857
INFO:root:current mean train loss 1612.987570556454
INFO:root:current train perplexity3.5657200813293457
INFO:root:current mean train loss 1613.8035547325508
INFO:root:current train perplexity3.5663886070251465
INFO:root:current mean train loss 1614.0871361188338
INFO:root:current train perplexity3.5683088302612305
INFO:root:current mean train loss 1614.255021649462
INFO:root:current train perplexity3.5687153339385986
INFO:root:current mean train loss 1614.3421024436348
INFO:root:current train perplexity3.570310354232788
INFO:root:current mean train loss 1614.0084659709266
INFO:root:current train perplexity3.570162534713745
INFO:root:current mean train loss 1613.7095060992954
INFO:root:current train perplexity3.5696463584899902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.39s/it]
INFO:root:final mean train loss: 1613.3522061854376
INFO:root:final train perplexity: 3.5693612098693848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.77s/it]
INFO:root:eval mean loss: 3378.206073749531
INFO:root:eval perplexity: 15.991609573364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:17:40<7:38:05, 398.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.5440486027644
INFO:root:current train perplexity3.5563082695007324
INFO:root:current mean train loss 1602.5122806609622
INFO:root:current train perplexity3.5364768505096436
INFO:root:current mean train loss 1602.9124388568168
INFO:root:current train perplexity3.5322134494781494
INFO:root:current mean train loss 1593.881631488449
INFO:root:current train perplexity3.51269793510437
INFO:root:current mean train loss 1592.476288844722
INFO:root:current train perplexity3.5099222660064697
INFO:root:current mean train loss 1594.4759038772872
INFO:root:current train perplexity3.51397442817688
INFO:root:current mean train loss 1596.2836295910918
INFO:root:current train perplexity3.5191025733947754
INFO:root:current mean train loss 1599.5726950569258
INFO:root:current train perplexity3.5236618518829346
INFO:root:current mean train loss 1603.2435329335653
INFO:root:current train perplexity3.530040979385376
INFO:root:current mean train loss 1601.2284443074632
INFO:root:current train perplexity3.5279784202575684
INFO:root:current mean train loss 1601.966346785339
INFO:root:current train perplexity3.5330584049224854
INFO:root:current mean train loss 1604.020344654578
INFO:root:current train perplexity3.539153814315796
INFO:root:current mean train loss 1603.981625729634
INFO:root:current train perplexity3.540393590927124
INFO:root:current mean train loss 1604.8279484307245
INFO:root:current train perplexity3.5408565998077393
INFO:root:current mean train loss 1604.078233973007
INFO:root:current train perplexity3.5418405532836914
INFO:root:current mean train loss 1602.9016316465124
INFO:root:current train perplexity3.5415284633636475
INFO:root:current mean train loss 1604.1261451786881
INFO:root:current train perplexity3.543830633163452
INFO:root:current mean train loss 1605.0020771755956
INFO:root:current train perplexity3.545811176300049
INFO:root:current mean train loss 1604.6563021439451
INFO:root:current train perplexity3.54463267326355
INFO:root:current mean train loss 1604.947898666683
INFO:root:current train perplexity3.546232223510742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.79s/it]
INFO:root:final mean train loss: 1605.292757050653
INFO:root:final train perplexity: 3.546745538711548
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it]
INFO:root:eval mean loss: 3392.781302787162
INFO:root:eval perplexity: 16.184022903442383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:24:28<7:34:40, 401.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1572.6610391306322
INFO:root:current train perplexity3.4378833770751953
INFO:root:current mean train loss 1591.7676301969516
INFO:root:current train perplexity3.483680009841919
INFO:root:current mean train loss 1600.212116508327
INFO:root:current train perplexity3.510082960128784
INFO:root:current mean train loss 1600.3925080146455
INFO:root:current train perplexity3.5168979167938232
INFO:root:current mean train loss 1596.3958230459932
INFO:root:current train perplexity3.5140602588653564
INFO:root:current mean train loss 1592.506476695586
INFO:root:current train perplexity3.509249448776245
INFO:root:current mean train loss 1589.4178178232528
INFO:root:current train perplexity3.5079524517059326
INFO:root:current mean train loss 1590.7247217519769
INFO:root:current train perplexity3.5107712745666504
INFO:root:current mean train loss 1591.2193523873073
INFO:root:current train perplexity3.512847900390625
INFO:root:current mean train loss 1594.0095320991848
INFO:root:current train perplexity3.5163257122039795
INFO:root:current mean train loss 1594.7576320278793
INFO:root:current train perplexity3.518648386001587
INFO:root:current mean train loss 1594.7919929350871
INFO:root:current train perplexity3.5187296867370605
INFO:root:current mean train loss 1596.1699048853266
INFO:root:current train perplexity3.520005464553833
INFO:root:current mean train loss 1596.3979650342633
INFO:root:current train perplexity3.5193896293640137
INFO:root:current mean train loss 1596.385347552706
INFO:root:current train perplexity3.5195624828338623
INFO:root:current mean train loss 1597.465749981646
INFO:root:current train perplexity3.5204524993896484
INFO:root:current mean train loss 1598.283323263585
INFO:root:current train perplexity3.52165150642395
INFO:root:current mean train loss 1597.616932433977
INFO:root:current train perplexity3.5217556953430176
INFO:root:current mean train loss 1597.1463836984535
INFO:root:current train perplexity3.5228028297424316
INFO:root:current mean train loss 1597.4494714349187
INFO:root:current train perplexity3.5234837532043457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.61s/it]
INFO:root:final mean train loss: 1596.6873114466125
INFO:root:final train perplexity: 3.522756338119507
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it]
INFO:root:eval mean loss: 3394.121485987941
INFO:root:eval perplexity: 16.20183563232422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:30:53<7:22:33, 396.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1558.8977213541666
INFO:root:current train perplexity3.440225601196289
INFO:root:current mean train loss 1567.2136253356935
INFO:root:current train perplexity3.468027353286743
INFO:root:current mean train loss 1572.9724107008715
INFO:root:current train perplexity3.4821441173553467
INFO:root:current mean train loss 1575.3278866238065
INFO:root:current train perplexity3.485471248626709
INFO:root:current mean train loss 1574.075070323115
INFO:root:current train perplexity3.48513126373291
INFO:root:current mean train loss 1576.9489798409597
INFO:root:current train perplexity3.4862253665924072
INFO:root:current mean train loss 1579.487960907907
INFO:root:current train perplexity3.4910478591918945
INFO:root:current mean train loss 1582.3346602590461
INFO:root:current train perplexity3.4922053813934326
INFO:root:current mean train loss 1585.247623319404
INFO:root:current train perplexity3.4947240352630615
INFO:root:current mean train loss 1586.0267528533936
INFO:root:current train perplexity3.4926788806915283
INFO:root:current mean train loss 1585.322419479658
INFO:root:current train perplexity3.4909708499908447
INFO:root:current mean train loss 1584.5400372735385
INFO:root:current train perplexity3.4902634620666504
INFO:root:current mean train loss 1585.1039987715465
INFO:root:current train perplexity3.49183988571167
INFO:root:current mean train loss 1584.6829603307388
INFO:root:current train perplexity3.4917030334472656
INFO:root:current mean train loss 1584.43241769451
INFO:root:current train perplexity3.490659236907959
INFO:root:current mean train loss 1584.238986675556
INFO:root:current train perplexity3.4915201663970947
INFO:root:current mean train loss 1584.4479924581137
INFO:root:current train perplexity3.4916434288024902
INFO:root:current mean train loss 1586.697964408181
INFO:root:current train perplexity3.4952144622802734
INFO:root:current mean train loss 1588.0155596333166
INFO:root:current train perplexity3.4981799125671387
INFO:root:current mean train loss 1589.7107969322983
INFO:root:current train perplexity3.502347230911255

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.32s/it]
INFO:root:final mean train loss: 1588.9273339683698
INFO:root:final train perplexity: 3.501262903213501
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.41s/it]
INFO:root:eval mean loss: 3403.642842060811
INFO:root:eval perplexity: 16.328916549682617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:37:43<7:20:25, 400.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.9819082284903
INFO:root:current train perplexity3.4717485904693604
INFO:root:current mean train loss 1592.2429385427702
INFO:root:current train perplexity3.478447914123535
INFO:root:current mean train loss 1582.1776841366764
INFO:root:current train perplexity3.4681975841522217
INFO:root:current mean train loss 1580.8424036648291
INFO:root:current train perplexity3.4707131385803223
INFO:root:current mean train loss 1577.8607643495316
INFO:root:current train perplexity3.4717252254486084
INFO:root:current mean train loss 1579.321118544871
INFO:root:current train perplexity3.4743142127990723
INFO:root:current mean train loss 1578.4311321489567
INFO:root:current train perplexity3.471859931945801
INFO:root:current mean train loss 1578.7558056452099
INFO:root:current train perplexity3.468644618988037
INFO:root:current mean train loss 1577.7977410450221
INFO:root:current train perplexity3.467280864715576
INFO:root:current mean train loss 1578.2017791029618
INFO:root:current train perplexity3.468812942504883
INFO:root:current mean train loss 1578.6191339377683
INFO:root:current train perplexity3.4707441329956055
INFO:root:current mean train loss 1579.6067968998912
INFO:root:current train perplexity3.472587823867798
INFO:root:current mean train loss 1581.0986021276367
INFO:root:current train perplexity3.476962089538574
INFO:root:current mean train loss 1581.172743321504
INFO:root:current train perplexity3.4771602153778076
INFO:root:current mean train loss 1580.8105556356318
INFO:root:current train perplexity3.477543354034424
INFO:root:current mean train loss 1580.9306604243866
INFO:root:current train perplexity3.477579355239868
INFO:root:current mean train loss 1581.8471342665707
INFO:root:current train perplexity3.479487180709839
INFO:root:current mean train loss 1582.2241321535814
INFO:root:current train perplexity3.480694532394409
INFO:root:current mean train loss 1582.624311281508
INFO:root:current train perplexity3.4821832180023193
INFO:root:current mean train loss 1582.2861586220047
INFO:root:current train perplexity3.4819676876068115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.77s/it]
INFO:root:final mean train loss: 1581.8401846912132
INFO:root:final train perplexity: 3.48174786567688
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.47s/it]
INFO:root:eval mean loss: 3400.9513888888887
INFO:root:eval perplexity: 16.29288673400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:44:38<7:18:47, 405.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1596.8599528860539
INFO:root:current train perplexity3.4986846446990967
INFO:root:current mean train loss 1580.2282557536646
INFO:root:current train perplexity3.4642603397369385
INFO:root:current mean train loss 1578.4864136572598
INFO:root:current train perplexity3.4559574127197266
INFO:root:current mean train loss 1574.4061474485445
INFO:root:current train perplexity3.448164224624634
INFO:root:current mean train loss 1572.019633057629
INFO:root:current train perplexity3.45017409324646
INFO:root:current mean train loss 1572.9844808353719
INFO:root:current train perplexity3.4504730701446533
INFO:root:current mean train loss 1572.6136585422482
INFO:root:current train perplexity3.453115224838257
INFO:root:current mean train loss 1573.4681511790086
INFO:root:current train perplexity3.4522924423217773
INFO:root:current mean train loss 1573.9317103989706
INFO:root:current train perplexity3.455601930618286
INFO:root:current mean train loss 1572.3863105390153
INFO:root:current train perplexity3.453569173812866
INFO:root:current mean train loss 1573.8562974668291
INFO:root:current train perplexity3.4553029537200928
INFO:root:current mean train loss 1574.625689482569
INFO:root:current train perplexity3.4549050331115723
INFO:root:current mean train loss 1574.2019769353144
INFO:root:current train perplexity3.4569311141967773
INFO:root:current mean train loss 1574.6489327867198
INFO:root:current train perplexity3.4576120376586914
INFO:root:current mean train loss 1574.774651421441
INFO:root:current train perplexity3.457535743713379
INFO:root:current mean train loss 1573.6311856105906
INFO:root:current train perplexity3.456216335296631
INFO:root:current mean train loss 1573.4347125597237
INFO:root:current train perplexity3.456540584564209
INFO:root:current mean train loss 1574.0947335709961
INFO:root:current train perplexity3.4580142498016357
INFO:root:current mean train loss 1574.0898084952687
INFO:root:current train perplexity3.4589221477508545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.65s/it]
INFO:root:final mean train loss: 1573.3989766284906
INFO:root:final train perplexity: 3.458645820617676
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it]
INFO:root:eval mean loss: 3411.0412942239113
INFO:root:eval perplexity: 16.428348541259766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:51:22<7:11:35, 404.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1603.949141068892
INFO:root:current train perplexity3.5416104793548584
INFO:root:current mean train loss 1551.4457556922157
INFO:root:current train perplexity3.425912380218506
INFO:root:current mean train loss 1545.1826079309835
INFO:root:current train perplexity3.402409791946411
INFO:root:current mean train loss 1550.7082672609777
INFO:root:current train perplexity3.4117088317871094
INFO:root:current mean train loss 1553.1373112810788
INFO:root:current train perplexity3.406820774078369
INFO:root:current mean train loss 1555.5379010403926
INFO:root:current train perplexity3.413761615753174
INFO:root:current mean train loss 1559.917803125959
INFO:root:current train perplexity3.4232840538024902
INFO:root:current mean train loss 1560.8239991607882
INFO:root:current train perplexity3.4245474338531494
INFO:root:current mean train loss 1559.5609404802617
INFO:root:current train perplexity3.4254794120788574
INFO:root:current mean train loss 1558.9448230127864
INFO:root:current train perplexity3.4267520904541016
INFO:root:current mean train loss 1559.464721196719
INFO:root:current train perplexity3.4278478622436523
INFO:root:current mean train loss 1559.5764183229846
INFO:root:current train perplexity3.4288830757141113
INFO:root:current mean train loss 1561.283719328196
INFO:root:current train perplexity3.430654287338257
INFO:root:current mean train loss 1560.7918438595002
INFO:root:current train perplexity3.4305577278137207
INFO:root:current mean train loss 1563.8705892042435
INFO:root:current train perplexity3.4332404136657715
INFO:root:current mean train loss 1564.2310416160396
INFO:root:current train perplexity3.435344696044922
INFO:root:current mean train loss 1565.0577292557757
INFO:root:current train perplexity3.436638593673706
INFO:root:current mean train loss 1566.2353912300007
INFO:root:current train perplexity3.4376626014709473
INFO:root:current mean train loss 1566.3963707303026
INFO:root:current train perplexity3.4385604858398438
INFO:root:current mean train loss 1566.4252838342368
INFO:root:current train perplexity3.438988208770752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.11s/it]
INFO:root:final mean train loss: 1567.1864981369965
INFO:root:final train perplexity: 3.4417412281036377
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.44s/it]
INFO:root:eval mean loss: 3414.2033544775245
INFO:root:eval perplexity: 16.47102928161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:58:05<7:04:20, 404.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.5455889020648
INFO:root:current train perplexity3.3694159984588623
INFO:root:current mean train loss 1551.4587364196777
INFO:root:current train perplexity3.399277687072754
INFO:root:current mean train loss 1551.5420537580524
INFO:root:current train perplexity3.394925594329834
INFO:root:current mean train loss 1544.7854513773104
INFO:root:current train perplexity3.3874006271362305
INFO:root:current mean train loss 1545.3571263963931
INFO:root:current train perplexity3.392807960510254
INFO:root:current mean train loss 1548.0277076489997
INFO:root:current train perplexity3.399540662765503
INFO:root:current mean train loss 1549.7374172332181
INFO:root:current train perplexity3.4026377201080322
INFO:root:current mean train loss 1548.7567660153568
INFO:root:current train perplexity3.402482032775879
INFO:root:current mean train loss 1549.6739883791422
INFO:root:current train perplexity3.406592845916748
INFO:root:current mean train loss 1549.9054327339961
INFO:root:current train perplexity3.40748929977417
INFO:root:current mean train loss 1552.247202238684
INFO:root:current train perplexity3.409801721572876
INFO:root:current mean train loss 1553.5364807345343
INFO:root:current train perplexity3.4104132652282715
INFO:root:current mean train loss 1552.9031091745978
INFO:root:current train perplexity3.4106950759887695
INFO:root:current mean train loss 1553.8234690470867
INFO:root:current train perplexity3.4113609790802
INFO:root:current mean train loss 1553.047485864463
INFO:root:current train perplexity3.410209894180298
INFO:root:current mean train loss 1555.2590713900422
INFO:root:current train perplexity3.4139719009399414
INFO:root:current mean train loss 1558.0755294312423
INFO:root:current train perplexity3.4183480739593506
INFO:root:current mean train loss 1559.8163101055004
INFO:root:current train perplexity3.420551061630249
INFO:root:current mean train loss 1560.643248843938
INFO:root:current train perplexity3.422438621520996
INFO:root:current mean train loss 1560.1973576209357
INFO:root:current train perplexity3.4213666915893555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.81s/it]
INFO:root:final mean train loss: 1559.6731820080056
INFO:root:final train perplexity: 3.42140793800354
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it]
INFO:root:eval mean loss: 3431.674460837791
INFO:root:eval perplexity: 16.708864212036133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:04:33<6:52:37, 399.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1533.256591796875
INFO:root:current train perplexity3.3803768157958984
INFO:root:current mean train loss 1557.2020945581896
INFO:root:current train perplexity3.4015419483184814
INFO:root:current mean train loss 1559.894827208227
INFO:root:current train perplexity3.407578229904175
INFO:root:current mean train loss 1552.206548983809
INFO:root:current train perplexity3.398066282272339
INFO:root:current mean train loss 1553.165234375
INFO:root:current train perplexity3.398569107055664
INFO:root:current mean train loss 1551.9890967692804
INFO:root:current train perplexity3.3977551460266113
INFO:root:current mean train loss 1552.0152063650678
INFO:root:current train perplexity3.3956034183502197
INFO:root:current mean train loss 1549.6182741715604
INFO:root:current train perplexity3.390498399734497
INFO:root:current mean train loss 1550.9589759962093
INFO:root:current train perplexity3.391718864440918
INFO:root:current mean train loss 1550.7791162884425
INFO:root:current train perplexity3.391157627105713
INFO:root:current mean train loss 1551.4914634887111
INFO:root:current train perplexity3.3942675590515137
INFO:root:current mean train loss 1553.430168638271
INFO:root:current train perplexity3.3989973068237305
INFO:root:current mean train loss 1553.6698699093247
INFO:root:current train perplexity3.4001259803771973
INFO:root:current mean train loss 1551.9773776937152
INFO:root:current train perplexity3.400041103363037
INFO:root:current mean train loss 1553.2193153249352
INFO:root:current train perplexity3.4007744789123535
INFO:root:current mean train loss 1553.081779129374
INFO:root:current train perplexity3.4003183841705322
INFO:root:current mean train loss 1553.5638405472312
INFO:root:current train perplexity3.401454448699951
INFO:root:current mean train loss 1554.0883526034204
INFO:root:current train perplexity3.4025676250457764
INFO:root:current mean train loss 1554.2334871617759
INFO:root:current train perplexity3.4036102294921875
INFO:root:current mean train loss 1554.0012455565152
INFO:root:current train perplexity3.4039268493652344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it]
INFO:root:final mean train loss: 1553.6617170632999
INFO:root:final train perplexity: 3.4052250385284424
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.63s/it]
INFO:root:eval mean loss: 3428.5898818740616
INFO:root:eval perplexity: 16.666627883911133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:11:11<6:45:32, 398.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1530.6956590221773
INFO:root:current train perplexity3.352674961090088
INFO:root:current mean train loss 1532.87068986304
INFO:root:current train perplexity3.352048397064209
INFO:root:current mean train loss 1539.361906328274
INFO:root:current train perplexity3.3567681312561035
INFO:root:current mean train loss 1542.187510453535
INFO:root:current train perplexity3.3657126426696777
INFO:root:current mean train loss 1539.856508461428
INFO:root:current train perplexity3.3692638874053955
INFO:root:current mean train loss 1542.5494169730732
INFO:root:current train perplexity3.3787786960601807
INFO:root:current mean train loss 1542.351057438692
INFO:root:current train perplexity3.3794105052948
INFO:root:current mean train loss 1542.5596130851686
INFO:root:current train perplexity3.3796632289886475
INFO:root:current mean train loss 1544.6969472792198
INFO:root:current train perplexity3.384087085723877
INFO:root:current mean train loss 1544.024851333079
INFO:root:current train perplexity3.3837387561798096
INFO:root:current mean train loss 1545.3142419732449
INFO:root:current train perplexity3.3832168579101562
INFO:root:current mean train loss 1545.4511852165917
INFO:root:current train perplexity3.38177490234375
INFO:root:current mean train loss 1544.5805318744738
INFO:root:current train perplexity3.3808250427246094
INFO:root:current mean train loss 1545.5432793929538
INFO:root:current train perplexity3.383204936981201
INFO:root:current mean train loss 1545.0328627976444
INFO:root:current train perplexity3.3840901851654053
INFO:root:current mean train loss 1546.1048005674315
INFO:root:current train perplexity3.385667085647583
INFO:root:current mean train loss 1547.261787276836
INFO:root:current train perplexity3.3872365951538086
INFO:root:current mean train loss 1547.426917570809
INFO:root:current train perplexity3.3879170417785645
INFO:root:current mean train loss 1548.0250314944028
INFO:root:current train perplexity3.3885836601257324
INFO:root:current mean train loss 1548.1107284748105
INFO:root:current train perplexity3.38840913772583

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.70s/it]
INFO:root:final mean train loss: 1547.5436579270972
INFO:root:final train perplexity: 3.388833999633789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.04s/it]
INFO:root:eval mean loss: 3430.403948626361
INFO:root:eval perplexity: 16.69145393371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:17:58<6:41:10, 401.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1535.4416117607793
INFO:root:current train perplexity3.3642501831054688
INFO:root:current mean train loss 1540.482625780159
INFO:root:current train perplexity3.361586570739746
INFO:root:current mean train loss 1539.0731594947076
INFO:root:current train perplexity3.3643271923065186
INFO:root:current mean train loss 1539.3791906512822
INFO:root:current train perplexity3.3685553073883057
INFO:root:current mean train loss 1537.9360137493477
INFO:root:current train perplexity3.3676419258117676
INFO:root:current mean train loss 1541.1081677899665
INFO:root:current train perplexity3.3673629760742188
INFO:root:current mean train loss 1541.0404601061994
INFO:root:current train perplexity3.366420030593872
INFO:root:current mean train loss 1542.9047614943538
INFO:root:current train perplexity3.370678186416626
INFO:root:current mean train loss 1541.9193081904598
INFO:root:current train perplexity3.369974374771118
INFO:root:current mean train loss 1542.6625727184946
INFO:root:current train perplexity3.37125301361084
INFO:root:current mean train loss 1542.2531307245206
INFO:root:current train perplexity3.3692879676818848
INFO:root:current mean train loss 1541.9222340668734
INFO:root:current train perplexity3.370725393295288
INFO:root:current mean train loss 1542.5517518950962
INFO:root:current train perplexity3.3697736263275146
INFO:root:current mean train loss 1543.676234654018
INFO:root:current train perplexity3.373440742492676
INFO:root:current mean train loss 1544.1744000974581
INFO:root:current train perplexity3.3744285106658936
INFO:root:current mean train loss 1542.7164626698316
INFO:root:current train perplexity3.37294340133667
INFO:root:current mean train loss 1542.0637912261764
INFO:root:current train perplexity3.3709208965301514
INFO:root:current mean train loss 1540.9645342856327
INFO:root:current train perplexity3.3699045181274414
INFO:root:current mean train loss 1540.6568446948593
INFO:root:current train perplexity3.3701138496398926
INFO:root:current mean train loss 1540.465957741836
INFO:root:current train perplexity3.3688392639160156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.31s/it]
INFO:root:final mean train loss: 1540.0257092512923
INFO:root:final train perplexity: 3.368800640106201
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.36s/it]
INFO:root:eval mean loss: 3433.6659232474663
INFO:root:eval perplexity: 16.73619270324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:24:34<6:32:57, 399.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1522.5361887613933
INFO:root:current train perplexity3.330097198486328
INFO:root:current mean train loss 1520.8148946956712
INFO:root:current train perplexity3.325594186782837
INFO:root:current mean train loss 1525.683840777423
INFO:root:current train perplexity3.3360702991485596
INFO:root:current mean train loss 1527.1207343207466
INFO:root:current train perplexity3.337294340133667
INFO:root:current mean train loss 1527.2361597861013
INFO:root:current train perplexity3.34281325340271
INFO:root:current mean train loss 1529.1880161362205
INFO:root:current train perplexity3.3387022018432617
INFO:root:current mean train loss 1525.861839557516
INFO:root:current train perplexity3.3343968391418457
INFO:root:current mean train loss 1527.5994868446235
INFO:root:current train perplexity3.338701009750366
INFO:root:current mean train loss 1528.5817249843053
INFO:root:current train perplexity3.3398447036743164
INFO:root:current mean train loss 1528.922146349068
INFO:root:current train perplexity3.3419268131256104
INFO:root:current mean train loss 1528.9725497726106
INFO:root:current train perplexity3.338996648788452
INFO:root:current mean train loss 1530.1715936054752
INFO:root:current train perplexity3.341068744659424
INFO:root:current mean train loss 1532.232299145357
INFO:root:current train perplexity3.3447368144989014
INFO:root:current mean train loss 1532.227247440371
INFO:root:current train perplexity3.3464112281799316
INFO:root:current mean train loss 1533.1227702584497
INFO:root:current train perplexity3.349031925201416
INFO:root:current mean train loss 1535.1986213244293
INFO:root:current train perplexity3.351761817932129
INFO:root:current mean train loss 1535.5647534064526
INFO:root:current train perplexity3.35335636138916
INFO:root:current mean train loss 1535.3537001577943
INFO:root:current train perplexity3.3537099361419678
INFO:root:current mean train loss 1535.7178593245237
INFO:root:current train perplexity3.35481595993042

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.33s/it]
INFO:root:final mean train loss: 1535.0354729679818
INFO:root:final train perplexity: 3.3555686473846436
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it]
INFO:root:eval mean loss: 3453.009383651229
INFO:root:eval perplexity: 17.00395965576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:31:12<6:26:04, 399.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.126201923077
INFO:root:current train perplexity3.40478253364563
INFO:root:current mean train loss 1515.2357987935563
INFO:root:current train perplexity3.340376138687134
INFO:root:current mean train loss 1514.9874525473151
INFO:root:current train perplexity3.332568883895874
INFO:root:current mean train loss 1518.3925426349092
INFO:root:current train perplexity3.323253631591797
INFO:root:current mean train loss 1517.2960994249395
INFO:root:current train perplexity3.321633815765381
INFO:root:current mean train loss 1519.9439014338145
INFO:root:current train perplexity3.3203561305999756
INFO:root:current mean train loss 1522.108264219897
INFO:root:current train perplexity3.3279740810394287
INFO:root:current mean train loss 1525.3694428046656
INFO:root:current train perplexity3.3299126625061035
INFO:root:current mean train loss 1524.8076029234414
INFO:root:current train perplexity3.3315000534057617
INFO:root:current mean train loss 1526.60707759126
INFO:root:current train perplexity3.331822156906128
INFO:root:current mean train loss 1527.9785943139575
INFO:root:current train perplexity3.3337900638580322
INFO:root:current mean train loss 1528.0756633035364
INFO:root:current train perplexity3.335378885269165
INFO:root:current mean train loss 1528.1426938553045
INFO:root:current train perplexity3.336662530899048
INFO:root:current mean train loss 1527.5658058462848
INFO:root:current train perplexity3.3348143100738525
INFO:root:current mean train loss 1529.2665716712559
INFO:root:current train perplexity3.337698221206665
INFO:root:current mean train loss 1529.2493990881114
INFO:root:current train perplexity3.3384816646575928
INFO:root:current mean train loss 1527.7311537211087
INFO:root:current train perplexity3.334789276123047
INFO:root:current mean train loss 1528.0519202878722
INFO:root:current train perplexity3.335902452468872
INFO:root:current mean train loss 1527.387245005688
INFO:root:current train perplexity3.3347227573394775
INFO:root:current mean train loss 1528.3859397461447
INFO:root:current train perplexity3.336787462234497

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.26s/it]
INFO:root:final mean train loss: 1528.4927810768977
INFO:root:final train perplexity: 3.338299036026001
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.12s/it]
INFO:root:eval mean loss: 3451.0760384407845
INFO:root:eval perplexity: 16.977001190185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:37:57<6:20:59, 401.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1534.6466512044271
INFO:root:current train perplexity3.3490231037139893
INFO:root:current mean train loss 1526.4001615084135
INFO:root:current train perplexity3.3235435485839844
INFO:root:current mean train loss 1532.6597640327786
INFO:root:current train perplexity3.3331477642059326
INFO:root:current mean train loss 1529.7090158173532
INFO:root:current train perplexity3.3227715492248535
INFO:root:current mean train loss 1525.0960378247637
INFO:root:current train perplexity3.3193209171295166
INFO:root:current mean train loss 1524.6505354971257
INFO:root:current train perplexity3.3147640228271484
INFO:root:current mean train loss 1522.1444233243428
INFO:root:current train perplexity3.3131308555603027
INFO:root:current mean train loss 1523.6670729545697
INFO:root:current train perplexity3.3173110485076904
INFO:root:current mean train loss 1524.7344347115022
INFO:root:current train perplexity3.3168680667877197
INFO:root:current mean train loss 1524.6663290700606
INFO:root:current train perplexity3.3176894187927246
INFO:root:current mean train loss 1523.6252365556736
INFO:root:current train perplexity3.3178021907806396
INFO:root:current mean train loss 1523.9614840077088
INFO:root:current train perplexity3.3190090656280518
INFO:root:current mean train loss 1524.3326744513784
INFO:root:current train perplexity3.320948839187622
INFO:root:current mean train loss 1523.7992074607907
INFO:root:current train perplexity3.3198776245117188
INFO:root:current mean train loss 1524.2943922776442
INFO:root:current train perplexity3.3222832679748535
INFO:root:current mean train loss 1522.734070781633
INFO:root:current train perplexity3.3204736709594727
INFO:root:current mean train loss 1522.6927216137844
INFO:root:current train perplexity3.322324752807617
INFO:root:current mean train loss 1523.6135570018967
INFO:root:current train perplexity3.3231277465820312
INFO:root:current mean train loss 1523.5935358766649
INFO:root:current train perplexity3.324192762374878
INFO:root:current mean train loss 1522.747237669001
INFO:root:current train perplexity3.322197675704956

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.16s/it]
INFO:root:final mean train loss: 1522.746747869587
INFO:root:final train perplexity: 3.3232052326202393
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.23s/it]
INFO:root:eval mean loss: 3458.807565866648
INFO:root:eval perplexity: 17.08505630493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:44:36<6:13:44, 400.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1507.59172155502
INFO:root:current train perplexity3.29495906829834
INFO:root:current mean train loss 1492.5986618768602
INFO:root:current train perplexity3.2679226398468018
INFO:root:current mean train loss 1504.6347710613297
INFO:root:current train perplexity3.275171995162964
INFO:root:current mean train loss 1512.3226666629143
INFO:root:current train perplexity3.2958250045776367
INFO:root:current mean train loss 1512.7024248025027
INFO:root:current train perplexity3.2958948612213135
INFO:root:current mean train loss 1513.6379778372086
INFO:root:current train perplexity3.2988407611846924
INFO:root:current mean train loss 1513.4507115170982
INFO:root:current train perplexity3.2996826171875
INFO:root:current mean train loss 1513.5633093899035
INFO:root:current train perplexity3.2945504188537598
INFO:root:current mean train loss 1516.6227651188478
INFO:root:current train perplexity3.3012313842773438
INFO:root:current mean train loss 1516.9589290759884
INFO:root:current train perplexity3.3004493713378906
INFO:root:current mean train loss 1516.711721454901
INFO:root:current train perplexity3.3035576343536377
INFO:root:current mean train loss 1518.3532692494346
INFO:root:current train perplexity3.306025266647339
INFO:root:current mean train loss 1516.537251904571
INFO:root:current train perplexity3.3041460514068604
INFO:root:current mean train loss 1515.1999742809542
INFO:root:current train perplexity3.302521228790283
INFO:root:current mean train loss 1515.9775500294252
INFO:root:current train perplexity3.3034780025482178
INFO:root:current mean train loss 1517.142862903124
INFO:root:current train perplexity3.307666063308716
INFO:root:current mean train loss 1516.5450054045946
INFO:root:current train perplexity3.307088851928711
INFO:root:current mean train loss 1516.111669181208
INFO:root:current train perplexity3.305422306060791
INFO:root:current mean train loss 1516.8176006488563
INFO:root:current train perplexity3.3072633743286133
INFO:root:current mean train loss 1518.0269649997392
INFO:root:current train perplexity3.309617519378662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it]
INFO:root:final mean train loss: 1517.4991718548088
INFO:root:final train perplexity: 3.3094804286956787
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it]
INFO:root:eval mean loss: 3455.9545766469596
INFO:root:eval perplexity: 17.045101165771484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:50:59<6:02:10, 395.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1501.12593460083
INFO:root:current train perplexity3.2658426761627197
INFO:root:current mean train loss 1512.4968365925115
INFO:root:current train perplexity3.2855801582336426
INFO:root:current mean train loss 1512.4725744074042
INFO:root:current train perplexity3.291473865509033
INFO:root:current mean train loss 1513.8340179108002
INFO:root:current train perplexity3.3034863471984863
INFO:root:current mean train loss 1512.0817360713563
INFO:root:current train perplexity3.2955880165100098
INFO:root:current mean train loss 1511.2951885250443
INFO:root:current train perplexity3.2941062450408936
INFO:root:current mean train loss 1508.3176394543016
INFO:root:current train perplexity3.2884292602539062
INFO:root:current mean train loss 1507.4658485931875
INFO:root:current train perplexity3.2880172729492188
INFO:root:current mean train loss 1510.198834878427
INFO:root:current train perplexity3.292470693588257
INFO:root:current mean train loss 1511.5241686555855
INFO:root:current train perplexity3.2947866916656494
INFO:root:current mean train loss 1509.5757306321223
INFO:root:current train perplexity3.2922279834747314
INFO:root:current mean train loss 1511.1285455972468
INFO:root:current train perplexity3.293217897415161
INFO:root:current mean train loss 1512.0033485316023
INFO:root:current train perplexity3.293680191040039
INFO:root:current mean train loss 1513.1916259586637
INFO:root:current train perplexity3.294435977935791
INFO:root:current mean train loss 1513.7537048006318
INFO:root:current train perplexity3.294020652770996
INFO:root:current mean train loss 1513.326666478306
INFO:root:current train perplexity3.293370246887207
INFO:root:current mean train loss 1512.5109379108135
INFO:root:current train perplexity3.294494152069092
INFO:root:current mean train loss 1512.4884352911085
INFO:root:current train perplexity3.29422664642334
INFO:root:current mean train loss 1512.2898758000058
INFO:root:current train perplexity3.2949092388153076
INFO:root:current mean train loss 1512.2226362364356
INFO:root:current train perplexity3.2943527698516846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it]
INFO:root:final mean train loss: 1511.5331298705007
INFO:root:final train perplexity: 3.293944835662842
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.44s/it]
INFO:root:eval mean loss: 3466.2504193646773
INFO:root:eval perplexity: 17.18971824645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:57:27<5:53:39, 392.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.3491602768133
INFO:root:current train perplexity3.2880890369415283
INFO:root:current mean train loss 1514.333635024603
INFO:root:current train perplexity3.2818856239318848
INFO:root:current mean train loss 1511.7246732338467
INFO:root:current train perplexity3.2756540775299072
INFO:root:current mean train loss 1509.8200987968544
INFO:root:current train perplexity3.270461320877075
INFO:root:current mean train loss 1504.9106846291904
INFO:root:current train perplexity3.2666397094726562
INFO:root:current mean train loss 1506.178383595767
INFO:root:current train perplexity3.270362615585327
INFO:root:current mean train loss 1507.654845922529
INFO:root:current train perplexity3.2773544788360596
INFO:root:current mean train loss 1508.960166003121
INFO:root:current train perplexity3.278376579284668
INFO:root:current mean train loss 1511.5772849179289
INFO:root:current train perplexity3.281028985977173
INFO:root:current mean train loss 1509.0914728473815
INFO:root:current train perplexity3.2793281078338623
INFO:root:current mean train loss 1508.6275976923855
INFO:root:current train perplexity3.278594732284546
INFO:root:current mean train loss 1509.13603821576
INFO:root:current train perplexity3.2799363136291504
INFO:root:current mean train loss 1509.914317885197
INFO:root:current train perplexity3.283494472503662
INFO:root:current mean train loss 1509.276142493268
INFO:root:current train perplexity3.282965898513794
INFO:root:current mean train loss 1508.4844317078832
INFO:root:current train perplexity3.2825164794921875
INFO:root:current mean train loss 1506.995582228292
INFO:root:current train perplexity3.279930353164673
INFO:root:current mean train loss 1507.303121281975
INFO:root:current train perplexity3.2794878482818604
INFO:root:current mean train loss 1507.3462720782084
INFO:root:current train perplexity3.2804300785064697
INFO:root:current mean train loss 1506.3415973831654
INFO:root:current train perplexity3.2796692848205566
INFO:root:current mean train loss 1506.7624679942855
INFO:root:current train perplexity3.2803804874420166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it]
INFO:root:final mean train loss: 1506.2575479835436
INFO:root:final train perplexity: 3.280269145965576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.80s/it]
INFO:root:eval mean loss: 3466.6643220368805
INFO:root:eval perplexity: 17.195560455322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [5:04:06<5:48:43, 394.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1499.2169513313138
INFO:root:current train perplexity3.2400944232940674
INFO:root:current mean train loss 1496.1326651525017
INFO:root:current train perplexity3.2385997772216797
INFO:root:current mean train loss 1495.5197061628303
INFO:root:current train perplexity3.2514097690582275
INFO:root:current mean train loss 1493.8970453463608
INFO:root:current train perplexity3.2514491081237793
INFO:root:current mean train loss 1495.733331274316
INFO:root:current train perplexity3.2529101371765137
INFO:root:current mean train loss 1495.2844217868155
INFO:root:current train perplexity3.2517001628875732
INFO:root:current mean train loss 1499.4562003674002
INFO:root:current train perplexity3.260479211807251
INFO:root:current mean train loss 1499.7881859800868
INFO:root:current train perplexity3.2630434036254883
INFO:root:current mean train loss 1500.6638016392765
INFO:root:current train perplexity3.2653844356536865
INFO:root:current mean train loss 1499.3511461399362
INFO:root:current train perplexity3.2633142471313477
INFO:root:current mean train loss 1501.643778483073
INFO:root:current train perplexity3.2649223804473877
INFO:root:current mean train loss 1502.040318866405
INFO:root:current train perplexity3.2663114070892334
INFO:root:current mean train loss 1500.0424045744955
INFO:root:current train perplexity3.26348614692688
INFO:root:current mean train loss 1500.5953424150853
INFO:root:current train perplexity3.265401601791382
INFO:root:current mean train loss 1500.8018530729776
INFO:root:current train perplexity3.2669036388397217
INFO:root:current mean train loss 1501.1885602853176
INFO:root:current train perplexity3.268537759780884
INFO:root:current mean train loss 1501.6750936159958
INFO:root:current train perplexity3.2694365978240967
INFO:root:current mean train loss 1501.6302721068114
INFO:root:current train perplexity3.268735408782959
INFO:root:current mean train loss 1501.5255703217615
INFO:root:current train perplexity3.2678849697113037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it]
INFO:root:final mean train loss: 1501.4996664765742
INFO:root:final train perplexity: 3.2679829597473145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it]
INFO:root:eval mean loss: 3479.1933769707207
INFO:root:eval perplexity: 17.373249053955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:11:01<5:47:23, 400.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1422.9676432291667
INFO:root:current train perplexity3.0595719814300537
INFO:root:current mean train loss 1490.098183806046
INFO:root:current train perplexity3.235520839691162
INFO:root:current mean train loss 1496.972580736737
INFO:root:current train perplexity3.2390482425689697
INFO:root:current mean train loss 1494.9628813244049
INFO:root:current train perplexity3.2353765964508057
INFO:root:current mean train loss 1498.740623235128
INFO:root:current train perplexity3.2444305419921875
INFO:root:current mean train loss 1494.098354065534
INFO:root:current train perplexity3.2359840869903564
INFO:root:current mean train loss 1491.1850228658536
INFO:root:current train perplexity3.2349326610565186
INFO:root:current mean train loss 1493.2978133194931
INFO:root:current train perplexity3.241915702819824
INFO:root:current mean train loss 1492.5524709128163
INFO:root:current train perplexity3.2433393001556396
INFO:root:current mean train loss 1491.8309881158214
INFO:root:current train perplexity3.244401216506958
INFO:root:current mean train loss 1493.4716775227064
INFO:root:current train perplexity3.246807336807251
INFO:root:current mean train loss 1494.9809831969942
INFO:root:current train perplexity3.2469823360443115
INFO:root:current mean train loss 1496.332551480517
INFO:root:current train perplexity3.2483508586883545
INFO:root:current mean train loss 1496.2880912287608
INFO:root:current train perplexity3.2488036155700684
INFO:root:current mean train loss 1495.4963341810678
INFO:root:current train perplexity3.24922251701355
INFO:root:current mean train loss 1494.5885905753662
INFO:root:current train perplexity3.249408483505249
INFO:root:current mean train loss 1495.3210359272205
INFO:root:current train perplexity3.250291109085083
INFO:root:current mean train loss 1495.0620896586872
INFO:root:current train perplexity3.2508959770202637
INFO:root:current mean train loss 1496.0168074342503
INFO:root:current train perplexity3.25237774848938
INFO:root:current mean train loss 1496.1009755425914
INFO:root:current train perplexity3.2539477348327637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it]
INFO:root:final mean train loss: 1496.4100480611073
INFO:root:final train perplexity: 3.2548916339874268
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.91s/it]
INFO:root:eval mean loss: 3484.257470116601
INFO:root:eval perplexity: 17.44559669494629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:17:58<5:44:51, 405.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1509.898769378662
INFO:root:current train perplexity3.270937442779541
INFO:root:current mean train loss 1490.5980206113873
INFO:root:current train perplexity3.21555495262146
INFO:root:current mean train loss 1485.3679820093616
INFO:root:current train perplexity3.2094204425811768
INFO:root:current mean train loss 1487.3548977403755
INFO:root:current train perplexity3.2184059619903564
INFO:root:current mean train loss 1489.652207268609
INFO:root:current train perplexity3.2259292602539062
INFO:root:current mean train loss 1487.2051446670876
INFO:root:current train perplexity3.227991819381714
INFO:root:current mean train loss 1487.7757224553748
INFO:root:current train perplexity3.2313179969787598
INFO:root:current mean train loss 1488.5649692556246
INFO:root:current train perplexity3.232928514480591
INFO:root:current mean train loss 1488.5474364940937
INFO:root:current train perplexity3.2339961528778076
INFO:root:current mean train loss 1489.1481120228257
INFO:root:current train perplexity3.236078977584839
INFO:root:current mean train loss 1488.0724474293318
INFO:root:current train perplexity3.234102964401245
INFO:root:current mean train loss 1489.9714701622197
INFO:root:current train perplexity3.2365238666534424
INFO:root:current mean train loss 1490.7593673111555
INFO:root:current train perplexity3.237865686416626
INFO:root:current mean train loss 1489.597750368777
INFO:root:current train perplexity3.2359671592712402
INFO:root:current mean train loss 1489.0343943334824
INFO:root:current train perplexity3.2355356216430664
INFO:root:current mean train loss 1488.9575757855846
INFO:root:current train perplexity3.2349743843078613
INFO:root:current mean train loss 1490.1401406082452
INFO:root:current train perplexity3.2369987964630127
INFO:root:current mean train loss 1489.5521145791986
INFO:root:current train perplexity3.2370734214782715
INFO:root:current mean train loss 1490.665494560675
INFO:root:current train perplexity3.238726854324341
INFO:root:current mean train loss 1490.7025936908603
INFO:root:current train perplexity3.2400128841400146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.22s/it]
INFO:root:final mean train loss: 1491.1655156168742
INFO:root:final train perplexity: 3.241456985473633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.29s/it]
INFO:root:eval mean loss: 3482.547468855574
INFO:root:eval perplexity: 17.42113494873047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:24:47<5:38:50, 406.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1459.271260164222
INFO:root:current train perplexity3.1788580417633057
INFO:root:current mean train loss 1474.4014990889787
INFO:root:current train perplexity3.1828885078430176
INFO:root:current mean train loss 1475.2985222138554
INFO:root:current train perplexity3.196230173110962
INFO:root:current mean train loss 1477.4961780449723
INFO:root:current train perplexity3.2041664123535156
INFO:root:current mean train loss 1480.974839922049
INFO:root:current train perplexity3.204556703567505
INFO:root:current mean train loss 1481.393825954861
INFO:root:current train perplexity3.2067947387695312
INFO:root:current mean train loss 1480.3897866835396
INFO:root:current train perplexity3.2092463970184326
INFO:root:current mean train loss 1483.0979250002608
INFO:root:current train perplexity3.2149980068206787
INFO:root:current mean train loss 1482.9245845583498
INFO:root:current train perplexity3.2149298191070557
INFO:root:current mean train loss 1485.0379407137036
INFO:root:current train perplexity3.2199060916900635
INFO:root:current mean train loss 1485.3786206822717
INFO:root:current train perplexity3.222515344619751
INFO:root:current mean train loss 1485.0383268909106
INFO:root:current train perplexity3.2240958213806152
INFO:root:current mean train loss 1485.1055451783302
INFO:root:current train perplexity3.2258360385894775
INFO:root:current mean train loss 1483.3808157590693
INFO:root:current train perplexity3.223193407058716
INFO:root:current mean train loss 1483.065901035601
INFO:root:current train perplexity3.222930908203125
INFO:root:current mean train loss 1482.9753341527044
INFO:root:current train perplexity3.2228822708129883
INFO:root:current mean train loss 1483.510084606793
INFO:root:current train perplexity3.2240402698516846
INFO:root:current mean train loss 1483.804157342142
INFO:root:current train perplexity3.2247848510742188
INFO:root:current mean train loss 1484.6710945818475
INFO:root:current train perplexity3.2257933616638184
INFO:root:current mean train loss 1486.267243418099
INFO:root:current train perplexity3.2279880046844482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.82s/it]
INFO:root:final mean train loss: 1485.603630431421
INFO:root:final train perplexity: 3.227269172668457
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it]
INFO:root:eval mean loss: 3485.446070582301
INFO:root:eval perplexity: 17.462623596191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:31:24<5:29:41, 403.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1480.6810506184895
INFO:root:current train perplexity3.1946706771850586
INFO:root:current mean train loss 1474.9610500105891
INFO:root:current train perplexity3.2022697925567627
INFO:root:current mean train loss 1479.5796100358318
INFO:root:current train perplexity3.20039439201355
INFO:root:current mean train loss 1477.3868798427895
INFO:root:current train perplexity3.2049453258514404
INFO:root:current mean train loss 1477.8845138877246
INFO:root:current train perplexity3.2047531604766846
INFO:root:current mean train loss 1484.0684506042264
INFO:root:current train perplexity3.210709571838379
INFO:root:current mean train loss 1484.3715618694866
INFO:root:current train perplexity3.211019277572632
INFO:root:current mean train loss 1481.6225077576798
INFO:root:current train perplexity3.208735227584839
INFO:root:current mean train loss 1484.3301178753788
INFO:root:current train perplexity3.214829444885254
INFO:root:current mean train loss 1482.646061930844
INFO:root:current train perplexity3.212360382080078
INFO:root:current mean train loss 1482.8525094037655
INFO:root:current train perplexity3.216662645339966
INFO:root:current mean train loss 1481.8945084272486
INFO:root:current train perplexity3.21515154838562
INFO:root:current mean train loss 1482.4382427390342
INFO:root:current train perplexity3.2157838344573975
INFO:root:current mean train loss 1481.3064249019149
INFO:root:current train perplexity3.215679168701172
INFO:root:current mean train loss 1480.4980017439568
INFO:root:current train perplexity3.2149429321289062
INFO:root:current mean train loss 1481.7914600981303
INFO:root:current train perplexity3.2173068523406982
INFO:root:current mean train loss 1481.4777613682193
INFO:root:current train perplexity3.216688394546509
INFO:root:current mean train loss 1482.3746163010733
INFO:root:current train perplexity3.2175676822662354
INFO:root:current mean train loss 1482.0911967286727
INFO:root:current train perplexity3.217498302459717
INFO:root:current mean train loss 1481.974172132304
INFO:root:current train perplexity3.217047691345215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.20s/it]
INFO:root:final mean train loss: 1482.0027073385495
INFO:root:final train perplexity: 3.2181169986724854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it]
INFO:root:eval mean loss: 3497.765506228885
INFO:root:eval perplexity: 17.64004898071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:38:01<5:21:25, 401.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1471.6550998917546
INFO:root:current train perplexity3.198378324508667
INFO:root:current mean train loss 1471.4090776287142
INFO:root:current train perplexity3.197697877883911
INFO:root:current mean train loss 1466.6962446340824
INFO:root:current train perplexity3.185786724090576
INFO:root:current mean train loss 1468.716483571822
INFO:root:current train perplexity3.1919541358947754
INFO:root:current mean train loss 1467.590759150977
INFO:root:current train perplexity3.188114881515503
INFO:root:current mean train loss 1468.2195157137785
INFO:root:current train perplexity3.193071126937866
INFO:root:current mean train loss 1470.960195963065
INFO:root:current train perplexity3.1958580017089844
INFO:root:current mean train loss 1471.0813993841296
INFO:root:current train perplexity3.193796396255493
INFO:root:current mean train loss 1472.4840154248213
INFO:root:current train perplexity3.194521427154541
INFO:root:current mean train loss 1472.7653433565933
INFO:root:current train perplexity3.195939540863037
INFO:root:current mean train loss 1472.4600795136485
INFO:root:current train perplexity3.195183753967285
INFO:root:current mean train loss 1473.2756900738984
INFO:root:current train perplexity3.1988413333892822
INFO:root:current mean train loss 1472.417361538204
INFO:root:current train perplexity3.199408769607544
INFO:root:current mean train loss 1473.6120277123441
INFO:root:current train perplexity3.201369047164917
INFO:root:current mean train loss 1475.1402927020556
INFO:root:current train perplexity3.2026748657226562
INFO:root:current mean train loss 1476.54808074315
INFO:root:current train perplexity3.2043004035949707
INFO:root:current mean train loss 1476.4525772430184
INFO:root:current train perplexity3.203181028366089
INFO:root:current mean train loss 1477.4661399682986
INFO:root:current train perplexity3.205219268798828
INFO:root:current mean train loss 1477.632301788411
INFO:root:current train perplexity3.2059624195098877
INFO:root:current mean train loss 1477.56732500916
INFO:root:current train perplexity3.2068803310394287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.72s/it]
INFO:root:final mean train loss: 1477.56732500916
INFO:root:final train perplexity: 3.2068803310394287
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.47s/it]
INFO:root:eval mean loss: 3513.439314558699
INFO:root:eval perplexity: 17.868391036987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:44:21<5:09:40, 395.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.1630895996093
INFO:root:current train perplexity3.2306549549102783
INFO:root:current mean train loss 1481.079580078125
INFO:root:current train perplexity3.2165260314941406
INFO:root:current mean train loss 1470.507519938151
INFO:root:current train perplexity3.2007999420166016
INFO:root:current mean train loss 1469.491209716797
INFO:root:current train perplexity3.1945579051971436
INFO:root:current mean train loss 1468.4014328613282
INFO:root:current train perplexity3.190948963165283
INFO:root:current mean train loss 1473.4154307047527
INFO:root:current train perplexity3.1977789402008057
INFO:root:current mean train loss 1471.7870232282366
INFO:root:current train perplexity3.193101167678833
INFO:root:current mean train loss 1471.3578703308106
INFO:root:current train perplexity3.1939315795898438
INFO:root:current mean train loss 1472.1756165907118
INFO:root:current train perplexity3.1946732997894287
INFO:root:current mean train loss 1471.5700076904297
INFO:root:current train perplexity3.193938732147217
INFO:root:current mean train loss 1474.4544693270598
INFO:root:current train perplexity3.1980881690979004
INFO:root:current mean train loss 1474.640254313151
INFO:root:current train perplexity3.1980020999908447
INFO:root:current mean train loss 1475.224280442458
INFO:root:current train perplexity3.1979048252105713
INFO:root:current mean train loss 1472.6149974714006
INFO:root:current train perplexity3.1942551136016846
INFO:root:current mean train loss 1472.6501829427084
INFO:root:current train perplexity3.194467782974243
INFO:root:current mean train loss 1472.8760939788817
INFO:root:current train perplexity3.194620370864868
INFO:root:current mean train loss 1473.644246754366
INFO:root:current train perplexity3.1950743198394775
INFO:root:current mean train loss 1475.0507806396483
INFO:root:current train perplexity3.1973495483398438
INFO:root:current mean train loss 1473.8449324758428
INFO:root:current train perplexity3.196168899536133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.81s/it]
INFO:root:final mean train loss: 1472.962614812577
INFO:root:final train perplexity: 3.1952548027038574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 3496.026506486956
INFO:root:eval perplexity: 17.614891052246094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:51:01<5:04:08, 396.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1472.109073414522
INFO:root:current train perplexity3.228464126586914
INFO:root:current mean train loss 1461.1702870426016
INFO:root:current train perplexity3.179178237915039
INFO:root:current mean train loss 1463.4810408491144
INFO:root:current train perplexity3.1703498363494873
INFO:root:current mean train loss 1461.418758163693
INFO:root:current train perplexity3.170822858810425
INFO:root:current mean train loss 1467.8356655495916
INFO:root:current train perplexity3.1830224990844727
INFO:root:current mean train loss 1466.1998952131437
INFO:root:current train perplexity3.1781134605407715
INFO:root:current mean train loss 1465.3211662008077
INFO:root:current train perplexity3.1770119667053223
INFO:root:current mean train loss 1465.095092943689
INFO:root:current train perplexity3.1797308921813965
INFO:root:current mean train loss 1465.3738634163192
INFO:root:current train perplexity3.1802217960357666
INFO:root:current mean train loss 1466.4728957314528
INFO:root:current train perplexity3.1826088428497314
INFO:root:current mean train loss 1466.8942841086298
INFO:root:current train perplexity3.1837825775146484
INFO:root:current mean train loss 1467.2118710045743
INFO:root:current train perplexity3.1852779388427734
INFO:root:current mean train loss 1467.547397585315
INFO:root:current train perplexity3.1865463256835938
INFO:root:current mean train loss 1466.527391669781
INFO:root:current train perplexity3.1856372356414795
INFO:root:current mean train loss 1467.5165148124613
INFO:root:current train perplexity3.1864566802978516
INFO:root:current mean train loss 1467.4572267878111
INFO:root:current train perplexity3.184892177581787
INFO:root:current mean train loss 1468.1525359522361
INFO:root:current train perplexity3.186429023742676
INFO:root:current mean train loss 1468.1138397021286
INFO:root:current train perplexity3.185948133468628
INFO:root:current mean train loss 1468.5068338548474
INFO:root:current train perplexity3.185664415359497
INFO:root:current mean train loss 1469.0506857970013
INFO:root:current train perplexity3.185250997543335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.96s/it]
INFO:root:final mean train loss: 1469.1828985709585
INFO:root:final train perplexity: 3.185744524002075
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.32s/it]
INFO:root:eval mean loss: 3518.822902736721
INFO:root:eval perplexity: 17.94750213623047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:57:38<4:57:37, 396.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1452.7780725815717
INFO:root:current train perplexity3.1655473709106445
INFO:root:current mean train loss 1456.9199492041744
INFO:root:current train perplexity3.1553261280059814
INFO:root:current mean train loss 1466.030045990251
INFO:root:current train perplexity3.1653895378112793
INFO:root:current mean train loss 1467.9428952154285
INFO:root:current train perplexity3.1701269149780273
INFO:root:current mean train loss 1468.5190905030422
INFO:root:current train perplexity3.1741180419921875
INFO:root:current mean train loss 1467.5045879235429
INFO:root:current train perplexity3.172034502029419
INFO:root:current mean train loss 1465.5960608641808
INFO:root:current train perplexity3.168693780899048
INFO:root:current mean train loss 1464.7973674389582
INFO:root:current train perplexity3.167435884475708
INFO:root:current mean train loss 1463.953712664634
INFO:root:current train perplexity3.1673684120178223
INFO:root:current mean train loss 1461.226443697094
INFO:root:current train perplexity3.164914608001709
INFO:root:current mean train loss 1460.0346630103813
INFO:root:current train perplexity3.165358066558838
INFO:root:current mean train loss 1460.2406117810983
INFO:root:current train perplexity3.165165901184082
INFO:root:current mean train loss 1461.4112979140814
INFO:root:current train perplexity3.1685009002685547
INFO:root:current mean train loss 1461.4572480300378
INFO:root:current train perplexity3.169048547744751
INFO:root:current mean train loss 1461.5633071622756
INFO:root:current train perplexity3.1702585220336914
INFO:root:current mean train loss 1462.6780643786415
INFO:root:current train perplexity3.1712639331817627
INFO:root:current mean train loss 1463.3130503622963
INFO:root:current train perplexity3.1724066734313965
INFO:root:current mean train loss 1464.3660535273393
INFO:root:current train perplexity3.174691677093506
INFO:root:current mean train loss 1464.1738579437024
INFO:root:current train perplexity3.1738083362579346
INFO:root:current mean train loss 1465.1078424305801
INFO:root:current train perplexity3.174537181854248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.96s/it]
INFO:root:final mean train loss: 1464.5850699266518
INFO:root:final train perplexity: 3.174213171005249
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it]
INFO:root:eval mean loss: 3521.4691605668168
INFO:root:eval perplexity: 17.986513137817383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [6:04:08<4:49:24, 394.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1466.1617982153798
INFO:root:current train perplexity3.1745107173919678
INFO:root:current mean train loss 1463.0858049203227
INFO:root:current train perplexity3.1649529933929443
INFO:root:current mean train loss 1458.588887613608
INFO:root:current train perplexity3.1613447666168213
INFO:root:current mean train loss 1457.2810538528313
INFO:root:current train perplexity3.154430627822876
INFO:root:current mean train loss 1456.9432576046286
INFO:root:current train perplexity3.153733968734741
INFO:root:current mean train loss 1458.5908165462654
INFO:root:current train perplexity3.1553807258605957
INFO:root:current mean train loss 1459.8099157096053
INFO:root:current train perplexity3.1582603454589844
INFO:root:current mean train loss 1457.5554334130013
INFO:root:current train perplexity3.1564888954162598
INFO:root:current mean train loss 1457.3084145892242
INFO:root:current train perplexity3.157106399536133
INFO:root:current mean train loss 1457.2520544010006
INFO:root:current train perplexity3.1582655906677246
INFO:root:current mean train loss 1458.3788486411752
INFO:root:current train perplexity3.160698652267456
INFO:root:current mean train loss 1459.7350568332224
INFO:root:current train perplexity3.1617345809936523
INFO:root:current mean train loss 1461.3406286689399
INFO:root:current train perplexity3.1633963584899902
INFO:root:current mean train loss 1462.3134134943446
INFO:root:current train perplexity3.165238618850708
INFO:root:current mean train loss 1462.3487379730036
INFO:root:current train perplexity3.1659655570983887
INFO:root:current mean train loss 1462.5910121934942
INFO:root:current train perplexity3.1672093868255615
INFO:root:current mean train loss 1461.9875535601057
INFO:root:current train perplexity3.166049003601074
INFO:root:current mean train loss 1461.8708316927157
INFO:root:current train perplexity3.1661081314086914
INFO:root:current mean train loss 1462.5600195523534
INFO:root:current train perplexity3.1670496463775635
INFO:root:current mean train loss 1461.916906907215
INFO:root:current train perplexity3.1664774417877197

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.28s/it]
INFO:root:final mean train loss: 1461.441895885535
INFO:root:final train perplexity: 3.1663546562194824
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.13s/it]
INFO:root:eval mean loss: 3527.927217500704
INFO:root:eval perplexity: 18.08208656311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [6:11:01<4:46:46, 400.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1439.7143644445082
INFO:root:current train perplexity3.1045613288879395
INFO:root:current mean train loss 1435.8041701543898
INFO:root:current train perplexity3.1135072708129883
INFO:root:current mean train loss 1448.2991697396806
INFO:root:current train perplexity3.13038969039917
INFO:root:current mean train loss 1446.6105738100798
INFO:root:current train perplexity3.1314496994018555
INFO:root:current mean train loss 1448.8723363631811
INFO:root:current train perplexity3.133857250213623
INFO:root:current mean train loss 1450.1013116970869
INFO:root:current train perplexity3.13703989982605
INFO:root:current mean train loss 1449.2270061926927
INFO:root:current train perplexity3.1353518962860107
INFO:root:current mean train loss 1449.822642962138
INFO:root:current train perplexity3.1367886066436768
INFO:root:current mean train loss 1451.6545023412748
INFO:root:current train perplexity3.1391539573669434
INFO:root:current mean train loss 1454.3954382021566
INFO:root:current train perplexity3.1445870399475098
INFO:root:current mean train loss 1453.399610197946
INFO:root:current train perplexity3.1449708938598633
INFO:root:current mean train loss 1453.3672259605094
INFO:root:current train perplexity3.14638352394104
INFO:root:current mean train loss 1455.0183327852365
INFO:root:current train perplexity3.148651599884033
INFO:root:current mean train loss 1453.9517675031695
INFO:root:current train perplexity3.1492831707000732
INFO:root:current mean train loss 1454.4949001551324
INFO:root:current train perplexity3.151563882827759
INFO:root:current mean train loss 1455.0151452823561
INFO:root:current train perplexity3.1518073081970215
INFO:root:current mean train loss 1455.189692362321
INFO:root:current train perplexity3.151520013809204
INFO:root:current mean train loss 1455.3808383855344
INFO:root:current train perplexity3.1511194705963135
INFO:root:current mean train loss 1455.7027695061563
INFO:root:current train perplexity3.151625871658325
INFO:root:current mean train loss 1456.6488124568289
INFO:root:current train perplexity3.1538639068603516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.02s/it]
INFO:root:final mean train loss: 1456.3740310091835
INFO:root:final train perplexity: 3.1537249088287354
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.06s/it]
INFO:root:eval mean loss: 3523.608352248733
INFO:root:eval perplexity: 18.018115997314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:17:25<4:36:46, 395.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1450.8337632123162
INFO:root:current train perplexity3.14524507522583
INFO:root:current mean train loss 1448.5423913904137
INFO:root:current train perplexity3.133131980895996
INFO:root:current mean train loss 1442.5090965940242
INFO:root:current train perplexity3.1182236671447754
INFO:root:current mean train loss 1442.0568895216113
INFO:root:current train perplexity3.117485284805298
INFO:root:current mean train loss 1444.759678288096
INFO:root:current train perplexity3.1224939823150635
INFO:root:current mean train loss 1444.956271701389
INFO:root:current train perplexity3.123929738998413
INFO:root:current mean train loss 1442.538470147126
INFO:root:current train perplexity3.1234850883483887
INFO:root:current mean train loss 1444.197925737709
INFO:root:current train perplexity3.1242716312408447
INFO:root:current mean train loss 1446.0133160090043
INFO:root:current train perplexity3.1290628910064697
INFO:root:current mean train loss 1446.4638062143083
INFO:root:current train perplexity3.1315743923187256
INFO:root:current mean train loss 1447.4323637087773
INFO:root:current train perplexity3.1320571899414062
INFO:root:current mean train loss 1448.885509996374
INFO:root:current train perplexity3.1349902153015137
INFO:root:current mean train loss 1448.219200472702
INFO:root:current train perplexity3.1355531215667725
INFO:root:current mean train loss 1449.245621157209
INFO:root:current train perplexity3.136023759841919
INFO:root:current mean train loss 1449.3634556831335
INFO:root:current train perplexity3.137247085571289
INFO:root:current mean train loss 1449.8592124192874
INFO:root:current train perplexity3.1401641368865967
INFO:root:current mean train loss 1449.8430362690096
INFO:root:current train perplexity3.140683650970459
INFO:root:current mean train loss 1451.5768193605568
INFO:root:current train perplexity3.142930507659912
INFO:root:current mean train loss 1452.067947509118
INFO:root:current train perplexity3.1435952186584473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.30s/it]
INFO:root:final mean train loss: 1453.1088116790572
INFO:root:final train perplexity: 3.145613670349121
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.01s/it]
INFO:root:eval mean loss: 3528.6410956855293
INFO:root:eval perplexity: 18.092687606811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:24:21<4:34:25, 401.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1511.309814453125
INFO:root:current train perplexity3.27028226852417
INFO:root:current mean train loss 1449.288875804228
INFO:root:current train perplexity3.1177120208740234
INFO:root:current mean train loss 1441.588973545792
INFO:root:current train perplexity3.113801956176758
INFO:root:current mean train loss 1439.2641160977598
INFO:root:current train perplexity3.1081840991973877
INFO:root:current mean train loss 1443.121123204777
INFO:root:current train perplexity3.1168034076690674
INFO:root:current mean train loss 1446.5010470812065
INFO:root:current train perplexity3.121887683868408
INFO:root:current mean train loss 1445.1141266173302
INFO:root:current train perplexity3.121533155441284
INFO:root:current mean train loss 1448.8278493854054
INFO:root:current train perplexity3.127859592437744
INFO:root:current mean train loss 1449.0064672912445
INFO:root:current train perplexity3.133546829223633
INFO:root:current mean train loss 1447.842413181212
INFO:root:current train perplexity3.133335828781128
INFO:root:current mean train loss 1447.2957445704294
INFO:root:current train perplexity3.1333720684051514
INFO:root:current mean train loss 1448.1158112735368
INFO:root:current train perplexity3.1337623596191406
INFO:root:current mean train loss 1447.4297747366043
INFO:root:current train perplexity3.1332132816314697
INFO:root:current mean train loss 1447.8590056013584
INFO:root:current train perplexity3.134481906890869
INFO:root:current mean train loss 1448.027479490098
INFO:root:current train perplexity3.135071039199829
INFO:root:current mean train loss 1449.5426817791122
INFO:root:current train perplexity3.1354408264160156
INFO:root:current mean train loss 1450.134037698848
INFO:root:current train perplexity3.135869026184082
INFO:root:current mean train loss 1449.6060333431258
INFO:root:current train perplexity3.1354846954345703
INFO:root:current mean train loss 1449.7304799273593
INFO:root:current train perplexity3.135784864425659
INFO:root:current mean train loss 1449.5515095001767
INFO:root:current train perplexity3.1363015174865723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it]
INFO:root:final mean train loss: 1449.6710490093528
INFO:root:final train perplexity: 3.137096405029297
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.06s/it]
INFO:root:eval mean loss: 3541.6641504786035
INFO:root:eval perplexity: 18.28706932067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:31:12<4:29:32, 404.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1408.7784166837994
INFO:root:current train perplexity3.0949811935424805
INFO:root:current mean train loss 1431.8227456998425
INFO:root:current train perplexity3.1110942363739014
INFO:root:current mean train loss 1443.9360017123288
INFO:root:current train perplexity3.119910717010498
INFO:root:current mean train loss 1445.1004313406152
INFO:root:current train perplexity3.1245367527008057
INFO:root:current mean train loss 1445.7345626211963
INFO:root:current train perplexity3.1261439323425293
INFO:root:current mean train loss 1443.447328894584
INFO:root:current train perplexity3.1256864070892334
INFO:root:current mean train loss 1442.067640954728
INFO:root:current train perplexity3.122027635574341
INFO:root:current mean train loss 1439.2123442797072
INFO:root:current train perplexity3.1185624599456787
INFO:root:current mean train loss 1438.9439233726343
INFO:root:current train perplexity3.1180014610290527
INFO:root:current mean train loss 1438.8033825829707
INFO:root:current train perplexity3.1161646842956543
INFO:root:current mean train loss 1441.878091888877
INFO:root:current train perplexity3.119981288909912
INFO:root:current mean train loss 1441.8131430781877
INFO:root:current train perplexity3.12105131149292
INFO:root:current mean train loss 1442.547750721807
INFO:root:current train perplexity3.121734380722046
INFO:root:current mean train loss 1441.7218270233132
INFO:root:current train perplexity3.1205084323883057
INFO:root:current mean train loss 1443.0876119881134
INFO:root:current train perplexity3.1234028339385986
INFO:root:current mean train loss 1443.5899631683571
INFO:root:current train perplexity3.124582290649414
INFO:root:current mean train loss 1443.699110100636
INFO:root:current train perplexity3.124075412750244
INFO:root:current mean train loss 1445.090262297075
INFO:root:current train perplexity3.1256861686706543
INFO:root:current mean train loss 1445.5632071219807
INFO:root:current train perplexity3.1266849040985107
INFO:root:current mean train loss 1446.6255354173113
INFO:root:current train perplexity3.1282477378845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.55s/it]
INFO:root:final mean train loss: 1446.1987922733863
INFO:root:final train perplexity: 3.1285181045532227
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it]
INFO:root:eval mean loss: 3526.209761519332
INFO:root:eval perplexity: 18.056621551513672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:37:58<4:23:13, 404.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.1402723524307
INFO:root:current train perplexity3.111978769302368
INFO:root:current mean train loss 1432.7717374913832
INFO:root:current train perplexity3.086440086364746
INFO:root:current mean train loss 1438.6762053926113
INFO:root:current train perplexity3.103189706802368
INFO:root:current mean train loss 1440.5162368047804
INFO:root:current train perplexity3.1153345108032227
INFO:root:current mean train loss 1441.3677250573394
INFO:root:current train perplexity3.115572214126587
INFO:root:current mean train loss 1442.706665950035
INFO:root:current train perplexity3.1170010566711426
INFO:root:current mean train loss 1440.8137636964427
INFO:root:current train perplexity3.1141140460968018
INFO:root:current mean train loss 1442.3422377213187
INFO:root:current train perplexity3.116868734359741
INFO:root:current mean train loss 1444.884602961928
INFO:root:current train perplexity3.1232450008392334
INFO:root:current mean train loss 1445.3418916881594
INFO:root:current train perplexity3.1239027976989746
INFO:root:current mean train loss 1443.833762975273
INFO:root:current train perplexity3.1204445362091064
INFO:root:current mean train loss 1443.549051204198
INFO:root:current train perplexity3.118807315826416
INFO:root:current mean train loss 1443.1790502850677
INFO:root:current train perplexity3.1178369522094727
INFO:root:current mean train loss 1443.5097763152894
INFO:root:current train perplexity3.1182961463928223
INFO:root:current mean train loss 1442.875272788045
INFO:root:current train perplexity3.118595600128174
INFO:root:current mean train loss 1442.6803549130757
INFO:root:current train perplexity3.119077682495117
INFO:root:current mean train loss 1442.1095196786894
INFO:root:current train perplexity3.1184396743774414
INFO:root:current mean train loss 1442.4012086929813
INFO:root:current train perplexity3.118785858154297
INFO:root:current mean train loss 1442.5454975202972
INFO:root:current train perplexity3.118769884109497
INFO:root:current mean train loss 1442.9758019565552
INFO:root:current train perplexity3.1196017265319824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 333.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 333.00s/it]
INFO:root:final mean train loss: 1442.5617806592857
INFO:root:final train perplexity: 3.1195573806762695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it]
INFO:root:eval mean loss: 3539.0378491284255
INFO:root:eval perplexity: 18.247697830200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:44:40<4:15:56, 404.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1442.9208086121757
INFO:root:current train perplexity3.0975096225738525
INFO:root:current mean train loss 1431.3477376302083
INFO:root:current train perplexity3.099851608276367
INFO:root:current mean train loss 1431.736004855793
INFO:root:current train perplexity3.096440315246582
INFO:root:current mean train loss 1433.7971526840254
INFO:root:current train perplexity3.1001482009887695
INFO:root:current mean train loss 1434.4191064560914
INFO:root:current train perplexity3.102276563644409
INFO:root:current mean train loss 1436.667724167891
INFO:root:current train perplexity3.106295347213745
INFO:root:current mean train loss 1437.0699225479757
INFO:root:current train perplexity3.105783700942993
INFO:root:current mean train loss 1437.9317296244708
INFO:root:current train perplexity3.107422351837158
INFO:root:current mean train loss 1439.3932314086771
INFO:root:current train perplexity3.1082234382629395
INFO:root:current mean train loss 1439.4866625694763
INFO:root:current train perplexity3.107633590698242
INFO:root:current mean train loss 1440.2175643065943
INFO:root:current train perplexity3.1087703704833984
INFO:root:current mean train loss 1440.2214232657334
INFO:root:current train perplexity3.1102418899536133
INFO:root:current mean train loss 1439.2195770190606
INFO:root:current train perplexity3.1097021102905273
INFO:root:current mean train loss 1439.3291643569844
INFO:root:current train perplexity3.109626293182373
INFO:root:current mean train loss 1440.5791879274561
INFO:root:current train perplexity3.112522602081299
INFO:root:current mean train loss 1441.0160650976688
INFO:root:current train perplexity3.1138064861297607
INFO:root:current mean train loss 1440.3836851587314
INFO:root:current train perplexity3.113121271133423
INFO:root:current mean train loss 1439.871079822982
INFO:root:current train perplexity3.1119205951690674
INFO:root:current mean train loss 1439.7058974388028
INFO:root:current train perplexity3.1119801998138428
INFO:root:current mean train loss 1439.5492452141937
INFO:root:current train perplexity3.1110057830810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.18s/it]
INFO:root:final mean train loss: 1439.0112626022362
INFO:root:final train perplexity: 3.1108341217041016
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.80s/it]
INFO:root:eval mean loss: 3534.921680713917
INFO:root:eval perplexity: 18.1861629486084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:51:37<4:11:27, 407.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.8459350585938
INFO:root:current train perplexity3.0979952812194824
INFO:root:current mean train loss 1434.1177583582262
INFO:root:current train perplexity3.099900007247925
INFO:root:current mean train loss 1435.138181785301
INFO:root:current train perplexity3.0977511405944824
INFO:root:current mean train loss 1431.9685510583827
INFO:root:current train perplexity3.091038465499878
INFO:root:current mean train loss 1434.0385744784742
INFO:root:current train perplexity3.09921932220459
INFO:root:current mean train loss 1433.7457740114446
INFO:root:current train perplexity3.1030666828155518
INFO:root:current mean train loss 1434.4099175752099
INFO:root:current train perplexity3.0989179611206055
INFO:root:current mean train loss 1435.7716073965098
INFO:root:current train perplexity3.1012039184570312
INFO:root:current mean train loss 1437.1442626953126
INFO:root:current train perplexity3.1023945808410645
INFO:root:current mean train loss 1437.8627684288417
INFO:root:current train perplexity3.1021931171417236
INFO:root:current mean train loss 1437.4097567264164
INFO:root:current train perplexity3.1008756160736084
INFO:root:current mean train loss 1436.8933130508815
INFO:root:current train perplexity3.098497152328491
INFO:root:current mean train loss 1437.130760373093
INFO:root:current train perplexity3.0982654094696045
INFO:root:current mean train loss 1436.6469739927863
INFO:root:current train perplexity3.0985636711120605
INFO:root:current mean train loss 1436.2352206067974
INFO:root:current train perplexity3.0988359451293945
INFO:root:current mean train loss 1435.6124234922372
INFO:root:current train perplexity3.0982673168182373
INFO:root:current mean train loss 1435.851806494433
INFO:root:current train perplexity3.099606990814209
INFO:root:current mean train loss 1436.0057917190811
INFO:root:current train perplexity3.099625825881958
INFO:root:current mean train loss 1435.5879542060077
INFO:root:current train perplexity3.0998659133911133
INFO:root:current mean train loss 1435.679532216648
INFO:root:current train perplexity3.1014676094055176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.04s/it]
INFO:root:final mean train loss: 1435.3071309684565
INFO:root:final train perplexity: 3.101759672164917
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.58s/it]
INFO:root:eval mean loss: 3536.4498433980857
INFO:root:eval perplexity: 18.208988189697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:58:20<4:03:48, 406.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1430.041648426275
INFO:root:current train perplexity3.075991153717041
INFO:root:current mean train loss 1431.7945550112802
INFO:root:current train perplexity3.085574150085449
INFO:root:current mean train loss 1433.3850603801448
INFO:root:current train perplexity3.086073875427246
INFO:root:current mean train loss 1425.443299759266
INFO:root:current train perplexity3.080439329147339
INFO:root:current mean train loss 1424.9982591820938
INFO:root:current train perplexity3.0823590755462646
INFO:root:current mean train loss 1424.416953091727
INFO:root:current train perplexity3.0825791358947754
INFO:root:current mean train loss 1424.5623608718272
INFO:root:current train perplexity3.0817902088165283
INFO:root:current mean train loss 1423.6140313542328
INFO:root:current train perplexity3.0789308547973633
INFO:root:current mean train loss 1426.4939494686707
INFO:root:current train perplexity3.081367015838623
INFO:root:current mean train loss 1428.5970614818816
INFO:root:current train perplexity3.085012674331665
INFO:root:current mean train loss 1427.9356540093866
INFO:root:current train perplexity3.083620309829712
INFO:root:current mean train loss 1429.6222135677192
INFO:root:current train perplexity3.088106393814087
INFO:root:current mean train loss 1429.7772653101022
INFO:root:current train perplexity3.088599920272827
INFO:root:current mean train loss 1430.3724298346533
INFO:root:current train perplexity3.0896737575531006
INFO:root:current mean train loss 1431.2267148621386
INFO:root:current train perplexity3.090343952178955
INFO:root:current mean train loss 1432.0356500694115
INFO:root:current train perplexity3.0922963619232178
INFO:root:current mean train loss 1431.730034738302
INFO:root:current train perplexity3.0931601524353027
INFO:root:current mean train loss 1431.278967893117
INFO:root:current train perplexity3.0916905403137207
INFO:root:current mean train loss 1431.3155124908917
INFO:root:current train perplexity3.09173583984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.68s/it]
INFO:root:final mean train loss: 1431.6987701739197
INFO:root:final train perplexity: 3.092944860458374
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.32s/it]
INFO:root:eval mean loss: 3558.1764660167983
INFO:root:eval perplexity: 18.536527633666992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [7:04:50<3:54:10, 401.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1431.9713745117188
INFO:root:current train perplexity3.1299378871917725
INFO:root:current mean train loss 1416.302261352539
INFO:root:current train perplexity3.0629444122314453
INFO:root:current mean train loss 1431.793421128217
INFO:root:current train perplexity3.0897860527038574
INFO:root:current mean train loss 1427.5413858514082
INFO:root:current train perplexity3.0785326957702637
INFO:root:current mean train loss 1426.3988405737546
INFO:root:current train perplexity3.0774917602539062
INFO:root:current mean train loss 1428.5142463805184
INFO:root:current train perplexity3.081204652786255
INFO:root:current mean train loss 1428.6632520663027
INFO:root:current train perplexity3.080594062805176
INFO:root:current mean train loss 1428.5304783907804
INFO:root:current train perplexity3.082108497619629
INFO:root:current mean train loss 1430.3036465621112
INFO:root:current train perplexity3.0855329036712646
INFO:root:current mean train loss 1430.003053918349
INFO:root:current train perplexity3.0834479331970215
INFO:root:current mean train loss 1429.211810351368
INFO:root:current train perplexity3.0809967517852783
INFO:root:current mean train loss 1428.5468283390653
INFO:root:current train perplexity3.08166766166687
INFO:root:current mean train loss 1429.3554948065369
INFO:root:current train perplexity3.08388352394104
INFO:root:current mean train loss 1429.6329383148006
INFO:root:current train perplexity3.0848591327667236
INFO:root:current mean train loss 1429.6060456278658
INFO:root:current train perplexity3.085968017578125
INFO:root:current mean train loss 1428.990019696824
INFO:root:current train perplexity3.0849485397338867
INFO:root:current mean train loss 1429.072651394585
INFO:root:current train perplexity3.0842957496643066
INFO:root:current mean train loss 1428.409736884032
INFO:root:current train perplexity3.0849251747131348
INFO:root:current mean train loss 1428.6090060147371
INFO:root:current train perplexity3.085785150527954
INFO:root:current mean train loss 1429.3737023618041
INFO:root:current train perplexity3.0869359970092773

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.30s/it]
INFO:root:final mean train loss: 1429.9566448786857
INFO:root:final train perplexity: 3.088698387145996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it]
INFO:root:eval mean loss: 3552.6477732615426
INFO:root:eval perplexity: 18.452621459960938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [7:11:29<3:47:11, 400.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.9039829799108
INFO:root:current train perplexity2.993765115737915
INFO:root:current mean train loss 1425.2146823347107
INFO:root:current train perplexity3.0532360076904297
INFO:root:current mean train loss 1416.7635371005374
INFO:root:current train perplexity3.0560100078582764
INFO:root:current mean train loss 1422.541046427789
INFO:root:current train perplexity3.069092273712158
INFO:root:current mean train loss 1425.3612220021155
INFO:root:current train perplexity3.0748627185821533
INFO:root:current mean train loss 1425.7129330333044
INFO:root:current train perplexity3.077441453933716
INFO:root:current mean train loss 1424.9959421941048
INFO:root:current train perplexity3.074981451034546
INFO:root:current mean train loss 1424.1057079807233
INFO:root:current train perplexity3.0698490142822266
INFO:root:current mean train loss 1425.0079669836232
INFO:root:current train perplexity3.0713095664978027
INFO:root:current mean train loss 1426.0169492176897
INFO:root:current train perplexity3.073132038116455
INFO:root:current mean train loss 1424.6255760379684
INFO:root:current train perplexity3.0723462104797363
INFO:root:current mean train loss 1424.2797086036812
INFO:root:current train perplexity3.0720303058624268
INFO:root:current mean train loss 1424.5527786642288
INFO:root:current train perplexity3.0724568367004395
INFO:root:current mean train loss 1422.4209242191935
INFO:root:current train perplexity3.071451187133789
INFO:root:current mean train loss 1423.140211971103
INFO:root:current train perplexity3.0727853775024414
INFO:root:current mean train loss 1423.1041310327294
INFO:root:current train perplexity3.0737907886505127
INFO:root:current mean train loss 1423.9721858161677
INFO:root:current train perplexity3.074443817138672
INFO:root:current mean train loss 1424.3511800461215
INFO:root:current train perplexity3.076138496398926
INFO:root:current mean train loss 1425.381217005487
INFO:root:current train perplexity3.0767364501953125
INFO:root:current mean train loss 1425.1032360897034
INFO:root:current train perplexity3.076648473739624

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.24s/it]
INFO:root:final mean train loss: 1425.843188033342
INFO:root:final train perplexity: 3.0786945819854736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it]
INFO:root:eval mean loss: 3559.892017994557
INFO:root:eval perplexity: 18.56264305114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:17:55<3:37:55, 396.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.5192357113488
INFO:root:current train perplexity3.0564887523651123
INFO:root:current mean train loss 1409.502907573313
INFO:root:current train perplexity3.0475175380706787
INFO:root:current mean train loss 1414.194572384618
INFO:root:current train perplexity3.0553274154663086
INFO:root:current mean train loss 1412.735486995539
INFO:root:current train perplexity3.055309534072876
INFO:root:current mean train loss 1415.3582607600242
INFO:root:current train perplexity3.059121608734131
INFO:root:current mean train loss 1419.336902490779
INFO:root:current train perplexity3.0627193450927734
INFO:root:current mean train loss 1423.270173936802
INFO:root:current train perplexity3.067413091659546
INFO:root:current mean train loss 1420.1120681555938
INFO:root:current train perplexity3.064518928527832
INFO:root:current mean train loss 1421.1201588487284
INFO:root:current train perplexity3.0652883052825928
INFO:root:current mean train loss 1422.8825864486857
INFO:root:current train perplexity3.066936492919922
INFO:root:current mean train loss 1422.8537824627062
INFO:root:current train perplexity3.0682711601257324
INFO:root:current mean train loss 1424.5674135982467
INFO:root:current train perplexity3.069812774658203
INFO:root:current mean train loss 1424.397002828718
INFO:root:current train perplexity3.069822072982788
INFO:root:current mean train loss 1423.1516217287347
INFO:root:current train perplexity3.068828582763672
INFO:root:current mean train loss 1423.3641496639755
INFO:root:current train perplexity3.0697126388549805
INFO:root:current mean train loss 1424.1023048430643
INFO:root:current train perplexity3.0706787109375
INFO:root:current mean train loss 1423.7545646695428
INFO:root:current train perplexity3.070573091506958
INFO:root:current mean train loss 1424.235943722917
INFO:root:current train perplexity3.072158098220825
INFO:root:current mean train loss 1424.8536558265396
INFO:root:current train perplexity3.0733819007873535
INFO:root:current mean train loss 1423.5107607688942
INFO:root:current train perplexity3.0721657276153564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.29s/it]
INFO:root:final mean train loss: 1423.2352788620265
INFO:root:final train perplexity: 3.072369337081909
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 3556.5847974439284
INFO:root:eval perplexity: 18.512338638305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:24:20<3:29:31, 392.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1402.0558260830967
INFO:root:current train perplexity3.0363597869873047
INFO:root:current mean train loss 1422.8215395035281
INFO:root:current train perplexity3.0533623695373535
INFO:root:current mean train loss 1420.131231330423
INFO:root:current train perplexity3.056525230407715
INFO:root:current mean train loss 1423.988046393596
INFO:root:current train perplexity3.0659754276275635
INFO:root:current mean train loss 1423.0741916530735
INFO:root:current train perplexity3.0679280757904053
INFO:root:current mean train loss 1420.3294242240288
INFO:root:current train perplexity3.0621211528778076
INFO:root:current mean train loss 1420.0919655370349
INFO:root:current train perplexity3.0620276927948
INFO:root:current mean train loss 1419.9806385166598
INFO:root:current train perplexity3.058767795562744
INFO:root:current mean train loss 1418.315457242553
INFO:root:current train perplexity3.0566418170928955
INFO:root:current mean train loss 1418.8511688072645
INFO:root:current train perplexity3.0576822757720947
INFO:root:current mean train loss 1418.2467844018438
INFO:root:current train perplexity3.0572540760040283
INFO:root:current mean train loss 1420.1814280852611
INFO:root:current train perplexity3.060643434524536
INFO:root:current mean train loss 1420.834631007221
INFO:root:current train perplexity3.0620524883270264
INFO:root:current mean train loss 1420.4728145360066
INFO:root:current train perplexity3.062161922454834
INFO:root:current mean train loss 1421.3637266598207
INFO:root:current train perplexity3.063976764678955
INFO:root:current mean train loss 1421.7848825141932
INFO:root:current train perplexity3.064450979232788
INFO:root:current mean train loss 1423.0268663850075
INFO:root:current train perplexity3.06719970703125
INFO:root:current mean train loss 1421.993476645967
INFO:root:current train perplexity3.0660970211029053
INFO:root:current mean train loss 1421.3637777570123
INFO:root:current train perplexity3.065446138381958
INFO:root:current mean train loss 1420.8782146639226
INFO:root:current train perplexity3.0652828216552734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.26s/it]
INFO:root:final mean train loss: 1420.5909906446002
INFO:root:final train perplexity: 3.0659687519073486
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.93s/it]
INFO:root:eval mean loss: 3570.6666908607826
INFO:root:eval perplexity: 18.727493286132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:30:54<3:23:08, 393.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1401.5379333496094
INFO:root:current train perplexity3.0399885177612305
INFO:root:current mean train loss 1407.1497674986374
INFO:root:current train perplexity3.046659231185913
INFO:root:current mean train loss 1406.520144743078
INFO:root:current train perplexity3.0454654693603516
INFO:root:current mean train loss 1405.0511474609375
INFO:root:current train perplexity3.0399017333984375
INFO:root:current mean train loss 1409.494084503691
INFO:root:current train perplexity3.0425970554351807
INFO:root:current mean train loss 1412.7564315262375
INFO:root:current train perplexity3.0506491661071777
INFO:root:current mean train loss 1414.0590662275042
INFO:root:current train perplexity3.0539257526397705
INFO:root:current mean train loss 1413.0760959763602
INFO:root:current train perplexity3.0519859790802
INFO:root:current mean train loss 1411.2513419335041
INFO:root:current train perplexity3.0506787300109863
INFO:root:current mean train loss 1412.0008951822917
INFO:root:current train perplexity3.0519001483917236
INFO:root:current mean train loss 1412.0484753509065
INFO:root:current train perplexity3.0521252155303955
INFO:root:current mean train loss 1413.1374898135866
INFO:root:current train perplexity3.0529625415802
INFO:root:current mean train loss 1413.500311413651
INFO:root:current train perplexity3.053004741668701
INFO:root:current mean train loss 1412.956287083751
INFO:root:current train perplexity3.053192615509033
INFO:root:current mean train loss 1413.9315853118896
INFO:root:current train perplexity3.0546538829803467
INFO:root:current mean train loss 1413.649388980623
INFO:root:current train perplexity3.0539140701293945
INFO:root:current mean train loss 1415.1775863866487
INFO:root:current train perplexity3.0550692081451416
INFO:root:current mean train loss 1415.8017533347515
INFO:root:current train perplexity3.0554330348968506
INFO:root:current mean train loss 1416.9075820792434
INFO:root:current train perplexity3.056464910507202
INFO:root:current mean train loss 1417.2601589489177
INFO:root:current train perplexity3.057213544845581

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it]
INFO:root:final mean train loss: 1417.1910862694228
INFO:root:final train perplexity: 3.0577588081359863
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it]
INFO:root:eval mean loss: 3567.5824858061187
INFO:root:eval perplexity: 18.680156707763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:37:26<3:16:28, 392.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1402.9318326457162
INFO:root:current train perplexity3.0535194873809814
INFO:root:current mean train loss 1398.4811688781415
INFO:root:current train perplexity3.0387630462646484
INFO:root:current mean train loss 1404.2916225974534
INFO:root:current train perplexity3.040936231613159
INFO:root:current mean train loss 1402.6579006165648
INFO:root:current train perplexity3.0368974208831787
INFO:root:current mean train loss 1408.103145419942
INFO:root:current train perplexity3.044463634490967
INFO:root:current mean train loss 1407.8724191144286
INFO:root:current train perplexity3.0446832180023193
INFO:root:current mean train loss 1408.3012790984444
INFO:root:current train perplexity3.043015241622925
INFO:root:current mean train loss 1407.7347531240098
INFO:root:current train perplexity3.0402445793151855
INFO:root:current mean train loss 1409.5289058106018
INFO:root:current train perplexity3.0426480770111084
INFO:root:current mean train loss 1412.364419132923
INFO:root:current train perplexity3.0451555252075195
INFO:root:current mean train loss 1410.5483364809315
INFO:root:current train perplexity3.0437161922454834
INFO:root:current mean train loss 1410.126611040659
INFO:root:current train perplexity3.0446009635925293
INFO:root:current mean train loss 1410.75363814988
INFO:root:current train perplexity3.0458555221557617
INFO:root:current mean train loss 1410.9217886983104
INFO:root:current train perplexity3.046762228012085
INFO:root:current mean train loss 1411.7917155002572
INFO:root:current train perplexity3.0487380027770996
INFO:root:current mean train loss 1411.4061074950096
INFO:root:current train perplexity3.048333168029785
INFO:root:current mean train loss 1412.5150658905047
INFO:root:current train perplexity3.048776149749756
INFO:root:current mean train loss 1413.2658958200504
INFO:root:current train perplexity3.0486268997192383
INFO:root:current mean train loss 1414.4745511508859
INFO:root:current train perplexity3.049999713897705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.45s/it]
INFO:root:final mean train loss: 1414.7909309821964
INFO:root:final train perplexity: 3.051975727081299
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.18s/it]
INFO:root:eval mean loss: 3566.7116295983483
INFO:root:eval perplexity: 18.666805267333984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:44:13<3:11:52, 396.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.1869506835938
INFO:root:current train perplexity3.072053909301758
INFO:root:current mean train loss 1406.7141251474056
INFO:root:current train perplexity3.0196621417999268
INFO:root:current mean train loss 1399.7392252209117
INFO:root:current train perplexity3.0153305530548096
INFO:root:current mean train loss 1400.5886876723346
INFO:root:current train perplexity3.0158352851867676
INFO:root:current mean train loss 1403.2462699401556
INFO:root:current train perplexity3.0245234966278076
INFO:root:current mean train loss 1401.412674613621
INFO:root:current train perplexity3.0216383934020996
INFO:root:current mean train loss 1403.5503622627887
INFO:root:current train perplexity3.0260937213897705
INFO:root:current mean train loss 1406.3561811149964
INFO:root:current train perplexity3.0314598083496094
INFO:root:current mean train loss 1407.5647964666855
INFO:root:current train perplexity3.0323548316955566
INFO:root:current mean train loss 1407.7762952387727
INFO:root:current train perplexity3.0328729152679443
INFO:root:current mean train loss 1408.9921506119533
INFO:root:current train perplexity3.036797046661377
INFO:root:current mean train loss 1404.7549223253136
INFO:root:current train perplexity3.031968832015991
INFO:root:current mean train loss 1406.8693898265833
INFO:root:current train perplexity3.034280300140381
INFO:root:current mean train loss 1409.2466350280856
INFO:root:current train perplexity3.0377490520477295
INFO:root:current mean train loss 1409.7099858551242
INFO:root:current train perplexity3.0397844314575195
INFO:root:current mean train loss 1410.3113914783573
INFO:root:current train perplexity3.0400402545928955
INFO:root:current mean train loss 1410.0801714639438
INFO:root:current train perplexity3.0411581993103027
INFO:root:current mean train loss 1409.384209654116
INFO:root:current train perplexity3.0407235622406006
INFO:root:current mean train loss 1410.3277560178096
INFO:root:current train perplexity3.042712450027466
INFO:root:current mean train loss 1412.3909769928844
INFO:root:current train perplexity3.0449376106262207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.18s/it]
INFO:root:final mean train loss: 1412.3089599917166
INFO:root:final train perplexity: 3.0460076332092285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it]
INFO:root:eval mean loss: 3571.007057350319
INFO:root:eval perplexity: 18.732723236083984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:50:55<3:06:00, 398.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1427.8720968495245
INFO:root:current train perplexity3.0390970706939697
INFO:root:current mean train loss 1418.6197579236534
INFO:root:current train perplexity3.0437064170837402
INFO:root:current mean train loss 1409.231697116732
INFO:root:current train perplexity3.030640125274658
INFO:root:current mean train loss 1409.477580634433
INFO:root:current train perplexity3.032137632369995
INFO:root:current mean train loss 1409.1747290789376
INFO:root:current train perplexity3.0332539081573486
INFO:root:current mean train loss 1410.0010465837117
INFO:root:current train perplexity3.0339467525482178
INFO:root:current mean train loss 1408.454453665793
INFO:root:current train perplexity3.030823230743408
INFO:root:current mean train loss 1408.6571551437694
INFO:root:current train perplexity3.036576509475708
INFO:root:current mean train loss 1408.4058920951834
INFO:root:current train perplexity3.036280632019043
INFO:root:current mean train loss 1409.4478837795402
INFO:root:current train perplexity3.038485288619995
INFO:root:current mean train loss 1410.638472481557
INFO:root:current train perplexity3.0393412113189697
INFO:root:current mean train loss 1410.3425139701483
INFO:root:current train perplexity3.0390899181365967
INFO:root:current mean train loss 1409.9449392023969
INFO:root:current train perplexity3.0391626358032227
INFO:root:current mean train loss 1409.4274294298882
INFO:root:current train perplexity3.038623332977295
INFO:root:current mean train loss 1409.0319053880446
INFO:root:current train perplexity3.038248300552368
INFO:root:current mean train loss 1409.753273055339
INFO:root:current train perplexity3.039562940597534
INFO:root:current mean train loss 1410.3230671674032
INFO:root:current train perplexity3.0398731231689453
INFO:root:current mean train loss 1409.948182958956
INFO:root:current train perplexity3.0388975143432617
INFO:root:current mean train loss 1409.8290720995612
INFO:root:current train perplexity3.0375285148620605
INFO:root:current mean train loss 1409.482664111252
INFO:root:current train perplexity3.0378363132476807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it]
INFO:root:final mean train loss: 1409.1109966022225
INFO:root:final train perplexity: 3.038334608078003
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 3574.3237993853227
INFO:root:eval perplexity: 18.78377914428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:57:44<3:00:43, 401.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1394.8248901367188
INFO:root:current train perplexity3.042224168777466
INFO:root:current mean train loss 1399.8653267996651
INFO:root:current train perplexity3.0228896141052246
INFO:root:current mean train loss 1394.9825281778972
INFO:root:current train perplexity3.0147924423217773
INFO:root:current mean train loss 1398.8200913373162
INFO:root:current train perplexity3.0206761360168457
INFO:root:current mean train loss 1403.3282970081675
INFO:root:current train perplexity3.0251121520996094
INFO:root:current mean train loss 1403.5600371184173
INFO:root:current train perplexity3.028170585632324
INFO:root:current mean train loss 1403.7871812820435
INFO:root:current train perplexity3.024672031402588
INFO:root:current mean train loss 1403.663111176362
INFO:root:current train perplexity3.0251026153564453
INFO:root:current mean train loss 1404.2196860177175
INFO:root:current train perplexity3.026003360748291
INFO:root:current mean train loss 1404.6763677069482
INFO:root:current train perplexity3.028836727142334
INFO:root:current mean train loss 1405.9884570782
INFO:root:current train perplexity3.0319690704345703
INFO:root:current mean train loss 1405.8730856376783
INFO:root:current train perplexity3.0333945751190186
INFO:root:current mean train loss 1406.8530552033455
INFO:root:current train perplexity3.0347046852111816
INFO:root:current mean train loss 1406.629579185372
INFO:root:current train perplexity3.033306360244751
INFO:root:current mean train loss 1405.7634568956164
INFO:root:current train perplexity3.031118392944336
INFO:root:current mean train loss 1405.7295289671267
INFO:root:current train perplexity3.031599283218384
INFO:root:current mean train loss 1406.2634272877763
INFO:root:current train perplexity3.031778335571289
INFO:root:current mean train loss 1406.5766702586207
INFO:root:current train perplexity3.032057046890259
INFO:root:current mean train loss 1406.9347615117613
INFO:root:current train perplexity3.0328171253204346
INFO:root:current mean train loss 1407.5361329383456
INFO:root:current train perplexity3.0335562229156494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.41s/it]
INFO:root:final mean train loss: 1407.1177675648285
INFO:root:final train perplexity: 3.033562660217285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it]
INFO:root:eval mean loss: 3578.8497919306024
INFO:root:eval perplexity: 18.853668212890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [8:04:36<2:55:26, 404.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.44711571409
INFO:root:current train perplexity2.9939165115356445
INFO:root:current mean train loss 1408.8754665107483
INFO:root:current train perplexity3.0288517475128174
INFO:root:current mean train loss 1406.2518210800706
INFO:root:current train perplexity3.018927574157715
INFO:root:current mean train loss 1403.096951866684
INFO:root:current train perplexity3.0182039737701416
INFO:root:current mean train loss 1399.5294782442388
INFO:root:current train perplexity3.0145654678344727
INFO:root:current mean train loss 1402.53228398157
INFO:root:current train perplexity3.0221340656280518
INFO:root:current mean train loss 1403.5637495020571
INFO:root:current train perplexity3.0212414264678955
INFO:root:current mean train loss 1402.324435638468
INFO:root:current train perplexity3.0206682682037354
INFO:root:current mean train loss 1402.651830826785
INFO:root:current train perplexity3.0228819847106934
INFO:root:current mean train loss 1402.5056299032212
INFO:root:current train perplexity3.0228090286254883
INFO:root:current mean train loss 1401.3965254885584
INFO:root:current train perplexity3.01981782913208
INFO:root:current mean train loss 1403.6292357448885
INFO:root:current train perplexity3.0219345092773438
INFO:root:current mean train loss 1402.1966282761846
INFO:root:current train perplexity3.020655870437622
INFO:root:current mean train loss 1403.0589972926837
INFO:root:current train perplexity3.0233638286590576
INFO:root:current mean train loss 1403.31635832672
INFO:root:current train perplexity3.02422833442688
INFO:root:current mean train loss 1403.465342693782
INFO:root:current train perplexity3.025127649307251
INFO:root:current mean train loss 1404.000975457458
INFO:root:current train perplexity3.026175022125244
INFO:root:current mean train loss 1403.6972113638083
INFO:root:current train perplexity3.0253283977508545
INFO:root:current mean train loss 1405.2786643049315
INFO:root:current train perplexity3.029099464416504
INFO:root:current mean train loss 1404.7770908143243
INFO:root:current train perplexity3.0277323722839355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.07s/it]
INFO:root:final mean train loss: 1404.715652473515
INFO:root:final train perplexity: 3.0278208255767822
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it]
INFO:root:eval mean loss: 3584.6723478849945
INFO:root:eval perplexity: 18.943960189819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [8:11:20<2:48:38, 404.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1407.6469858530406
INFO:root:current train perplexity3.036806106567383
INFO:root:current mean train loss 1394.130249724991
INFO:root:current train perplexity3.0107505321502686
INFO:root:current mean train loss 1399.772783933765
INFO:root:current train perplexity3.0128610134124756
INFO:root:current mean train loss 1399.6399333770262
INFO:root:current train perplexity3.0103752613067627
INFO:root:current mean train loss 1402.1073896834619
INFO:root:current train perplexity3.016697883605957
INFO:root:current mean train loss 1399.7907193811927
INFO:root:current train perplexity3.0161964893341064
INFO:root:current mean train loss 1398.8806318967916
INFO:root:current train perplexity3.0141491889953613
INFO:root:current mean train loss 1400.8591316479428
INFO:root:current train perplexity3.018042802810669
INFO:root:current mean train loss 1400.2422848489791
INFO:root:current train perplexity3.015681743621826
INFO:root:current mean train loss 1402.032040950454
INFO:root:current train perplexity3.0186259746551514
INFO:root:current mean train loss 1401.4618674621013
INFO:root:current train perplexity3.0163087844848633
INFO:root:current mean train loss 1402.0255201817372
INFO:root:current train perplexity3.016669511795044
INFO:root:current mean train loss 1400.9346660332553
INFO:root:current train perplexity3.0162549018859863
INFO:root:current mean train loss 1403.009833856441
INFO:root:current train perplexity3.020686626434326
INFO:root:current mean train loss 1402.523612241085
INFO:root:current train perplexity3.0208888053894043
INFO:root:current mean train loss 1402.2745008456511
INFO:root:current train perplexity3.021284580230713
INFO:root:current mean train loss 1402.5449466682535
INFO:root:current train perplexity3.021998882293701
INFO:root:current mean train loss 1402.5979372731997
INFO:root:current train perplexity3.022400379180908
INFO:root:current mean train loss 1403.209711194929
INFO:root:current train perplexity3.02341628074646
INFO:root:current mean train loss 1403.48545198914
INFO:root:current train perplexity3.0242021083831787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it]
INFO:root:final mean train loss: 1403.2577487870533
INFO:root:final train perplexity: 3.0243418216705322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it]
INFO:root:eval mean loss: 3587.0930732979073
INFO:root:eval perplexity: 18.981630325317383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [8:17:58<2:41:04, 402.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1393.412851186899
INFO:root:current train perplexity3.0122013092041016
INFO:root:current mean train loss 1401.1609628088188
INFO:root:current train perplexity3.0255050659179688
INFO:root:current mean train loss 1397.601054922412
INFO:root:current train perplexity3.016101598739624
INFO:root:current mean train loss 1398.530367721987
INFO:root:current train perplexity3.01572847366333
INFO:root:current mean train loss 1399.3715422527368
INFO:root:current train perplexity3.0172688961029053
INFO:root:current mean train loss 1397.3843285678406
INFO:root:current train perplexity3.010206937789917
INFO:root:current mean train loss 1397.5907261540679
INFO:root:current train perplexity3.010864734649658
INFO:root:current mean train loss 1400.0918163198285
INFO:root:current train perplexity3.013744592666626
INFO:root:current mean train loss 1399.676805900805
INFO:root:current train perplexity3.014073133468628
INFO:root:current mean train loss 1399.5752024568776
INFO:root:current train perplexity3.0148098468780518
INFO:root:current mean train loss 1400.0273622115963
INFO:root:current train perplexity3.014329671859741
INFO:root:current mean train loss 1401.0461266915604
INFO:root:current train perplexity3.0162017345428467
INFO:root:current mean train loss 1400.0202031567703
INFO:root:current train perplexity3.0150833129882812
INFO:root:current mean train loss 1400.707369905166
INFO:root:current train perplexity3.0170397758483887
INFO:root:current mean train loss 1400.6134510513602
INFO:root:current train perplexity3.0160419940948486
INFO:root:current mean train loss 1400.8517794797885
INFO:root:current train perplexity3.0164737701416016
INFO:root:current mean train loss 1400.1375814716469
INFO:root:current train perplexity3.01481294631958
INFO:root:current mean train loss 1400.635563546356
INFO:root:current train perplexity3.016305923461914
INFO:root:current mean train loss 1400.313799393612
INFO:root:current train perplexity3.016352415084839

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.85s/it]
INFO:root:final mean train loss: 1400.367879724238
INFO:root:final train perplexity: 3.0174567699432373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.82s/it]
INFO:root:eval mean loss: 3591.146125129035
INFO:root:eval perplexity: 19.044862747192383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:24:24<2:32:22, 397.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1353.7819519042969
INFO:root:current train perplexity2.925518274307251
INFO:root:current mean train loss 1390.1621353714554
INFO:root:current train perplexity3.0017147064208984
INFO:root:current mean train loss 1394.3788634080154
INFO:root:current train perplexity2.99788498878479
INFO:root:current mean train loss 1397.075642771535
INFO:root:current train perplexity3.0055878162384033
INFO:root:current mean train loss 1397.6780344645183
INFO:root:current train perplexity3.0037996768951416
INFO:root:current mean train loss 1396.4463950329878
INFO:root:current train perplexity3.003593921661377
INFO:root:current mean train loss 1396.697672191419
INFO:root:current train perplexity3.0055148601531982
INFO:root:current mean train loss 1395.818137303584
INFO:root:current train perplexity3.006464719772339
INFO:root:current mean train loss 1398.6228016768353
INFO:root:current train perplexity3.0097875595092773
INFO:root:current mean train loss 1399.0216586075164
INFO:root:current train perplexity3.0111734867095947
INFO:root:current mean train loss 1399.205574641152
INFO:root:current train perplexity3.0101158618927
INFO:root:current mean train loss 1397.8255780492018
INFO:root:current train perplexity3.0094707012176514
INFO:root:current mean train loss 1396.7980897410816
INFO:root:current train perplexity3.0075111389160156
INFO:root:current mean train loss 1396.913064192559
INFO:root:current train perplexity3.0077903270721436
INFO:root:current mean train loss 1397.7393426895142
INFO:root:current train perplexity3.010270118713379
INFO:root:current mean train loss 1397.7121144099956
INFO:root:current train perplexity3.010068655014038
INFO:root:current mean train loss 1397.1995255958975
INFO:root:current train perplexity3.00994610786438
INFO:root:current mean train loss 1398.7021797412453
INFO:root:current train perplexity3.011686086654663
INFO:root:current mean train loss 1398.4950442018762
INFO:root:current train perplexity3.01171612739563
INFO:root:current mean train loss 1398.0396503952313
INFO:root:current train perplexity3.011492967605591

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.34s/it]
INFO:root:final mean train loss: 1398.5429963897227
INFO:root:final train perplexity: 3.0131170749664307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it]
INFO:root:eval mean loss: 3595.270242410379
INFO:root:eval perplexity: 19.109416961669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:30:49<2:24:24, 393.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1402.418388671875
INFO:root:current train perplexity3.033292293548584
INFO:root:current mean train loss 1384.9028662109374
INFO:root:current train perplexity2.989119291305542
INFO:root:current mean train loss 1393.613537326389
INFO:root:current train perplexity3.0095622539520264
INFO:root:current mean train loss 1391.6795838341345
INFO:root:current train perplexity3.010049343109131
INFO:root:current mean train loss 1395.3342790670956
INFO:root:current train perplexity3.0114448070526123
INFO:root:current mean train loss 1393.5817761811757
INFO:root:current train perplexity3.006716012954712
INFO:root:current mean train loss 1394.7298337890625
INFO:root:current train perplexity3.0060200691223145
INFO:root:current mean train loss 1394.6150555630388
INFO:root:current train perplexity3.003972053527832
INFO:root:current mean train loss 1393.3137850674716
INFO:root:current train perplexity3.0029380321502686
INFO:root:current mean train loss 1391.3204671663852
INFO:root:current train perplexity3.0001766681671143
INFO:root:current mean train loss 1390.6587359470275
INFO:root:current train perplexity2.9995880126953125
INFO:root:current mean train loss 1392.661140842014
INFO:root:current train perplexity3.0019142627716064
INFO:root:current mean train loss 1393.680914182079
INFO:root:current train perplexity3.0039994716644287
INFO:root:current mean train loss 1394.7202296764447
INFO:root:current train perplexity3.0047779083251953
INFO:root:current mean train loss 1394.0296288205866
INFO:root:current train perplexity3.0032498836517334
INFO:root:current mean train loss 1394.4000787653688
INFO:root:current train perplexity3.003941297531128
INFO:root:current mean train loss 1394.630399639423
INFO:root:current train perplexity3.003406524658203
INFO:root:current mean train loss 1395.6094816434556
INFO:root:current train perplexity3.0043375492095947
INFO:root:current mean train loss 1395.479823416096
INFO:root:current train perplexity3.0063087940216064
INFO:root:current mean train loss 1396.0243647904829
INFO:root:current train perplexity3.0067644119262695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.16s/it]
INFO:root:final mean train loss: 1396.003369983975
INFO:root:final train perplexity: 3.0070884227752686
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it]
INFO:root:eval mean loss: 3598.6127555778435
INFO:root:eval perplexity: 19.161911010742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:37:03<2:15:44, 387.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.4608183361236
INFO:root:current train perplexity2.9971039295196533
INFO:root:current mean train loss 1392.5080033423196
INFO:root:current train perplexity2.999234914779663
INFO:root:current mean train loss 1390.7393980420325
INFO:root:current train perplexity2.9955780506134033
INFO:root:current mean train loss 1397.2024639642727
INFO:root:current train perplexity3.004652738571167
INFO:root:current mean train loss 1395.4532575650453
INFO:root:current train perplexity2.9984793663024902
INFO:root:current mean train loss 1396.9582084852832
INFO:root:current train perplexity3.0009753704071045
INFO:root:current mean train loss 1397.149585949669
INFO:root:current train perplexity3.0005624294281006
INFO:root:current mean train loss 1396.0152173312206
INFO:root:current train perplexity3.0012741088867188
INFO:root:current mean train loss 1396.6648824877523
INFO:root:current train perplexity3.0047736167907715
INFO:root:current mean train loss 1397.9373942575637
INFO:root:current train perplexity3.0078182220458984
INFO:root:current mean train loss 1395.7716120685132
INFO:root:current train perplexity3.0046846866607666
INFO:root:current mean train loss 1394.208609292052
INFO:root:current train perplexity3.001896858215332
INFO:root:current mean train loss 1395.1382638928203
INFO:root:current train perplexity3.0029518604278564
INFO:root:current mean train loss 1394.639016255181
INFO:root:current train perplexity3.002812385559082
INFO:root:current mean train loss 1394.7995486953882
INFO:root:current train perplexity3.002516269683838
INFO:root:current mean train loss 1395.031171073864
INFO:root:current train perplexity3.003051519393921
INFO:root:current mean train loss 1396.3270672555382
INFO:root:current train perplexity3.0056090354919434
INFO:root:current mean train loss 1395.5440958331837
INFO:root:current train perplexity3.004709482192993
INFO:root:current mean train loss 1394.3628143741305
INFO:root:current train perplexity3.0038421154022217
INFO:root:current mean train loss 1394.2728760519922
INFO:root:current train perplexity3.0031442642211914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it]
INFO:root:final mean train loss: 1393.952467186909
INFO:root:final train perplexity: 3.002227783203125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it]
INFO:root:eval mean loss: 3596.0981298681495
INFO:root:eval perplexity: 19.122406005859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:43:16<2:07:47, 383.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1377.5768070544227
INFO:root:current train perplexity3.0002028942108154
INFO:root:current mean train loss 1397.6110271717766
INFO:root:current train perplexity3.0142128467559814
INFO:root:current mean train loss 1387.4122517118124
INFO:root:current train perplexity2.9918711185455322
INFO:root:current mean train loss 1383.6768775026114
INFO:root:current train perplexity2.985982894897461
INFO:root:current mean train loss 1385.0792566104133
INFO:root:current train perplexity2.98600697517395
INFO:root:current mean train loss 1385.8258958519677
INFO:root:current train perplexity2.98435115814209
INFO:root:current mean train loss 1387.0132497228874
INFO:root:current train perplexity2.9844460487365723
INFO:root:current mean train loss 1388.6006071671195
INFO:root:current train perplexity2.9884908199310303
INFO:root:current mean train loss 1388.7715805817538
INFO:root:current train perplexity2.9899771213531494
INFO:root:current mean train loss 1388.6329745391113
INFO:root:current train perplexity2.9914145469665527
INFO:root:current mean train loss 1388.3237267801287
INFO:root:current train perplexity2.9912819862365723
INFO:root:current mean train loss 1389.9519623303022
INFO:root:current train perplexity2.9927847385406494
INFO:root:current mean train loss 1391.3828943326796
INFO:root:current train perplexity2.9956281185150146
INFO:root:current mean train loss 1391.614184875713
INFO:root:current train perplexity2.9972426891326904
INFO:root:current mean train loss 1392.2742031377174
INFO:root:current train perplexity2.9989852905273438
INFO:root:current mean train loss 1392.6946223603372
INFO:root:current train perplexity2.9992072582244873
INFO:root:current mean train loss 1393.0335023039577
INFO:root:current train perplexity3.000383138656616
INFO:root:current mean train loss 1392.5440925741277
INFO:root:current train perplexity2.9991419315338135
INFO:root:current mean train loss 1392.4860858886457
INFO:root:current train perplexity2.9985251426696777
INFO:root:current mean train loss 1392.5524491080828
INFO:root:current train perplexity2.998657464981079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it]
INFO:root:final mean train loss: 1392.5001288109577
INFO:root:final train perplexity: 2.9987919330596924
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it]
INFO:root:eval mean loss: 3598.9247922238646
INFO:root:eval perplexity: 19.166818618774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:49:28<2:00:21, 380.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1396.1607473273027
INFO:root:current train perplexity3.0243277549743652
INFO:root:current mean train loss 1398.8816452026367
INFO:root:current train perplexity3.0133602619171143
INFO:root:current mean train loss 1399.0130371978316
INFO:root:current train perplexity3.007844924926758
INFO:root:current mean train loss 1392.6918409631608
INFO:root:current train perplexity2.9964704513549805
INFO:root:current mean train loss 1391.4490400041852
INFO:root:current train perplexity2.995573043823242
INFO:root:current mean train loss 1391.8091235690647
INFO:root:current train perplexity2.995391368865967
INFO:root:current mean train loss 1390.8347122824405
INFO:root:current train perplexity2.9930059909820557
INFO:root:current mean train loss 1389.525332893293
INFO:root:current train perplexity2.9924721717834473
INFO:root:current mean train loss 1390.9968557140055
INFO:root:current train perplexity2.990579128265381
INFO:root:current mean train loss 1391.6943012925444
INFO:root:current train perplexity2.992335081100464
INFO:root:current mean train loss 1389.3500070111015
INFO:root:current train perplexity2.989898443222046
INFO:root:current mean train loss 1388.8942440318413
INFO:root:current train perplexity2.9905271530151367
INFO:root:current mean train loss 1390.6123790202844
INFO:root:current train perplexity2.9929003715515137
INFO:root:current mean train loss 1391.3003903766012
INFO:root:current train perplexity2.9933080673217773
INFO:root:current mean train loss 1391.5859456049395
INFO:root:current train perplexity2.9926092624664307
INFO:root:current mean train loss 1391.7326419268768
INFO:root:current train perplexity2.9930319786071777
INFO:root:current mean train loss 1392.3264922731532
INFO:root:current train perplexity2.9936816692352295
INFO:root:current mean train loss 1391.4583786285675
INFO:root:current train perplexity2.9934208393096924
INFO:root:current mean train loss 1391.1417897433869
INFO:root:current train perplexity2.994364023208618
INFO:root:current mean train loss 1390.9148861039505
INFO:root:current train perplexity2.994013547897339

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it]
INFO:root:final mean train loss: 1390.2839452115443
INFO:root:final train perplexity: 2.9935550689697266
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 3598.4622857721
INFO:root:eval perplexity: 19.159543991088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:55:41<1:53:21, 377.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1388.7622030934979
INFO:root:current train perplexity2.9869279861450195
INFO:root:current mean train loss 1400.0605778669446
INFO:root:current train perplexity3.000044107437134
INFO:root:current mean train loss 1387.2137234528318
INFO:root:current train perplexity2.9879889488220215
INFO:root:current mean train loss 1386.8250695148497
INFO:root:current train perplexity2.9871408939361572
INFO:root:current mean train loss 1386.387008697943
INFO:root:current train perplexity2.9851458072662354
INFO:root:current mean train loss 1385.7926247710925
INFO:root:current train perplexity2.9871890544891357
INFO:root:current mean train loss 1386.894416754036
INFO:root:current train perplexity2.9904556274414062
INFO:root:current mean train loss 1387.0216620157826
INFO:root:current train perplexity2.9919443130493164
INFO:root:current mean train loss 1387.3929957339637
INFO:root:current train perplexity2.993835210800171
INFO:root:current mean train loss 1389.093960457578
INFO:root:current train perplexity2.995638132095337
INFO:root:current mean train loss 1388.8425894944032
INFO:root:current train perplexity2.9947197437286377
INFO:root:current mean train loss 1387.704475447598
INFO:root:current train perplexity2.992154598236084
INFO:root:current mean train loss 1387.7172057586222
INFO:root:current train perplexity2.9917705059051514
INFO:root:current mean train loss 1388.281144754885
INFO:root:current train perplexity2.991023540496826
INFO:root:current mean train loss 1388.2216104352865
INFO:root:current train perplexity2.9903764724731445
INFO:root:current mean train loss 1389.0528820394647
INFO:root:current train perplexity2.991234540939331
INFO:root:current mean train loss 1389.3153096360704
INFO:root:current train perplexity2.9909934997558594
INFO:root:current mean train loss 1388.9724678001255
INFO:root:current train perplexity2.9910295009613037
INFO:root:current mean train loss 1389.5049118952845
INFO:root:current train perplexity2.9906694889068604

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.23s/it]
INFO:root:final mean train loss: 1388.6145565554282
INFO:root:final train perplexity: 2.9896156787872314
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.91s/it]
INFO:root:eval mean loss: 3605.1041849955423
INFO:root:eval perplexity: 19.264253616333008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [9:01:54<1:46:39, 376.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.39248046875
INFO:root:current train perplexity3.0054359436035156
INFO:root:current mean train loss 1389.043887606534
INFO:root:current train perplexity2.9785780906677246
INFO:root:current mean train loss 1391.563878813244
INFO:root:current train perplexity2.981487512588501
INFO:root:current mean train loss 1390.2344076833417
INFO:root:current train perplexity2.9844391345977783
INFO:root:current mean train loss 1385.166011754478
INFO:root:current train perplexity2.9805445671081543
INFO:root:current mean train loss 1385.298102644378
INFO:root:current train perplexity2.986605167388916
INFO:root:current mean train loss 1386.2905999855916
INFO:root:current train perplexity2.9896724224090576
INFO:root:current mean train loss 1384.4586056131711
INFO:root:current train perplexity2.9863698482513428
INFO:root:current mean train loss 1384.9378246166089
INFO:root:current train perplexity2.985586643218994
INFO:root:current mean train loss 1385.5932999495622
INFO:root:current train perplexity2.98510479927063
INFO:root:current mean train loss 1384.6764800723236
INFO:root:current train perplexity2.982071876525879
INFO:root:current mean train loss 1385.4356098896749
INFO:root:current train perplexity2.984550714492798
INFO:root:current mean train loss 1386.2404422980694
INFO:root:current train perplexity2.9859001636505127
INFO:root:current mean train loss 1387.3920657092378
INFO:root:current train perplexity2.987053632736206
INFO:root:current mean train loss 1387.2539534332059
INFO:root:current train perplexity2.987915277481079
INFO:root:current mean train loss 1388.3643832781456
INFO:root:current train perplexity2.989133358001709
INFO:root:current mean train loss 1388.264627814441
INFO:root:current train perplexity2.988236427307129
INFO:root:current mean train loss 1387.7294705574973
INFO:root:current train perplexity2.9869227409362793
INFO:root:current mean train loss 1386.5736856871547
INFO:root:current train perplexity2.9862589836120605
INFO:root:current mean train loss 1387.385310851092
INFO:root:current train perplexity2.986454725265503

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.55s/it]
INFO:root:final mean train loss: 1387.153815611408
INFO:root:final train perplexity: 2.986173629760742
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it]
INFO:root:eval mean loss: 3606.8452976902686
INFO:root:eval perplexity: 19.291793823242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [9:08:05<1:39:57, 374.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1372.9635552300347
INFO:root:current train perplexity2.977155923843384
INFO:root:current mean train loss 1374.2049156849778
INFO:root:current train perplexity2.9742496013641357
INFO:root:current mean train loss 1379.5575725538615
INFO:root:current train perplexity2.9795610904693604
INFO:root:current mean train loss 1382.1071657886564
INFO:root:current train perplexity2.9776980876922607
INFO:root:current mean train loss 1382.2743674642309
INFO:root:current train perplexity2.9748876094818115
INFO:root:current mean train loss 1381.082934153374
INFO:root:current train perplexity2.9763519763946533
INFO:root:current mean train loss 1380.9981701134495
INFO:root:current train perplexity2.9778623580932617
INFO:root:current mean train loss 1381.330038834143
INFO:root:current train perplexity2.9782443046569824
INFO:root:current mean train loss 1381.1782126190296
INFO:root:current train perplexity2.977476119995117
INFO:root:current mean train loss 1383.1231426086756
INFO:root:current train perplexity2.979623556137085
INFO:root:current mean train loss 1382.8275795465784
INFO:root:current train perplexity2.978101968765259
INFO:root:current mean train loss 1384.0953609598562
INFO:root:current train perplexity2.979573965072632
INFO:root:current mean train loss 1385.3363250011143
INFO:root:current train perplexity2.9813883304595947
INFO:root:current mean train loss 1385.6218086938347
INFO:root:current train perplexity2.9820868968963623
INFO:root:current mean train loss 1386.4541481836075
INFO:root:current train perplexity2.982632637023926
INFO:root:current mean train loss 1387.071138213332
INFO:root:current train perplexity2.983152151107788
INFO:root:current mean train loss 1387.0686333016815
INFO:root:current train perplexity2.9830517768859863
INFO:root:current mean train loss 1386.7377022818878
INFO:root:current train perplexity2.98309063911438
INFO:root:current mean train loss 1385.9922158293994
INFO:root:current train perplexity2.982349157333374
INFO:root:current mean train loss 1385.7376056506835
INFO:root:current train perplexity2.9821903705596924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.17s/it]
INFO:root:final mean train loss: 1385.8212764430275
INFO:root:final train perplexity: 2.9830377101898193
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it]
INFO:root:eval mean loss: 3601.124043232686
INFO:root:eval perplexity: 19.201433181762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [9:14:18<1:33:32, 374.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1355.9191200949929
INFO:root:current train perplexity2.956441640853882
INFO:root:current mean train loss 1361.6113722059463
INFO:root:current train perplexity2.9694836139678955
INFO:root:current mean train loss 1377.8776245117188
INFO:root:current train perplexity2.9855315685272217
INFO:root:current mean train loss 1378.6110577250636
INFO:root:current train perplexity2.977569580078125
INFO:root:current mean train loss 1381.1856279802753
INFO:root:current train perplexity2.98006010055542
INFO:root:current mean train loss 1384.6607291277717
INFO:root:current train perplexity2.982384204864502
INFO:root:current mean train loss 1387.4312167908095
INFO:root:current train perplexity2.982261896133423
INFO:root:current mean train loss 1385.736574562647
INFO:root:current train perplexity2.980046272277832
INFO:root:current mean train loss 1387.0789952571922
INFO:root:current train perplexity2.9815189838409424
INFO:root:current mean train loss 1385.071858939478
INFO:root:current train perplexity2.978508234024048
INFO:root:current mean train loss 1384.2547906751377
INFO:root:current train perplexity2.9805445671081543
INFO:root:current mean train loss 1384.1183680821132
INFO:root:current train perplexity2.9792048931121826
INFO:root:current mean train loss 1383.9854594043597
INFO:root:current train perplexity2.979062795639038
INFO:root:current mean train loss 1382.6939832596552
INFO:root:current train perplexity2.9776713848114014
INFO:root:current mean train loss 1383.5068770221067
INFO:root:current train perplexity2.978515863418579
INFO:root:current mean train loss 1383.5420856377004
INFO:root:current train perplexity2.978001832962036
INFO:root:current mean train loss 1384.375587481942
INFO:root:current train perplexity2.9790918827056885
INFO:root:current mean train loss 1384.4601492225577
INFO:root:current train perplexity2.9784951210021973
INFO:root:current mean train loss 1384.4993187496823
INFO:root:current train perplexity2.97890043258667
INFO:root:current mean train loss 1385.0027241647979
INFO:root:current train perplexity2.979247570037842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.13s/it]
INFO:root:final mean train loss: 1384.0959296291426
INFO:root:final train perplexity: 2.9789812564849854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.73s/it]
INFO:root:eval mean loss: 3608.3608266469596
INFO:root:eval perplexity: 19.3157958984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [9:20:42<1:28:02, 377.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1374.5950267353996
INFO:root:current train perplexity2.9560956954956055
INFO:root:current mean train loss 1363.9343155570652
INFO:root:current train perplexity2.9522972106933594
INFO:root:current mean train loss 1368.814007872366
INFO:root:current train perplexity2.9547433853149414
INFO:root:current mean train loss 1373.0367773166984
INFO:root:current train perplexity2.961129903793335
INFO:root:current mean train loss 1374.5560040587718
INFO:root:current train perplexity2.967747211456299
INFO:root:current mean train loss 1374.490664993803
INFO:root:current train perplexity2.9690189361572266
INFO:root:current mean train loss 1375.18920455217
INFO:root:current train perplexity2.968547821044922
INFO:root:current mean train loss 1376.1301970513202
INFO:root:current train perplexity2.9693222045898438
INFO:root:current mean train loss 1377.9272958576057
INFO:root:current train perplexity2.9710922241210938
INFO:root:current mean train loss 1378.1344829960246
INFO:root:current train perplexity2.9696288108825684
INFO:root:current mean train loss 1379.4977886980148
INFO:root:current train perplexity2.9728641510009766
INFO:root:current mean train loss 1380.60737960776
INFO:root:current train perplexity2.973240375518799
INFO:root:current mean train loss 1380.1822809859177
INFO:root:current train perplexity2.971377372741699
INFO:root:current mean train loss 1380.6936686317506
INFO:root:current train perplexity2.9724795818328857
INFO:root:current mean train loss 1381.8403010332445
INFO:root:current train perplexity2.975795030593872
INFO:root:current mean train loss 1382.1242567865152
INFO:root:current train perplexity2.9754114151000977
INFO:root:current mean train loss 1381.9217090549273
INFO:root:current train perplexity2.9743354320526123
INFO:root:current mean train loss 1382.0576515695982
INFO:root:current train perplexity2.974480628967285
INFO:root:current mean train loss 1382.5536180564884
INFO:root:current train perplexity2.9747323989868164
INFO:root:current mean train loss 1383.1132116556046
INFO:root:current train perplexity2.975827932357788

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it]
INFO:root:final mean train loss: 1382.700375247711
INFO:root:final train perplexity: 2.9757041931152344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.20s/it]
INFO:root:eval mean loss: 3611.4901016739395
INFO:root:eval perplexity: 19.365463256835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [9:26:57<1:21:35, 376.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1383.590809357472
INFO:root:current train perplexity2.974609613418579
INFO:root:current mean train loss 1383.1854892687852
INFO:root:current train perplexity2.963848829269409
INFO:root:current mean train loss 1384.4157506270374
INFO:root:current train perplexity2.9647092819213867
INFO:root:current mean train loss 1386.9823726270565
INFO:root:current train perplexity2.973904848098755
INFO:root:current mean train loss 1387.130995363371
INFO:root:current train perplexity2.97459077835083
INFO:root:current mean train loss 1385.3244604618903
INFO:root:current train perplexity2.973785638809204
INFO:root:current mean train loss 1383.8916644881258
INFO:root:current train perplexity2.9721670150756836
INFO:root:current mean train loss 1381.1179873115912
INFO:root:current train perplexity2.9696075916290283
INFO:root:current mean train loss 1380.2543441320606
INFO:root:current train perplexity2.9681949615478516
INFO:root:current mean train loss 1379.1175643827287
INFO:root:current train perplexity2.9668521881103516
INFO:root:current mean train loss 1379.9427049173273
INFO:root:current train perplexity2.967527389526367
INFO:root:current mean train loss 1380.4159298752686
INFO:root:current train perplexity2.966545581817627
INFO:root:current mean train loss 1380.7021185885385
INFO:root:current train perplexity2.966792106628418
INFO:root:current mean train loss 1379.376384984253
INFO:root:current train perplexity2.9659423828125
INFO:root:current mean train loss 1380.157357181038
INFO:root:current train perplexity2.9687273502349854
INFO:root:current mean train loss 1380.5948820899798
INFO:root:current train perplexity2.9693493843078613
INFO:root:current mean train loss 1381.9099459005909
INFO:root:current train perplexity2.971968650817871
INFO:root:current mean train loss 1381.463130543283
INFO:root:current train perplexity2.972212314605713
INFO:root:current mean train loss 1381.5469971028126
INFO:root:current train perplexity2.9724302291870117
INFO:root:current mean train loss 1381.7623326501182
INFO:root:current train perplexity2.9727509021759033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.37s/it]
INFO:root:final mean train loss: 1381.3939867659283
INFO:root:final train perplexity: 2.972639799118042
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it]
INFO:root:eval mean loss: 3613.0879272827515
INFO:root:eval perplexity: 19.390869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:33:18<1:15:33, 377.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.4069245990954
INFO:root:current train perplexity2.9934630393981934
INFO:root:current mean train loss 1386.7688119741586
INFO:root:current train perplexity2.9705264568328857
INFO:root:current mean train loss 1382.6769671941208
INFO:root:current train perplexity2.9676568508148193
INFO:root:current mean train loss 1379.6038014858584
INFO:root:current train perplexity2.964348793029785
INFO:root:current mean train loss 1378.7734133325441
INFO:root:current train perplexity2.9613335132598877
INFO:root:current mean train loss 1377.1090551552652
INFO:root:current train perplexity2.9586825370788574
INFO:root:current mean train loss 1378.238534699584
INFO:root:current train perplexity2.9638383388519287
INFO:root:current mean train loss 1380.1959185522308
INFO:root:current train perplexity2.9663705825805664
INFO:root:current mean train loss 1380.0902234636872
INFO:root:current train perplexity2.968398094177246
INFO:root:current mean train loss 1379.1547252865892
INFO:root:current train perplexity2.965987205505371
INFO:root:current mean train loss 1380.1733931310646
INFO:root:current train perplexity2.96762752532959
INFO:root:current mean train loss 1379.1495433855257
INFO:root:current train perplexity2.96536922454834
INFO:root:current mean train loss 1379.2354273497829
INFO:root:current train perplexity2.9654557704925537
INFO:root:current mean train loss 1377.7637245533715
INFO:root:current train perplexity2.9649786949157715
INFO:root:current mean train loss 1378.3847810573004
INFO:root:current train perplexity2.963935136795044
INFO:root:current mean train loss 1378.2157695710473
INFO:root:current train perplexity2.963979959487915
INFO:root:current mean train loss 1378.6268327831167
INFO:root:current train perplexity2.9652411937713623
INFO:root:current mean train loss 1379.3524618759793
INFO:root:current train perplexity2.9676685333251953
INFO:root:current mean train loss 1379.9040453908312
INFO:root:current train perplexity2.9686288833618164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.84s/it]
INFO:root:final mean train loss: 1379.7222253411812
INFO:root:final train perplexity: 2.9687230587005615
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 3614.3858308992585
INFO:root:eval perplexity: 19.411531448364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:39:31<1:09:01, 376.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1363.5089823404949
INFO:root:current train perplexity2.9398834705352783
INFO:root:current mean train loss 1385.1451688494
INFO:root:current train perplexity2.9741108417510986
INFO:root:current mean train loss 1374.795585776275
INFO:root:current train perplexity2.9594953060150146
INFO:root:current mean train loss 1374.9336160513071
INFO:root:current train perplexity2.962144613265991
INFO:root:current mean train loss 1376.9222515809884
INFO:root:current train perplexity2.9659125804901123
INFO:root:current mean train loss 1375.1743848323822
INFO:root:current train perplexity2.961704730987549
INFO:root:current mean train loss 1373.1627001793556
INFO:root:current train perplexity2.9589905738830566
INFO:root:current mean train loss 1372.6866916270737
INFO:root:current train perplexity2.9577057361602783
INFO:root:current mean train loss 1372.1767009866649
INFO:root:current train perplexity2.9548141956329346
INFO:root:current mean train loss 1372.2995328401264
INFO:root:current train perplexity2.95479416847229
INFO:root:current mean train loss 1373.468306590446
INFO:root:current train perplexity2.955451726913452
INFO:root:current mean train loss 1373.8143784776867
INFO:root:current train perplexity2.9578545093536377
INFO:root:current mean train loss 1374.6135435198794
INFO:root:current train perplexity2.960287570953369
INFO:root:current mean train loss 1376.1987929925685
INFO:root:current train perplexity2.9611711502075195
INFO:root:current mean train loss 1377.3377874876892
INFO:root:current train perplexity2.9619994163513184
INFO:root:current mean train loss 1377.1461655551163
INFO:root:current train perplexity2.961714267730713
INFO:root:current mean train loss 1376.363299878596
INFO:root:current train perplexity2.961207151412964
INFO:root:current mean train loss 1376.9879234527873
INFO:root:current train perplexity2.9627597332000732
INFO:root:current mean train loss 1377.3475639562207
INFO:root:current train perplexity2.963303804397583
INFO:root:current mean train loss 1378.4375589282943
INFO:root:current train perplexity2.965070962905884

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.97s/it]
INFO:root:final mean train loss: 1378.4120439999763
INFO:root:final train perplexity: 2.9656569957733154
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.12s/it]
INFO:root:eval mean loss: 3615.640283349756
INFO:root:eval perplexity: 19.43152618408203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:45:44<1:02:34, 375.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1355.1797043372844
INFO:root:current train perplexity2.9627597332000732
INFO:root:current mean train loss 1370.2475302053053
INFO:root:current train perplexity2.950084924697876
INFO:root:current mean train loss 1379.4276709410822
INFO:root:current train perplexity2.9601333141326904
INFO:root:current mean train loss 1381.9460170942962
INFO:root:current train perplexity2.9643685817718506
INFO:root:current mean train loss 1385.1600091396233
INFO:root:current train perplexity2.965754270553589
INFO:root:current mean train loss 1382.5228792994594
INFO:root:current train perplexity2.9646334648132324
INFO:root:current mean train loss 1383.8339737011254
INFO:root:current train perplexity2.9690418243408203
INFO:root:current mean train loss 1383.5827653463648
INFO:root:current train perplexity2.9661715030670166
INFO:root:current mean train loss 1383.8437875487691
INFO:root:current train perplexity2.96791410446167
INFO:root:current mean train loss 1381.9149610110837
INFO:root:current train perplexity2.9660356044769287
INFO:root:current mean train loss 1382.3892850736836
INFO:root:current train perplexity2.9673421382904053
INFO:root:current mean train loss 1380.0324209667708
INFO:root:current train perplexity2.9648020267486572
INFO:root:current mean train loss 1380.3018379677012
INFO:root:current train perplexity2.96565842628479
INFO:root:current mean train loss 1379.018645436536
INFO:root:current train perplexity2.964871644973755
INFO:root:current mean train loss 1378.2653689854958
INFO:root:current train perplexity2.9651503562927246
INFO:root:current mean train loss 1378.4088550714825
INFO:root:current train perplexity2.965761423110962
INFO:root:current mean train loss 1377.722721893704
INFO:root:current train perplexity2.964017868041992
INFO:root:current mean train loss 1378.2251314038551
INFO:root:current train perplexity2.965118169784546
INFO:root:current mean train loss 1379.1040378109624
INFO:root:current train perplexity2.9660205841064453
INFO:root:current mean train loss 1378.7265903122873
INFO:root:current train perplexity2.9652035236358643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.08s/it]
INFO:root:final mean train loss: 1378.0469359120395
INFO:root:final train perplexity: 2.964803457260132
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it]
INFO:root:eval mean loss: 3614.7883696684967
INFO:root:eval perplexity: 19.41794204711914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:51:58<56:15, 375.02s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1385.160859481148
INFO:root:current train perplexity2.990781784057617
INFO:root:current mean train loss 1375.7553259444564
INFO:root:current train perplexity2.9641802310943604
INFO:root:current mean train loss 1377.3416683538173
INFO:root:current train perplexity2.9650800228118896
INFO:root:current mean train loss 1374.5465588872833
INFO:root:current train perplexity2.958646297454834
INFO:root:current mean train loss 1374.582187532844
INFO:root:current train perplexity2.9605581760406494
INFO:root:current mean train loss 1375.7747420426253
INFO:root:current train perplexity2.962628126144409
INFO:root:current mean train loss 1375.3227274513836
INFO:root:current train perplexity2.961008071899414
INFO:root:current mean train loss 1373.92151337079
INFO:root:current train perplexity2.9590156078338623
INFO:root:current mean train loss 1372.9640228776505
INFO:root:current train perplexity2.9592576026916504
INFO:root:current mean train loss 1374.4327633879905
INFO:root:current train perplexity2.9611034393310547
INFO:root:current mean train loss 1376.2984306379212
INFO:root:current train perplexity2.9640185832977295
INFO:root:current mean train loss 1376.6492489586742
INFO:root:current train perplexity2.964214324951172
INFO:root:current mean train loss 1376.5675819850082
INFO:root:current train perplexity2.9619381427764893
INFO:root:current mean train loss 1377.0094370508973
INFO:root:current train perplexity2.9639482498168945
INFO:root:current mean train loss 1377.5381896888236
INFO:root:current train perplexity2.9635233879089355
INFO:root:current mean train loss 1377.7700550627123
INFO:root:current train perplexity2.9639945030212402
INFO:root:current mean train loss 1377.298274062239
INFO:root:current train perplexity2.9635486602783203
INFO:root:current mean train loss 1377.618758683352
INFO:root:current train perplexity2.964240789413452
INFO:root:current mean train loss 1377.4998047933032
INFO:root:current train perplexity2.9634881019592285
INFO:root:current mean train loss 1377.318517702579
INFO:root:current train perplexity2.962752342224121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it]
INFO:root:final mean train loss: 1377.194646438083
INFO:root:final train perplexity: 2.9628114700317383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.65s/it]
INFO:root:eval mean loss: 3615.0466044657937
INFO:root:eval perplexity: 19.42205810546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:58:12<49:57, 374.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1367.7502383277529
INFO:root:current train perplexity2.9399242401123047
INFO:root:current mean train loss 1371.8613970235813
INFO:root:current train perplexity2.939110517501831
INFO:root:current mean train loss 1373.8717672253742
INFO:root:current train perplexity2.9552199840545654
INFO:root:current mean train loss 1371.627302185563
INFO:root:current train perplexity2.955310106277466
INFO:root:current mean train loss 1378.1256493718784
INFO:root:current train perplexity2.9640746116638184
INFO:root:current mean train loss 1377.9712234957815
INFO:root:current train perplexity2.963503122329712
INFO:root:current mean train loss 1377.8067951001012
INFO:root:current train perplexity2.962477922439575
INFO:root:current mean train loss 1379.3751979042943
INFO:root:current train perplexity2.9621121883392334
INFO:root:current mean train loss 1379.5359459586382
INFO:root:current train perplexity2.964792490005493
INFO:root:current mean train loss 1380.2098507826697
INFO:root:current train perplexity2.966550827026367
INFO:root:current mean train loss 1380.0665232675433
INFO:root:current train perplexity2.966434955596924
INFO:root:current mean train loss 1378.3326543019132
INFO:root:current train perplexity2.9633572101593018
INFO:root:current mean train loss 1377.2720593522677
INFO:root:current train perplexity2.9610652923583984
INFO:root:current mean train loss 1376.9457764209235
INFO:root:current train perplexity2.959552526473999
INFO:root:current mean train loss 1376.025102011732
INFO:root:current train perplexity2.9592607021331787
INFO:root:current mean train loss 1376.347802062715
INFO:root:current train perplexity2.960145950317383
INFO:root:current mean train loss 1375.7735619926339
INFO:root:current train perplexity2.958514451980591
INFO:root:current mean train loss 1375.272233276021
INFO:root:current train perplexity2.9576380252838135
INFO:root:current mean train loss 1375.0665426044393
INFO:root:current train perplexity2.9569337368011475
INFO:root:current mean train loss 1376.2337380951908
INFO:root:current train perplexity2.959367513656616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.19s/it]
INFO:root:final mean train loss: 1375.6736423109614
INFO:root:final train perplexity: 2.959259271621704
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.52s/it]
INFO:root:eval mean loss: 3618.4922212251313
INFO:root:eval perplexity: 19.47705078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [10:04:37<44:03, 377.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1355.8515548706055
INFO:root:current train perplexity2.929043769836426
INFO:root:current mean train loss 1366.7643764919706
INFO:root:current train perplexity2.9344279766082764
INFO:root:current mean train loss 1373.1810943603516
INFO:root:current train perplexity2.9437856674194336
INFO:root:current mean train loss 1373.9320203279194
INFO:root:current train perplexity2.95497727394104
INFO:root:current mean train loss 1373.6737856547038
INFO:root:current train perplexity2.954817295074463
INFO:root:current mean train loss 1374.3450811978043
INFO:root:current train perplexity2.9570164680480957
INFO:root:current mean train loss 1373.7352165670957
INFO:root:current train perplexity2.9554848670959473
INFO:root:current mean train loss 1373.1813448392427
INFO:root:current train perplexity2.955569267272949
INFO:root:current mean train loss 1372.8395341352982
INFO:root:current train perplexity2.954216241836548
INFO:root:current mean train loss 1372.758919727559
INFO:root:current train perplexity2.9543979167938232
INFO:root:current mean train loss 1373.318302295826
INFO:root:current train perplexity2.9555933475494385
INFO:root:current mean train loss 1372.3378363657805
INFO:root:current train perplexity2.9544548988342285
INFO:root:current mean train loss 1373.5891446590424
INFO:root:current train perplexity2.956697940826416
INFO:root:current mean train loss 1374.1755617445795
INFO:root:current train perplexity2.956313133239746
INFO:root:current mean train loss 1375.7925220798802
INFO:root:current train perplexity2.958055257797241
INFO:root:current mean train loss 1375.99835487076
INFO:root:current train perplexity2.958030939102173
INFO:root:current mean train loss 1375.358440326509
INFO:root:current train perplexity2.9576656818389893
INFO:root:current mean train loss 1375.5757899252217
INFO:root:current train perplexity2.9574882984161377
INFO:root:current mean train loss 1374.8217268598842
INFO:root:current train perplexity2.956378936767578
INFO:root:current mean train loss 1374.8588801528467
INFO:root:current train perplexity2.9565579891204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.41s/it]
INFO:root:final mean train loss: 1374.4856635097055
INFO:root:final train perplexity: 2.9564878940582275
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it]
INFO:root:eval mean loss: 3615.1322113128754
INFO:root:eval perplexity: 19.423423767089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [10:10:49<37:35, 375.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1377.1704957313145
INFO:root:current train perplexity2.970881223678589
INFO:root:current mean train loss 1379.2437403335184
INFO:root:current train perplexity2.9716267585754395
INFO:root:current mean train loss 1379.179842862216
INFO:root:current train perplexity2.9628100395202637
INFO:root:current mean train loss 1377.9556817119608
INFO:root:current train perplexity2.9644196033477783
INFO:root:current mean train loss 1378.0238226232395
INFO:root:current train perplexity2.9633426666259766
INFO:root:current mean train loss 1379.4771746918184
INFO:root:current train perplexity2.960702419281006
INFO:root:current mean train loss 1378.6956473614598
INFO:root:current train perplexity2.9588310718536377
INFO:root:current mean train loss 1376.8623812686246
INFO:root:current train perplexity2.9583709239959717
INFO:root:current mean train loss 1376.852566279961
INFO:root:current train perplexity2.9573845863342285
INFO:root:current mean train loss 1376.2996237246896
INFO:root:current train perplexity2.9569685459136963
INFO:root:current mean train loss 1376.6124091761267
INFO:root:current train perplexity2.958716869354248
INFO:root:current mean train loss 1376.1131824311756
INFO:root:current train perplexity2.958280563354492
INFO:root:current mean train loss 1376.0889152815091
INFO:root:current train perplexity2.958841323852539
INFO:root:current mean train loss 1375.717081734856
INFO:root:current train perplexity2.9570767879486084
INFO:root:current mean train loss 1375.8288865328313
INFO:root:current train perplexity2.9578940868377686
INFO:root:current mean train loss 1375.8176333738552
INFO:root:current train perplexity2.9577550888061523
INFO:root:current mean train loss 1375.0433840192482
INFO:root:current train perplexity2.9567112922668457
INFO:root:current mean train loss 1374.8491993491757
INFO:root:current train perplexity2.9568755626678467
INFO:root:current mean train loss 1375.0659715072318
INFO:root:current train perplexity2.9576215744018555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.59s/it]
INFO:root:final mean train loss: 1373.9881198592577
INFO:root:final train perplexity: 2.9553282260894775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.49s/it]
INFO:root:eval mean loss: 3615.3839027015297
INFO:root:eval perplexity: 19.427438735961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:17:02<31:15, 375.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1338.8709019252233
INFO:root:current train perplexity2.888658046722412
INFO:root:current mean train loss 1361.831448739035
INFO:root:current train perplexity2.9248690605163574
INFO:root:current mean train loss 1367.064699547313
INFO:root:current train perplexity2.928318977355957
INFO:root:current mean train loss 1367.5681245645899
INFO:root:current train perplexity2.9334614276885986
INFO:root:current mean train loss 1366.5710593698104
INFO:root:current train perplexity2.9329404830932617
INFO:root:current mean train loss 1369.1301537895945
INFO:root:current train perplexity2.9395461082458496
INFO:root:current mean train loss 1369.967484365457
INFO:root:current train perplexity2.94474458694458
INFO:root:current mean train loss 1371.7094273500416
INFO:root:current train perplexity2.944985866546631
INFO:root:current mean train loss 1371.4774777274167
INFO:root:current train perplexity2.9459500312805176
INFO:root:current mean train loss 1372.2810053251505
INFO:root:current train perplexity2.947213888168335
INFO:root:current mean train loss 1371.9738483015133
INFO:root:current train perplexity2.9453141689300537
INFO:root:current mean train loss 1372.8230471379882
INFO:root:current train perplexity2.9467689990997314
INFO:root:current mean train loss 1373.0452208165477
INFO:root:current train perplexity2.948214292526245
INFO:root:current mean train loss 1372.6166545339552
INFO:root:current train perplexity2.948565721511841
INFO:root:current mean train loss 1372.802756216435
INFO:root:current train perplexity2.9503867626190186
INFO:root:current mean train loss 1373.978662528639
INFO:root:current train perplexity2.951453924179077
INFO:root:current mean train loss 1373.8433901421643
INFO:root:current train perplexity2.9523766040802
INFO:root:current mean train loss 1374.1152318823156
INFO:root:current train perplexity2.952422857284546
INFO:root:current mean train loss 1374.313764982213
INFO:root:current train perplexity2.9523818492889404
INFO:root:current mean train loss 1374.216190987869
INFO:root:current train perplexity2.952799081802368

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it]
INFO:root:final mean train loss: 1372.6924098366387
INFO:root:final train perplexity: 2.9523098468780518
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.63s/it]
INFO:root:eval mean loss: 3620.151169968797
INFO:root:eval perplexity: 19.503583908081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:23:16<24:58, 374.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1393.3184184412803
INFO:root:current train perplexity2.9986467361450195
INFO:root:current mean train loss 1382.8136713158992
INFO:root:current train perplexity2.9886386394500732
INFO:root:current mean train loss 1377.5191016259132
INFO:root:current train perplexity2.9700727462768555
INFO:root:current mean train loss 1376.6829756537952
INFO:root:current train perplexity2.9621686935424805
INFO:root:current mean train loss 1380.3542463475203
INFO:root:current train perplexity2.9658961296081543
INFO:root:current mean train loss 1378.763209571048
INFO:root:current train perplexity2.962217330932617
INFO:root:current mean train loss 1377.2654147140574
INFO:root:current train perplexity2.9579687118530273
INFO:root:current mean train loss 1377.1398514983755
INFO:root:current train perplexity2.957521438598633
INFO:root:current mean train loss 1377.0348345484545
INFO:root:current train perplexity2.9584784507751465
INFO:root:current mean train loss 1375.565842314002
INFO:root:current train perplexity2.956463098526001
INFO:root:current mean train loss 1374.0345054056666
INFO:root:current train perplexity2.954301357269287
INFO:root:current mean train loss 1373.871529576633
INFO:root:current train perplexity2.9538731575012207
INFO:root:current mean train loss 1374.185767513867
INFO:root:current train perplexity2.953986644744873
INFO:root:current mean train loss 1373.9951527722342
INFO:root:current train perplexity2.9531750679016113
INFO:root:current mean train loss 1372.3176639751484
INFO:root:current train perplexity2.9518840312957764
INFO:root:current mean train loss 1372.1596425341127
INFO:root:current train perplexity2.9525036811828613
INFO:root:current mean train loss 1373.6002824457053
INFO:root:current train perplexity2.954599618911743
INFO:root:current mean train loss 1373.6367545036965
INFO:root:current train perplexity2.9536893367767334
INFO:root:current mean train loss 1373.2377366337341
INFO:root:current train perplexity2.9535467624664307
INFO:root:current mean train loss 1373.052412352125
INFO:root:current train perplexity2.952662706375122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.16s/it]
INFO:root:final mean train loss: 1372.6013961076376
INFO:root:final train perplexity: 2.9520976543426514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it]
INFO:root:eval mean loss: 3617.755959084084
INFO:root:eval perplexity: 19.465286254882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:29:30<18:43, 374.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1376.6269022623699
INFO:root:current train perplexity2.967031955718994
INFO:root:current mean train loss 1373.059810329128
INFO:root:current train perplexity2.9694650173187256
INFO:root:current mean train loss 1374.524144326487
INFO:root:current train perplexity2.9680187702178955
INFO:root:current mean train loss 1372.5156902444774
INFO:root:current train perplexity2.9575817584991455
INFO:root:current mean train loss 1374.9596252441406
INFO:root:current train perplexity2.9577910900115967
INFO:root:current mean train loss 1376.1683285010122
INFO:root:current train perplexity2.953907012939453
INFO:root:current mean train loss 1377.4856951678241
INFO:root:current train perplexity2.9551076889038086
INFO:root:current mean train loss 1376.7655877914021
INFO:root:current train perplexity2.95283842086792
INFO:root:current mean train loss 1374.6478697578862
INFO:root:current train perplexity2.9524319171905518
INFO:root:current mean train loss 1374.9668004804523
INFO:root:current train perplexity2.953367233276367
INFO:root:current mean train loss 1374.33439379976
INFO:root:current train perplexity2.952913761138916
INFO:root:current mean train loss 1372.549625091021
INFO:root:current train perplexity2.952225923538208
INFO:root:current mean train loss 1373.11778034308
INFO:root:current train perplexity2.9518532752990723
INFO:root:current mean train loss 1373.8931320597935
INFO:root:current train perplexity2.952326774597168
INFO:root:current mean train loss 1373.4733883346642
INFO:root:current train perplexity2.9519405364990234
INFO:root:current mean train loss 1372.5861856623214
INFO:root:current train perplexity2.950284957885742
INFO:root:current mean train loss 1372.6422141362164
INFO:root:current train perplexity2.9497880935668945
INFO:root:current mean train loss 1372.316136480196
INFO:root:current train perplexity2.9492733478546143
INFO:root:current mean train loss 1371.832283779656
INFO:root:current train perplexity2.949774742126465
INFO:root:current mean train loss 1371.5691471922323
INFO:root:current train perplexity2.949667453765869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.88s/it]
INFO:root:final mean train loss: 1371.6237230940533
INFO:root:final train perplexity: 2.9498226642608643
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.64s/it]
INFO:root:eval mean loss: 3620.398098782376
INFO:root:eval perplexity: 19.507532119750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:35:43<12:28, 374.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1376.5120849609375
INFO:root:current train perplexity2.9412930011749268
INFO:root:current mean train loss 1368.403184185606
INFO:root:current train perplexity2.9447035789489746
INFO:root:current mean train loss 1368.766782134434
INFO:root:current train perplexity2.9487383365631104
INFO:root:current mean train loss 1368.1886581629924
INFO:root:current train perplexity2.9488563537597656
INFO:root:current mean train loss 1371.167720409106
INFO:root:current train perplexity2.9505128860473633
INFO:root:current mean train loss 1374.1810099643944
INFO:root:current train perplexity2.95042085647583
INFO:root:current mean train loss 1373.0736284069549
INFO:root:current train perplexity2.946620464324951
INFO:root:current mean train loss 1374.157155554279
INFO:root:current train perplexity2.9482545852661133
INFO:root:current mean train loss 1374.2979016607208
INFO:root:current train perplexity2.9495327472686768
INFO:root:current mean train loss 1374.1468529893943
INFO:root:current train perplexity2.9497599601745605
INFO:root:current mean train loss 1373.7076440085827
INFO:root:current train perplexity2.9482719898223877
INFO:root:current mean train loss 1373.2129276128287
INFO:root:current train perplexity2.9494755268096924
INFO:root:current mean train loss 1373.4264027953618
INFO:root:current train perplexity2.9503116607666016
INFO:root:current mean train loss 1373.5889922983918
INFO:root:current train perplexity2.951066255569458
INFO:root:current mean train loss 1372.2378270484483
INFO:root:current train perplexity2.949111223220825
INFO:root:current mean train loss 1371.945988683731
INFO:root:current train perplexity2.948981285095215
INFO:root:current mean train loss 1371.7092373134853
INFO:root:current train perplexity2.9483094215393066
INFO:root:current mean train loss 1372.0047943547495
INFO:root:current train perplexity2.9485714435577393
INFO:root:current mean train loss 1371.5414203224489
INFO:root:current train perplexity2.9479904174804688
INFO:root:current mean train loss 1371.8386164619117
INFO:root:current train perplexity2.9491052627563477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it]
INFO:root:final mean train loss: 1371.3609318427827
INFO:root:final train perplexity: 2.9492111206054688
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.00s/it]
INFO:root:eval mean loss: 3619.057964702984
INFO:root:eval perplexity: 19.48609733581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:41:56<06:13, 373.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1368.1465811380526
INFO:root:current train perplexity2.924513101577759
INFO:root:current mean train loss 1360.429727072244
INFO:root:current train perplexity2.9241690635681152
INFO:root:current mean train loss 1364.9135040932513
INFO:root:current train perplexity2.931830883026123
INFO:root:current mean train loss 1365.9668432105898
INFO:root:current train perplexity2.930445432662964
INFO:root:current mean train loss 1368.2888596404143
INFO:root:current train perplexity2.935220241546631
INFO:root:current mean train loss 1368.4849408860878
INFO:root:current train perplexity2.9395618438720703
INFO:root:current mean train loss 1370.10826616483
INFO:root:current train perplexity2.943114757537842
INFO:root:current mean train loss 1370.5438547744166
INFO:root:current train perplexity2.94411039352417
INFO:root:current mean train loss 1369.5507355774341
INFO:root:current train perplexity2.9426329135894775
INFO:root:current mean train loss 1370.4977477903035
INFO:root:current train perplexity2.9445950984954834
INFO:root:current mean train loss 1370.3348579336227
INFO:root:current train perplexity2.9442801475524902
INFO:root:current mean train loss 1370.602155708016
INFO:root:current train perplexity2.9444358348846436
INFO:root:current mean train loss 1370.675734402423
INFO:root:current train perplexity2.9446873664855957
INFO:root:current mean train loss 1370.7661636286293
INFO:root:current train perplexity2.9450387954711914
INFO:root:current mean train loss 1372.326802489246
INFO:root:current train perplexity2.9473214149475098
INFO:root:current mean train loss 1370.2952507395207
INFO:root:current train perplexity2.944554090499878
INFO:root:current mean train loss 1369.2484037964011
INFO:root:current train perplexity2.9438531398773193
INFO:root:current mean train loss 1368.9463559203143
INFO:root:current train perplexity2.943389654159546
INFO:root:current mean train loss 1369.9032536992104
INFO:root:current train perplexity2.945406436920166
INFO:root:current mean train loss 1370.5632874828534
INFO:root:current train perplexity2.946485996246338

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it]
INFO:root:final mean train loss: 1370.1516970482007
INFO:root:final train perplexity: 2.9464001655578613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it]
INFO:root:eval mean loss: 3619.1965449336053
INFO:root:eval perplexity: 19.488313674926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_13/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:48:09<00:00, 373.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:48:09<00:00, 388.90s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.69s/it]
INFO:root:eval mean loss: 3619.1965449336053
INFO:root:eval perplexity: 19.488313674926758
INFO:root:evalaution complete
INFO:root:save model final: pld_13/final
