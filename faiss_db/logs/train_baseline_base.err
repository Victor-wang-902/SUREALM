INFO:root:Output: small_baseline_base
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 99272.43647411616
INFO:root:current train perplexity18036.224609375
INFO:root:current mean train loss 81820.84429962312
INFO:root:current train perplexity3171.821533203125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.00s/it]
INFO:root:final mean train loss: 75349.2867313508
INFO:root:final train perplexity: 1688.959716796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 44183.75246465774
INFO:root:eval perplexity: 96.8175048828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/1

  0%|          | 1/200 [02:30<8:17:30, 150.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 43216.07506127451
INFO:root:current train perplexity70.40328979492188
INFO:root:current mean train loss 39473.134209437085
INFO:root:current train perplexity48.95458221435547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.91s/it]
INFO:root:final mean train loss: 36940.597727129534
INFO:root:final train perplexity: 38.22666931152344
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 32167.186337425595
INFO:root:eval perplexity: 27.915021896362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/2

  1%|          | 2/200 [04:48<7:53:19, 143.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31326.970703125
INFO:root:current train perplexity21.348215103149414
INFO:root:current mean train loss 30246.24943112864
INFO:root:current train perplexity19.656265258789062
INFO:root:current mean train loss 29370.208609144087
INFO:root:current train perplexity18.05287742614746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.15s/it]
INFO:root:final mean train loss: 29016.065051663307
INFO:root:final train perplexity: 17.495071411132812
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 28852.208054315477
INFO:root:eval perplexity: 19.8078670501709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/3

  2%|â–         | 3/200 [07:08<7:44:39, 141.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26925.203338068182
INFO:root:current train perplexity14.135064125061035
INFO:root:current mean train loss 26440.808505544355
INFO:root:current train perplexity13.528770446777344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it]
INFO:root:final mean train loss: 26023.954424458167
INFO:root:final train perplexity: 13.024091720581055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 27391.79417782738
INFO:root:eval perplexity: 17.02925682067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/4

  2%|â–         | 4/200 [09:27<7:39:10, 140.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 25189.284598214286
INFO:root:current train perplexity11.964125633239746
INFO:root:current mean train loss 24833.868227949766
INFO:root:current train perplexity11.503554344177246
INFO:root:current mean train loss 24498.364724864132
INFO:root:current train perplexity11.181487083435059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it]
INFO:root:final mean train loss: 24382.911518712197
INFO:root:final train perplexity: 11.077777862548828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 26486.230864025296
INFO:root:eval perplexity: 15.50575065612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/5

  2%|â–Ž         | 5/200 [11:46<7:35:32, 140.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23790.61338056144
INFO:root:current train perplexity10.39542293548584
INFO:root:current mean train loss 23490.403265035377
INFO:root:current train perplexity10.13741397857666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 23316.47658612651
INFO:root:final train perplexity: 9.971749305725098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 25912.863374255954
INFO:root:eval perplexity: 14.612381935119629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/6

  3%|â–Ž         | 6/200 [14:06<7:32:23, 139.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23096.460404829544
INFO:root:current train perplexity9.57815933227539
INFO:root:current mean train loss 22737.15427927928
INFO:root:current train perplexity9.393837928771973
INFO:root:current mean train loss 22595.831077828792
INFO:root:current train perplexity9.272260665893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.77s/it]
INFO:root:final mean train loss: 22551.161030430947
INFO:root:final train perplexity: 9.246742248535156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 25486.209170386905
INFO:root:eval perplexity: 13.98118782043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/7

  4%|â–Ž         | 7/200 [16:25<7:29:52, 139.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22129.18359375
INFO:root:current train perplexity8.827982902526855
INFO:root:current mean train loss 22063.24342168328
INFO:root:current train perplexity8.785246849060059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it]
INFO:root:final mean train loss: 21954.569304435485
INFO:root:final train perplexity: 8.718334197998047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 25144.274483816964
INFO:root:eval perplexity: 13.495064735412598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/8

  4%|â–         | 8/200 [18:45<7:26:53, 139.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22062.146223958334
INFO:root:current train perplexity8.560218811035156
INFO:root:current mean train loss 21668.105723505436
INFO:root:current train perplexity8.423442840576172
INFO:root:current mean train loss 21534.955804869187
INFO:root:current train perplexity8.343761444091797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it]
INFO:root:final mean train loss: 21485.696690713205
INFO:root:final train perplexity: 8.324326515197754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it]
INFO:root:eval mean loss: 24899.073218936013
INFO:root:eval perplexity: 13.156905174255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/9

  4%|â–         | 9/200 [21:03<7:23:45, 139.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21277.861269822763
INFO:root:current train perplexity8.109246253967285
INFO:root:current mean train loss 21168.360556231288
INFO:root:current train perplexity8.051921844482422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it]
INFO:root:final mean train loss: 21101.053640057962
INFO:root:final train perplexity: 8.014432907104492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it]
INFO:root:eval mean loss: 24690.55115327381
INFO:root:eval perplexity: 12.876006126403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/10

  5%|â–Œ         | 10/200 [23:23<7:21:24, 139.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20751.936574835527
INFO:root:current train perplexity7.837059020996094
INFO:root:current mean train loss 20874.772140887606
INFO:root:current train perplexity7.825272083282471
INFO:root:current mean train loss 20796.380003210616
INFO:root:current train perplexity7.764382839202881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it]
INFO:root:final mean train loss: 20774.003953503023
INFO:root:final train perplexity: 7.76003360748291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it]
INFO:root:eval mean loss: 24506.23611886161
INFO:root:eval perplexity: 12.632712364196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/11

  6%|â–Œ         | 11/200 [25:42<7:18:42, 139.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20540.986383142605
INFO:root:current train perplexity7.591703414916992
INFO:root:current mean train loss 20572.70152595029
INFO:root:current train perplexity7.580435276031494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 20490.853409305695
INFO:root:final train perplexity: 7.546308994293213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 24360.84498232887
INFO:root:eval perplexity: 12.444046974182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/12

  6%|â–Œ         | 12/200 [28:01<7:16:21, 139.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20318.129245923912
INFO:root:current train perplexity7.3958611488342285
INFO:root:current mean train loss 20313.188929115855
INFO:root:current train perplexity7.391269207000732
INFO:root:current mean train loss 20269.13045648823
INFO:root:current train perplexity7.366604328155518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.43s/it]
INFO:root:final mean train loss: 20247.405848349295
INFO:root:final train perplexity: 7.367268085479736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 24220.309105282737
INFO:root:eval perplexity: 12.264362335205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/13

  6%|â–‹         | 13/200 [30:21<7:14:19, 139.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20098.906614583335
INFO:root:current train perplexity7.256165027618408
INFO:root:current mean train loss 20099.540212053573
INFO:root:current train perplexity7.240778923034668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it]
INFO:root:final mean train loss: 20028.541940996725
INFO:root:final train perplexity: 7.209934234619141
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 24101.935686383928
INFO:root:eval perplexity: 12.115026473999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/14

  7%|â–‹         | 14/200 [32:40<7:11:56, 139.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20069.118995949073
INFO:root:current train perplexity7.088993072509766
INFO:root:current mean train loss 19899.469795767716
INFO:root:current train perplexity7.080132961273193
INFO:root:current mean train loss 19860.169646544604
INFO:root:current train perplexity7.076396465301514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 19835.27490234375
INFO:root:final train perplexity: 7.073797225952148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it]
INFO:root:eval mean loss: 24018.92357235863
INFO:root:eval perplexity: 12.011384010314941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/15

  8%|â–Š         | 15/200 [34:59<7:09:42, 139.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19683.30434137658
INFO:root:current train perplexity6.976203918457031
INFO:root:current mean train loss 19703.80180691341
INFO:root:current train perplexity6.957712650299072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it]
INFO:root:final mean train loss: 19657.82929451235
INFO:root:final train perplexity: 6.9510698318481445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23916.12560453869
INFO:root:eval perplexity: 11.884272575378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/16

  8%|â–Š         | 16/200 [37:19<7:07:18, 139.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19554.8318422379
INFO:root:current train perplexity6.881736755371094
INFO:root:current mean train loss 19498.84717915076
INFO:root:current train perplexity6.843597412109375
INFO:root:current mean train loss 19518.358521036254
INFO:root:current train perplexity6.848130702972412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.66s/it]
INFO:root:final mean train loss: 19498.929813508064
INFO:root:final train perplexity: 6.8429789543151855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 23844.082054501487
INFO:root:eval perplexity: 11.795989990234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/17

  8%|â–Š         | 17/200 [39:38<7:05:13, 139.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19413.83466679217
INFO:root:current train perplexity6.7644362449646
INFO:root:current mean train loss 19387.193700905056
INFO:root:current train perplexity6.756857872009277


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.22s/it]
INFO:root:final mean train loss: 19350.093060893396
INFO:root:final train perplexity: 6.743257522583008
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 23779.944010416668
INFO:root:eval perplexity: 11.717947006225586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/18

  9%|â–‰         | 18/200 [41:57<7:02:47, 139.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19163.574051339285
INFO:root:current train perplexity6.632863998413086
INFO:root:current mean train loss 19215.618388310184
INFO:root:current train perplexity6.6667866706848145
INFO:root:current mean train loss 19226.984599401596
INFO:root:current train perplexity6.655580043792725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.65s/it]
INFO:root:final mean train loss: 19213.800517420616
INFO:root:final train perplexity: 6.653215408325195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it]
INFO:root:eval mean loss: 23706.150344122023
INFO:root:eval perplexity: 11.62879467010498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/19

 10%|â–‰         | 19/200 [44:17<7:00:50, 139.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19138.394733297413
INFO:root:current train perplexity6.595510959625244
INFO:root:current mean train loss 19113.256747159092
INFO:root:current train perplexity6.576667308807373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it]
INFO:root:final mean train loss: 19093.268176663307
INFO:root:final train perplexity: 6.574586868286133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23660.45631045387
INFO:root:eval perplexity: 11.573933601379395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/20

 10%|â–ˆ         | 20/200 [46:37<6:58:19, 139.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18995.27564102564
INFO:root:current train perplexity6.474824905395508
INFO:root:current mean train loss 18993.744772931655
INFO:root:current train perplexity6.499113082885742
INFO:root:current mean train loss 18984.837890625
INFO:root:current train perplexity6.49662446975708


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 18971.82814468876
INFO:root:final train perplexity: 6.496308326721191
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it]
INFO:root:eval mean loss: 23599.52999441964
INFO:root:eval perplexity: 11.501178741455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/21

 10%|â–ˆ         | 21/200 [48:56<6:55:50, 139.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18873.576923076922
INFO:root:current train perplexity6.442200660705566
INFO:root:current mean train loss 18865.672805546466
INFO:root:current train perplexity6.424109935760498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.38s/it]
INFO:root:final mean train loss: 18861.884419102822
INFO:root:final train perplexity: 6.426241397857666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 23564.61837332589
INFO:root:eval perplexity: 11.459700584411621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/22

 11%|â–ˆ         | 22/200 [51:15<6:53:24, 139.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18800.93468386628
INFO:root:current train perplexity6.3845744132995605
INFO:root:current mean train loss 18739.58640187937
INFO:root:current train perplexity6.355602741241455
INFO:root:current mean train loss 18774.934309092077
INFO:root:current train perplexity6.3642449378967285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it]
INFO:root:final mean train loss: 18758.796122889366
INFO:root:final train perplexity: 6.36122989654541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 23519.444521949405
INFO:root:eval perplexity: 11.406244277954102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/23

 12%|â–ˆâ–        | 23/200 [53:35<6:51:13, 139.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18721.879502467105
INFO:root:current train perplexity6.317439079284668
INFO:root:current mean train loss 18689.68258213141
INFO:root:current train perplexity6.307843208312988


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.83s/it]
INFO:root:final mean train loss: 18665.67931735131
INFO:root:final train perplexity: 6.303075313568115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 23480.477887834822
INFO:root:eval perplexity: 11.360340118408203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/24

 12%|â–ˆâ–        | 24/200 [55:53<6:48:16, 139.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18585.350856050532
INFO:root:current train perplexity6.217006206512451
INFO:root:current mean train loss 18579.126767113095
INFO:root:current train perplexity6.23259973526001
INFO:root:current mean train loss 18584.53456319585
INFO:root:current train perplexity6.243312358856201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it]
INFO:root:final mean train loss: 18569.61083984375
INFO:root:final train perplexity: 6.243632793426514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23433.20386904762
INFO:root:eval perplexity: 11.30489444732666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/25

 12%|â–ˆâ–Ž        | 25/200 [58:12<6:45:33, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18542.690617108587
INFO:root:current train perplexity6.20359992980957
INFO:root:current mean train loss 18503.898741755653
INFO:root:current train perplexity6.194275379180908


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.26s/it]
INFO:root:final mean train loss: 18487.668559412803
INFO:root:final train perplexity: 6.193373203277588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23405.671549479168
INFO:root:eval perplexity: 11.272726058959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/26

 13%|â–ˆâ–Ž        | 26/200 [1:00:31<6:43:27, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18389.695235906864
INFO:root:current train perplexity6.156371116638184
INFO:root:current mean train loss 18418.558852442053
INFO:root:current train perplexity6.141715049743652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it]
INFO:root:final mean train loss: 18404.54543378276
INFO:root:final train perplexity: 6.14280366897583
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 23377.89188058036
INFO:root:eval perplexity: 11.240362167358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/27

 14%|â–ˆâ–Ž        | 27/200 [1:02:51<6:41:22, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18210.485026041668
INFO:root:current train perplexity6.094415187835693
INFO:root:current mean train loss 18359.699446298542
INFO:root:current train perplexity6.099527835845947
INFO:root:current mean train loss 18344.146493996304
INFO:root:current train perplexity6.094867706298828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it]
INFO:root:final mean train loss: 18326.95736202117
INFO:root:final train perplexity: 6.095975399017334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 23339.92359561012
INFO:root:eval perplexity: 11.196281433105469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/28

 14%|â–ˆâ–        | 28/200 [1:05:10<6:39:05, 139.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18195.428764204546
INFO:root:current train perplexity6.011232852935791
INFO:root:current mean train loss 18316.04090221774
INFO:root:current train perplexity6.061087131500244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it]
INFO:root:final mean train loss: 18256.32540795111
INFO:root:final train perplexity: 6.05365514755249
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 23324.366629464286
INFO:root:eval perplexity: 11.178266525268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/29

 14%|â–ˆâ–        | 29/200 [1:07:29<6:37:02, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18110.585379464286
INFO:root:current train perplexity5.920889854431152
INFO:root:current mean train loss 18250.09628723715
INFO:root:current train perplexity6.01621675491333
INFO:root:current mean train loss 18198.100052838163
INFO:root:current train perplexity6.012768268585205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it]
INFO:root:final mean train loss: 18183.68548780872
INFO:root:final train perplexity: 6.010437488555908
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23312.003766741072
INFO:root:eval perplexity: 11.16397476196289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/30

 15%|â–ˆâ–Œ        | 30/200 [1:09:49<6:34:39, 139.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18149.516618114405
INFO:root:current train perplexity5.960518836975098
INFO:root:current mean train loss 18149.03120086478
INFO:root:current train perplexity5.9670538902282715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.49s/it]
INFO:root:final mean train loss: 18112.702534337197
INFO:root:final train perplexity: 5.968502998352051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 23245.668061755954
INFO:root:eval perplexity: 11.0875883102417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/31

 16%|â–ˆâ–Œ        | 31/200 [1:12:08<6:32:25, 139.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17840.07013494318
INFO:root:current train perplexity5.861542701721191
INFO:root:current mean train loss 18040.392490146398
INFO:root:current train perplexity5.924568176269531
INFO:root:current mean train loss 18069.781175947868
INFO:root:current train perplexity5.937246322631836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it]
INFO:root:final mean train loss: 18046.52154344128
INFO:root:final train perplexity: 5.929670810699463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it]
INFO:root:eval mean loss: 23245.18040829613
INFO:root:eval perplexity: 11.087030410766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/32

 16%|â–ˆâ–Œ        | 32/200 [1:14:27<6:30:02, 139.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18029.38963293651
INFO:root:current train perplexity5.89932107925415
INFO:root:current mean train loss 17968.09246788727
INFO:root:current train perplexity5.884007930755615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 17982.54236233619
INFO:root:final train perplexity: 5.89237117767334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23222.973609561013
INFO:root:eval perplexity: 11.061577796936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/33

 16%|â–ˆâ–‹        | 33/200 [1:16:47<6:27:44, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17951.37890625
INFO:root:current train perplexity5.83578634262085
INFO:root:current mean train loss 17946.68172554348
INFO:root:current train perplexity5.866715908050537
INFO:root:current mean train loss 17951.32605377907
INFO:root:current train perplexity5.865018844604492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.07s/it]
INFO:root:final mean train loss: 17930.8047859438
INFO:root:final train perplexity: 5.862377643585205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 23208.10997953869
INFO:root:eval perplexity: 11.044575691223145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/34

 17%|â–ˆâ–‹        | 34/200 [1:19:06<6:25:15, 139.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17871.87400886194
INFO:root:current train perplexity5.811878204345703
INFO:root:current mean train loss 17867.090697511227
INFO:root:current train perplexity5.825929164886475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it]
INFO:root:final mean train loss: 17865.444304435485
INFO:root:final train perplexity: 5.824706077575684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 23198.473539806546
INFO:root:eval perplexity: 11.03356647491455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/35

 18%|â–ˆâ–Š        | 35/200 [1:21:25<6:23:05, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17801.936574835527
INFO:root:current train perplexity5.770393371582031
INFO:root:current mean train loss 17868.330078125
INFO:root:current train perplexity5.799435138702393
INFO:root:current mean train loss 17858.24041274258
INFO:root:current train perplexity5.79884672164917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it]
INFO:root:final mean train loss: 17816.37609469506
INFO:root:final train perplexity: 5.796584606170654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23153.541922433036
INFO:root:eval perplexity: 10.982375144958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/36

 18%|â–ˆâ–Š        | 36/200 [1:23:45<6:20:47, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17864.338055677817
INFO:root:current train perplexity5.766769886016846
INFO:root:current mean train loss 17777.530290570176
INFO:root:current train perplexity5.770205020904541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it]
INFO:root:final mean train loss: 17758.603665259576
INFO:root:final train perplexity: 5.7636494636535645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 23156.548851376487
INFO:root:eval perplexity: 10.985793113708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/37

 18%|â–ˆâ–Š        | 37/200 [1:26:04<6:18:15, 139.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17738.058254076088
INFO:root:current train perplexity5.703378200531006
INFO:root:current mean train loss 17744.467336763213
INFO:root:current train perplexity5.722940444946289
INFO:root:current mean train loss 17719.709658772423
INFO:root:current train perplexity5.7334489822387695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.58s/it]
INFO:root:final mean train loss: 17712.071415070564
INFO:root:final train perplexity: 5.737256050109863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23129.68526785714
INFO:root:eval perplexity: 10.955292701721191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/38

 19%|â–ˆâ–‰        | 38/200 [1:28:22<6:15:25, 139.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17707.213697916668
INFO:root:current train perplexity5.712975978851318
INFO:root:current mean train loss 17710.116841517858
INFO:root:current train perplexity5.702221870422363


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 17659.230921591483
INFO:root:final train perplexity: 5.707432746887207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23135.92127046131
INFO:root:eval perplexity: 10.96236801147461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/39

 20%|â–ˆâ–‰        | 39/200 [1:30:42<6:13:20, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17603.152994791668
INFO:root:current train perplexity5.635200023651123
INFO:root:current mean train loss 17585.450848917324
INFO:root:current train perplexity5.65806770324707
INFO:root:current mean train loss 17614.020770236784
INFO:root:current train perplexity5.674855709075928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it]
INFO:root:final mean train loss: 17610.294189453125
INFO:root:final train perplexity: 5.679951190948486
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 23115.31863839286
INFO:root:eval perplexity: 10.939016342163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/40

 20%|â–ˆâ–ˆ        | 40/200 [1:33:00<6:10:43, 139.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17619.26797369462
INFO:root:current train perplexity5.667893409729004
INFO:root:current mean train loss 17583.031893767456
INFO:root:current train perplexity5.658780097961426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 17561.98111454133
INFO:root:final train perplexity: 5.652948379516602
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 23101.545851934523
INFO:root:eval perplexity: 10.923434257507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/41

 20%|â–ˆâ–ˆ        | 41/200 [1:35:20<6:08:33, 139.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17465.380418346773
INFO:root:current train perplexity5.599308490753174
INFO:root:current mean train loss 17494.047471374044
INFO:root:current train perplexity5.618127346038818
INFO:root:current mean train loss 17525.380199878247
INFO:root:current train perplexity5.63206148147583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.20s/it]
INFO:root:final mean train loss: 17521.997015183973
INFO:root:final train perplexity: 5.63070011138916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.91s/it]
INFO:root:eval mean loss: 23081.109793526786
INFO:root:eval perplexity: 10.900352478027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/42

 21%|â–ˆâ–ˆ        | 42/200 [1:37:39<6:06:28, 139.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17433.03765060241
INFO:root:current train perplexity5.605145454406738
INFO:root:current mean train loss 17497.634199965847
INFO:root:current train perplexity5.609626770019531


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it]
INFO:root:final mean train loss: 17476.333976499496
INFO:root:final train perplexity: 5.605397701263428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 23088.830961681546
INFO:root:eval perplexity: 10.909070014953613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/43

 22%|â–ˆâ–ˆâ–       | 43/200 [1:39:58<6:03:54, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17402.36372767857
INFO:root:current train perplexity5.592402935028076
INFO:root:current mean train loss 17475.940928819444
INFO:root:current train perplexity5.5852370262146
INFO:root:current mean train loss 17449.77306349734
INFO:root:current train perplexity5.579267978668213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 17428.579881237398
INFO:root:final train perplexity: 5.579057693481445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 23061.809175037204
INFO:root:eval perplexity: 10.878606796264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/44

 22%|â–ˆâ–ˆâ–       | 44/200 [1:42:17<6:01:48, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17408.163770653737
INFO:root:current train perplexity5.544428825378418
INFO:root:current mean train loss 17425.285218917114
INFO:root:current train perplexity5.560427665710449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.55s/it]
INFO:root:final mean train loss: 17389.71470592868
INFO:root:final train perplexity: 5.557711124420166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23050.208984375
INFO:root:eval perplexity: 10.86555290222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [1:44:37<5:59:50, 139.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17411.971404246793
INFO:root:current train perplexity5.529393196105957
INFO:root:current mean train loss 17376.193942502247
INFO:root:current train perplexity5.530219554901123
INFO:root:current mean train loss 17379.687218063547
INFO:root:current train perplexity5.538061618804932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it]
INFO:root:final mean train loss: 17351.689575195312
INFO:root:final train perplexity: 5.5369062423706055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23061.122581845237
INFO:root:eval perplexity: 10.877828598022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [1:46:56<5:57:37, 139.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17253.020303914836
INFO:root:current train perplexity5.484337329864502
INFO:root:current mean train loss 17322.709659276832
INFO:root:current train perplexity5.5152363777160645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it]
INFO:root:final mean train loss: 17311.355346679688
INFO:root:final train perplexity: 5.514922142028809
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 23037.039202008928
INFO:root:eval perplexity: 10.850752830505371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [1:49:16<5:55:21, 139.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17276.34606649709
INFO:root:current train perplexity5.490032196044922
INFO:root:current mean train loss 17251.829033271417
INFO:root:current train perplexity5.489766597747803
INFO:root:current mean train loss 17285.72809365355
INFO:root:current train perplexity5.494372367858887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.55s/it]
INFO:root:final mean train loss: 17270.84747905116
INFO:root:final train perplexity: 5.492932319641113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it]
INFO:root:eval mean loss: 23036.183919270832
INFO:root:eval perplexity: 10.84979248046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/48

 24%|â–ˆâ–ˆâ–       | 48/200 [1:51:35<5:53:09, 139.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17263.954738898025
INFO:root:current train perplexity5.481515884399414
INFO:root:current mean train loss 17250.584740584934
INFO:root:current train perplexity5.478067874908447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it]
INFO:root:final mean train loss: 17240.17476137223
INFO:root:final train perplexity: 5.476339340209961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 23018.371930803572
INFO:root:eval perplexity: 10.82980728149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/49

 24%|â–ˆâ–ˆâ–       | 49/200 [1:53:55<5:50:52, 139.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17174.002119348403
INFO:root:current train perplexity5.450104713439941
INFO:root:current mean train loss 17191.804813722363
INFO:root:current train perplexity5.449957847595215
INFO:root:current mean train loss 17212.88170151189
INFO:root:current train perplexity5.45460844039917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.67s/it]
INFO:root:final mean train loss: 17200.6136750252
INFO:root:final train perplexity: 5.455012321472168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 23018.526413690477
INFO:root:eval perplexity: 10.829980850219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [1:56:14<5:48:45, 139.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17150.652994791668
INFO:root:current train perplexity5.415801525115967
INFO:root:current mean train loss 17170.339200887247
INFO:root:current train perplexity5.431326389312744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it]
INFO:root:final mean train loss: 17167.378587292085
INFO:root:final train perplexity: 5.437160491943359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 23018.11583891369
INFO:root:eval perplexity: 10.829523086547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [1:58:33<5:46:07, 139.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17121.13893995098
INFO:root:current train perplexity5.399256706237793
INFO:root:current mean train loss 17116.011654076985
INFO:root:current train perplexity5.408272743225098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it]
INFO:root:final mean train loss: 17127.644460370462
INFO:root:final train perplexity: 5.4158935546875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 23008.240234375
INFO:root:eval perplexity: 10.81845760345459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:00:52<5:43:21, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16945.953125
INFO:root:current train perplexity5.406293869018555
INFO:root:current mean train loss 17165.450138425364
INFO:root:current train perplexity5.399906635284424
INFO:root:current mean train loss 17127.647465748152
INFO:root:current train perplexity5.399425506591797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 17095.241258190523
INFO:root:final train perplexity: 5.398612022399902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 23011.690104166668
INFO:root:eval perplexity: 10.822321891784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:03:11<5:40:58, 139.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17106.709215198865
INFO:root:current train perplexity5.371212482452393
INFO:root:current mean train loss 17055.638816784274
INFO:root:current train perplexity5.366471290588379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.87s/it]
INFO:root:final mean train loss: 17064.173186271422
INFO:root:final train perplexity: 5.382094383239746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 22984.777669270832
INFO:root:eval perplexity: 10.792219161987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:05:30<5:38:22, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17016.20675223214
INFO:root:current train perplexity5.324815273284912
INFO:root:current mean train loss 17051.918306439835
INFO:root:current train perplexity5.351286888122559
INFO:root:current mean train loss 17053.077360733696
INFO:root:current train perplexity5.3652238845825195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it]
INFO:root:final mean train loss: 17034.95222719254
INFO:root:final train perplexity: 5.366604328155518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it]
INFO:root:eval mean loss: 22992.33337983631
INFO:root:eval perplexity: 10.80066204071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:07:49<5:36:03, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16972.763655323095
INFO:root:current train perplexity5.327030658721924
INFO:root:current mean train loss 16990.303403842376
INFO:root:current train perplexity5.340614318847656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 17002.254154328377
INFO:root:final train perplexity: 5.3493242263793945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 22977.967610677082
INFO:root:eval perplexity: 10.784615516662598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:10:08<5:33:55, 139.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16663.520862926136
INFO:root:current train perplexity5.2555131912231445
INFO:root:current mean train loss 16923.9502393018
INFO:root:current train perplexity5.307852268218994
INFO:root:current mean train loss 16971.27805187352
INFO:root:current train perplexity5.3237104415893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it]
INFO:root:final mean train loss: 16971.98117360761
INFO:root:final train perplexity: 5.333376407623291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 22970.446707589286
INFO:root:eval perplexity: 10.776224136352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:12:27<5:31:18, 139.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16958.583364335318
INFO:root:current train perplexity5.310282230377197
INFO:root:current mean train loss 16958.5544358704
INFO:root:current train perplexity5.311863422393799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it]
INFO:root:final mean train loss: 16940.82136781754
INFO:root:final train perplexity: 5.317008972167969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 22976.398484002977
INFO:root:eval perplexity: 10.782864570617676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:14:46<5:29:09, 139.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17016.530729166665
INFO:root:current train perplexity5.28200626373291
INFO:root:current mean train loss 16914.680018682066
INFO:root:current train perplexity5.305500507354736
INFO:root:current mean train loss 16925.436459847384
INFO:root:current train perplexity5.308116436004639


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it]
INFO:root:final mean train loss: 16910.75509938886
INFO:root:final train perplexity: 5.301265716552734
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it]
INFO:root:eval mean loss: 22977.127255394345
INFO:root:eval perplexity: 10.783677101135254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:17:06<5:27:00, 139.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16862.820108442163
INFO:root:current train perplexity5.283156871795654
INFO:root:current mean train loss 16904.199809365644
INFO:root:current train perplexity5.288084983825684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.69s/it]
INFO:root:final mean train loss: 16883.415968371977
INFO:root:final train perplexity: 5.286989688873291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 22968.56982421875
INFO:root:eval perplexity: 10.774129867553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:19:24<5:24:22, 139.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16751.207082648027
INFO:root:current train perplexity5.240880966186523
INFO:root:current mean train loss 16847.705028886554
INFO:root:current train perplexity5.261713027954102
INFO:root:current mean train loss 16856.254057862443
INFO:root:current train perplexity5.266308307647705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it]
INFO:root:final mean train loss: 16851.28299048639
INFO:root:final train perplexity: 5.270259380340576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.68s/it]
INFO:root:eval mean loss: 22967.156668526786
INFO:root:eval perplexity: 10.772555351257324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:21:43<5:21:56, 138.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16842.016381492078
INFO:root:current train perplexity5.246164321899414
INFO:root:current mean train loss 16829.30540707237
INFO:root:current train perplexity5.254256248474121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.28s/it]
INFO:root:final mean train loss: 16825.72332173009
INFO:root:final train perplexity: 5.2569899559021
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it]
INFO:root:eval mean loss: 22964.400716145832
INFO:root:eval perplexity: 10.769481658935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:24:02<5:19:49, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16698.109842051632
INFO:root:current train perplexity5.221106052398682
INFO:root:current mean train loss 16794.098426384655
INFO:root:current train perplexity5.230710983276367
INFO:root:current mean train loss 16821.19434469591
INFO:root:current train perplexity5.241699695587158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it]
INFO:root:final mean train loss: 16800.535053868447
INFO:root:final train perplexity: 5.243945598602295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it]
INFO:root:eval mean loss: 22954.561941964286
INFO:root:eval perplexity: 10.758523941040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:26:22<5:17:43, 139.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16775.560416666667
INFO:root:current train perplexity5.230948448181152
INFO:root:current mean train loss 16779.147103794643
INFO:root:current train perplexity5.222146511077881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 16770.759623865928
INFO:root:final train perplexity: 5.228567600250244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 22956.53882998512
INFO:root:eval perplexity: 10.760725021362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [2:28:41<5:15:21, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16739.610279224536
INFO:root:current train perplexity5.19536828994751
INFO:root:current mean train loss 16773.756090059054
INFO:root:current train perplexity5.215545654296875
INFO:root:current mean train loss 16755.77237919879
INFO:root:current train perplexity5.213772773742676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it]
INFO:root:final mean train loss: 16746.033100743447
INFO:root:final train perplexity: 5.215831756591797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 22959.42845517113
INFO:root:eval perplexity: 10.76394271850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [2:31:00<5:13:01, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16743.84153728244
INFO:root:current train perplexity5.216385364532471
INFO:root:current mean train loss 16743.93696534567
INFO:root:current train perplexity5.206717014312744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it]
INFO:root:final mean train loss: 16720.671284337197
INFO:root:final train perplexity: 5.20280122756958
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it]
INFO:root:eval mean loss: 22952.975399925595
INFO:root:eval perplexity: 10.756756782531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [2:33:19<5:10:42, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16647.515593497985
INFO:root:current train perplexity5.1680378913879395
INFO:root:current mean train loss 16666.59523348044
INFO:root:current train perplexity5.170455455780029
INFO:root:current mean train loss 16724.870730181276
INFO:root:current train perplexity5.192752838134766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.13s/it]
INFO:root:final mean train loss: 16694.76056498866
INFO:root:final train perplexity: 5.1895222663879395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it]
INFO:root:eval mean loss: 22957.168294270832
INFO:root:eval perplexity: 10.761425018310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [2:35:38<5:08:19, 139.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16675.255624058736
INFO:root:current train perplexity5.189011096954346
INFO:root:current mean train loss 16699.81069095799
INFO:root:current train perplexity5.187061309814453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.73s/it]
INFO:root:final mean train loss: 16671.041846490676
INFO:root:final train perplexity: 5.177395343780518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 22968.210518973214
INFO:root:eval perplexity: 10.77373218536377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [2:37:57<5:05:37, 138.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16628.69771205357
INFO:root:current train perplexity5.181397914886475
INFO:root:current mean train loss 16644.263773148148
INFO:root:current train perplexity5.160154342651367
INFO:root:current mean train loss 16649.92938829787
INFO:root:current train perplexity5.164647579193115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.94s/it]
INFO:root:final mean train loss: 16647.963969569053
INFO:root:final train perplexity: 5.165623664855957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it]
INFO:root:eval mean loss: 22951.975632440477
INFO:root:eval perplexity: 10.755640983581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [2:40:16<5:03:22, 138.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16630.72235317888
INFO:root:current train perplexity5.137303829193115
INFO:root:current mean train loss 16631.928998161766
INFO:root:current train perplexity5.148112773895264


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.52s/it]
INFO:root:final mean train loss: 16622.984934160788
INFO:root:final train perplexity: 5.152912139892578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 22949.87576729911
INFO:root:eval perplexity: 10.753305435180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [2:42:35<5:01:23, 139.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16746.97859074519
INFO:root:current train perplexity5.12979793548584
INFO:root:current mean train loss 16619.461555755395
INFO:root:current train perplexity5.129596710205078
INFO:root:current mean train loss 16613.059517194037
INFO:root:current train perplexity5.1395583152771


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.70s/it]
INFO:root:final mean train loss: 16600.47369187878
INFO:root:final train perplexity: 5.14148473739624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 22941.193894159227
INFO:root:eval perplexity: 10.743646621704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [2:44:55<4:59:24, 139.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16599.893425910028
INFO:root:current train perplexity5.134632587432861
INFO:root:current mean train loss 16609.053910340313
INFO:root:current train perplexity5.1329731941223145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it]
INFO:root:final mean train loss: 16576.491459015877
INFO:root:final train perplexity: 5.129336833953857
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 22937.744768415178
INFO:root:eval perplexity: 10.739812850952148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [2:47:14<4:56:57, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16541.802325581397
INFO:root:current train perplexity5.104062080383301
INFO:root:current mean train loss 16535.223960609703
INFO:root:current train perplexity5.112120151519775
INFO:root:current mean train loss 16566.530803915895
INFO:root:current train perplexity5.116146087646484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it]
INFO:root:final mean train loss: 16549.943898847025
INFO:root:final train perplexity: 5.115922927856445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 22957.286039806546
INFO:root:eval perplexity: 10.761555671691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [2:49:33<4:54:52, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16481.427981085526
INFO:root:current train perplexity5.089026927947998
INFO:root:current mean train loss 16514.89315905449
INFO:root:current train perplexity5.096421241760254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.76s/it]
INFO:root:final mean train loss: 16527.92404470136
INFO:root:final train perplexity: 5.104824066162109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 22946.089308965773
INFO:root:eval perplexity: 10.749093055725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [2:51:53<4:52:52, 139.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16492.98213098404
INFO:root:current train perplexity5.081721782684326
INFO:root:current mean train loss 16511.776526626276
INFO:root:current train perplexity5.092621326446533
INFO:root:current mean train loss 16523.613822906125
INFO:root:current train perplexity5.095609664916992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it]
INFO:root:final mean train loss: 16509.49576691658
INFO:root:final train perplexity: 5.095554351806641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 22934.463355654763
INFO:root:eval perplexity: 10.736166954040527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/75
##########################best####################
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [2:54:13<4:50:31, 139.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16530.090001578283
INFO:root:current train perplexity5.084728240966797
INFO:root:current mean train loss 16496.764879082915
INFO:root:current train perplexity5.084408760070801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.64s/it]
INFO:root:final mean train loss: 16488.815185546875
INFO:root:final train perplexity: 5.085170745849609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it]
INFO:root:eval mean loss: 22947.003092447918
INFO:root:eval perplexity: 10.750110626220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [2:56:32<4:48:13, 139.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16487.579982383577
INFO:root:current train perplexity5.0637526512146
INFO:root:current mean train loss 16509.96668693088
INFO:root:current train perplexity5.0754618644714355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 16464.052104334678
INFO:root:final train perplexity: 5.072765350341797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 22954.79736328125
INFO:root:eval perplexity: 10.758788108825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [2:58:51<4:45:44, 139.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16439.476236979168
INFO:root:current train perplexity5.03367280960083
INFO:root:current mean train loss 16422.877427184467
INFO:root:current train perplexity5.055566310882568
INFO:root:current mean train loss 16454.736395474138
INFO:root:current train perplexity5.063945293426514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it]
INFO:root:final mean train loss: 16449.607965284777
INFO:root:final train perplexity: 5.065544605255127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 22944.43968563988
INFO:root:eval perplexity: 10.747259140014648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:01:11<4:43:22, 139.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16536.4474609375
INFO:root:current train perplexity5.05784273147583
INFO:root:current mean train loss 16452.348973034274
INFO:root:current train perplexity5.0562262535095215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 16430.17664361769
INFO:root:final train perplexity: 5.055845260620117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it]
INFO:root:eval mean loss: 22943.134765625
INFO:root:eval perplexity: 10.745805740356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:03:30<4:40:58, 139.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16573.44921875
INFO:root:current train perplexity5.076376438140869
INFO:root:current mean train loss 16450.273565274532
INFO:root:current train perplexity5.046494960784912
INFO:root:current mean train loss 16411.790600467993
INFO:root:current train perplexity5.042241096496582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.29s/it]
INFO:root:final mean train loss: 16409.010915448587
INFO:root:final train perplexity: 5.04530143737793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.81s/it]
INFO:root:eval mean loss: 22944.000418526786
INFO:root:eval perplexity: 10.746768951416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:05:49<4:38:41, 139.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16380.90578654661
INFO:root:current train perplexity5.039949893951416
INFO:root:current mean train loss 16406.652509581367
INFO:root:current train perplexity5.036974906921387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it]
INFO:root:final mean train loss: 16390.151977539062
INFO:root:final train perplexity: 5.035924911499023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 22943.56373232887
INFO:root:eval perplexity: 10.746282577514648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:08:09<4:36:18, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16253.965465198864
INFO:root:current train perplexity4.9792866706848145
INFO:root:current mean train loss 16341.542388091217
INFO:root:current train perplexity5.008860111236572
INFO:root:current mean train loss 16368.63026232968
INFO:root:current train perplexity5.020787239074707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.59s/it]
INFO:root:final mean train loss: 16368.156950919858
INFO:root:final train perplexity: 5.025012493133545
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 22949.199637276786
INFO:root:eval perplexity: 10.752551078796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:10:28<4:34:12, 139.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16318.113498263889
INFO:root:current train perplexity4.993972301483154
INFO:root:current mean train loss 16369.708229486196
INFO:root:current train perplexity5.0179123878479


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 16348.723242975051
INFO:root:final train perplexity: 5.015389919281006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 22945.338402157737
INFO:root:eval perplexity: 10.748255729675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:12:47<4:31:41, 139.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16314.720377604166
INFO:root:current train perplexity5.0015130043029785
INFO:root:current mean train loss 16311.40406759511
INFO:root:current train perplexity4.994339942932129
INFO:root:current mean train loss 16344.132290152616
INFO:root:current train perplexity5.010372638702393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 16329.790421024445
INFO:root:final train perplexity: 5.006032943725586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it]
INFO:root:eval mean loss: 22941.16673642113
INFO:root:eval perplexity: 10.743616104125977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:15:07<4:29:19, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16318.313301655784
INFO:root:current train perplexity4.9840922355651855
INFO:root:current mean train loss 16300.189277694612
INFO:root:current train perplexity4.985278129577637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 16311.454137002269
INFO:root:final train perplexity: 4.9969868659973145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 22960.94080171131
INFO:root:eval perplexity: 10.765625953674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [3:17:26<4:26:50, 139.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16283.876490542763
INFO:root:current train perplexity4.964085578918457
INFO:root:current mean train loss 16290.681460084033
INFO:root:current train perplexity4.982892036437988
INFO:root:current mean train loss 16295.824713720034
INFO:root:current train perplexity4.98662805557251


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it]
INFO:root:final mean train loss: 16290.09035172001
INFO:root:final train perplexity: 4.986469268798828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 22952.375395275296
INFO:root:eval perplexity: 10.756087303161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [3:19:45<4:24:34, 139.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16206.749092209508
INFO:root:current train perplexity4.973340034484863
INFO:root:current mean train loss 16255.2018686038
INFO:root:current train perplexity4.975221157073975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it]
INFO:root:final mean train loss: 16276.833708732358
INFO:root:final train perplexity: 4.979953765869141
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 22956.514787946428
INFO:root:eval perplexity: 10.760696411132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [3:22:04<4:22:25, 139.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16303.140752377718
INFO:root:current train perplexity4.973062515258789
INFO:root:current mean train loss 16277.79359597307
INFO:root:current train perplexity4.9752678871154785
INFO:root:current mean train loss 16268.20642254064
INFO:root:current train perplexity4.970983982086182


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.77s/it]
INFO:root:final mean train loss: 16259.692646641884
INFO:root:final train perplexity: 4.971540927886963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 22963.001999627977
INFO:root:eval perplexity: 10.767923355102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [3:24:23<4:19:46, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16202.694622395833
INFO:root:current train perplexity4.939460277557373
INFO:root:current mean train loss 16241.294095982143
INFO:root:current train perplexity4.951367378234863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.69s/it]
INFO:root:final mean train loss: 16240.374988186744
INFO:root:final train perplexity: 4.962076187133789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 22950.859468005954
INFO:root:eval perplexity: 10.754400253295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [3:26:43<4:17:46, 139.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16225.275028935184
INFO:root:current train perplexity4.9003987312316895
INFO:root:current mean train loss 16201.649237204725
INFO:root:current train perplexity4.942409515380859
INFO:root:current mean train loss 16228.579966272026
INFO:root:current train perplexity4.949005126953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it]
INFO:root:final mean train loss: 16220.741907919606
INFO:root:final train perplexity: 4.95247745513916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it]
INFO:root:eval mean loss: 22961.874604724704
INFO:root:eval perplexity: 10.7666654586792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [3:29:02<4:15:25, 139.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16269.846160502373
INFO:root:current train perplexity4.957738876342773
INFO:root:current mean train loss 16239.295527452863
INFO:root:current train perplexity4.952178955078125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it]
INFO:root:final mean train loss: 16209.769535187752
INFO:root:final train perplexity: 4.9471211433410645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 22941.37060546875
INFO:root:eval perplexity: 10.743844032287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [3:31:21<4:12:50, 139.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16217.479177167339
INFO:root:current train perplexity4.935665130615234
INFO:root:current mean train loss 16214.84858062977
INFO:root:current train perplexity4.946033477783203
INFO:root:current mean train loss 16208.486822747565
INFO:root:current train perplexity4.940404415130615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it]
INFO:root:final mean train loss: 16192.233902469758
INFO:root:final train perplexity: 4.938571929931641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 22955.964029947918
INFO:root:eval perplexity: 10.760083198547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [3:33:40<4:10:20, 139.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16123.519695971385
INFO:root:current train perplexity4.920506477355957
INFO:root:current mean train loss 16181.976695910178
INFO:root:current train perplexity4.929882049560547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it]
INFO:root:final mean train loss: 16172.30044654108
INFO:root:final train perplexity: 4.9288716316223145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 22945.963239397322
INFO:root:eval perplexity: 10.748952865600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [3:35:59<4:08:01, 139.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16154.212862723214
INFO:root:current train perplexity4.907169342041016
INFO:root:current mean train loss 16164.637000868055
INFO:root:current train perplexity4.9255547523498535
INFO:root:current mean train loss 16164.471953956117
INFO:root:current train perplexity4.920528888702393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.12s/it]
INFO:root:final mean train loss: 16159.167787613407
INFO:root:final train perplexity: 4.922491073608398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 22972.36755952381
INFO:root:eval perplexity: 10.778367042541504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [3:38:18<4:05:36, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16130.356759608478
INFO:root:current train perplexity4.896819591522217
INFO:root:current mean train loss 16153.544128091578
INFO:root:current train perplexity4.9056925773620605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it]
INFO:root:final mean train loss: 16143.944721837197
INFO:root:final train perplexity: 4.915106296539307
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 22963.06222098214
INFO:root:eval perplexity: 10.767992973327637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [3:40:37<4:03:12, 138.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16186.718775040064
INFO:root:current train perplexity4.888343334197998
INFO:root:current mean train loss 16151.306514163669
INFO:root:current train perplexity4.91101598739624
INFO:root:current mean train loss 16142.149499869247
INFO:root:current train perplexity4.908195972442627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it]
INFO:root:final mean train loss: 16132.049911006805
INFO:root:final train perplexity: 4.9093427658081055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.89s/it]
INFO:root:eval mean loss: 22965.84451729911
INFO:root:eval perplexity: 10.77109146118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [3:42:56<4:01:09, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16079.703575721154
INFO:root:current train perplexity4.882980823516846
INFO:root:current mean train loss 16104.187218790903
INFO:root:current train perplexity4.8910393714904785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it]
INFO:root:final mean train loss: 16117.716674804688
INFO:root:final train perplexity: 4.902407646179199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 22954.578543526786
INFO:root:eval perplexity: 10.758541107177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [3:45:15<3:58:41, 139.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16042.82655795785
INFO:root:current train perplexity4.847442626953125
INFO:root:current mean train loss 16073.30829326923
INFO:root:current train perplexity4.8799214363098145
INFO:root:current mean train loss 16103.126820505402
INFO:root:current train perplexity4.889312267303467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it]
INFO:root:final mean train loss: 16094.444178427419
INFO:root:final train perplexity: 4.891167163848877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.93s/it]
INFO:root:eval mean loss: 22963.33275204613
INFO:root:eval perplexity: 10.768293380737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [3:47:34<3:56:29, 139.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16099.93767475329
INFO:root:current train perplexity4.887573719024658
INFO:root:current mean train loss 16082.361047676282
INFO:root:current train perplexity4.881101608276367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it]
INFO:root:final mean train loss: 16083.763923891129
INFO:root:final train perplexity: 4.886017799377441
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 22968.746535528273
INFO:root:eval perplexity: 10.774328231811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [3:49:53<3:54:07, 139.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16022.638277094415
INFO:root:current train perplexity4.848026752471924
INFO:root:current mean train loss 16051.852957589286
INFO:root:current train perplexity4.866083145141602
INFO:root:current mean train loss 16078.051536405617
INFO:root:current train perplexity4.877574443817139


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it]
INFO:root:final mean train loss: 16066.96060279108
INFO:root:final train perplexity: 4.877927303314209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 22967.889206659227
INFO:root:eval perplexity: 10.773372650146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [3:52:13<3:51:55, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16026.860469933712
INFO:root:current train perplexity4.851388931274414
INFO:root:current mean train loss 16053.26654267431
INFO:root:current train perplexity4.868358612060547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.77s/it]
INFO:root:final mean train loss: 16049.932286416331
INFO:root:final train perplexity: 4.869740962982178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 22966.76732235863
INFO:root:eval perplexity: 10.772119522094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [3:54:32<3:49:27, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16081.508157169117
INFO:root:current train perplexity4.887949466705322
INFO:root:current mean train loss 16069.742155163492
INFO:root:current train perplexity4.862947463989258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 16037.45847640499
INFO:root:final train perplexity: 4.863752841949463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 22974.012137276786
INFO:root:eval perplexity: 10.78020191192627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [3:56:51<3:47:07, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15954.387369791666
INFO:root:current train perplexity4.817342281341553
INFO:root:current mean train loss 16024.682162090412
INFO:root:current train perplexity4.84622049331665
INFO:root:current mean train loss 16039.275130849754
INFO:root:current train perplexity4.857306957244873


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it]
INFO:root:final mean train loss: 16024.528304561492
INFO:root:final train perplexity: 4.857553958892822
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 22970.308640252977
INFO:root:eval perplexity: 10.776069641113281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [3:59:10<3:44:47, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15956.62215909091
INFO:root:current train perplexity4.843181133270264
INFO:root:current mean train loss 16002.45120967742
INFO:root:current train perplexity4.846907615661621


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it]
INFO:root:final mean train loss: 16009.176572738155
INFO:root:final train perplexity: 4.8502044677734375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 22988.208565848214
INFO:root:eval perplexity: 10.796051025390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [4:01:29<3:42:43, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16190.353934151786
INFO:root:current train perplexity4.8692708015441895
INFO:root:current mean train loss 16003.594169830607
INFO:root:current train perplexity4.8389058113098145
INFO:root:current mean train loss 16032.541411911232
INFO:root:current train perplexity4.848385334014893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it]
INFO:root:final mean train loss: 15999.849833826866
INFO:root:final train perplexity: 4.845744609832764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 22978.851655505954
INFO:root:eval perplexity: 10.785603523254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [4:03:48<3:40:14, 139.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16000.943855932202
INFO:root:current train perplexity4.8357672691345215
INFO:root:current mean train loss 16011.367568297956
INFO:root:current train perplexity4.836372375488281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 15982.810090095767
INFO:root:final train perplexity: 4.837606906890869
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 22984.222958519345
INFO:root:eval perplexity: 10.79159927368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [4:06:07<3:37:57, 139.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15829.32421875
INFO:root:current train perplexity4.802847385406494
INFO:root:current mean train loss 15921.648067989865
INFO:root:current train perplexity4.8177361488342285
INFO:root:current mean train loss 15978.423902177132
INFO:root:current train perplexity4.833546161651611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it]
INFO:root:final mean train loss: 15973.861906974545
INFO:root:final train perplexity: 4.833339214324951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.72s/it]
INFO:root:eval mean loss: 22990.233537946428
INFO:root:eval perplexity: 10.798314094543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [4:08:26<3:35:35, 139.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15941.047123015873
INFO:root:current train perplexity4.802047252655029
INFO:root:current mean train loss 15936.33124041411
INFO:root:current train perplexity4.812605381011963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.86s/it]
INFO:root:final mean train loss: 15956.584811302924
INFO:root:final train perplexity: 4.825109481811523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 22994.37667410714
INFO:root:eval perplexity: 10.80294418334961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [4:10:45<3:33:11, 139.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15872.9515625
INFO:root:current train perplexity4.8240065574646
INFO:root:current mean train loss 15984.706309442934
INFO:root:current train perplexity4.818626880645752
INFO:root:current mean train loss 15964.426126453489
INFO:root:current train perplexity4.816027641296387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it]
INFO:root:final mean train loss: 15942.388644310737
INFO:root:final train perplexity: 4.818358898162842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 22993.062686011905
INFO:root:eval perplexity: 10.801475524902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [4:13:04<3:30:56, 139.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15947.074175023321
INFO:root:current train perplexity4.815181255340576
INFO:root:current mean train loss 15936.661969030689
INFO:root:current train perplexity4.812503814697266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it]
INFO:root:final mean train loss: 15930.778647145917
INFO:root:final train perplexity: 4.812845230102539
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it]
INFO:root:eval mean loss: 22998.619001116072
INFO:root:eval perplexity: 10.80769157409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [4:15:24<3:28:42, 139.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15858.701531661185
INFO:root:current train perplexity4.79572868347168
INFO:root:current mean train loss 15957.089589351366
INFO:root:current train perplexity4.819342136383057
INFO:root:current mean train loss 15935.79438231307
INFO:root:current train perplexity4.808387756347656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.03s/it]
INFO:root:final mean train loss: 15921.55746361517
INFO:root:final train perplexity: 4.808468818664551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 22982.91589936756
INFO:root:eval perplexity: 10.790143013000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [4:17:42<3:26:15, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16000.521168023768
INFO:root:current train perplexity4.8163323402404785
INFO:root:current mean train loss 15944.882070084064
INFO:root:current train perplexity4.8076558113098145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it]
INFO:root:final mean train loss: 15910.830794795867
INFO:root:final train perplexity: 4.803385257720947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 22995.74841889881
INFO:root:eval perplexity: 10.804478645324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [4:20:02<3:24:02, 139.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15956.18550441576
INFO:root:current train perplexity4.8268585205078125
INFO:root:current mean train loss 15915.977396150915
INFO:root:current train perplexity4.799153804779053
INFO:root:current mean train loss 15905.829622687781
INFO:root:current train perplexity4.7929368019104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it]
INFO:root:final mean train loss: 15893.719088646674
INFO:root:final train perplexity: 4.795284271240234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it]
INFO:root:eval mean loss: 22992.976632254464
INFO:root:eval perplexity: 10.801383018493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [4:22:21<3:21:37, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15861.432135416666
INFO:root:current train perplexity4.767102241516113
INFO:root:current mean train loss 15882.236651785714
INFO:root:current train perplexity4.7821526527404785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.82s/it]
INFO:root:final mean train loss: 15884.448852539062
INFO:root:final train perplexity: 4.790901184082031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 22997.827473958332
INFO:root:eval perplexity: 10.806802749633789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [4:24:39<3:19:08, 138.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15892.018880208334
INFO:root:current train perplexity4.782549858093262
INFO:root:current mean train loss 15850.429472194883
INFO:root:current train perplexity4.7718377113342285
INFO:root:current mean train loss 15884.898166471641
INFO:root:current train perplexity4.784681797027588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it]
INFO:root:final mean train loss: 15873.207377772178
INFO:root:final train perplexity: 4.785592555999756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 22994.501511346727
INFO:root:eval perplexity: 10.803085327148438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [4:26:59<3:16:56, 139.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15857.369635087025
INFO:root:current train perplexity4.775635242462158
INFO:root:current mean train loss 15861.775750698323
INFO:root:current train perplexity4.777508735656738


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it]
INFO:root:final mean train loss: 15860.48285108997
INFO:root:final train perplexity: 4.779590606689453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 22991.586007254464
INFO:root:eval perplexity: 10.799827575683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [4:29:18<3:14:39, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15836.062027469758
INFO:root:current train perplexity4.772097110748291
INFO:root:current mean train loss 15847.271782562022
INFO:root:current train perplexity4.764841079711914
INFO:root:current mean train loss 15850.51796283144
INFO:root:current train perplexity4.769456386566162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it]
INFO:root:final mean train loss: 15845.49103373866
INFO:root:final train perplexity: 4.772527694702148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it]
INFO:root:eval mean loss: 22992.13692801339
INFO:root:eval perplexity: 10.800440788269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [4:31:36<3:12:14, 138.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15816.130341679216
INFO:root:current train perplexity4.783645153045654
INFO:root:current mean train loss 15824.651858136953
INFO:root:current train perplexity4.769259452819824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.17s/it]
INFO:root:final mean train loss: 15833.58972561744
INFO:root:final train perplexity: 4.766929626464844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 23005.36014229911
INFO:root:eval perplexity: 10.815234184265137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [4:33:56<3:10:00, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15812.212276785714
INFO:root:current train perplexity4.752409934997559
INFO:root:current mean train loss 15839.852488425926
INFO:root:current train perplexity4.76439905166626
INFO:root:current mean train loss 15841.605381482712
INFO:root:current train perplexity4.766109466552734


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.54s/it]
INFO:root:final mean train loss: 15826.63505701865
INFO:root:final train perplexity: 4.763660430908203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it]
INFO:root:eval mean loss: 23011.082077752977
INFO:root:eval perplexity: 10.821638107299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [4:36:15<3:07:57, 139.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15775.990268049569
INFO:root:current train perplexity4.749104976654053
INFO:root:current mean train loss 15812.584287266043
INFO:root:current train perplexity4.753794193267822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.78s/it]
INFO:root:final mean train loss: 15819.194446194557
INFO:root:final train perplexity: 4.760165214538574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 23012.04764229911
INFO:root:eval perplexity: 10.822722434997559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [4:38:34<3:05:27, 139.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15796.102614182691
INFO:root:current train perplexity4.759038925170898
INFO:root:current mean train loss 15833.823860442895
INFO:root:current train perplexity4.755195140838623
INFO:root:current mean train loss 15814.988375228819
INFO:root:current train perplexity4.752877235412598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.94s/it]
INFO:root:final mean train loss: 15805.327042118195
INFO:root:final train perplexity: 4.753659248352051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23009.287551153273
INFO:root:eval perplexity: 10.819631576538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [4:40:53<3:03:05, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15757.18755365728
INFO:root:current train perplexity4.722133636474609
INFO:root:current mean train loss 15804.207174410994
INFO:root:current train perplexity4.74806547164917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.32s/it]
INFO:root:final mean train loss: 15799.147390057964
INFO:root:final train perplexity: 4.750762462615967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.63s/it]
INFO:root:eval mean loss: 23001.35714285714
INFO:root:eval perplexity: 10.81075382232666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [4:43:12<3:00:50, 139.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15798.230355196221
INFO:root:current train perplexity4.733304500579834
INFO:root:current mean train loss 15765.610413024475
INFO:root:current train perplexity4.732481956481934
INFO:root:current mean train loss 15790.714490097736
INFO:root:current train perplexity4.742965221405029


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.03s/it]
INFO:root:final mean train loss: 15783.679214969758
INFO:root:final train perplexity: 4.743520259857178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23009.782249813987
INFO:root:eval perplexity: 10.820185661315918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [4:45:31<2:58:25, 139.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15803.532113486843
INFO:root:current train perplexity4.74775505065918
INFO:root:current mean train loss 15779.711182892628
INFO:root:current train perplexity4.738040447235107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.82s/it]
INFO:root:final mean train loss: 15776.544350900958
INFO:root:final train perplexity: 4.740183353424072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23002.295828683036
INFO:root:eval perplexity: 10.811802864074707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [4:47:50<2:55:58, 138.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15718.798329454787
INFO:root:current train perplexity4.707208633422852
INFO:root:current mean train loss 15734.63433381165
INFO:root:current train perplexity4.719812870025635
INFO:root:current mean train loss 15772.342872279858
INFO:root:current train perplexity4.7326507568359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 15761.000259891633
INFO:root:final train perplexity: 4.732921600341797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 23011.76632254464
INFO:root:eval perplexity: 10.822407722473145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [4:50:09<2:53:42, 138.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15757.276613794193
INFO:root:current train perplexity4.728392124176025
INFO:root:current mean train loss 15761.996559948178
INFO:root:current train perplexity4.726852893829346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.04s/it]
INFO:root:final mean train loss: 15755.516365297379
INFO:root:final train perplexity: 4.730362415313721
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 23009.91868954613
INFO:root:eval perplexity: 10.820338249206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [4:52:28<2:51:22, 138.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15716.116134344362
INFO:root:current train perplexity4.713079929351807
INFO:root:current mean train loss 15725.936529904802
INFO:root:current train perplexity4.717731952667236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.76s/it]
INFO:root:final mean train loss: 15743.431573683216
INFO:root:final train perplexity: 4.724727153778076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.70s/it]
INFO:root:eval mean loss: 23023.358747209822
INFO:root:eval perplexity: 10.83539867401123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [4:54:46<2:48:57, 138.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16114.859700520834
INFO:root:current train perplexity4.805356025695801
INFO:root:current mean train loss 15771.523475424758
INFO:root:current train perplexity4.729022026062012
INFO:root:current mean train loss 15751.840281519397
INFO:root:current train perplexity4.725921630859375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.88s/it]
INFO:root:final mean train loss: 15739.169870684223
INFO:root:final train perplexity: 4.722741603851318
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 23022.639508928572
INFO:root:eval perplexity: 10.834590911865234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [4:57:05<2:46:35, 138.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15821.514825994318
INFO:root:current train perplexity4.735658168792725
INFO:root:current mean train loss 15757.92146547379
INFO:root:current train perplexity4.722972393035889


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it]
INFO:root:final mean train loss: 15729.836323399697
INFO:root:final train perplexity: 4.718395709991455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23020.936337425595
INFO:root:eval perplexity: 10.83267879486084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [4:59:24<2:44:24, 138.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15511.019810267857
INFO:root:current train perplexity4.663433074951172
INFO:root:current mean train loss 15643.848523291472
INFO:root:current train perplexity4.687737941741943
INFO:root:current mean train loss 15718.654117602657
INFO:root:current train perplexity4.708983421325684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.59s/it]
INFO:root:final mean train loss: 15714.878638482864
INFO:root:final train perplexity: 4.71143913269043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 23030.959821428572
INFO:root:eval perplexity: 10.843924522399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [5:01:44<2:42:21, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15711.151797537077
INFO:root:current train perplexity4.701534271240234
INFO:root:current mean train loss 15729.68830458923
INFO:root:current train perplexity4.707435131072998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.18s/it]
INFO:root:final mean train loss: 15706.959547473538
INFO:root:final train perplexity: 4.707761764526367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it]
INFO:root:eval mean loss: 23024.287527901786
INFO:root:eval perplexity: 10.836440086364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [5:04:03<2:40:05, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15757.716175426136
INFO:root:current train perplexity4.702149391174316
INFO:root:current mean train loss 15690.456116272522
INFO:root:current train perplexity4.687191009521484
INFO:root:current mean train loss 15693.038104450534
INFO:root:current train perplexity4.701818943023682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it]
INFO:root:final mean train loss: 15697.118569650958
INFO:root:final train perplexity: 4.7031941413879395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 23034.727120535714
INFO:root:eval perplexity: 10.84815502166748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [5:06:23<2:37:46, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15694.592897445436
INFO:root:current train perplexity4.699771881103516
INFO:root:current mean train loss 15702.981409365415
INFO:root:current train perplexity4.696816921234131


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.03s/it]
INFO:root:final mean train loss: 15690.93566500756
INFO:root:final train perplexity: 4.700326919555664
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.58s/it]
INFO:root:eval mean loss: 23036.636858258928
INFO:root:eval perplexity: 10.850299835205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [5:08:42<2:35:20, 139.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15640.824739583333
INFO:root:current train perplexity4.662879943847656
INFO:root:current mean train loss 15653.39281589674
INFO:root:current train perplexity4.689266681671143
INFO:root:current mean train loss 15694.711777797966
INFO:root:current train perplexity4.6938323974609375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.10s/it]
INFO:root:final mean train loss: 15681.807660502773
INFO:root:final train perplexity: 4.696096897125244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23028.98702566964
INFO:root:eval perplexity: 10.84171199798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [5:11:00<2:32:58, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15694.410987056903
INFO:root:current train perplexity4.686248779296875
INFO:root:current mean train loss 15710.969907840568
INFO:root:current train perplexity4.691669464111328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it]
INFO:root:final mean train loss: 15674.028158864667
INFO:root:final train perplexity: 4.692494869232178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it]
INFO:root:eval mean loss: 23038.40748232887
INFO:root:eval perplexity: 10.852286338806152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [5:13:19<2:30:30, 138.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15710.546001233553
INFO:root:current train perplexity4.718531608581543
INFO:root:current mean train loss 15698.517537092963
INFO:root:current train perplexity4.693949222564697
INFO:root:current mean train loss 15680.803715396689
INFO:root:current train perplexity4.6889166831970215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 15665.635060956402
INFO:root:final train perplexity: 4.68861198425293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 23036.050595238095
INFO:root:eval perplexity: 10.849639892578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [5:15:38<2:28:18, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15659.318428147008
INFO:root:current train perplexity4.687872409820557
INFO:root:current mean train loss 15662.001096491229
INFO:root:current train perplexity4.675596237182617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 15657.415854177167
INFO:root:final train perplexity: 4.684812068939209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23041.90892392113
INFO:root:eval perplexity: 10.856220245361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [5:17:58<2:26:05, 139.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15688.296238111414
INFO:root:current train perplexity4.685908794403076
INFO:root:current mean train loss 15690.60972433943
INFO:root:current train perplexity4.68251895904541
INFO:root:current mean train loss 15655.23894250981
INFO:root:current train perplexity4.678246021270752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it]
INFO:root:final mean train loss: 15647.180538054436
INFO:root:final train perplexity: 4.680084705352783
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 23044.987816220237
INFO:root:eval perplexity: 10.859681129455566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [5:20:17<2:23:42, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15669.022252604167
INFO:root:current train perplexity4.67425012588501
INFO:root:current mean train loss 15638.667449776785
INFO:root:current train perplexity4.673374652862549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.92s/it]
INFO:root:final mean train loss: 15642.838942004788
INFO:root:final train perplexity: 4.678081512451172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.73s/it]
INFO:root:eval mean loss: 23033.130533854168
INFO:root:eval perplexity: 10.846363067626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [5:22:36<2:21:19, 139.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15683.715205439816
INFO:root:current train perplexity4.671426773071289
INFO:root:current mean train loss 15651.50956569882
INFO:root:current train perplexity4.677187442779541
INFO:root:current mean train loss 15658.27769651707
INFO:root:current train perplexity4.675746917724609


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.98s/it]
INFO:root:final mean train loss: 15634.555994833669
INFO:root:final train perplexity: 4.674261093139648
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23046.284226190477
INFO:root:eval perplexity: 10.861139297485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [5:24:54<2:18:57, 138.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15659.06620846519
INFO:root:current train perplexity4.680451393127441
INFO:root:current mean train loss 15646.964314551327
INFO:root:current train perplexity4.6743083000183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.97s/it]
INFO:root:final mean train loss: 15623.894039030998
INFO:root:final train perplexity: 4.66934871673584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.76s/it]
INFO:root:eval mean loss: 23047.096702938987
INFO:root:eval perplexity: 10.862051010131836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [5:27:13<2:16:39, 138.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15560.212292086693
INFO:root:current train perplexity4.639293670654297
INFO:root:current mean train loss 15635.215037571565
INFO:root:current train perplexity4.659738063812256
INFO:root:current mean train loss 15634.520972842261
INFO:root:current train perplexity4.664327144622803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it]
INFO:root:final mean train loss: 15614.373759608116
INFO:root:final train perplexity: 4.664966583251953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.51s/it]
INFO:root:eval mean loss: 23040.340727306546
INFO:root:eval perplexity: 10.854460716247559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [5:29:32<2:14:16, 138.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15621.37156438253
INFO:root:current train perplexity4.657512187957764
INFO:root:current mean train loss 15605.22928940403
INFO:root:current train perplexity4.655975818634033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 15610.84363186744
INFO:root:final train perplexity: 4.663342475891113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.57s/it]
INFO:root:eval mean loss: 23042.942940848214
INFO:root:eval perplexity: 10.857382774353027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [5:31:51<2:12:00, 138.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15664.639006696429
INFO:root:current train perplexity4.648542881011963
INFO:root:current mean train loss 15621.95101273148
INFO:root:current train perplexity4.6573052406311035
INFO:root:current mean train loss 15610.713750831117
INFO:root:current train perplexity4.65843391418457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.20s/it]
INFO:root:final mean train loss: 15600.791767735634
INFO:root:final train perplexity: 4.658721446990967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 23046.35681733631
INFO:root:eval perplexity: 10.86121940612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [5:34:10<2:09:44, 139.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15623.374764278018
INFO:root:current train perplexity4.651029586791992
INFO:root:current mean train loss 15603.687233664772
INFO:root:current train perplexity4.651340007781982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 15596.334342710434
INFO:root:final train perplexity: 4.656672954559326
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.82s/it]
INFO:root:eval mean loss: 23050.39334542411
INFO:root:eval perplexity: 10.86575698852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [5:36:30<2:07:32, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15526.599584334936
INFO:root:current train perplexity4.640402793884277
INFO:root:current mean train loss 15576.669725157373
INFO:root:current train perplexity4.651649475097656
INFO:root:current mean train loss 15603.958465448482
INFO:root:current train perplexity4.65276575088501


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.30s/it]
INFO:root:final mean train loss: 15589.280222246723
INFO:root:final train perplexity: 4.653434753417969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 23056.103701636905
INFO:root:eval perplexity: 10.872180938720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [5:38:49<2:05:14, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15594.318134014424
INFO:root:current train perplexity4.657038688659668
INFO:root:current mean train loss 15594.00319555792
INFO:root:current train perplexity4.652951240539551


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.76s/it]
INFO:root:final mean train loss: 15581.43216828377
INFO:root:final train perplexity: 4.6498332023620605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.46s/it]
INFO:root:eval mean loss: 23056.873953683036
INFO:root:eval perplexity: 10.873046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [5:41:07<2:02:44, 138.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15565.476335392443
INFO:root:current train perplexity4.638927459716797
INFO:root:current mean train loss 15592.067444274475
INFO:root:current train perplexity4.647243976593018
INFO:root:current mean train loss 15590.119819798098
INFO:root:current train perplexity4.646790027618408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.05s/it]
INFO:root:final mean train loss: 15576.232614824848
INFO:root:final train perplexity: 4.647449493408203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 23060.151785714286
INFO:root:eval perplexity: 10.876736640930176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [5:43:27<2:00:27, 139.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15493.471607730264
INFO:root:current train perplexity4.629962921142578
INFO:root:current mean train loss 15563.929607371794
INFO:root:current train perplexity4.6412882804870605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.19s/it]
INFO:root:final mean train loss: 15568.076636529739
INFO:root:final train perplexity: 4.643712520599365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it]
INFO:root:eval mean loss: 23066.99483816964
INFO:root:eval perplexity: 10.884446144104004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [5:45:45<1:58:08, 138.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15582.765230219415
INFO:root:current train perplexity4.632772922515869
INFO:root:current mean train loss 15587.88238068665
INFO:root:current train perplexity4.637491703033447
INFO:root:current mean train loss 15572.278257053391
INFO:root:current train perplexity4.640914440155029


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 15563.748795047883
INFO:root:final train perplexity: 4.641730785369873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23069.54566592262
INFO:root:eval perplexity: 10.887316703796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [5:48:05<1:55:51, 139.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15565.524700126263
INFO:root:current train perplexity4.627219200134277
INFO:root:current mean train loss 15556.322059516331
INFO:root:current train perplexity4.635822296142578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it]
INFO:root:final mean train loss: 15552.993853169102
INFO:root:final train perplexity: 4.636809349060059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 23066.530226934523
INFO:root:eval perplexity: 10.88392162322998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [5:50:24<1:53:37, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15520.430740655638
INFO:root:current train perplexity4.63237190246582
INFO:root:current mean train loss 15543.896950020695
INFO:root:current train perplexity4.633011341094971


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.41s/it]
INFO:root:final mean train loss: 15552.084267893146
INFO:root:final train perplexity: 4.636393070220947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23068.28441220238
INFO:root:eval perplexity: 10.885896682739258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [5:52:42<1:51:09, 138.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15641.900065104166
INFO:root:current train perplexity4.632138252258301
INFO:root:current mean train loss 15540.068207675971
INFO:root:current train perplexity4.625751495361328
INFO:root:current mean train loss 15545.570961938116
INFO:root:current train perplexity4.627466201782227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.91s/it]
INFO:root:final mean train loss: 15541.622491651966
INFO:root:final train perplexity: 4.631610870361328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.87s/it]
INFO:root:eval mean loss: 23071.32882254464
INFO:root:eval perplexity: 10.889328956604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [5:55:02<1:48:51, 138.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15524.41239346591
INFO:root:current train perplexity4.630624771118164
INFO:root:current mean train loss 15534.35541204637
INFO:root:current train perplexity4.6328582763671875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.12s/it]
INFO:root:final mean train loss: 15536.752220892136
INFO:root:final train perplexity: 4.629387378692627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23068.047549293155
INFO:root:eval perplexity: 10.885629653930664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [5:57:20<1:46:31, 138.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15725.43568638393
INFO:root:current train perplexity4.670654773712158
INFO:root:current mean train loss 15568.44344151577
INFO:root:current train perplexity4.633358955383301
INFO:root:current mean train loss 15550.573053479771
INFO:root:current train perplexity4.627440929412842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it]
INFO:root:final mean train loss: 15529.066666141633
INFO:root:final train perplexity: 4.625880241394043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.49s/it]
INFO:root:eval mean loss: 23072.05933779762
INFO:root:eval perplexity: 10.890149116516113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [5:59:39<1:44:09, 138.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15462.669210143009
INFO:root:current train perplexity4.623349666595459
INFO:root:current mean train loss 15545.478632321148
INFO:root:current train perplexity4.629385948181152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it]
INFO:root:final mean train loss: 15524.135167275706
INFO:root:final train perplexity: 4.623630046844482
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23073.072265625
INFO:root:eval perplexity: 10.891291618347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [6:01:58<1:41:53, 138.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15498.453302556818
INFO:root:current train perplexity4.571038722991943
INFO:root:current mean train loss 15510.00902660473
INFO:root:current train perplexity4.602819919586182
INFO:root:current mean train loss 15528.138093342714
INFO:root:current train perplexity4.6193366050720215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.35s/it]
INFO:root:final mean train loss: 15523.070576329384
INFO:root:final train perplexity: 4.623144626617432
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.60s/it]
INFO:root:eval mean loss: 23074.40711030506
INFO:root:eval perplexity: 10.892797470092773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [6:04:17<1:39:37, 139.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15580.498248387898
INFO:root:current train perplexity4.6262431144714355
INFO:root:current mean train loss 15549.107553680982
INFO:root:current train perplexity4.623981475830078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.26s/it]
INFO:root:final mean train loss: 15512.113927041331
INFO:root:final train perplexity: 4.6181511878967285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]
INFO:root:eval mean loss: 23075.81077938988
INFO:root:eval perplexity: 10.894379615783691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [6:06:37<1:37:20, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15447.297721354167
INFO:root:current train perplexity4.658473491668701
INFO:root:current mean train loss 15519.143384850544
INFO:root:current train perplexity4.622430801391602
INFO:root:current mean train loss 15532.385551417152
INFO:root:current train perplexity4.618511199951172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.93s/it]
INFO:root:final mean train loss: 15509.395334551411
INFO:root:final train perplexity: 4.616912841796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 23080.256161644345
INFO:root:eval perplexity: 10.899395942687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [6:08:55<1:34:58, 138.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15499.354725396455
INFO:root:current train perplexity4.607782363891602
INFO:root:current mean train loss 15527.182728293414
INFO:root:current train perplexity4.6150946617126465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.99s/it]
INFO:root:final mean train loss: 15506.791204637097
INFO:root:final train perplexity: 4.615726947784424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.47s/it]
INFO:root:eval mean loss: 23078.063825334822
INFO:root:eval perplexity: 10.896923065185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [6:11:14<1:32:36, 138.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15501.769325657895
INFO:root:current train perplexity4.590714454650879
INFO:root:current mean train loss 15512.35637966124
INFO:root:current train perplexity4.607852935791016
INFO:root:current mean train loss 15504.094699807363
INFO:root:current train perplexity4.609650611877441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it]
INFO:root:final mean train loss: 15494.338063886089
INFO:root:final train perplexity: 4.610061168670654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 23080.7451171875
INFO:root:eval perplexity: 10.899944305419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [6:13:33<1:30:19, 138.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15442.256890955106
INFO:root:current train perplexity4.569182395935059
INFO:root:current mean train loss 15486.36116822003
INFO:root:current train perplexity4.598287105560303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.42s/it]
INFO:root:final mean train loss: 15490.565504504788
INFO:root:final train perplexity: 4.608345985412598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23082.10558500744
INFO:root:eval perplexity: 10.901480674743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [6:15:53<1:28:06, 139.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15446.315726902174
INFO:root:current train perplexity4.590662002563477
INFO:root:current mean train loss 15510.390553544208
INFO:root:current train perplexity4.604857921600342
INFO:root:current mean train loss 15507.242051744675
INFO:root:current train perplexity4.608290195465088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 15491.68884671119
INFO:root:final train perplexity: 4.608857154846191
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 23085.00109281994
INFO:root:eval perplexity: 10.904745101928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [6:18:12<1:25:44, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15482.264505208334
INFO:root:current train perplexity4.599813938140869
INFO:root:current mean train loss 15501.907137276785
INFO:root:current train perplexity4.605951309204102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.87s/it]
INFO:root:final mean train loss: 15483.3460969002
INFO:root:final train perplexity: 4.605066299438477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 23086.52001953125
INFO:root:eval perplexity: 10.906458854675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [6:20:30<1:23:21, 138.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15523.655092592593
INFO:root:current train perplexity4.5829691886901855
INFO:root:current mean train loss 15485.470349409448
INFO:root:current train perplexity4.598927974700928
INFO:root:current mean train loss 15503.947480726873
INFO:root:current train perplexity4.605765342712402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it]
INFO:root:final mean train loss: 15479.167484406502
INFO:root:final train perplexity: 4.60316801071167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.90s/it]
INFO:root:eval mean loss: 23086.361142113095
INFO:root:eval perplexity: 10.906282424926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [6:22:50<1:21:07, 139.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15437.300558742088
INFO:root:current train perplexity4.593022346496582
INFO:root:current mean train loss 15496.110449764315
INFO:root:current train perplexity4.598206996917725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.36s/it]
INFO:root:final mean train loss: 15475.01870825983
INFO:root:final train perplexity: 4.601285457611084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.77s/it]
INFO:root:eval mean loss: 23093.796456473214
INFO:root:eval perplexity: 10.914673805236816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [6:25:09<1:18:52, 139.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15494.34170236895
INFO:root:current train perplexity4.603480815887451
INFO:root:current mean train loss 15480.629547352099
INFO:root:current train perplexity4.595736026763916
INFO:root:current mean train loss 15483.540863433442
INFO:root:current train perplexity4.598703861236572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 15468.999736170616
INFO:root:final train perplexity: 4.5985541343688965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 23088.178199404763
INFO:root:eval perplexity: 10.908333778381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [6:27:28<1:16:32, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15438.690923851656
INFO:root:current train perplexity4.5964765548706055
INFO:root:current mean train loss 15484.99321742657
INFO:root:current train perplexity4.5966339111328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.32s/it]
INFO:root:final mean train loss: 15461.97250267767
INFO:root:final train perplexity: 4.595368385314941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 23094.72619047619
INFO:root:eval perplexity: 10.915727615356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [6:29:47<1:14:13, 139.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15365.30189732143
INFO:root:current train perplexity4.562042713165283
INFO:root:current mean train loss 15417.950108506944
INFO:root:current train perplexity4.589113712310791
INFO:root:current mean train loss 15466.829342586436
INFO:root:current train perplexity4.59431266784668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it]
INFO:root:final mean train loss: 15460.748480027722
INFO:root:final train perplexity: 4.594813346862793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.53s/it]
INFO:root:eval mean loss: 23098.437360491072
INFO:root:eval perplexity: 10.919920921325684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [6:32:06<1:11:52, 139.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15487.001144935344
INFO:root:current train perplexity4.607368469238281
INFO:root:current mean train loss 15479.856064087568
INFO:root:current train perplexity4.598737716674805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.53s/it]
INFO:root:final mean train loss: 15457.5591765373
INFO:root:final train perplexity: 4.593368053436279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 23091.928896949405
INFO:root:eval perplexity: 10.912569046020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [6:34:26<1:09:37, 139.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15479.926732772436
INFO:root:current train perplexity4.5750322341918945
INFO:root:current mean train loss 15478.563933228417
INFO:root:current train perplexity4.590515613555908
INFO:root:current mean train loss 15468.480816063024
INFO:root:current train perplexity4.595402717590332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.49s/it]
INFO:root:final mean train loss: 15457.097097089214
INFO:root:final train perplexity: 4.593159198760986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.67s/it]
INFO:root:eval mean loss: 23099.421409970237
INFO:root:eval perplexity: 10.921035766601562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [6:36:45<1:07:19, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15452.689270690247
INFO:root:current train perplexity4.595128059387207
INFO:root:current mean train loss 15456.503880685537
INFO:root:current train perplexity4.585036277770996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it]
INFO:root:final mean train loss: 15447.424450289818
INFO:root:final train perplexity: 4.588778972625732
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 23093.38011532738
INFO:root:eval perplexity: 10.91420841217041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [6:39:04<1:04:57, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15438.03683684593
INFO:root:current train perplexity4.584451198577881
INFO:root:current mean train loss 15460.589495465472
INFO:root:current train perplexity4.583611011505127
INFO:root:current mean train loss 15449.80275446888
INFO:root:current train perplexity4.584570407867432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.15s/it]
INFO:root:final mean train loss: 15445.131780808972
INFO:root:final train perplexity: 4.587741851806641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23096.286295572918
INFO:root:eval perplexity: 10.917490005493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [6:41:24<1:02:39, 139.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15440.119860197368
INFO:root:current train perplexity4.596283912658691
INFO:root:current mean train loss 15457.33682391827
INFO:root:current train perplexity4.590765476226807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it]
INFO:root:final mean train loss: 15446.912298387097
INFO:root:final train perplexity: 4.588547229766846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 23097.24832589286
INFO:root:eval perplexity: 10.918575286865234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [6:43:43<1:00:19, 139.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15440.520819481382
INFO:root:current train perplexity4.599429607391357
INFO:root:current mean train loss 15461.543320843963
INFO:root:current train perplexity4.589440822601318
INFO:root:current mean train loss 15449.856484849442
INFO:root:current train perplexity4.583987236022949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.29s/it]
INFO:root:final mean train loss: 15437.816898469002
INFO:root:final train perplexity: 4.584432601928711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 23100.479678199405
INFO:root:eval perplexity: 10.92222785949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [6:46:02<58:00, 139.22s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15417.489800347223
INFO:root:current train perplexity4.575941562652588
INFO:root:current mean train loss 15441.772627787373
INFO:root:current train perplexity4.58180570602417


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.31s/it]
INFO:root:final mean train loss: 15435.647724766884
INFO:root:final train perplexity: 4.583451747894287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]
INFO:root:eval mean loss: 23101.035946800595
INFO:root:eval perplexity: 10.922861099243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [6:48:21<55:41, 139.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15387.640280330883
INFO:root:current train perplexity4.585539817810059
INFO:root:current mean train loss 15427.401975113824
INFO:root:current train perplexity4.580447673797607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it]
INFO:root:final mean train loss: 15429.059857768398
INFO:root:final train perplexity: 4.580474376678467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.54s/it]
INFO:root:eval mean loss: 23099.245651971727
INFO:root:eval perplexity: 10.920835494995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [6:50:41<53:23, 139.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15498.295572916666
INFO:root:current train perplexity4.6137213706970215
INFO:root:current mean train loss 15436.019559693568
INFO:root:current train perplexity4.58139181137085
INFO:root:current mean train loss 15446.26773687654
INFO:root:current train perplexity4.581723690032959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.00s/it]
INFO:root:final mean train loss: 15428.357004473286
INFO:root:final train perplexity: 4.5801568031311035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.83s/it]
INFO:root:eval mean loss: 23100.44456845238
INFO:root:eval perplexity: 10.922188758850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [6:53:00<51:02, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15407.794744318182
INFO:root:current train perplexity4.567579746246338
INFO:root:current mean train loss 15451.946742691533
INFO:root:current train perplexity4.575818061828613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.76s/it]
INFO:root:final mean train loss: 15428.049615675403
INFO:root:final train perplexity: 4.580018997192383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 23099.06812686012
INFO:root:eval perplexity: 10.920632362365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [6:55:19<48:41, 139.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15244.09877232143
INFO:root:current train perplexity4.532446384429932
INFO:root:current mean train loss 15382.302259783879
INFO:root:current train perplexity4.563644886016846
INFO:root:current mean train loss 15423.508119150061
INFO:root:current train perplexity4.574788570404053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.21s/it]
INFO:root:final mean train loss: 15419.251031691028
INFO:root:final train perplexity: 4.576045513153076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.62s/it]
INFO:root:eval mean loss: 23101.25516183036
INFO:root:eval perplexity: 10.92310619354248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [6:57:38<46:21, 139.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15442.300764698093
INFO:root:current train perplexity4.603227615356445
INFO:root:current mean train loss 15436.783516362028
INFO:root:current train perplexity4.577983379364014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 15420.0837874874
INFO:root:final train perplexity: 4.57642126083374
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.64s/it]
INFO:root:eval mean loss: 23104.209914434523
INFO:root:eval perplexity: 10.926447868347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [6:59:57<44:03, 139.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15476.497869318182
INFO:root:current train perplexity4.5769453048706055
INFO:root:current mean train loss 15424.326048704956
INFO:root:current train perplexity4.573513984680176
INFO:root:current mean train loss 15431.104052502962
INFO:root:current train perplexity4.5738444328308105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.41s/it]
INFO:root:final mean train loss: 15416.313193044354
INFO:root:final train perplexity: 4.5747199058532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.65s/it]
INFO:root:eval mean loss: 23103.275390625
INFO:root:eval perplexity: 10.925390243530273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [7:02:16<41:45, 139.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15437.419503348214
INFO:root:current train perplexity4.572718620300293
INFO:root:current mean train loss 15438.050925038344
INFO:root:current train perplexity4.567884922027588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it]
INFO:root:final mean train loss: 15422.124763734879
INFO:root:final train perplexity: 4.577342510223389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]
INFO:root:eval mean loss: 23102.48660714286
INFO:root:eval perplexity: 10.9244966506958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [7:04:36<39:27, 139.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15363.859114583332
INFO:root:current train perplexity4.550210952758789
INFO:root:current mean train loss 15404.045516304348
INFO:root:current train perplexity4.568624973297119
INFO:root:current mean train loss 15410.241810501453
INFO:root:current train perplexity4.57178258895874


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.83s/it]
INFO:root:final mean train loss: 15414.743801978326
INFO:root:final train perplexity: 4.574012279510498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 23104.357607886905
INFO:root:eval perplexity: 10.926614761352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [7:06:56<37:11, 139.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15450.341024370337
INFO:root:current train perplexity4.57381534576416
INFO:root:current mean train loss 15423.171494900824
INFO:root:current train perplexity4.577314853668213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it]
INFO:root:final mean train loss: 15412.293079007057
INFO:root:final train perplexity: 4.572906017303467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.59s/it]
INFO:root:eval mean loss: 23104.643647693454
INFO:root:eval perplexity: 10.926937103271484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [7:09:14<34:49, 139.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15466.078433388158
INFO:root:current train perplexity4.615067958831787
INFO:root:current mean train loss 15399.24908908876
INFO:root:current train perplexity4.568396091461182
INFO:root:current mean train loss 15424.412087079052
INFO:root:current train perplexity4.571268558502197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it]
INFO:root:final mean train loss: 15409.477164976059
INFO:root:final train perplexity: 4.57163667678833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23104.28538876488
INFO:root:eval perplexity: 10.926530838012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [7:11:33<32:27, 139.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15394.86366637324
INFO:root:current train perplexity4.5631914138793945
INFO:root:current mean train loss 15416.393737436038
INFO:root:current train perplexity4.564734935760498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.50s/it]
INFO:root:final mean train loss: 15403.89201108871
INFO:root:final train perplexity: 4.569118499755859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.78s/it]
INFO:root:eval mean loss: 23101.58475167411
INFO:root:eval perplexity: 10.923478126525879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [7:13:53<30:10, 139.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15467.152428668478
INFO:root:current train perplexity4.563557147979736
INFO:root:current mean train loss 15433.199456935976
INFO:root:current train perplexity4.564398288726807
INFO:root:current mean train loss 15416.557170508688
INFO:root:current train perplexity4.568121433258057


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 15405.595514112903
INFO:root:final train perplexity: 4.569886684417725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.55s/it]
INFO:root:eval mean loss: 23104.657273065477
INFO:root:eval perplexity: 10.926953315734863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [7:16:12<27:49, 139.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15449.744947916666
INFO:root:current train perplexity4.5762858390808105
INFO:root:current mean train loss 15433.236350446428
INFO:root:current train perplexity4.570222854614258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.33s/it]
INFO:root:final mean train loss: 15405.056806010585
INFO:root:final train perplexity: 4.569643497467041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it]
INFO:root:eval mean loss: 23105.773995535714
INFO:root:eval perplexity: 10.928216934204102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [7:18:31<25:31, 139.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15385.718532986111
INFO:root:current train perplexity4.558691501617432
INFO:root:current mean train loss 15380.249454047736
INFO:root:current train perplexity4.559617519378662
INFO:root:current mean train loss 15410.24952677588
INFO:root:current train perplexity4.567424297332764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it]
INFO:root:final mean train loss: 15395.783974924396
INFO:root:final train perplexity: 4.565465927124023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.79s/it]
INFO:root:eval mean loss: 23106.625046502977
INFO:root:eval perplexity: 10.929178237915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [7:20:50<23:11, 139.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15423.80897695807
INFO:root:current train perplexity4.568440914154053
INFO:root:current mean train loss 15425.568670347417
INFO:root:current train perplexity4.571856498718262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.27s/it]
INFO:root:final mean train loss: 15397.121416645665
INFO:root:final train perplexity: 4.566068649291992
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.52s/it]
INFO:root:eval mean loss: 23107.036318824405
INFO:root:eval perplexity: 10.929641723632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [7:23:09<20:51, 139.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15508.582818800403
INFO:root:current train perplexity4.602925777435303
INFO:root:current mean train loss 15420.10097358063
INFO:root:current train perplexity4.570333957672119
INFO:root:current mean train loss 15409.795796976461
INFO:root:current train perplexity4.565954208374023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.16s/it]
INFO:root:final mean train loss: 15400.131261025706
INFO:root:final train perplexity: 4.567423343658447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.71s/it]
INFO:root:eval mean loss: 23106.918294270832
INFO:root:eval perplexity: 10.929509162902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [7:25:28<18:32, 139.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15404.967314570784
INFO:root:current train perplexity4.557182312011719
INFO:root:current mean train loss 15419.602816555669
INFO:root:current train perplexity4.563977241516113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.78s/it]
INFO:root:final mean train loss: 15394.116986674648
INFO:root:final train perplexity: 4.5647149085998535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it]
INFO:root:eval mean loss: 23108.260277157737
INFO:root:eval perplexity: 10.931025505065918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [7:27:47<16:13, 139.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15344.924246651786
INFO:root:current train perplexity4.539379596710205
INFO:root:current mean train loss 15404.959476273149
INFO:root:current train perplexity4.557638645172119
INFO:root:current mean train loss 15404.33635305851
INFO:root:current train perplexity4.564014911651611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.96s/it]
INFO:root:final mean train loss: 15393.547410534275
INFO:root:final train perplexity: 4.56445837020874
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.80s/it]
INFO:root:eval mean loss: 23108.449032738095
INFO:root:eval perplexity: 10.931241989135742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [7:30:06<13:54, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15411.030329561781
INFO:root:current train perplexity4.565427780151367
INFO:root:current mean train loss 15406.918694644051
INFO:root:current train perplexity4.569622039794922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.72s/it]
INFO:root:final mean train loss: 15394.147354618195
INFO:root:final train perplexity: 4.564728736877441
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.84s/it]
INFO:root:eval mean loss: 23109.160621279763
INFO:root:eval perplexity: 10.932046890258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [7:32:26<11:36, 139.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15384.37920673077
INFO:root:current train perplexity4.540557861328125
INFO:root:current mean train loss 15371.080836892985
INFO:root:current train perplexity4.559608459472656
INFO:root:current mean train loss 15400.742498038702
INFO:root:current train perplexity4.562896728515625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.08s/it]
INFO:root:final mean train loss: 15393.847494802167
INFO:root:final train perplexity: 4.56459379196167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.74s/it]
INFO:root:eval mean loss: 23108.85721261161
INFO:root:eval perplexity: 10.931700706481934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [7:34:45<09:16, 139.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15396.311448317309
INFO:root:current train perplexity4.563405990600586
INFO:root:current mean train loss 15412.673337287304
INFO:root:current train perplexity4.5661163330078125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.23s/it]
INFO:root:final mean train loss: 15394.345100648941
INFO:root:final train perplexity: 4.564817905426025
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 23108.494791666668
INFO:root:eval perplexity: 10.931291580200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [7:37:04<06:57, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15395.212209302326
INFO:root:current train perplexity4.567625999450684
INFO:root:current mean train loss 15429.403101781032
INFO:root:current train perplexity4.573618412017822
INFO:root:current mean train loss 15403.746921617798
INFO:root:current train perplexity4.564160346984863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.25s/it]
INFO:root:final mean train loss: 15389.925923009072
INFO:root:final train perplexity: 4.562828063964844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.56s/it]
INFO:root:eval mean loss: 23108.96065848214
INFO:root:eval perplexity: 10.9318208694458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [7:39:23<04:38, 139.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15364.256805098685
INFO:root:current train perplexity4.548479080200195
INFO:root:current mean train loss 15408.124569310898
INFO:root:current train perplexity4.569607257843018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.47s/it]
INFO:root:final mean train loss: 15391.668228641633
INFO:root:final train perplexity: 4.563612461090088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.69s/it]
INFO:root:eval mean loss: 23108.74779110863
INFO:root:eval perplexity: 10.931578636169434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [7:41:42<02:19, 139.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15441.59003075133
INFO:root:current train perplexity4.556830406188965
INFO:root:current mean train loss 15400.005606930272
INFO:root:current train perplexity4.566641330718994
INFO:root:current mean train loss 15400.883686266447
INFO:root:current train perplexity4.562119483947754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.39s/it]
INFO:root:final mean train loss: 15387.073939169606
INFO:root:final train perplexity: 4.561545372009277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.50s/it]
INFO:root:eval mean loss: 23108.479166666668
INFO:root:eval perplexity: 10.931276321411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_baseline_base/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:44:02<00:00, 139.21s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:44:02<00:00, 139.21s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]
INFO:root:eval mean loss: 23108.479166666668
INFO:root:eval perplexity: 10.931276321411133
INFO:root:evalaution complete
INFO:root:save model final: small_baseline_base/final
