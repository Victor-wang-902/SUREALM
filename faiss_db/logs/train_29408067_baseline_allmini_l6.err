INFO:root:Output: allmini_l6_baseline
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 2.75MB/s]
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12506.868361347853
INFO:root:current train perplexity20658.529296875
INFO:root:current mean train loss 10674.332823786903
INFO:root:current train perplexity4618.8740234375
INFO:root:current mean train loss 9296.471211002821
INFO:root:current train perplexity1513.4085693359375
INFO:root:current mean train loss 8319.613993479794
INFO:root:current train perplexity707.7415161132812
INFO:root:current mean train loss 7616.212371031124
INFO:root:current train perplexity406.2274475097656
INFO:root:current mean train loss 7080.996170782685
INFO:root:current train perplexity266.796142578125
INFO:root:current mean train loss 6661.941367830159
INFO:root:current train perplexity192.41014099121094
INFO:root:current mean train loss 6322.337684067976
INFO:root:current train perplexity147.25503540039062
INFO:root:current mean train loss 6049.735087868899
INFO:root:current train perplexity118.27372741699219
INFO:root:current mean train loss 5815.628128861284
INFO:root:current train perplexity98.42848205566406
INFO:root:current mean train loss 5614.443328052135
INFO:root:current train perplexity84.0934829711914
INFO:root:current mean train loss 5442.142714957778
INFO:root:current train perplexity73.38643646240234
INFO:root:current mean train loss 5290.218060241652
INFO:root:current train perplexity65.05986022949219
INFO:root:current mean train loss 5158.962661841327
INFO:root:current train perplexity58.500736236572266
INFO:root:current mean train loss 5040.262112730102
INFO:root:current train perplexity53.22336959838867
INFO:root:current mean train loss 4934.887495908087
INFO:root:current train perplexity48.90583038330078
INFO:root:current mean train loss 4838.596182928147
INFO:root:current train perplexity45.30541229248047
INFO:root:current mean train loss 4748.685406280399
INFO:root:current train perplexity42.24443435668945
INFO:root:current mean train loss 4665.608825651453
INFO:root:current train perplexity39.6215934753418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:13<00:00, 133.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:13<00:00, 133.01s/it]
INFO:root:final mean train loss: 4601.142967297222
INFO:root:final train perplexity: 37.66524887084961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2949.180568830341
INFO:root:eval perplexity: 10.860411643981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/1
  0%|          | 1/200 [02:19<7:44:08, 139.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.5855255126953
INFO:root:current train perplexity12.598414421081543
INFO:root:current mean train loss 3140.3583816002156
INFO:root:current train perplexity11.856077194213867
INFO:root:current mean train loss 3126.2055166739005
INFO:root:current train perplexity11.713111877441406
INFO:root:current mean train loss 3099.326309397251
INFO:root:current train perplexity11.523115158081055
INFO:root:current mean train loss 3089.947185809796
INFO:root:current train perplexity11.397488594055176
INFO:root:current mean train loss 3076.498409773952
INFO:root:current train perplexity11.31606674194336
INFO:root:current mean train loss 3065.6284037007913
INFO:root:current train perplexity11.226314544677734
INFO:root:current mean train loss 3056.033975100384
INFO:root:current train perplexity11.128962516784668
INFO:root:current mean train loss 3043.859891106101
INFO:root:current train perplexity11.034521102905273
INFO:root:current mean train loss 3036.6296847814037
INFO:root:current train perplexity10.969803810119629
INFO:root:current mean train loss 3027.8618507685624
INFO:root:current train perplexity10.897831916809082
INFO:root:current mean train loss 3019.2778998480903
INFO:root:current train perplexity10.820714950561523
INFO:root:current mean train loss 3009.0495280215614
INFO:root:current train perplexity10.726144790649414
INFO:root:current mean train loss 2999.202784575952
INFO:root:current train perplexity10.65102481842041
INFO:root:current mean train loss 2990.584594554147
INFO:root:current train perplexity10.575618743896484
INFO:root:current mean train loss 2980.513534344595
INFO:root:current train perplexity10.496169090270996
INFO:root:current mean train loss 2970.1866695290746
INFO:root:current train perplexity10.416220664978027
INFO:root:current mean train loss 2963.317300294107
INFO:root:current train perplexity10.356501579284668
INFO:root:current mean train loss 2955.501430158573
INFO:root:current train perplexity10.292030334472656
INFO:root:current mean train loss 2949.5264621169185
INFO:root:current train perplexity10.233134269714355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it]
INFO:root:final mean train loss: 2944.6103375887424
INFO:root:final train perplexity: 10.199070930480957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2626.8445391282967
INFO:root:eval perplexity: 8.368189811706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/2
  1%|          | 2/200 [04:38<7:39:02, 139.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2759.3350053267045
INFO:root:current train perplexity8.751150131225586
INFO:root:current mean train loss 2777.7692742598683
INFO:root:current train perplexity8.821045875549316
INFO:root:current mean train loss 2774.6966474148335
INFO:root:current train perplexity8.825518608093262
INFO:root:current mean train loss 2763.4026230820664
INFO:root:current train perplexity8.768978118896484
INFO:root:current mean train loss 2757.92994968335
INFO:root:current train perplexity8.759737968444824
INFO:root:current mean train loss 2758.360897099994
INFO:root:current train perplexity8.744405746459961
INFO:root:current mean train loss 2754.3371990860733
INFO:root:current train perplexity8.73671817779541
INFO:root:current mean train loss 2749.2563819625043
INFO:root:current train perplexity8.717635154724121
INFO:root:current mean train loss 2745.416853557829
INFO:root:current train perplexity8.694833755493164
INFO:root:current mean train loss 2740.871352544296
INFO:root:current train perplexity8.675128936767578
INFO:root:current mean train loss 2735.178638617044
INFO:root:current train perplexity8.637398719787598
INFO:root:current mean train loss 2734.0704204562694
INFO:root:current train perplexity8.625609397888184
INFO:root:current mean train loss 2729.6405196611413
INFO:root:current train perplexity8.597163200378418
INFO:root:current mean train loss 2728.1354410868344
INFO:root:current train perplexity8.57988452911377
INFO:root:current mean train loss 2725.4657760162245
INFO:root:current train perplexity8.55614185333252
INFO:root:current mean train loss 2721.757066859813
INFO:root:current train perplexity8.533766746520996
INFO:root:current mean train loss 2716.99325212057
INFO:root:current train perplexity8.512462615966797
INFO:root:current mean train loss 2713.896147114379
INFO:root:current train perplexity8.494999885559082
INFO:root:current mean train loss 2711.0415308109996
INFO:root:current train perplexity8.47731876373291
INFO:root:current mean train loss 2707.1869659976396
INFO:root:current train perplexity8.452998161315918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.98s/it]
INFO:root:final mean train loss: 2705.68833282363
INFO:root:final train perplexity: 8.447484016418457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2490.457575371925
INFO:root:eval perplexity: 7.494248390197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/3
  2%|â–         | 3/200 [06:57<7:36:28, 139.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2603.14798828125
INFO:root:current train perplexity7.857549667358398
INFO:root:current mean train loss 2628.1477783203127
INFO:root:current train perplexity7.906731128692627
INFO:root:current mean train loss 2629.1555244140627
INFO:root:current train perplexity7.8902482986450195
INFO:root:current mean train loss 2624.342795061384
INFO:root:current train perplexity7.855388164520264
INFO:root:current mean train loss 2619.4462109375
INFO:root:current train perplexity7.8584208488464355
INFO:root:current mean train loss 2611.9245587713067
INFO:root:current train perplexity7.840723991394043
INFO:root:current mean train loss 2612.7629356971156
INFO:root:current train perplexity7.840258598327637
INFO:root:current mean train loss 2611.0293313802085
INFO:root:current train perplexity7.836756229400635
INFO:root:current mean train loss 2605.8574155560664
INFO:root:current train perplexity7.801356792449951
INFO:root:current mean train loss 2602.75496145148
INFO:root:current train perplexity7.782233715057373
INFO:root:current mean train loss 2603.1089327566965
INFO:root:current train perplexity7.781931400299072
INFO:root:current mean train loss 2600.491476732337
INFO:root:current train perplexity7.763759136199951
INFO:root:current mean train loss 2597.41292890625
INFO:root:current train perplexity7.745185852050781
INFO:root:current mean train loss 2596.5055618851275
INFO:root:current train perplexity7.738109111785889
INFO:root:current mean train loss 2591.7583807583514
INFO:root:current train perplexity7.721005439758301
INFO:root:current mean train loss 2589.9161158014113
INFO:root:current train perplexity7.707255840301514
INFO:root:current mean train loss 2586.0724980764676
INFO:root:current train perplexity7.686361789703369
INFO:root:current mean train loss 2584.8647751116073
INFO:root:current train perplexity7.678432464599609
INFO:root:current mean train loss 2584.347092747044
INFO:root:current train perplexity7.669467449188232
INFO:root:current mean train loss 2582.2253685897435
INFO:root:current train perplexity7.659278392791748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 2580.5781772015252
INFO:root:final train perplexity: 7.653776168823242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.71s/it]
INFO:root:eval mean loss: 2410.4247917012967
INFO:root:eval perplexity: 7.024542331695557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/4
  2%|â–         | 4/200 [09:16<7:33:41, 138.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2537.582719945196
INFO:root:current train perplexity7.376045227050781
INFO:root:current mean train loss 2518.5210048652693
INFO:root:current train perplexity7.339116096496582
INFO:root:current mean train loss 2519.3964455136647
INFO:root:current train perplexity7.310048580169678
INFO:root:current mean train loss 2518.475385369657
INFO:root:current train perplexity7.298290729522705
INFO:root:current mean train loss 2515.889284840488
INFO:root:current train perplexity7.271569728851318
INFO:root:current mean train loss 2520.887666678723
INFO:root:current train perplexity7.285455703735352
INFO:root:current mean train loss 2520.549068056304
INFO:root:current train perplexity7.283866882324219
INFO:root:current mean train loss 2520.864568638211
INFO:root:current train perplexity7.276689529418945
INFO:root:current mean train loss 2519.70251380366
INFO:root:current train perplexity7.261524677276611
INFO:root:current mean train loss 2516.821939052199
INFO:root:current train perplexity7.241952419281006
INFO:root:current mean train loss 2515.2721837337817
INFO:root:current train perplexity7.235526084899902
INFO:root:current mean train loss 2512.674811382016
INFO:root:current train perplexity7.224287509918213
INFO:root:current mean train loss 2511.0203804431603
INFO:root:current train perplexity7.214139938354492
INFO:root:current mean train loss 2507.4493387664593
INFO:root:current train perplexity7.204437255859375
INFO:root:current mean train loss 2505.4336504997977
INFO:root:current train perplexity7.198584079742432
INFO:root:current mean train loss 2505.149168363862
INFO:root:current train perplexity7.1974711418151855
INFO:root:current mean train loss 2501.7607588833794
INFO:root:current train perplexity7.189235687255859
INFO:root:current mean train loss 2499.9525202441905
INFO:root:current train perplexity7.175973415374756
INFO:root:current mean train loss 2499.0340810243497
INFO:root:current train perplexity7.172184944152832
INFO:root:current mean train loss 2497.889412674858
INFO:root:current train perplexity7.165313243865967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it]
INFO:root:final mean train loss: 2497.0087148230664
INFO:root:final train perplexity: 7.1655964851379395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2354.856005513076
INFO:root:eval perplexity: 6.715842247009277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/5
  2%|â–Ž         | 5/200 [11:34<7:31:15, 138.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2457.4855041503906
INFO:root:current train perplexity7.017946720123291
INFO:root:current mean train loss 2459.8340487272844
INFO:root:current train perplexity6.983424186706543
INFO:root:current mean train loss 2467.5855579644863
INFO:root:current train perplexity6.975165843963623
INFO:root:current mean train loss 2465.137978553772
INFO:root:current train perplexity6.963647365570068
INFO:root:current mean train loss 2460.719569687016
INFO:root:current train perplexity6.947301387786865
INFO:root:current mean train loss 2455.085878555089
INFO:root:current train perplexity6.920239448547363
INFO:root:current mean train loss 2447.745433785065
INFO:root:current train perplexity6.9047980308532715
INFO:root:current mean train loss 2444.4068626870912
INFO:root:current train perplexity6.895087718963623
INFO:root:current mean train loss 2445.0450902049897
INFO:root:current train perplexity6.8932952880859375
INFO:root:current mean train loss 2445.1678080985216
INFO:root:current train perplexity6.883196830749512
INFO:root:current mean train loss 2445.590831911432
INFO:root:current train perplexity6.878702640533447
INFO:root:current mean train loss 2444.6833156894995
INFO:root:current train perplexity6.871758460998535
INFO:root:current mean train loss 2443.3528268404098
INFO:root:current train perplexity6.866755962371826
INFO:root:current mean train loss 2441.637780602957
INFO:root:current train perplexity6.861985206604004
INFO:root:current mean train loss 2440.349622289447
INFO:root:current train perplexity6.855257987976074
INFO:root:current mean train loss 2439.0242940729313
INFO:root:current train perplexity6.851104259490967
INFO:root:current mean train loss 2438.22600006321
INFO:root:current train perplexity6.846232891082764
INFO:root:current mean train loss 2437.4677921859675
INFO:root:current train perplexity6.83959436416626
INFO:root:current mean train loss 2435.8529175841377
INFO:root:current train perplexity6.830350399017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 2435.9752992292397
INFO:root:final train perplexity: 6.828852653503418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2313.206181086547
INFO:root:eval perplexity: 6.49339485168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/6
  3%|â–Ž         | 6/200 [13:53<7:28:46, 138.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2401.251708984375
INFO:root:current train perplexity6.414454936981201
INFO:root:current mean train loss 2430.5708660465657
INFO:root:current train perplexity6.697915554046631
INFO:root:current mean train loss 2409.7914285991915
INFO:root:current train perplexity6.665704250335693
INFO:root:current mean train loss 2409.9519594515677
INFO:root:current train perplexity6.675833225250244
INFO:root:current mean train loss 2409.2491302870753
INFO:root:current train perplexity6.6661272048950195
INFO:root:current mean train loss 2406.4815232815617
INFO:root:current train perplexity6.647093772888184
INFO:root:current mean train loss 2406.3263144596244
INFO:root:current train perplexity6.640173435211182
INFO:root:current mean train loss 2399.311160883448
INFO:root:current train perplexity6.617432594299316
INFO:root:current mean train loss 2395.416700803683
INFO:root:current train perplexity6.598442554473877
INFO:root:current mean train loss 2395.0772736239246
INFO:root:current train perplexity6.602499008178711
INFO:root:current mean train loss 2394.9057069639343
INFO:root:current train perplexity6.593201160430908
INFO:root:current mean train loss 2394.1623376608977
INFO:root:current train perplexity6.59297513961792
INFO:root:current mean train loss 2393.944784578932
INFO:root:current train perplexity6.593947410583496
INFO:root:current mean train loss 2394.310514598146
INFO:root:current train perplexity6.5934834480285645
INFO:root:current mean train loss 2394.2595598219464
INFO:root:current train perplexity6.592548847198486
INFO:root:current mean train loss 2392.100085376025
INFO:root:current train perplexity6.585376739501953
INFO:root:current mean train loss 2390.3760002750964
INFO:root:current train perplexity6.5812859535217285
INFO:root:current mean train loss 2388.83305532017
INFO:root:current train perplexity6.576323986053467
INFO:root:current mean train loss 2388.9558177992476
INFO:root:current train perplexity6.575923442840576
INFO:root:current mean train loss 2389.5860883380665
INFO:root:current train perplexity6.579710006713867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it]
INFO:root:final mean train loss: 2387.7598377098893
INFO:root:final train perplexity: 6.574057102203369
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2282.742590938054
INFO:root:eval perplexity: 6.335370063781738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/7
  4%|â–Ž         | 7/200 [16:12<7:26:29, 138.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2356.344251844618
INFO:root:current train perplexity6.420244216918945
INFO:root:current mean train loss 2356.672189486229
INFO:root:current train perplexity6.383980751037598
INFO:root:current mean train loss 2364.6570031402307
INFO:root:current train perplexity6.41947078704834
INFO:root:current mean train loss 2355.753087073752
INFO:root:current train perplexity6.3997368812561035
INFO:root:current mean train loss 2357.2554143148177
INFO:root:current train perplexity6.385225296020508
INFO:root:current mean train loss 2355.8412602840704
INFO:root:current train perplexity6.393818378448486
INFO:root:current mean train loss 2359.2994017369538
INFO:root:current train perplexity6.397075653076172
INFO:root:current mean train loss 2361.1826646215072
INFO:root:current train perplexity6.409862995147705
INFO:root:current mean train loss 2359.865451654187
INFO:root:current train perplexity6.409578800201416
INFO:root:current mean train loss 2356.403718038322
INFO:root:current train perplexity6.4045257568359375
INFO:root:current mean train loss 2356.3387272503146
INFO:root:current train perplexity6.405154228210449
INFO:root:current mean train loss 2356.2235666455863
INFO:root:current train perplexity6.406639575958252
INFO:root:current mean train loss 2354.997787199976
INFO:root:current train perplexity6.397365093231201
INFO:root:current mean train loss 2355.4121591107796
INFO:root:current train perplexity6.3930439949035645
INFO:root:current mean train loss 2354.2151382510856
INFO:root:current train perplexity6.387300968170166
INFO:root:current mean train loss 2353.5958099968348
INFO:root:current train perplexity6.386760711669922
INFO:root:current mean train loss 2352.903390099298
INFO:root:current train perplexity6.387667179107666
INFO:root:current mean train loss 2352.281934957982
INFO:root:current train perplexity6.387442588806152
INFO:root:current mean train loss 2351.04722865475
INFO:root:current train perplexity6.3805317878723145
INFO:root:current mean train loss 2350.2601369275044
INFO:root:current train perplexity6.380221366882324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.05s/it]
INFO:root:final mean train loss: 2349.1807230046707
INFO:root:final train perplexity: 6.377047538757324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2257.203234949856
INFO:root:eval perplexity: 6.205857276916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/8
  4%|â–         | 8/200 [18:31<7:24:23, 138.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2371.87158203125
INFO:root:current train perplexity6.3549065589904785
INFO:root:current mean train loss 2357.98953088831
INFO:root:current train perplexity6.270578384399414
INFO:root:current mean train loss 2347.956568941157
INFO:root:current train perplexity6.272022724151611
INFO:root:current mean train loss 2341.0423263322064
INFO:root:current train perplexity6.285695552825928
INFO:root:current mean train loss 2343.800706324084
INFO:root:current train perplexity6.295995712280273
INFO:root:current mean train loss 2339.244533531688
INFO:root:current train perplexity6.273777961730957
INFO:root:current mean train loss 2333.682026444082
INFO:root:current train perplexity6.256852626800537
INFO:root:current mean train loss 2332.312103396046
INFO:root:current train perplexity6.257266044616699
INFO:root:current mean train loss 2330.2593660822886
INFO:root:current train perplexity6.251905918121338
INFO:root:current mean train loss 2328.9707328918785
INFO:root:current train perplexity6.24670934677124
INFO:root:current mean train loss 2325.486052022003
INFO:root:current train perplexity6.2379302978515625
INFO:root:current mean train loss 2322.6921731957254
INFO:root:current train perplexity6.228940486907959
INFO:root:current mean train loss 2320.064361201607
INFO:root:current train perplexity6.221973419189453
INFO:root:current mean train loss 2320.7280228632667
INFO:root:current train perplexity6.219415664672852
INFO:root:current mean train loss 2320.893271586455
INFO:root:current train perplexity6.221709251403809
INFO:root:current mean train loss 2320.1511440413783
INFO:root:current train perplexity6.221553325653076
INFO:root:current mean train loss 2319.01352688384
INFO:root:current train perplexity6.219076156616211
INFO:root:current mean train loss 2319.5446243330107
INFO:root:current train perplexity6.22027587890625
INFO:root:current mean train loss 2318.140640034273
INFO:root:current train perplexity6.217024326324463
INFO:root:current mean train loss 2317.755001286943
INFO:root:current train perplexity6.217430591583252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it]
INFO:root:final mean train loss: 2316.4069811291483
INFO:root:final train perplexity: 6.214330673217773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2237.9861995615856
INFO:root:eval perplexity: 6.110153675079346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/9
  4%|â–         | 9/200 [20:50<7:21:52, 138.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2256.071338360126
INFO:root:current train perplexity6.041538715362549
INFO:root:current mean train loss 2270.266166285465
INFO:root:current train perplexity6.039688587188721
INFO:root:current mean train loss 2286.879377092634
INFO:root:current train perplexity6.078227519989014
INFO:root:current mean train loss 2285.7128628817472
INFO:root:current train perplexity6.071850299835205
INFO:root:current mean train loss 2291.4523277620297
INFO:root:current train perplexity6.085774898529053
INFO:root:current mean train loss 2299.005932572959
INFO:root:current train perplexity6.098535060882568
INFO:root:current mean train loss 2297.776406879074
INFO:root:current train perplexity6.099636077880859
INFO:root:current mean train loss 2297.026868130298
INFO:root:current train perplexity6.102205276489258
INFO:root:current mean train loss 2296.191269708911
INFO:root:current train perplexity6.103468418121338
INFO:root:current mean train loss 2293.899866825392
INFO:root:current train perplexity6.093860149383545
INFO:root:current mean train loss 2292.5232882771656
INFO:root:current train perplexity6.090504169464111
INFO:root:current mean train loss 2290.258678966098
INFO:root:current train perplexity6.081573009490967
INFO:root:current mean train loss 2288.7123284385607
INFO:root:current train perplexity6.075018405914307
INFO:root:current mean train loss 2291.210722161468
INFO:root:current train perplexity6.0828986167907715
INFO:root:current mean train loss 2291.254109196098
INFO:root:current train perplexity6.083620071411133
INFO:root:current mean train loss 2289.201524714834
INFO:root:current train perplexity6.080014705657959
INFO:root:current mean train loss 2289.8587393772227
INFO:root:current train perplexity6.0814528465271
INFO:root:current mean train loss 2289.5407620085975
INFO:root:current train perplexity6.082976818084717
INFO:root:current mean train loss 2289.213772273218
INFO:root:current train perplexity6.079713821411133
INFO:root:current mean train loss 2288.0776501639943
INFO:root:current train perplexity6.07530403137207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it]
INFO:root:final mean train loss: 2287.525253780671
INFO:root:final train perplexity: 6.074378967285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2218.3097512536015
INFO:root:eval perplexity: 6.013691425323486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/10
  5%|â–Œ         | 10/200 [23:08<7:19:24, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2234.311081153759
INFO:root:current train perplexity5.902079105377197
INFO:root:current mean train loss 2251.250464445035
INFO:root:current train perplexity5.968408584594727
INFO:root:current mean train loss 2255.608640762953
INFO:root:current train perplexity5.969576835632324
INFO:root:current mean train loss 2260.918640963753
INFO:root:current train perplexity5.960357666015625
INFO:root:current mean train loss 2265.0921175373132
INFO:root:current train perplexity5.967901706695557
INFO:root:current mean train loss 2263.911722354185
INFO:root:current train perplexity5.966139793395996
INFO:root:current mean train loss 2263.7604354607506
INFO:root:current train perplexity5.973539352416992
INFO:root:current mean train loss 2263.2674447842164
INFO:root:current train perplexity5.963593006134033
INFO:root:current mean train loss 2263.7849996235345
INFO:root:current train perplexity5.967217445373535
INFO:root:current mean train loss 2265.2511201746324
INFO:root:current train perplexity5.965085983276367
INFO:root:current mean train loss 2263.8143255735135
INFO:root:current train perplexity5.9589924812316895
INFO:root:current mean train loss 2263.7629250427717
INFO:root:current train perplexity5.957083225250244
INFO:root:current mean train loss 2263.7553588770993
INFO:root:current train perplexity5.956559658050537
INFO:root:current mean train loss 2262.677939014421
INFO:root:current train perplexity5.955852508544922
INFO:root:current mean train loss 2263.283038259445
INFO:root:current train perplexity5.957377910614014
INFO:root:current mean train loss 2263.2428425095354
INFO:root:current train perplexity5.959085464477539
INFO:root:current mean train loss 2263.6743687012013
INFO:root:current train perplexity5.96042537689209
INFO:root:current mean train loss 2262.8710686320837
INFO:root:current train perplexity5.95188570022583
INFO:root:current mean train loss 2263.233524034724
INFO:root:current train perplexity5.955115795135498
INFO:root:current mean train loss 2262.5593892839006
INFO:root:current train perplexity5.953918933868408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it]
INFO:root:final mean train loss: 2262.1999181765714
INFO:root:final train perplexity: 5.954258918762207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2204.0392183344416
INFO:root:eval perplexity: 5.944684982299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/11
  6%|â–Œ         | 11/200 [25:27<7:16:52, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2256.359445971112
INFO:root:current train perplexity5.838253498077393
INFO:root:current mean train loss 2253.8712191017726
INFO:root:current train perplexity5.879839897155762
INFO:root:current mean train loss 2247.637462269176
INFO:root:current train perplexity5.874821186065674
INFO:root:current mean train loss 2242.0803077183855
INFO:root:current train perplexity5.860413551330566
INFO:root:current mean train loss 2236.9115786454313
INFO:root:current train perplexity5.843276500701904
INFO:root:current mean train loss 2239.579534224683
INFO:root:current train perplexity5.856097221374512
INFO:root:current mean train loss 2236.2673955533664
INFO:root:current train perplexity5.847579479217529
INFO:root:current mean train loss 2236.6844824094505
INFO:root:current train perplexity5.849816799163818
INFO:root:current mean train loss 2240.6932386824565
INFO:root:current train perplexity5.8565263748168945
INFO:root:current mean train loss 2240.311547826802
INFO:root:current train perplexity5.850683689117432
INFO:root:current mean train loss 2243.612508587635
INFO:root:current train perplexity5.856934070587158
INFO:root:current mean train loss 2242.4233976881983
INFO:root:current train perplexity5.854732990264893
INFO:root:current mean train loss 2243.1887618994824
INFO:root:current train perplexity5.858333587646484
INFO:root:current mean train loss 2245.7961335065215
INFO:root:current train perplexity5.8631978034973145
INFO:root:current mean train loss 2244.0155029296875
INFO:root:current train perplexity5.859963893890381
INFO:root:current mean train loss 2241.852555764428
INFO:root:current train perplexity5.855126857757568
INFO:root:current mean train loss 2242.326143855302
INFO:root:current train perplexity5.855690956115723
INFO:root:current mean train loss 2242.1611178441917
INFO:root:current train perplexity5.855867385864258
INFO:root:current mean train loss 2241.430505940669
INFO:root:current train perplexity5.853844165802002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it]
INFO:root:final mean train loss: 2240.012296783401
INFO:root:final train perplexity: 5.8509745597839355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2191.5988812818596
INFO:root:eval perplexity: 5.8851752281188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/12
  6%|â–Œ         | 12/200 [27:46<7:14:40, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2279.958984375
INFO:root:current train perplexity5.847656726837158
INFO:root:current mean train loss 2195.631309731493
INFO:root:current train perplexity5.672766208648682
INFO:root:current mean train loss 2214.74347074161
INFO:root:current train perplexity5.719022274017334
INFO:root:current mean train loss 2213.3594237475504
INFO:root:current train perplexity5.7233662605285645
INFO:root:current mean train loss 2210.039280590881
INFO:root:current train perplexity5.720011234283447
INFO:root:current mean train loss 2218.499949036251
INFO:root:current train perplexity5.73893928527832
INFO:root:current mean train loss 2221.912929047795
INFO:root:current train perplexity5.749500274658203
INFO:root:current mean train loss 2223.227780772137
INFO:root:current train perplexity5.758521556854248
INFO:root:current mean train loss 2219.684916001031
INFO:root:current train perplexity5.75093936920166
INFO:root:current mean train loss 2220.474437962867
INFO:root:current train perplexity5.749605178833008
INFO:root:current mean train loss 2220.837089561394
INFO:root:current train perplexity5.752277374267578
INFO:root:current mean train loss 2219.0715139463396
INFO:root:current train perplexity5.749166011810303
INFO:root:current mean train loss 2220.873966207528
INFO:root:current train perplexity5.753885746002197
INFO:root:current mean train loss 2221.375013677871
INFO:root:current train perplexity5.754586219787598
INFO:root:current mean train loss 2220.934853519105
INFO:root:current train perplexity5.757682800292969
INFO:root:current mean train loss 2220.686465935317
INFO:root:current train perplexity5.754779815673828
INFO:root:current mean train loss 2220.535145512686
INFO:root:current train perplexity5.756318092346191
INFO:root:current mean train loss 2219.4763944114015
INFO:root:current train perplexity5.751348495483398
INFO:root:current mean train loss 2220.1043232660195
INFO:root:current train perplexity5.754240989685059
INFO:root:current mean train loss 2220.518755016237
INFO:root:current train perplexity5.756836891174316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it]
INFO:root:final mean train loss: 2219.6454071337325
INFO:root:final train perplexity: 5.757743835449219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2178.7938193463265
INFO:root:eval perplexity: 5.824542999267578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/13
  6%|â–‹         | 13/200 [30:04<7:12:27, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2142.213067626953
INFO:root:current train perplexity5.720447063446045
INFO:root:current mean train loss 2210.3747751871747
INFO:root:current train perplexity5.703700542449951
INFO:root:current mean train loss 2210.6375926624646
INFO:root:current train perplexity5.68269681930542
INFO:root:current mean train loss 2200.157318878174
INFO:root:current train perplexity5.682163715362549
INFO:root:current mean train loss 2202.5570513044086
INFO:root:current train perplexity5.686934947967529
INFO:root:current mean train loss 2201.690242826022
INFO:root:current train perplexity5.677670001983643
INFO:root:current mean train loss 2200.022629670174
INFO:root:current train perplexity5.675682544708252
INFO:root:current mean train loss 2199.323900349935
INFO:root:current train perplexity5.662402629852295
INFO:root:current mean train loss 2203.782555259146
INFO:root:current train perplexity5.672274589538574
INFO:root:current mean train loss 2203.7769080120584
INFO:root:current train perplexity5.667937755584717
INFO:root:current mean train loss 2201.921828326057
INFO:root:current train perplexity5.669243335723877
INFO:root:current mean train loss 2202.9976303100584
INFO:root:current train perplexity5.672395706176758
INFO:root:current mean train loss 2203.1391744644916
INFO:root:current train perplexity5.674200057983398
INFO:root:current mean train loss 2204.38012528853
INFO:root:current train perplexity5.681842803955078
INFO:root:current mean train loss 2203.6444298112897
INFO:root:current train perplexity5.677893161773682
INFO:root:current mean train loss 2203.341018757067
INFO:root:current train perplexity5.677842617034912
INFO:root:current mean train loss 2201.6311342592594
INFO:root:current train perplexity5.671894073486328
INFO:root:current mean train loss 2200.9781181867734
INFO:root:current train perplexity5.672245025634766
INFO:root:current mean train loss 2200.3775920490643
INFO:root:current train perplexity5.669602394104004
INFO:root:current mean train loss 2200.9918060938517
INFO:root:current train perplexity5.671600818634033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it]
INFO:root:final mean train loss: 2200.4122424950456
INFO:root:final train perplexity: 5.671067714691162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2169.2712043058787
INFO:root:eval perplexity: 5.7798590660095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/14
  7%|â–‹         | 14/200 [32:23<7:10:09, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2201.9021589949325
INFO:root:current train perplexity5.607851505279541
INFO:root:current mean train loss 2198.0031871934875
INFO:root:current train perplexity5.56542444229126
INFO:root:current mean train loss 2196.837543471453
INFO:root:current train perplexity5.580621719360352
INFO:root:current mean train loss 2198.2016844254217
INFO:root:current train perplexity5.593400955200195
INFO:root:current mean train loss 2194.690811820652
INFO:root:current train perplexity5.58040714263916
INFO:root:current mean train loss 2187.5291286589268
INFO:root:current train perplexity5.570964336395264
INFO:root:current mean train loss 2190.721386297157
INFO:root:current train perplexity5.591963768005371
INFO:root:current mean train loss 2191.9249862194706
INFO:root:current train perplexity5.598745822906494
INFO:root:current mean train loss 2190.769755556022
INFO:root:current train perplexity5.598057746887207
INFO:root:current mean train loss 2187.939628869772
INFO:root:current train perplexity5.588500499725342
INFO:root:current mean train loss 2185.536397670941
INFO:root:current train perplexity5.584646701812744
INFO:root:current mean train loss 2185.669126109691
INFO:root:current train perplexity5.590051651000977
INFO:root:current mean train loss 2185.3917518560215
INFO:root:current train perplexity5.589839458465576
INFO:root:current mean train loss 2185.7862561610355
INFO:root:current train perplexity5.5907135009765625
INFO:root:current mean train loss 2186.7762113928216
INFO:root:current train perplexity5.59615421295166
INFO:root:current mean train loss 2185.4053054442247
INFO:root:current train perplexity5.595245361328125
INFO:root:current mean train loss 2186.7605960312308
INFO:root:current train perplexity5.597806930541992
INFO:root:current mean train loss 2185.5992747884957
INFO:root:current train perplexity5.598182678222656
INFO:root:current mean train loss 2185.3987932781456
INFO:root:current train perplexity5.598653793334961
INFO:root:current mean train loss 2184.381578877714
INFO:root:current train perplexity5.59683084487915

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 2183.4390936854866
INFO:root:final train perplexity: 5.595661163330078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2160.9395288778537
INFO:root:eval perplexity: 5.741043567657471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/15
  8%|â–Š         | 15/200 [34:42<7:07:43, 138.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2174.360464590567
INFO:root:current train perplexity5.5861897468566895
INFO:root:current mean train loss 2147.1890092329545
INFO:root:current train perplexity5.475432395935059
INFO:root:current mean train loss 2160.7183861920216
INFO:root:current train perplexity5.517317771911621
INFO:root:current mean train loss 2160.130663855601
INFO:root:current train perplexity5.514183044433594
INFO:root:current mean train loss 2162.2826180479074
INFO:root:current train perplexity5.516290664672852
INFO:root:current mean train loss 2163.9032658876495
INFO:root:current train perplexity5.5229268074035645
INFO:root:current mean train loss 2162.474036913764
INFO:root:current train perplexity5.514023780822754
INFO:root:current mean train loss 2163.9096325133146
INFO:root:current train perplexity5.515381813049316
INFO:root:current mean train loss 2167.558733687747
INFO:root:current train perplexity5.5229668617248535
INFO:root:current mean train loss 2167.582351140756
INFO:root:current train perplexity5.525546073913574
INFO:root:current mean train loss 2167.2728398882236
INFO:root:current train perplexity5.521824359893799
INFO:root:current mean train loss 2167.7594602376585
INFO:root:current train perplexity5.518080711364746
INFO:root:current mean train loss 2169.4935737865394
INFO:root:current train perplexity5.526556015014648
INFO:root:current mean train loss 2169.4892952269606
INFO:root:current train perplexity5.523505210876465
INFO:root:current mean train loss 2169.817334034748
INFO:root:current train perplexity5.522508144378662
INFO:root:current mean train loss 2168.904937390655
INFO:root:current train perplexity5.522732734680176
INFO:root:current mean train loss 2167.9280423552987
INFO:root:current train perplexity5.521975517272949
INFO:root:current mean train loss 2168.461116151364
INFO:root:current train perplexity5.525354862213135
INFO:root:current mean train loss 2169.1237269528087
INFO:root:current train perplexity5.527135372161865
INFO:root:current mean train loss 2168.4386819704773
INFO:root:current train perplexity5.5260796546936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.88s/it]
INFO:root:final mean train loss: 2167.8221577131203
INFO:root:final train perplexity: 5.527165412902832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2150.7190612360096
INFO:root:eval perplexity: 5.693785190582275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/16
  8%|â–Š         | 16/200 [37:01<7:05:31, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2139.126525019256
INFO:root:current train perplexity5.4335455894470215
INFO:root:current mean train loss 2150.7992471616867
INFO:root:current train perplexity5.440878868103027
INFO:root:current mean train loss 2143.4430481182253
INFO:root:current train perplexity5.4489359855651855
INFO:root:current mean train loss 2143.5798099651493
INFO:root:current train perplexity5.450165748596191
INFO:root:current mean train loss 2144.2025890309847
INFO:root:current train perplexity5.445401191711426
INFO:root:current mean train loss 2145.4799785446994
INFO:root:current train perplexity5.445236682891846
INFO:root:current mean train loss 2146.8655656567275
INFO:root:current train perplexity5.4486470222473145
INFO:root:current mean train loss 2147.4499475303483
INFO:root:current train perplexity5.4531636238098145
INFO:root:current mean train loss 2148.4964536542047
INFO:root:current train perplexity5.452184200286865
INFO:root:current mean train loss 2148.0131746679085
INFO:root:current train perplexity5.449586391448975
INFO:root:current mean train loss 2148.0005294272655
INFO:root:current train perplexity5.444994926452637
INFO:root:current mean train loss 2148.9210377081554
INFO:root:current train perplexity5.449257850646973
INFO:root:current mean train loss 2150.015052489274
INFO:root:current train perplexity5.451530933380127
INFO:root:current mean train loss 2150.148125601893
INFO:root:current train perplexity5.453904151916504
INFO:root:current mean train loss 2151.7063021475083
INFO:root:current train perplexity5.458215713500977
INFO:root:current mean train loss 2152.5667503934847
INFO:root:current train perplexity5.459412097930908
INFO:root:current mean train loss 2152.818887469727
INFO:root:current train perplexity5.462536334991455
INFO:root:current mean train loss 2152.588334585973
INFO:root:current train perplexity5.465208530426025
INFO:root:current mean train loss 2153.1879806477777
INFO:root:current train perplexity5.46224308013916
INFO:root:current mean train loss 2153.623526175938
INFO:root:current train perplexity5.4623517990112305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.22s/it]
INFO:root:final mean train loss: 2152.845017364394
INFO:root:final train perplexity: 5.462263107299805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2144.7147467863474
INFO:root:eval perplexity: 5.66620397567749
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/17
  8%|â–Š         | 17/200 [39:20<7:03:36, 138.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2141.2647386030717
INFO:root:current train perplexity5.372113227844238
INFO:root:current mean train loss 2136.365492800449
INFO:root:current train perplexity5.398828029632568
INFO:root:current mean train loss 2139.439963870578
INFO:root:current train perplexity5.407225131988525
INFO:root:current mean train loss 2141.8943245484656
INFO:root:current train perplexity5.401175022125244
INFO:root:current mean train loss 2142.286437738137
INFO:root:current train perplexity5.401601791381836
INFO:root:current mean train loss 2141.6475626627603
INFO:root:current train perplexity5.404106616973877
INFO:root:current mean train loss 2141.144425680471
INFO:root:current train perplexity5.401954650878906
INFO:root:current mean train loss 2141.832346340121
INFO:root:current train perplexity5.40561580657959
INFO:root:current mean train loss 2138.7061111862595
INFO:root:current train perplexity5.403337478637695
INFO:root:current mean train loss 2138.5945736039507
INFO:root:current train perplexity5.404270648956299
INFO:root:current mean train loss 2138.1331287832822
INFO:root:current train perplexity5.401437282562256
INFO:root:current mean train loss 2139.7238848650895
INFO:root:current train perplexity5.401566028594971
INFO:root:current mean train loss 2140.9925808166126
INFO:root:current train perplexity5.405477046966553
INFO:root:current mean train loss 2141.1662091082044
INFO:root:current train perplexity5.408320903778076
INFO:root:current mean train loss 2140.1676257553922
INFO:root:current train perplexity5.404452323913574
INFO:root:current mean train loss 2140.3832631915884
INFO:root:current train perplexity5.4056267738342285
INFO:root:current mean train loss 2141.194906948867
INFO:root:current train perplexity5.408848285675049
INFO:root:current mean train loss 2140.982941629636
INFO:root:current train perplexity5.408912181854248
INFO:root:current mean train loss 2140.5411246348235
INFO:root:current train perplexity5.4061279296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 2139.0658972543474
INFO:root:final train perplexity: 5.403226375579834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2138.414532600565
INFO:root:eval perplexity: 5.637405872344971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/18
  9%|â–‰         | 18/200 [41:38<7:00:56, 138.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.2927001953126
INFO:root:current train perplexity5.064800262451172
INFO:root:current mean train loss 2124.296193731399
INFO:root:current train perplexity5.372730255126953
INFO:root:current mean train loss 2107.4688565882243
INFO:root:current train perplexity5.296420097351074
INFO:root:current mean train loss 2116.7620557441087
INFO:root:current train perplexity5.313986778259277
INFO:root:current mean train loss 2117.4548059534145
INFO:root:current train perplexity5.3285040855407715
INFO:root:current mean train loss 2118.5141574972927
INFO:root:current train perplexity5.337930202484131
INFO:root:current mean train loss 2120.8806697120353
INFO:root:current train perplexity5.341194152832031
INFO:root:current mean train loss 2119.515195589539
INFO:root:current train perplexity5.340132713317871
INFO:root:current mean train loss 2118.5583423306484
INFO:root:current train perplexity5.336835861206055
INFO:root:current mean train loss 2121.421330337103
INFO:root:current train perplexity5.341292381286621
INFO:root:current mean train loss 2121.4820201968673
INFO:root:current train perplexity5.344916343688965
INFO:root:current mean train loss 2123.4124173677883
INFO:root:current train perplexity5.3513288497924805
INFO:root:current mean train loss 2123.9426978653396
INFO:root:current train perplexity5.35089111328125
INFO:root:current mean train loss 2124.668543930346
INFO:root:current train perplexity5.349346160888672
INFO:root:current mean train loss 2124.847064665119
INFO:root:current train perplexity5.352033615112305
INFO:root:current mean train loss 2126.000604754983
INFO:root:current train perplexity5.355091571807861
INFO:root:current mean train loss 2126.50219308253
INFO:root:current train perplexity5.354806900024414
INFO:root:current mean train loss 2126.608442039154
INFO:root:current train perplexity5.352498531341553
INFO:root:current mean train loss 2126.1593682371017
INFO:root:current train perplexity5.349006175994873
INFO:root:current mean train loss 2126.5200808547615
INFO:root:current train perplexity5.34785270690918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it]
INFO:root:final mean train loss: 2126.3978295799943
INFO:root:final train perplexity: 5.349511623382568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2132.435636912677
INFO:root:eval perplexity: 5.6102142333984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/19
 10%|â–‰         | 19/200 [43:57<6:58:27, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2122.8654563210225
INFO:root:current train perplexity5.291603088378906
INFO:root:current mean train loss 2104.9654851194286
INFO:root:current train perplexity5.285714149475098
INFO:root:current mean train loss 2100.4985983908714
INFO:root:current train perplexity5.255089282989502
INFO:root:current mean train loss 2098.393238138708
INFO:root:current train perplexity5.261857986450195
INFO:root:current mean train loss 2106.169560003055
INFO:root:current train perplexity5.265691757202148
INFO:root:current mean train loss 2106.250807955804
INFO:root:current train perplexity5.273497104644775
INFO:root:current mean train loss 2109.095535327384
INFO:root:current train perplexity5.2758564949035645
INFO:root:current mean train loss 2110.1049268727816
INFO:root:current train perplexity5.283562660217285
INFO:root:current mean train loss 2112.2756184301816
INFO:root:current train perplexity5.2883429527282715
INFO:root:current mean train loss 2112.9375651394726
INFO:root:current train perplexity5.288857460021973
INFO:root:current mean train loss 2113.912927914972
INFO:root:current train perplexity5.287328720092773
INFO:root:current mean train loss 2115.199761756176
INFO:root:current train perplexity5.296247959136963
INFO:root:current mean train loss 2114.5643607231677
INFO:root:current train perplexity5.293981552124023
INFO:root:current mean train loss 2114.307735194958
INFO:root:current train perplexity5.292806148529053
INFO:root:current mean train loss 2113.248241140202
INFO:root:current train perplexity5.289495468139648
INFO:root:current mean train loss 2112.9617100238174
INFO:root:current train perplexity5.290966033935547
INFO:root:current mean train loss 2112.3472193707375
INFO:root:current train perplexity5.2911882400512695
INFO:root:current mean train loss 2112.386728107306
INFO:root:current train perplexity5.292069435119629
INFO:root:current mean train loss 2113.290546706165
INFO:root:current train perplexity5.296050071716309
INFO:root:current mean train loss 2113.28244968061
INFO:root:current train perplexity5.294863700866699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 2113.191028650758
INFO:root:final train perplexity: 5.294082164764404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2127.910883910267
INFO:root:eval perplexity: 5.589720249176025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/20
 10%|â–ˆ         | 20/200 [46:16<6:56:04, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2081.5706849709536
INFO:root:current train perplexity5.160088539123535
INFO:root:current mean train loss 2092.7793153172775
INFO:root:current train perplexity5.148164749145508
INFO:root:current mean train loss 2094.569097415174
INFO:root:current train perplexity5.17601203918457
INFO:root:current mean train loss 2096.899332322202
INFO:root:current train perplexity5.200835704803467
INFO:root:current mean train loss 2100.0228599600478
INFO:root:current train perplexity5.206831455230713
INFO:root:current mean train loss 2101.329945183862
INFO:root:current train perplexity5.216542720794678
INFO:root:current mean train loss 2101.9976900246966
INFO:root:current train perplexity5.229316234588623
INFO:root:current mean train loss 2101.639258770562
INFO:root:current train perplexity5.231546401977539
INFO:root:current mean train loss 2098.594950624814
INFO:root:current train perplexity5.2281670570373535
INFO:root:current mean train loss 2100.0211316840973
INFO:root:current train perplexity5.236108303070068
INFO:root:current mean train loss 2099.7663319269204
INFO:root:current train perplexity5.235294342041016
INFO:root:current mean train loss 2100.993073929811
INFO:root:current train perplexity5.236090183258057
INFO:root:current mean train loss 2102.274475935104
INFO:root:current train perplexity5.241215229034424
INFO:root:current mean train loss 2100.494249841008
INFO:root:current train perplexity5.240860462188721
INFO:root:current mean train loss 2101.1078246476504
INFO:root:current train perplexity5.242949962615967
INFO:root:current mean train loss 2100.9591429315656
INFO:root:current train perplexity5.243981838226318
INFO:root:current mean train loss 2101.356139876044
INFO:root:current train perplexity5.243093013763428
INFO:root:current mean train loss 2103.4625156396005
INFO:root:current train perplexity5.248586654663086
INFO:root:current mean train loss 2102.392499665452
INFO:root:current train perplexity5.247806072235107
INFO:root:current mean train loss 2102.9269099754424
INFO:root:current train perplexity5.2495198249816895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it]
INFO:root:final mean train loss: 2102.256388777263
INFO:root:final train perplexity: 5.248623847961426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2120.3007886088485
INFO:root:eval perplexity: 5.555423736572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/21
 10%|â–ˆ         | 21/200 [48:34<6:53:41, 138.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2081.4488285609655
INFO:root:current train perplexity5.165764808654785
INFO:root:current mean train loss 2084.2599424704526
INFO:root:current train perplexity5.196596145629883
INFO:root:current mean train loss 2079.9259762763977
INFO:root:current train perplexity5.178471565246582
INFO:root:current mean train loss 2081.4217861904185
INFO:root:current train perplexity5.1879353523254395
INFO:root:current mean train loss 2084.1956894188597
INFO:root:current train perplexity5.188169956207275
INFO:root:current mean train loss 2084.9334380883965
INFO:root:current train perplexity5.18385124206543
INFO:root:current mean train loss 2089.089059224943
INFO:root:current train perplexity5.195332050323486
INFO:root:current mean train loss 2086.462925179295
INFO:root:current train perplexity5.195051193237305
INFO:root:current mean train loss 2089.364757644796
INFO:root:current train perplexity5.195878982543945
INFO:root:current mean train loss 2090.5764632604114
INFO:root:current train perplexity5.196924209594727
INFO:root:current mean train loss 2090.662665280429
INFO:root:current train perplexity5.201471328735352
INFO:root:current mean train loss 2090.9330130712383
INFO:root:current train perplexity5.20045804977417
INFO:root:current mean train loss 2089.2416990243705
INFO:root:current train perplexity5.199094295501709
INFO:root:current mean train loss 2088.9652558723383
INFO:root:current train perplexity5.196028709411621
INFO:root:current mean train loss 2089.2187519283084
INFO:root:current train perplexity5.195846080780029
INFO:root:current mean train loss 2089.6165361968287
INFO:root:current train perplexity5.198049068450928
INFO:root:current mean train loss 2091.4057140995337
INFO:root:current train perplexity5.201692581176758
INFO:root:current mean train loss 2091.640605187905
INFO:root:current train perplexity5.20049524307251
INFO:root:current mean train loss 2091.1756615474305
INFO:root:current train perplexity5.201605319976807
INFO:root:current mean train loss 2091.804406101718
INFO:root:current train perplexity5.2026872634887695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 2091.079352289874
INFO:root:final train perplexity: 5.202560901641846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2116.9480486930684
INFO:root:eval perplexity: 5.54038143157959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/22
 11%|â–ˆ         | 22/200 [50:53<6:51:20, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2064.1363241117297
INFO:root:current train perplexity5.1251139640808105
INFO:root:current mean train loss 2083.822993107614
INFO:root:current train perplexity5.178785800933838
INFO:root:current mean train loss 2079.412769359547
INFO:root:current train perplexity5.159842491149902
INFO:root:current mean train loss 2079.097947844232
INFO:root:current train perplexity5.151238918304443
INFO:root:current mean train loss 2075.5665848391254
INFO:root:current train perplexity5.144809246063232
INFO:root:current mean train loss 2075.354037566127
INFO:root:current train perplexity5.140344619750977
INFO:root:current mean train loss 2073.3352203142413
INFO:root:current train perplexity5.130331993103027
INFO:root:current mean train loss 2072.752551632742
INFO:root:current train perplexity5.132274150848389
INFO:root:current mean train loss 2073.4418355236076
INFO:root:current train perplexity5.134317874908447
INFO:root:current mean train loss 2073.856346200941
INFO:root:current train perplexity5.138762474060059
INFO:root:current mean train loss 2074.082338302911
INFO:root:current train perplexity5.142489910125732
INFO:root:current mean train loss 2074.784984331708
INFO:root:current train perplexity5.14387845993042
INFO:root:current mean train loss 2075.771976204248
INFO:root:current train perplexity5.144285202026367
INFO:root:current mean train loss 2076.714571425625
INFO:root:current train perplexity5.1466474533081055
INFO:root:current mean train loss 2077.414782905449
INFO:root:current train perplexity5.147493839263916
INFO:root:current mean train loss 2077.5110858158178
INFO:root:current train perplexity5.151867389678955
INFO:root:current mean train loss 2077.5241821070167
INFO:root:current train perplexity5.150359630584717
INFO:root:current mean train loss 2078.4541008740043
INFO:root:current train perplexity5.154231548309326
INFO:root:current mean train loss 2079.339455314836
INFO:root:current train perplexity5.156498432159424
INFO:root:current mean train loss 2081.157760813462
INFO:root:current train perplexity5.159297943115234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it]
INFO:root:final mean train loss: 2080.3489989003206
INFO:root:final train perplexity: 5.158719062805176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2112.7051690284243
INFO:root:eval perplexity: 5.521402835845947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/23
 12%|â–ˆâ–        | 23/200 [53:11<6:48:58, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2084.3150309244793
INFO:root:current train perplexity5.133330821990967
INFO:root:current mean train loss 2078.4630942896792
INFO:root:current train perplexity5.149333477020264
INFO:root:current mean train loss 2068.226498939251
INFO:root:current train perplexity5.120068073272705
INFO:root:current mean train loss 2070.399756172376
INFO:root:current train perplexity5.1160101890563965
INFO:root:current mean train loss 2069.442894262197
INFO:root:current train perplexity5.1126837730407715
INFO:root:current mean train loss 2070.3390378790386
INFO:root:current train perplexity5.107813358306885
INFO:root:current mean train loss 2069.4553741012796
INFO:root:current train perplexity5.102489471435547
INFO:root:current mean train loss 2069.2585568198674
INFO:root:current train perplexity5.103420257568359
INFO:root:current mean train loss 2068.49603175474
INFO:root:current train perplexity5.1061530113220215
INFO:root:current mean train loss 2067.591329308712
INFO:root:current train perplexity5.108373641967773
INFO:root:current mean train loss 2068.6971197005805
INFO:root:current train perplexity5.112243175506592
INFO:root:current mean train loss 2069.4110269498424
INFO:root:current train perplexity5.111807346343994
INFO:root:current mean train loss 2069.569852701823
INFO:root:current train perplexity5.109837055206299
INFO:root:current mean train loss 2069.565723534454
INFO:root:current train perplexity5.1087422370910645
INFO:root:current mean train loss 2069.676114526531
INFO:root:current train perplexity5.111170768737793
INFO:root:current mean train loss 2070.169219318126
INFO:root:current train perplexity5.114658832550049
INFO:root:current mean train loss 2070.6423803566477
INFO:root:current train perplexity5.11455774307251
INFO:root:current mean train loss 2071.4850299515538
INFO:root:current train perplexity5.114490032196045
INFO:root:current mean train loss 2070.8266899310725
INFO:root:current train perplexity5.116217136383057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it]
INFO:root:final mean train loss: 2069.735943077191
INFO:root:final train perplexity: 5.115719795227051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2108.7836372970687
INFO:root:eval perplexity: 5.503918647766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/24
 12%|â–ˆâ–        | 24/200 [55:30<6:46:44, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2065.7952706473216
INFO:root:current train perplexity5.0745368003845215
INFO:root:current mean train loss 2063.4696261682243
INFO:root:current train perplexity5.054165840148926
INFO:root:current mean train loss 2059.256591796875
INFO:root:current train perplexity5.056553363800049
INFO:root:current mean train loss 2056.329462604336
INFO:root:current train perplexity5.030457496643066
INFO:root:current mean train loss 2054.622860620297
INFO:root:current train perplexity5.0336103439331055
INFO:root:current mean train loss 2058.1747981867143
INFO:root:current train perplexity5.058619022369385
INFO:root:current mean train loss 2055.122396302577
INFO:root:current train perplexity5.055149078369141
INFO:root:current mean train loss 2056.384413399487
INFO:root:current train perplexity5.05885124206543
INFO:root:current mean train loss 2054.7159180292556
INFO:root:current train perplexity5.059545516967773
INFO:root:current mean train loss 2054.4694575232998
INFO:root:current train perplexity5.058393478393555
INFO:root:current mean train loss 2056.160527309808
INFO:root:current train perplexity5.056900978088379
INFO:root:current mean train loss 2057.7804044397867
INFO:root:current train perplexity5.060145378112793
INFO:root:current mean train loss 2058.539845489527
INFO:root:current train perplexity5.062530994415283
INFO:root:current mean train loss 2058.364822959754
INFO:root:current train perplexity5.06527042388916
INFO:root:current mean train loss 2059.670831199055
INFO:root:current train perplexity5.064032077789307
INFO:root:current mean train loss 2061.0550401835703
INFO:root:current train perplexity5.066884994506836
INFO:root:current mean train loss 2061.9623590456304
INFO:root:current train perplexity5.071404933929443
INFO:root:current mean train loss 2062.1521778430724
INFO:root:current train perplexity5.071300506591797
INFO:root:current mean train loss 2061.4664332311195
INFO:root:current train perplexity5.073430061340332
INFO:root:current mean train loss 2062.4401696079617
INFO:root:current train perplexity5.077460765838623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 2060.6579681873563
INFO:root:final train perplexity: 5.079225540161133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2104.9239813622007
INFO:root:eval perplexity: 5.486765384674072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/25
 12%|â–ˆâ–Ž        | 25/200 [57:49<6:44:24, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2075.217498779297
INFO:root:current train perplexity5.097715854644775
INFO:root:current mean train loss 2038.9258875693045
INFO:root:current train perplexity5.003594875335693
INFO:root:current mean train loss 2040.8043654305595
INFO:root:current train perplexity5.013245582580566
INFO:root:current mean train loss 2047.3613134313512
INFO:root:current train perplexity5.027512550354004
INFO:root:current mean train loss 2050.712965479437
INFO:root:current train perplexity5.030355453491211
INFO:root:current mean train loss 2049.8453723237712
INFO:root:current train perplexity5.03082275390625
INFO:root:current mean train loss 2051.8851584410054
INFO:root:current train perplexity5.0319647789001465
INFO:root:current mean train loss 2053.5365561806693
INFO:root:current train perplexity5.036555290222168
INFO:root:current mean train loss 2053.1845103143487
INFO:root:current train perplexity5.036446571350098
INFO:root:current mean train loss 2050.5517438087627
INFO:root:current train perplexity5.036069869995117
INFO:root:current mean train loss 2050.6695103645325
INFO:root:current train perplexity5.036929130554199
INFO:root:current mean train loss 2051.1341232354107
INFO:root:current train perplexity5.037764549255371
INFO:root:current mean train loss 2049.6026175505194
INFO:root:current train perplexity5.034520626068115
INFO:root:current mean train loss 2049.3174704929133
INFO:root:current train perplexity5.033398151397705
INFO:root:current mean train loss 2048.5871003397397
INFO:root:current train perplexity5.032209396362305
INFO:root:current mean train loss 2049.4591963960743
INFO:root:current train perplexity5.034842014312744
INFO:root:current mean train loss 2051.367053628555
INFO:root:current train perplexity5.039921760559082
INFO:root:current mean train loss 2051.9055437057036
INFO:root:current train perplexity5.039921760559082
INFO:root:current mean train loss 2050.5441636871874
INFO:root:current train perplexity5.038444519042969
INFO:root:current mean train loss 2051.762704702524
INFO:root:current train perplexity5.041506290435791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it]
INFO:root:final mean train loss: 2051.17208965415
INFO:root:final train perplexity: 5.0413689613342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2102.00602126967
INFO:root:eval perplexity: 5.4738335609436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/26
 13%|â–ˆâ–Ž        | 26/200 [1:00:07<6:42:11, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2029.0054336175685
INFO:root:current train perplexity4.946680068969727
INFO:root:current mean train loss 2034.492044651762
INFO:root:current train perplexity4.99216890335083
INFO:root:current mean train loss 2032.361690283811
INFO:root:current train perplexity4.992116451263428
INFO:root:current mean train loss 2035.7589408449414
INFO:root:current train perplexity4.998169422149658
INFO:root:current mean train loss 2035.0878510421096
INFO:root:current train perplexity4.997588634490967
INFO:root:current mean train loss 2036.3089064846638
INFO:root:current train perplexity4.987915992736816
INFO:root:current mean train loss 2039.2239834075785
INFO:root:current train perplexity4.991143226623535
INFO:root:current mean train loss 2038.6393319772162
INFO:root:current train perplexity4.992435932159424
INFO:root:current mean train loss 2039.9998369976684
INFO:root:current train perplexity4.996333599090576
INFO:root:current mean train loss 2040.7523591612148
INFO:root:current train perplexity4.9983906745910645
INFO:root:current mean train loss 2041.8182507898805
INFO:root:current train perplexity4.999267578125
INFO:root:current mean train loss 2042.117672357718
INFO:root:current train perplexity4.999985218048096
INFO:root:current mean train loss 2041.296083657805
INFO:root:current train perplexity5.002152442932129
INFO:root:current mean train loss 2040.7204859290525
INFO:root:current train perplexity5.0030317306518555
INFO:root:current mean train loss 2041.795513759298
INFO:root:current train perplexity5.002072334289551
INFO:root:current mean train loss 2042.0345950117364
INFO:root:current train perplexity5.00178861618042
INFO:root:current mean train loss 2042.0362331615868
INFO:root:current train perplexity5.000316619873047
INFO:root:current mean train loss 2041.6600343199177
INFO:root:current train perplexity5.003028869628906
INFO:root:current mean train loss 2042.8400829839422
INFO:root:current train perplexity5.004067897796631
INFO:root:current mean train loss 2043.4138412514892
INFO:root:current train perplexity5.007172107696533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it]
INFO:root:final mean train loss: 2042.2178901522316
INFO:root:final train perplexity: 5.005893707275391
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2099.111822899352
INFO:root:eval perplexity: 5.461036205291748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/27
 14%|â–ˆâ–Ž        | 27/200 [1:02:26<6:40:00, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2030.719899144666
INFO:root:current train perplexity4.9109787940979
INFO:root:current mean train loss 2030.8130632231507
INFO:root:current train perplexity4.93856954574585
INFO:root:current mean train loss 2031.2949147778888
INFO:root:current train perplexity4.942636013031006
INFO:root:current mean train loss 2030.6610086963162
INFO:root:current train perplexity4.947360992431641
INFO:root:current mean train loss 2028.3175405977074
INFO:root:current train perplexity4.9446120262146
INFO:root:current mean train loss 2027.712651734711
INFO:root:current train perplexity4.946249485015869
INFO:root:current mean train loss 2032.323843263203
INFO:root:current train perplexity4.961089611053467
INFO:root:current mean train loss 2033.6962914781395
INFO:root:current train perplexity4.963616371154785
INFO:root:current mean train loss 2033.7595335775877
INFO:root:current train perplexity4.967676639556885
INFO:root:current mean train loss 2033.9648376337423
INFO:root:current train perplexity4.965538501739502
INFO:root:current mean train loss 2034.2035130174488
INFO:root:current train perplexity4.963935375213623
INFO:root:current mean train loss 2033.7783339110063
INFO:root:current train perplexity4.964746475219727
INFO:root:current mean train loss 2034.386898459236
INFO:root:current train perplexity4.9639129638671875
INFO:root:current mean train loss 2034.5985187423773
INFO:root:current train perplexity4.9676666259765625
INFO:root:current mean train loss 2033.74984854239
INFO:root:current train perplexity4.9687628746032715
INFO:root:current mean train loss 2033.7203587738938
INFO:root:current train perplexity4.967941761016846
INFO:root:current mean train loss 2033.384691705462
INFO:root:current train perplexity4.96643590927124
INFO:root:current mean train loss 2033.768865001622
INFO:root:current train perplexity4.968461990356445
INFO:root:current mean train loss 2034.7826457932126
INFO:root:current train perplexity4.970083713531494
INFO:root:current mean train loss 2034.390288090925
INFO:root:current train perplexity4.971534252166748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 2033.5602692773832
INFO:root:final train perplexity: 4.971829414367676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2097.2309643900985
INFO:root:eval perplexity: 5.45273494720459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/28
 14%|â–ˆâ–        | 28/200 [1:04:45<6:37:38, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1996.6258463541667
INFO:root:current train perplexity4.889347553253174
INFO:root:current mean train loss 2014.417400251116
INFO:root:current train perplexity4.900291919708252
INFO:root:current mean train loss 2017.2020188210226
INFO:root:current train perplexity4.8914289474487305
INFO:root:current mean train loss 2014.0727496744792
INFO:root:current train perplexity4.884517669677734
INFO:root:current mean train loss 2015.138368883635
INFO:root:current train perplexity4.897034645080566
INFO:root:current mean train loss 2020.505974439538
INFO:root:current train perplexity4.909712791442871
INFO:root:current mean train loss 2022.8429678457755
INFO:root:current train perplexity4.917722225189209
INFO:root:current mean train loss 2027.1934031628025
INFO:root:current train perplexity4.918002128601074
INFO:root:current mean train loss 2028.0817215401785
INFO:root:current train perplexity4.9213175773620605
INFO:root:current mean train loss 2028.4090410907452
INFO:root:current train perplexity4.925164699554443
INFO:root:current mean train loss 2028.0460444676598
INFO:root:current train perplexity4.930542945861816
INFO:root:current mean train loss 2028.2877195187832
INFO:root:current train perplexity4.933676242828369
INFO:root:current mean train loss 2027.4437216605393
INFO:root:current train perplexity4.934408187866211
INFO:root:current mean train loss 2027.1005487393466
INFO:root:current train perplexity4.934110641479492
INFO:root:current mean train loss 2027.6182444220074
INFO:root:current train perplexity4.935009956359863
INFO:root:current mean train loss 2027.6362684461806
INFO:root:current train perplexity4.936802387237549
INFO:root:current mean train loss 2026.0279162051072
INFO:root:current train perplexity4.933847427368164
INFO:root:current mean train loss 2024.9682467952246
INFO:root:current train perplexity4.933750629425049
INFO:root:current mean train loss 2024.4266222005208
INFO:root:current train perplexity4.9355974197387695
INFO:root:current mean train loss 2025.3390638597705
INFO:root:current train perplexity4.937816143035889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it]
INFO:root:final mean train loss: 2024.8000499053971
INFO:root:final train perplexity: 4.93759822845459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2093.895792210356
INFO:root:eval perplexity: 5.438047409057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/29
 14%|â–ˆâ–        | 29/200 [1:07:04<6:35:27, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2018.6080255923064
INFO:root:current train perplexity4.879582405090332
INFO:root:current mean train loss 2028.6811129252117
INFO:root:current train perplexity4.900149345397949
INFO:root:current mean train loss 2027.7900432429901
INFO:root:current train perplexity4.894665241241455
INFO:root:current mean train loss 2025.546026113082
INFO:root:current train perplexity4.8971381187438965
INFO:root:current mean train loss 2022.3342922799955
INFO:root:current train perplexity4.892624855041504
INFO:root:current mean train loss 2024.1335251266892
INFO:root:current train perplexity4.898909091949463
INFO:root:current mean train loss 2021.3765687446373
INFO:root:current train perplexity4.8963141441345215
INFO:root:current mean train loss 2020.1293849752408
INFO:root:current train perplexity4.8943023681640625
INFO:root:current mean train loss 2021.0293379300379
INFO:root:current train perplexity4.898036003112793
INFO:root:current mean train loss 2020.8080445566486
INFO:root:current train perplexity4.904428482055664
INFO:root:current mean train loss 2020.66893301604
INFO:root:current train perplexity4.906673431396484
INFO:root:current mean train loss 2021.0741883348298
INFO:root:current train perplexity4.909252643585205
INFO:root:current mean train loss 2019.8397125149659
INFO:root:current train perplexity4.906636714935303
INFO:root:current mean train loss 2019.692906697591
INFO:root:current train perplexity4.908688068389893
INFO:root:current mean train loss 2018.0192976637118
INFO:root:current train perplexity4.904693126678467
INFO:root:current mean train loss 2017.073924232368
INFO:root:current train perplexity4.906013011932373
INFO:root:current mean train loss 2016.4451091937703
INFO:root:current train perplexity4.906213760375977
INFO:root:current mean train loss 2016.1190544537135
INFO:root:current train perplexity4.907711029052734
INFO:root:current mean train loss 2017.6527071866121
INFO:root:current train perplexity4.908928394317627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 2017.1111088847488
INFO:root:final train perplexity: 4.907747268676758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2092.686232113669
INFO:root:eval perplexity: 5.432729721069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/30
 15%|â–ˆâ–Œ        | 30/200 [1:09:22<6:33:01, 138.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1983.7836235894097
INFO:root:current train perplexity4.792764663696289
INFO:root:current mean train loss 2016.2817584396503
INFO:root:current train perplexity4.850873947143555
INFO:root:current mean train loss 2011.4530327171801
INFO:root:current train perplexity4.860438823699951
INFO:root:current mean train loss 2011.5077919574233
INFO:root:current train perplexity4.86272668838501
INFO:root:current mean train loss 2008.0749195350702
INFO:root:current train perplexity4.851825714111328
INFO:root:current mean train loss 2007.0268698581779
INFO:root:current train perplexity4.860414981842041
INFO:root:current mean train loss 2009.278510333282
INFO:root:current train perplexity4.86314582824707
INFO:root:current mean train loss 2008.1613752314
INFO:root:current train perplexity4.85929012298584
INFO:root:current mean train loss 2009.6293625424908
INFO:root:current train perplexity4.861473560333252
INFO:root:current mean train loss 2010.6631965930967
INFO:root:current train perplexity4.865569114685059
INFO:root:current mean train loss 2011.6917550396045
INFO:root:current train perplexity4.86901330947876
INFO:root:current mean train loss 2011.068400872302
INFO:root:current train perplexity4.870654582977295
INFO:root:current mean train loss 2010.7100158640922
INFO:root:current train perplexity4.872109889984131
INFO:root:current mean train loss 2010.4194845107788
INFO:root:current train perplexity4.870790004730225
INFO:root:current mean train loss 2010.9479353223142
INFO:root:current train perplexity4.872502326965332
INFO:root:current mean train loss 2011.3898170223451
INFO:root:current train perplexity4.874162673950195
INFO:root:current mean train loss 2011.4645777596236
INFO:root:current train perplexity4.875405311584473
INFO:root:current mean train loss 2011.1332284961966
INFO:root:current train perplexity4.87620210647583
INFO:root:current mean train loss 2010.511611390206
INFO:root:current train perplexity4.875405788421631
INFO:root:current mean train loss 2010.4379665400734
INFO:root:current train perplexity4.877885341644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 2008.9542334513778
INFO:root:final train perplexity: 4.876277923583984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2089.6025723937555
INFO:root:eval perplexity: 5.419198513031006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/31
 16%|â–ˆâ–Œ        | 31/200 [1:11:41<6:30:38, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.5109346829927
INFO:root:current train perplexity4.7745137214660645
INFO:root:current mean train loss 1973.7979784768725
INFO:root:current train perplexity4.7761759757995605
INFO:root:current mean train loss 1989.0054791205753
INFO:root:current train perplexity4.813445091247559
INFO:root:current mean train loss 1996.679832037241
INFO:root:current train perplexity4.829583168029785
INFO:root:current mean train loss 1995.3610000252163
INFO:root:current train perplexity4.816657066345215
INFO:root:current mean train loss 1999.3259154345146
INFO:root:current train perplexity4.82466983795166
INFO:root:current mean train loss 1997.2522111106605
INFO:root:current train perplexity4.8281025886535645
INFO:root:current mean train loss 1994.7165328937458
INFO:root:current train perplexity4.823433876037598
INFO:root:current mean train loss 1994.8978986763204
INFO:root:current train perplexity4.8241424560546875
INFO:root:current mean train loss 1996.1805649298055
INFO:root:current train perplexity4.8298821449279785
INFO:root:current mean train loss 1997.6778957076938
INFO:root:current train perplexity4.834771156311035
INFO:root:current mean train loss 1998.063480465281
INFO:root:current train perplexity4.837291717529297
INFO:root:current mean train loss 1998.992618629244
INFO:root:current train perplexity4.838973522186279
INFO:root:current mean train loss 1998.881520359045
INFO:root:current train perplexity4.84234619140625
INFO:root:current mean train loss 1999.7898539025518
INFO:root:current train perplexity4.8453450202941895
INFO:root:current mean train loss 2001.3839747277657
INFO:root:current train perplexity4.84818172454834
INFO:root:current mean train loss 2001.6285712698436
INFO:root:current train perplexity4.847067832946777
INFO:root:current mean train loss 2002.0899208395947
INFO:root:current train perplexity4.849533557891846
INFO:root:current mean train loss 2002.7933858347096
INFO:root:current train perplexity4.850465774536133
INFO:root:current mean train loss 2001.8326561156339
INFO:root:current train perplexity4.847539901733398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it]
INFO:root:final mean train loss: 2001.4768674603267
INFO:root:final train perplexity: 4.847606182098389
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2087.5791699565048
INFO:root:eval perplexity: 5.410337924957275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/32
 16%|â–ˆâ–Œ        | 32/200 [1:14:00<6:28:25, 138.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1986.6511457576307
INFO:root:current train perplexity4.768095016479492
INFO:root:current mean train loss 1980.5549820052993
INFO:root:current train perplexity4.792202472686768
INFO:root:current mean train loss 1981.7698301464443
INFO:root:current train perplexity4.802384853363037
INFO:root:current mean train loss 1987.6586323284894
INFO:root:current train perplexity4.806116580963135
INFO:root:current mean train loss 1988.8503635656214
INFO:root:current train perplexity4.803505897521973
INFO:root:current mean train loss 1992.917660988936
INFO:root:current train perplexity4.80585241317749
INFO:root:current mean train loss 1990.667718914026
INFO:root:current train perplexity4.797405242919922
INFO:root:current mean train loss 1989.7351990978298
INFO:root:current train perplexity4.798609256744385
INFO:root:current mean train loss 1990.5255541094398
INFO:root:current train perplexity4.800008773803711
INFO:root:current mean train loss 1990.9143022393623
INFO:root:current train perplexity4.805510520935059
INFO:root:current mean train loss 1989.467408631015
INFO:root:current train perplexity4.807946681976318
INFO:root:current mean train loss 1990.500280452004
INFO:root:current train perplexity4.80743408203125
INFO:root:current mean train loss 1989.739150865943
INFO:root:current train perplexity4.8077311515808105
INFO:root:current mean train loss 1990.0254993339306
INFO:root:current train perplexity4.8068060874938965
INFO:root:current mean train loss 1991.3992278693206
INFO:root:current train perplexity4.810942649841309
INFO:root:current mean train loss 1991.9955212932396
INFO:root:current train perplexity4.8116583824157715
INFO:root:current mean train loss 1992.4342555895275
INFO:root:current train perplexity4.8116631507873535
INFO:root:current mean train loss 1992.2771557070917
INFO:root:current train perplexity4.811202049255371
INFO:root:current mean train loss 1993.7040255914483
INFO:root:current train perplexity4.81671667098999
INFO:root:current mean train loss 1994.4526434410986
INFO:root:current train perplexity4.819066524505615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 1994.0338668476977
INFO:root:final train perplexity: 4.819234848022461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2086.0413177706673
INFO:root:eval perplexity: 5.403613567352295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/33
 16%|â–ˆâ–‹        | 33/200 [1:16:19<6:26:04, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1989.9801106770833
INFO:root:current train perplexity4.753464221954346
INFO:root:current mean train loss 1987.0389884948731
INFO:root:current train perplexity4.770212650299072
INFO:root:current mean train loss 1986.4246971717248
INFO:root:current train perplexity4.761845588684082
INFO:root:current mean train loss 1981.3091406928168
INFO:root:current train perplexity4.770057201385498
INFO:root:current mean train loss 1983.1597844662874
INFO:root:current train perplexity4.778615951538086
INFO:root:current mean train loss 1988.2847473144532
INFO:root:current train perplexity4.779226303100586
INFO:root:current mean train loss 1988.4045241847182
INFO:root:current train perplexity4.786269187927246
INFO:root:current mean train loss 1985.849926275956
INFO:root:current train perplexity4.78270959854126
INFO:root:current mean train loss 1986.581663477698
INFO:root:current train perplexity4.787746429443359
INFO:root:current mean train loss 1984.514950434367
INFO:root:current train perplexity4.787693977355957
INFO:root:current mean train loss 1984.0029175956295
INFO:root:current train perplexity4.786652565002441
INFO:root:current mean train loss 1984.5882010624327
INFO:root:current train perplexity4.792675018310547
INFO:root:current mean train loss 1984.6899253239708
INFO:root:current train perplexity4.790208339691162
INFO:root:current mean train loss 1985.2423784143784
INFO:root:current train perplexity4.790131092071533
INFO:root:current mean train loss 1987.1123299376604
INFO:root:current train perplexity4.79132080078125
INFO:root:current mean train loss 1986.768227758163
INFO:root:current train perplexity4.791749000549316
INFO:root:current mean train loss 1987.0741931593561
INFO:root:current train perplexity4.793132305145264
INFO:root:current mean train loss 1987.0001888621937
INFO:root:current train perplexity4.792111396789551
INFO:root:current mean train loss 1987.773413545342
INFO:root:current train perplexity4.792753219604492
INFO:root:current mean train loss 1987.2123665323063
INFO:root:current train perplexity4.791345119476318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.92s/it]
INFO:root:final mean train loss: 1986.8446142799735
INFO:root:final train perplexity: 4.791987419128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2083.8044931398217
INFO:root:eval perplexity: 5.39384651184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/34
 17%|â–ˆâ–‹        | 34/200 [1:18:37<6:23:54, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.1292027064733
INFO:root:current train perplexity4.6823015213012695
INFO:root:current mean train loss 1960.5514709127824
INFO:root:current train perplexity4.714059352874756
INFO:root:current mean train loss 1973.012188963081
INFO:root:current train perplexity4.729367256164551
INFO:root:current mean train loss 1976.11413347563
INFO:root:current train perplexity4.742191314697266
INFO:root:current mean train loss 1975.4021761272438
INFO:root:current train perplexity4.743834018707275
INFO:root:current mean train loss 1975.2835777983507
INFO:root:current train perplexity4.743177890777588
INFO:root:current mean train loss 1972.9310917593705
INFO:root:current train perplexity4.745334148406982
INFO:root:current mean train loss 1973.4366505351613
INFO:root:current train perplexity4.745167255401611
INFO:root:current mean train loss 1974.4008768183883
INFO:root:current train perplexity4.749076843261719
INFO:root:current mean train loss 1973.5044327641217
INFO:root:current train perplexity4.747580051422119
INFO:root:current mean train loss 1975.1999557055913
INFO:root:current train perplexity4.750723838806152
INFO:root:current mean train loss 1975.6418056698703
INFO:root:current train perplexity4.755131721496582
INFO:root:current mean train loss 1977.3529757243539
INFO:root:current train perplexity4.760275363922119
INFO:root:current mean train loss 1978.7272248001486
INFO:root:current train perplexity4.762723445892334
INFO:root:current mean train loss 1980.2720670396602
INFO:root:current train perplexity4.763563632965088
INFO:root:current mean train loss 1980.84718050863
INFO:root:current train perplexity4.7681193351745605
INFO:root:current mean train loss 1980.2584253992434
INFO:root:current train perplexity4.765509605407715
INFO:root:current mean train loss 1980.1319439254185
INFO:root:current train perplexity4.765468597412109
INFO:root:current mean train loss 1980.2211103078591
INFO:root:current train perplexity4.766922950744629
INFO:root:current mean train loss 1980.6313743301878
INFO:root:current train perplexity4.766375541687012

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it]
INFO:root:final mean train loss: 1980.0079370018693
INFO:root:final train perplexity: 4.766219615936279
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2083.378962090675
INFO:root:eval perplexity: 5.3919901847839355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/35
 18%|â–ˆâ–Š        | 35/200 [1:20:56<6:21:34, 138.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.840955369016
INFO:root:current train perplexity4.687049388885498
INFO:root:current mean train loss 1962.782434207877
INFO:root:current train perplexity4.7074127197265625
INFO:root:current mean train loss 1963.8464546463117
INFO:root:current train perplexity4.698461055755615
INFO:root:current mean train loss 1964.375604464923
INFO:root:current train perplexity4.705156326293945
INFO:root:current mean train loss 1967.3897467856466
INFO:root:current train perplexity4.711309432983398
INFO:root:current mean train loss 1971.0923104334358
INFO:root:current train perplexity4.716576099395752
INFO:root:current mean train loss 1973.1376733257723
INFO:root:current train perplexity4.7267231941223145
INFO:root:current mean train loss 1970.975827003306
INFO:root:current train perplexity4.72572660446167
INFO:root:current mean train loss 1973.008596945129
INFO:root:current train perplexity4.729228496551514
INFO:root:current mean train loss 1974.356238259636
INFO:root:current train perplexity4.731241703033447
INFO:root:current mean train loss 1976.400700821955
INFO:root:current train perplexity4.735663414001465
INFO:root:current mean train loss 1975.2019580732438
INFO:root:current train perplexity4.729937553405762
INFO:root:current mean train loss 1974.5756451991463
INFO:root:current train perplexity4.731418609619141
INFO:root:current mean train loss 1976.0759597843996
INFO:root:current train perplexity4.735939025878906
INFO:root:current mean train loss 1976.5378408163906
INFO:root:current train perplexity4.736057758331299
INFO:root:current mean train loss 1976.5073552341055
INFO:root:current train perplexity4.737605571746826
INFO:root:current mean train loss 1975.362104503717
INFO:root:current train perplexity4.737578392028809
INFO:root:current mean train loss 1975.4378787309695
INFO:root:current train perplexity4.739055633544922
INFO:root:current mean train loss 1974.958415658824
INFO:root:current train perplexity4.738934516906738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it]
INFO:root:final mean train loss: 1973.1008844341945
INFO:root:final train perplexity: 4.740326881408691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2081.9355161409853
INFO:root:eval perplexity: 5.385700702667236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/36
 18%|â–ˆâ–Š        | 36/200 [1:23:15<6:19:11, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1948.5817427201705
INFO:root:current train perplexity4.5577778816223145
INFO:root:current mean train loss 1960.4058573954815
INFO:root:current train perplexity4.653587341308594
INFO:root:current mean train loss 1963.3889860180318
INFO:root:current train perplexity4.65294885635376
INFO:root:current mean train loss 1970.7102847574608
INFO:root:current train perplexity4.67300271987915
INFO:root:current mean train loss 1969.838667895092
INFO:root:current train perplexity4.686291217803955
INFO:root:current mean train loss 1972.9626424233275
INFO:root:current train perplexity4.696939468383789
INFO:root:current mean train loss 1970.7303121164075
INFO:root:current train perplexity4.699521541595459
INFO:root:current mean train loss 1968.0604406000023
INFO:root:current train perplexity4.703536033630371
INFO:root:current mean train loss 1966.5873976776838
INFO:root:current train perplexity4.702831268310547
INFO:root:current mean train loss 1965.6328118300203
INFO:root:current train perplexity4.702330589294434
INFO:root:current mean train loss 1965.6586118371738
INFO:root:current train perplexity4.706638336181641
INFO:root:current mean train loss 1967.4024063783331
INFO:root:current train perplexity4.711740493774414
INFO:root:current mean train loss 1965.6226863089325
INFO:root:current train perplexity4.713640213012695
INFO:root:current mean train loss 1966.2507562586409
INFO:root:current train perplexity4.714768409729004
INFO:root:current mean train loss 1965.7898839440943
INFO:root:current train perplexity4.712972164154053
INFO:root:current mean train loss 1966.1255949210995
INFO:root:current train perplexity4.715918064117432
INFO:root:current mean train loss 1966.9727827151469
INFO:root:current train perplexity4.715703010559082
INFO:root:current mean train loss 1966.5314521901028
INFO:root:current train perplexity4.715945243835449
INFO:root:current mean train loss 1967.2417750492864
INFO:root:current train perplexity4.715063095092773
INFO:root:current mean train loss 1966.36722467683
INFO:root:current train perplexity4.714015483856201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1966.1439497693284
INFO:root:final train perplexity: 4.714389324188232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2082.367045517509
INFO:root:eval perplexity: 5.387579441070557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/37
 18%|â–ˆâ–Š        | 37/200 [1:25:34<6:16:49, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.0727321079798
INFO:root:current train perplexity4.672652244567871
INFO:root:current mean train loss 1960.9052076339722
INFO:root:current train perplexity4.666456699371338
INFO:root:current mean train loss 1951.0197186386376
INFO:root:current train perplexity4.639019966125488
INFO:root:current mean train loss 1953.3637900003573
INFO:root:current train perplexity4.649591445922852
INFO:root:current mean train loss 1954.8481120171948
INFO:root:current train perplexity4.654427528381348
INFO:root:current mean train loss 1954.0755647601504
INFO:root:current train perplexity4.6599931716918945
INFO:root:current mean train loss 1959.4828131608901
INFO:root:current train perplexity4.6706929206848145
INFO:root:current mean train loss 1958.1536425915392
INFO:root:current train perplexity4.670454025268555
INFO:root:current mean train loss 1957.2799856582126
INFO:root:current train perplexity4.668332099914551
INFO:root:current mean train loss 1957.4798339317585
INFO:root:current train perplexity4.6646952629089355
INFO:root:current mean train loss 1956.8604254221639
INFO:root:current train perplexity4.665023326873779
INFO:root:current mean train loss 1956.663628652586
INFO:root:current train perplexity4.671189785003662
INFO:root:current mean train loss 1957.422796591097
INFO:root:current train perplexity4.674278259277344
INFO:root:current mean train loss 1958.9672657610422
INFO:root:current train perplexity4.679100036621094
INFO:root:current mean train loss 1958.34380787227
INFO:root:current train perplexity4.680140018463135
INFO:root:current mean train loss 1959.0506034970908
INFO:root:current train perplexity4.683656692504883
INFO:root:current mean train loss 1959.959603799356
INFO:root:current train perplexity4.686915874481201
INFO:root:current mean train loss 1958.9538801687736
INFO:root:current train perplexity4.686330318450928
INFO:root:current mean train loss 1958.7370306970777
INFO:root:current train perplexity4.684788227081299
INFO:root:current mean train loss 1960.0798983751986
INFO:root:current train perplexity4.688381671905518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it]
INFO:root:final mean train loss: 1959.5536744333672
INFO:root:final train perplexity: 4.6899495124816895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2079.5288276401816
INFO:root:eval perplexity: 5.375226974487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/38
 19%|â–ˆâ–‰        | 38/200 [1:27:52<6:14:28, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1968.628662109375
INFO:root:current train perplexity4.672580718994141
INFO:root:current mean train loss 1956.3825355266702
INFO:root:current train perplexity4.62213659286499
INFO:root:current mean train loss 1947.4798469387756
INFO:root:current train perplexity4.624334812164307
INFO:root:current mean train loss 1950.2879950039628
INFO:root:current train perplexity4.632103443145752
INFO:root:current mean train loss 1949.4391236723138
INFO:root:current train perplexity4.641916275024414
INFO:root:current mean train loss 1950.326100200688
INFO:root:current train perplexity4.643497943878174
INFO:root:current mean train loss 1951.3463221823522
INFO:root:current train perplexity4.647163391113281
INFO:root:current mean train loss 1954.9028243301698
INFO:root:current train perplexity4.651998043060303
INFO:root:current mean train loss 1955.074064464682
INFO:root:current train perplexity4.648699760437012
INFO:root:current mean train loss 1955.452103484623
INFO:root:current train perplexity4.648873805999756
INFO:root:current mean train loss 1956.2335986561752
INFO:root:current train perplexity4.654562473297119
INFO:root:current mean train loss 1956.1019651721138
INFO:root:current train perplexity4.653082847595215
INFO:root:current mean train loss 1955.0110315284576
INFO:root:current train perplexity4.651440620422363
INFO:root:current mean train loss 1955.4054539563488
INFO:root:current train perplexity4.652894020080566
INFO:root:current mean train loss 1956.3543760306281
INFO:root:current train perplexity4.657746315002441
INFO:root:current mean train loss 1955.59897911294
INFO:root:current train perplexity4.6607866287231445
INFO:root:current mean train loss 1955.6125768041177
INFO:root:current train perplexity4.664324760437012
INFO:root:current mean train loss 1954.7646334672725
INFO:root:current train perplexity4.665566444396973
INFO:root:current mean train loss 1953.6783424770283
INFO:root:current train perplexity4.664176940917969
INFO:root:current mean train loss 1953.4270928311778
INFO:root:current train perplexity4.6652398109436035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it]
INFO:root:final mean train loss: 1952.9137736987539
INFO:root:final train perplexity: 4.665454864501953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2080.980254477643
INFO:root:eval perplexity: 5.381540775299072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/39
 20%|â–ˆâ–‰        | 39/200 [1:30:11<6:12:13, 138.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.7616459015876
INFO:root:current train perplexity4.559950828552246
INFO:root:current mean train loss 1933.5418874481577
INFO:root:current train perplexity4.574177265167236
INFO:root:current mean train loss 1941.9381229313276
INFO:root:current train perplexity4.596979141235352
INFO:root:current mean train loss 1944.1315536920538
INFO:root:current train perplexity4.613360404968262
INFO:root:current mean train loss 1941.4360766390184
INFO:root:current train perplexity4.617737770080566
INFO:root:current mean train loss 1941.6513261353841
INFO:root:current train perplexity4.618334770202637
INFO:root:current mean train loss 1936.7517997073262
INFO:root:current train perplexity4.607591152191162
INFO:root:current mean train loss 1939.2666585927248
INFO:root:current train perplexity4.615923881530762
INFO:root:current mean train loss 1941.5595249963746
INFO:root:current train perplexity4.619197845458984
INFO:root:current mean train loss 1941.1698793661074
INFO:root:current train perplexity4.622467994689941
INFO:root:current mean train loss 1940.604169885093
INFO:root:current train perplexity4.619302749633789
INFO:root:current mean train loss 1939.6645439528763
INFO:root:current train perplexity4.623589515686035
INFO:root:current mean train loss 1940.6584012232568
INFO:root:current train perplexity4.627636432647705
INFO:root:current mean train loss 1942.1818526795957
INFO:root:current train perplexity4.631966590881348
INFO:root:current mean train loss 1943.4905676887397
INFO:root:current train perplexity4.634401798248291
INFO:root:current mean train loss 1944.1941879213848
INFO:root:current train perplexity4.636073589324951
INFO:root:current mean train loss 1944.9092089931887
INFO:root:current train perplexity4.636224746704102
INFO:root:current mean train loss 1946.6088572057233
INFO:root:current train perplexity4.640738010406494
INFO:root:current mean train loss 1947.2201666581004
INFO:root:current train perplexity4.642849922180176
INFO:root:current mean train loss 1948.4341615449398
INFO:root:current train perplexity4.6468963623046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.45s/it]
INFO:root:final mean train loss: 1947.863338406977
INFO:root:final train perplexity: 4.646908760070801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2078.8647716332835
INFO:root:eval perplexity: 5.372341156005859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/40
 20%|â–ˆâ–ˆ        | 40/200 [1:32:29<6:09:39, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1951.1774067939082
INFO:root:current train perplexity4.578738212585449
INFO:root:current mean train loss 1930.7486040339124
INFO:root:current train perplexity4.577062129974365
INFO:root:current mean train loss 1942.765884016577
INFO:root:current train perplexity4.599457740783691
INFO:root:current mean train loss 1939.2984657790855
INFO:root:current train perplexity4.597651481628418
INFO:root:current mean train loss 1940.5776825906837
INFO:root:current train perplexity4.605370998382568
INFO:root:current mean train loss 1940.149116371168
INFO:root:current train perplexity4.606998920440674
INFO:root:current mean train loss 1942.3684813734008
INFO:root:current train perplexity4.612547874450684
INFO:root:current mean train loss 1942.5119371916119
INFO:root:current train perplexity4.616767406463623
INFO:root:current mean train loss 1941.1629601175875
INFO:root:current train perplexity4.615303039550781
INFO:root:current mean train loss 1942.4490732381976
INFO:root:current train perplexity4.618128299713135
INFO:root:current mean train loss 1943.0798953023634
INFO:root:current train perplexity4.619089126586914
INFO:root:current mean train loss 1943.419364016778
INFO:root:current train perplexity4.621922016143799
INFO:root:current mean train loss 1942.570998632507
INFO:root:current train perplexity4.6206231117248535
INFO:root:current mean train loss 1940.5906083049595
INFO:root:current train perplexity4.616323947906494
INFO:root:current mean train loss 1940.0269947890256
INFO:root:current train perplexity4.616227149963379
INFO:root:current mean train loss 1941.638268865159
INFO:root:current train perplexity4.619825839996338
INFO:root:current mean train loss 1941.436156572225
INFO:root:current train perplexity4.620972156524658
INFO:root:current mean train loss 1940.7981798966457
INFO:root:current train perplexity4.619919776916504
INFO:root:current mean train loss 1940.0784710716098
INFO:root:current train perplexity4.619174480438232
INFO:root:current mean train loss 1941.1044996511218
INFO:root:current train perplexity4.620649337768555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it]
INFO:root:final mean train loss: 1940.6408655702376
INFO:root:final train perplexity: 4.6205153465271
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2077.9541699565048
INFO:root:eval perplexity: 5.368386268615723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/41
 20%|â–ˆâ–ˆ        | 41/200 [1:34:48<6:07:21, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1908.6666196187336
INFO:root:current train perplexity4.515312194824219
INFO:root:current mean train loss 1921.3330974968112
INFO:root:current train perplexity4.548852920532227
INFO:root:current mean train loss 1928.931746611724
INFO:root:current train perplexity4.571616172790527
INFO:root:current mean train loss 1928.9800276322799
INFO:root:current train perplexity4.566095352172852
INFO:root:current mean train loss 1929.7679517192225
INFO:root:current train perplexity4.576376914978027
INFO:root:current mean train loss 1923.5636678606072
INFO:root:current train perplexity4.5679402351379395
INFO:root:current mean train loss 1922.956258664186
INFO:root:current train perplexity4.575159549713135
INFO:root:current mean train loss 1925.1395559646376
INFO:root:current train perplexity4.579152584075928
INFO:root:current mean train loss 1927.8617698124476
INFO:root:current train perplexity4.580626010894775
INFO:root:current mean train loss 1929.041750498086
INFO:root:current train perplexity4.582555770874023
INFO:root:current mean train loss 1931.3360702626026
INFO:root:current train perplexity4.5892767906188965
INFO:root:current mean train loss 1930.5104866155414
INFO:root:current train perplexity4.588215351104736
INFO:root:current mean train loss 1933.1814317114558
INFO:root:current train perplexity4.591855049133301
INFO:root:current mean train loss 1933.9057064548263
INFO:root:current train perplexity4.593400955200195
INFO:root:current mean train loss 1934.4799067043366
INFO:root:current train perplexity4.594966411590576
INFO:root:current mean train loss 1933.7505686671514
INFO:root:current train perplexity4.595649242401123
INFO:root:current mean train loss 1933.7133025403293
INFO:root:current train perplexity4.6003737449646
INFO:root:current mean train loss 1935.1201462777526
INFO:root:current train perplexity4.602717876434326
INFO:root:current mean train loss 1935.789227256292
INFO:root:current train perplexity4.6048054695129395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 1935.7608143031687
INFO:root:final train perplexity: 4.602766513824463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2078.148348760943
INFO:root:eval perplexity: 5.369229793548584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/42
 21%|â–ˆâ–ˆ        | 42/200 [1:37:07<6:05:02, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1912.8643423227163
INFO:root:current train perplexity4.507882595062256
INFO:root:current mean train loss 1911.5624729932938
INFO:root:current train perplexity4.538698673248291
INFO:root:current mean train loss 1908.391435936583
INFO:root:current train perplexity4.546071529388428
INFO:root:current mean train loss 1913.1678837297823
INFO:root:current train perplexity4.533336639404297
INFO:root:current mean train loss 1914.5478719568137
INFO:root:current train perplexity4.546499729156494
INFO:root:current mean train loss 1918.5731976901345
INFO:root:current train perplexity4.556568145751953
INFO:root:current mean train loss 1918.2063171486286
INFO:root:current train perplexity4.564284801483154
INFO:root:current mean train loss 1919.8307850370902
INFO:root:current train perplexity4.562189102172852
INFO:root:current mean train loss 1922.2490229870562
INFO:root:current train perplexity4.566497325897217
INFO:root:current mean train loss 1923.5082704308
INFO:root:current train perplexity4.568910121917725
INFO:root:current mean train loss 1923.3058933811622
INFO:root:current train perplexity4.567254066467285
INFO:root:current mean train loss 1925.5819419730599
INFO:root:current train perplexity4.570047378540039
INFO:root:current mean train loss 1926.2920363662859
INFO:root:current train perplexity4.5711846351623535
INFO:root:current mean train loss 1927.6226200472736
INFO:root:current train perplexity4.571957588195801
INFO:root:current mean train loss 1928.7247545116772
INFO:root:current train perplexity4.574756622314453
INFO:root:current mean train loss 1929.0124552059237
INFO:root:current train perplexity4.57481050491333
INFO:root:current mean train loss 1930.2764195574048
INFO:root:current train perplexity4.578385829925537
INFO:root:current mean train loss 1929.5872831951438
INFO:root:current train perplexity4.577139854431152
INFO:root:current mean train loss 1929.2282924241804
INFO:root:current train perplexity4.577073574066162
INFO:root:current mean train loss 1929.099207238508
INFO:root:current train perplexity4.577601909637451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.00s/it]
INFO:root:final mean train loss: 1929.2202691690404
INFO:root:final train perplexity: 4.579084396362305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2077.3110931612923
INFO:root:eval perplexity: 5.36559534072876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/43
 22%|â–ˆâ–ˆâ–       | 43/200 [1:39:26<6:03:00, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1882.5087931315104
INFO:root:current train perplexity4.560063362121582
INFO:root:current mean train loss 1909.0773362379807
INFO:root:current train perplexity4.56090784072876
INFO:root:current mean train loss 1910.0875201681386
INFO:root:current train perplexity4.549427509307861
INFO:root:current mean train loss 1916.285292376894
INFO:root:current train perplexity4.553035736083984
INFO:root:current mean train loss 1917.686544444949
INFO:root:current train perplexity4.549532890319824
INFO:root:current mean train loss 1918.5922427771227
INFO:root:current train perplexity4.551133155822754
INFO:root:current mean train loss 1918.1902161613343
INFO:root:current train perplexity4.548316955566406
INFO:root:current mean train loss 1920.7345831884097
INFO:root:current train perplexity4.549960613250732
INFO:root:current mean train loss 1920.4736885530403
INFO:root:current train perplexity4.550179481506348
INFO:root:current mean train loss 1923.3191251365088
INFO:root:current train perplexity4.552256107330322
INFO:root:current mean train loss 1925.1432153794372
INFO:root:current train perplexity4.5554399490356445
INFO:root:current mean train loss 1924.7171954939852
INFO:root:current train perplexity4.554288864135742
INFO:root:current mean train loss 1923.3461360280107
INFO:root:current train perplexity4.557419776916504
INFO:root:current mean train loss 1923.3142729565614
INFO:root:current train perplexity4.555214881896973
INFO:root:current mean train loss 1924.1994366839215
INFO:root:current train perplexity4.558416843414307
INFO:root:current mean train loss 1925.2198622759652
INFO:root:current train perplexity4.561334133148193
INFO:root:current mean train loss 1924.2181093180839
INFO:root:current train perplexity4.560367584228516
INFO:root:current mean train loss 1925.5006529703305
INFO:root:current train perplexity4.560286045074463
INFO:root:current mean train loss 1924.951151596653
INFO:root:current train perplexity4.559732913970947
INFO:root:current mean train loss 1924.5180087865326
INFO:root:current train perplexity4.560060024261475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.84s/it]
INFO:root:final mean train loss: 1924.2098900837784
INFO:root:final train perplexity: 4.561026573181152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2076.2564099900264
INFO:root:eval perplexity: 5.361021518707275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/44
 22%|â–ˆâ–ˆâ–       | 44/200 [1:41:44<6:00:43, 138.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.7170695852726
INFO:root:current train perplexity4.474595069885254
INFO:root:current mean train loss 1918.3163539341517
INFO:root:current train perplexity4.504712104797363
INFO:root:current mean train loss 1925.1734801998987
INFO:root:current train perplexity4.509927272796631
INFO:root:current mean train loss 1919.1967115594605
INFO:root:current train perplexity4.512045860290527
INFO:root:current mean train loss 1920.0519506125909
INFO:root:current train perplexity4.517303466796875
INFO:root:current mean train loss 1916.4034783121
INFO:root:current train perplexity4.510995388031006
INFO:root:current mean train loss 1914.059307493419
INFO:root:current train perplexity4.512820243835449
INFO:root:current mean train loss 1915.881394882917
INFO:root:current train perplexity4.516139030456543
INFO:root:current mean train loss 1918.0554627257509
INFO:root:current train perplexity4.525850772857666
INFO:root:current mean train loss 1916.5430101275822
INFO:root:current train perplexity4.527865886688232
INFO:root:current mean train loss 1917.416930744277
INFO:root:current train perplexity4.53147554397583
INFO:root:current mean train loss 1917.9462329761402
INFO:root:current train perplexity4.529336452484131
INFO:root:current mean train loss 1917.9808228224301
INFO:root:current train perplexity4.529667854309082
INFO:root:current mean train loss 1918.6644926007448
INFO:root:current train perplexity4.533268928527832
INFO:root:current mean train loss 1920.3062097935654
INFO:root:current train perplexity4.53741455078125
INFO:root:current mean train loss 1920.1734088091366
INFO:root:current train perplexity4.538513660430908
INFO:root:current mean train loss 1920.3866352204054
INFO:root:current train perplexity4.539740562438965
INFO:root:current mean train loss 1919.1841062077401
INFO:root:current train perplexity4.538356304168701
INFO:root:current mean train loss 1918.66156716339
INFO:root:current train perplexity4.537139415740967
INFO:root:current mean train loss 1919.0563729731439
INFO:root:current train perplexity4.540405750274658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it]
INFO:root:final mean train loss: 1918.4269214655135
INFO:root:final train perplexity: 4.540271759033203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2076.997226579815
INFO:root:eval perplexity: 5.364232540130615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [1:44:03<5:58:17, 138.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1896.6387615203857
INFO:root:current train perplexity4.423459053039551
INFO:root:current mean train loss 1899.0100105099561
INFO:root:current train perplexity4.475646495819092
INFO:root:current mean train loss 1903.6630873246627
INFO:root:current train perplexity4.475093364715576
INFO:root:current mean train loss 1912.8380589747167
INFO:root:current train perplexity4.497584819793701
INFO:root:current mean train loss 1905.8380453175512
INFO:root:current train perplexity4.486807346343994
INFO:root:current mean train loss 1907.9038536125886
INFO:root:current train perplexity4.494757175445557
INFO:root:current mean train loss 1908.4966568544687
INFO:root:current train perplexity4.50429105758667
INFO:root:current mean train loss 1911.9066249987218
INFO:root:current train perplexity4.505821228027344
INFO:root:current mean train loss 1913.5833772729945
INFO:root:current train perplexity4.505018711090088
INFO:root:current mean train loss 1911.6432119029191
INFO:root:current train perplexity4.502192974090576
INFO:root:current mean train loss 1911.5228009905134
INFO:root:current train perplexity4.50290060043335
INFO:root:current mean train loss 1910.1809922051184
INFO:root:current train perplexity4.500967025756836
INFO:root:current mean train loss 1909.1098807612552
INFO:root:current train perplexity4.505170822143555
INFO:root:current mean train loss 1908.7620808441968
INFO:root:current train perplexity4.5080389976501465
INFO:root:current mean train loss 1910.4906376072618
INFO:root:current train perplexity4.512931823730469
INFO:root:current mean train loss 1911.374140746758
INFO:root:current train perplexity4.512729644775391
INFO:root:current mean train loss 1914.0604043373694
INFO:root:current train perplexity4.5174784660339355
INFO:root:current mean train loss 1913.5535819471017
INFO:root:current train perplexity4.517725944519043
INFO:root:current mean train loss 1914.6468158116156
INFO:root:current train perplexity4.520047187805176
INFO:root:current mean train loss 1913.6162098808832
INFO:root:current train perplexity4.51981258392334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it]
INFO:root:final mean train loss: 1912.7291901819765
INFO:root:final train perplexity: 4.5199151039123535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2076.921791022551
INFO:root:eval perplexity: 5.363905906677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [1:46:21<5:55:52, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1911.1129979263117
INFO:root:current train perplexity4.475062370300293
INFO:root:current mean train loss 1895.6425174270546
INFO:root:current train perplexity4.4700822830200195
INFO:root:current mean train loss 1901.9177037575066
INFO:root:current train perplexity4.477949142456055
INFO:root:current mean train loss 1896.5065616797901
INFO:root:current train perplexity4.466948509216309
INFO:root:current mean train loss 1897.4874034096447
INFO:root:current train perplexity4.4666666984558105
INFO:root:current mean train loss 1896.8507546508579
INFO:root:current train perplexity4.469963073730469
INFO:root:current mean train loss 1896.739328796118
INFO:root:current train perplexity4.467484474182129
INFO:root:current mean train loss 1898.0795663987476
INFO:root:current train perplexity4.468853950500488
INFO:root:current mean train loss 1899.7820597376915
INFO:root:current train perplexity4.477267742156982
INFO:root:current mean train loss 1901.881556208588
INFO:root:current train perplexity4.4820380210876465
INFO:root:current mean train loss 1903.364102316829
INFO:root:current train perplexity4.486852645874023
INFO:root:current mean train loss 1905.960953314359
INFO:root:current train perplexity4.488971710205078
INFO:root:current mean train loss 1906.4150078064013
INFO:root:current train perplexity4.494442462921143
INFO:root:current mean train loss 1906.1623056951767
INFO:root:current train perplexity4.495069980621338
INFO:root:current mean train loss 1905.9324370080922
INFO:root:current train perplexity4.49362850189209
INFO:root:current mean train loss 1906.1003249649154
INFO:root:current train perplexity4.495840549468994
INFO:root:current mean train loss 1905.678019471994
INFO:root:current train perplexity4.494562149047852
INFO:root:current mean train loss 1906.7868205460854
INFO:root:current train perplexity4.497454643249512
INFO:root:current mean train loss 1906.612197154003
INFO:root:current train perplexity4.497641086578369
INFO:root:current mean train loss 1907.2681831155746
INFO:root:current train perplexity4.498850345611572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it]
INFO:root:final mean train loss: 1906.8511052134058
INFO:root:final train perplexity: 4.4990105628967285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2077.120165669326
INFO:root:eval perplexity: 5.364766597747803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [1:48:40<5:53:42, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1898.0682136379942
INFO:root:current train perplexity4.474931716918945
INFO:root:current mean train loss 1897.1925283104483
INFO:root:current train perplexity4.459893226623535
INFO:root:current mean train loss 1895.5602777468278
INFO:root:current train perplexity4.459514617919922
INFO:root:current mean train loss 1899.2076820871937
INFO:root:current train perplexity4.465668678283691
INFO:root:current mean train loss 1897.2419315935617
INFO:root:current train perplexity4.460897445678711
INFO:root:current mean train loss 1898.437476116678
INFO:root:current train perplexity4.4657206535339355
INFO:root:current mean train loss 1899.4338641235001
INFO:root:current train perplexity4.472945690155029
INFO:root:current mean train loss 1899.0318906396851
INFO:root:current train perplexity4.473336219787598
INFO:root:current mean train loss 1897.8686837449106
INFO:root:current train perplexity4.472897529602051
INFO:root:current mean train loss 1897.2401245361818
INFO:root:current train perplexity4.474242687225342
INFO:root:current mean train loss 1897.8174174991461
INFO:root:current train perplexity4.474243640899658
INFO:root:current mean train loss 1898.5529268548166
INFO:root:current train perplexity4.478986740112305
INFO:root:current mean train loss 1898.7321134076465
INFO:root:current train perplexity4.479509353637695
INFO:root:current mean train loss 1899.7258851756694
INFO:root:current train perplexity4.4789323806762695
INFO:root:current mean train loss 1900.5802337687228
INFO:root:current train perplexity4.479205131530762
INFO:root:current mean train loss 1901.1635221975466
INFO:root:current train perplexity4.479787349700928
INFO:root:current mean train loss 1901.604187371172
INFO:root:current train perplexity4.481657981872559
INFO:root:current mean train loss 1902.485030499926
INFO:root:current train perplexity4.481571674346924
INFO:root:current mean train loss 1902.8834703805198
INFO:root:current train perplexity4.484611511230469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it]
INFO:root:final mean train loss: 1902.2797098087651
INFO:root:final train perplexity: 4.482819080352783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2076.0608139579176
INFO:root:eval perplexity: 5.360172271728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/48
 24%|â–ˆâ–ˆâ–       | 48/200 [1:50:59<5:51:21, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1871.8978271484375
INFO:root:current train perplexity4.380288600921631
INFO:root:current mean train loss 1884.2818147078804
INFO:root:current train perplexity4.437557220458984
INFO:root:current mean train loss 1890.6617766624274
INFO:root:current train perplexity4.448704719543457
INFO:root:current mean train loss 1891.7254425533233
INFO:root:current train perplexity4.444906234741211
INFO:root:current mean train loss 1900.9410735716303
INFO:root:current train perplexity4.454112529754639
INFO:root:current mean train loss 1899.6075166868932
INFO:root:current train perplexity4.453770160675049
INFO:root:current mean train loss 1898.668615623412
INFO:root:current train perplexity4.456229209899902
INFO:root:current mean train loss 1896.340542709244
INFO:root:current train perplexity4.456600189208984
INFO:root:current mean train loss 1895.761495428729
INFO:root:current train perplexity4.457603931427002
INFO:root:current mean train loss 1894.7449940499062
INFO:root:current train perplexity4.461677074432373
INFO:root:current mean train loss 1895.3086851524015
INFO:root:current train perplexity4.460059642791748
INFO:root:current mean train loss 1894.4186524532302
INFO:root:current train perplexity4.460271835327148
INFO:root:current mean train loss 1897.0119786643197
INFO:root:current train perplexity4.464639663696289
INFO:root:current mean train loss 1896.4637191250297
INFO:root:current train perplexity4.462284088134766
INFO:root:current mean train loss 1897.3973377456934
INFO:root:current train perplexity4.463533878326416
INFO:root:current mean train loss 1897.3695367290636
INFO:root:current train perplexity4.464643478393555
INFO:root:current mean train loss 1897.6009444387334
INFO:root:current train perplexity4.46552848815918
INFO:root:current mean train loss 1897.63478868668
INFO:root:current train perplexity4.463949680328369
INFO:root:current mean train loss 1897.4183854704718
INFO:root:current train perplexity4.462466716766357
INFO:root:current mean train loss 1897.4366579379487
INFO:root:current train perplexity4.4631195068359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1897.0634233452608
INFO:root:final train perplexity: 4.464416027069092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2076.8668502915834
INFO:root:eval perplexity: 5.363668441772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/49
 24%|â–ˆâ–ˆâ–       | 49/200 [1:53:18<5:49:02, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1880.9455833435059
INFO:root:current train perplexity4.357020854949951
INFO:root:current mean train loss 1878.19443396366
INFO:root:current train perplexity4.411771774291992
INFO:root:current mean train loss 1887.0145784575363
INFO:root:current train perplexity4.429505348205566
INFO:root:current mean train loss 1883.690369387707
INFO:root:current train perplexity4.424890518188477
INFO:root:current mean train loss 1883.7374750773113
INFO:root:current train perplexity4.4188618659973145
INFO:root:current mean train loss 1882.9302147886806
INFO:root:current train perplexity4.422944068908691
INFO:root:current mean train loss 1882.1847893437252
INFO:root:current train perplexity4.418771266937256
INFO:root:current mean train loss 1881.207298737406
INFO:root:current train perplexity4.41917085647583
INFO:root:current mean train loss 1884.2415202214167
INFO:root:current train perplexity4.423872470855713
INFO:root:current mean train loss 1885.6972446687232
INFO:root:current train perplexity4.430057048797607
INFO:root:current mean train loss 1886.4958190917969
INFO:root:current train perplexity4.432546138763428
INFO:root:current mean train loss 1887.7673252496618
INFO:root:current train perplexity4.436816215515137
INFO:root:current mean train loss 1887.3368606567383
INFO:root:current train perplexity4.434860706329346
INFO:root:current mean train loss 1889.0680811426662
INFO:root:current train perplexity4.439210414886475
INFO:root:current mean train loss 1889.9060420883434
INFO:root:current train perplexity4.440309524536133
INFO:root:current mean train loss 1890.3132474017827
INFO:root:current train perplexity4.441059589385986
INFO:root:current mean train loss 1889.9314403159945
INFO:root:current train perplexity4.440338611602783
INFO:root:current mean train loss 1890.6735118839538
INFO:root:current train perplexity4.439528942108154
INFO:root:current mean train loss 1891.8928773038772
INFO:root:current train perplexity4.441635608673096
INFO:root:current mean train loss 1891.9221287445005
INFO:root:current train perplexity4.444962501525879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it]
INFO:root:final mean train loss: 1891.6788359010575
INFO:root:final train perplexity: 4.445496559143066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2077.205169894171
INFO:root:eval perplexity: 5.365135669708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [1:55:37<5:46:51, 138.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1882.005463269292
INFO:root:current train perplexity4.368135929107666
INFO:root:current mean train loss 1876.5794038708577
INFO:root:current train perplexity4.380047798156738
INFO:root:current mean train loss 1870.9210945343875
INFO:root:current train perplexity4.372298717498779
INFO:root:current mean train loss 1874.5115795408758
INFO:root:current train perplexity4.377945423126221
INFO:root:current mean train loss 1877.0095190375314
INFO:root:current train perplexity4.380463600158691
INFO:root:current mean train loss 1879.8920878425974
INFO:root:current train perplexity4.391178607940674
INFO:root:current mean train loss 1879.6480208809828
INFO:root:current train perplexity4.395503520965576
INFO:root:current mean train loss 1880.7741324369993
INFO:root:current train perplexity4.398700714111328
INFO:root:current mean train loss 1883.5590108595131
INFO:root:current train perplexity4.409936904907227
INFO:root:current mean train loss 1882.8881185067341
INFO:root:current train perplexity4.414852142333984
INFO:root:current mean train loss 1884.2735408350215
INFO:root:current train perplexity4.414515972137451
INFO:root:current mean train loss 1882.996907233362
INFO:root:current train perplexity4.412106037139893
INFO:root:current mean train loss 1882.1986250132918
INFO:root:current train perplexity4.4139509201049805
INFO:root:current mean train loss 1883.3018313804496
INFO:root:current train perplexity4.415541648864746
INFO:root:current mean train loss 1883.681055378305
INFO:root:current train perplexity4.4170355796813965
INFO:root:current mean train loss 1886.429386776751
INFO:root:current train perplexity4.424015998840332
INFO:root:current mean train loss 1886.597140726861
INFO:root:current train perplexity4.425181865692139
INFO:root:current mean train loss 1887.5801382179325
INFO:root:current train perplexity4.427502632141113
INFO:root:current mean train loss 1887.5764306719848
INFO:root:current train perplexity4.429263591766357
INFO:root:current mean train loss 1887.7184568809325
INFO:root:current train perplexity4.428531169891357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.83s/it]
INFO:root:final mean train loss: 1887.0062179834747
INFO:root:final train perplexity: 4.429145812988281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2076.4844035696474
INFO:root:eval perplexity: 5.362009048461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [1:57:55<5:44:34, 138.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1880.2883911132812
INFO:root:current train perplexity4.397424697875977
INFO:root:current mean train loss 1879.441851880177
INFO:root:current train perplexity4.393416404724121
INFO:root:current mean train loss 1876.5280073352326
INFO:root:current train perplexity4.390843391418457
INFO:root:current mean train loss 1877.520389077442
INFO:root:current train perplexity4.389849662780762
INFO:root:current mean train loss 1874.8155271341873
INFO:root:current train perplexity4.385860919952393
INFO:root:current mean train loss 1878.7911784573073
INFO:root:current train perplexity4.387836933135986
INFO:root:current mean train loss 1874.9521115964596
INFO:root:current train perplexity4.387547969818115
INFO:root:current mean train loss 1876.6490169355825
INFO:root:current train perplexity4.391860008239746
INFO:root:current mean train loss 1877.5524169358039
INFO:root:current train perplexity4.394673824310303
INFO:root:current mean train loss 1877.6612438889024
INFO:root:current train perplexity4.398128032684326
INFO:root:current mean train loss 1878.9559161273892
INFO:root:current train perplexity4.401299476623535
INFO:root:current mean train loss 1877.7144497958097
INFO:root:current train perplexity4.397669315338135
INFO:root:current mean train loss 1876.677728300411
INFO:root:current train perplexity4.394834995269775
INFO:root:current mean train loss 1876.7549847760627
INFO:root:current train perplexity4.398403644561768
INFO:root:current mean train loss 1878.3750823516637
INFO:root:current train perplexity4.402673721313477
INFO:root:current mean train loss 1878.8116560311153
INFO:root:current train perplexity4.405324935913086
INFO:root:current mean train loss 1878.9195558106055
INFO:root:current train perplexity4.406495571136475
INFO:root:current mean train loss 1878.9068430018183
INFO:root:current train perplexity4.4063849449157715
INFO:root:current mean train loss 1880.6398778590358
INFO:root:current train perplexity4.409208297729492
INFO:root:current mean train loss 1881.6265058236108
INFO:root:current train perplexity4.40986967086792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it]
INFO:root:final mean train loss: 1881.865535087797
INFO:root:final train perplexity: 4.41122579574585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2076.832320842337
INFO:root:eval perplexity: 5.363518238067627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:00:14<5:42:12, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.6760665709714
INFO:root:current train perplexity4.360547065734863
INFO:root:current mean train loss 1868.3623133591616
INFO:root:current train perplexity4.372137546539307
INFO:root:current mean train loss 1874.4184406401832
INFO:root:current train perplexity4.387966632843018
INFO:root:current mean train loss 1872.4644297308462
INFO:root:current train perplexity4.3793416023254395
INFO:root:current mean train loss 1876.588385224589
INFO:root:current train perplexity4.378175258636475
INFO:root:current mean train loss 1878.2368919935275
INFO:root:current train perplexity4.374905586242676
INFO:root:current mean train loss 1878.0730125237349
INFO:root:current train perplexity4.376666069030762
INFO:root:current mean train loss 1877.80805963392
INFO:root:current train perplexity4.375585556030273
INFO:root:current mean train loss 1878.3158411045442
INFO:root:current train perplexity4.37710428237915
INFO:root:current mean train loss 1878.1307721996598
INFO:root:current train perplexity4.37860107421875
INFO:root:current mean train loss 1878.0573228887133
INFO:root:current train perplexity4.3825578689575195
INFO:root:current mean train loss 1878.1526072897955
INFO:root:current train perplexity4.384532928466797
INFO:root:current mean train loss 1878.5958715306533
INFO:root:current train perplexity4.385894775390625
INFO:root:current mean train loss 1878.4516473578442
INFO:root:current train perplexity4.385585308074951
INFO:root:current mean train loss 1878.191634915764
INFO:root:current train perplexity4.387208938598633
INFO:root:current mean train loss 1878.191425142752
INFO:root:current train perplexity4.388886451721191
INFO:root:current mean train loss 1878.35047714043
INFO:root:current train perplexity4.390506744384766
INFO:root:current mean train loss 1877.05165888283
INFO:root:current train perplexity4.391066074371338
INFO:root:current mean train loss 1877.4512644487686
INFO:root:current train perplexity4.394425392150879
INFO:root:current mean train loss 1877.033436092775
INFO:root:current train perplexity4.39444637298584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it]
INFO:root:final mean train loss: 1877.033436092775
INFO:root:final train perplexity: 4.39444637298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2078.083868364916
INFO:root:eval perplexity: 5.368948459625244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:02:33<5:39:47, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1872.6289453125
INFO:root:current train perplexity4.35404634475708
INFO:root:current mean train loss 1869.556573486328
INFO:root:current train perplexity4.354581356048584
INFO:root:current mean train loss 1872.8942529296876
INFO:root:current train perplexity4.359757900238037
INFO:root:current mean train loss 1872.775181274414
INFO:root:current train perplexity4.355427265167236
INFO:root:current mean train loss 1868.904109375
INFO:root:current train perplexity4.354518890380859
INFO:root:current mean train loss 1871.1993178304037
INFO:root:current train perplexity4.352400302886963
INFO:root:current mean train loss 1870.7766746303014
INFO:root:current train perplexity4.356562614440918
INFO:root:current mean train loss 1868.5366906738282
INFO:root:current train perplexity4.352795600891113
INFO:root:current mean train loss 1870.222308485243
INFO:root:current train perplexity4.354620456695557
INFO:root:current mean train loss 1870.7257546386718
INFO:root:current train perplexity4.3582024574279785
INFO:root:current mean train loss 1869.7645241477273
INFO:root:current train perplexity4.362209796905518
INFO:root:current mean train loss 1869.17902730306
INFO:root:current train perplexity4.360559940338135
INFO:root:current mean train loss 1869.3502919358473
INFO:root:current train perplexity4.363124847412109
INFO:root:current mean train loss 1869.3728242710658
INFO:root:current train perplexity4.36455774307251
INFO:root:current mean train loss 1868.5004713541666
INFO:root:current train perplexity4.365533828735352
INFO:root:current mean train loss 1869.7506690216064
INFO:root:current train perplexity4.367419719696045
INFO:root:current mean train loss 1870.3010519588695
INFO:root:current train perplexity4.369773864746094
INFO:root:current mean train loss 1870.8890127902562
INFO:root:current train perplexity4.371542930603027
INFO:root:current mean train loss 1872.0566431306538
INFO:root:current train perplexity4.373859882354736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1871.8926244169188
INFO:root:final train perplexity: 4.3766655921936035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2077.8901726472463
INFO:root:eval perplexity: 5.368107795715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:04:51<5:37:26, 138.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.2741986443016
INFO:root:current train perplexity4.299126625061035
INFO:root:current mean train loss 1865.9874591012285
INFO:root:current train perplexity4.335911273956299
INFO:root:current mean train loss 1860.9908812914027
INFO:root:current train perplexity4.350298881530762
INFO:root:current mean train loss 1861.9983611001578
INFO:root:current train perplexity4.350094795227051
INFO:root:current mean train loss 1862.822323879178
INFO:root:current train perplexity4.348609447479248
INFO:root:current mean train loss 1862.2831629858256
INFO:root:current train perplexity4.349422931671143
INFO:root:current mean train loss 1861.8288633572224
INFO:root:current train perplexity4.342950344085693
INFO:root:current mean train loss 1862.9110187440072
INFO:root:current train perplexity4.339231491088867
INFO:root:current mean train loss 1863.84661558938
INFO:root:current train perplexity4.338926315307617
INFO:root:current mean train loss 1864.9528723397457
INFO:root:current train perplexity4.336629867553711
INFO:root:current mean train loss 1865.7559151888597
INFO:root:current train perplexity4.344473838806152
INFO:root:current mean train loss 1866.6184695114914
INFO:root:current train perplexity4.3439202308654785
INFO:root:current mean train loss 1866.2899436731268
INFO:root:current train perplexity4.344387531280518
INFO:root:current mean train loss 1866.749459349937
INFO:root:current train perplexity4.34729528427124
INFO:root:current mean train loss 1866.271051744718
INFO:root:current train perplexity4.34850549697876
INFO:root:current mean train loss 1865.6821058923347
INFO:root:current train perplexity4.350747585296631
INFO:root:current mean train loss 1866.1601613834455
INFO:root:current train perplexity4.353766441345215
INFO:root:current mean train loss 1866.8628106714336
INFO:root:current train perplexity4.356563091278076
INFO:root:current mean train loss 1867.394722115029
INFO:root:current train perplexity4.35888147354126
INFO:root:current mean train loss 1867.094157728853
INFO:root:current train perplexity4.358668327331543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it]
INFO:root:final mean train loss: 1867.245731601917
INFO:root:final train perplexity: 4.360655307769775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2078.3594369009033
INFO:root:eval perplexity: 5.37014627456665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:07:10<5:35:09, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1850.9773774988512
INFO:root:current train perplexity4.3488945960998535
INFO:root:current mean train loss 1863.6979688957556
INFO:root:current train perplexity4.310512542724609
INFO:root:current mean train loss 1853.886265942174
INFO:root:current train perplexity4.295573711395264
INFO:root:current mean train loss 1850.2620677833786
INFO:root:current train perplexity4.294737815856934
INFO:root:current mean train loss 1853.3286526587701
INFO:root:current train perplexity4.3054118156433105
INFO:root:current mean train loss 1853.826375782713
INFO:root:current train perplexity4.31276273727417
INFO:root:current mean train loss 1854.659087460876
INFO:root:current train perplexity4.318070411682129
INFO:root:current mean train loss 1855.8598042417937
INFO:root:current train perplexity4.326855659484863
INFO:root:current mean train loss 1857.505684466099
INFO:root:current train perplexity4.3309454917907715
INFO:root:current mean train loss 1858.6374136620466
INFO:root:current train perplexity4.332974433898926
INFO:root:current mean train loss 1858.6427454109119
INFO:root:current train perplexity4.335756778717041
INFO:root:current mean train loss 1858.0767597285949
INFO:root:current train perplexity4.334417343139648
INFO:root:current mean train loss 1858.9845919369493
INFO:root:current train perplexity4.334201335906982
INFO:root:current mean train loss 1859.4144535093294
INFO:root:current train perplexity4.331543445587158
INFO:root:current mean train loss 1861.0830697840395
INFO:root:current train perplexity4.338457107543945
INFO:root:current mean train loss 1861.446701109487
INFO:root:current train perplexity4.340645790100098
INFO:root:current mean train loss 1861.0580276246462
INFO:root:current train perplexity4.34037446975708
INFO:root:current mean train loss 1861.6044708568745
INFO:root:current train perplexity4.342528820037842
INFO:root:current mean train loss 1862.6057124912675
INFO:root:current train perplexity4.3444719314575195
INFO:root:current mean train loss 1863.0816130297876
INFO:root:current train perplexity4.345702171325684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 1863.1215181951864
INFO:root:final train perplexity: 4.346495151519775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2078.873436893977
INFO:root:eval perplexity: 5.372379302978516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:09:29<5:32:48, 138.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.2419002757354
INFO:root:current train perplexity4.278951168060303
INFO:root:current mean train loss 1838.4981891556292
INFO:root:current train perplexity4.287147045135498
INFO:root:current mean train loss 1842.2960511469746
INFO:root:current train perplexity4.284108638763428
INFO:root:current mean train loss 1848.2882306134259
INFO:root:current train perplexity4.292677402496338
INFO:root:current mean train loss 1846.967116531406
INFO:root:current train perplexity4.297623634338379
INFO:root:current mean train loss 1848.7328310653215
INFO:root:current train perplexity4.301016807556152
INFO:root:current mean train loss 1851.8815672328028
INFO:root:current train perplexity4.3053975105285645
INFO:root:current mean train loss 1852.9302492509987
INFO:root:current train perplexity4.306103706359863
INFO:root:current mean train loss 1850.9268085914548
INFO:root:current train perplexity4.307738780975342
INFO:root:current mean train loss 1850.9666164009102
INFO:root:current train perplexity4.305870056152344
INFO:root:current mean train loss 1853.713026981372
INFO:root:current train perplexity4.309021949768066
INFO:root:current mean train loss 1854.843086514444
INFO:root:current train perplexity4.31147575378418
INFO:root:current mean train loss 1854.9086312005084
INFO:root:current train perplexity4.31422233581543
INFO:root:current mean train loss 1854.900839059464
INFO:root:current train perplexity4.3159332275390625
INFO:root:current mean train loss 1855.6170988286635
INFO:root:current train perplexity4.318627834320068
INFO:root:current mean train loss 1856.182715803942
INFO:root:current train perplexity4.319693088531494
INFO:root:current mean train loss 1857.2124816044254
INFO:root:current train perplexity4.321775436401367
INFO:root:current mean train loss 1857.8802198827232
INFO:root:current train perplexity4.325178146362305
INFO:root:current mean train loss 1857.826650395901
INFO:root:current train perplexity4.326169490814209
INFO:root:current mean train loss 1858.4931653764295
INFO:root:current train perplexity4.32834529876709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it]
INFO:root:final mean train loss: 1858.1893786701119
INFO:root:final train perplexity: 4.329620838165283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2078.9306956622618
INFO:root:eval perplexity: 5.3726277351379395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:11:47<5:30:21, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1847.1763395421644
INFO:root:current train perplexity4.251392841339111
INFO:root:current mean train loss 1857.0364096505302
INFO:root:current train perplexity4.264554023742676
INFO:root:current mean train loss 1852.3324543967176
INFO:root:current train perplexity4.282431602478027
INFO:root:current mean train loss 1850.9145929087763
INFO:root:current train perplexity4.285511016845703
INFO:root:current mean train loss 1850.4558355869392
INFO:root:current train perplexity4.290832996368408
INFO:root:current mean train loss 1849.1015029692314
INFO:root:current train perplexity4.2921905517578125
INFO:root:current mean train loss 1849.361623250082
INFO:root:current train perplexity4.289026260375977
INFO:root:current mean train loss 1851.90625222524
INFO:root:current train perplexity4.292632579803467
INFO:root:current mean train loss 1850.6723943613642
INFO:root:current train perplexity4.292949676513672
INFO:root:current mean train loss 1851.2855529785156
INFO:root:current train perplexity4.29621696472168
INFO:root:current mean train loss 1851.3386100168977
INFO:root:current train perplexity4.298551082611084
INFO:root:current mean train loss 1851.3032378105268
INFO:root:current train perplexity4.301074504852295
INFO:root:current mean train loss 1852.1463617270676
INFO:root:current train perplexity4.30320405960083
INFO:root:current mean train loss 1853.5379395958973
INFO:root:current train perplexity4.3078484535217285
INFO:root:current mean train loss 1854.05266228034
INFO:root:current train perplexity4.3091654777526855
INFO:root:current mean train loss 1855.139729791758
INFO:root:current train perplexity4.311756134033203
INFO:root:current mean train loss 1854.2427450861576
INFO:root:current train perplexity4.313372611999512
INFO:root:current mean train loss 1854.5592493255754
INFO:root:current train perplexity4.313541412353516
INFO:root:current mean train loss 1855.2960336427873
INFO:root:current train perplexity4.316046714782715
INFO:root:current mean train loss 1854.8261559959349
INFO:root:current train perplexity4.316232681274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.95s/it]
INFO:root:final mean train loss: 1854.1422053888718
INFO:root:final train perplexity: 4.315823554992676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2078.6312186599625
INFO:root:eval perplexity: 5.371326446533203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:14:06<5:28:14, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.9686049517463
INFO:root:current train perplexity4.230624198913574
INFO:root:current mean train loss 1841.6528128959037
INFO:root:current train perplexity4.245718002319336
INFO:root:current mean train loss 1837.3944751404879
INFO:root:current train perplexity4.255276203155518
INFO:root:current mean train loss 1843.0231835303368
INFO:root:current train perplexity4.266584396362305
INFO:root:current mean train loss 1840.4175358408504
INFO:root:current train perplexity4.264258861541748
INFO:root:current mean train loss 1842.9142062717015
INFO:root:current train perplexity4.274519920349121
INFO:root:current mean train loss 1848.4399592267337
INFO:root:current train perplexity4.289639949798584
INFO:root:current mean train loss 1847.6937002388536
INFO:root:current train perplexity4.293981075286865
INFO:root:current mean train loss 1847.3147412661106
INFO:root:current train perplexity4.2941765785217285
INFO:root:current mean train loss 1847.2543986209153
INFO:root:current train perplexity4.296847343444824
INFO:root:current mean train loss 1846.782596373668
INFO:root:current train perplexity4.297061443328857
INFO:root:current mean train loss 1847.3149323411128
INFO:root:current train perplexity4.300612449645996
INFO:root:current mean train loss 1847.4996552582381
INFO:root:current train perplexity4.302613735198975
INFO:root:current mean train loss 1848.9365312817295
INFO:root:current train perplexity4.303258895874023
INFO:root:current mean train loss 1849.6547754563867
INFO:root:current train perplexity4.305051326751709
INFO:root:current mean train loss 1848.169497439989
INFO:root:current train perplexity4.3038458824157715
INFO:root:current mean train loss 1849.0987698789875
INFO:root:current train perplexity4.302643299102783
INFO:root:current mean train loss 1850.643725244004
INFO:root:current train perplexity4.3030195236206055
INFO:root:current mean train loss 1850.3683527696037
INFO:root:current train perplexity4.301798343658447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it]
INFO:root:final mean train loss: 1849.8828085602622
INFO:root:final train perplexity: 4.301349639892578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2080.410554493573
INFO:root:eval perplexity: 5.379061222076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:16:24<5:25:47, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1940.6859130859375
INFO:root:current train perplexity4.276577472686768
INFO:root:current mean train loss 1835.2066734164368
INFO:root:current train perplexity4.253291606903076
INFO:root:current mean train loss 1846.269002480082
INFO:root:current train perplexity4.266130447387695
INFO:root:current mean train loss 1838.2598028119826
INFO:root:current train perplexity4.260261058807373
INFO:root:current mean train loss 1839.5606935415694
INFO:root:current train perplexity4.2676215171813965
INFO:root:current mean train loss 1837.138163653978
INFO:root:current train perplexity4.262073516845703
INFO:root:current mean train loss 1838.8868600839
INFO:root:current train perplexity4.272003650665283
INFO:root:current mean train loss 1840.653032351763
INFO:root:current train perplexity4.270816802978516
INFO:root:current mean train loss 1842.8659661880456
INFO:root:current train perplexity4.273749828338623
INFO:root:current mean train loss 1841.9277113684002
INFO:root:current train perplexity4.276017189025879
INFO:root:current mean train loss 1842.9509814599317
INFO:root:current train perplexity4.277915000915527
INFO:root:current mean train loss 1844.2654044537276
INFO:root:current train perplexity4.27716588973999
INFO:root:current mean train loss 1845.9261764043977
INFO:root:current train perplexity4.27890157699585
INFO:root:current mean train loss 1845.5090078890048
INFO:root:current train perplexity4.280656814575195
INFO:root:current mean train loss 1845.545396399396
INFO:root:current train perplexity4.282578468322754
INFO:root:current mean train loss 1845.702552846205
INFO:root:current train perplexity4.283466815948486
INFO:root:current mean train loss 1845.620655988486
INFO:root:current train perplexity4.284255027770996
INFO:root:current mean train loss 1845.1653492587993
INFO:root:current train perplexity4.282228469848633
INFO:root:current mean train loss 1846.884040790181
INFO:root:current train perplexity4.285971164703369
INFO:root:current mean train loss 1846.360775920495
INFO:root:current train perplexity4.284693717956543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1845.6034443095905
INFO:root:final train perplexity: 4.286857604980469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2081.741624764517
INFO:root:eval perplexity: 5.3848557472229
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:18:43<5:23:26, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1837.242097553454
INFO:root:current train perplexity4.165750980377197
INFO:root:current mean train loss 1823.7068763540572
INFO:root:current train perplexity4.212411880493164
INFO:root:current mean train loss 1817.9411453874143
INFO:root:current train perplexity4.233371257781982
INFO:root:current mean train loss 1825.7632524735502
INFO:root:current train perplexity4.236321449279785
INFO:root:current mean train loss 1828.1838329378916
INFO:root:current train perplexity4.2490129470825195
INFO:root:current mean train loss 1829.1034095484856
INFO:root:current train perplexity4.249625205993652
INFO:root:current mean train loss 1833.5171612322042
INFO:root:current train perplexity4.253820896148682
INFO:root:current mean train loss 1835.9366667300503
INFO:root:current train perplexity4.2612714767456055
INFO:root:current mean train loss 1836.256825206044
INFO:root:current train perplexity4.260581016540527
INFO:root:current mean train loss 1837.1642758241805
INFO:root:current train perplexity4.258856773376465
INFO:root:current mean train loss 1838.6434534613823
INFO:root:current train perplexity4.260917663574219
INFO:root:current mean train loss 1839.4553031750936
INFO:root:current train perplexity4.263049125671387
INFO:root:current mean train loss 1839.1300135949677
INFO:root:current train perplexity4.262568473815918
INFO:root:current mean train loss 1839.6436462170975
INFO:root:current train perplexity4.264545440673828
INFO:root:current mean train loss 1839.1710216261451
INFO:root:current train perplexity4.265457630157471
INFO:root:current mean train loss 1839.3630754421854
INFO:root:current train perplexity4.267275333404541
INFO:root:current mean train loss 1839.7080689607542
INFO:root:current train perplexity4.26713752746582
INFO:root:current mean train loss 1840.8722272499
INFO:root:current train perplexity4.268606185913086
INFO:root:current mean train loss 1840.8930674799856
INFO:root:current train perplexity4.2698283195495605
INFO:root:current mean train loss 1841.14127873455
INFO:root:current train perplexity4.270964622497559

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it]
INFO:root:final mean train loss: 1841.4277734030272
INFO:root:final train perplexity: 4.272763252258301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2081.4925325001386
INFO:root:eval perplexity: 5.383770942687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:21:01<5:21:00, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.197536892361
INFO:root:current train perplexity4.2571258544921875
INFO:root:current mean train loss 1824.0029988008387
INFO:root:current train perplexity4.217979431152344
INFO:root:current mean train loss 1832.3902355129435
INFO:root:current train perplexity4.2376837730407715
INFO:root:current mean train loss 1836.303797040667
INFO:root:current train perplexity4.228812217712402
INFO:root:current mean train loss 1830.7533625331494
INFO:root:current train perplexity4.2217206954956055
INFO:root:current mean train loss 1831.3352465273729
INFO:root:current train perplexity4.230814456939697
INFO:root:current mean train loss 1831.2057706245087
INFO:root:current train perplexity4.232151031494141
INFO:root:current mean train loss 1831.779350446618
INFO:root:current train perplexity4.236546516418457
INFO:root:current mean train loss 1832.6658506256542
INFO:root:current train perplexity4.239072322845459
INFO:root:current mean train loss 1832.132583226913
INFO:root:current train perplexity4.239706993103027
INFO:root:current mean train loss 1833.9436867025368
INFO:root:current train perplexity4.242501258850098
INFO:root:current mean train loss 1834.5870410758005
INFO:root:current train perplexity4.244124889373779
INFO:root:current mean train loss 1834.6896084782375
INFO:root:current train perplexity4.247994899749756
INFO:root:current mean train loss 1834.6242770806043
INFO:root:current train perplexity4.248321056365967
INFO:root:current mean train loss 1834.8934282818213
INFO:root:current train perplexity4.2496747970581055
INFO:root:current mean train loss 1836.0697999795277
INFO:root:current train perplexity4.252005100250244
INFO:root:current mean train loss 1837.6678302643643
INFO:root:current train perplexity4.254211902618408
INFO:root:current mean train loss 1838.0124354911839
INFO:root:current train perplexity4.256109237670898
INFO:root:current mean train loss 1837.511572012974
INFO:root:current train perplexity4.258073329925537
INFO:root:current mean train loss 1837.4430580454425
INFO:root:current train perplexity4.257278919219971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it]
INFO:root:final mean train loss: 1837.3464097846834
INFO:root:final train perplexity: 4.259031772613525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2082.005652028618
INFO:root:eval perplexity: 5.386005401611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:23:20<5:18:49, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1797.1779048127948
INFO:root:current train perplexity4.1501994132995605
INFO:root:current mean train loss 1812.8176883872038
INFO:root:current train perplexity4.196778774261475
INFO:root:current mean train loss 1816.9385238466527
INFO:root:current train perplexity4.213475704193115
INFO:root:current mean train loss 1821.140869140625
INFO:root:current train perplexity4.212335586547852
INFO:root:current mean train loss 1822.8039825641556
INFO:root:current train perplexity4.218013763427734
INFO:root:current mean train loss 1822.6826642055407
INFO:root:current train perplexity4.213675022125244
INFO:root:current mean train loss 1823.016700826414
INFO:root:current train perplexity4.215237617492676
INFO:root:current mean train loss 1822.4465518460015
INFO:root:current train perplexity4.213857173919678
INFO:root:current mean train loss 1824.910738981902
INFO:root:current train perplexity4.220049858093262
INFO:root:current mean train loss 1827.3536032389493
INFO:root:current train perplexity4.223470687866211
INFO:root:current mean train loss 1828.687509390024
INFO:root:current train perplexity4.222627639770508
INFO:root:current mean train loss 1830.3159865737478
INFO:root:current train perplexity4.229159355163574
INFO:root:current mean train loss 1831.3891580129564
INFO:root:current train perplexity4.23446798324585
INFO:root:current mean train loss 1831.8819530456046
INFO:root:current train perplexity4.238018035888672
INFO:root:current mean train loss 1831.0252908180273
INFO:root:current train perplexity4.236011028289795
INFO:root:current mean train loss 1831.8395125173556
INFO:root:current train perplexity4.236617565155029
INFO:root:current mean train loss 1832.876815694358
INFO:root:current train perplexity4.236704349517822
INFO:root:current mean train loss 1833.586276971063
INFO:root:current train perplexity4.239389896392822
INFO:root:current mean train loss 1833.1834739195097
INFO:root:current train perplexity4.240635395050049
INFO:root:current mean train loss 1833.1781058362735
INFO:root:current train perplexity4.242866039276123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it]
INFO:root:final mean train loss: 1832.7223454724042
INFO:root:final train perplexity: 4.243528366088867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2081.3004111432015
INFO:root:eval perplexity: 5.382933616638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:25:39<5:16:33, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1830.9078125
INFO:root:current train perplexity4.20576810836792
INFO:root:current mean train loss 1830.28301858341
INFO:root:current train perplexity4.206103801727295
INFO:root:current mean train loss 1825.7385787398728
INFO:root:current train perplexity4.202432632446289
INFO:root:current mean train loss 1824.5472610061233
INFO:root:current train perplexity4.206007480621338
INFO:root:current mean train loss 1823.6224466526762
INFO:root:current train perplexity4.209347724914551
INFO:root:current mean train loss 1820.841494697437
INFO:root:current train perplexity4.204560279846191
INFO:root:current mean train loss 1821.0762440240205
INFO:root:current train perplexity4.209914207458496
INFO:root:current mean train loss 1823.5662875088778
INFO:root:current train perplexity4.215115547180176
INFO:root:current mean train loss 1824.7520921729076
INFO:root:current train perplexity4.218498706817627
INFO:root:current mean train loss 1825.628649021424
INFO:root:current train perplexity4.219716548919678
INFO:root:current mean train loss 1826.0461371020735
INFO:root:current train perplexity4.220008850097656
INFO:root:current mean train loss 1825.1392668895232
INFO:root:current train perplexity4.219026565551758
INFO:root:current mean train loss 1826.0491559847133
INFO:root:current train perplexity4.2212958335876465
INFO:root:current mean train loss 1826.9807027329493
INFO:root:current train perplexity4.221119403839111
INFO:root:current mean train loss 1828.8107705044908
INFO:root:current train perplexity4.224023342132568
INFO:root:current mean train loss 1828.8371292794586
INFO:root:current train perplexity4.224490165710449
INFO:root:current mean train loss 1829.1185324663174
INFO:root:current train perplexity4.225175380706787
INFO:root:current mean train loss 1829.0590886520126
INFO:root:current train perplexity4.226656913757324
INFO:root:current mean train loss 1829.1065672522561
INFO:root:current train perplexity4.2276201248168945
INFO:root:current mean train loss 1829.0730097581893
INFO:root:current train perplexity4.230529308319092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1828.9913377170303
INFO:root:final train perplexity: 4.23106050491333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2082.4356170004985
INFO:root:eval perplexity: 5.387878894805908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [2:27:57<5:14:08, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1801.2971780711207
INFO:root:current train perplexity4.16719913482666
INFO:root:current mean train loss 1816.8964288884943
INFO:root:current train perplexity4.176340579986572
INFO:root:current mean train loss 1811.8715463033536
INFO:root:current train perplexity4.176045894622803
INFO:root:current mean train loss 1819.9179624414567
INFO:root:current train perplexity4.194619655609131
INFO:root:current mean train loss 1821.6823161475713
INFO:root:current train perplexity4.1992011070251465
INFO:root:current mean train loss 1821.1023483666286
INFO:root:current train perplexity4.1973066329956055
INFO:root:current mean train loss 1818.8129292894832
INFO:root:current train perplexity4.196317672729492
INFO:root:current mean train loss 1820.2874343271026
INFO:root:current train perplexity4.199699401855469
INFO:root:current mean train loss 1822.6215143214488
INFO:root:current train perplexity4.202492713928223
INFO:root:current mean train loss 1823.665209985673
INFO:root:current train perplexity4.203121185302734
INFO:root:current mean train loss 1822.9245224771087
INFO:root:current train perplexity4.203745365142822
INFO:root:current mean train loss 1823.1693372332759
INFO:root:current train perplexity4.202788829803467
INFO:root:current mean train loss 1824.2737762996553
INFO:root:current train perplexity4.204439163208008
INFO:root:current mean train loss 1823.6076708561925
INFO:root:current train perplexity4.205954074859619
INFO:root:current mean train loss 1823.752417845941
INFO:root:current train perplexity4.207771301269531
INFO:root:current mean train loss 1823.6285768063021
INFO:root:current train perplexity4.210514545440674
INFO:root:current mean train loss 1823.9023179176932
INFO:root:current train perplexity4.211400032043457
INFO:root:current mean train loss 1824.1433895134567
INFO:root:current train perplexity4.212529182434082
INFO:root:current mean train loss 1823.8519748997044
INFO:root:current train perplexity4.212652683258057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it]
INFO:root:final mean train loss: 1824.0937225757316
INFO:root:final train perplexity: 4.214748859405518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2084.0533979699967
INFO:root:eval perplexity: 5.394932746887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [2:30:16<5:11:51, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1856.142578125
INFO:root:current train perplexity4.131031036376953
INFO:root:current mean train loss 1825.3574688251201
INFO:root:current train perplexity4.227179050445557
INFO:root:current mean train loss 1822.7909946815641
INFO:root:current train perplexity4.19661283493042
INFO:root:current mean train loss 1815.7711438630756
INFO:root:current train perplexity4.2034101486206055
INFO:root:current mean train loss 1819.8309718972384
INFO:root:current train perplexity4.209597110748291
INFO:root:current mean train loss 1820.3021298363096
INFO:root:current train perplexity4.212584018707275
INFO:root:current mean train loss 1819.0394143616127
INFO:root:current train perplexity4.206240653991699
INFO:root:current mean train loss 1820.2237623388116
INFO:root:current train perplexity4.203238010406494
INFO:root:current mean train loss 1817.8095399467506
INFO:root:current train perplexity4.199793338775635
INFO:root:current mean train loss 1817.6459659812724
INFO:root:current train perplexity4.199774742126465
INFO:root:current mean train loss 1817.3588996066514
INFO:root:current train perplexity4.197650909423828
INFO:root:current mean train loss 1818.1695208342178
INFO:root:current train perplexity4.201218605041504
INFO:root:current mean train loss 1817.9539235263965
INFO:root:current train perplexity4.1983323097229
INFO:root:current mean train loss 1819.414010358003
INFO:root:current train perplexity4.1970672607421875
INFO:root:current mean train loss 1820.194933855975
INFO:root:current train perplexity4.199477672576904
INFO:root:current mean train loss 1820.7439247293676
INFO:root:current train perplexity4.199499130249023
INFO:root:current mean train loss 1820.189499472145
INFO:root:current train perplexity4.1979851722717285
INFO:root:current mean train loss 1820.6814253542905
INFO:root:current train perplexity4.200847148895264
INFO:root:current mean train loss 1821.5341411176119
INFO:root:current train perplexity4.202507019042969
INFO:root:current mean train loss 1822.1992222120782
INFO:root:current train perplexity4.2046380043029785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it]
INFO:root:final mean train loss: 1820.8870391307066
INFO:root:final train perplexity: 4.204102993011475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2085.154037150931
INFO:root:eval perplexity: 5.399736404418945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [2:32:34<5:09:27, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.6543143136162
INFO:root:current train perplexity4.158420562744141
INFO:root:current mean train loss 1804.2902075397083
INFO:root:current train perplexity4.146233558654785
INFO:root:current mean train loss 1804.865948016827
INFO:root:current train perplexity4.15731954574585
INFO:root:current mean train loss 1808.196155583747
INFO:root:current train perplexity4.161425590515137
INFO:root:current mean train loss 1808.1881700819292
INFO:root:current train perplexity4.158308029174805
INFO:root:current mean train loss 1808.7958356450936
INFO:root:current train perplexity4.159427642822266
INFO:root:current mean train loss 1809.4513741460976
INFO:root:current train perplexity4.160052299499512
INFO:root:current mean train loss 1807.893490858779
INFO:root:current train perplexity4.160785675048828
INFO:root:current mean train loss 1808.4485373270497
INFO:root:current train perplexity4.165250301361084
INFO:root:current mean train loss 1809.4229648851028
INFO:root:current train perplexity4.16679048538208
INFO:root:current mean train loss 1810.1664356377403
INFO:root:current train perplexity4.168527603149414
INFO:root:current mean train loss 1811.5410284745067
INFO:root:current train perplexity4.1713056564331055
INFO:root:current mean train loss 1813.1969277071817
INFO:root:current train perplexity4.174444675445557
INFO:root:current mean train loss 1814.3549139353472
INFO:root:current train perplexity4.179405212402344
INFO:root:current mean train loss 1815.8054242171006
INFO:root:current train perplexity4.182426452636719
INFO:root:current mean train loss 1815.987655970707
INFO:root:current train perplexity4.183217525482178
INFO:root:current mean train loss 1817.151272227189
INFO:root:current train perplexity4.187026023864746
INFO:root:current mean train loss 1818.2048079531114
INFO:root:current train perplexity4.18927001953125
INFO:root:current mean train loss 1818.1554513477743
INFO:root:current train perplexity4.190226078033447
INFO:root:current mean train loss 1817.363722062992
INFO:root:current train perplexity4.190200328826904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it]
INFO:root:final mean train loss: 1816.625378368722
INFO:root:final train perplexity: 4.189997673034668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2085.276055085744
INFO:root:eval perplexity: 5.400269985198975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [2:34:53<5:07:20, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1818.8474313836348
INFO:root:current train perplexity4.170805931091309
INFO:root:current mean train loss 1795.5908893087635
INFO:root:current train perplexity4.144546031951904
INFO:root:current mean train loss 1806.922401235885
INFO:root:current train perplexity4.167046070098877
INFO:root:current mean train loss 1803.0235314002405
INFO:root:current train perplexity4.166768550872803
INFO:root:current mean train loss 1805.779964359928
INFO:root:current train perplexity4.172003269195557
INFO:root:current mean train loss 1808.0760693177858
INFO:root:current train perplexity4.172999858856201
INFO:root:current mean train loss 1809.371124937243
INFO:root:current train perplexity4.1763014793396
INFO:root:current mean train loss 1809.9744535616742
INFO:root:current train perplexity4.181392192840576
INFO:root:current mean train loss 1811.2483527791244
INFO:root:current train perplexity4.180303573608398
INFO:root:current mean train loss 1811.9494785072961
INFO:root:current train perplexity4.184063911437988
INFO:root:current mean train loss 1813.1286864528765
INFO:root:current train perplexity4.182518005371094
INFO:root:current mean train loss 1813.820622073745
INFO:root:current train perplexity4.18267822265625
INFO:root:current mean train loss 1813.6209131096023
INFO:root:current train perplexity4.180050373077393
INFO:root:current mean train loss 1814.7947219825824
INFO:root:current train perplexity4.182118892669678
INFO:root:current mean train loss 1814.2959936829038
INFO:root:current train perplexity4.181075096130371
INFO:root:current mean train loss 1813.1795863038697
INFO:root:current train perplexity4.1804280281066895
INFO:root:current mean train loss 1814.1805596543757
INFO:root:current train perplexity4.182016372680664
INFO:root:current mean train loss 1814.4335929774031
INFO:root:current train perplexity4.181570053100586
INFO:root:current mean train loss 1813.3807410903282
INFO:root:current train perplexity4.17948055267334
INFO:root:current mean train loss 1813.4750802086357
INFO:root:current train perplexity4.178511142730713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it]
INFO:root:final mean train loss: 1813.053058018302
INFO:root:final train perplexity: 4.17820930480957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2086.470154674341
INFO:root:eval perplexity: 5.405487060546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [2:37:12<5:05:03, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.4453768643466
INFO:root:current train perplexity4.122758388519287
INFO:root:current mean train loss 1787.3854791456654
INFO:root:current train perplexity4.145267963409424
INFO:root:current mean train loss 1797.7100447112439
INFO:root:current train perplexity4.156375408172607
INFO:root:current mean train loss 1801.71474643761
INFO:root:current train perplexity4.151510238647461
INFO:root:current mean train loss 1800.3876094608515
INFO:root:current train perplexity4.152431011199951
INFO:root:current mean train loss 1799.048852759009
INFO:root:current train perplexity4.147254467010498
INFO:root:current mean train loss 1801.3547626058564
INFO:root:current train perplexity4.148246765136719
INFO:root:current mean train loss 1801.7155621054947
INFO:root:current train perplexity4.1468400955200195
INFO:root:current mean train loss 1803.6085976048519
INFO:root:current train perplexity4.1512956619262695
INFO:root:current mean train loss 1804.8779558910749
INFO:root:current train perplexity4.153390884399414
INFO:root:current mean train loss 1804.7292498981783
INFO:root:current train perplexity4.152310371398926
INFO:root:current mean train loss 1805.4328190526921
INFO:root:current train perplexity4.154156684875488
INFO:root:current mean train loss 1806.0066372206486
INFO:root:current train perplexity4.1581196784973145
INFO:root:current mean train loss 1807.9853998500923
INFO:root:current train perplexity4.161625862121582
INFO:root:current mean train loss 1808.1533677982711
INFO:root:current train perplexity4.16276741027832
INFO:root:current mean train loss 1808.3869402821042
INFO:root:current train perplexity4.16466760635376
INFO:root:current mean train loss 1808.750503696776
INFO:root:current train perplexity4.164097785949707
INFO:root:current mean train loss 1809.4760171134926
INFO:root:current train perplexity4.165527820587158
INFO:root:current mean train loss 1808.3709791157767
INFO:root:current train perplexity4.16391658782959
INFO:root:current mean train loss 1809.0909946451407
INFO:root:current train perplexity4.164952754974365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it]
INFO:root:final mean train loss: 1809.1114314199997
INFO:root:final train perplexity: 4.165241241455078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2087.2008918058787
INFO:root:eval perplexity: 5.4086833000183105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [2:39:31<5:02:40, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.687252468533
INFO:root:current train perplexity4.086109161376953
INFO:root:current mean train loss 1796.6714960142624
INFO:root:current train perplexity4.102593898773193
INFO:root:current mean train loss 1794.7353416891658
INFO:root:current train perplexity4.108402252197266
INFO:root:current mean train loss 1793.386196997858
INFO:root:current train perplexity4.1139655113220215
INFO:root:current mean train loss 1794.9767872438592
INFO:root:current train perplexity4.118466854095459
INFO:root:current mean train loss 1796.8784358951596
INFO:root:current train perplexity4.1230878829956055
INFO:root:current mean train loss 1799.9300684247698
INFO:root:current train perplexity4.125619888305664
INFO:root:current mean train loss 1800.866583315202
INFO:root:current train perplexity4.127425193786621
INFO:root:current mean train loss 1801.1691107793686
INFO:root:current train perplexity4.12855863571167
INFO:root:current mean train loss 1800.0697507505063
INFO:root:current train perplexity4.132622241973877
INFO:root:current mean train loss 1800.6074059329815
INFO:root:current train perplexity4.132105350494385
INFO:root:current mean train loss 1801.833097802901
INFO:root:current train perplexity4.135749340057373
INFO:root:current mean train loss 1802.0978782221955
INFO:root:current train perplexity4.137970447540283
INFO:root:current mean train loss 1803.2868025087407
INFO:root:current train perplexity4.141149044036865
INFO:root:current mean train loss 1804.260041527126
INFO:root:current train perplexity4.144532680511475
INFO:root:current mean train loss 1804.353462743395
INFO:root:current train perplexity4.14528226852417
INFO:root:current mean train loss 1804.5911952844647
INFO:root:current train perplexity4.145575523376465
INFO:root:current mean train loss 1804.2113006109578
INFO:root:current train perplexity4.146721363067627
INFO:root:current mean train loss 1804.9553822574453
INFO:root:current train perplexity4.14984130859375
INFO:root:current mean train loss 1805.5216527478449
INFO:root:current train perplexity4.152113914489746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it]
INFO:root:final mean train loss: 1805.1086695714846
INFO:root:final train perplexity: 4.1521124839782715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2086.25259204621
INFO:root:eval perplexity: 5.404536724090576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [2:41:49<5:00:20, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1804.4968947507023
INFO:root:current train perplexity4.09752082824707
INFO:root:current mean train loss 1804.419033151455
INFO:root:current train perplexity4.102748870849609
INFO:root:current mean train loss 1807.8641125108131
INFO:root:current train perplexity4.110811710357666
INFO:root:current mean train loss 1808.6059350648698
INFO:root:current train perplexity4.112833499908447
INFO:root:current mean train loss 1808.6698989088063
INFO:root:current train perplexity4.113968849182129
INFO:root:current mean train loss 1806.1630749532444
INFO:root:current train perplexity4.110695838928223
INFO:root:current mean train loss 1803.9553344903734
INFO:root:current train perplexity4.116217613220215
INFO:root:current mean train loss 1801.9830020570937
INFO:root:current train perplexity4.119931697845459
INFO:root:current mean train loss 1800.74817443779
INFO:root:current train perplexity4.1222076416015625
INFO:root:current mean train loss 1799.3114127225654
INFO:root:current train perplexity4.121243000030518
INFO:root:current mean train loss 1799.2740496450658
INFO:root:current train perplexity4.119288921356201
INFO:root:current mean train loss 1801.4492385646092
INFO:root:current train perplexity4.126855850219727
INFO:root:current mean train loss 1803.343818848035
INFO:root:current train perplexity4.131814002990723
INFO:root:current mean train loss 1802.8906781695746
INFO:root:current train perplexity4.132099628448486
INFO:root:current mean train loss 1802.8495737130886
INFO:root:current train perplexity4.132852554321289
INFO:root:current mean train loss 1803.4877441867181
INFO:root:current train perplexity4.136670112609863
INFO:root:current mean train loss 1803.1904085113001
INFO:root:current train perplexity4.137616157531738
INFO:root:current mean train loss 1801.890142109222
INFO:root:current train perplexity4.137824058532715
INFO:root:current mean train loss 1801.8110027807993
INFO:root:current train perplexity4.138729572296143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it]
INFO:root:final mean train loss: 1801.7112664065455
INFO:root:final train perplexity: 4.141002655029297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2087.650944270141
INFO:root:eval perplexity: 5.410651683807373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [2:44:08<4:58:00, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.9206136067708
INFO:root:current train perplexity4.1514458656311035
INFO:root:current mean train loss 1790.3396019125885
INFO:root:current train perplexity4.0920515060424805
INFO:root:current mean train loss 1800.4773209951456
INFO:root:current train perplexity4.114309310913086
INFO:root:current mean train loss 1801.9821593839358
INFO:root:current train perplexity4.122289657592773
INFO:root:current mean train loss 1796.4516809021898
INFO:root:current train perplexity4.114524841308594
INFO:root:current mean train loss 1795.5590325758862
INFO:root:current train perplexity4.114354610443115
INFO:root:current mean train loss 1797.0367415525732
INFO:root:current train perplexity4.118359565734863
INFO:root:current mean train loss 1794.997302004028
INFO:root:current train perplexity4.116829872131348
INFO:root:current mean train loss 1795.149392707768
INFO:root:current train perplexity4.1198930740356445
INFO:root:current mean train loss 1793.7257462726786
INFO:root:current train perplexity4.114694595336914
INFO:root:current mean train loss 1794.6260522800696
INFO:root:current train perplexity4.115074634552002
INFO:root:current mean train loss 1797.2104985545816
INFO:root:current train perplexity4.119700908660889
INFO:root:current mean train loss 1797.5290719660163
INFO:root:current train perplexity4.12087345123291
INFO:root:current mean train loss 1798.219379419207
INFO:root:current train perplexity4.122453212738037
INFO:root:current mean train loss 1798.4605313514069
INFO:root:current train perplexity4.123605728149414
INFO:root:current mean train loss 1798.5265225718222
INFO:root:current train perplexity4.125567436218262
INFO:root:current mean train loss 1798.7692274423791
INFO:root:current train perplexity4.124268054962158
INFO:root:current mean train loss 1798.8200619911113
INFO:root:current train perplexity4.125171184539795
INFO:root:current mean train loss 1798.0534362455012
INFO:root:current train perplexity4.125279903411865
INFO:root:current mean train loss 1798.6033249621876
INFO:root:current train perplexity4.127893447875977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1797.8971102085009
INFO:root:final train perplexity: 4.128564357757568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2089.2142974637077
INFO:root:eval perplexity: 5.417496681213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [2:46:26<4:55:34, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.051168690557
INFO:root:current train perplexity4.191051006317139
INFO:root:current mean train loss 1795.3705022548272
INFO:root:current train perplexity4.119325637817383
INFO:root:current mean train loss 1792.6152113841788
INFO:root:current train perplexity4.105964660644531
INFO:root:current mean train loss 1787.847718229973
INFO:root:current train perplexity4.093652725219727
INFO:root:current mean train loss 1785.5837416772865
INFO:root:current train perplexity4.093833923339844
INFO:root:current mean train loss 1786.876518293275
INFO:root:current train perplexity4.099486351013184
INFO:root:current mean train loss 1787.2303368827122
INFO:root:current train perplexity4.102483749389648
INFO:root:current mean train loss 1789.3184497036546
INFO:root:current train perplexity4.109203815460205
INFO:root:current mean train loss 1789.1837626905663
INFO:root:current train perplexity4.106345176696777
INFO:root:current mean train loss 1789.6110677171503
INFO:root:current train perplexity4.105467796325684
INFO:root:current mean train loss 1790.3780930445457
INFO:root:current train perplexity4.109218597412109
INFO:root:current mean train loss 1791.1784735362867
INFO:root:current train perplexity4.111107349395752
INFO:root:current mean train loss 1790.639864231462
INFO:root:current train perplexity4.109704971313477
INFO:root:current mean train loss 1792.9341586135322
INFO:root:current train perplexity4.110024452209473
INFO:root:current mean train loss 1793.5248600523487
INFO:root:current train perplexity4.113472938537598
INFO:root:current mean train loss 1794.0692567480917
INFO:root:current train perplexity4.115496635437012
INFO:root:current mean train loss 1794.663872738202
INFO:root:current train perplexity4.116385459899902
INFO:root:current mean train loss 1795.7351687049977
INFO:root:current train perplexity4.117770671844482
INFO:root:current mean train loss 1795.9617818810425
INFO:root:current train perplexity4.118436336517334
INFO:root:current mean train loss 1795.6040008592531
INFO:root:current train perplexity4.118155479431152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it]
INFO:root:final mean train loss: 1794.6798390567874
INFO:root:final train perplexity: 4.118102073669434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2090.019791839816
INFO:root:eval perplexity: 5.421027660369873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [2:48:45<4:53:21, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.9277587890624
INFO:root:current train perplexity4.055399417877197
INFO:root:current mean train loss 1776.6973885672433
INFO:root:current train perplexity4.062203884124756
INFO:root:current mean train loss 1774.6948842366537
INFO:root:current train perplexity4.067343711853027
INFO:root:current mean train loss 1775.735454604205
INFO:root:current train perplexity4.072309494018555
INFO:root:current mean train loss 1774.9455816095526
INFO:root:current train perplexity4.074948310852051
INFO:root:current mean train loss 1776.745443612558
INFO:root:current train perplexity4.071977615356445
INFO:root:current mean train loss 1778.3471048355102
INFO:root:current train perplexity4.076831817626953
INFO:root:current mean train loss 1781.2509943781672
INFO:root:current train perplexity4.083913803100586
INFO:root:current mean train loss 1782.6950321742468
INFO:root:current train perplexity4.083666801452637
INFO:root:current mean train loss 1786.0284726406665
INFO:root:current train perplexity4.087177753448486
INFO:root:current mean train loss 1784.5281437800481
INFO:root:current train perplexity4.087637901306152
INFO:root:current mean train loss 1785.325964462548
INFO:root:current train perplexity4.091121196746826
INFO:root:current mean train loss 1786.0133054671749
INFO:root:current train perplexity4.092045783996582
INFO:root:current mean train loss 1787.2982185022154
INFO:root:current train perplexity4.094884395599365
INFO:root:current mean train loss 1787.8167276170518
INFO:root:current train perplexity4.096418857574463
INFO:root:current mean train loss 1787.7666313666803
INFO:root:current train perplexity4.09785270690918
INFO:root:current mean train loss 1788.9048616734947
INFO:root:current train perplexity4.100024223327637
INFO:root:current mean train loss 1790.3675165286008
INFO:root:current train perplexity4.1023101806640625
INFO:root:current mean train loss 1790.7684894727624
INFO:root:current train perplexity4.101250171661377
INFO:root:current mean train loss 1791.1382803690801
INFO:root:current train perplexity4.104045867919922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.37s/it]
INFO:root:final mean train loss: 1790.7191833711547
INFO:root:final train perplexity: 4.105258941650391
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2090.195103854998
INFO:root:eval perplexity: 5.4217963218688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [2:51:03<4:50:51, 138.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1778.2141927083333
INFO:root:current train perplexity4.060675621032715
INFO:root:current mean train loss 1791.8832541301751
INFO:root:current train perplexity4.077180862426758
INFO:root:current mean train loss 1778.0759006604146
INFO:root:current train perplexity4.059988975524902
INFO:root:current mean train loss 1778.7350756220458
INFO:root:current train perplexity4.0680718421936035
INFO:root:current mean train loss 1782.3377936632419
INFO:root:current train perplexity4.06956672668457
INFO:root:current mean train loss 1780.2331501328968
INFO:root:current train perplexity4.06770658493042
INFO:root:current mean train loss 1782.0645556863585
INFO:root:current train perplexity4.079608917236328
INFO:root:current mean train loss 1783.7177887567598
INFO:root:current train perplexity4.081019401550293
INFO:root:current mean train loss 1783.3059324177727
INFO:root:current train perplexity4.081059455871582
INFO:root:current mean train loss 1783.8793651935573
INFO:root:current train perplexity4.0821533203125
INFO:root:current mean train loss 1784.7692186252734
INFO:root:current train perplexity4.083389759063721
INFO:root:current mean train loss 1784.399763814519
INFO:root:current train perplexity4.085885047912598
INFO:root:current mean train loss 1784.8455819286992
INFO:root:current train perplexity4.0858154296875
INFO:root:current mean train loss 1785.5944663197483
INFO:root:current train perplexity4.086508750915527
INFO:root:current mean train loss 1785.6350271922722
INFO:root:current train perplexity4.0881547927856445
INFO:root:current mean train loss 1785.5410188394399
INFO:root:current train perplexity4.087996006011963
INFO:root:current mean train loss 1787.5298559526111
INFO:root:current train perplexity4.091728687286377
INFO:root:current mean train loss 1787.3402302480924
INFO:root:current train perplexity4.091794490814209
INFO:root:current mean train loss 1787.1358997548339
INFO:root:current train perplexity4.091400146484375
INFO:root:current mean train loss 1787.5871718011465
INFO:root:current train perplexity4.093428134918213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.87s/it]
INFO:root:final mean train loss: 1787.265683418924
INFO:root:final train perplexity: 4.094093322753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2090.844827854887
INFO:root:eval perplexity: 5.42464542388916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [2:53:22<4:48:44, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.8459043760558
INFO:root:current train perplexity4.079092979431152
INFO:root:current mean train loss 1780.1805553217043
INFO:root:current train perplexity4.050844192504883
INFO:root:current mean train loss 1780.6136211757241
INFO:root:current train perplexity4.068144798278809
INFO:root:current mean train loss 1782.91583219314
INFO:root:current train perplexity4.073925495147705
INFO:root:current mean train loss 1780.7838111587719
INFO:root:current train perplexity4.070510387420654
INFO:root:current mean train loss 1780.2349628089612
INFO:root:current train perplexity4.064280986785889
INFO:root:current mean train loss 1783.9881407061387
INFO:root:current train perplexity4.069031715393066
INFO:root:current mean train loss 1782.8449878939055
INFO:root:current train perplexity4.068057060241699
INFO:root:current mean train loss 1782.2299549094055
INFO:root:current train perplexity4.069336414337158
INFO:root:current mean train loss 1781.100428649777
INFO:root:current train perplexity4.068216800689697
INFO:root:current mean train loss 1780.7731790382768
INFO:root:current train perplexity4.068297863006592
INFO:root:current mean train loss 1780.4877435791432
INFO:root:current train perplexity4.068206310272217
INFO:root:current mean train loss 1780.5367904016325
INFO:root:current train perplexity4.072391986846924
INFO:root:current mean train loss 1780.2850969917042
INFO:root:current train perplexity4.07277250289917
INFO:root:current mean train loss 1781.6068972376663
INFO:root:current train perplexity4.075397968292236
INFO:root:current mean train loss 1781.746716665343
INFO:root:current train perplexity4.076165199279785
INFO:root:current mean train loss 1782.5225905187099
INFO:root:current train perplexity4.079301834106445
INFO:root:current mean train loss 1783.000526333608
INFO:root:current train perplexity4.081052780151367
INFO:root:current mean train loss 1783.4173475853788
INFO:root:current train perplexity4.080965995788574
INFO:root:current mean train loss 1783.9625304124518
INFO:root:current train perplexity4.081469535827637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it]
INFO:root:final mean train loss: 1783.581209260649
INFO:root:final train perplexity: 4.082213401794434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2092.4263781824857
INFO:root:eval perplexity: 5.431588649749756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [2:55:41<4:46:28, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1784.8761818015969
INFO:root:current train perplexity4.049189567565918
INFO:root:current mean train loss 1776.6640184013006
INFO:root:current train perplexity4.038553714752197
INFO:root:current mean train loss 1779.0507611146907
INFO:root:current train perplexity4.0432586669921875
INFO:root:current mean train loss 1778.0625330932305
INFO:root:current train perplexity4.051516532897949
INFO:root:current mean train loss 1779.6225188152368
INFO:root:current train perplexity4.057329177856445
INFO:root:current mean train loss 1780.997128559248
INFO:root:current train perplexity4.060457706451416
INFO:root:current mean train loss 1779.2106453085428
INFO:root:current train perplexity4.059929847717285
INFO:root:current mean train loss 1778.5427855673693
INFO:root:current train perplexity4.058160781860352
INFO:root:current mean train loss 1778.104983345828
INFO:root:current train perplexity4.05666446685791
INFO:root:current mean train loss 1778.607082024352
INFO:root:current train perplexity4.060342788696289
INFO:root:current mean train loss 1780.0272509944646
INFO:root:current train perplexity4.063437461853027
INFO:root:current mean train loss 1781.984339537088
INFO:root:current train perplexity4.066833019256592
INFO:root:current mean train loss 1781.6363755158914
INFO:root:current train perplexity4.067074775695801
INFO:root:current mean train loss 1780.7716796348457
INFO:root:current train perplexity4.068452835083008
INFO:root:current mean train loss 1780.7820424336383
INFO:root:current train perplexity4.067879676818848
INFO:root:current mean train loss 1781.2454577721116
INFO:root:current train perplexity4.069359302520752
INFO:root:current mean train loss 1780.6740681508954
INFO:root:current train perplexity4.068756103515625
INFO:root:current mean train loss 1780.5080201081362
INFO:root:current train perplexity4.069325923919678
INFO:root:current mean train loss 1781.935110365506
INFO:root:current train perplexity4.073963642120361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.78s/it]
INFO:root:final mean train loss: 1780.7668130156133
INFO:root:final train perplexity: 4.073163032531738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2093.549008200355
INFO:root:eval perplexity: 5.436522006988525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [2:57:59<4:44:12, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1781.3558959960938
INFO:root:current train perplexity4.0597662925720215
INFO:root:current mean train loss 1786.8575190791378
INFO:root:current train perplexity4.055047035217285
INFO:root:current mean train loss 1772.0612763624924
INFO:root:current train perplexity4.037049770355225
INFO:root:current mean train loss 1764.2868141075232
INFO:root:current train perplexity4.033231258392334
INFO:root:current mean train loss 1765.0302955777038
INFO:root:current train perplexity4.0378546714782715
INFO:root:current mean train loss 1763.8834507258857
INFO:root:current train perplexity4.035613059997559
INFO:root:current mean train loss 1764.0348380239386
INFO:root:current train perplexity4.036644458770752
INFO:root:current mean train loss 1766.7141715012028
INFO:root:current train perplexity4.04328727722168
INFO:root:current mean train loss 1768.116040220355
INFO:root:current train perplexity4.038430213928223
INFO:root:current mean train loss 1770.6064024265643
INFO:root:current train perplexity4.044288635253906
INFO:root:current mean train loss 1771.1562845139276
INFO:root:current train perplexity4.045612812042236
INFO:root:current mean train loss 1771.4099377793955
INFO:root:current train perplexity4.047271251678467
INFO:root:current mean train loss 1773.1438794672883
INFO:root:current train perplexity4.047757148742676
INFO:root:current mean train loss 1773.6068767582606
INFO:root:current train perplexity4.051779270172119
INFO:root:current mean train loss 1773.7436740181663
INFO:root:current train perplexity4.052755832672119
INFO:root:current mean train loss 1773.431903221879
INFO:root:current train perplexity4.054440498352051
INFO:root:current mean train loss 1775.5294732240895
INFO:root:current train perplexity4.0562310218811035
INFO:root:current mean train loss 1776.5405199108973
INFO:root:current train perplexity4.058701992034912
INFO:root:current mean train loss 1777.1712409500526
INFO:root:current train perplexity4.0585150718688965
INFO:root:current mean train loss 1777.3303589890838
INFO:root:current train perplexity4.05935001373291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it]
INFO:root:final mean train loss: 1776.9627476248306
INFO:root:final train perplexity: 4.06096076965332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2094.762481040143
INFO:root:eval perplexity: 5.441859722137451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:00:18<4:41:47, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.5100341796874
INFO:root:current train perplexity4.023495197296143
INFO:root:current mean train loss 1785.58896875
INFO:root:current train perplexity4.035115718841553
INFO:root:current mean train loss 1776.3702994791668
INFO:root:current train perplexity4.0301947593688965
INFO:root:current mean train loss 1782.6507970252403
INFO:root:current train perplexity4.024570465087891
INFO:root:current mean train loss 1778.7013674747243
INFO:root:current train perplexity4.033731460571289
INFO:root:current mean train loss 1780.4292731584821
INFO:root:current train perplexity4.0340423583984375
INFO:root:current mean train loss 1779.1025984375
INFO:root:current train perplexity4.036012649536133
INFO:root:current mean train loss 1776.3740086206897
INFO:root:current train perplexity4.034768104553223
INFO:root:current mean train loss 1775.4810511363637
INFO:root:current train perplexity4.038976192474365
INFO:root:current mean train loss 1774.5781483583194
INFO:root:current train perplexity4.037236213684082
INFO:root:current mean train loss 1773.2831020150534
INFO:root:current train perplexity4.03921365737915
INFO:root:current mean train loss 1772.7471170789931
INFO:root:current train perplexity4.042657375335693
INFO:root:current mean train loss 1773.0242297114157
INFO:root:current train perplexity4.043026447296143
INFO:root:current mean train loss 1772.3618486512382
INFO:root:current train perplexity4.043644428253174
INFO:root:current mean train loss 1773.130933645148
INFO:root:current train perplexity4.043863773345947
INFO:root:current mean train loss 1771.8368814837347
INFO:root:current train perplexity4.043071746826172
INFO:root:current mean train loss 1771.9537176983174
INFO:root:current train perplexity4.045950889587402
INFO:root:current mean train loss 1773.6728999660327
INFO:root:current train perplexity4.048636436462402
INFO:root:current mean train loss 1774.330345208155
INFO:root:current train perplexity4.051074504852295
INFO:root:current mean train loss 1775.0196826171875
INFO:root:current train perplexity4.052315711975098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it]
INFO:root:final mean train loss: 1773.9177074038014
INFO:root:final train perplexity: 4.051220893859863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2095.014571386026
INFO:root:eval perplexity: 5.442969799041748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:02:36<4:39:26, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.908668154762
INFO:root:current train perplexity4.033761501312256
INFO:root:current mean train loss 1776.4443041304467
INFO:root:current train perplexity4.04240083694458
INFO:root:current mean train loss 1766.1054223431042
INFO:root:current train perplexity4.013004302978516
INFO:root:current mean train loss 1769.12702558194
INFO:root:current train perplexity4.019209861755371
INFO:root:current mean train loss 1765.5852614182693
INFO:root:current train perplexity4.010311126708984
INFO:root:current mean train loss 1765.973335069044
INFO:root:current train perplexity4.012619495391846
INFO:root:current mean train loss 1768.951563374647
INFO:root:current train perplexity4.0235443115234375
INFO:root:current mean train loss 1767.876038091202
INFO:root:current train perplexity4.025356769561768
INFO:root:current mean train loss 1769.4177212749128
INFO:root:current train perplexity4.028307914733887
INFO:root:current mean train loss 1769.9610087724755
INFO:root:current train perplexity4.030043125152588
INFO:root:current mean train loss 1769.366053722184
INFO:root:current train perplexity4.030827522277832
INFO:root:current mean train loss 1769.5158287355653
INFO:root:current train perplexity4.030651092529297
INFO:root:current mean train loss 1769.576696914943
INFO:root:current train perplexity4.030711650848389
INFO:root:current mean train loss 1768.9293503967376
INFO:root:current train perplexity4.031312465667725
INFO:root:current mean train loss 1769.8067612562033
INFO:root:current train perplexity4.0350141525268555
INFO:root:current mean train loss 1769.3419468900727
INFO:root:current train perplexity4.034487724304199
INFO:root:current mean train loss 1769.2536218157638
INFO:root:current train perplexity4.035164833068848
INFO:root:current mean train loss 1769.9014662732761
INFO:root:current train perplexity4.037703037261963
INFO:root:current mean train loss 1769.49572972599
INFO:root:current train perplexity4.037876605987549
INFO:root:current mean train loss 1769.8713726511207
INFO:root:current train perplexity4.038150787353516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.47s/it]
INFO:root:final mean train loss: 1770.1491492382518
INFO:root:final train perplexity: 4.0391974449157715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2095.5217553537786
INFO:root:eval perplexity: 5.445202350616455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:04:55<4:37:01, 138.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.7767209845074
INFO:root:current train perplexity4.040947914123535
INFO:root:current mean train loss 1750.311531882616
INFO:root:current train perplexity4.014780044555664
INFO:root:current mean train loss 1752.5318801467483
INFO:root:current train perplexity4.0054755210876465
INFO:root:current mean train loss 1758.2181022452776
INFO:root:current train perplexity4.011779308319092
INFO:root:current mean train loss 1759.0162103524135
INFO:root:current train perplexity4.015147686004639
INFO:root:current mean train loss 1760.4288646718471
INFO:root:current train perplexity4.014771461486816
INFO:root:current mean train loss 1760.8631482507824
INFO:root:current train perplexity4.012054443359375
INFO:root:current mean train loss 1759.8703999274333
INFO:root:current train perplexity4.0101423263549805
INFO:root:current mean train loss 1760.6733858865687
INFO:root:current train perplexity4.013136863708496
INFO:root:current mean train loss 1761.9791011551747
INFO:root:current train perplexity4.015042304992676
INFO:root:current mean train loss 1763.0120473831075
INFO:root:current train perplexity4.016503810882568
INFO:root:current mean train loss 1763.7478043142323
INFO:root:current train perplexity4.01784610748291
INFO:root:current mean train loss 1764.7973054941917
INFO:root:current train perplexity4.020522117614746
INFO:root:current mean train loss 1765.3422911744333
INFO:root:current train perplexity4.019402980804443
INFO:root:current mean train loss 1765.7048229403165
INFO:root:current train perplexity4.021312236785889
INFO:root:current mean train loss 1767.308565248657
INFO:root:current train perplexity4.023532390594482
INFO:root:current mean train loss 1765.8802421804362
INFO:root:current train perplexity4.022955417633057
INFO:root:current mean train loss 1767.0009146598743
INFO:root:current train perplexity4.026278495788574
INFO:root:current mean train loss 1767.1646331902023
INFO:root:current train perplexity4.029051780700684
INFO:root:current mean train loss 1767.7166442092187
INFO:root:current train perplexity4.029750347137451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.37s/it]
INFO:root:final mean train loss: 1767.1279545878738
INFO:root:final train perplexity: 4.0295844078063965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2097.4058045732213
INFO:root:eval perplexity: 5.453505992889404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:07:13<4:34:36, 138.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.0072471217106
INFO:root:current train perplexity3.9564292430877686
INFO:root:current mean train loss 1743.861764387651
INFO:root:current train perplexity3.9633891582489014
INFO:root:current mean train loss 1743.9610971644304
INFO:root:current train perplexity3.968015432357788
INFO:root:current mean train loss 1747.3461180342006
INFO:root:current train perplexity3.9707188606262207
INFO:root:current mean train loss 1751.6351869727382
INFO:root:current train perplexity3.980642080307007
INFO:root:current mean train loss 1754.1529954274495
INFO:root:current train perplexity3.9856069087982178
INFO:root:current mean train loss 1754.9209618201623
INFO:root:current train perplexity3.9869027137756348
INFO:root:current mean train loss 1756.8110747976402
INFO:root:current train perplexity3.9937944412231445
INFO:root:current mean train loss 1756.6659895666114
INFO:root:current train perplexity3.9958736896514893
INFO:root:current mean train loss 1757.3638702142434
INFO:root:current train perplexity3.9985530376434326
INFO:root:current mean train loss 1756.8768942453605
INFO:root:current train perplexity4.000186920166016
INFO:root:current mean train loss 1758.0111200241815
INFO:root:current train perplexity4.004490375518799
INFO:root:current mean train loss 1759.7496954938836
INFO:root:current train perplexity4.00748348236084
INFO:root:current mean train loss 1760.900125636611
INFO:root:current train perplexity4.009073257446289
INFO:root:current mean train loss 1761.1699939924204
INFO:root:current train perplexity4.010503768920898
INFO:root:current mean train loss 1762.0914646671508
INFO:root:current train perplexity4.013317108154297
INFO:root:current mean train loss 1762.1260847942926
INFO:root:current train perplexity4.013726711273193
INFO:root:current mean train loss 1762.9182958516988
INFO:root:current train perplexity4.014160633087158
INFO:root:current mean train loss 1763.8522382463727
INFO:root:current train perplexity4.017792224884033
INFO:root:current mean train loss 1764.378672117164
INFO:root:current train perplexity4.019181728363037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.78s/it]
INFO:root:final mean train loss: 1763.8668678887734
INFO:root:final train perplexity: 4.019234657287598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2097.785639769642
INFO:root:eval perplexity: 5.45518159866333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:09:32<4:32:27, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.4063116914483
INFO:root:current train perplexity3.976635694503784
INFO:root:current mean train loss 1757.3430542624676
INFO:root:current train perplexity3.9781265258789062
INFO:root:current mean train loss 1751.8953690772985
INFO:root:current train perplexity3.979855537414551
INFO:root:current mean train loss 1745.4460884074824
INFO:root:current train perplexity3.963977575302124
INFO:root:current mean train loss 1750.1302235199037
INFO:root:current train perplexity3.97629451751709
INFO:root:current mean train loss 1751.6337289536784
INFO:root:current train perplexity3.980257749557495
INFO:root:current mean train loss 1751.4811102796943
INFO:root:current train perplexity3.98227858543396
INFO:root:current mean train loss 1752.4594989791042
INFO:root:current train perplexity3.9853403568267822
INFO:root:current mean train loss 1757.610236737122
INFO:root:current train perplexity3.994621992111206
INFO:root:current mean train loss 1758.5296019893158
INFO:root:current train perplexity3.9959352016448975
INFO:root:current mean train loss 1757.4060854898717
INFO:root:current train perplexity3.994720220565796
INFO:root:current mean train loss 1758.006044066462
INFO:root:current train perplexity3.999791145324707
INFO:root:current mean train loss 1759.3455076992097
INFO:root:current train perplexity4.002196788787842
INFO:root:current mean train loss 1757.684127950018
INFO:root:current train perplexity4.00173807144165
INFO:root:current mean train loss 1758.4979558741575
INFO:root:current train perplexity4.0022149085998535
INFO:root:current mean train loss 1758.1616705195827
INFO:root:current train perplexity4.002172946929932
INFO:root:current mean train loss 1758.2069827968105
INFO:root:current train perplexity4.003695487976074
INFO:root:current mean train loss 1759.2134769437569
INFO:root:current train perplexity4.005303382873535
INFO:root:current mean train loss 1760.0208774411483
INFO:root:current train perplexity4.007730484008789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.45s/it]
INFO:root:final mean train loss: 1760.4928894504658
INFO:root:final train perplexity: 4.008553981781006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2098.645234669354
INFO:root:eval perplexity: 5.458975791931152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:11:50<4:30:03, 138.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.946484375
INFO:root:current train perplexity3.9280788898468018
INFO:root:current mean train loss 1748.9927135120738
INFO:root:current train perplexity3.9670298099517822
INFO:root:current mean train loss 1740.7069091796875
INFO:root:current train perplexity3.9576239585876465
INFO:root:current mean train loss 1741.4340013073336
INFO:root:current train perplexity3.962437391281128
INFO:root:current mean train loss 1741.8970819240662
INFO:root:current train perplexity3.9643592834472656
INFO:root:current mean train loss 1746.20958850337
INFO:root:current train perplexity3.9716522693634033
INFO:root:current mean train loss 1751.2244722960424
INFO:root:current train perplexity3.981092929840088
INFO:root:current mean train loss 1750.9566261828786
INFO:root:current train perplexity3.977646589279175
INFO:root:current mean train loss 1749.6880268614968
INFO:root:current train perplexity3.9775843620300293
INFO:root:current mean train loss 1751.1467393812243
INFO:root:current train perplexity3.9813497066497803
INFO:root:current mean train loss 1751.6564610245205
INFO:root:current train perplexity3.9826836585998535
INFO:root:current mean train loss 1753.324962389147
INFO:root:current train perplexity3.9876201152801514
INFO:root:current mean train loss 1753.8000208831031
INFO:root:current train perplexity3.9900870323181152
INFO:root:current mean train loss 1753.6912962003519
INFO:root:current train perplexity3.991840124130249
INFO:root:current mean train loss 1754.5390582578402
INFO:root:current train perplexity3.994037389755249
INFO:root:current mean train loss 1756.5275071301996
INFO:root:current train perplexity3.996366262435913
INFO:root:current mean train loss 1757.139462829969
INFO:root:current train perplexity3.9983956813812256
INFO:root:current mean train loss 1757.6928452519646
INFO:root:current train perplexity4.000213623046875
INFO:root:current mean train loss 1757.4986386125258
INFO:root:current train perplexity4.000656604766846
INFO:root:current mean train loss 1758.1146045944454
INFO:root:current train perplexity4.000744819641113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it]
INFO:root:final mean train loss: 1757.5395095678994
INFO:root:final train perplexity: 3.9992284774780273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2100.6734593168217
INFO:root:eval perplexity: 5.4679365158081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:14:09<4:27:47, 138.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1776.0961778428818
INFO:root:current train perplexity3.9990270137786865
INFO:root:current mean train loss 1736.811791607714
INFO:root:current train perplexity3.946530818939209
INFO:root:current mean train loss 1751.222587417401
INFO:root:current train perplexity3.9684672355651855
INFO:root:current mean train loss 1749.3485745771216
INFO:root:current train perplexity3.9688727855682373
INFO:root:current mean train loss 1748.132973735729
INFO:root:current train perplexity3.973947048187256
INFO:root:current mean train loss 1749.8501127123607
INFO:root:current train perplexity3.9651453495025635
INFO:root:current mean train loss 1748.7495019842754
INFO:root:current train perplexity3.9691991806030273
INFO:root:current mean train loss 1747.3263114079157
INFO:root:current train perplexity3.9698309898376465
INFO:root:current mean train loss 1747.0436269259656
INFO:root:current train perplexity3.970219850540161
INFO:root:current mean train loss 1746.7282184160515
INFO:root:current train perplexity3.9697377681732178
INFO:root:current mean train loss 1747.6109074756953
INFO:root:current train perplexity3.973055362701416
INFO:root:current mean train loss 1748.1695158043685
INFO:root:current train perplexity3.9757039546966553
INFO:root:current mean train loss 1748.771826609617
INFO:root:current train perplexity3.9773032665252686
INFO:root:current mean train loss 1750.768891829697
INFO:root:current train perplexity3.9778504371643066
INFO:root:current mean train loss 1751.7443425072267
INFO:root:current train perplexity3.979046583175659
INFO:root:current mean train loss 1753.5859115190888
INFO:root:current train perplexity3.982992172241211
INFO:root:current mean train loss 1753.5315557384902
INFO:root:current train perplexity3.985513210296631
INFO:root:current mean train loss 1755.3740676146542
INFO:root:current train perplexity3.987985134124756
INFO:root:current mean train loss 1755.1133128533156
INFO:root:current train perplexity3.9903109073638916
INFO:root:current mean train loss 1755.2729745576835
INFO:root:current train perplexity3.990757703781128

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 1754.8401227942393
INFO:root:final train perplexity: 3.990722894668579
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2100.771404293412
INFO:root:eval perplexity: 5.468369483947754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [3:16:27<4:25:33, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.9948147860441
INFO:root:current train perplexity3.908503770828247
INFO:root:current mean train loss 1744.6650890774197
INFO:root:current train perplexity3.934581995010376
INFO:root:current mean train loss 1742.299844210265
INFO:root:current train perplexity3.9464292526245117
INFO:root:current mean train loss 1741.2186392850654
INFO:root:current train perplexity3.9578282833099365
INFO:root:current mean train loss 1739.0889815596847
INFO:root:current train perplexity3.949775218963623
INFO:root:current mean train loss 1739.868283215691
INFO:root:current train perplexity3.9573631286621094
INFO:root:current mean train loss 1742.9760334654625
INFO:root:current train perplexity3.962773084640503
INFO:root:current mean train loss 1744.6276079403456
INFO:root:current train perplexity3.9651906490325928
INFO:root:current mean train loss 1747.6519193965678
INFO:root:current train perplexity3.966367721557617
INFO:root:current mean train loss 1747.6716412043168
INFO:root:current train perplexity3.968073606491089
INFO:root:current mean train loss 1747.2632289608775
INFO:root:current train perplexity3.9695229530334473
INFO:root:current mean train loss 1749.5662278395432
INFO:root:current train perplexity3.9722869396209717
INFO:root:current mean train loss 1749.2998436440225
INFO:root:current train perplexity3.971902847290039
INFO:root:current mean train loss 1749.136739004226
INFO:root:current train perplexity3.971257448196411
INFO:root:current mean train loss 1749.2313592546204
INFO:root:current train perplexity3.9734373092651367
INFO:root:current mean train loss 1748.3100602540328
INFO:root:current train perplexity3.97243070602417
INFO:root:current mean train loss 1750.2628936396318
INFO:root:current train perplexity3.977233648300171
INFO:root:current mean train loss 1750.1963832750232
INFO:root:current train perplexity3.976733922958374
INFO:root:current mean train loss 1750.5019275723207
INFO:root:current train perplexity3.977433204650879
INFO:root:current mean train loss 1751.5756072998047
INFO:root:current train perplexity3.978074789047241

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it]
INFO:root:final mean train loss: 1751.0317500389049
INFO:root:final train perplexity: 3.978755474090576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2102.197624477089
INFO:root:eval perplexity: 5.474681377410889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [3:18:46<4:23:14, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.5700583536118
INFO:root:current train perplexity3.942802906036377
INFO:root:current mean train loss 1730.4261216821137
INFO:root:current train perplexity3.9615087509155273
INFO:root:current mean train loss 1729.8359459186422
INFO:root:current train perplexity3.9510457515716553
INFO:root:current mean train loss 1736.7803363324533
INFO:root:current train perplexity3.953822374343872
INFO:root:current mean train loss 1732.3709046866527
INFO:root:current train perplexity3.9476945400238037
INFO:root:current mean train loss 1737.617217310397
INFO:root:current train perplexity3.9567103385925293
INFO:root:current mean train loss 1736.9209311250117
INFO:root:current train perplexity3.9520788192749023
INFO:root:current mean train loss 1737.9876304756797
INFO:root:current train perplexity3.9527955055236816
INFO:root:current mean train loss 1740.1585500542158
INFO:root:current train perplexity3.955789089202881
INFO:root:current mean train loss 1741.0241612842253
INFO:root:current train perplexity3.959868907928467
INFO:root:current mean train loss 1740.954375961836
INFO:root:current train perplexity3.956901788711548
INFO:root:current mean train loss 1741.5505444693422
INFO:root:current train perplexity3.9584195613861084
INFO:root:current mean train loss 1742.3311114148617
INFO:root:current train perplexity3.9596164226531982
INFO:root:current mean train loss 1742.7073877742412
INFO:root:current train perplexity3.959270477294922
INFO:root:current mean train loss 1743.4400868712835
INFO:root:current train perplexity3.9617321491241455
INFO:root:current mean train loss 1744.8467791579917
INFO:root:current train perplexity3.9625563621520996
INFO:root:current mean train loss 1745.775763597207
INFO:root:current train perplexity3.964224100112915
INFO:root:current mean train loss 1746.8540174234056
INFO:root:current train perplexity3.9658865928649902
INFO:root:current mean train loss 1747.192834885898
INFO:root:current train perplexity3.967071056365967
INFO:root:current mean train loss 1747.8009280331703
INFO:root:current train perplexity3.9679932594299316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1747.6349930217395
INFO:root:final train perplexity: 3.9681105613708496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2102.696910235899
INFO:root:eval perplexity: 5.47689151763916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [3:21:05<4:21:03, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.4148356119792
INFO:root:current train perplexity3.9350616931915283
INFO:root:current mean train loss 1744.2488842224807
INFO:root:current train perplexity3.950073719024658
INFO:root:current mean train loss 1742.0641580485612
INFO:root:current train perplexity3.940577507019043
INFO:root:current mean train loss 1741.0297564148273
INFO:root:current train perplexity3.94282865524292
INFO:root:current mean train loss 1741.9101914920568
INFO:root:current train perplexity3.94467830657959
INFO:root:current mean train loss 1740.9618863960452
INFO:root:current train perplexity3.942995071411133
INFO:root:current mean train loss 1741.544421890844
INFO:root:current train perplexity3.944809913635254
INFO:root:current mean train loss 1740.6870584757592
INFO:root:current train perplexity3.9444680213928223
INFO:root:current mean train loss 1741.3128086515874
INFO:root:current train perplexity3.9519901275634766
INFO:root:current mean train loss 1744.1860390255545
INFO:root:current train perplexity3.9557735919952393
INFO:root:current mean train loss 1744.0652764768017
INFO:root:current train perplexity3.9543814659118652
INFO:root:current mean train loss 1744.3397299696917
INFO:root:current train perplexity3.956141471862793
INFO:root:current mean train loss 1744.5934162647325
INFO:root:current train perplexity3.955893039703369
INFO:root:current mean train loss 1744.9483280264933
INFO:root:current train perplexity3.95774245262146
INFO:root:current mean train loss 1745.2952985750644
INFO:root:current train perplexity3.958698034286499
INFO:root:current mean train loss 1745.0304618032865
INFO:root:current train perplexity3.9584403038024902
INFO:root:current mean train loss 1744.96699918581
INFO:root:current train perplexity3.960008144378662
INFO:root:current mean train loss 1745.046333853654
INFO:root:current train perplexity3.959462881088257
INFO:root:current mean train loss 1745.9338014905318
INFO:root:current train perplexity3.9614317417144775
INFO:root:current mean train loss 1746.0003917605377
INFO:root:current train perplexity3.962022066116333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.83s/it]
INFO:root:final mean train loss: 1745.6864723440258
INFO:root:final train perplexity: 3.962017297744751
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2103.0915414796655
INFO:root:eval perplexity: 5.478640079498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [3:23:23<4:18:49, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.0769197162829
INFO:root:current train perplexity3.929241180419922
INFO:root:current mean train loss 1731.857158954327
INFO:root:current train perplexity3.9048755168914795
INFO:root:current mean train loss 1732.580738959878
INFO:root:current train perplexity3.905670166015625
INFO:root:current mean train loss 1732.6254997156843
INFO:root:current train perplexity3.9177234172821045
INFO:root:current mean train loss 1735.138916015625
INFO:root:current train perplexity3.922424077987671
INFO:root:current mean train loss 1734.5086928423714
INFO:root:current train perplexity3.9276504516601562
INFO:root:current mean train loss 1736.8500774575652
INFO:root:current train perplexity3.929564952850342
INFO:root:current mean train loss 1739.0499348958333
INFO:root:current train perplexity3.929861068725586
INFO:root:current mean train loss 1739.689228897521
INFO:root:current train perplexity3.9313106536865234
INFO:root:current mean train loss 1739.6093980645414
INFO:root:current train perplexity3.9354355335235596
INFO:root:current mean train loss 1740.5046397866724
INFO:root:current train perplexity3.941377639770508
INFO:root:current mean train loss 1740.3573825469077
INFO:root:current train perplexity3.9386181831359863
INFO:root:current mean train loss 1740.5824557153414
INFO:root:current train perplexity3.941622734069824
INFO:root:current mean train loss 1740.9612862098174
INFO:root:current train perplexity3.941948413848877
INFO:root:current mean train loss 1741.140610302571
INFO:root:current train perplexity3.9453070163726807
INFO:root:current mean train loss 1741.0850093829595
INFO:root:current train perplexity3.9450042247772217
INFO:root:current mean train loss 1741.9136803010924
INFO:root:current train perplexity3.9467718601226807
INFO:root:current mean train loss 1743.07306238031
INFO:root:current train perplexity3.949976682662964
INFO:root:current mean train loss 1742.6323210623145
INFO:root:current train perplexity3.9498534202575684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1742.4774631302103
INFO:root:final train perplexity: 3.952003002166748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2103.685936893977
INFO:root:eval perplexity: 5.481274604797363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [3:25:42<4:16:23, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1731.2825826009114
INFO:root:current train perplexity3.9069907665252686
INFO:root:current mean train loss 1724.716213771275
INFO:root:current train perplexity3.86434006690979
INFO:root:current mean train loss 1728.8238669341465
INFO:root:current train perplexity3.883136034011841
INFO:root:current mean train loss 1741.3416877159705
INFO:root:current train perplexity3.910961866378784
INFO:root:current mean train loss 1741.6679326029657
INFO:root:current train perplexity3.919624090194702
INFO:root:current mean train loss 1742.451315164566
INFO:root:current train perplexity3.9245946407318115
INFO:root:current mean train loss 1737.4837929719413
INFO:root:current train perplexity3.9216954708099365
INFO:root:current mean train loss 1734.5332794189453
INFO:root:current train perplexity3.920586347579956
INFO:root:current mean train loss 1735.8239785180303
INFO:root:current train perplexity3.9275572299957275
INFO:root:current mean train loss 1735.75054744252
INFO:root:current train perplexity3.9288487434387207
INFO:root:current mean train loss 1734.9901564526463
INFO:root:current train perplexity3.929577589035034
INFO:root:current mean train loss 1735.9649034678507
INFO:root:current train perplexity3.9294614791870117
INFO:root:current mean train loss 1735.8464643522457
INFO:root:current train perplexity3.932119846343994
INFO:root:current mean train loss 1736.9261935164288
INFO:root:current train perplexity3.9334876537323
INFO:root:current mean train loss 1736.5303295448887
INFO:root:current train perplexity3.9345409870147705
INFO:root:current mean train loss 1738.2898247128442
INFO:root:current train perplexity3.937912940979004
INFO:root:current mean train loss 1739.6647106388366
INFO:root:current train perplexity3.939610481262207
INFO:root:current mean train loss 1739.6946802584926
INFO:root:current train perplexity3.9403765201568604
INFO:root:current mean train loss 1739.131721749211
INFO:root:current train perplexity3.9387640953063965
INFO:root:current mean train loss 1739.2604672100754
INFO:root:current train perplexity3.940488815307617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it]
INFO:root:final mean train loss: 1739.113889539356
INFO:root:final train perplexity: 3.941533088684082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2105.9030051806294
INFO:root:eval perplexity: 5.491110801696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [3:28:01<4:14:08, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1738.4271997912176
INFO:root:current train perplexity3.854220390319824
INFO:root:current mean train loss 1735.353946183079
INFO:root:current train perplexity3.9257428646087646
INFO:root:current mean train loss 1735.0342857660685
INFO:root:current train perplexity3.9224767684936523
INFO:root:current mean train loss 1733.1658586774554
INFO:root:current train perplexity3.9185588359832764
INFO:root:current mean train loss 1734.4758064607918
INFO:root:current train perplexity3.9253807067871094
INFO:root:current mean train loss 1739.3100237494832
INFO:root:current train perplexity3.9283995628356934
INFO:root:current mean train loss 1737.8231785323926
INFO:root:current train perplexity3.9291489124298096
INFO:root:current mean train loss 1738.0393297485855
INFO:root:current train perplexity3.9346625804901123
INFO:root:current mean train loss 1738.4724658556524
INFO:root:current train perplexity3.9335947036743164
INFO:root:current mean train loss 1738.7943540969372
INFO:root:current train perplexity3.9341859817504883
INFO:root:current mean train loss 1737.2502147203747
INFO:root:current train perplexity3.9324848651885986
INFO:root:current mean train loss 1735.806608512615
INFO:root:current train perplexity3.930363655090332
INFO:root:current mean train loss 1736.4933050045452
INFO:root:current train perplexity3.9300947189331055
INFO:root:current mean train loss 1735.8455898724076
INFO:root:current train perplexity3.930258274078369
INFO:root:current mean train loss 1736.7797777243975
INFO:root:current train perplexity3.931413412094116
INFO:root:current mean train loss 1736.9221597775047
INFO:root:current train perplexity3.9309887886047363
INFO:root:current mean train loss 1735.975400621427
INFO:root:current train perplexity3.93171763420105
INFO:root:current mean train loss 1736.4299730838138
INFO:root:current train perplexity3.9313809871673584
INFO:root:current mean train loss 1736.984092683203
INFO:root:current train perplexity3.930999517440796
INFO:root:current mean train loss 1737.0583405600983
INFO:root:current train perplexity3.9314138889312744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it]
INFO:root:final mean train loss: 1736.1740447182399
INFO:root:final train perplexity: 3.932405710220337
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2107.1898163058236
INFO:root:eval perplexity: 5.496828556060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [3:30:19<4:11:53, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.691668966542
INFO:root:current train perplexity3.8937830924987793
INFO:root:current mean train loss 1717.2126832726883
INFO:root:current train perplexity3.887360095977783
INFO:root:current mean train loss 1728.460150493839
INFO:root:current train perplexity3.9015228748321533
INFO:root:current mean train loss 1731.0903616668172
INFO:root:current train perplexity3.9136240482330322
INFO:root:current mean train loss 1732.8241593570453
INFO:root:current train perplexity3.9202685356140137
INFO:root:current mean train loss 1729.47708655277
INFO:root:current train perplexity3.9195199012756348
INFO:root:current mean train loss 1731.9524902721678
INFO:root:current train perplexity3.9220733642578125
INFO:root:current mean train loss 1730.9938128678473
INFO:root:current train perplexity3.9203059673309326
INFO:root:current mean train loss 1730.340288455323
INFO:root:current train perplexity3.920663356781006
INFO:root:current mean train loss 1731.5679455488983
INFO:root:current train perplexity3.9227325916290283
INFO:root:current mean train loss 1733.1500765798653
INFO:root:current train perplexity3.9232447147369385
INFO:root:current mean train loss 1733.3080428358148
INFO:root:current train perplexity3.9230895042419434
INFO:root:current mean train loss 1732.8904782413097
INFO:root:current train perplexity3.922074794769287
INFO:root:current mean train loss 1732.5550754768178
INFO:root:current train perplexity3.9233274459838867
INFO:root:current mean train loss 1733.0348600226648
INFO:root:current train perplexity3.924022912979126
INFO:root:current mean train loss 1734.1585627033978
INFO:root:current train perplexity3.9267239570617676
INFO:root:current mean train loss 1733.8247147440766
INFO:root:current train perplexity3.9270119667053223
INFO:root:current mean train loss 1734.1506709113016
INFO:root:current train perplexity3.9262044429779053
INFO:root:current mean train loss 1734.3015262359916
INFO:root:current train perplexity3.925529956817627
INFO:root:current mean train loss 1734.069902127963
INFO:root:current train perplexity3.924712657928467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.32s/it]
INFO:root:final mean train loss: 1734.006052606826
INFO:root:final train perplexity: 3.925687313079834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2106.935572847407
INFO:root:eval perplexity: 5.495698928833008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [3:32:38<4:09:22, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.4354558066716
INFO:root:current train perplexity3.8634049892425537
INFO:root:current mean train loss 1705.3303230145227
INFO:root:current train perplexity3.8694050312042236
INFO:root:current mean train loss 1714.1798480944035
INFO:root:current train perplexity3.881779432296753
INFO:root:current mean train loss 1716.4136344132016
INFO:root:current train perplexity3.8845314979553223
INFO:root:current mean train loss 1720.1808905385226
INFO:root:current train perplexity3.88881254196167
INFO:root:current mean train loss 1718.7201571693217
INFO:root:current train perplexity3.893481492996216
INFO:root:current mean train loss 1720.949994991987
INFO:root:current train perplexity3.8984498977661133
INFO:root:current mean train loss 1720.9945554720778
INFO:root:current train perplexity3.8996193408966064
INFO:root:current mean train loss 1719.962640826423
INFO:root:current train perplexity3.897754669189453
INFO:root:current mean train loss 1722.2760265821732
INFO:root:current train perplexity3.8980166912078857
INFO:root:current mean train loss 1725.204833984375
INFO:root:current train perplexity3.8997318744659424
INFO:root:current mean train loss 1726.0574825217984
INFO:root:current train perplexity3.903717517852783
INFO:root:current mean train loss 1727.1763466588109
INFO:root:current train perplexity3.906630277633667
INFO:root:current mean train loss 1728.5472515999002
INFO:root:current train perplexity3.90913987159729
INFO:root:current mean train loss 1729.7351992040649
INFO:root:current train perplexity3.9123198986053467
INFO:root:current mean train loss 1729.2550046485126
INFO:root:current train perplexity3.9106030464172363
INFO:root:current mean train loss 1730.2308821595009
INFO:root:current train perplexity3.9129247665405273
INFO:root:current mean train loss 1730.7913944376373
INFO:root:current train perplexity3.912949562072754
INFO:root:current mean train loss 1730.764221879403
INFO:root:current train perplexity3.913206100463867
INFO:root:current mean train loss 1731.4283437937786
INFO:root:current train perplexity3.916260004043579

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1731.050979529615
INFO:root:final train perplexity: 3.9165494441986084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2107.1778101278537
INFO:root:eval perplexity: 5.4967756271362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [3:34:56<4:07:08, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1710.167446899414
INFO:root:current train perplexity3.884181499481201
INFO:root:current mean train loss 1717.6344950358073
INFO:root:current train perplexity3.8737900257110596
INFO:root:current mean train loss 1721.7912523542132
INFO:root:current train perplexity3.8820035457611084
INFO:root:current mean train loss 1723.5518724943463
INFO:root:current train perplexity3.8869192600250244
INFO:root:current mean train loss 1720.2858741760253
INFO:root:current train perplexity3.8879647254943848
INFO:root:current mean train loss 1722.0262564823545
INFO:root:current train perplexity3.892852544784546
INFO:root:current mean train loss 1721.160475068934
INFO:root:current train perplexity3.8943305015563965
INFO:root:current mean train loss 1723.811138290014
INFO:root:current train perplexity3.9007198810577393
INFO:root:current mean train loss 1724.0955831354315
INFO:root:current train perplexity3.8988571166992188
INFO:root:current mean train loss 1724.419854487205
INFO:root:current train perplexity3.90126633644104
INFO:root:current mean train loss 1725.8826550519025
INFO:root:current train perplexity3.903571367263794
INFO:root:current mean train loss 1727.478011722888
INFO:root:current train perplexity3.9049503803253174
INFO:root:current mean train loss 1727.3726732254029
INFO:root:current train perplexity3.9059081077575684
INFO:root:current mean train loss 1727.9623316668083
INFO:root:current train perplexity3.907182216644287
INFO:root:current mean train loss 1727.3524599642367
INFO:root:current train perplexity3.9064557552337646
INFO:root:current mean train loss 1727.8791828396954
INFO:root:current train perplexity3.906439781188965
INFO:root:current mean train loss 1727.9965645926338
INFO:root:current train perplexity3.9063546657562256
INFO:root:current mean train loss 1727.9545949185833
INFO:root:current train perplexity3.9059760570526123
INFO:root:current mean train loss 1727.9405060463764
INFO:root:current train perplexity3.906557083129883
INFO:root:current mean train loss 1728.6267764313052
INFO:root:current train perplexity3.907780408859253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it]
INFO:root:final mean train loss: 1728.169079386701
INFO:root:final train perplexity: 3.9076573848724365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2108.813670489805
INFO:root:eval perplexity: 5.504052639007568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [3:37:15<4:04:54, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.825898789868
INFO:root:current train perplexity3.8425252437591553
INFO:root:current mean train loss 1720.8074548401808
INFO:root:current train perplexity3.872793674468994
INFO:root:current mean train loss 1716.5467960858587
INFO:root:current train perplexity3.8652260303497314
INFO:root:current mean train loss 1720.271125543628
INFO:root:current train perplexity3.877265691757202
INFO:root:current mean train loss 1722.4222962285432
INFO:root:current train perplexity3.8810720443725586
INFO:root:current mean train loss 1721.576513958137
INFO:root:current train perplexity3.882193088531494
INFO:root:current mean train loss 1720.4860629679654
INFO:root:current train perplexity3.878737211227417
INFO:root:current mean train loss 1721.453683276398
INFO:root:current train perplexity3.8827028274536133
INFO:root:current mean train loss 1722.3623842985733
INFO:root:current train perplexity3.8855583667755127
INFO:root:current mean train loss 1720.9731183295983
INFO:root:current train perplexity3.88494873046875
INFO:root:current mean train loss 1722.2109280414982
INFO:root:current train perplexity3.8840222358703613
INFO:root:current mean train loss 1722.7403835720486
INFO:root:current train perplexity3.885826826095581
INFO:root:current mean train loss 1723.5416599529563
INFO:root:current train perplexity3.8895344734191895
INFO:root:current mean train loss 1724.4012874092643
INFO:root:current train perplexity3.8909623622894287
INFO:root:current mean train loss 1725.1093764677794
INFO:root:current train perplexity3.8911776542663574
INFO:root:current mean train loss 1725.697628549135
INFO:root:current train perplexity3.8946948051452637
INFO:root:current mean train loss 1726.0355856181175
INFO:root:current train perplexity3.8984014987945557
INFO:root:current mean train loss 1726.5004040479794
INFO:root:current train perplexity3.9007816314697266
INFO:root:current mean train loss 1726.393270071268
INFO:root:current train perplexity3.8999295234680176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it]
INFO:root:final mean train loss: 1725.7737845970535
INFO:root:final train perplexity: 3.900282859802246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2110.147358779366
INFO:root:eval perplexity: 5.509991645812988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [3:39:34<4:02:33, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.7705601283483
INFO:root:current train perplexity3.7997138500213623
INFO:root:current mean train loss 1722.0516700075384
INFO:root:current train perplexity3.844895601272583
INFO:root:current mean train loss 1721.488634911653
INFO:root:current train perplexity3.854619264602661
INFO:root:current mean train loss 1722.0085484207057
INFO:root:current train perplexity3.859473943710327
INFO:root:current mean train loss 1721.045514240357
INFO:root:current train perplexity3.8668103218078613
INFO:root:current mean train loss 1719.028002787193
INFO:root:current train perplexity3.867723226547241
INFO:root:current mean train loss 1719.8019104997963
INFO:root:current train perplexity3.872593879699707
INFO:root:current mean train loss 1718.7568390149029
INFO:root:current train perplexity3.8759264945983887
INFO:root:current mean train loss 1718.6183390699382
INFO:root:current train perplexity3.87783145904541
INFO:root:current mean train loss 1718.5033336948252
INFO:root:current train perplexity3.879051685333252
INFO:root:current mean train loss 1719.258463300897
INFO:root:current train perplexity3.8803822994232178
INFO:root:current mean train loss 1721.6833461028668
INFO:root:current train perplexity3.884723663330078
INFO:root:current mean train loss 1722.2192100260952
INFO:root:current train perplexity3.8849997520446777
INFO:root:current mean train loss 1723.121481420787
INFO:root:current train perplexity3.8860714435577393
INFO:root:current mean train loss 1722.0662322954881
INFO:root:current train perplexity3.8851029872894287
INFO:root:current mean train loss 1722.7533778967913
INFO:root:current train perplexity3.8862197399139404
INFO:root:current mean train loss 1722.8808806276381
INFO:root:current train perplexity3.88690447807312
INFO:root:current mean train loss 1722.8469845071834
INFO:root:current train perplexity3.8896708488464355
INFO:root:current mean train loss 1723.358752535617
INFO:root:current train perplexity3.890221357345581
INFO:root:current mean train loss 1722.6725332485346
INFO:root:current train perplexity3.8893935680389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.80s/it]
INFO:root:final mean train loss: 1722.4117002578557
INFO:root:final train perplexity: 3.8899545669555664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2112.1714109596633
INFO:root:eval perplexity: 5.519020080566406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [3:41:52<4:00:19, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1732.4036550214214
INFO:root:current train perplexity3.858751058578491
INFO:root:current mean train loss 1711.8480159380963
INFO:root:current train perplexity3.8452365398406982
INFO:root:current mean train loss 1714.991801208232
INFO:root:current train perplexity3.876479148864746
INFO:root:current mean train loss 1717.4769630086387
INFO:root:current train perplexity3.8734970092773438
INFO:root:current mean train loss 1712.1024444650884
INFO:root:current train perplexity3.865396499633789
INFO:root:current mean train loss 1712.195464915475
INFO:root:current train perplexity3.8638687133789062
INFO:root:current mean train loss 1711.993409363857
INFO:root:current train perplexity3.8595571517944336
INFO:root:current mean train loss 1710.3685980717232
INFO:root:current train perplexity3.854616165161133
INFO:root:current mean train loss 1712.3804667228396
INFO:root:current train perplexity3.858766794204712
INFO:root:current mean train loss 1713.1173142905393
INFO:root:current train perplexity3.861656665802002
INFO:root:current mean train loss 1712.724436274324
INFO:root:current train perplexity3.8598599433898926
INFO:root:current mean train loss 1712.6579840244392
INFO:root:current train perplexity3.861844539642334
INFO:root:current mean train loss 1712.5093281154802
INFO:root:current train perplexity3.861161708831787
INFO:root:current mean train loss 1713.7589798260237
INFO:root:current train perplexity3.865144968032837
INFO:root:current mean train loss 1714.5064838017558
INFO:root:current train perplexity3.868589162826538
INFO:root:current mean train loss 1715.9547026651035
INFO:root:current train perplexity3.869993209838867
INFO:root:current mean train loss 1717.120682557911
INFO:root:current train perplexity3.8736534118652344
INFO:root:current mean train loss 1718.3688748347008
INFO:root:current train perplexity3.875800371170044
INFO:root:current mean train loss 1718.9727021180365
INFO:root:current train perplexity3.8767614364624023
INFO:root:current mean train loss 1719.7685036088815
INFO:root:current train perplexity3.880737543106079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it]
INFO:root:final mean train loss: 1719.7254800878266
INFO:root:final train perplexity: 3.8817222118377686
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2113.011536077405
INFO:root:eval perplexity: 5.522770881652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [3:44:11<3:57:56, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.7792561848958
INFO:root:current train perplexity3.814418315887451
INFO:root:current mean train loss 1707.0649199614654
INFO:root:current train perplexity3.825366497039795
INFO:root:current mean train loss 1706.1062951857043
INFO:root:current train perplexity3.827510356903076
INFO:root:current mean train loss 1705.1843380982848
INFO:root:current train perplexity3.828861713409424
INFO:root:current mean train loss 1708.3183351244245
INFO:root:current train perplexity3.8360111713409424
INFO:root:current mean train loss 1708.114705329394
INFO:root:current train perplexity3.8409159183502197
INFO:root:current mean train loss 1709.768334282769
INFO:root:current train perplexity3.8483011722564697
INFO:root:current mean train loss 1709.8671620414857
INFO:root:current train perplexity3.84940505027771
INFO:root:current mean train loss 1710.1307662388065
INFO:root:current train perplexity3.853898048400879
INFO:root:current mean train loss 1710.8526195413453
INFO:root:current train perplexity3.858186721801758
INFO:root:current mean train loss 1710.781446151151
INFO:root:current train perplexity3.8592240810394287
INFO:root:current mean train loss 1712.6066556392232
INFO:root:current train perplexity3.8616175651550293
INFO:root:current mean train loss 1713.7923805041191
INFO:root:current train perplexity3.8617467880249023
INFO:root:current mean train loss 1715.2346752857243
INFO:root:current train perplexity3.866419553756714
INFO:root:current mean train loss 1715.2359231348196
INFO:root:current train perplexity3.866331100463867
INFO:root:current mean train loss 1715.7498272247708
INFO:root:current train perplexity3.8696250915527344
INFO:root:current mean train loss 1716.3292510393753
INFO:root:current train perplexity3.8711435794830322
INFO:root:current mean train loss 1716.0586773416271
INFO:root:current train perplexity3.8722281455993652
INFO:root:current mean train loss 1716.3492750688033
INFO:root:current train perplexity3.8726325035095215
INFO:root:current mean train loss 1717.6414269167294
INFO:root:current train perplexity3.87406849861145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1717.52832532951
INFO:root:final train perplexity: 3.8750016689300537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2113.6968561267176
INFO:root:eval perplexity: 5.525832653045654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [3:46:29<3:55:36, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.2263596754808
INFO:root:current train perplexity3.8016059398651123
INFO:root:current mean train loss 1696.5001598011363
INFO:root:current train perplexity3.813478469848633
INFO:root:current mean train loss 1700.2309293926887
INFO:root:current train perplexity3.820120096206665
INFO:root:current mean train loss 1703.6212174925085
INFO:root:current train perplexity3.829956531524658
INFO:root:current mean train loss 1705.6188830960182
INFO:root:current train perplexity3.837346315383911
INFO:root:current mean train loss 1706.2048331201604
INFO:root:current train perplexity3.8416247367858887
INFO:root:current mean train loss 1710.0444649832589
INFO:root:current train perplexity3.8469278812408447
INFO:root:current mean train loss 1711.1698532603145
INFO:root:current train perplexity3.8537886142730713
INFO:root:current mean train loss 1711.8009562409682
INFO:root:current train perplexity3.853686571121216
INFO:root:current mean train loss 1711.7295234324401
INFO:root:current train perplexity3.8528897762298584
INFO:root:current mean train loss 1712.3501343346538
INFO:root:current train perplexity3.8526761531829834
INFO:root:current mean train loss 1711.303177390692
INFO:root:current train perplexity3.853781223297119
INFO:root:current mean train loss 1711.169536943398
INFO:root:current train perplexity3.854191541671753
INFO:root:current mean train loss 1711.0262174836882
INFO:root:current train perplexity3.854912519454956
INFO:root:current mean train loss 1711.9214663769199
INFO:root:current train perplexity3.8576579093933105
INFO:root:current mean train loss 1712.1345856785392
INFO:root:current train perplexity3.858299493789673
INFO:root:current mean train loss 1713.5064513243713
INFO:root:current train perplexity3.8594536781311035
INFO:root:current mean train loss 1714.024855521313
INFO:root:current train perplexity3.8626253604888916
INFO:root:current mean train loss 1714.2622726154073
INFO:root:current train perplexity3.8653318881988525
INFO:root:current mean train loss 1714.567339451137
INFO:root:current train perplexity3.865849018096924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1714.228643881932
INFO:root:final train perplexity: 3.864931106567383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2114.250139818124
INFO:root:eval perplexity: 5.5283050537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [3:48:48<3:53:14, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1696.197037859661
INFO:root:current train perplexity3.7973148822784424
INFO:root:current mean train loss 1697.093532688015
INFO:root:current train perplexity3.8026747703552246
INFO:root:current mean train loss 1698.9561200513908
INFO:root:current train perplexity3.8150765895843506
INFO:root:current mean train loss 1700.447233349865
INFO:root:current train perplexity3.82088565826416
INFO:root:current mean train loss 1698.250990744943
INFO:root:current train perplexity3.823568820953369
INFO:root:current mean train loss 1700.052007406438
INFO:root:current train perplexity3.8262321949005127
INFO:root:current mean train loss 1701.339308036737
INFO:root:current train perplexity3.830786943435669
INFO:root:current mean train loss 1702.6955391574088
INFO:root:current train perplexity3.830087423324585
INFO:root:current mean train loss 1704.3120279117506
INFO:root:current train perplexity3.8357186317443848
INFO:root:current mean train loss 1705.9937869691557
INFO:root:current train perplexity3.8375720977783203
INFO:root:current mean train loss 1705.3230899944763
INFO:root:current train perplexity3.839221239089966
INFO:root:current mean train loss 1706.979245051918
INFO:root:current train perplexity3.842587471008301
INFO:root:current mean train loss 1707.2863933307333
INFO:root:current train perplexity3.8428280353546143
INFO:root:current mean train loss 1708.948099889907
INFO:root:current train perplexity3.8468422889709473
INFO:root:current mean train loss 1710.0368299806005
INFO:root:current train perplexity3.8488261699676514
INFO:root:current mean train loss 1710.419245935722
INFO:root:current train perplexity3.8512673377990723
INFO:root:current mean train loss 1711.4539429146384
INFO:root:current train perplexity3.8560633659362793
INFO:root:current mean train loss 1711.9077220364452
INFO:root:current train perplexity3.856754779815674
INFO:root:current mean train loss 1711.3015420814377
INFO:root:current train perplexity3.856506586074829
INFO:root:current mean train loss 1712.0511536814731
INFO:root:current train perplexity3.856872081756592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it]
INFO:root:final mean train loss: 1711.6314846544751
INFO:root:final train perplexity: 3.857022762298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2115.5492791791335
INFO:root:eval perplexity: 5.534116744995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [3:51:07<3:51:01, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.7684967349273
INFO:root:current train perplexity3.81632661819458
INFO:root:current mean train loss 1706.1863590413002
INFO:root:current train perplexity3.8234808444976807
INFO:root:current mean train loss 1705.4982440655049
INFO:root:current train perplexity3.8299367427825928
INFO:root:current mean train loss 1704.1169975108671
INFO:root:current train perplexity3.8290698528289795
INFO:root:current mean train loss 1704.0207864459387
INFO:root:current train perplexity3.832571268081665
INFO:root:current mean train loss 1701.5809454559683
INFO:root:current train perplexity3.8345632553100586
INFO:root:current mean train loss 1702.6734750117355
INFO:root:current train perplexity3.8339149951934814
INFO:root:current mean train loss 1704.049183641417
INFO:root:current train perplexity3.831230401992798
INFO:root:current mean train loss 1703.25669485735
INFO:root:current train perplexity3.834221363067627
INFO:root:current mean train loss 1707.0724052910332
INFO:root:current train perplexity3.84329891204834
INFO:root:current mean train loss 1707.240478959921
INFO:root:current train perplexity3.8435795307159424
INFO:root:current mean train loss 1707.00437467828
INFO:root:current train perplexity3.8411362171173096
INFO:root:current mean train loss 1707.056136838283
INFO:root:current train perplexity3.8417365550994873
INFO:root:current mean train loss 1708.0964866785428
INFO:root:current train perplexity3.8433127403259277
INFO:root:current mean train loss 1708.1656940401674
INFO:root:current train perplexity3.84462833404541
INFO:root:current mean train loss 1708.2473610215368
INFO:root:current train perplexity3.8475897312164307
INFO:root:current mean train loss 1708.3382722833285
INFO:root:current train perplexity3.8480947017669678
INFO:root:current mean train loss 1708.8375649232212
INFO:root:current train perplexity3.848783016204834
INFO:root:current mean train loss 1709.3547721328455
INFO:root:current train perplexity3.8492591381073

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it]
INFO:root:final mean train loss: 1709.3093660309407
INFO:root:final train perplexity: 3.8499650955200195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2116.1387476278537
INFO:root:eval perplexity: 5.5367560386657715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [3:53:25<3:48:42, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1697.1199645996094
INFO:root:current train perplexity3.856135606765747
INFO:root:current mean train loss 1701.156498349946
INFO:root:current train perplexity3.849907636642456
INFO:root:current mean train loss 1702.2388808638962
INFO:root:current train perplexity3.841129779815674
INFO:root:current mean train loss 1703.6610833662974
INFO:root:current train perplexity3.837611198425293
INFO:root:current mean train loss 1706.3758500906138
INFO:root:current train perplexity3.8417928218841553
INFO:root:current mean train loss 1706.3430405254512
INFO:root:current train perplexity3.8403711318969727
INFO:root:current mean train loss 1707.439770983411
INFO:root:current train perplexity3.8376893997192383
INFO:root:current mean train loss 1707.6644261535985
INFO:root:current train perplexity3.834695339202881
INFO:root:current mean train loss 1705.5948386098823
INFO:root:current train perplexity3.8281359672546387
INFO:root:current mean train loss 1706.3748813945654
INFO:root:current train perplexity3.831219434738159
INFO:root:current mean train loss 1705.9947551817406
INFO:root:current train perplexity3.8321216106414795
INFO:root:current mean train loss 1705.8912928864947
INFO:root:current train perplexity3.8337104320526123
INFO:root:current mean train loss 1706.5679284145958
INFO:root:current train perplexity3.834535837173462
INFO:root:current mean train loss 1705.8402529081675
INFO:root:current train perplexity3.833399534225464
INFO:root:current mean train loss 1705.7935509115962
INFO:root:current train perplexity3.8346126079559326
INFO:root:current mean train loss 1705.690824483504
INFO:root:current train perplexity3.836946964263916
INFO:root:current mean train loss 1705.392745593987
INFO:root:current train perplexity3.838721513748169
INFO:root:current mean train loss 1706.0394735980979
INFO:root:current train perplexity3.839834213256836
INFO:root:current mean train loss 1706.7581861050644
INFO:root:current train perplexity3.841794729232788
INFO:root:current mean train loss 1707.476515481268
INFO:root:current train perplexity3.8433778285980225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.97s/it]
INFO:root:final mean train loss: 1707.3099620701746
INFO:root:final train perplexity: 3.8438992500305176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2117.1069851056905
INFO:root:eval perplexity: 5.541092395782471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [3:55:44<3:46:31, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.8752663352273
INFO:root:current train perplexity3.7783217430114746
INFO:root:current mean train loss 1692.1553257533483
INFO:root:current train perplexity3.799206495285034
INFO:root:current mean train loss 1691.0248740527763
INFO:root:current train perplexity3.7939352989196777
INFO:root:current mean train loss 1694.1351190057244
INFO:root:current train perplexity3.787883758544922
INFO:root:current mean train loss 1699.6006775607138
INFO:root:current train perplexity3.8014345169067383
INFO:root:current mean train loss 1700.7326428841025
INFO:root:current train perplexity3.8116514682769775
INFO:root:current mean train loss 1703.835588452187
INFO:root:current train perplexity3.8174145221710205
INFO:root:current mean train loss 1701.3118898149728
INFO:root:current train perplexity3.81821870803833
INFO:root:current mean train loss 1701.966609006884
INFO:root:current train perplexity3.8221542835235596
INFO:root:current mean train loss 1702.4352048687867
INFO:root:current train perplexity3.8230783939361572
INFO:root:current mean train loss 1701.870020760225
INFO:root:current train perplexity3.823923110961914
INFO:root:current mean train loss 1703.115528291869
INFO:root:current train perplexity3.8253233432769775
INFO:root:current mean train loss 1703.1536420712312
INFO:root:current train perplexity3.827946662902832
INFO:root:current mean train loss 1703.4913570922026
INFO:root:current train perplexity3.8289918899536133
INFO:root:current mean train loss 1704.4227711477233
INFO:root:current train perplexity3.8319311141967773
INFO:root:current mean train loss 1704.0896318588705
INFO:root:current train perplexity3.832458734512329
INFO:root:current mean train loss 1704.16377844171
INFO:root:current train perplexity3.832056760787964
INFO:root:current mean train loss 1704.5856263721464
INFO:root:current train perplexity3.832327127456665
INFO:root:current mean train loss 1704.8089636237128
INFO:root:current train perplexity3.8351073265075684
INFO:root:current mean train loss 1705.1992749541273
INFO:root:current train perplexity3.835709810256958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it]
INFO:root:final mean train loss: 1704.5430647811081
INFO:root:final train perplexity: 3.8355209827423096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2118.534675760472
INFO:root:eval perplexity: 5.547494411468506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [3:58:03<3:44:13, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.0760595703125
INFO:root:current train perplexity3.8457276821136475
INFO:root:current mean train loss 1707.5147900390625
INFO:root:current train perplexity3.8073272705078125
INFO:root:current mean train loss 1700.3003227539064
INFO:root:current train perplexity3.8104238510131836
INFO:root:current mean train loss 1696.7138267299108
INFO:root:current train perplexity3.816338539123535
INFO:root:current mean train loss 1694.8107093641493
INFO:root:current train perplexity3.8199501037597656
INFO:root:current mean train loss 1695.985527121804
INFO:root:current train perplexity3.8140339851379395
INFO:root:current mean train loss 1697.0077693058895
INFO:root:current train perplexity3.8148674964904785
INFO:root:current mean train loss 1698.6134811197917
INFO:root:current train perplexity3.8168303966522217
INFO:root:current mean train loss 1699.9350647690717
INFO:root:current train perplexity3.8192853927612305
INFO:root:current mean train loss 1701.1764773077714
INFO:root:current train perplexity3.8213279247283936
INFO:root:current mean train loss 1700.2129503813244
INFO:root:current train perplexity3.8214941024780273
INFO:root:current mean train loss 1700.2637592348844
INFO:root:current train perplexity3.8232033252716064
INFO:root:current mean train loss 1699.9190248046875
INFO:root:current train perplexity3.8231167793273926
INFO:root:current mean train loss 1700.1358110894098
INFO:root:current train perplexity3.8220295906066895
INFO:root:current mean train loss 1699.9030921672952
INFO:root:current train perplexity3.8233487606048584
INFO:root:current mean train loss 1700.056657951109
INFO:root:current train perplexity3.8248777389526367
INFO:root:current mean train loss 1700.9304831764914
INFO:root:current train perplexity3.827045440673828
INFO:root:current mean train loss 1700.9823369140624
INFO:root:current train perplexity3.827836751937866
INFO:root:current mean train loss 1701.5875005278717
INFO:root:current train perplexity3.8281993865966797
INFO:root:current mean train loss 1701.9336398237178
INFO:root:current train perplexity3.82771635055542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it]
INFO:root:final mean train loss: 1702.0387844714744
INFO:root:final train perplexity: 3.8279521465301514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2119.9955366418717
INFO:root:eval perplexity: 5.55405330657959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [4:00:21<3:41:55, 138.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.2716720353312
INFO:root:current train perplexity3.8066954612731934
INFO:root:current mean train loss 1699.3661312628649
INFO:root:current train perplexity3.790501356124878
INFO:root:current mean train loss 1701.7609886140858
INFO:root:current train perplexity3.8064815998077393
INFO:root:current mean train loss 1699.7169468851116
INFO:root:current train perplexity3.808553695678711
INFO:root:current mean train loss 1700.3555717386575
INFO:root:current train perplexity3.8118631839752197
INFO:root:current mean train loss 1697.1738050888034
INFO:root:current train perplexity3.8115828037261963
INFO:root:current mean train loss 1696.8735501633948
INFO:root:current train perplexity3.8107104301452637
INFO:root:current mean train loss 1696.7960849647573
INFO:root:current train perplexity3.810399293899536
INFO:root:current mean train loss 1697.5233289461235
INFO:root:current train perplexity3.8109757900238037
INFO:root:current mean train loss 1699.4903142824537
INFO:root:current train perplexity3.809141159057617
INFO:root:current mean train loss 1699.992823592725
INFO:root:current train perplexity3.8115501403808594
INFO:root:current mean train loss 1700.0584186465696
INFO:root:current train perplexity3.8123879432678223
INFO:root:current mean train loss 1701.4808143429052
INFO:root:current train perplexity3.8170855045318604
INFO:root:current mean train loss 1700.6986952853533
INFO:root:current train perplexity3.818964958190918
INFO:root:current mean train loss 1701.2480490384821
INFO:root:current train perplexity3.8219001293182373
INFO:root:current mean train loss 1700.5552579664318
INFO:root:current train perplexity3.8208673000335693
INFO:root:current mean train loss 1701.6345017861663
INFO:root:current train perplexity3.820129156112671
INFO:root:current mean train loss 1700.6335556297972
INFO:root:current train perplexity3.8194289207458496
INFO:root:current mean train loss 1701.063188680558
INFO:root:current train perplexity3.8211967945098877
INFO:root:current mean train loss 1700.41085900761
INFO:root:current train perplexity3.821261405944824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it]
INFO:root:final mean train loss: 1700.0272384851314
INFO:root:final train perplexity: 3.821885585784912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2120.1606202903367
INFO:root:eval perplexity: 5.5547943115234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [4:02:40<3:39:39, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1699.6654910132997
INFO:root:current train perplexity3.796595573425293
INFO:root:current mean train loss 1692.287481556768
INFO:root:current train perplexity3.8020663261413574
INFO:root:current mean train loss 1691.9331093371754
INFO:root:current train perplexity3.8035356998443604
INFO:root:current mean train loss 1693.944032351176
INFO:root:current train perplexity3.7988696098327637
INFO:root:current mean train loss 1693.4834561939083
INFO:root:current train perplexity3.797865867614746
INFO:root:current mean train loss 1695.0260281497485
INFO:root:current train perplexity3.7969038486480713
INFO:root:current mean train loss 1697.0481449595668
INFO:root:current train perplexity3.7970807552337646
INFO:root:current mean train loss 1697.5701466774453
INFO:root:current train perplexity3.8000776767730713
INFO:root:current mean train loss 1696.9214728860295
INFO:root:current train perplexity3.800751209259033
INFO:root:current mean train loss 1696.898350041087
INFO:root:current train perplexity3.8026773929595947
INFO:root:current mean train loss 1698.0026247369408
INFO:root:current train perplexity3.804830312728882
INFO:root:current mean train loss 1697.4821549492913
INFO:root:current train perplexity3.805692195892334
INFO:root:current mean train loss 1697.1554680464794
INFO:root:current train perplexity3.8055293560028076
INFO:root:current mean train loss 1697.8802908307555
INFO:root:current train perplexity3.808335304260254
INFO:root:current mean train loss 1698.4819011842465
INFO:root:current train perplexity3.8092429637908936
INFO:root:current mean train loss 1698.7144595830127
INFO:root:current train perplexity3.810006856918335
INFO:root:current mean train loss 1698.7127818200481
INFO:root:current train perplexity3.8111157417297363
INFO:root:current mean train loss 1698.033852068298
INFO:root:current train perplexity3.812016725540161
INFO:root:current mean train loss 1697.6467217771365
INFO:root:current train perplexity3.8129444122314453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it]
INFO:root:final mean train loss: 1697.1898596566912
INFO:root:final train perplexity: 3.8133420944213867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.71s/it]
INFO:root:eval mean loss: 2122.505569782663
INFO:root:eval perplexity: 5.565340042114258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [4:04:59<3:37:24, 138.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1614.798095703125
INFO:root:current train perplexity3.5205283164978027
INFO:root:current mean train loss 1679.2261576133199
INFO:root:current train perplexity3.781405448913574
INFO:root:current mean train loss 1675.743215076959
INFO:root:current train perplexity3.7816078662872314
INFO:root:current mean train loss 1677.3486701230274
INFO:root:current train perplexity3.7773187160491943
INFO:root:current mean train loss 1683.262512054824
INFO:root:current train perplexity3.7917027473449707
INFO:root:current mean train loss 1685.3971473556792
INFO:root:current train perplexity3.7950825691223145
INFO:root:current mean train loss 1689.3900300849496
INFO:root:current train perplexity3.796344041824341
INFO:root:current mean train loss 1687.3186898877718
INFO:root:current train perplexity3.7947394847869873
INFO:root:current mean train loss 1687.2314152902134
INFO:root:current train perplexity3.791813373565674
INFO:root:current mean train loss 1687.7151353097254
INFO:root:current train perplexity3.793696641921997
INFO:root:current mean train loss 1687.6054487504682
INFO:root:current train perplexity3.791816234588623
INFO:root:current mean train loss 1686.4034434915347
INFO:root:current train perplexity3.7927658557891846
INFO:root:current mean train loss 1687.7722664991088
INFO:root:current train perplexity3.792782783508301
INFO:root:current mean train loss 1689.102211133413
INFO:root:current train perplexity3.794461250305176
INFO:root:current mean train loss 1689.8640669088206
INFO:root:current train perplexity3.7947640419006348
INFO:root:current mean train loss 1690.7891753804756
INFO:root:current train perplexity3.7956299781799316
INFO:root:current mean train loss 1692.0062748410417
INFO:root:current train perplexity3.8000192642211914
INFO:root:current mean train loss 1693.5893165009784
INFO:root:current train perplexity3.803748369216919
INFO:root:current mean train loss 1694.1736679627854
INFO:root:current train perplexity3.804037094116211
INFO:root:current mean train loss 1694.6853532063717
INFO:root:current train perplexity3.80472731590271

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 1694.6239478130024
INFO:root:final train perplexity: 3.805633783340454
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2122.4756569287456
INFO:root:eval perplexity: 5.56520414352417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [4:07:18<3:35:02, 138.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1756.1346706814236
INFO:root:current train perplexity3.8305559158325195
INFO:root:current mean train loss 1690.8713865118511
INFO:root:current train perplexity3.7845726013183594
INFO:root:current mean train loss 1690.7526351508745
INFO:root:current train perplexity3.7835469245910645
INFO:root:current mean train loss 1686.8538764617729
INFO:root:current train perplexity3.773853063583374
INFO:root:current mean train loss 1686.7590092563173
INFO:root:current train perplexity3.7740330696105957
INFO:root:current mean train loss 1687.7617590473426
INFO:root:current train perplexity3.776221990585327
INFO:root:current mean train loss 1687.1570873075318
INFO:root:current train perplexity3.7773993015289307
INFO:root:current mean train loss 1685.9470974807953
INFO:root:current train perplexity3.779905080795288
INFO:root:current mean train loss 1685.6764732304878
INFO:root:current train perplexity3.7864878177642822
INFO:root:current mean train loss 1686.2056670677168
INFO:root:current train perplexity3.7861082553863525
INFO:root:current mean train loss 1686.944191803398
INFO:root:current train perplexity3.7880661487579346
INFO:root:current mean train loss 1686.4572435082177
INFO:root:current train perplexity3.78580641746521
INFO:root:current mean train loss 1687.341716497011
INFO:root:current train perplexity3.7867257595062256
INFO:root:current mean train loss 1688.9608623869321
INFO:root:current train perplexity3.7894134521484375
INFO:root:current mean train loss 1690.539147639308
INFO:root:current train perplexity3.7913384437561035
INFO:root:current mean train loss 1689.7768948722105
INFO:root:current train perplexity3.7922592163085938
INFO:root:current mean train loss 1690.101340615705
INFO:root:current train perplexity3.7942943572998047
INFO:root:current mean train loss 1691.4820948146692
INFO:root:current train perplexity3.7965621948242188
INFO:root:current mean train loss 1691.9761703709432
INFO:root:current train perplexity3.798927068710327
INFO:root:current mean train loss 1692.7808436929745
INFO:root:current train perplexity3.8003158569335938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it]
INFO:root:final mean train loss: 1692.7192007614035
INFO:root:final train perplexity: 3.7999205589294434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2123.7280489874224
INFO:root:eval perplexity: 5.5708441734313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [4:09:36<3:32:43, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1671.4730433872767
INFO:root:current train perplexity3.7777464389801025
INFO:root:current mean train loss 1678.3902126736111
INFO:root:current train perplexity3.770745277404785
INFO:root:current mean train loss 1688.534318899601
INFO:root:current train perplexity3.777878999710083
INFO:root:current mean train loss 1687.9712088969216
INFO:root:current train perplexity3.7810277938842773
INFO:root:current mean train loss 1687.750471724587
INFO:root:current train perplexity3.782625913619995
INFO:root:current mean train loss 1690.437037958163
INFO:root:current train perplexity3.788975715637207
INFO:root:current mean train loss 1690.3848052257629
INFO:root:current train perplexity3.785614013671875
INFO:root:current mean train loss 1689.3016779270301
INFO:root:current train perplexity3.7803940773010254
INFO:root:current mean train loss 1690.5295106076908
INFO:root:current train perplexity3.7797141075134277
INFO:root:current mean train loss 1689.3926144197026
INFO:root:current train perplexity3.7797389030456543
INFO:root:current mean train loss 1690.6879004142136
INFO:root:current train perplexity3.7838616371154785
INFO:root:current mean train loss 1691.35386258432
INFO:root:current train perplexity3.7872204780578613
INFO:root:current mean train loss 1690.1512550014234
INFO:root:current train perplexity3.7858030796051025
INFO:root:current mean train loss 1691.18979345886
INFO:root:current train perplexity3.787564516067505
INFO:root:current mean train loss 1690.6668167805421
INFO:root:current train perplexity3.786278486251831
INFO:root:current mean train loss 1691.074850493689
INFO:root:current train perplexity3.789565324783325
INFO:root:current mean train loss 1691.6296437488054
INFO:root:current train perplexity3.7881548404693604
INFO:root:current mean train loss 1691.2584848365454
INFO:root:current train perplexity3.7895684242248535
INFO:root:current mean train loss 1691.3086178314459
INFO:root:current train perplexity3.790137767791748
INFO:root:current mean train loss 1691.1540893870115
INFO:root:current train perplexity3.791356086730957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it]
INFO:root:final mean train loss: 1690.5299912845614
INFO:root:final train perplexity: 3.793365001678467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2124.2726834344526
INFO:root:eval perplexity: 5.57329797744751
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [4:11:55<3:30:28, 138.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1672.1033771221455
INFO:root:current train perplexity3.7078258991241455
INFO:root:current mean train loss 1681.4924798262746
INFO:root:current train perplexity3.767563581466675
INFO:root:current mean train loss 1678.6244153219557
INFO:root:current train perplexity3.761582374572754
INFO:root:current mean train loss 1679.2615498629484
INFO:root:current train perplexity3.762747049331665
INFO:root:current mean train loss 1683.2440271968335
INFO:root:current train perplexity3.7704598903656006
INFO:root:current mean train loss 1683.3833262125652
INFO:root:current train perplexity3.7703585624694824
INFO:root:current mean train loss 1682.8331059180887
INFO:root:current train perplexity3.771550416946411
INFO:root:current mean train loss 1684.7110535641934
INFO:root:current train perplexity3.7718193531036377
INFO:root:current mean train loss 1684.902323978048
INFO:root:current train perplexity3.7741494178771973
INFO:root:current mean train loss 1685.2518611875903
INFO:root:current train perplexity3.77447247505188
INFO:root:current mean train loss 1684.974418727164
INFO:root:current train perplexity3.774322271347046
INFO:root:current mean train loss 1685.214029735989
INFO:root:current train perplexity3.7776784896850586
INFO:root:current mean train loss 1685.4735669998315
INFO:root:current train perplexity3.7781310081481934
INFO:root:current mean train loss 1685.8859973433455
INFO:root:current train perplexity3.7801191806793213
INFO:root:current mean train loss 1685.8394228932614
INFO:root:current train perplexity3.779263496398926
INFO:root:current mean train loss 1686.2576611705663
INFO:root:current train perplexity3.7804386615753174
INFO:root:current mean train loss 1686.9780467035696
INFO:root:current train perplexity3.78317928314209
INFO:root:current mean train loss 1686.951975225858
INFO:root:current train perplexity3.7831315994262695
INFO:root:current mean train loss 1688.0644831152765
INFO:root:current train perplexity3.7848072052001953
INFO:root:current mean train loss 1687.89083574639
INFO:root:current train perplexity3.7851791381835938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1688.030269774775
INFO:root:final train perplexity: 3.7858948707580566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2125.232983311863
INFO:root:eval perplexity: 5.577628135681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [4:14:14<3:28:07, 138.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1664.6085311226223
INFO:root:current train perplexity3.7591567039489746
INFO:root:current mean train loss 1674.535765879253
INFO:root:current train perplexity3.751401901245117
INFO:root:current mean train loss 1680.9400784517309
INFO:root:current train perplexity3.760120391845703
INFO:root:current mean train loss 1679.784336824081
INFO:root:current train perplexity3.7577171325683594
INFO:root:current mean train loss 1681.7608718058702
INFO:root:current train perplexity3.764606237411499
INFO:root:current mean train loss 1682.97314453125
INFO:root:current train perplexity3.767656087875366
INFO:root:current mean train loss 1684.1053508764246
INFO:root:current train perplexity3.769545316696167
INFO:root:current mean train loss 1683.134833089087
INFO:root:current train perplexity3.7707901000976562
INFO:root:current mean train loss 1683.716126120406
INFO:root:current train perplexity3.7732160091400146
INFO:root:current mean train loss 1684.7137434795052
INFO:root:current train perplexity3.7745158672332764
INFO:root:current mean train loss 1683.449169305243
INFO:root:current train perplexity3.770832061767578
INFO:root:current mean train loss 1682.8339610887042
INFO:root:current train perplexity3.7704575061798096
INFO:root:current mean train loss 1683.3566757935628
INFO:root:current train perplexity3.7732088565826416
INFO:root:current mean train loss 1683.2722095743072
INFO:root:current train perplexity3.77315616607666
INFO:root:current mean train loss 1684.0162933536578
INFO:root:current train perplexity3.7762084007263184
INFO:root:current mean train loss 1684.6787921621055
INFO:root:current train perplexity3.7768924236297607
INFO:root:current mean train loss 1685.0247144476248
INFO:root:current train perplexity3.7754833698272705
INFO:root:current mean train loss 1686.0407992244911
INFO:root:current train perplexity3.7767369747161865
INFO:root:current mean train loss 1686.7284222271685
INFO:root:current train perplexity3.77834153175354
INFO:root:current mean train loss 1686.1245706770371
INFO:root:current train perplexity3.778446912765503

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it]
INFO:root:final mean train loss: 1685.536145370414
INFO:root:final train perplexity: 3.7784550189971924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2127.204179912594
INFO:root:eval perplexity: 5.586528301239014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [4:16:33<3:25:50, 138.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1688.8611478583757
INFO:root:current train perplexity3.740499258041382
INFO:root:current mean train loss 1690.4342592300907
INFO:root:current train perplexity3.757899522781372
INFO:root:current mean train loss 1685.1335073617788
INFO:root:current train perplexity3.755600690841675
INFO:root:current mean train loss 1682.198400942155
INFO:root:current train perplexity3.7522029876708984
INFO:root:current mean train loss 1684.3400949234824
INFO:root:current train perplexity3.758286714553833
INFO:root:current mean train loss 1685.183915174048
INFO:root:current train perplexity3.760523796081543
INFO:root:current mean train loss 1684.7767051051726
INFO:root:current train perplexity3.762078285217285
INFO:root:current mean train loss 1684.045755711524
INFO:root:current train perplexity3.7622838020324707
INFO:root:current mean train loss 1682.8684496739647
INFO:root:current train perplexity3.7632808685302734
INFO:root:current mean train loss 1683.1827609234358
INFO:root:current train perplexity3.762810707092285
INFO:root:current mean train loss 1683.3044254872023
INFO:root:current train perplexity3.76469349861145
INFO:root:current mean train loss 1683.6817529173363
INFO:root:current train perplexity3.765138626098633
INFO:root:current mean train loss 1682.7769017909216
INFO:root:current train perplexity3.7646596431732178
INFO:root:current mean train loss 1684.0484530186068
INFO:root:current train perplexity3.7676260471343994
INFO:root:current mean train loss 1684.0796040551659
INFO:root:current train perplexity3.7692599296569824
INFO:root:current mean train loss 1684.539721725868
INFO:root:current train perplexity3.771042823791504
INFO:root:current mean train loss 1683.937131616993
INFO:root:current train perplexity3.7721762657165527
INFO:root:current mean train loss 1683.963016659522
INFO:root:current train perplexity3.7723264694213867
INFO:root:current mean train loss 1682.9780657253489
INFO:root:current train perplexity3.770686388015747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it]
INFO:root:final mean train loss: 1683.1797139701132
INFO:root:final train perplexity: 3.771439790725708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2128.324665475399
INFO:root:eval perplexity: 5.5915913581848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [4:18:51<3:23:27, 138.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1639.9221598307292
INFO:root:current train perplexity3.7224843502044678
INFO:root:current mean train loss 1684.2715934086773
INFO:root:current train perplexity3.7757349014282227
INFO:root:current mean train loss 1683.5084384861839
INFO:root:current train perplexity3.7784926891326904
INFO:root:current mean train loss 1680.8437504028723
INFO:root:current train perplexity3.767695188522339
INFO:root:current mean train loss 1681.1257057663229
INFO:root:current train perplexity3.7554726600646973
INFO:root:current mean train loss 1679.8717269139072
INFO:root:current train perplexity3.754042148590088
INFO:root:current mean train loss 1680.4137997350488
INFO:root:current train perplexity3.7593185901641846
INFO:root:current mean train loss 1680.7640500672342
INFO:root:current train perplexity3.7600531578063965
INFO:root:current mean train loss 1682.566919614191
INFO:root:current train perplexity3.7580411434173584
INFO:root:current mean train loss 1681.1883248870952
INFO:root:current train perplexity3.75978422164917
INFO:root:current mean train loss 1680.8693794105964
INFO:root:current train perplexity3.7614901065826416
INFO:root:current mean train loss 1680.8145917959896
INFO:root:current train perplexity3.7583847045898438
INFO:root:current mean train loss 1680.5074569435785
INFO:root:current train perplexity3.7583999633789062
INFO:root:current mean train loss 1680.2841661969974
INFO:root:current train perplexity3.7578296661376953
INFO:root:current mean train loss 1680.2426752592103
INFO:root:current train perplexity3.758527994155884
INFO:root:current mean train loss 1680.6666396211483
INFO:root:current train perplexity3.760042905807495
INFO:root:current mean train loss 1681.4093726545443
INFO:root:current train perplexity3.7601778507232666
INFO:root:current mean train loss 1680.8655694053234
INFO:root:current train perplexity3.7615833282470703
INFO:root:current mean train loss 1681.513423536727
INFO:root:current train perplexity3.763066053390503
INFO:root:current mean train loss 1681.9048788097741
INFO:root:current train perplexity3.7647321224212646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it]
INFO:root:final mean train loss: 1681.7460814690987
INFO:root:final train perplexity: 3.7671773433685303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2128.506152863198
INFO:root:eval perplexity: 5.592412948608398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [4:21:10<3:21:02, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.448468017578
INFO:root:current train perplexity3.6976044178009033
INFO:root:current mean train loss 1670.0127950032552
INFO:root:current train perplexity3.6749398708343506
INFO:root:current mean train loss 1666.367177512429
INFO:root:current train perplexity3.710463762283325
INFO:root:current mean train loss 1670.5786529541015
INFO:root:current train perplexity3.7132372856140137
INFO:root:current mean train loss 1671.3730518159412
INFO:root:current train perplexity3.7259862422943115
INFO:root:current mean train loss 1672.5651644193208
INFO:root:current train perplexity3.7323877811431885
INFO:root:current mean train loss 1672.8945158927672
INFO:root:current train perplexity3.7347524166107178
INFO:root:current mean train loss 1672.8343780517578
INFO:root:current train perplexity3.734717845916748
INFO:root:current mean train loss 1674.466692817502
INFO:root:current train perplexity3.738319158554077
INFO:root:current mean train loss 1675.8441435440727
INFO:root:current train perplexity3.7425527572631836
INFO:root:current mean train loss 1676.4089926326976
INFO:root:current train perplexity3.7470035552978516
INFO:root:current mean train loss 1677.346391405378
INFO:root:current train perplexity3.748488664627075
INFO:root:current mean train loss 1678.6023014256211
INFO:root:current train perplexity3.7502129077911377
INFO:root:current mean train loss 1678.0667066169508
INFO:root:current train perplexity3.750516176223755
INFO:root:current mean train loss 1677.701093217017
INFO:root:current train perplexity3.753025531768799
INFO:root:current mean train loss 1677.8027957313939
INFO:root:current train perplexity3.7548727989196777
INFO:root:current mean train loss 1678.6425638081114
INFO:root:current train perplexity3.7575345039367676
INFO:root:current mean train loss 1678.9788613962573
INFO:root:current train perplexity3.7586159706115723
INFO:root:current mean train loss 1679.5157290951236
INFO:root:current train perplexity3.7608752250671387
INFO:root:current mean train loss 1680.193585840861
INFO:root:current train perplexity3.761168956756592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1679.8161596162597
INFO:root:final train perplexity: 3.761448383331299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2129.038739143534
INFO:root:eval perplexity: 5.594822406768799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [4:23:28<3:18:40, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.4092819626267
INFO:root:current train perplexity3.7036428451538086
INFO:root:current mean train loss 1668.5810814182253
INFO:root:current train perplexity3.7274012565612793
INFO:root:current mean train loss 1673.0565386422072
INFO:root:current train perplexity3.728701591491699
INFO:root:current mean train loss 1672.5522457315235
INFO:root:current train perplexity3.7319936752319336
INFO:root:current mean train loss 1672.3050900247604
INFO:root:current train perplexity3.7360081672668457
INFO:root:current mean train loss 1672.5453940165999
INFO:root:current train perplexity3.7372751235961914
INFO:root:current mean train loss 1672.5246836903332
INFO:root:current train perplexity3.7346856594085693
INFO:root:current mean train loss 1672.269453071998
INFO:root:current train perplexity3.7362241744995117
INFO:root:current mean train loss 1672.347629123264
INFO:root:current train perplexity3.7367746829986572
INFO:root:current mean train loss 1672.6481726452025
INFO:root:current train perplexity3.736846923828125
INFO:root:current mean train loss 1672.9487857947354
INFO:root:current train perplexity3.7418532371520996
INFO:root:current mean train loss 1673.4653138871138
INFO:root:current train perplexity3.7445292472839355
INFO:root:current mean train loss 1673.1280125808407
INFO:root:current train perplexity3.744457960128784
INFO:root:current mean train loss 1674.1325212477211
INFO:root:current train perplexity3.746117115020752
INFO:root:current mean train loss 1674.9148837775097
INFO:root:current train perplexity3.747699022293091
INFO:root:current mean train loss 1676.360833172373
INFO:root:current train perplexity3.7500243186950684
INFO:root:current mean train loss 1676.5005308604489
INFO:root:current train perplexity3.7495768070220947
INFO:root:current mean train loss 1676.4784114049232
INFO:root:current train perplexity3.7496886253356934
INFO:root:current mean train loss 1677.4072625788906
INFO:root:current train perplexity3.7526845932006836
INFO:root:current mean train loss 1677.3550501691968
INFO:root:current train perplexity3.752392053604126

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1676.919716731623
INFO:root:final train perplexity: 3.752865791320801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2130.105227639489
INFO:root:eval perplexity: 5.599649906158447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [4:25:47<3:16:24, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.6175650137443
INFO:root:current train perplexity3.723891258239746
INFO:root:current mean train loss 1669.2311219054384
INFO:root:current train perplexity3.736525774002075
INFO:root:current mean train loss 1669.9980651374876
INFO:root:current train perplexity3.7430078983306885
INFO:root:current mean train loss 1669.3749703445003
INFO:root:current train perplexity3.7406539916992188
INFO:root:current mean train loss 1669.2725203593923
INFO:root:current train perplexity3.738468885421753
INFO:root:current mean train loss 1670.2268949983784
INFO:root:current train perplexity3.7376961708068848
INFO:root:current mean train loss 1669.6024371505878
INFO:root:current train perplexity3.7340316772460938
INFO:root:current mean train loss 1669.1845363141372
INFO:root:current train perplexity3.733330726623535
INFO:root:current mean train loss 1670.4867838160494
INFO:root:current train perplexity3.733952522277832
INFO:root:current mean train loss 1672.3078751474056
INFO:root:current train perplexity3.737140417098999
INFO:root:current mean train loss 1673.887436926478
INFO:root:current train perplexity3.740443706512451
INFO:root:current mean train loss 1674.199369063617
INFO:root:current train perplexity3.7423582077026367
INFO:root:current mean train loss 1674.9883620461399
INFO:root:current train perplexity3.7437472343444824
INFO:root:current mean train loss 1674.484877615947
INFO:root:current train perplexity3.7425599098205566
INFO:root:current mean train loss 1674.2226014275006
INFO:root:current train perplexity3.7447071075439453
INFO:root:current mean train loss 1675.201795894667
INFO:root:current train perplexity3.746314287185669
INFO:root:current mean train loss 1675.1025910936792
INFO:root:current train perplexity3.746856212615967
INFO:root:current mean train loss 1674.88251470133
INFO:root:current train perplexity3.7456891536712646
INFO:root:current mean train loss 1675.386525965817
INFO:root:current train perplexity3.746943712234497
INFO:root:current mean train loss 1675.646583767972
INFO:root:current train perplexity3.7475244998931885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it]
INFO:root:final mean train loss: 1675.2238393717203
INFO:root:final train perplexity: 3.747850179672241
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2131.74315150917
INFO:root:eval perplexity: 5.607072353363037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [4:28:06<3:14:09, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1661.062996877751
INFO:root:current train perplexity3.7062318325042725
INFO:root:current mean train loss 1664.9267214055646
INFO:root:current train perplexity3.713657855987549
INFO:root:current mean train loss 1665.6285598585966
INFO:root:current train perplexity3.7231366634368896
INFO:root:current mean train loss 1667.9245714048811
INFO:root:current train perplexity3.727046251296997
INFO:root:current mean train loss 1669.5532682706344
INFO:root:current train perplexity3.7271697521209717
INFO:root:current mean train loss 1670.5022498563376
INFO:root:current train perplexity3.720552682876587
INFO:root:current mean train loss 1671.0725334156111
INFO:root:current train perplexity3.7246921062469482
INFO:root:current mean train loss 1671.5889031277866
INFO:root:current train perplexity3.723813056945801
INFO:root:current mean train loss 1670.6548513068672
INFO:root:current train perplexity3.72434663772583
INFO:root:current mean train loss 1668.747186977021
INFO:root:current train perplexity3.7245402336120605
INFO:root:current mean train loss 1670.285552209165
INFO:root:current train perplexity3.7303524017333984
INFO:root:current mean train loss 1669.5487484822002
INFO:root:current train perplexity3.733184814453125
INFO:root:current mean train loss 1669.1694121762207
INFO:root:current train perplexity3.7352097034454346
INFO:root:current mean train loss 1669.5254369244622
INFO:root:current train perplexity3.7342050075531006
INFO:root:current mean train loss 1669.7155415673064
INFO:root:current train perplexity3.7344911098480225
INFO:root:current mean train loss 1670.1178047670671
INFO:root:current train perplexity3.737180709838867
INFO:root:current mean train loss 1670.80115630026
INFO:root:current train perplexity3.7385454177856445
INFO:root:current mean train loss 1671.5667078760234
INFO:root:current train perplexity3.737748146057129
INFO:root:current mean train loss 1672.486851572417
INFO:root:current train perplexity3.7383971214294434
INFO:root:current mean train loss 1672.9667667135377
INFO:root:current train perplexity3.7402710914611816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it]
INFO:root:final mean train loss: 1672.60129619835
INFO:root:final train perplexity: 3.740105628967285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2131.12428575881
INFO:root:eval perplexity: 5.604267120361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [4:30:24<3:11:46, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1659.4573267156427
INFO:root:current train perplexity3.7329394817352295
INFO:root:current mean train loss 1657.7440555653673
INFO:root:current train perplexity3.725839614868164
INFO:root:current mean train loss 1663.4526731703018
INFO:root:current train perplexity3.7437362670898438
INFO:root:current mean train loss 1664.1785250005034
INFO:root:current train perplexity3.7365241050720215
INFO:root:current mean train loss 1663.6308916435867
INFO:root:current train perplexity3.7309508323669434
INFO:root:current mean train loss 1664.3812895275298
INFO:root:current train perplexity3.7325658798217773
INFO:root:current mean train loss 1665.8027129062386
INFO:root:current train perplexity3.737591028213501
INFO:root:current mean train loss 1669.114826802675
INFO:root:current train perplexity3.739474296569824
INFO:root:current mean train loss 1668.1737811114338
INFO:root:current train perplexity3.7388622760772705
INFO:root:current mean train loss 1668.7233428337313
INFO:root:current train perplexity3.7386505603790283
INFO:root:current mean train loss 1667.180897768806
INFO:root:current train perplexity3.7357177734375
INFO:root:current mean train loss 1668.4419641976406
INFO:root:current train perplexity3.737915277481079
INFO:root:current mean train loss 1668.3329523690738
INFO:root:current train perplexity3.736485242843628
INFO:root:current mean train loss 1668.7276263937827
INFO:root:current train perplexity3.7359983921051025
INFO:root:current mean train loss 1668.362203700568
INFO:root:current train perplexity3.7350223064422607
INFO:root:current mean train loss 1669.3703453390665
INFO:root:current train perplexity3.7357940673828125
INFO:root:current mean train loss 1669.359859231524
INFO:root:current train perplexity3.7333106994628906
INFO:root:current mean train loss 1669.8845335685166
INFO:root:current train perplexity3.734442710876465
INFO:root:current mean train loss 1671.1593011759096
INFO:root:current train perplexity3.7350311279296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.32s/it]
INFO:root:final mean train loss: 1671.0362245037409
INFO:root:final train perplexity: 3.7354929447174072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2132.876020715592
INFO:root:eval perplexity: 5.612211227416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [4:32:43<3:09:18, 138.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1726.1255615234375
INFO:root:current train perplexity3.803837537765503
INFO:root:current mean train loss 1678.705236235119
INFO:root:current train perplexity3.745842933654785
INFO:root:current mean train loss 1672.4789604373095
INFO:root:current train perplexity3.715269088745117
INFO:root:current mean train loss 1662.7249779873207
INFO:root:current train perplexity3.711211681365967
INFO:root:current mean train loss 1663.334223391686
INFO:root:current train perplexity3.7108538150787354
INFO:root:current mean train loss 1663.8154826249227
INFO:root:current train perplexity3.714672565460205
INFO:root:current mean train loss 1664.1162839779183
INFO:root:current train perplexity3.7190942764282227
INFO:root:current mean train loss 1667.1920164284131
INFO:root:current train perplexity3.724684238433838
INFO:root:current mean train loss 1665.369893669934
INFO:root:current train perplexity3.7253129482269287
INFO:root:current mean train loss 1665.9350479378884
INFO:root:current train perplexity3.724555015563965
INFO:root:current mean train loss 1667.829005849658
INFO:root:current train perplexity3.7256994247436523
INFO:root:current mean train loss 1667.5155065752263
INFO:root:current train perplexity3.7251365184783936
INFO:root:current mean train loss 1668.453528591805
INFO:root:current train perplexity3.728414535522461
INFO:root:current mean train loss 1668.5756824712644
INFO:root:current train perplexity3.729405164718628
INFO:root:current mean train loss 1669.0503470967249
INFO:root:current train perplexity3.729336738586426
INFO:root:current mean train loss 1668.6373644654536
INFO:root:current train perplexity3.7286224365234375
INFO:root:current mean train loss 1669.3138309086594
INFO:root:current train perplexity3.7301125526428223
INFO:root:current mean train loss 1669.398152693136
INFO:root:current train perplexity3.7295329570770264
INFO:root:current mean train loss 1668.7302413813625
INFO:root:current train perplexity3.7297043800354004
INFO:root:current mean train loss 1669.139808378445
INFO:root:current train perplexity3.7285406589508057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it]
INFO:root:final mean train loss: 1668.5210513424163
INFO:root:final train perplexity: 3.7280900478363037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2134.663392844775
INFO:root:eval perplexity: 5.620329856872559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [4:35:01<3:07:05, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.7348521839488
INFO:root:current train perplexity3.660888910293579
INFO:root:current mean train loss 1661.984121854188
INFO:root:current train perplexity3.7132227420806885
INFO:root:current mean train loss 1653.3695403777801
INFO:root:current train perplexity3.701111078262329
INFO:root:current mean train loss 1651.4947426363549
INFO:root:current train perplexity3.695899248123169
INFO:root:current mean train loss 1654.342521486689
INFO:root:current train perplexity3.703275442123413
INFO:root:current mean train loss 1654.7184988438398
INFO:root:current train perplexity3.7057104110717773
INFO:root:current mean train loss 1656.19134462608
INFO:root:current train perplexity3.7078404426574707
INFO:root:current mean train loss 1660.7822782986711
INFO:root:current train perplexity3.71420955657959
INFO:root:current mean train loss 1661.4028176263591
INFO:root:current train perplexity3.7137866020202637
INFO:root:current mean train loss 1661.5718169305433
INFO:root:current train perplexity3.7133452892303467
INFO:root:current mean train loss 1662.9742543916645
INFO:root:current train perplexity3.7149670124053955
INFO:root:current mean train loss 1663.4987939844793
INFO:root:current train perplexity3.71382212638855
INFO:root:current mean train loss 1663.3177977716473
INFO:root:current train perplexity3.713364362716675
INFO:root:current mean train loss 1664.1109474170587
INFO:root:current train perplexity3.713862419128418
INFO:root:current mean train loss 1664.7846702006966
INFO:root:current train perplexity3.7171719074249268
INFO:root:current mean train loss 1665.3548148477282
INFO:root:current train perplexity3.718684196472168
INFO:root:current mean train loss 1665.6452332671856
INFO:root:current train perplexity3.719954490661621
INFO:root:current mean train loss 1665.702178848745
INFO:root:current train perplexity3.7202682495117188
INFO:root:current mean train loss 1667.2996778603313
INFO:root:current train perplexity3.722918748855591
INFO:root:current mean train loss 1667.1000112162421
INFO:root:current train perplexity3.722033977508545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.79s/it]
INFO:root:final mean train loss: 1666.9186359199682
INFO:root:final train perplexity: 3.723381519317627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2135.280377760001
INFO:root:eval perplexity: 5.623135089874268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [4:37:20<3:04:54, 138.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.4886286808894
INFO:root:current train perplexity3.730506658554077
INFO:root:current mean train loss 1670.481838747752
INFO:root:current train perplexity3.714155435562134
INFO:root:current mean train loss 1660.6918562246665
INFO:root:current train perplexity3.7133572101593018
INFO:root:current mean train loss 1660.239569289846
INFO:root:current train perplexity3.7128279209136963
INFO:root:current mean train loss 1659.5874290379413
INFO:root:current train perplexity3.70823335647583
INFO:root:current mean train loss 1660.0215258200226
INFO:root:current train perplexity3.706618070602417
INFO:root:current mean train loss 1662.688618882348
INFO:root:current train perplexity3.7109084129333496
INFO:root:current mean train loss 1664.2920239026557
INFO:root:current train perplexity3.709559202194214
INFO:root:current mean train loss 1663.0021873719643
INFO:root:current train perplexity3.708413600921631
INFO:root:current mean train loss 1663.0815718288238
INFO:root:current train perplexity3.706616163253784
INFO:root:current mean train loss 1663.2881154270558
INFO:root:current train perplexity3.708366870880127
INFO:root:current mean train loss 1665.4999413762414
INFO:root:current train perplexity3.7125914096832275
INFO:root:current mean train loss 1664.4653168586688
INFO:root:current train perplexity3.711351156234741
INFO:root:current mean train loss 1664.4026980182855
INFO:root:current train perplexity3.7095632553100586
INFO:root:current mean train loss 1664.0198166179855
INFO:root:current train perplexity3.7116003036499023
INFO:root:current mean train loss 1664.3475624168748
INFO:root:current train perplexity3.713009834289551
INFO:root:current mean train loss 1663.7705199525005
INFO:root:current train perplexity3.7132678031921387
INFO:root:current mean train loss 1664.356137083206
INFO:root:current train perplexity3.71465802192688
INFO:root:current mean train loss 1663.867356035358
INFO:root:current train perplexity3.714006185531616
INFO:root:current mean train loss 1664.6825466775722
INFO:root:current train perplexity3.715305805206299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it]
INFO:root:final mean train loss: 1664.448390327796
INFO:root:final train perplexity: 3.716134786605835
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2135.72991900072
INFO:root:eval perplexity: 5.625180721282959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [4:39:39<3:02:33, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1645.7010585239955
INFO:root:current train perplexity3.6657843589782715
INFO:root:current mean train loss 1658.508791410006
INFO:root:current train perplexity3.682177782058716
INFO:root:current mean train loss 1657.8603911399841
INFO:root:current train perplexity3.6747565269470215
INFO:root:current mean train loss 1659.6400304215679
INFO:root:current train perplexity3.6835150718688965
INFO:root:current mean train loss 1655.305963081226
INFO:root:current train perplexity3.68412184715271
INFO:root:current mean train loss 1652.2436953757306
INFO:root:current train perplexity3.6806540489196777
INFO:root:current mean train loss 1652.5856706572742
INFO:root:current train perplexity3.68155574798584
INFO:root:current mean train loss 1654.4043453156003
INFO:root:current train perplexity3.684316873550415
INFO:root:current mean train loss 1656.1906099408586
INFO:root:current train perplexity3.690059185028076
INFO:root:current mean train loss 1657.695804101154
INFO:root:current train perplexity3.698472738265991
INFO:root:current mean train loss 1659.4260226162996
INFO:root:current train perplexity3.701277017593384
INFO:root:current mean train loss 1659.9740034585182
INFO:root:current train perplexity3.70418643951416
INFO:root:current mean train loss 1661.2984935979175
INFO:root:current train perplexity3.705322265625
INFO:root:current mean train loss 1661.4621363276929
INFO:root:current train perplexity3.7072255611419678
INFO:root:current mean train loss 1661.375739632072
INFO:root:current train perplexity3.7081408500671387
INFO:root:current mean train loss 1662.5911715392283
INFO:root:current train perplexity3.709442615509033
INFO:root:current mean train loss 1663.1965403533789
INFO:root:current train perplexity3.709723472595215
INFO:root:current mean train loss 1663.4690633786838
INFO:root:current train perplexity3.7096469402313232
INFO:root:current mean train loss 1663.5536902855183
INFO:root:current train perplexity3.7119457721710205
INFO:root:current mean train loss 1663.3248096302243
INFO:root:current train perplexity3.711339235305786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it]
INFO:root:final mean train loss: 1663.0138135208845
INFO:root:final train perplexity: 3.71193265914917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2136.9473521996897
INFO:root:eval perplexity: 5.630721092224121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [4:41:57<3:00:09, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1665.7319519879068
INFO:root:current train perplexity3.719848394393921
INFO:root:current mean train loss 1658.2589414739884
INFO:root:current train perplexity3.69305157661438
INFO:root:current mean train loss 1655.7870534819997
INFO:root:current train perplexity3.6833200454711914
INFO:root:current mean train loss 1659.0023802074606
INFO:root:current train perplexity3.6900076866149902
INFO:root:current mean train loss 1658.0884836854189
INFO:root:current train perplexity3.6893768310546875
INFO:root:current mean train loss 1657.8535663278524
INFO:root:current train perplexity3.6908071041107178
INFO:root:current mean train loss 1657.9884912907457
INFO:root:current train perplexity3.6890757083892822
INFO:root:current mean train loss 1657.0300373506732
INFO:root:current train perplexity3.6867504119873047
INFO:root:current mean train loss 1656.4690987323704
INFO:root:current train perplexity3.688577890396118
INFO:root:current mean train loss 1656.178827111302
INFO:root:current train perplexity3.69232177734375
INFO:root:current mean train loss 1656.0504622517183
INFO:root:current train perplexity3.693211078643799
INFO:root:current mean train loss 1656.4401712897286
INFO:root:current train perplexity3.6936755180358887
INFO:root:current mean train loss 1657.7053374165357
INFO:root:current train perplexity3.6959667205810547
INFO:root:current mean train loss 1657.367346555928
INFO:root:current train perplexity3.6978542804718018
INFO:root:current mean train loss 1658.3532143027621
INFO:root:current train perplexity3.699579954147339
INFO:root:current mean train loss 1659.3296710946192
INFO:root:current train perplexity3.7020740509033203
INFO:root:current mean train loss 1659.6731836258546
INFO:root:current train perplexity3.70361590385437
INFO:root:current mean train loss 1659.336492496497
INFO:root:current train perplexity3.7033987045288086
INFO:root:current mean train loss 1661.0482098874215
INFO:root:current train perplexity3.7060317993164062
INFO:root:current mean train loss 1661.588582892981
INFO:root:current train perplexity3.7066125869750977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1661.0247746100645
INFO:root:final train perplexity: 3.7061142921447754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2137.499785727643
INFO:root:eval perplexity: 5.633238792419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [4:44:16<2:57:53, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1655.2701836480035
INFO:root:current train perplexity3.710357189178467
INFO:root:current mean train loss 1656.0131039268092
INFO:root:current train perplexity3.6905136108398438
INFO:root:current mean train loss 1656.5330444335937
INFO:root:current train perplexity3.689565658569336
INFO:root:current mean train loss 1653.640535481771
INFO:root:current train perplexity3.687479257583618
INFO:root:current mean train loss 1655.826226183833
INFO:root:current train perplexity3.69356632232666
INFO:root:current mean train loss 1656.6101885262183
INFO:root:current train perplexity3.6946351528167725
INFO:root:current mean train loss 1657.1415099213089
INFO:root:current train perplexity3.6940951347351074
INFO:root:current mean train loss 1657.4504893628857
INFO:root:current train perplexity3.6948764324188232
INFO:root:current mean train loss 1656.3897829891591
INFO:root:current train perplexity3.693682909011841
INFO:root:current mean train loss 1655.4687802093197
INFO:root:current train perplexity3.694167375564575
INFO:root:current mean train loss 1656.3686730621057
INFO:root:current train perplexity3.694373846054077
INFO:root:current mean train loss 1656.2583977194392
INFO:root:current train perplexity3.6946663856506348
INFO:root:current mean train loss 1656.6170679846475
INFO:root:current train perplexity3.6930816173553467
INFO:root:current mean train loss 1656.2568964457341
INFO:root:current train perplexity3.6920673847198486
INFO:root:current mean train loss 1657.2217679222158
INFO:root:current train perplexity3.693401575088501
INFO:root:current mean train loss 1657.3443195079108
INFO:root:current train perplexity3.6947567462921143
INFO:root:current mean train loss 1658.040906917414
INFO:root:current train perplexity3.694873332977295
INFO:root:current mean train loss 1658.7032091535004
INFO:root:current train perplexity3.6959683895111084
INFO:root:current mean train loss 1659.1663448919064
INFO:root:current train perplexity3.6981215476989746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.40s/it]
INFO:root:final mean train loss: 1658.4411739593675
INFO:root:final train perplexity: 3.69857120513916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2138.3040684909683
INFO:root:eval perplexity: 5.636903285980225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [4:46:34<2:55:28, 138.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1617.6285400390625
INFO:root:current train perplexity3.692653179168701
INFO:root:current mean train loss 1646.6744590117553
INFO:root:current train perplexity3.6714444160461426
INFO:root:current mean train loss 1644.635955663119
INFO:root:current train perplexity3.671605348587036
INFO:root:current mean train loss 1648.3806426703736
INFO:root:current train perplexity3.6689343452453613
INFO:root:current mean train loss 1647.5384689443526
INFO:root:current train perplexity3.6678481101989746
INFO:root:current mean train loss 1647.0347917244515
INFO:root:current train perplexity3.668454647064209
INFO:root:current mean train loss 1650.8152611620933
INFO:root:current train perplexity3.674422264099121
INFO:root:current mean train loss 1650.5296451293427
INFO:root:current train perplexity3.67558217048645
INFO:root:current mean train loss 1651.880570460134
INFO:root:current train perplexity3.6757938861846924
INFO:root:current mean train loss 1652.3470589533663
INFO:root:current train perplexity3.679227828979492
INFO:root:current mean train loss 1651.7395071656606
INFO:root:current train perplexity3.6807422637939453
INFO:root:current mean train loss 1653.3428103783804
INFO:root:current train perplexity3.6847610473632812
INFO:root:current mean train loss 1653.8709570150684
INFO:root:current train perplexity3.685225248336792
INFO:root:current mean train loss 1655.2840005514179
INFO:root:current train perplexity3.6871371269226074
INFO:root:current mean train loss 1655.8547312093272
INFO:root:current train perplexity3.6880767345428467
INFO:root:current mean train loss 1656.4407504562043
INFO:root:current train perplexity3.690542697906494
INFO:root:current mean train loss 1656.7716424511173
INFO:root:current train perplexity3.6928327083587646
INFO:root:current mean train loss 1657.2974881405153
INFO:root:current train perplexity3.6942026615142822
INFO:root:current mean train loss 1657.8434764733286
INFO:root:current train perplexity3.6942808628082275
INFO:root:current mean train loss 1658.086352103783
INFO:root:current train perplexity3.696394681930542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1657.7750279536706
INFO:root:final train perplexity: 3.6966280937194824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2139.2498826912956
INFO:root:eval perplexity: 5.641216278076172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [4:48:53<2:53:13, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.2907053629558
INFO:root:current train perplexity3.6430068016052246
INFO:root:current mean train loss 1651.933830015121
INFO:root:current train perplexity3.6682097911834717
INFO:root:current mean train loss 1643.1223733084541
INFO:root:current train perplexity3.6644792556762695
INFO:root:current mean train loss 1649.4452816056616
INFO:root:current train perplexity3.666381359100342
INFO:root:current mean train loss 1652.5737235591096
INFO:root:current train perplexity3.6732606887817383
INFO:root:current mean train loss 1650.901032425975
INFO:root:current train perplexity3.67474102973938
INFO:root:current mean train loss 1648.8515701293945
INFO:root:current train perplexity3.673218250274658
INFO:root:current mean train loss 1649.9326598446671
INFO:root:current train perplexity3.678088903427124
INFO:root:current mean train loss 1650.9425588070767
INFO:root:current train perplexity3.6780502796173096
INFO:root:current mean train loss 1651.0098911301914
INFO:root:current train perplexity3.677788734436035
INFO:root:current mean train loss 1651.5601193904877
INFO:root:current train perplexity3.6815667152404785
INFO:root:current mean train loss 1653.3373438064739
INFO:root:current train perplexity3.6850552558898926
INFO:root:current mean train loss 1653.6303719913258
INFO:root:current train perplexity3.683361768722534
INFO:root:current mean train loss 1654.98749802696
INFO:root:current train perplexity3.6839599609375
INFO:root:current mean train loss 1654.1466800818282
INFO:root:current train perplexity3.682978868484497
INFO:root:current mean train loss 1654.659974906701
INFO:root:current train perplexity3.685115098953247
INFO:root:current mean train loss 1654.8420092953836
INFO:root:current train perplexity3.6865241527557373
INFO:root:current mean train loss 1654.8159363076195
INFO:root:current train perplexity3.6870510578155518
INFO:root:current mean train loss 1655.566712429649
INFO:root:current train perplexity3.688690423965454
INFO:root:current mean train loss 1655.7051617469708
INFO:root:current train perplexity3.6909632682800293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it]
INFO:root:final mean train loss: 1655.4661713185121
INFO:root:final train perplexity: 3.689903497695923
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2140.4865004086323
INFO:root:eval perplexity: 5.646859645843506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [4:51:12<2:50:54, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1645.0312083174542
INFO:root:current train perplexity3.6374495029449463
INFO:root:current mean train loss 1642.651283210051
INFO:root:current train perplexity3.668773889541626
INFO:root:current mean train loss 1643.9188207096083
INFO:root:current train perplexity3.670396327972412
INFO:root:current mean train loss 1645.8549002818
INFO:root:current train perplexity3.668163299560547
INFO:root:current mean train loss 1645.9345238095239
INFO:root:current train perplexity3.6674067974090576
INFO:root:current mean train loss 1647.4109277072985
INFO:root:current train perplexity3.6680469512939453
INFO:root:current mean train loss 1648.9279600432064
INFO:root:current train perplexity3.6700615882873535
INFO:root:current mean train loss 1648.4330319959304
INFO:root:current train perplexity3.6706976890563965
INFO:root:current mean train loss 1650.2440914194876
INFO:root:current train perplexity3.6743993759155273
INFO:root:current mean train loss 1650.4708376488195
INFO:root:current train perplexity3.6722137928009033
INFO:root:current mean train loss 1651.1102385214037
INFO:root:current train perplexity3.6734161376953125
INFO:root:current mean train loss 1650.8418205187677
INFO:root:current train perplexity3.6767935752868652
INFO:root:current mean train loss 1650.2954546169924
INFO:root:current train perplexity3.6762149333953857
INFO:root:current mean train loss 1650.631515150191
INFO:root:current train perplexity3.678607225418091
INFO:root:current mean train loss 1650.282499335856
INFO:root:current train perplexity3.679816484451294
INFO:root:current mean train loss 1650.600529377991
INFO:root:current train perplexity3.6796844005584717
INFO:root:current mean train loss 1651.7518382703001
INFO:root:current train perplexity3.681009531021118
INFO:root:current mean train loss 1652.2422621725345
INFO:root:current train perplexity3.6835813522338867
INFO:root:current mean train loss 1653.128575446747
INFO:root:current train perplexity3.6839685440063477
INFO:root:current mean train loss 1653.2514589320501
INFO:root:current train perplexity3.68290376663208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it]
INFO:root:final mean train loss: 1653.454928476523
INFO:root:final train perplexity: 3.6840546131134033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2140.7391461311504
INFO:root:eval perplexity: 5.648015022277832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [4:53:30<2:48:33, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.8445139917835
INFO:root:current train perplexity3.672975778579712
INFO:root:current mean train loss 1652.6775868089894
INFO:root:current train perplexity3.667205810546875
INFO:root:current mean train loss 1651.5081228803294
INFO:root:current train perplexity3.662485361099243
INFO:root:current mean train loss 1652.7465636184095
INFO:root:current train perplexity3.664525270462036
INFO:root:current mean train loss 1653.3792815229258
INFO:root:current train perplexity3.6668601036071777
INFO:root:current mean train loss 1652.0600319045418
INFO:root:current train perplexity3.6727852821350098
INFO:root:current mean train loss 1650.1932738515743
INFO:root:current train perplexity3.6702322959899902
INFO:root:current mean train loss 1649.990546636657
INFO:root:current train perplexity3.673494577407837
INFO:root:current mean train loss 1650.6326892915029
INFO:root:current train perplexity3.671358108520508
INFO:root:current mean train loss 1650.6519340881475
INFO:root:current train perplexity3.6729931831359863
INFO:root:current mean train loss 1649.8490520974865
INFO:root:current train perplexity3.6728014945983887
INFO:root:current mean train loss 1648.9082601543946
INFO:root:current train perplexity3.67429256439209
INFO:root:current mean train loss 1648.855139897624
INFO:root:current train perplexity3.672802686691284
INFO:root:current mean train loss 1649.360794988753
INFO:root:current train perplexity3.6728994846343994
INFO:root:current mean train loss 1649.944056381414
INFO:root:current train perplexity3.674116849899292
INFO:root:current mean train loss 1651.071222386097
INFO:root:current train perplexity3.6746976375579834
INFO:root:current mean train loss 1650.918836052944
INFO:root:current train perplexity3.6770005226135254
INFO:root:current mean train loss 1651.56139310418
INFO:root:current train perplexity3.677351951599121
INFO:root:current mean train loss 1652.1779368619232
INFO:root:current train perplexity3.678595542907715
INFO:root:current mean train loss 1652.7542269495339
INFO:root:current train perplexity3.679457664489746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.82s/it]
INFO:root:final mean train loss: 1651.9124887594357
INFO:root:final train perplexity: 3.6795761585235596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2141.596921230884
INFO:root:eval perplexity: 5.6519341468811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [4:55:49<2:46:19, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1660.8196305338543
INFO:root:current train perplexity3.7074553966522217
INFO:root:current mean train loss 1665.234826311384
INFO:root:current train perplexity3.6716015338897705
INFO:root:current mean train loss 1656.6021511008523
INFO:root:current train perplexity3.673482656478882
INFO:root:current mean train loss 1657.7131956380208
INFO:root:current train perplexity3.678257465362549
INFO:root:current mean train loss 1654.0209272203947
INFO:root:current train perplexity3.671570062637329
INFO:root:current mean train loss 1652.029349099864
INFO:root:current train perplexity3.6715197563171387
INFO:root:current mean train loss 1650.0075690827546
INFO:root:current train perplexity3.6722936630249023
INFO:root:current mean train loss 1648.2918757875505
INFO:root:current train perplexity3.6732563972473145
INFO:root:current mean train loss 1648.452707310268
INFO:root:current train perplexity3.6720917224884033
INFO:root:current mean train loss 1650.3560332782451
INFO:root:current train perplexity3.6742501258850098
INFO:root:current mean train loss 1649.5636772120276
INFO:root:current train perplexity3.673037528991699
INFO:root:current mean train loss 1650.0352439328458
INFO:root:current train perplexity3.6727235317230225
INFO:root:current mean train loss 1651.58738080193
INFO:root:current train perplexity3.673546314239502
INFO:root:current mean train loss 1650.4989927201705
INFO:root:current train perplexity3.672283411026001
INFO:root:current mean train loss 1650.5195396914723
INFO:root:current train perplexity3.673452138900757
INFO:root:current mean train loss 1651.1377492559525
INFO:root:current train perplexity3.6737003326416016
INFO:root:current mean train loss 1651.2914738077193
INFO:root:current train perplexity3.6723392009735107
INFO:root:current mean train loss 1650.6483229258363
INFO:root:current train perplexity3.6732699871063232
INFO:root:current mean train loss 1650.7194954427084
INFO:root:current train perplexity3.675192356109619
INFO:root:current mean train loss 1650.5552617558346
INFO:root:current train perplexity3.6740477085113525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it]
INFO:root:final mean train loss: 1650.117548755486
INFO:root:final train perplexity: 3.6743710041046143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2142.6001907240416
INFO:root:eval perplexity: 5.656521797180176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [4:58:07<2:43:54, 138.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1631.5590661090353
INFO:root:current train perplexity3.6387698650360107
INFO:root:current mean train loss 1631.4869988759358
INFO:root:current train perplexity3.636941432952881
INFO:root:current mean train loss 1629.7203168477097
INFO:root:current train perplexity3.6478164196014404
INFO:root:current mean train loss 1631.674927692024
INFO:root:current train perplexity3.642486572265625
INFO:root:current mean train loss 1633.0710022468877
INFO:root:current train perplexity3.645169734954834
INFO:root:current mean train loss 1634.5513285044078
INFO:root:current train perplexity3.649556875228882
INFO:root:current mean train loss 1636.1771725340386
INFO:root:current train perplexity3.6471312046051025
INFO:root:current mean train loss 1638.8980973368944
INFO:root:current train perplexity3.651752233505249
INFO:root:current mean train loss 1639.743707768051
INFO:root:current train perplexity3.6541078090667725
INFO:root:current mean train loss 1641.9352039214104
INFO:root:current train perplexity3.653409004211426
INFO:root:current mean train loss 1642.7203382554944
INFO:root:current train perplexity3.6571590900421143
INFO:root:current mean train loss 1644.0345403684066
INFO:root:current train perplexity3.6597628593444824
INFO:root:current mean train loss 1645.1193193843121
INFO:root:current train perplexity3.6603286266326904
INFO:root:current mean train loss 1645.6412560473914
INFO:root:current train perplexity3.66372013092041
INFO:root:current mean train loss 1646.2418231708434
INFO:root:current train perplexity3.663529396057129
INFO:root:current mean train loss 1646.6925335601347
INFO:root:current train perplexity3.666109085083008
INFO:root:current mean train loss 1648.1751493269107
INFO:root:current train perplexity3.668057441711426
INFO:root:current mean train loss 1648.8256051199776
INFO:root:current train perplexity3.668295383453369
INFO:root:current mean train loss 1648.6509560712045
INFO:root:current train perplexity3.6689889430999756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it]
INFO:root:final mean train loss: 1648.5161913065253
INFO:root:final train perplexity: 3.6697335243225098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2144.3913764683066
INFO:root:eval perplexity: 5.664721965789795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [5:00:26<2:41:51, 138.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1680.3335774739583
INFO:root:current train perplexity3.67425799369812
INFO:root:current mean train loss 1654.0153763797305
INFO:root:current train perplexity3.649071216583252
INFO:root:current mean train loss 1647.6220008083508
INFO:root:current train perplexity3.646427869796753
INFO:root:current mean train loss 1644.922776108035
INFO:root:current train perplexity3.655219554901123
INFO:root:current mean train loss 1642.2521011613692
INFO:root:current train perplexity3.6498355865478516
INFO:root:current mean train loss 1642.1291961969703
INFO:root:current train perplexity3.65065336227417
INFO:root:current mean train loss 1640.4415682086412
INFO:root:current train perplexity3.6477999687194824
INFO:root:current mean train loss 1644.4231948744932
INFO:root:current train perplexity3.6534125804901123
INFO:root:current mean train loss 1644.1598030156347
INFO:root:current train perplexity3.6533355712890625
INFO:root:current mean train loss 1645.2113046509728
INFO:root:current train perplexity3.6562254428863525
INFO:root:current mean train loss 1646.1254707389355
INFO:root:current train perplexity3.65757155418396
INFO:root:current mean train loss 1646.697612793409
INFO:root:current train perplexity3.65844988822937
INFO:root:current mean train loss 1647.2069801601917
INFO:root:current train perplexity3.660280704498291
INFO:root:current mean train loss 1647.4320509453783
INFO:root:current train perplexity3.661219835281372
INFO:root:current mean train loss 1646.930885504458
INFO:root:current train perplexity3.660761594772339
INFO:root:current mean train loss 1647.0527342132102
INFO:root:current train perplexity3.6616055965423584
INFO:root:current mean train loss 1646.8609012961758
INFO:root:current train perplexity3.661221981048584
INFO:root:current mean train loss 1646.7469069568506
INFO:root:current train perplexity3.6619198322296143
INFO:root:current mean train loss 1646.614073526141
INFO:root:current train perplexity3.663360834121704
INFO:root:current mean train loss 1647.1898799554535
INFO:root:current train perplexity3.664674997329712

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.43s/it]
INFO:root:final mean train loss: 1647.2185658480385
INFO:root:final train perplexity: 3.6659798622131348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2144.1307944439827
INFO:root:eval perplexity: 5.663527965545654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [5:02:45<2:39:25, 138.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1647.4721304086538
INFO:root:current train perplexity3.6341793537139893
INFO:root:current mean train loss 1643.1944221617684
INFO:root:current train perplexity3.637907028198242
INFO:root:current mean train loss 1635.8695505868018
INFO:root:current train perplexity3.62823486328125
INFO:root:current mean train loss 1639.41104144699
INFO:root:current train perplexity3.629112482070923
INFO:root:current mean train loss 1637.718799859705
INFO:root:current train perplexity3.6352760791778564
INFO:root:current mean train loss 1640.7914906780982
INFO:root:current train perplexity3.641800880432129
INFO:root:current mean train loss 1640.4972358679238
INFO:root:current train perplexity3.6430797576904297
INFO:root:current mean train loss 1642.6331291093643
INFO:root:current train perplexity3.64505934715271
INFO:root:current mean train loss 1641.4628860436687
INFO:root:current train perplexity3.6444365978240967
INFO:root:current mean train loss 1641.487487529318
INFO:root:current train perplexity3.6447882652282715
INFO:root:current mean train loss 1640.141199182581
INFO:root:current train perplexity3.6469039916992188
INFO:root:current mean train loss 1640.9455648798291
INFO:root:current train perplexity3.6472959518432617
INFO:root:current mean train loss 1641.9950997631079
INFO:root:current train perplexity3.650453567504883
INFO:root:current mean train loss 1642.1065535739535
INFO:root:current train perplexity3.6520919799804688
INFO:root:current mean train loss 1643.3428673443252
INFO:root:current train perplexity3.6544008255004883
INFO:root:current mean train loss 1643.5462540892754
INFO:root:current train perplexity3.656520128250122
INFO:root:current mean train loss 1643.455301620277
INFO:root:current train perplexity3.655595302581787
INFO:root:current mean train loss 1642.9809519390933
INFO:root:current train perplexity3.656829595565796
INFO:root:current mean train loss 1644.1328752732877
INFO:root:current train perplexity3.6580145359039307
INFO:root:current mean train loss 1644.9108208550347
INFO:root:current train perplexity3.6587140560150146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1644.8564686123555
INFO:root:final train perplexity: 3.6591572761535645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2145.8600935699246
INFO:root:eval perplexity: 5.671455383300781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [5:05:03<2:37:05, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1656.8017067132994
INFO:root:current train perplexity3.6168153285980225
INFO:root:current mean train loss 1639.55154013467
INFO:root:current train perplexity3.614946126937866
INFO:root:current mean train loss 1642.6400829676247
INFO:root:current train perplexity3.6338398456573486
INFO:root:current mean train loss 1638.2484212714103
INFO:root:current train perplexity3.6329829692840576
INFO:root:current mean train loss 1636.3083746847665
INFO:root:current train perplexity3.636779308319092
INFO:root:current mean train loss 1637.8406777847317
INFO:root:current train perplexity3.6408069133758545
INFO:root:current mean train loss 1640.9877297503767
INFO:root:current train perplexity3.643267869949341
INFO:root:current mean train loss 1640.1768838258643
INFO:root:current train perplexity3.6448276042938232
INFO:root:current mean train loss 1639.757414576846
INFO:root:current train perplexity3.6456336975097656
INFO:root:current mean train loss 1640.261738296784
INFO:root:current train perplexity3.648648500442505
INFO:root:current mean train loss 1639.7836495067563
INFO:root:current train perplexity3.647505283355713
INFO:root:current mean train loss 1640.90703592776
INFO:root:current train perplexity3.648759365081787
INFO:root:current mean train loss 1641.7507118967783
INFO:root:current train perplexity3.6473703384399414
INFO:root:current mean train loss 1642.2372466972845
INFO:root:current train perplexity3.647991895675659
INFO:root:current mean train loss 1641.9069261663255
INFO:root:current train perplexity3.648665428161621
INFO:root:current mean train loss 1642.036529877243
INFO:root:current train perplexity3.6495275497436523
INFO:root:current mean train loss 1643.2246755738122
INFO:root:current train perplexity3.6516618728637695
INFO:root:current mean train loss 1643.9471759106739
INFO:root:current train perplexity3.6535820960998535
INFO:root:current mean train loss 1643.5007601741597
INFO:root:current train perplexity3.654275417327881
INFO:root:current mean train loss 1643.7352071890682
INFO:root:current train perplexity3.6544344425201416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it]
INFO:root:final mean train loss: 1643.086545789356
INFO:root:final train perplexity: 3.654052495956421
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2146.4366610912566
INFO:root:eval perplexity: 5.674100875854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [5:07:22<2:34:46, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.092685953776
INFO:root:current train perplexity3.6242103576660156
INFO:root:current mean train loss 1637.9525764465332
INFO:root:current train perplexity3.628776788711548
INFO:root:current mean train loss 1637.242401592548
INFO:root:current train perplexity3.6392745971679688
INFO:root:current mean train loss 1636.503579711914
INFO:root:current train perplexity3.635124444961548
INFO:root:current mean train loss 1635.9351785411006
INFO:root:current train perplexity3.6322784423828125
INFO:root:current mean train loss 1635.2715377807617
INFO:root:current train perplexity3.634565830230713
INFO:root:current mean train loss 1636.4766566421047
INFO:root:current train perplexity3.6363792419433594
INFO:root:current mean train loss 1635.5816073769017
INFO:root:current train perplexity3.638275384902954
INFO:root:current mean train loss 1635.3982816474381
INFO:root:current train perplexity3.638469696044922
INFO:root:current mean train loss 1636.7947447458903
INFO:root:current train perplexity3.6413252353668213
INFO:root:current mean train loss 1639.247085398548
INFO:root:current train perplexity3.6422746181488037
INFO:root:current mean train loss 1640.784375420932
INFO:root:current train perplexity3.6435084342956543
INFO:root:current mean train loss 1641.6919894748264
INFO:root:current train perplexity3.643155336380005
INFO:root:current mean train loss 1642.8668735279757
INFO:root:current train perplexity3.6458163261413574
INFO:root:current mean train loss 1643.128470642926
INFO:root:current train perplexity3.6485235691070557
INFO:root:current mean train loss 1642.4792578281501
INFO:root:current train perplexity3.648483991622925
INFO:root:current mean train loss 1641.8417576801346
INFO:root:current train perplexity3.6480300426483154
INFO:root:current mean train loss 1641.7394823247737
INFO:root:current train perplexity3.6475765705108643
INFO:root:current mean train loss 1641.3183110719085
INFO:root:current train perplexity3.6472716331481934
INFO:root:current mean train loss 1642.0088809266383
INFO:root:current train perplexity3.6494076251983643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1641.4736416153517
INFO:root:final train perplexity: 3.649407148361206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2146.623025664201
INFO:root:eval perplexity: 5.674954891204834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [5:09:41<2:32:28, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1629.2519610516438
INFO:root:current train perplexity3.6310975551605225
INFO:root:current mean train loss 1630.1628880042815
INFO:root:current train perplexity3.623441219329834
INFO:root:current mean train loss 1633.9842613027415
INFO:root:current train perplexity3.6297481060028076
INFO:root:current mean train loss 1631.860940543663
INFO:root:current train perplexity3.620100498199463
INFO:root:current mean train loss 1635.4450727098892
INFO:root:current train perplexity3.625476837158203
INFO:root:current mean train loss 1636.8280397411856
INFO:root:current train perplexity3.6296961307525635
INFO:root:current mean train loss 1638.8130723060146
INFO:root:current train perplexity3.6298210620880127
INFO:root:current mean train loss 1637.1579033693292
INFO:root:current train perplexity3.624972105026245
INFO:root:current mean train loss 1637.7229044271576
INFO:root:current train perplexity3.629312753677368
INFO:root:current mean train loss 1639.4365374312308
INFO:root:current train perplexity3.6340317726135254
INFO:root:current mean train loss 1639.5660659945886
INFO:root:current train perplexity3.634993076324463
INFO:root:current mean train loss 1640.8639364056194
INFO:root:current train perplexity3.6367650032043457
INFO:root:current mean train loss 1640.9139367972116
INFO:root:current train perplexity3.637223720550537
INFO:root:current mean train loss 1640.0710463402663
INFO:root:current train perplexity3.6363253593444824
INFO:root:current mean train loss 1640.5577799203675
INFO:root:current train perplexity3.638634443283081
INFO:root:current mean train loss 1641.4097031113765
INFO:root:current train perplexity3.6396048069000244
INFO:root:current mean train loss 1640.1634464707486
INFO:root:current train perplexity3.641309976577759
INFO:root:current mean train loss 1640.4428805736054
INFO:root:current train perplexity3.6433515548706055
INFO:root:current mean train loss 1640.711957765883
INFO:root:current train perplexity3.6444602012634277
INFO:root:current mean train loss 1640.3110194729625
INFO:root:current train perplexity3.644693374633789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 1639.7707901193346
INFO:root:final train perplexity: 3.6445093154907227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2147.455890628463
INFO:root:eval perplexity: 5.6787800788879395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [5:11:59<2:30:09, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1642.3707418238862
INFO:root:current train perplexity3.6416494846343994
INFO:root:current mean train loss 1637.3796877516913
INFO:root:current train perplexity3.6365902423858643
INFO:root:current mean train loss 1635.2682976755154
INFO:root:current train perplexity3.631065845489502
INFO:root:current mean train loss 1638.6109925865521
INFO:root:current train perplexity3.6365177631378174
INFO:root:current mean train loss 1636.2185799911438
INFO:root:current train perplexity3.635525703430176
INFO:root:current mean train loss 1635.0603247234717
INFO:root:current train perplexity3.633747100830078
INFO:root:current mean train loss 1634.3847612276545
INFO:root:current train perplexity3.6346511840820312
INFO:root:current mean train loss 1637.492564319063
INFO:root:current train perplexity3.6378962993621826
INFO:root:current mean train loss 1638.402032020108
INFO:root:current train perplexity3.636484146118164
INFO:root:current mean train loss 1639.1980131521552
INFO:root:current train perplexity3.638139009475708
INFO:root:current mean train loss 1638.5131906233933
INFO:root:current train perplexity3.6403636932373047
INFO:root:current mean train loss 1637.9688438530543
INFO:root:current train perplexity3.641099452972412
INFO:root:current mean train loss 1638.159303455854
INFO:root:current train perplexity3.6394526958465576
INFO:root:current mean train loss 1638.0223771345666
INFO:root:current train perplexity3.639064311981201
INFO:root:current mean train loss 1638.395140375957
INFO:root:current train perplexity3.6408612728118896
INFO:root:current mean train loss 1638.194294047625
INFO:root:current train perplexity3.6404988765716553
INFO:root:current mean train loss 1638.0344937987704
INFO:root:current train perplexity3.6396946907043457
INFO:root:current mean train loss 1638.8525164720074
INFO:root:current train perplexity3.6403539180755615
INFO:root:current mean train loss 1638.9585185871708
INFO:root:current train perplexity3.640622854232788

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.75s/it]
INFO:root:final mean train loss: 1638.6223751804891
INFO:root:final train perplexity: 3.6412100791931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2147.228580988891
INFO:root:eval perplexity: 5.677734851837158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [5:14:18<2:27:53, 138.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1666.2721835049715
INFO:root:current train perplexity3.6422250270843506
INFO:root:current mean train loss 1633.9708570875564
INFO:root:current train perplexity3.6337695121765137
INFO:root:current mean train loss 1634.9527130850117
INFO:root:current train perplexity3.6299595832824707
INFO:root:current mean train loss 1639.2721500703376
INFO:root:current train perplexity3.6283628940582275
INFO:root:current mean train loss 1633.0883331670088
INFO:root:current train perplexity3.627065896987915
INFO:root:current mean train loss 1633.5221957749816
INFO:root:current train perplexity3.6252050399780273
INFO:root:current mean train loss 1632.2088435246394
INFO:root:current train perplexity3.6310415267944336
INFO:root:current mean train loss 1633.6426632823488
INFO:root:current train perplexity3.6283130645751953
INFO:root:current mean train loss 1634.2914098323347
INFO:root:current train perplexity3.629096508026123
INFO:root:current mean train loss 1635.4963713896132
INFO:root:current train perplexity3.6269521713256836
INFO:root:current mean train loss 1634.5997412254267
INFO:root:current train perplexity3.6247758865356445
INFO:root:current mean train loss 1635.1251582189468
INFO:root:current train perplexity3.6249802112579346
INFO:root:current mean train loss 1635.1577170613775
INFO:root:current train perplexity3.6258704662323
INFO:root:current mean train loss 1635.0351199361771
INFO:root:current train perplexity3.6256017684936523
INFO:root:current mean train loss 1634.78369426119
INFO:root:current train perplexity3.6256864070892334
INFO:root:current mean train loss 1634.9278192829406
INFO:root:current train perplexity3.6275181770324707
INFO:root:current mean train loss 1635.5724942321588
INFO:root:current train perplexity3.6287238597869873
INFO:root:current mean train loss 1635.69085896691
INFO:root:current train perplexity3.6299328804016113
INFO:root:current mean train loss 1636.2204315505721
INFO:root:current train perplexity3.631845474243164
INFO:root:current mean train loss 1636.4409802495218
INFO:root:current train perplexity3.6342878341674805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it]
INFO:root:final mean train loss: 1636.2637346030124
INFO:root:final train perplexity: 3.634443759918213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2148.4660700804798
INFO:root:eval perplexity: 5.683420658111572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [5:16:36<2:25:31, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1649.7352600097656
INFO:root:current train perplexity3.5829243659973145
INFO:root:current mean train loss 1636.0332260131836
INFO:root:current train perplexity3.6178276538848877
INFO:root:current mean train loss 1637.5107191654674
INFO:root:current train perplexity3.6206700801849365
INFO:root:current mean train loss 1634.7018298637577
INFO:root:current train perplexity3.617011785507202
INFO:root:current mean train loss 1633.5989667945933
INFO:root:current train perplexity3.6189961433410645
INFO:root:current mean train loss 1634.453611200506
INFO:root:current train perplexity3.616250991821289
INFO:root:current mean train loss 1636.8423360836734
INFO:root:current train perplexity3.6193089485168457
INFO:root:current mean train loss 1635.5066130921082
INFO:root:current train perplexity3.6163582801818848
INFO:root:current mean train loss 1635.7690870496963
INFO:root:current train perplexity3.6197574138641357
INFO:root:current mean train loss 1635.2082697111985
INFO:root:current train perplexity3.621445894241333
INFO:root:current mean train loss 1634.8551449311847
INFO:root:current train perplexity3.6207759380340576
INFO:root:current mean train loss 1635.3090120139698
INFO:root:current train perplexity3.623573064804077
INFO:root:current mean train loss 1634.1004079017266
INFO:root:current train perplexity3.62485933303833
INFO:root:current mean train loss 1634.6643742021308
INFO:root:current train perplexity3.624412775039673
INFO:root:current mean train loss 1635.1235224192217
INFO:root:current train perplexity3.625779390335083
INFO:root:current mean train loss 1635.089162057607
INFO:root:current train perplexity3.6253552436828613
INFO:root:current mean train loss 1635.12744523032
INFO:root:current train perplexity3.6262028217315674
INFO:root:current mean train loss 1634.9536451410365
INFO:root:current train perplexity3.6276049613952637
INFO:root:current mean train loss 1634.8149235765052
INFO:root:current train perplexity3.6280837059020996
INFO:root:current mean train loss 1634.4444000117512
INFO:root:current train perplexity3.6289782524108887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.54s/it]
INFO:root:final mean train loss: 1634.7188429839673
INFO:root:final train perplexity: 3.6300179958343506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2149.4693573214486
INFO:root:eval perplexity: 5.6880340576171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [5:18:55<2:23:11, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1650.1492567274306
INFO:root:current train perplexity3.5991063117980957
INFO:root:current mean train loss 1638.1287563981682
INFO:root:current train perplexity3.616786003112793
INFO:root:current mean train loss 1635.8833575813137
INFO:root:current train perplexity3.6142654418945312
INFO:root:current mean train loss 1632.8389411373414
INFO:root:current train perplexity3.6143040657043457
INFO:root:current mean train loss 1629.3119137881847
INFO:root:current train perplexity3.6095685958862305
INFO:root:current mean train loss 1630.6485687535837
INFO:root:current train perplexity3.611541271209717
INFO:root:current mean train loss 1632.9829765852107
INFO:root:current train perplexity3.6133227348327637
INFO:root:current mean train loss 1633.080736157718
INFO:root:current train perplexity3.6150729656219482
INFO:root:current mean train loss 1631.519713994314
INFO:root:current train perplexity3.6170079708099365
INFO:root:current mean train loss 1630.1875871930804
INFO:root:current train perplexity3.6167492866516113
INFO:root:current mean train loss 1630.7718643699536
INFO:root:current train perplexity3.6171529293060303
INFO:root:current mean train loss 1631.7505963854394
INFO:root:current train perplexity3.6204917430877686
INFO:root:current mean train loss 1631.1211077709274
INFO:root:current train perplexity3.6212751865386963
INFO:root:current mean train loss 1630.9902891931924
INFO:root:current train perplexity3.620910882949829
INFO:root:current mean train loss 1631.5338815656087
INFO:root:current train perplexity3.621042251586914
INFO:root:current mean train loss 1631.894319029379
INFO:root:current train perplexity3.623366117477417
INFO:root:current mean train loss 1631.9652184205215
INFO:root:current train perplexity3.6242659091949463
INFO:root:current mean train loss 1632.5426401744942
INFO:root:current train perplexity3.6240999698638916
INFO:root:current mean train loss 1633.291729587462
INFO:root:current train perplexity3.6250813007354736
INFO:root:current mean train loss 1633.924539396389
INFO:root:current train perplexity3.6262574195861816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1633.495752531774
INFO:root:final train perplexity: 3.6265180110931396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2150.2724384280805
INFO:root:eval perplexity: 5.691728591918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [5:21:14<2:20:53, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1637.5850790700604
INFO:root:current train perplexity3.6044695377349854
INFO:root:current mean train loss 1633.113609784915
INFO:root:current train perplexity3.6002962589263916
INFO:root:current mean train loss 1632.6737726808503
INFO:root:current train perplexity3.6112613677978516
INFO:root:current mean train loss 1629.276532420796
INFO:root:current train perplexity3.6151621341705322
INFO:root:current mean train loss 1630.0890304763595
INFO:root:current train perplexity3.6147069931030273
INFO:root:current mean train loss 1633.419319125681
INFO:root:current train perplexity3.6195764541625977
INFO:root:current mean train loss 1633.9456803705036
INFO:root:current train perplexity3.6198315620422363
INFO:root:current mean train loss 1633.6063027369382
INFO:root:current train perplexity3.6207568645477295
INFO:root:current mean train loss 1632.5639394950424
INFO:root:current train perplexity3.621060848236084
INFO:root:current mean train loss 1631.5135053924116
INFO:root:current train perplexity3.619628667831421
INFO:root:current mean train loss 1631.9180924295256
INFO:root:current train perplexity3.6215403079986572
INFO:root:current mean train loss 1633.210198459855
INFO:root:current train perplexity3.6221370697021484
INFO:root:current mean train loss 1633.0399392395502
INFO:root:current train perplexity3.6222164630889893
INFO:root:current mean train loss 1632.8446102282373
INFO:root:current train perplexity3.621305465698242
INFO:root:current mean train loss 1633.3292121104437
INFO:root:current train perplexity3.6218550205230713
INFO:root:current mean train loss 1634.1339294199145
INFO:root:current train perplexity3.6232564449310303
INFO:root:current mean train loss 1633.4662731918904
INFO:root:current train perplexity3.622897148132324
INFO:root:current mean train loss 1633.6819702564114
INFO:root:current train perplexity3.6233134269714355
INFO:root:current mean train loss 1633.3156215122767
INFO:root:current train perplexity3.622401237487793
INFO:root:current mean train loss 1633.1174902493071
INFO:root:current train perplexity3.6234476566314697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1632.61313249412
INFO:root:final train perplexity: 3.6239945888519287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2151.1697097670103
INFO:root:eval perplexity: 5.695860862731934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [5:23:32<2:18:35, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1644.2216070633901
INFO:root:current train perplexity3.6023359298706055
INFO:root:current mean train loss 1634.9241152289194
INFO:root:current train perplexity3.6034202575683594
INFO:root:current mean train loss 1623.8011378353215
INFO:root:current train perplexity3.6078040599823
INFO:root:current mean train loss 1627.5255755019377
INFO:root:current train perplexity3.614194631576538
INFO:root:current mean train loss 1629.351044147149
INFO:root:current train perplexity3.615419387817383
INFO:root:current mean train loss 1627.7400309244792
INFO:root:current train perplexity3.611663579940796
INFO:root:current mean train loss 1629.9406391306725
INFO:root:current train perplexity3.61342453956604
INFO:root:current mean train loss 1628.5677601492298
INFO:root:current train perplexity3.6117660999298096
INFO:root:current mean train loss 1628.2523215579226
INFO:root:current train perplexity3.612504005432129
INFO:root:current mean train loss 1628.0683586268674
INFO:root:current train perplexity3.614105463027954
INFO:root:current mean train loss 1629.4989551052768
INFO:root:current train perplexity3.6141581535339355
INFO:root:current mean train loss 1629.6636524928435
INFO:root:current train perplexity3.6159026622772217
INFO:root:current mean train loss 1630.3394296271806
INFO:root:current train perplexity3.6153147220611572
INFO:root:current mean train loss 1630.6875898487071
INFO:root:current train perplexity3.6154844760894775
INFO:root:current mean train loss 1631.7228261084877
INFO:root:current train perplexity3.618048906326294
INFO:root:current mean train loss 1630.7419002984732
INFO:root:current train perplexity3.6174211502075195
INFO:root:current mean train loss 1630.7007389216285
INFO:root:current train perplexity3.6171653270721436
INFO:root:current mean train loss 1631.111063742249
INFO:root:current train perplexity3.6187167167663574
INFO:root:current mean train loss 1631.5919036134371
INFO:root:current train perplexity3.6181585788726807
INFO:root:current mean train loss 1631.358851991319
INFO:root:current train perplexity3.6192150115966797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1630.884353337598
INFO:root:final train perplexity: 3.6190571784973145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2151.417863561752
INFO:root:eval perplexity: 5.6970038414001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [5:25:51<2:16:19, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1624.5743039449055
INFO:root:current train perplexity3.6012215614318848
INFO:root:current mean train loss 1622.420882867307
INFO:root:current train perplexity3.5863778591156006
INFO:root:current mean train loss 1621.0406102360905
INFO:root:current train perplexity3.5908260345458984
INFO:root:current mean train loss 1623.6309771296953
INFO:root:current train perplexity3.5933337211608887
INFO:root:current mean train loss 1626.6963796307964
INFO:root:current train perplexity3.601217746734619
INFO:root:current mean train loss 1628.154987719235
INFO:root:current train perplexity3.6043710708618164
INFO:root:current mean train loss 1628.2699300831762
INFO:root:current train perplexity3.6032166481018066
INFO:root:current mean train loss 1627.662203381409
INFO:root:current train perplexity3.6033027172088623
INFO:root:current mean train loss 1627.713271686009
INFO:root:current train perplexity3.6061923503875732
INFO:root:current mean train loss 1628.2364146527516
INFO:root:current train perplexity3.607131004333496
INFO:root:current mean train loss 1629.7800225028157
INFO:root:current train perplexity3.6080479621887207
INFO:root:current mean train loss 1630.32010887937
INFO:root:current train perplexity3.6102240085601807
INFO:root:current mean train loss 1629.3089732417354
INFO:root:current train perplexity3.611182689666748
INFO:root:current mean train loss 1629.2180940906776
INFO:root:current train perplexity3.610776662826538
INFO:root:current mean train loss 1630.2003402301973
INFO:root:current train perplexity3.6105504035949707
INFO:root:current mean train loss 1631.046493109605
INFO:root:current train perplexity3.6121225357055664
INFO:root:current mean train loss 1630.6631931089005
INFO:root:current train perplexity3.6135025024414062
INFO:root:current mean train loss 1630.2168882917986
INFO:root:current train perplexity3.6136996746063232
INFO:root:current mean train loss 1629.9130752499093
INFO:root:current train perplexity3.6143290996551514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1629.493404694296
INFO:root:final train perplexity: 3.6150896549224854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2152.457191413176
INFO:root:eval perplexity: 5.701793670654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [5:28:10<2:14:01, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1626.2918419471155
INFO:root:current train perplexity3.5720574855804443
INFO:root:current mean train loss 1616.1245344043832
INFO:root:current train perplexity3.5781280994415283
INFO:root:current mean train loss 1627.2202188554504
INFO:root:current train perplexity3.598146915435791
INFO:root:current mean train loss 1624.2154291414986
INFO:root:current train perplexity3.5877363681793213
INFO:root:current mean train loss 1621.695960980062
INFO:root:current train perplexity3.595095634460449
INFO:root:current mean train loss 1624.1015191924037
INFO:root:current train perplexity3.5955474376678467
INFO:root:current mean train loss 1625.7806265054676
INFO:root:current train perplexity3.5975358486175537
INFO:root:current mean train loss 1625.8998100633876
INFO:root:current train perplexity3.6015641689300537
INFO:root:current mean train loss 1625.9772039321956
INFO:root:current train perplexity3.601492166519165
INFO:root:current mean train loss 1624.9094991025893
INFO:root:current train perplexity3.6000776290893555
INFO:root:current mean train loss 1626.1206516216914
INFO:root:current train perplexity3.6043341159820557
INFO:root:current mean train loss 1627.157254420415
INFO:root:current train perplexity3.603823184967041
INFO:root:current mean train loss 1626.7889043017055
INFO:root:current train perplexity3.6021413803100586
INFO:root:current mean train loss 1625.498131478187
INFO:root:current train perplexity3.6023402214050293
INFO:root:current mean train loss 1626.0198058866054
INFO:root:current train perplexity3.6035847663879395
INFO:root:current mean train loss 1625.6899118770139
INFO:root:current train perplexity3.6038124561309814
INFO:root:current mean train loss 1626.1053752863695
INFO:root:current train perplexity3.607614517211914
INFO:root:current mean train loss 1626.5318446741144
INFO:root:current train perplexity3.6099438667297363
INFO:root:current mean train loss 1626.879620290631
INFO:root:current train perplexity3.6104238033294678
INFO:root:current mean train loss 1628.1235541080966
INFO:root:current train perplexity3.6102283000946045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it]
INFO:root:final mean train loss: 1627.8675075113563
INFO:root:final train perplexity: 3.610456943511963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2153.566191111896
INFO:root:eval perplexity: 5.706910133361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [5:30:28<2:11:45, 138.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1634.1858154296874
INFO:root:current train perplexity3.5941455364227295
INFO:root:current mean train loss 1620.212060546875
INFO:root:current train perplexity3.5706074237823486
INFO:root:current mean train loss 1625.506324834409
INFO:root:current train perplexity3.579192876815796
INFO:root:current mean train loss 1624.7253943241003
INFO:root:current train perplexity3.586592197418213
INFO:root:current mean train loss 1624.887836119186
INFO:root:current train perplexity3.5893449783325195
INFO:root:current mean train loss 1622.9093754606427
INFO:root:current train perplexity3.5879173278808594
INFO:root:current mean train loss 1623.9688294425844
INFO:root:current train perplexity3.589677333831787
INFO:root:current mean train loss 1624.7301060506743
INFO:root:current train perplexity3.59266996383667
INFO:root:current mean train loss 1624.5330404626318
INFO:root:current train perplexity3.592594861984253
INFO:root:current mean train loss 1624.0666110131049
INFO:root:current train perplexity3.59425687789917
INFO:root:current mean train loss 1624.940285810452
INFO:root:current train perplexity3.5970489978790283
INFO:root:current mean train loss 1625.3180341062293
INFO:root:current train perplexity3.5993120670318604
INFO:root:current mean train loss 1625.9843798629636
INFO:root:current train perplexity3.601353883743286
INFO:root:current mean train loss 1625.8713801104323
INFO:root:current train perplexity3.6021575927734375
INFO:root:current mean train loss 1624.7171047824247
INFO:root:current train perplexity3.602882146835327
INFO:root:current mean train loss 1624.4252559487336
INFO:root:current train perplexity3.6033201217651367
INFO:root:current mean train loss 1625.434379118937
INFO:root:current train perplexity3.604846239089966
INFO:root:current mean train loss 1625.654035305839
INFO:root:current train perplexity3.6054277420043945
INFO:root:current mean train loss 1626.117642695526
INFO:root:current train perplexity3.6059741973876953
INFO:root:current mean train loss 1627.4219003627954
INFO:root:current train perplexity3.607478618621826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.91s/it]
INFO:root:final mean train loss: 1626.696428646178
INFO:root:final train perplexity: 3.607123851776123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2153.8481220218305
INFO:root:eval perplexity: 5.708211898803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [5:32:47<2:09:28, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1627.4953665226064
INFO:root:current train perplexity3.6281585693359375
INFO:root:current mean train loss 1618.6502369990965
INFO:root:current train perplexity3.563814640045166
INFO:root:current mean train loss 1616.683958972514
INFO:root:current train perplexity3.569406747817993
INFO:root:current mean train loss 1618.842884250608
INFO:root:current train perplexity3.5806829929351807
INFO:root:current mean train loss 1620.9305310686696
INFO:root:current train perplexity3.577819585800171
INFO:root:current mean train loss 1622.8367759244315
INFO:root:current train perplexity3.5824472904205322
INFO:root:current mean train loss 1624.3005480523088
INFO:root:current train perplexity3.5892367362976074
INFO:root:current mean train loss 1624.6916379711554
INFO:root:current train perplexity3.593777894973755
INFO:root:current mean train loss 1624.0093753458898
INFO:root:current train perplexity3.5931589603424072
INFO:root:current mean train loss 1624.5740018077233
INFO:root:current train perplexity3.5941481590270996
INFO:root:current mean train loss 1623.7282101577423
INFO:root:current train perplexity3.593381404876709
INFO:root:current mean train loss 1624.7266229498148
INFO:root:current train perplexity3.5945115089416504
INFO:root:current mean train loss 1624.3426647782803
INFO:root:current train perplexity3.5964131355285645
INFO:root:current mean train loss 1625.773589838675
INFO:root:current train perplexity3.59800124168396
INFO:root:current mean train loss 1625.6091522870595
INFO:root:current train perplexity3.5996546745300293
INFO:root:current mean train loss 1625.6870151906917
INFO:root:current train perplexity3.600762367248535
INFO:root:current mean train loss 1625.3566923436788
INFO:root:current train perplexity3.6017913818359375
INFO:root:current mean train loss 1625.8494760549333
INFO:root:current train perplexity3.6019930839538574
INFO:root:current mean train loss 1626.1867041306425
INFO:root:current train perplexity3.603262186050415
INFO:root:current mean train loss 1626.0868746890249
INFO:root:current train perplexity3.6031947135925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1625.477432351009
INFO:root:final train perplexity: 3.6036574840545654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2154.7336187700853
INFO:root:eval perplexity: 5.712301731109619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [5:35:06<2:07:06, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.075101852417
INFO:root:current train perplexity3.607344388961792
INFO:root:current mean train loss 1622.4086698206459
INFO:root:current train perplexity3.5931034088134766
INFO:root:current mean train loss 1615.61203696511
INFO:root:current train perplexity3.5788066387176514
INFO:root:current mean train loss 1617.3890005258413
INFO:root:current train perplexity3.5876803398132324
INFO:root:current mean train loss 1618.04712782235
INFO:root:current train perplexity3.5920331478118896
INFO:root:current mean train loss 1618.0673155006787
INFO:root:current train perplexity3.589226722717285
INFO:root:current mean train loss 1620.2843675728304
INFO:root:current train perplexity3.5925674438476562
INFO:root:current mean train loss 1620.1024324906434
INFO:root:current train perplexity3.5928964614868164
INFO:root:current mean train loss 1620.90121572989
INFO:root:current train perplexity3.5946104526519775
INFO:root:current mean train loss 1620.5207606905228
INFO:root:current train perplexity3.5968124866485596
INFO:root:current mean train loss 1620.7174102094837
INFO:root:current train perplexity3.597731351852417
INFO:root:current mean train loss 1620.728697996369
INFO:root:current train perplexity3.594355583190918
INFO:root:current mean train loss 1621.5662743290768
INFO:root:current train perplexity3.595730781555176
INFO:root:current mean train loss 1623.099802861815
INFO:root:current train perplexity3.5972299575805664
INFO:root:current mean train loss 1623.6447342002327
INFO:root:current train perplexity3.5975637435913086
INFO:root:current mean train loss 1623.7462201911164
INFO:root:current train perplexity3.5977883338928223
INFO:root:current mean train loss 1624.8900045248179
INFO:root:current train perplexity3.599860191345215
INFO:root:current mean train loss 1624.4996881809363
INFO:root:current train perplexity3.6005866527557373
INFO:root:current mean train loss 1624.9005511369828
INFO:root:current train perplexity3.600207805633545
INFO:root:current mean train loss 1624.8959179662638
INFO:root:current train perplexity3.600607395172119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1624.4763865660852
INFO:root:final train perplexity: 3.600813865661621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2154.943126921958
INFO:root:eval perplexity: 5.713269233703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [5:37:24<2:04:48, 138.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1612.2744818793403
INFO:root:current train perplexity3.600921630859375
INFO:root:current mean train loss 1615.4381912821564
INFO:root:current train perplexity3.596419334411621
INFO:root:current mean train loss 1617.8861153490602
INFO:root:current train perplexity3.5912654399871826
INFO:root:current mean train loss 1616.989852464731
INFO:root:current train perplexity3.5900659561157227
INFO:root:current mean train loss 1616.617248915833
INFO:root:current train perplexity3.5857350826263428
INFO:root:current mean train loss 1619.2226783109
INFO:root:current train perplexity3.5891451835632324
INFO:root:current mean train loss 1620.013890741155
INFO:root:current train perplexity3.5935449600219727
INFO:root:current mean train loss 1620.610976762564
INFO:root:current train perplexity3.5911104679107666
INFO:root:current mean train loss 1621.0686902534408
INFO:root:current train perplexity3.5938498973846436
INFO:root:current mean train loss 1621.1662572769337
INFO:root:current train perplexity3.594252347946167
INFO:root:current mean train loss 1620.2415611132992
INFO:root:current train perplexity3.590803384780884
INFO:root:current mean train loss 1620.1269078525218
INFO:root:current train perplexity3.5921790599823
INFO:root:current mean train loss 1620.4063599681035
INFO:root:current train perplexity3.5932271480560303
INFO:root:current mean train loss 1621.9252252599451
INFO:root:current train perplexity3.592886209487915
INFO:root:current mean train loss 1621.5821789542538
INFO:root:current train perplexity3.594252347946167
INFO:root:current mean train loss 1621.3349146110056
INFO:root:current train perplexity3.594195604324341
INFO:root:current mean train loss 1622.5774644696237
INFO:root:current train perplexity3.5942723751068115
INFO:root:current mean train loss 1622.5552590577406
INFO:root:current train perplexity3.595193386077881
INFO:root:current mean train loss 1622.6699987124534
INFO:root:current train perplexity3.5955851078033447
INFO:root:current mean train loss 1622.8939002555528
INFO:root:current train perplexity3.5950918197631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.33s/it]
INFO:root:final mean train loss: 1622.502823283801
INFO:root:final train perplexity: 3.5952134132385254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2157.262193612173
INFO:root:eval perplexity: 5.723996162414551
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [5:39:43<2:02:23, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1610.115289182079
INFO:root:current train perplexity3.5593655109405518
INFO:root:current mean train loss 1618.0121823705808
INFO:root:current train perplexity3.577208995819092
INFO:root:current mean train loss 1619.739127549549
INFO:root:current train perplexity3.5810091495513916
INFO:root:current mean train loss 1613.511959210113
INFO:root:current train perplexity3.5765459537506104
INFO:root:current mean train loss 1613.8541080827215
INFO:root:current train perplexity3.5790374279022217
INFO:root:current mean train loss 1615.574209155845
INFO:root:current train perplexity3.576631546020508
INFO:root:current mean train loss 1616.0369761119941
INFO:root:current train perplexity3.5785672664642334
INFO:root:current mean train loss 1617.2004888625372
INFO:root:current train perplexity3.575239658355713
INFO:root:current mean train loss 1617.5323673919474
INFO:root:current train perplexity3.5772898197174072
INFO:root:current mean train loss 1619.1199864328266
INFO:root:current train perplexity3.5813794136047363
INFO:root:current mean train loss 1619.1432980952584
INFO:root:current train perplexity3.583319902420044
INFO:root:current mean train loss 1619.561137662706
INFO:root:current train perplexity3.583237409591675
INFO:root:current mean train loss 1620.3739624963887
INFO:root:current train perplexity3.5813519954681396
INFO:root:current mean train loss 1620.47187877213
INFO:root:current train perplexity3.5838046073913574
INFO:root:current mean train loss 1621.3138840068007
INFO:root:current train perplexity3.5869781970977783
INFO:root:current mean train loss 1621.029641773286
INFO:root:current train perplexity3.5873332023620605
INFO:root:current mean train loss 1621.3290459910327
INFO:root:current train perplexity3.588000774383545
INFO:root:current mean train loss 1621.9207840390147
INFO:root:current train perplexity3.5897057056427
INFO:root:current mean train loss 1621.691851504359
INFO:root:current train perplexity3.590000867843628

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1620.721959131869
INFO:root:final train perplexity: 3.59016752243042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2157.1129345183676
INFO:root:eval perplexity: 5.723303318023682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [5:42:01<2:00:05, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1596.9966796875
INFO:root:current train perplexity3.5291337966918945
INFO:root:current mean train loss 1614.9834738026495
INFO:root:current train perplexity3.602240562438965
INFO:root:current mean train loss 1611.1086539335029
INFO:root:current train perplexity3.589460849761963
INFO:root:current mean train loss 1608.1545669797868
INFO:root:current train perplexity3.5818028450012207
INFO:root:current mean train loss 1610.4912156438254
INFO:root:current train perplexity3.580348014831543
INFO:root:current mean train loss 1612.1130183840262
INFO:root:current train perplexity3.5800137519836426
INFO:root:current mean train loss 1609.9616377667683
INFO:root:current train perplexity3.573643922805786
INFO:root:current mean train loss 1610.660530997323
INFO:root:current train perplexity3.5742084980010986
INFO:root:current mean train loss 1612.419799355349
INFO:root:current train perplexity3.578962802886963
INFO:root:current mean train loss 1612.571445285818
INFO:root:current train perplexity3.578646659851074
INFO:root:current mean train loss 1612.825104391164
INFO:root:current train perplexity3.5825278759002686
INFO:root:current mean train loss 1613.8813099950953
INFO:root:current train perplexity3.583423137664795
INFO:root:current mean train loss 1615.9136207360789
INFO:root:current train perplexity3.5828700065612793
INFO:root:current mean train loss 1615.87282473488
INFO:root:current train perplexity3.58376407623291
INFO:root:current mean train loss 1616.4772678334805
INFO:root:current train perplexity3.583085298538208
INFO:root:current mean train loss 1617.6175405773
INFO:root:current train perplexity3.5837910175323486
INFO:root:current mean train loss 1618.327674435831
INFO:root:current train perplexity3.584873676300049
INFO:root:current mean train loss 1618.165320785122
INFO:root:current train perplexity3.584834098815918
INFO:root:current mean train loss 1618.8707432770532
INFO:root:current train perplexity3.5858914852142334
INFO:root:current mean train loss 1619.990679373878
INFO:root:current train perplexity3.5869176387786865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1619.8165635009395
INFO:root:final train perplexity: 3.5876047611236572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2157.3468878996287
INFO:root:eval perplexity: 5.724387168884277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [5:44:20<1:57:47, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.0629196166992
INFO:root:current train perplexity3.5262157917022705
INFO:root:current mean train loss 1610.7122146144059
INFO:root:current train perplexity3.558089256286621
INFO:root:current mean train loss 1610.5889366412985
INFO:root:current train perplexity3.569453716278076
INFO:root:current mean train loss 1612.5936139577843
INFO:root:current train perplexity3.563343048095703
INFO:root:current mean train loss 1613.6077377884476
INFO:root:current train perplexity3.5676398277282715
INFO:root:current mean train loss 1611.8234236867804
INFO:root:current train perplexity3.5708823204040527
INFO:root:current mean train loss 1615.1149745892874
INFO:root:current train perplexity3.5738391876220703
INFO:root:current mean train loss 1615.1846618652344
INFO:root:current train perplexity3.572437286376953
INFO:root:current mean train loss 1613.0510666186992
INFO:root:current train perplexity3.571942090988159
INFO:root:current mean train loss 1615.3434143066406
INFO:root:current train perplexity3.573688268661499
INFO:root:current mean train loss 1616.8514017504315
INFO:root:current train perplexity3.575363874435425
INFO:root:current mean train loss 1618.5872198852971
INFO:root:current train perplexity3.5755603313446045
INFO:root:current mean train loss 1618.2551740175718
INFO:root:current train perplexity3.5769944190979004
INFO:root:current mean train loss 1617.6088031390766
INFO:root:current train perplexity3.576037645339966
INFO:root:current mean train loss 1618.502132223971
INFO:root:current train perplexity3.5791432857513428
INFO:root:current mean train loss 1618.5188228119137
INFO:root:current train perplexity3.580738067626953
INFO:root:current mean train loss 1618.163662255979
INFO:root:current train perplexity3.58154034614563
INFO:root:current mean train loss 1618.1699974289118
INFO:root:current train perplexity3.5809783935546875
INFO:root:current mean train loss 1617.7353846787366
INFO:root:current train perplexity3.5806515216827393
INFO:root:current mean train loss 1618.298064237796
INFO:root:current train perplexity3.582042932510376

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.68s/it]
INFO:root:final mean train loss: 1618.2794625594408
INFO:root:final train perplexity: 3.5832583904266357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2158.5682338417
INFO:root:eval perplexity: 5.730044364929199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [5:46:38<1:55:29, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.2903504663584
INFO:root:current train perplexity3.56451678276062
INFO:root:current mean train loss 1612.0081893613674
INFO:root:current train perplexity3.55033278465271
INFO:root:current mean train loss 1611.9971899316015
INFO:root:current train perplexity3.548417329788208
INFO:root:current mean train loss 1607.8429612648863
INFO:root:current train perplexity3.5565028190612793
INFO:root:current mean train loss 1610.1654941754246
INFO:root:current train perplexity3.560377836227417
INFO:root:current mean train loss 1610.1716344169797
INFO:root:current train perplexity3.5577025413513184
INFO:root:current mean train loss 1612.2670029462395
INFO:root:current train perplexity3.5620250701904297
INFO:root:current mean train loss 1614.0322704035068
INFO:root:current train perplexity3.562054395675659
INFO:root:current mean train loss 1613.8742930274127
INFO:root:current train perplexity3.5648040771484375
INFO:root:current mean train loss 1612.9709522822131
INFO:root:current train perplexity3.566032886505127
INFO:root:current mean train loss 1613.8502419529016
INFO:root:current train perplexity3.569758653640747
INFO:root:current mean train loss 1614.0968798445658
INFO:root:current train perplexity3.571153163909912
INFO:root:current mean train loss 1614.858565270185
INFO:root:current train perplexity3.572628974914551
INFO:root:current mean train loss 1614.894125766627
INFO:root:current train perplexity3.574291944503784
INFO:root:current mean train loss 1616.0441025970226
INFO:root:current train perplexity3.5753579139709473
INFO:root:current mean train loss 1616.012761115412
INFO:root:current train perplexity3.5762100219726562
INFO:root:current mean train loss 1615.579611903758
INFO:root:current train perplexity3.5762946605682373
INFO:root:current mean train loss 1615.381177358044
INFO:root:current train perplexity3.576331377029419
INFO:root:current mean train loss 1616.353248971678
INFO:root:current train perplexity3.577754020690918
INFO:root:current mean train loss 1616.7746406034546
INFO:root:current train perplexity3.5786054134368896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.77s/it]
INFO:root:final mean train loss: 1616.6632834168558
INFO:root:final train perplexity: 3.5786936283111572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2158.5593997603614
INFO:root:eval perplexity: 5.730003356933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [5:48:57<1:53:12, 138.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.3114032167377
INFO:root:current train perplexity3.5677762031555176
INFO:root:current mean train loss 1609.0805465514402
INFO:root:current train perplexity3.57122802734375
INFO:root:current mean train loss 1610.6922579887218
INFO:root:current train perplexity3.5700600147247314
INFO:root:current mean train loss 1610.6286080782531
INFO:root:current train perplexity3.571899890899658
INFO:root:current mean train loss 1611.1813315199167
INFO:root:current train perplexity3.5690183639526367
INFO:root:current mean train loss 1609.5740697206961
INFO:root:current train perplexity3.5701563358306885
INFO:root:current mean train loss 1610.1564904748498
INFO:root:current train perplexity3.5721473693847656
INFO:root:current mean train loss 1611.9297313241984
INFO:root:current train perplexity3.5745809078216553
INFO:root:current mean train loss 1612.2634555032566
INFO:root:current train perplexity3.57261323928833
INFO:root:current mean train loss 1612.7019294438649
INFO:root:current train perplexity3.571772575378418
INFO:root:current mean train loss 1612.6096165068377
INFO:root:current train perplexity3.5730347633361816
INFO:root:current mean train loss 1613.1864225148745
INFO:root:current train perplexity3.5717039108276367
INFO:root:current mean train loss 1614.4570766647846
INFO:root:current train perplexity3.5735020637512207
INFO:root:current mean train loss 1613.8849185256622
INFO:root:current train perplexity3.573249578475952
INFO:root:current mean train loss 1614.60779774498
INFO:root:current train perplexity3.573239803314209
INFO:root:current mean train loss 1615.6996037469817
INFO:root:current train perplexity3.5743563175201416
INFO:root:current mean train loss 1615.3283684811815
INFO:root:current train perplexity3.574525833129883
INFO:root:current mean train loss 1615.7584943242143
INFO:root:current train perplexity3.5760087966918945
INFO:root:current mean train loss 1616.2846565205696
INFO:root:current train perplexity3.576180934906006
INFO:root:current mean train loss 1616.9146626065974
INFO:root:current train perplexity3.577863931655884

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.51s/it]
INFO:root:final mean train loss: 1616.3920944606302
INFO:root:final train perplexity: 3.5779287815093994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2159.6415868448025
INFO:root:eval perplexity: 5.735019683837891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [5:51:16<1:50:51, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1595.7415609704442
INFO:root:current train perplexity3.5624849796295166
INFO:root:current mean train loss 1602.7230451406676
INFO:root:current train perplexity3.5565426349639893
INFO:root:current mean train loss 1608.9085775314709
INFO:root:current train perplexity3.567624807357788
INFO:root:current mean train loss 1609.6922613796303
INFO:root:current train perplexity3.572242259979248
INFO:root:current mean train loss 1606.3636509992075
INFO:root:current train perplexity3.5637660026550293
INFO:root:current mean train loss 1608.2805636423939
INFO:root:current train perplexity3.564504623413086
INFO:root:current mean train loss 1611.2582459121636
INFO:root:current train perplexity3.5669729709625244
INFO:root:current mean train loss 1612.0971766991938
INFO:root:current train perplexity3.5677263736724854
INFO:root:current mean train loss 1611.9239219933377
INFO:root:current train perplexity3.565061569213867
INFO:root:current mean train loss 1611.0150977257915
INFO:root:current train perplexity3.5655393600463867
INFO:root:current mean train loss 1611.615512442831
INFO:root:current train perplexity3.5660502910614014
INFO:root:current mean train loss 1611.3624093191963
INFO:root:current train perplexity3.5629682540893555
INFO:root:current mean train loss 1613.4613972379188
INFO:root:current train perplexity3.564074993133545
INFO:root:current mean train loss 1613.9977807564228
INFO:root:current train perplexity3.56567120552063
INFO:root:current mean train loss 1614.0204901151856
INFO:root:current train perplexity3.567063093185425
INFO:root:current mean train loss 1613.143922440703
INFO:root:current train perplexity3.566507339477539
INFO:root:current mean train loss 1613.2969711766098
INFO:root:current train perplexity3.5676612854003906
INFO:root:current mean train loss 1614.0466857670535
INFO:root:current train perplexity3.5667262077331543
INFO:root:current mean train loss 1613.8205034820185
INFO:root:current train perplexity3.569387674331665
INFO:root:current mean train loss 1614.0935269123488
INFO:root:current train perplexity3.571448564529419

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it]
INFO:root:final mean train loss: 1614.0935269123488
INFO:root:final train perplexity: 3.571448564529419
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2159.5725643076794
INFO:root:eval perplexity: 5.734701156616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [5:53:34<1:48:32, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1612.0318041992186
INFO:root:current train perplexity3.553342819213867
INFO:root:current mean train loss 1609.9591009521484
INFO:root:current train perplexity3.558105945587158
INFO:root:current mean train loss 1607.7272058105468
INFO:root:current train perplexity3.5583553314208984
INFO:root:current mean train loss 1609.6676321411132
INFO:root:current train perplexity3.5632262229919434
INFO:root:current mean train loss 1607.7704345703125
INFO:root:current train perplexity3.5679829120635986
INFO:root:current mean train loss 1607.3774674479166
INFO:root:current train perplexity3.569645881652832
INFO:root:current mean train loss 1608.9078278459822
INFO:root:current train perplexity3.569582939147949
INFO:root:current mean train loss 1610.583627166748
INFO:root:current train perplexity3.571326732635498
INFO:root:current mean train loss 1611.1972672526042
INFO:root:current train perplexity3.5703842639923096
INFO:root:current mean train loss 1611.9186201171874
INFO:root:current train perplexity3.5702199935913086
INFO:root:current mean train loss 1611.1884844415838
INFO:root:current train perplexity3.5701370239257812
INFO:root:current mean train loss 1611.6779682413737
INFO:root:current train perplexity3.570218324661255
INFO:root:current mean train loss 1612.423346886268
INFO:root:current train perplexity3.569899082183838
INFO:root:current mean train loss 1611.9190100969588
INFO:root:current train perplexity3.5704946517944336
INFO:root:current mean train loss 1612.229481201172
INFO:root:current train perplexity3.5711889266967773
INFO:root:current mean train loss 1613.1052072143555
INFO:root:current train perplexity3.569580078125
INFO:root:current mean train loss 1613.3809398696003
INFO:root:current train perplexity3.570340871810913
INFO:root:current mean train loss 1613.8470619710286
INFO:root:current train perplexity3.5699217319488525
INFO:root:current mean train loss 1613.8946286492599
INFO:root:current train perplexity3.5708436965942383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it]
INFO:root:final mean train loss: 1613.9065694265514
INFO:root:final train perplexity: 3.5709218978881836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2160.800947040531
INFO:root:eval perplexity: 5.740400314331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [5:55:53<1:46:15, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1620.640567555147
INFO:root:current train perplexity3.6214828491210938
INFO:root:current mean train loss 1623.8144792084001
INFO:root:current train perplexity3.579493522644043
INFO:root:current mean train loss 1614.4095914638538
INFO:root:current train perplexity3.5838124752044678
INFO:root:current mean train loss 1613.2082584994826
INFO:root:current train perplexity3.5808968544006348
INFO:root:current mean train loss 1612.0657268130808
INFO:root:current train perplexity3.5725297927856445
INFO:root:current mean train loss 1610.975129059251
INFO:root:current train perplexity3.565234661102295
INFO:root:current mean train loss 1610.869005694768
INFO:root:current train perplexity3.564418315887451
INFO:root:current mean train loss 1613.5230055719906
INFO:root:current train perplexity3.5656402111053467
INFO:root:current mean train loss 1612.9398106699912
INFO:root:current train perplexity3.563791513442993
INFO:root:current mean train loss 1613.1845878842353
INFO:root:current train perplexity3.564244031906128
INFO:root:current mean train loss 1614.0297799949683
INFO:root:current train perplexity3.56355881690979
INFO:root:current mean train loss 1614.6252052354941
INFO:root:current train perplexity3.565248727798462
INFO:root:current mean train loss 1614.9363029686858
INFO:root:current train perplexity3.56669020652771
INFO:root:current mean train loss 1614.0153401692708
INFO:root:current train perplexity3.566312074661255
INFO:root:current mean train loss 1613.9795616219897
INFO:root:current train perplexity3.5662994384765625
INFO:root:current mean train loss 1613.6499198858253
INFO:root:current train perplexity3.5646584033966064
INFO:root:current mean train loss 1612.665867585493
INFO:root:current train perplexity3.564786672592163
INFO:root:current mean train loss 1612.9899978415524
INFO:root:current train perplexity3.5653035640716553
INFO:root:current mean train loss 1613.3755775665804
INFO:root:current train perplexity3.565696954727173
INFO:root:current mean train loss 1612.7084980677614
INFO:root:current train perplexity3.565652370452881

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.56s/it]
INFO:root:final mean train loss: 1612.3166909883917
INFO:root:final train perplexity: 3.5664477348327637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2162.2515007722463
INFO:root:eval perplexity: 5.747138500213623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [5:58:11<1:43:55, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1627.1438167796416
INFO:root:current train perplexity3.592280149459839
INFO:root:current mean train loss 1601.0818035068796
INFO:root:current train perplexity3.5350501537323
INFO:root:current mean train loss 1598.3963878664197
INFO:root:current train perplexity3.547659397125244
INFO:root:current mean train loss 1600.9047924658496
INFO:root:current train perplexity3.5509884357452393
INFO:root:current mean train loss 1603.4055763631372
INFO:root:current train perplexity3.5590662956237793
INFO:root:current mean train loss 1605.2110828871137
INFO:root:current train perplexity3.5581886768341064
INFO:root:current mean train loss 1605.5037375850256
INFO:root:current train perplexity3.5584604740142822
INFO:root:current mean train loss 1606.1127266117273
INFO:root:current train perplexity3.561882495880127
INFO:root:current mean train loss 1606.3681049301183
INFO:root:current train perplexity3.559393882751465
INFO:root:current mean train loss 1608.0224272178634
INFO:root:current train perplexity3.5609090328216553
INFO:root:current mean train loss 1609.8141316574363
INFO:root:current train perplexity3.5610618591308594
INFO:root:current mean train loss 1610.2169325086807
INFO:root:current train perplexity3.561774969100952
INFO:root:current mean train loss 1610.3026416846574
INFO:root:current train perplexity3.5610294342041016
INFO:root:current mean train loss 1610.2878542418243
INFO:root:current train perplexity3.5608956813812256
INFO:root:current mean train loss 1610.5739724812315
INFO:root:current train perplexity3.561861276626587
INFO:root:current mean train loss 1611.19220718722
INFO:root:current train perplexity3.56321120262146
INFO:root:current mean train loss 1611.0160393218807
INFO:root:current train perplexity3.5639865398406982
INFO:root:current mean train loss 1612.0588755536107
INFO:root:current train perplexity3.563826084136963
INFO:root:current mean train loss 1612.192670416546
INFO:root:current train perplexity3.565016984939575
INFO:root:current mean train loss 1612.1991598608574
INFO:root:current train perplexity3.5651814937591553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.86s/it]
INFO:root:final mean train loss: 1611.7250373290153
INFO:root:final train perplexity: 3.5647833347320557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2162.444478785738
INFO:root:eval perplexity: 5.748035430908203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [6:00:30<1:41:39, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.5279588886335
INFO:root:current train perplexity3.537421941757202
INFO:root:current mean train loss 1600.1630511757553
INFO:root:current train perplexity3.5144989490509033
INFO:root:current mean train loss 1600.1484929422934
INFO:root:current train perplexity3.5268259048461914
INFO:root:current mean train loss 1598.2575711416043
INFO:root:current train perplexity3.524263858795166
INFO:root:current mean train loss 1602.364736620444
INFO:root:current train perplexity3.5309460163116455
INFO:root:current mean train loss 1601.8084747812925
INFO:root:current train perplexity3.5359790325164795
INFO:root:current mean train loss 1603.363796908002
INFO:root:current train perplexity3.538252353668213
INFO:root:current mean train loss 1603.811462808703
INFO:root:current train perplexity3.5395255088806152
INFO:root:current mean train loss 1605.593202906966
INFO:root:current train perplexity3.5404369831085205
INFO:root:current mean train loss 1606.5876762638834
INFO:root:current train perplexity3.541577100753784
INFO:root:current mean train loss 1606.055699835722
INFO:root:current train perplexity3.5438191890716553
INFO:root:current mean train loss 1606.6255191435098
INFO:root:current train perplexity3.5454025268554688
INFO:root:current mean train loss 1606.81305180465
INFO:root:current train perplexity3.5464847087860107
INFO:root:current mean train loss 1608.314337198863
INFO:root:current train perplexity3.5495355129241943
INFO:root:current mean train loss 1609.028599955311
INFO:root:current train perplexity3.5542681217193604
INFO:root:current mean train loss 1609.893889967662
INFO:root:current train perplexity3.5572566986083984
INFO:root:current mean train loss 1610.2503265066625
INFO:root:current train perplexity3.558222532272339
INFO:root:current mean train loss 1609.9730157683332
INFO:root:current train perplexity3.557790756225586
INFO:root:current mean train loss 1610.5909655306675
INFO:root:current train perplexity3.5593578815460205
INFO:root:current mean train loss 1610.8347898138175
INFO:root:current train perplexity3.5607399940490723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it]
INFO:root:final mean train loss: 1610.354889670106
INFO:root:final train perplexity: 3.5609331130981445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2162.1239156520114
INFO:root:eval perplexity: 5.746544361114502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [6:02:49<1:39:18, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1615.570877972771
INFO:root:current train perplexity3.5423662662506104
INFO:root:current mean train loss 1604.5931018647693
INFO:root:current train perplexity3.5392515659332275
INFO:root:current mean train loss 1608.9386473698403
INFO:root:current train perplexity3.5428566932678223
INFO:root:current mean train loss 1612.106443653936
INFO:root:current train perplexity3.5547192096710205
INFO:root:current mean train loss 1612.3349478958
INFO:root:current train perplexity3.5520198345184326
INFO:root:current mean train loss 1611.1465387478681
INFO:root:current train perplexity3.5545647144317627
INFO:root:current mean train loss 1611.2066962876006
INFO:root:current train perplexity3.553159713745117
INFO:root:current mean train loss 1610.06711769104
INFO:root:current train perplexity3.552839994430542
INFO:root:current mean train loss 1610.8362823345694
INFO:root:current train perplexity3.5516555309295654
INFO:root:current mean train loss 1610.016024881158
INFO:root:current train perplexity3.553449869155884
INFO:root:current mean train loss 1611.0644898146725
INFO:root:current train perplexity3.554297685623169
INFO:root:current mean train loss 1609.6541135605066
INFO:root:current train perplexity3.554095983505249
INFO:root:current mean train loss 1610.0390134985892
INFO:root:current train perplexity3.5551743507385254
INFO:root:current mean train loss 1610.6970894796807
INFO:root:current train perplexity3.5573980808258057
INFO:root:current mean train loss 1610.9759556409124
INFO:root:current train perplexity3.556490659713745
INFO:root:current mean train loss 1610.1718922050632
INFO:root:current train perplexity3.557598114013672
INFO:root:current mean train loss 1609.3671558846672
INFO:root:current train perplexity3.55651593208313
INFO:root:current mean train loss 1609.6191580241623
INFO:root:current train perplexity3.5575358867645264
INFO:root:current mean train loss 1609.948486785562
INFO:root:current train perplexity3.5560688972473145
INFO:root:current mean train loss 1609.3397613153224
INFO:root:current train perplexity3.5567352771759033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it]
INFO:root:final mean train loss: 1608.9209629814852
INFO:root:final train perplexity: 3.55690860748291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2163.373288418384
INFO:root:eval perplexity: 5.752354621887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [6:05:07<1:36:59, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.2543686810661
INFO:root:current train perplexity3.587144136428833
INFO:root:current mean train loss 1600.5173174883869
INFO:root:current train perplexity3.57391357421875
INFO:root:current mean train loss 1600.3559720223411
INFO:root:current train perplexity3.5623393058776855
INFO:root:current mean train loss 1603.268058796672
INFO:root:current train perplexity3.5567281246185303
INFO:root:current mean train loss 1602.8868554184116
INFO:root:current train perplexity3.5541980266571045
INFO:root:current mean train loss 1601.6860833583735
INFO:root:current train perplexity3.5477700233459473
INFO:root:current mean train loss 1604.73697928547
INFO:root:current train perplexity3.548374891281128
INFO:root:current mean train loss 1605.5954286611764
INFO:root:current train perplexity3.549453020095825
INFO:root:current mean train loss 1606.610067007636
INFO:root:current train perplexity3.5523033142089844
INFO:root:current mean train loss 1606.5844219691862
INFO:root:current train perplexity3.5528717041015625
INFO:root:current mean train loss 1606.5376317459318
INFO:root:current train perplexity3.5520222187042236
INFO:root:current mean train loss 1607.5617287422535
INFO:root:current train perplexity3.5502841472625732
INFO:root:current mean train loss 1608.6336016346972
INFO:root:current train perplexity3.5522780418395996
INFO:root:current mean train loss 1608.0657740403599
INFO:root:current train perplexity3.5540099143981934
INFO:root:current mean train loss 1608.040633877841
INFO:root:current train perplexity3.552962303161621
INFO:root:current mean train loss 1609.5144690673058
INFO:root:current train perplexity3.5536601543426514
INFO:root:current mean train loss 1609.5763306026288
INFO:root:current train perplexity3.55448317527771
INFO:root:current mean train loss 1608.9671006488534
INFO:root:current train perplexity3.5531301498413086
INFO:root:current mean train loss 1608.812777750435
INFO:root:current train perplexity3.5539469718933105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.54s/it]
INFO:root:final mean train loss: 1608.0300082439012
INFO:root:final train perplexity: 3.554409980773926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2163.97260603668
INFO:root:eval perplexity: 5.755143165588379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [6:07:26<1:34:40, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1591.823486328125
INFO:root:current train perplexity3.6383867263793945
INFO:root:current mean train loss 1607.8055419921875
INFO:root:current train perplexity3.5534427165985107
INFO:root:current mean train loss 1604.453657395769
INFO:root:current train perplexity3.5429043769836426
INFO:root:current mean train loss 1609.757389700176
INFO:root:current train perplexity3.541853666305542
INFO:root:current mean train loss 1606.1211216864895
INFO:root:current train perplexity3.5445306301116943
INFO:root:current mean train loss 1603.6803596162226
INFO:root:current train perplexity3.5441157817840576
INFO:root:current mean train loss 1604.1935915519232
INFO:root:current train perplexity3.544517993927002
INFO:root:current mean train loss 1604.4264955873844
INFO:root:current train perplexity3.54353404045105
INFO:root:current mean train loss 1604.4779469782575
INFO:root:current train perplexity3.542851448059082
INFO:root:current mean train loss 1604.4604213401642
INFO:root:current train perplexity3.544621467590332
INFO:root:current mean train loss 1605.5011038713587
INFO:root:current train perplexity3.545880079269409
INFO:root:current mean train loss 1606.4878919985679
INFO:root:current train perplexity3.549081563949585
INFO:root:current mean train loss 1606.721949928017
INFO:root:current train perplexity3.548424005508423
INFO:root:current mean train loss 1607.4892144034718
INFO:root:current train perplexity3.5497312545776367
INFO:root:current mean train loss 1607.370341215256
INFO:root:current train perplexity3.5498223304748535
INFO:root:current mean train loss 1607.6269869340879
INFO:root:current train perplexity3.5511412620544434
INFO:root:current mean train loss 1607.3408808904642
INFO:root:current train perplexity3.5485894680023193
INFO:root:current mean train loss 1606.5279339477684
INFO:root:current train perplexity3.5480809211730957
INFO:root:current mean train loss 1607.0646822947376
INFO:root:current train perplexity3.550631523132324
INFO:root:current mean train loss 1607.1902896467946
INFO:root:current train perplexity3.552449941635132

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1607.221757497321
INFO:root:final train perplexity: 3.5521459579467773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2164.1756561495736
INFO:root:eval perplexity: 5.7560882568359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [6:09:44<1:32:20, 138.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.4035580283717
INFO:root:current train perplexity3.4882760047912598
INFO:root:current mean train loss 1601.46991120667
INFO:root:current train perplexity3.5218708515167236
INFO:root:current mean train loss 1605.3157329123858
INFO:root:current train perplexity3.5328469276428223
INFO:root:current mean train loss 1603.1536383075775
INFO:root:current train perplexity3.536738395690918
INFO:root:current mean train loss 1603.7984254969049
INFO:root:current train perplexity3.5328595638275146
INFO:root:current mean train loss 1601.3332691229377
INFO:root:current train perplexity3.5357632637023926
INFO:root:current mean train loss 1604.0085831797758
INFO:root:current train perplexity3.538898468017578
INFO:root:current mean train loss 1605.6865198721641
INFO:root:current train perplexity3.5428481101989746
INFO:root:current mean train loss 1603.9849992130266
INFO:root:current train perplexity3.5397579669952393
INFO:root:current mean train loss 1604.8202638844023
INFO:root:current train perplexity3.5406973361968994
INFO:root:current mean train loss 1603.757776441939
INFO:root:current train perplexity3.53944730758667
INFO:root:current mean train loss 1602.8910669185307
INFO:root:current train perplexity3.5376832485198975
INFO:root:current mean train loss 1603.4785816170722
INFO:root:current train perplexity3.5401148796081543
INFO:root:current mean train loss 1602.8596718927693
INFO:root:current train perplexity3.5418436527252197
INFO:root:current mean train loss 1603.6339189611413
INFO:root:current train perplexity3.542003870010376
INFO:root:current mean train loss 1603.947124026652
INFO:root:current train perplexity3.5427403450012207
INFO:root:current mean train loss 1605.0623222101317
INFO:root:current train perplexity3.543051242828369
INFO:root:current mean train loss 1605.0109055870282
INFO:root:current train perplexity3.545074224472046
INFO:root:current mean train loss 1605.190758653235
INFO:root:current train perplexity3.545330286026001
INFO:root:current mean train loss 1605.70346576637
INFO:root:current train perplexity3.545814275741577

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1605.3436423035746
INFO:root:final train perplexity: 3.5468881130218506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2164.430690034907
INFO:root:eval perplexity: 5.75727653503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [6:12:03<1:30:02, 138.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1599.2134195963542
INFO:root:current train perplexity3.5194859504699707
INFO:root:current mean train loss 1609.6440339929918
INFO:root:current train perplexity3.4909729957580566
INFO:root:current mean train loss 1599.9712053719213
INFO:root:current train perplexity3.5069034099578857
INFO:root:current mean train loss 1598.9669654482886
INFO:root:current train perplexity3.5128962993621826
INFO:root:current mean train loss 1601.1095903029136
INFO:root:current train perplexity3.520529270172119
INFO:root:current mean train loss 1598.8824419619432
INFO:root:current train perplexity3.5192930698394775
INFO:root:current mean train loss 1600.715582889581
INFO:root:current train perplexity3.5217385292053223
INFO:root:current mean train loss 1602.1903046317723
INFO:root:current train perplexity3.524237871170044
INFO:root:current mean train loss 1602.0691637833152
INFO:root:current train perplexity3.52476167678833
INFO:root:current mean train loss 1601.776595808502
INFO:root:current train perplexity3.528198719024658
INFO:root:current mean train loss 1602.7152806580298
INFO:root:current train perplexity3.5297436714172363
INFO:root:current mean train loss 1603.2771445260921
INFO:root:current train perplexity3.5335006713867188
INFO:root:current mean train loss 1602.9517540792817
INFO:root:current train perplexity3.533798933029175
INFO:root:current mean train loss 1602.6374326237662
INFO:root:current train perplexity3.53602933883667
INFO:root:current mean train loss 1603.3079754927696
INFO:root:current train perplexity3.536176919937134
INFO:root:current mean train loss 1603.6348528067272
INFO:root:current train perplexity3.539367198944092
INFO:root:current mean train loss 1603.800757149321
INFO:root:current train perplexity3.5395305156707764
INFO:root:current mean train loss 1603.8348174908194
INFO:root:current train perplexity3.541206121444702
INFO:root:current mean train loss 1603.791605232588
INFO:root:current train perplexity3.542271614074707
INFO:root:current mean train loss 1604.098142828823
INFO:root:current train perplexity3.5432746410369873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it]
INFO:root:final mean train loss: 1604.0289798492263
INFO:root:final train perplexity: 3.5432121753692627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2166.0070900342143
INFO:root:eval perplexity: 5.764620780944824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [6:14:21<1:27:43, 138.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.4002800707547
INFO:root:current train perplexity3.544846773147583
INFO:root:current mean train loss 1594.5636903850082
INFO:root:current train perplexity3.5242197513580322
INFO:root:current mean train loss 1602.2750610834055
INFO:root:current train perplexity3.5315608978271484
INFO:root:current mean train loss 1600.154416870463
INFO:root:current train perplexity3.529890537261963
INFO:root:current mean train loss 1598.9416646725822
INFO:root:current train perplexity3.5254955291748047
INFO:root:current mean train loss 1598.2960483213014
INFO:root:current train perplexity3.5267858505249023
INFO:root:current mean train loss 1600.2970181942717
INFO:root:current train perplexity3.528688907623291
INFO:root:current mean train loss 1601.3538155321423
INFO:root:current train perplexity3.5313925743103027
INFO:root:current mean train loss 1603.2706180049274
INFO:root:current train perplexity3.5324902534484863
INFO:root:current mean train loss 1602.8582025870196
INFO:root:current train perplexity3.5333611965179443
INFO:root:current mean train loss 1602.1615379746484
INFO:root:current train perplexity3.5354552268981934
INFO:root:current mean train loss 1602.5163311656413
INFO:root:current train perplexity3.537688732147217
INFO:root:current mean train loss 1603.838858906593
INFO:root:current train perplexity3.539119243621826
INFO:root:current mean train loss 1603.6946362864064
INFO:root:current train perplexity3.5388870239257812
INFO:root:current mean train loss 1603.62337250785
INFO:root:current train perplexity3.5393736362457275
INFO:root:current mean train loss 1603.2245449992204
INFO:root:current train perplexity3.5398638248443604
INFO:root:current mean train loss 1604.4624687328674
INFO:root:current train perplexity3.5417726039886475
INFO:root:current mean train loss 1604.479930052945
INFO:root:current train perplexity3.5417957305908203
INFO:root:current mean train loss 1604.7415079115792
INFO:root:current train perplexity3.542328357696533
INFO:root:current mean train loss 1604.6096162029369
INFO:root:current train perplexity3.543015718460083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.59s/it]
INFO:root:final mean train loss: 1604.1105139843455
INFO:root:final train perplexity: 3.5434398651123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2165.9398375166224
INFO:root:eval perplexity: 5.764307498931885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [6:16:40<1:25:24, 138.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.631476702009
INFO:root:current train perplexity3.5318868160247803
INFO:root:current mean train loss 1595.2931935029872
INFO:root:current train perplexity3.514772891998291
INFO:root:current mean train loss 1598.2394373010707
INFO:root:current train perplexity3.5227503776550293
INFO:root:current mean train loss 1601.4315782701647
INFO:root:current train perplexity3.5274128913879395
INFO:root:current mean train loss 1597.5006025598404
INFO:root:current train perplexity3.517261505126953
INFO:root:current mean train loss 1598.4454240765488
INFO:root:current train perplexity3.527242422103882
INFO:root:current mean train loss 1601.2936388613573
INFO:root:current train perplexity3.531604766845703
INFO:root:current mean train loss 1600.5468870484983
INFO:root:current train perplexity3.529656410217285
INFO:root:current mean train loss 1601.5754046560703
INFO:root:current train perplexity3.533735990524292
INFO:root:current mean train loss 1601.8078055784874
INFO:root:current train perplexity3.5330605506896973
INFO:root:current mean train loss 1601.933512750073
INFO:root:current train perplexity3.534470319747925
INFO:root:current mean train loss 1602.352198308961
INFO:root:current train perplexity3.536146402359009
INFO:root:current mean train loss 1602.413292591966
INFO:root:current train perplexity3.5347018241882324
INFO:root:current mean train loss 1602.5706789782448
INFO:root:current train perplexity3.5363500118255615
INFO:root:current mean train loss 1601.6047717036033
INFO:root:current train perplexity3.5345730781555176
INFO:root:current mean train loss 1601.5546155018412
INFO:root:current train perplexity3.535083055496216
INFO:root:current mean train loss 1601.770278948938
INFO:root:current train perplexity3.5354902744293213
INFO:root:current mean train loss 1602.012694278006
INFO:root:current train perplexity3.5366203784942627
INFO:root:current mean train loss 1602.7193322166402
INFO:root:current train perplexity3.5388832092285156
INFO:root:current mean train loss 1603.0335163561826
INFO:root:current train perplexity3.5391764640808105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it]
INFO:root:final mean train loss: 1602.6499660566967
INFO:root:final train perplexity: 3.539361000061035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2166.562643713985
INFO:root:eval perplexity: 5.767211437225342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [6:18:58<1:23:08, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1603.1114501953125
INFO:root:current train perplexity3.528637170791626
INFO:root:current mean train loss 1601.8529209402157
INFO:root:current train perplexity3.5177695751190186
INFO:root:current mean train loss 1602.0954007138773
INFO:root:current train perplexity3.514422655105591
INFO:root:current mean train loss 1599.8819327736394
INFO:root:current train perplexity3.5231213569641113
INFO:root:current mean train loss 1600.1591205322768
INFO:root:current train perplexity3.5238726139068604
INFO:root:current mean train loss 1602.4204480042856
INFO:root:current train perplexity3.5285634994506836
INFO:root:current mean train loss 1601.4078262529
INFO:root:current train perplexity3.5275375843048096
INFO:root:current mean train loss 1601.0130743974348
INFO:root:current train perplexity3.530690908432007
INFO:root:current mean train loss 1601.1563711069616
INFO:root:current train perplexity3.529231071472168
INFO:root:current mean train loss 1600.4618963765276
INFO:root:current train perplexity3.5290303230285645
INFO:root:current mean train loss 1600.9641669167218
INFO:root:current train perplexity3.533651351928711
INFO:root:current mean train loss 1601.2635981391836
INFO:root:current train perplexity3.5331320762634277
INFO:root:current mean train loss 1601.7843391282113
INFO:root:current train perplexity3.5355677604675293
INFO:root:current mean train loss 1602.5020823241484
INFO:root:current train perplexity3.5366055965423584
INFO:root:current mean train loss 1602.3664103381652
INFO:root:current train perplexity3.5374910831451416
INFO:root:current mean train loss 1602.8381064594655
INFO:root:current train perplexity3.5383074283599854
INFO:root:current mean train loss 1602.845081195933
INFO:root:current train perplexity3.538224935531616
INFO:root:current mean train loss 1602.9726229829366
INFO:root:current train perplexity3.537429094314575
INFO:root:current mean train loss 1603.3878688114814
INFO:root:current train perplexity3.5376079082489014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1602.1589098770212
INFO:root:final train perplexity: 3.5379908084869385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2167.040011791473
INFO:root:eval perplexity: 5.76943826675415
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [6:21:17<1:20:49, 138.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1589.3573608398438
INFO:root:current train perplexity3.5329954624176025
INFO:root:current mean train loss 1607.6007760854868
INFO:root:current train perplexity3.5342495441436768
INFO:root:current mean train loss 1600.7389699898515
INFO:root:current train perplexity3.5211989879608154
INFO:root:current mean train loss 1597.4316313894171
INFO:root:current train perplexity3.523510694503784
INFO:root:current mean train loss 1596.336359005163
INFO:root:current train perplexity3.5221028327941895
INFO:root:current mean train loss 1594.808389330667
INFO:root:current train perplexity3.520329475402832
INFO:root:current mean train loss 1594.531106708855
INFO:root:current train perplexity3.5232064723968506
INFO:root:current mean train loss 1594.5360615470192
INFO:root:current train perplexity3.525069236755371
INFO:root:current mean train loss 1597.7240210386058
INFO:root:current train perplexity3.5277724266052246
INFO:root:current mean train loss 1598.1717384810997
INFO:root:current train perplexity3.52652907371521
INFO:root:current mean train loss 1598.890037506225
INFO:root:current train perplexity3.5247180461883545
INFO:root:current mean train loss 1599.1196689329286
INFO:root:current train perplexity3.527078866958618
INFO:root:current mean train loss 1600.2143811197375
INFO:root:current train perplexity3.5285584926605225
INFO:root:current mean train loss 1599.9737654609914
INFO:root:current train perplexity3.526822566986084
INFO:root:current mean train loss 1600.2104509576434
INFO:root:current train perplexity3.5271053314208984
INFO:root:current mean train loss 1600.6352956244286
INFO:root:current train perplexity3.5282182693481445
INFO:root:current mean train loss 1601.248485003921
INFO:root:current train perplexity3.530531883239746
INFO:root:current mean train loss 1600.6360828954848
INFO:root:current train perplexity3.531075954437256
INFO:root:current mean train loss 1601.1050020543541
INFO:root:current train perplexity3.5323386192321777
INFO:root:current mean train loss 1601.1710314710601
INFO:root:current train perplexity3.5333728790283203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.53s/it]
INFO:root:final mean train loss: 1600.8443522258533
INFO:root:final train perplexity: 3.5343246459960938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2167.761267262993
INFO:root:eval perplexity: 5.772803783416748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [6:23:35<1:18:30, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.3698207310267
INFO:root:current train perplexity3.5747265815734863
INFO:root:current mean train loss 1601.9526357099044
INFO:root:current train perplexity3.5272796154022217
INFO:root:current mean train loss 1600.6830264820771
INFO:root:current train perplexity3.528855085372925
INFO:root:current mean train loss 1599.9737309250877
INFO:root:current train perplexity3.525545120239258
INFO:root:current mean train loss 1598.5155316350579
INFO:root:current train perplexity3.5217268466949463
INFO:root:current mean train loss 1598.1327942245982
INFO:root:current train perplexity3.5186240673065186
INFO:root:current mean train loss 1598.4520220426355
INFO:root:current train perplexity3.5179452896118164
INFO:root:current mean train loss 1599.5687917849557
INFO:root:current train perplexity3.524125099182129
INFO:root:current mean train loss 1599.750505082645
INFO:root:current train perplexity3.5241310596466064
INFO:root:current mean train loss 1599.2886447305918
INFO:root:current train perplexity3.5255839824676514
INFO:root:current mean train loss 1598.939694515755
INFO:root:current train perplexity3.524803400039673
INFO:root:current mean train loss 1600.1336186431965
INFO:root:current train perplexity3.526707649230957
INFO:root:current mean train loss 1599.5144017974828
INFO:root:current train perplexity3.5277206897735596
INFO:root:current mean train loss 1598.7199706107176
INFO:root:current train perplexity3.527127265930176
INFO:root:current mean train loss 1599.8000536387776
INFO:root:current train perplexity3.5290603637695312
INFO:root:current mean train loss 1600.4530863163113
INFO:root:current train perplexity3.529611110687256
INFO:root:current mean train loss 1600.71367011285
INFO:root:current train perplexity3.530952215194702
INFO:root:current mean train loss 1601.4223263267859
INFO:root:current train perplexity3.5342609882354736
INFO:root:current mean train loss 1601.3960632625876
INFO:root:current train perplexity3.5336062908172607
INFO:root:current mean train loss 1601.4639400102892
INFO:root:current train perplexity3.5336673259735107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.70s/it]
INFO:root:final mean train loss: 1600.8310455460771
INFO:root:final train perplexity: 3.534287452697754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2167.155766480358
INFO:root:eval perplexity: 5.76997709274292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [6:25:54<1:16:12, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1592.2294215152137
INFO:root:current train perplexity3.5396127700805664
INFO:root:current mean train loss 1595.36181640625
INFO:root:current train perplexity3.5144097805023193
INFO:root:current mean train loss 1597.9775421399029
INFO:root:current train perplexity3.5268964767456055
INFO:root:current mean train loss 1597.1151740621533
INFO:root:current train perplexity3.528156280517578
INFO:root:current mean train loss 1597.4835637062108
INFO:root:current train perplexity3.5241003036499023
INFO:root:current mean train loss 1594.795764114777
INFO:root:current train perplexity3.5194952487945557
INFO:root:current mean train loss 1594.5216005139964
INFO:root:current train perplexity3.5239903926849365
INFO:root:current mean train loss 1595.6662943356728
INFO:root:current train perplexity3.5275931358337402
INFO:root:current mean train loss 1597.0420468132365
INFO:root:current train perplexity3.5278475284576416
INFO:root:current mean train loss 1597.0133067051738
INFO:root:current train perplexity3.527050256729126
INFO:root:current mean train loss 1597.4931461870785
INFO:root:current train perplexity3.5283544063568115
INFO:root:current mean train loss 1598.8055943386835
INFO:root:current train perplexity3.526829957962036
INFO:root:current mean train loss 1599.3595872919086
INFO:root:current train perplexity3.5259816646575928
INFO:root:current mean train loss 1600.153475500543
INFO:root:current train perplexity3.526867151260376
INFO:root:current mean train loss 1600.2468704839077
INFO:root:current train perplexity3.5293636322021484
INFO:root:current mean train loss 1599.6881260667262
INFO:root:current train perplexity3.5279741287231445
INFO:root:current mean train loss 1599.3181954967233
INFO:root:current train perplexity3.5264570713043213
INFO:root:current mean train loss 1599.6310294867933
INFO:root:current train perplexity3.5283868312835693
INFO:root:current mean train loss 1599.0367634869763
INFO:root:current train perplexity3.52898907661438
INFO:root:current mean train loss 1599.8210281041383
INFO:root:current train perplexity3.529998540878296

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1599.4683086262528
INFO:root:final train perplexity: 3.5304906368255615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2168.267920527898
INFO:root:eval perplexity: 5.775170803070068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [6:28:12<1:13:53, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1577.255095880682
INFO:root:current train perplexity3.4900429248809814
INFO:root:current mean train loss 1581.7718568863406
INFO:root:current train perplexity3.517388105392456
INFO:root:current mean train loss 1587.4021230660233
INFO:root:current train perplexity3.5118417739868164
INFO:root:current mean train loss 1589.4949641697842
INFO:root:current train perplexity3.5130972862243652
INFO:root:current mean train loss 1590.4606984568165
INFO:root:current train perplexity3.518178939819336
INFO:root:current mean train loss 1590.6487830359656
INFO:root:current train perplexity3.522014856338501
INFO:root:current mean train loss 1591.879551265804
INFO:root:current train perplexity3.5260422229766846
INFO:root:current mean train loss 1592.725261764021
INFO:root:current train perplexity3.524151563644409
INFO:root:current mean train loss 1594.0900664747808
INFO:root:current train perplexity3.5247645378112793
INFO:root:current mean train loss 1593.650605366492
INFO:root:current train perplexity3.5246567726135254
INFO:root:current mean train loss 1594.2910070627222
INFO:root:current train perplexity3.5253264904022217
INFO:root:current mean train loss 1592.7219004709484
INFO:root:current train perplexity3.523512601852417
INFO:root:current mean train loss 1593.132615533958
INFO:root:current train perplexity3.5229036808013916
INFO:root:current mean train loss 1593.7805882077375
INFO:root:current train perplexity3.522557258605957
INFO:root:current mean train loss 1594.5707825755746
INFO:root:current train perplexity3.5240437984466553
INFO:root:current mean train loss 1594.5493877643942
INFO:root:current train perplexity3.52287220954895
INFO:root:current mean train loss 1595.2168101515294
INFO:root:current train perplexity3.5238723754882812
INFO:root:current mean train loss 1596.6767473095842
INFO:root:current train perplexity3.5243725776672363
INFO:root:current mean train loss 1598.132813289673
INFO:root:current train perplexity3.5267279148101807
INFO:root:current mean train loss 1598.4081350653373
INFO:root:current train perplexity3.526313304901123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.43s/it]
INFO:root:final mean train loss: 1598.0131367170263
INFO:root:final train perplexity: 3.5264415740966797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2168.985435107076
INFO:root:eval perplexity: 5.778522491455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [6:30:31<1:11:33, 138.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1585.0433044433594
INFO:root:current train perplexity3.535902738571167
INFO:root:current mean train loss 1590.359601397847
INFO:root:current train perplexity3.5325756072998047
INFO:root:current mean train loss 1594.0448621862074
INFO:root:current train perplexity3.540116548538208
INFO:root:current mean train loss 1593.9224669753864
INFO:root:current train perplexity3.5377352237701416
INFO:root:current mean train loss 1595.473090220306
INFO:root:current train perplexity3.5331227779388428
INFO:root:current mean train loss 1596.8144844962167
INFO:root:current train perplexity3.5343053340911865
INFO:root:current mean train loss 1598.443812779018
INFO:root:current train perplexity3.531497001647949
INFO:root:current mean train loss 1599.2712957352555
INFO:root:current train perplexity3.531864881515503
INFO:root:current mean train loss 1599.6905015018008
INFO:root:current train perplexity3.5309956073760986
INFO:root:current mean train loss 1599.7998092086227
INFO:root:current train perplexity3.5284605026245117
INFO:root:current mean train loss 1600.0725194447077
INFO:root:current train perplexity3.5292201042175293
INFO:root:current mean train loss 1599.7538525057328
INFO:root:current train perplexity3.5281825065612793
INFO:root:current mean train loss 1600.353381078948
INFO:root:current train perplexity3.5277955532073975
INFO:root:current mean train loss 1599.4752977554722
INFO:root:current train perplexity3.5270235538482666
INFO:root:current mean train loss 1598.4673464401908
INFO:root:current train perplexity3.5265276432037354
INFO:root:current mean train loss 1597.616099272672
INFO:root:current train perplexity3.524608850479126
INFO:root:current mean train loss 1597.634567114725
INFO:root:current train perplexity3.5236117839813232
INFO:root:current mean train loss 1597.9494282397407
INFO:root:current train perplexity3.5256307125091553
INFO:root:current mean train loss 1597.967072706956
INFO:root:current train perplexity3.5247485637664795
INFO:root:current mean train loss 1598.0960378279308
INFO:root:current train perplexity3.5254554748535156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.64s/it]
INFO:root:final mean train loss: 1597.5878048125867
INFO:root:final train perplexity: 3.525258779525757
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2168.7330672893117
INFO:root:eval perplexity: 5.777343273162842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [6:32:49<1:09:15, 138.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.600396659937
INFO:root:current train perplexity3.505732297897339
INFO:root:current mean train loss 1602.7507266090029
INFO:root:current train perplexity3.5110416412353516
INFO:root:current mean train loss 1597.0110226535467
INFO:root:current train perplexity3.5061745643615723
INFO:root:current mean train loss 1596.5095014008275
INFO:root:current train perplexity3.51322603225708
INFO:root:current mean train loss 1597.111391781298
INFO:root:current train perplexity3.509918212890625
INFO:root:current mean train loss 1596.8043702000875
INFO:root:current train perplexity3.5127615928649902
INFO:root:current mean train loss 1596.1269681844726
INFO:root:current train perplexity3.5144917964935303
INFO:root:current mean train loss 1596.2232266850344
INFO:root:current train perplexity3.5143158435821533
INFO:root:current mean train loss 1596.8582462958732
INFO:root:current train perplexity3.5174267292022705
INFO:root:current mean train loss 1597.9101899458497
INFO:root:current train perplexity3.518150806427002
INFO:root:current mean train loss 1597.328025012196
INFO:root:current train perplexity3.5188698768615723
INFO:root:current mean train loss 1597.8475758622333
INFO:root:current train perplexity3.5203967094421387
INFO:root:current mean train loss 1597.6296154699926
INFO:root:current train perplexity3.521728515625
INFO:root:current mean train loss 1597.0819687647645
INFO:root:current train perplexity3.521573543548584
INFO:root:current mean train loss 1596.9515825198591
INFO:root:current train perplexity3.5221378803253174
INFO:root:current mean train loss 1596.1349230334772
INFO:root:current train perplexity3.5223405361175537
INFO:root:current mean train loss 1596.5875097424973
INFO:root:current train perplexity3.5241549015045166
INFO:root:current mean train loss 1596.654602153132
INFO:root:current train perplexity3.5236220359802246
INFO:root:current mean train loss 1596.8822303881022
INFO:root:current train perplexity3.5232388973236084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.42s/it]
INFO:root:final mean train loss: 1596.7033716952988
INFO:root:final train perplexity: 3.522800922393799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2169.864624456311
INFO:root:eval perplexity: 5.782633304595947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [6:35:08<1:06:55, 138.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.5762736002605
INFO:root:current train perplexity3.5179712772369385
INFO:root:current mean train loss 1590.777037422612
INFO:root:current train perplexity3.495265007019043
INFO:root:current mean train loss 1596.548320288797
INFO:root:current train perplexity3.503007173538208
INFO:root:current mean train loss 1594.6859098945567
INFO:root:current train perplexity3.507972240447998
INFO:root:current mean train loss 1595.446129709629
INFO:root:current train perplexity3.518141269683838
INFO:root:current mean train loss 1594.5699219232492
INFO:root:current train perplexity3.5172128677368164
INFO:root:current mean train loss 1593.770133544116
INFO:root:current train perplexity3.5175657272338867
INFO:root:current mean train loss 1594.3357189491855
INFO:root:current train perplexity3.5200772285461426
INFO:root:current mean train loss 1594.8341815655049
INFO:root:current train perplexity3.5198962688446045
INFO:root:current mean train loss 1596.3828216620102
INFO:root:current train perplexity3.5208256244659424
INFO:root:current mean train loss 1596.4373429831169
INFO:root:current train perplexity3.519179344177246
INFO:root:current mean train loss 1596.0550839525881
INFO:root:current train perplexity3.51820707321167
INFO:root:current mean train loss 1595.8033921983506
INFO:root:current train perplexity3.520085573196411
INFO:root:current mean train loss 1595.6597639612546
INFO:root:current train perplexity3.517014503479004
INFO:root:current mean train loss 1595.7891373396938
INFO:root:current train perplexity3.5172290802001953
INFO:root:current mean train loss 1595.2533904097154
INFO:root:current train perplexity3.5166845321655273
INFO:root:current mean train loss 1595.9773909211308
INFO:root:current train perplexity3.517428398132324
INFO:root:current mean train loss 1595.991329931011
INFO:root:current train perplexity3.517942428588867
INFO:root:current mean train loss 1596.425096074608
INFO:root:current train perplexity3.5196547508239746
INFO:root:current mean train loss 1596.2738091547867
INFO:root:current train perplexity3.5211780071258545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it]
INFO:root:final mean train loss: 1595.6635999809416
INFO:root:final train perplexity: 3.519913673400879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2170.338962852532
INFO:root:eval perplexity: 5.784852504730225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [6:37:26<1:04:37, 138.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.783590565557
INFO:root:current train perplexity3.483823776245117
INFO:root:current mean train loss 1587.2920596735264
INFO:root:current train perplexity3.515194892883301
INFO:root:current mean train loss 1586.9060075015766
INFO:root:current train perplexity3.5037403106689453
INFO:root:current mean train loss 1589.7758826855165
INFO:root:current train perplexity3.5031280517578125
INFO:root:current mean train loss 1591.1989731664635
INFO:root:current train perplexity3.504333257675171
INFO:root:current mean train loss 1592.593262652366
INFO:root:current train perplexity3.5033371448516846
INFO:root:current mean train loss 1591.9049611099267
INFO:root:current train perplexity3.5037081241607666
INFO:root:current mean train loss 1593.6175432429438
INFO:root:current train perplexity3.5102431774139404
INFO:root:current mean train loss 1594.84417212893
INFO:root:current train perplexity3.513866901397705
INFO:root:current mean train loss 1595.4985356852656
INFO:root:current train perplexity3.5147457122802734
INFO:root:current mean train loss 1595.696454925388
INFO:root:current train perplexity3.513207197189331
INFO:root:current mean train loss 1595.0964664177288
INFO:root:current train perplexity3.5128729343414307
INFO:root:current mean train loss 1594.6194397621437
INFO:root:current train perplexity3.5141985416412354
INFO:root:current mean train loss 1593.5330208038076
INFO:root:current train perplexity3.511230945587158
INFO:root:current mean train loss 1593.4289973695263
INFO:root:current train perplexity3.5108232498168945
INFO:root:current mean train loss 1593.6653907660661
INFO:root:current train perplexity3.513638973236084
INFO:root:current mean train loss 1593.5273502182974
INFO:root:current train perplexity3.51242733001709
INFO:root:current mean train loss 1594.1337069502003
INFO:root:current train perplexity3.5135178565979004
INFO:root:current mean train loss 1594.0772660214104
INFO:root:current train perplexity3.5149004459381104
INFO:root:current mean train loss 1594.513577672013
INFO:root:current train perplexity3.5153398513793945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.55s/it]
INFO:root:final mean train loss: 1594.6050446126055
INFO:root:final train perplexity: 3.5169758796691895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2170.6432161804632
INFO:root:eval perplexity: 5.786276340484619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [6:39:45<1:02:19, 138.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1591.3395080566406
INFO:root:current train perplexity3.5182926654815674
INFO:root:current mean train loss 1588.6656546456472
INFO:root:current train perplexity3.5129072666168213
INFO:root:current mean train loss 1590.014756266276
INFO:root:current train perplexity3.5083096027374268
INFO:root:current mean train loss 1593.226045855354
INFO:root:current train perplexity3.510073661804199
INFO:root:current mean train loss 1593.3785830411043
INFO:root:current train perplexity3.515326976776123
INFO:root:current mean train loss 1590.8490042227286
INFO:root:current train perplexity3.518035888671875
INFO:root:current mean train loss 1591.2065057754517
INFO:root:current train perplexity3.5179994106292725
INFO:root:current mean train loss 1591.3991677773965
INFO:root:current train perplexity3.5161337852478027
INFO:root:current mean train loss 1592.0532957531157
INFO:root:current train perplexity3.5173091888427734
INFO:root:current mean train loss 1592.980532122673
INFO:root:current train perplexity3.518721342086792
INFO:root:current mean train loss 1592.7509932297926
INFO:root:current train perplexity3.517224073410034
INFO:root:current mean train loss 1593.3011136239036
INFO:root:current train perplexity3.5168089866638184
INFO:root:current mean train loss 1594.1282081850113
INFO:root:current train perplexity3.5164430141448975
INFO:root:current mean train loss 1594.047495098968
INFO:root:current train perplexity3.5160958766937256
INFO:root:current mean train loss 1594.6317707485623
INFO:root:current train perplexity3.5158307552337646
INFO:root:current mean train loss 1594.1359962364295
INFO:root:current train perplexity3.515364170074463
INFO:root:current mean train loss 1594.6180507752954
INFO:root:current train perplexity3.5158729553222656
INFO:root:current mean train loss 1594.7671322175827
INFO:root:current train perplexity3.5154709815979004
INFO:root:current mean train loss 1594.6493174013883
INFO:root:current train perplexity3.516101360321045
INFO:root:current mean train loss 1594.5111088388974
INFO:root:current train perplexity3.5158746242523193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.76s/it]
INFO:root:final mean train loss: 1594.1939053980318
INFO:root:final train perplexity: 3.515835762023926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2170.8991599657857
INFO:root:eval perplexity: 5.787473201751709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [6:42:03<1:00:02, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.2875398334704
INFO:root:current train perplexity3.5153353214263916
INFO:root:current mean train loss 1595.1579613169288
INFO:root:current train perplexity3.5189054012298584
INFO:root:current mean train loss 1589.1406226250913
INFO:root:current train perplexity3.5186989307403564
INFO:root:current mean train loss 1589.1249613614978
INFO:root:current train perplexity3.515699863433838
INFO:root:current mean train loss 1593.7557399758102
INFO:root:current train perplexity3.51782488822937
INFO:root:current mean train loss 1593.607036378268
INFO:root:current train perplexity3.5120785236358643
INFO:root:current mean train loss 1592.4048113539884
INFO:root:current train perplexity3.51090145111084
INFO:root:current mean train loss 1592.3543788249774
INFO:root:current train perplexity3.511399507522583
INFO:root:current mean train loss 1592.8709226806357
INFO:root:current train perplexity3.5113816261291504
INFO:root:current mean train loss 1593.3624817340974
INFO:root:current train perplexity3.5109517574310303
INFO:root:current mean train loss 1593.5092075892858
INFO:root:current train perplexity3.511918306350708
INFO:root:current mean train loss 1593.555282447703
INFO:root:current train perplexity3.512040853500366
INFO:root:current mean train loss 1593.5023025354888
INFO:root:current train perplexity3.5127146244049072
INFO:root:current mean train loss 1593.4858241914035
INFO:root:current train perplexity3.512815237045288
INFO:root:current mean train loss 1593.31145197149
INFO:root:current train perplexity3.5129714012145996
INFO:root:current mean train loss 1592.9607088827674
INFO:root:current train perplexity3.5121729373931885
INFO:root:current mean train loss 1593.4313447684067
INFO:root:current train perplexity3.5130085945129395
INFO:root:current mean train loss 1593.6423266893364
INFO:root:current train perplexity3.513725996017456
INFO:root:current mean train loss 1593.6814254736091
INFO:root:current train perplexity3.5127506256103516
INFO:root:current mean train loss 1593.2781102916813
INFO:root:current train perplexity3.513185739517212

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it]
INFO:root:final mean train loss: 1593.3584728000503
INFO:root:final train perplexity: 3.5135200023651123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2171.1210643146055
INFO:root:eval perplexity: 5.788511753082275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [6:44:22<57:43, 138.55s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1581.0267300992398
INFO:root:current train perplexity3.5111424922943115
INFO:root:current mean train loss 1589.6627800601652
INFO:root:current train perplexity3.505812168121338
INFO:root:current mean train loss 1588.42703714858
INFO:root:current train perplexity3.50034499168396
INFO:root:current mean train loss 1590.8093591373872
INFO:root:current train perplexity3.5076234340667725
INFO:root:current mean train loss 1590.609652877357
INFO:root:current train perplexity3.5043487548828125
INFO:root:current mean train loss 1590.6173301989193
INFO:root:current train perplexity3.5088706016540527
INFO:root:current mean train loss 1590.2019405195197
INFO:root:current train perplexity3.5084095001220703
INFO:root:current mean train loss 1591.6243300327035
INFO:root:current train perplexity3.5106818675994873
INFO:root:current mean train loss 1591.8871626166513
INFO:root:current train perplexity3.512197494506836
INFO:root:current mean train loss 1592.7500490035854
INFO:root:current train perplexity3.513188600540161
INFO:root:current mean train loss 1593.9998245097183
INFO:root:current train perplexity3.512685775756836
INFO:root:current mean train loss 1593.9723071954522
INFO:root:current train perplexity3.5117571353912354
INFO:root:current mean train loss 1593.0115105405894
INFO:root:current train perplexity3.511482000350952
INFO:root:current mean train loss 1594.0079418554403
INFO:root:current train perplexity3.5120551586151123
INFO:root:current mean train loss 1593.949099661052
INFO:root:current train perplexity3.5129237174987793
INFO:root:current mean train loss 1594.1622768920743
INFO:root:current train perplexity3.513932943344116
INFO:root:current mean train loss 1594.0939393767035
INFO:root:current train perplexity3.5145742893218994
INFO:root:current mean train loss 1593.9152752210753
INFO:root:current train perplexity3.513230562210083
INFO:root:current mean train loss 1593.8863055087713
INFO:root:current train perplexity3.512934923171997
INFO:root:current mean train loss 1593.9511009455935
INFO:root:current train perplexity3.5137054920196533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it]
INFO:root:final mean train loss: 1593.4662542376805
INFO:root:final train perplexity: 3.5138182640075684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2172.1123367201353
INFO:root:eval perplexity: 5.793153285980225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [6:46:40<55:24, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1575.3184452266485
INFO:root:current train perplexity3.520705461502075
INFO:root:current mean train loss 1580.5798058634653
INFO:root:current train perplexity3.529967784881592
INFO:root:current mean train loss 1586.0042154108946
INFO:root:current train perplexity3.514688730239868
INFO:root:current mean train loss 1584.933432030251
INFO:root:current train perplexity3.509300947189331
INFO:root:current mean train loss 1586.2437788891452
INFO:root:current train perplexity3.508676767349243
INFO:root:current mean train loss 1587.0110040913178
INFO:root:current train perplexity3.5080528259277344
INFO:root:current mean train loss 1589.8426621432932
INFO:root:current train perplexity3.5062429904937744
INFO:root:current mean train loss 1589.0266127170414
INFO:root:current train perplexity3.5056989192962646
INFO:root:current mean train loss 1589.431294005594
INFO:root:current train perplexity3.5071635246276855
INFO:root:current mean train loss 1588.432747880337
INFO:root:current train perplexity3.506096363067627
INFO:root:current mean train loss 1589.9887153772343
INFO:root:current train perplexity3.504134178161621
INFO:root:current mean train loss 1589.96440845813
INFO:root:current train perplexity3.5059971809387207
INFO:root:current mean train loss 1590.6076177926511
INFO:root:current train perplexity3.5079691410064697
INFO:root:current mean train loss 1590.210505120108
INFO:root:current train perplexity3.5079708099365234
INFO:root:current mean train loss 1590.9528391868137
INFO:root:current train perplexity3.506981611251831
INFO:root:current mean train loss 1590.594109152189
INFO:root:current train perplexity3.506675958633423
INFO:root:current mean train loss 1591.047433592595
INFO:root:current train perplexity3.507460355758667
INFO:root:current mean train loss 1591.5716022468025
INFO:root:current train perplexity3.507977247238159
INFO:root:current mean train loss 1592.1684183638163
INFO:root:current train perplexity3.508857488632202

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.67s/it]
INFO:root:final mean train loss: 1591.8382220862193
INFO:root:final train perplexity: 3.509309768676758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2171.8218717101618
INFO:root:eval perplexity: 5.791793346405029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [6:48:59<53:06, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.1665496826172
INFO:root:current train perplexity3.5210416316986084
INFO:root:current mean train loss 1578.3253377278645
INFO:root:current train perplexity3.4983103275299072
INFO:root:current mean train loss 1586.0531469491812
INFO:root:current train perplexity3.4985713958740234
INFO:root:current mean train loss 1591.789345084847
INFO:root:current train perplexity3.5015339851379395
INFO:root:current mean train loss 1590.045093311983
INFO:root:current train perplexity3.503722667694092
INFO:root:current mean train loss 1589.7888940525806
INFO:root:current train perplexity3.502915859222412
INFO:root:current mean train loss 1589.4094641836066
INFO:root:current train perplexity3.5061798095703125
INFO:root:current mean train loss 1589.5557821672514
INFO:root:current train perplexity3.5068788528442383
INFO:root:current mean train loss 1589.8618028093092
INFO:root:current train perplexity3.50677752494812
INFO:root:current mean train loss 1590.4278713680048
INFO:root:current train perplexity3.505044937133789
INFO:root:current mean train loss 1591.4386239430262
INFO:root:current train perplexity3.507746458053589
INFO:root:current mean train loss 1591.1053185858882
INFO:root:current train perplexity3.5073294639587402
INFO:root:current mean train loss 1590.635163970341
INFO:root:current train perplexity3.506072998046875
INFO:root:current mean train loss 1590.1327532380365
INFO:root:current train perplexity3.504579544067383
INFO:root:current mean train loss 1590.0014799291437
INFO:root:current train perplexity3.506571054458618
INFO:root:current mean train loss 1591.2982179353344
INFO:root:current train perplexity3.507662773132324
INFO:root:current mean train loss 1592.0766171887146
INFO:root:current train perplexity3.508627414703369
INFO:root:current mean train loss 1592.304215013562
INFO:root:current train perplexity3.5086052417755127
INFO:root:current mean train loss 1591.8780597247908
INFO:root:current train perplexity3.507117509841919
INFO:root:current mean train loss 1591.4376305154285
INFO:root:current train perplexity3.506896734237671

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it]
INFO:root:final mean train loss: 1591.0591971146837
INFO:root:final train perplexity: 3.5071542263031006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2172.869862657912
INFO:root:eval perplexity: 5.796703815460205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [6:51:18<50:49, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1580.393203125
INFO:root:current train perplexity3.4615120887756348
INFO:root:current mean train loss 1581.958716796875
INFO:root:current train perplexity3.4684834480285645
INFO:root:current mean train loss 1582.4592301432292
INFO:root:current train perplexity3.483859062194824
INFO:root:current mean train loss 1583.326209810697
INFO:root:current train perplexity3.4857170581817627
INFO:root:current mean train loss 1585.620824620864
INFO:root:current train perplexity3.4923760890960693
INFO:root:current mean train loss 1586.2280026971725
INFO:root:current train perplexity3.4973998069763184
INFO:root:current mean train loss 1589.1877533203126
INFO:root:current train perplexity3.500749349594116
INFO:root:current mean train loss 1589.3136853448275
INFO:root:current train perplexity3.4982032775878906
INFO:root:current mean train loss 1590.8052081853693
INFO:root:current train perplexity3.4979164600372314
INFO:root:current mean train loss 1591.3128944520693
INFO:root:current train perplexity3.4993302822113037
INFO:root:current mean train loss 1591.1681785918445
INFO:root:current train perplexity3.4986112117767334
INFO:root:current mean train loss 1591.2555027126737
INFO:root:current train perplexity3.4995040893554688
INFO:root:current mean train loss 1591.3500565011161
INFO:root:current train perplexity3.5007734298706055
INFO:root:current mean train loss 1592.0887356279482
INFO:root:current train perplexity3.501208782196045
INFO:root:current mean train loss 1591.1138777240953
INFO:root:current train perplexity3.5011422634124756
INFO:root:current mean train loss 1591.4525224129097
INFO:root:current train perplexity3.5016257762908936
INFO:root:current mean train loss 1591.5028907001201
INFO:root:current train perplexity3.5026142597198486
INFO:root:current mean train loss 1592.065346608922
INFO:root:current train perplexity3.5056047439575195
INFO:root:current mean train loss 1591.5721493070419
INFO:root:current train perplexity3.505389928817749
INFO:root:current mean train loss 1590.9717779778814
INFO:root:current train perplexity3.5047662258148193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.48s/it]
INFO:root:final mean train loss: 1590.2202738782582
INFO:root:final train perplexity: 3.5048351287841797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2172.7772697286405
INFO:root:eval perplexity: 5.796269416809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [6:53:36<48:29, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1573.429207938058
INFO:root:current train perplexity3.4880528450012207
INFO:root:current mean train loss 1577.2211303710938
INFO:root:current train perplexity3.4768316745758057
INFO:root:current mean train loss 1582.9790982333097
INFO:root:current train perplexity3.4864726066589355
INFO:root:current mean train loss 1582.8167385525173
INFO:root:current train perplexity3.488436698913574
INFO:root:current mean train loss 1582.7500096662013
INFO:root:current train perplexity3.4959628582000732
INFO:root:current mean train loss 1582.9552785725612
INFO:root:current train perplexity3.496487617492676
INFO:root:current mean train loss 1585.1965784566053
INFO:root:current train perplexity3.4963364601135254
INFO:root:current mean train loss 1584.8262130038115
INFO:root:current train perplexity3.497009038925171
INFO:root:current mean train loss 1585.943575100208
INFO:root:current train perplexity3.497343063354492
INFO:root:current mean train loss 1585.0580901775643
INFO:root:current train perplexity3.4979538917541504
INFO:root:current mean train loss 1586.8345468122077
INFO:root:current train perplexity3.4990293979644775
INFO:root:current mean train loss 1586.5380690486127
INFO:root:current train perplexity3.4980111122131348
INFO:root:current mean train loss 1586.449788608029
INFO:root:current train perplexity3.499066114425659
INFO:root:current mean train loss 1587.6591121031167
INFO:root:current train perplexity3.4983959197998047
INFO:root:current mean train loss 1588.9530177440458
INFO:root:current train perplexity3.5004687309265137
INFO:root:current mean train loss 1589.2437087082524
INFO:root:current train perplexity3.503113269805908
INFO:root:current mean train loss 1589.1852011825804
INFO:root:current train perplexity3.502476453781128
INFO:root:current mean train loss 1589.8721627411694
INFO:root:current train perplexity3.5036444664001465
INFO:root:current mean train loss 1590.0660220797495
INFO:root:current train perplexity3.503971576690674
INFO:root:current mean train loss 1590.8552697414473
INFO:root:current train perplexity3.505040168762207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1590.2887780694005
INFO:root:final train perplexity: 3.5050244331359863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2173.1671778902096
INFO:root:eval perplexity: 5.798099040985107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [6:55:55<46:11, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1581.7252528303761
INFO:root:current train perplexity3.5060627460479736
INFO:root:current mean train loss 1583.5032575115467
INFO:root:current train perplexity3.506678581237793
INFO:root:current mean train loss 1588.530092452944
INFO:root:current train perplexity3.5100440979003906
INFO:root:current mean train loss 1589.77605504113
INFO:root:current train perplexity3.511091470718384
INFO:root:current mean train loss 1587.7626091452205
INFO:root:current train perplexity3.513845443725586
INFO:root:current mean train loss 1587.7559587345568
INFO:root:current train perplexity3.5093369483947754
INFO:root:current mean train loss 1589.5828227620566
INFO:root:current train perplexity3.5071651935577393
INFO:root:current mean train loss 1586.8659775725152
INFO:root:current train perplexity3.5040555000305176
INFO:root:current mean train loss 1585.8704200185082
INFO:root:current train perplexity3.501103639602661
INFO:root:current mean train loss 1586.6141292504399
INFO:root:current train perplexity3.4987759590148926
INFO:root:current mean train loss 1587.1549724690524
INFO:root:current train perplexity3.501278877258301
INFO:root:current mean train loss 1587.7764922068795
INFO:root:current train perplexity3.50003981590271
INFO:root:current mean train loss 1589.1797369486571
INFO:root:current train perplexity3.4999001026153564
INFO:root:current mean train loss 1588.5936146357903
INFO:root:current train perplexity3.4996840953826904
INFO:root:current mean train loss 1587.8540636445662
INFO:root:current train perplexity3.498887538909912
INFO:root:current mean train loss 1588.4008297336034
INFO:root:current train perplexity3.5001158714294434
INFO:root:current mean train loss 1588.3378631794144
INFO:root:current train perplexity3.4995830059051514
INFO:root:current mean train loss 1588.094950230844
INFO:root:current train perplexity3.500919818878174
INFO:root:current mean train loss 1588.8455418529788
INFO:root:current train perplexity3.5022683143615723
INFO:root:current mean train loss 1589.353567905241
INFO:root:current train perplexity3.501128673553467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.73s/it]
INFO:root:final mean train loss: 1588.7500797489106
INFO:root:final train perplexity: 3.5007734298706055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2172.978164564633
INFO:root:eval perplexity: 5.797213077545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [6:58:14<43:53, 138.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1591.337840833162
INFO:root:current train perplexity3.4822657108306885
INFO:root:current mean train loss 1584.8448937155983
INFO:root:current train perplexity3.4930665493011475
INFO:root:current mean train loss 1581.1377696161685
INFO:root:current train perplexity3.4789841175079346
INFO:root:current mean train loss 1582.2837258196892
INFO:root:current train perplexity3.4844517707824707
INFO:root:current mean train loss 1585.9447126628972
INFO:root:current train perplexity3.488673210144043
INFO:root:current mean train loss 1586.3160773383247
INFO:root:current train perplexity3.492292881011963
INFO:root:current mean train loss 1586.4093490690875
INFO:root:current train perplexity3.492568016052246
INFO:root:current mean train loss 1588.1634359458058
INFO:root:current train perplexity3.4950673580169678
INFO:root:current mean train loss 1587.7102178982948
INFO:root:current train perplexity3.495974540710449
INFO:root:current mean train loss 1587.0284492617748
INFO:root:current train perplexity3.4972684383392334
INFO:root:current mean train loss 1586.9461003980673
INFO:root:current train perplexity3.4985415935516357
INFO:root:current mean train loss 1587.873604080304
INFO:root:current train perplexity3.4966909885406494
INFO:root:current mean train loss 1589.142984515821
INFO:root:current train perplexity3.4979984760284424
INFO:root:current mean train loss 1589.6439866354299
INFO:root:current train perplexity3.498847723007202
INFO:root:current mean train loss 1589.3816288480268
INFO:root:current train perplexity3.4993956089019775
INFO:root:current mean train loss 1589.6319944894858
INFO:root:current train perplexity3.499262571334839
INFO:root:current mean train loss 1589.1983499094524
INFO:root:current train perplexity3.4991824626922607
INFO:root:current mean train loss 1589.032464173463
INFO:root:current train perplexity3.5008931159973145
INFO:root:current mean train loss 1588.760946830961
INFO:root:current train perplexity3.499917507171631
INFO:root:current mean train loss 1589.1988812033464
INFO:root:current train perplexity3.500859022140503

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.63s/it]
INFO:root:final mean train loss: 1588.728989532363
INFO:root:final train perplexity: 3.5007150173187256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2173.0661144932956
INFO:root:eval perplexity: 5.797624111175537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [7:00:32<41:34, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1584.4830282888104
INFO:root:current train perplexity3.4895858764648438
INFO:root:current mean train loss 1584.8040031472635
INFO:root:current train perplexity3.497345447540283
INFO:root:current mean train loss 1590.6652607055248
INFO:root:current train perplexity3.4968762397766113
INFO:root:current mean train loss 1587.945847683584
INFO:root:current train perplexity3.4959487915039062
INFO:root:current mean train loss 1587.406899225881
INFO:root:current train perplexity3.495931625366211
INFO:root:current mean train loss 1587.0087180435155
INFO:root:current train perplexity3.4918391704559326
INFO:root:current mean train loss 1586.16515162084
INFO:root:current train perplexity3.4886374473571777
INFO:root:current mean train loss 1586.3923960201075
INFO:root:current train perplexity3.488906145095825
INFO:root:current mean train loss 1587.522780398105
INFO:root:current train perplexity3.488887071609497
INFO:root:current mean train loss 1587.422357503501
INFO:root:current train perplexity3.4908390045166016
INFO:root:current mean train loss 1588.336486872248
INFO:root:current train perplexity3.49222993850708
INFO:root:current mean train loss 1589.3491711292763
INFO:root:current train perplexity3.4942221641540527
INFO:root:current mean train loss 1588.8280608965645
INFO:root:current train perplexity3.492839813232422
INFO:root:current mean train loss 1589.5252506779152
INFO:root:current train perplexity3.493210554122925
INFO:root:current mean train loss 1589.4271111868406
INFO:root:current train perplexity3.493898630142212
INFO:root:current mean train loss 1588.5877611982844
INFO:root:current train perplexity3.495274543762207
INFO:root:current mean train loss 1588.4066951636794
INFO:root:current train perplexity3.4968628883361816
INFO:root:current mean train loss 1588.3556946447557
INFO:root:current train perplexity3.4975340366363525
INFO:root:current mean train loss 1588.3733995440646
INFO:root:current train perplexity3.498286724090576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.61s/it]
INFO:root:final mean train loss: 1588.1413881702972
INFO:root:final train perplexity: 3.4990932941436768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2173.4880760679853
INFO:root:eval perplexity: 5.799604415893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [7:02:51<39:15, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1610.515673828125
INFO:root:current train perplexity3.4880170822143555
INFO:root:current mean train loss 1576.528437943892
INFO:root:current train perplexity3.4828319549560547
INFO:root:current mean train loss 1585.0419910249257
INFO:root:current train perplexity3.48937726020813
INFO:root:current mean train loss 1587.5687590568295
INFO:root:current train perplexity3.4885051250457764
INFO:root:current mean train loss 1587.093320669779
INFO:root:current train perplexity3.4947969913482666
INFO:root:current mean train loss 1584.841070915671
INFO:root:current train perplexity3.4953458309173584
INFO:root:current mean train loss 1583.6474169121414
INFO:root:current train perplexity3.491675853729248
INFO:root:current mean train loss 1584.5798920967209
INFO:root:current train perplexity3.4884893894195557
INFO:root:current mean train loss 1582.5041231131847
INFO:root:current train perplexity3.488156795501709
INFO:root:current mean train loss 1585.465693815462
INFO:root:current train perplexity3.4920871257781982
INFO:root:current mean train loss 1586.175366452661
INFO:root:current train perplexity3.4919872283935547
INFO:root:current mean train loss 1587.1399272197002
INFO:root:current train perplexity3.4947590827941895
INFO:root:current mean train loss 1586.7164776762654
INFO:root:current train perplexity3.496023416519165
INFO:root:current mean train loss 1586.3024469972568
INFO:root:current train perplexity3.4950199127197266
INFO:root:current mean train loss 1586.6430601728723
INFO:root:current train perplexity3.495088577270508
INFO:root:current mean train loss 1587.038601785622
INFO:root:current train perplexity3.4962785243988037
INFO:root:current mean train loss 1586.46148006842
INFO:root:current train perplexity3.495150327682495
INFO:root:current mean train loss 1586.1930658351607
INFO:root:current train perplexity3.494941234588623
INFO:root:current mean train loss 1586.7279624643904
INFO:root:current train perplexity3.4963417053222656
INFO:root:current mean train loss 1587.9888965227217
INFO:root:current train perplexity3.4971208572387695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.66s/it]
INFO:root:final mean train loss: 1587.3561968012284
INFO:root:final train perplexity: 3.49692702293396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2173.873843362145
INFO:root:eval perplexity: 5.801412105560303
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [7:05:09<36:57, 138.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1581.7719319661458
INFO:root:current train perplexity3.50295090675354
INFO:root:current mean train loss 1586.4863271638164
INFO:root:current train perplexity3.484940528869629
INFO:root:current mean train loss 1594.05542852595
INFO:root:current train perplexity3.499089479446411
INFO:root:current mean train loss 1591.7150871440176
INFO:root:current train perplexity3.4935390949249268
INFO:root:current mean train loss 1591.0210738528249
INFO:root:current train perplexity3.490903854370117
INFO:root:current mean train loss 1588.575492496961
INFO:root:current train perplexity3.491081953048706
INFO:root:current mean train loss 1589.066607753626
INFO:root:current train perplexity3.4941134452819824
INFO:root:current mean train loss 1588.6674499091944
INFO:root:current train perplexity3.4947891235351562
INFO:root:current mean train loss 1587.9986953089574
INFO:root:current train perplexity3.4965572357177734
INFO:root:current mean train loss 1587.1796994831698
INFO:root:current train perplexity3.4952611923217773
INFO:root:current mean train loss 1587.450204702524
INFO:root:current train perplexity3.494121789932251
INFO:root:current mean train loss 1588.1578182839883
INFO:root:current train perplexity3.495309591293335
INFO:root:current mean train loss 1587.8250995067046
INFO:root:current train perplexity3.498108148574829
INFO:root:current mean train loss 1587.0373388892651
INFO:root:current train perplexity3.498850107192993
INFO:root:current mean train loss 1587.3258898386857
INFO:root:current train perplexity3.4973223209381104
INFO:root:current mean train loss 1587.412466152868
INFO:root:current train perplexity3.4986119270324707
INFO:root:current mean train loss 1586.363614673767
INFO:root:current train perplexity3.4985318183898926
INFO:root:current mean train loss 1587.1327863471247
INFO:root:current train perplexity3.4985227584838867
INFO:root:current mean train loss 1587.3910026362378
INFO:root:current train perplexity3.4967548847198486
INFO:root:current mean train loss 1587.3959309726906
INFO:root:current train perplexity3.4970967769622803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.53s/it]
INFO:root:final mean train loss: 1587.8395386665563
INFO:root:final train perplexity: 3.498260736465454
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2174.052557762633
INFO:root:eval perplexity: 5.802251815795898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [7:07:28<34:38, 138.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1576.852705522017
INFO:root:current train perplexity3.497453212738037
INFO:root:current mean train loss 1587.5341771443684
INFO:root:current train perplexity3.514556884765625
INFO:root:current mean train loss 1586.9153757564357
INFO:root:current train perplexity3.5015709400177
INFO:root:current mean train loss 1585.050428168718
INFO:root:current train perplexity3.497079610824585
INFO:root:current mean train loss 1585.3816049936656
INFO:root:current train perplexity3.4959137439727783
INFO:root:current mean train loss 1585.38573141659
INFO:root:current train perplexity3.496286630630493
INFO:root:current mean train loss 1585.381936967743
INFO:root:current train perplexity3.494718313217163
INFO:root:current mean train loss 1585.2762354368804
INFO:root:current train perplexity3.493645668029785
INFO:root:current mean train loss 1584.7603664307799
INFO:root:current train perplexity3.49332332611084
INFO:root:current mean train loss 1584.0862100892148
INFO:root:current train perplexity3.4900686740875244
INFO:root:current mean train loss 1584.0363405892676
INFO:root:current train perplexity3.4874610900878906
INFO:root:current mean train loss 1584.755335134226
INFO:root:current train perplexity3.49110746383667
INFO:root:current mean train loss 1583.7893475596927
INFO:root:current train perplexity3.490290641784668
INFO:root:current mean train loss 1583.609927858625
INFO:root:current train perplexity3.490772008895874
INFO:root:current mean train loss 1585.4809556786704
INFO:root:current train perplexity3.4928362369537354
INFO:root:current mean train loss 1586.1482577150966
INFO:root:current train perplexity3.493212938308716
INFO:root:current mean train loss 1586.9970014066303
INFO:root:current train perplexity3.4938457012176514
INFO:root:current mean train loss 1587.2130838796634
INFO:root:current train perplexity3.494387626647949
INFO:root:current mean train loss 1587.1261832346886
INFO:root:current train perplexity3.4933176040649414
INFO:root:current mean train loss 1587.4983670583968
INFO:root:current train perplexity3.4944517612457275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.71s/it]
INFO:root:final mean train loss: 1586.4871302309868
INFO:root:final train perplexity: 3.4945311546325684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2174.2252456989695
INFO:root:eval perplexity: 5.803062915802002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [7:09:46<32:20, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1582.7601898693647
INFO:root:current train perplexity3.487166404724121
INFO:root:current mean train loss 1585.589790675951
INFO:root:current train perplexity3.476675271987915
INFO:root:current mean train loss 1578.3988710600754
INFO:root:current train perplexity3.4842231273651123
INFO:root:current mean train loss 1580.920304993183
INFO:root:current train perplexity3.4857051372528076
INFO:root:current mean train loss 1583.5392234951194
INFO:root:current train perplexity3.4902477264404297
INFO:root:current mean train loss 1583.422010125961
INFO:root:current train perplexity3.4876980781555176
INFO:root:current mean train loss 1582.4615537611692
INFO:root:current train perplexity3.4892938137054443
INFO:root:current mean train loss 1584.158230233913
INFO:root:current train perplexity3.4925501346588135
INFO:root:current mean train loss 1584.8166946251633
INFO:root:current train perplexity3.493535280227661
INFO:root:current mean train loss 1584.6183421505104
INFO:root:current train perplexity3.4909753799438477
INFO:root:current mean train loss 1586.6936644932553
INFO:root:current train perplexity3.490993022918701
INFO:root:current mean train loss 1587.033560293692
INFO:root:current train perplexity3.491224765777588
INFO:root:current mean train loss 1587.8275521117293
INFO:root:current train perplexity3.49082350730896
INFO:root:current mean train loss 1587.3578375957188
INFO:root:current train perplexity3.492769241333008
INFO:root:current mean train loss 1586.8794772482995
INFO:root:current train perplexity3.4923737049102783
INFO:root:current mean train loss 1586.5119572602198
INFO:root:current train perplexity3.4922103881835938
INFO:root:current mean train loss 1587.102118834898
INFO:root:current train perplexity3.4928781986236572
INFO:root:current mean train loss 1586.2718227198013
INFO:root:current train perplexity3.493295907974243
INFO:root:current mean train loss 1586.4424806130567
INFO:root:current train perplexity3.4937877655029297
INFO:root:current mean train loss 1587.075163627753
INFO:root:current train perplexity3.4942800998687744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.72s/it]
INFO:root:final mean train loss: 1586.5491935664575
INFO:root:final train perplexity: 3.4947025775909424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2174.406615778064
INFO:root:eval perplexity: 5.8039140701293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [7:12:05<30:01, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1592.3780642778445
INFO:root:current train perplexity3.4786436557769775
INFO:root:current mean train loss 1591.7199761894312
INFO:root:current train perplexity3.484905242919922
INFO:root:current mean train loss 1589.5027878576045
INFO:root:current train perplexity3.481736183166504
INFO:root:current mean train loss 1589.7915652643435
INFO:root:current train perplexity3.4898712635040283
INFO:root:current mean train loss 1587.066222889154
INFO:root:current train perplexity3.485915422439575
INFO:root:current mean train loss 1586.6790108334235
INFO:root:current train perplexity3.4878087043762207
INFO:root:current mean train loss 1585.5543987082872
INFO:root:current train perplexity3.485201835632324
INFO:root:current mean train loss 1586.2617615844413
INFO:root:current train perplexity3.4823920726776123
INFO:root:current mean train loss 1587.609602317723
INFO:root:current train perplexity3.48388671875
INFO:root:current mean train loss 1586.369176072821
INFO:root:current train perplexity3.4856414794921875
INFO:root:current mean train loss 1587.4471580491215
INFO:root:current train perplexity3.487933874130249
INFO:root:current mean train loss 1587.4398214084385
INFO:root:current train perplexity3.4890811443328857
INFO:root:current mean train loss 1586.7527737087673
INFO:root:current train perplexity3.4868085384368896
INFO:root:current mean train loss 1587.2560911137064
INFO:root:current train perplexity3.488051176071167
INFO:root:current mean train loss 1587.0879703258468
INFO:root:current train perplexity3.4890666007995605
INFO:root:current mean train loss 1586.058611542251
INFO:root:current train perplexity3.4892828464508057
INFO:root:current mean train loss 1586.7534477224792
INFO:root:current train perplexity3.4919369220733643
INFO:root:current mean train loss 1586.270468335318
INFO:root:current train perplexity3.491645097732544
INFO:root:current mean train loss 1586.5025786216013
INFO:root:current train perplexity3.4925951957702637
INFO:root:current mean train loss 1586.2204665751983
INFO:root:current train perplexity3.4926626682281494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.62s/it]
INFO:root:final mean train loss: 1585.8313383178404
INFO:root:final train perplexity: 3.4927241802215576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2174.4842083437225
INFO:root:eval perplexity: 5.8042778968811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [7:14:24<27:42, 138.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1590.868648488898
INFO:root:current train perplexity3.5001587867736816
INFO:root:current mean train loss 1587.7095552884616
INFO:root:current train perplexity3.503383159637451
INFO:root:current mean train loss 1586.4924937102753
INFO:root:current train perplexity3.498093605041504
INFO:root:current mean train loss 1585.7946715535998
INFO:root:current train perplexity3.4901177883148193
INFO:root:current mean train loss 1586.0689095545297
INFO:root:current train perplexity3.4900949001312256
INFO:root:current mean train loss 1586.3003692883403
INFO:root:current train perplexity3.489084243774414
INFO:root:current mean train loss 1587.0232226913781
INFO:root:current train perplexity3.487443685531616
INFO:root:current mean train loss 1587.8031191651926
INFO:root:current train perplexity3.4863429069519043
INFO:root:current mean train loss 1586.876945487081
INFO:root:current train perplexity3.488358497619629
INFO:root:current mean train loss 1586.4498884804884
INFO:root:current train perplexity3.4867241382598877
INFO:root:current mean train loss 1586.2248147206765
INFO:root:current train perplexity3.4876232147216797
INFO:root:current mean train loss 1586.4890898764384
INFO:root:current train perplexity3.4875946044921875
INFO:root:current mean train loss 1586.0775382141348
INFO:root:current train perplexity3.487248659133911
INFO:root:current mean train loss 1586.4483749334956
INFO:root:current train perplexity3.488553524017334
INFO:root:current mean train loss 1586.1089565315374
INFO:root:current train perplexity3.488985061645508
INFO:root:current mean train loss 1585.025619688602
INFO:root:current train perplexity3.489280939102173
INFO:root:current mean train loss 1585.6443041055954
INFO:root:current train perplexity3.4897115230560303
INFO:root:current mean train loss 1586.0431775956433
INFO:root:current train perplexity3.4918224811553955
INFO:root:current mean train loss 1586.2755365940386
INFO:root:current train perplexity3.491633176803589

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.84s/it]
INFO:root:final mean train loss: 1585.8482097215983
INFO:root:final train perplexity: 3.4927709102630615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2174.6904093424478
INFO:root:eval perplexity: 5.805246829986572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [7:16:42<25:25, 138.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1575.1379801432292
INFO:root:current train perplexity3.4664149284362793
INFO:root:current mean train loss 1577.6120943341937
INFO:root:current train perplexity3.4672112464904785
INFO:root:current mean train loss 1580.7933315061173
INFO:root:current train perplexity3.4808974266052246
INFO:root:current mean train loss 1579.2688457782451
INFO:root:current train perplexity3.4835150241851807
INFO:root:current mean train loss 1580.6265081016763
INFO:root:current train perplexity3.4802186489105225
INFO:root:current mean train loss 1580.8633868694305
INFO:root:current train perplexity3.476712226867676
INFO:root:current mean train loss 1579.8203053193934
INFO:root:current train perplexity3.475996971130371
INFO:root:current mean train loss 1579.5269389634723
INFO:root:current train perplexity3.477825164794922
INFO:root:current mean train loss 1580.9602049277921
INFO:root:current train perplexity3.481109142303467
INFO:root:current mean train loss 1581.701061717251
INFO:root:current train perplexity3.485358476638794
INFO:root:current mean train loss 1582.4273936154814
INFO:root:current train perplexity3.486008405685425
INFO:root:current mean train loss 1582.6400710730245
INFO:root:current train perplexity3.4857263565063477
INFO:root:current mean train loss 1582.1192913999653
INFO:root:current train perplexity3.4856183528900146
INFO:root:current mean train loss 1583.2376917397103
INFO:root:current train perplexity3.4863617420196533
INFO:root:current mean train loss 1583.181210093728
INFO:root:current train perplexity3.487018346786499
INFO:root:current mean train loss 1583.7779130077868
INFO:root:current train perplexity3.488159656524658
INFO:root:current mean train loss 1584.397965196936
INFO:root:current train perplexity3.4885201454162598
INFO:root:current mean train loss 1584.7690823991722
INFO:root:current train perplexity3.490035057067871
INFO:root:current mean train loss 1585.1281220223466
INFO:root:current train perplexity3.490154504776001
INFO:root:current mean train loss 1585.0420832294799
INFO:root:current train perplexity3.4896998405456543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1584.6058264350988
INFO:root:final train perplexity: 3.4893503189086914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2174.919052232242
INFO:root:eval perplexity: 5.806319713592529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [7:19:01<23:05, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.302212419181
INFO:root:current train perplexity3.485046148300171
INFO:root:current mean train loss 1583.7349607482438
INFO:root:current train perplexity3.491743803024292
INFO:root:current mean train loss 1581.6558805907137
INFO:root:current train perplexity3.486754894256592
INFO:root:current mean train loss 1581.0769532734137
INFO:root:current train perplexity3.4866206645965576
INFO:root:current mean train loss 1584.5118732585775
INFO:root:current train perplexity3.4901702404022217
INFO:root:current mean train loss 1583.355641586794
INFO:root:current train perplexity3.489107370376587
INFO:root:current mean train loss 1584.8288153085875
INFO:root:current train perplexity3.4864580631256104
INFO:root:current mean train loss 1584.7718529302233
INFO:root:current train perplexity3.4852123260498047
INFO:root:current mean train loss 1584.9227409776934
INFO:root:current train perplexity3.485891580581665
INFO:root:current mean train loss 1586.2129187445337
INFO:root:current train perplexity3.488654136657715
INFO:root:current mean train loss 1584.1239969830008
INFO:root:current train perplexity3.4865307807922363
INFO:root:current mean train loss 1584.8115424670616
INFO:root:current train perplexity3.48697566986084
INFO:root:current mean train loss 1585.768624314261
INFO:root:current train perplexity3.4892430305480957
INFO:root:current mean train loss 1585.7261235428718
INFO:root:current train perplexity3.489698886871338
INFO:root:current mean train loss 1585.726376959959
INFO:root:current train perplexity3.4898698329925537
INFO:root:current mean train loss 1585.280557097291
INFO:root:current train perplexity3.4889872074127197
INFO:root:current mean train loss 1584.1686505902537
INFO:root:current train perplexity3.4866421222686768
INFO:root:current mean train loss 1583.8343349829652
INFO:root:current train perplexity3.4859559535980225
INFO:root:current mean train loss 1584.3248040734777
INFO:root:current train perplexity3.4871268272399902
INFO:root:current mean train loss 1584.7875740521927
INFO:root:current train perplexity3.4875314235687256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.69s/it]
INFO:root:final mean train loss: 1584.0805140816078
INFO:root:final train perplexity: 3.4879043102264404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2175.3590135506706
INFO:root:eval perplexity: 5.808385848999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [7:21:19<20:47, 138.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1583.960223654042
INFO:root:current train perplexity3.5132715702056885
INFO:root:current mean train loss 1590.715770982716
INFO:root:current train perplexity3.493154287338257
INFO:root:current mean train loss 1588.8603257590194
INFO:root:current train perplexity3.4944469928741455
INFO:root:current mean train loss 1584.7301060671061
INFO:root:current train perplexity3.490863084793091
INFO:root:current mean train loss 1583.4081601540604
INFO:root:current train perplexity3.4884910583496094
INFO:root:current mean train loss 1583.0797635591948
INFO:root:current train perplexity3.48673415184021
INFO:root:current mean train loss 1583.4109812639076
INFO:root:current train perplexity3.4873275756835938
INFO:root:current mean train loss 1583.8716275212591
INFO:root:current train perplexity3.4876341819763184
INFO:root:current mean train loss 1583.4052207712305
INFO:root:current train perplexity3.485537528991699
INFO:root:current mean train loss 1584.3937923762057
INFO:root:current train perplexity3.4863221645355225
INFO:root:current mean train loss 1584.077826709638
INFO:root:current train perplexity3.4859635829925537
INFO:root:current mean train loss 1583.8820632481866
INFO:root:current train perplexity3.4856133460998535
INFO:root:current mean train loss 1583.1345059071843
INFO:root:current train perplexity3.4843225479125977
INFO:root:current mean train loss 1583.854638744428
INFO:root:current train perplexity3.4849014282226562
INFO:root:current mean train loss 1584.0326809916094
INFO:root:current train perplexity3.4853758811950684
INFO:root:current mean train loss 1583.4096313318646
INFO:root:current train perplexity3.4831576347351074
INFO:root:current mean train loss 1583.4107445755099
INFO:root:current train perplexity3.4851810932159424
INFO:root:current mean train loss 1583.235439864221
INFO:root:current train perplexity3.485518455505371
INFO:root:current mean train loss 1584.151983688867
INFO:root:current train perplexity3.4868314266204834
INFO:root:current mean train loss 1584.2720555210408
INFO:root:current train perplexity3.4868409633636475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1583.907449619372
INFO:root:final train perplexity: 3.487428665161133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2175.0108179403537
INFO:root:eval perplexity: 5.8067498207092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [7:23:38<18:28, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1593.8058461991568
INFO:root:current train perplexity3.5184326171875
INFO:root:current mean train loss 1589.3371057802915
INFO:root:current train perplexity3.488229990005493
INFO:root:current mean train loss 1587.293639904646
INFO:root:current train perplexity3.472339630126953
INFO:root:current mean train loss 1584.3179161555183
INFO:root:current train perplexity3.479998826980591
INFO:root:current mean train loss 1583.6570040412391
INFO:root:current train perplexity3.47932505607605
INFO:root:current mean train loss 1583.3530169363344
INFO:root:current train perplexity3.47853422164917
INFO:root:current mean train loss 1582.4963743460125
INFO:root:current train perplexity3.4787917137145996
INFO:root:current mean train loss 1583.6741885763945
INFO:root:current train perplexity3.479123592376709
INFO:root:current mean train loss 1584.176490615721
INFO:root:current train perplexity3.4825730323791504
INFO:root:current mean train loss 1584.2004180306092
INFO:root:current train perplexity3.4822206497192383
INFO:root:current mean train loss 1585.066947355656
INFO:root:current train perplexity3.485164165496826
INFO:root:current mean train loss 1584.9218294466762
INFO:root:current train perplexity3.4847757816314697
INFO:root:current mean train loss 1584.693316268619
INFO:root:current train perplexity3.4832825660705566
INFO:root:current mean train loss 1584.6408327792553
INFO:root:current train perplexity3.4840214252471924
INFO:root:current mean train loss 1584.4718039272097
INFO:root:current train perplexity3.4832003116607666
INFO:root:current mean train loss 1584.3361000261166
INFO:root:current train perplexity3.4840691089630127
INFO:root:current mean train loss 1584.3632175356097
INFO:root:current train perplexity3.4863762855529785
INFO:root:current mean train loss 1584.0189974087582
INFO:root:current train perplexity3.4846456050872803
INFO:root:current mean train loss 1583.0899610370957
INFO:root:current train perplexity3.484860897064209
INFO:root:current mean train loss 1583.6497680228763
INFO:root:current train perplexity3.4859094619750977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.52s/it]
INFO:root:final mean train loss: 1583.5273495980482
INFO:root:final train perplexity: 3.4863831996917725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2175.5684017965978
INFO:root:eval perplexity: 5.809369087219238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [7:25:56<16:09, 138.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.877197265625
INFO:root:current train perplexity3.481869697570801
INFO:root:current mean train loss 1578.179338921441
INFO:root:current train perplexity3.4661591053009033
INFO:root:current mean train loss 1577.6491777692522
INFO:root:current train perplexity3.470398187637329
INFO:root:current mean train loss 1580.744585860403
INFO:root:current train perplexity3.4661881923675537
INFO:root:current mean train loss 1584.3086280822754
INFO:root:current train perplexity3.480778217315674
INFO:root:current mean train loss 1581.6420233364763
INFO:root:current train perplexity3.4756853580474854
INFO:root:current mean train loss 1582.2109322940603
INFO:root:current train perplexity3.4774930477142334
INFO:root:current mean train loss 1581.522774251302
INFO:root:current train perplexity3.4799551963806152
INFO:root:current mean train loss 1582.542917841131
INFO:root:current train perplexity3.478938102722168
INFO:root:current mean train loss 1581.9653479751275
INFO:root:current train perplexity3.478243112564087
INFO:root:current mean train loss 1582.9717256899232
INFO:root:current train perplexity3.479545831680298
INFO:root:current mean train loss 1582.619088589943
INFO:root:current train perplexity3.481083631515503
INFO:root:current mean train loss 1582.9376734733582
INFO:root:current train perplexity3.4813435077667236
INFO:root:current mean train loss 1583.2338837112206
INFO:root:current train perplexity3.48124361038208
INFO:root:current mean train loss 1583.3109502843909
INFO:root:current train perplexity3.4815609455108643
INFO:root:current mean train loss 1583.9195171114764
INFO:root:current train perplexity3.483496904373169
INFO:root:current mean train loss 1584.296598815918
INFO:root:current train perplexity3.4842309951782227
INFO:root:current mean train loss 1583.517309021682
INFO:root:current train perplexity3.4849610328674316
INFO:root:current mean train loss 1583.3052449327834
INFO:root:current train perplexity3.4846389293670654
INFO:root:current mean train loss 1583.4531627308238
INFO:root:current train perplexity3.4849209785461426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.38s/it]
INFO:root:final mean train loss: 1582.9589586435877
INFO:root:final train perplexity: 3.48482084274292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.68s/it]
INFO:root:eval mean loss: 2175.7673413432235
INFO:root:eval perplexity: 5.810303688049316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [7:28:15<13:50, 138.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.1094656088917
INFO:root:current train perplexity3.5025570392608643
INFO:root:current mean train loss 1590.1599715954155
INFO:root:current train perplexity3.489511251449585
INFO:root:current mean train loss 1587.683134650542
INFO:root:current train perplexity3.487379550933838
INFO:root:current mean train loss 1584.7282570327259
INFO:root:current train perplexity3.484147548675537
INFO:root:current mean train loss 1581.5967376524773
INFO:root:current train perplexity3.4818074703216553
INFO:root:current mean train loss 1584.323071043695
INFO:root:current train perplexity3.484914779663086
INFO:root:current mean train loss 1584.7320427039433
INFO:root:current train perplexity3.4876577854156494
INFO:root:current mean train loss 1583.1752257305227
INFO:root:current train perplexity3.485426664352417
INFO:root:current mean train loss 1583.811085100291
INFO:root:current train perplexity3.4874050617218018
INFO:root:current mean train loss 1582.8097979240456
INFO:root:current train perplexity3.4900808334350586
INFO:root:current mean train loss 1583.3661279252365
INFO:root:current train perplexity3.492631435394287
INFO:root:current mean train loss 1583.2270851485812
INFO:root:current train perplexity3.4911322593688965
INFO:root:current mean train loss 1584.0327130555188
INFO:root:current train perplexity3.4894073009490967
INFO:root:current mean train loss 1583.8213250631934
INFO:root:current train perplexity3.4894943237304688
INFO:root:current mean train loss 1583.9689069708427
INFO:root:current train perplexity3.4893548488616943
INFO:root:current mean train loss 1584.258183755797
INFO:root:current train perplexity3.4876668453216553
INFO:root:current mean train loss 1583.9617525009667
INFO:root:current train perplexity3.4879720211029053
INFO:root:current mean train loss 1583.7041256776702
INFO:root:current train perplexity3.486865758895874
INFO:root:current mean train loss 1583.607441630185
INFO:root:current train perplexity3.4863994121551514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.74s/it]
INFO:root:final mean train loss: 1583.4383687121785
INFO:root:final train perplexity: 3.4861388206481934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2175.7102946829286
INFO:root:eval perplexity: 5.8100361824035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [7:30:33<11:32, 138.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1569.24560546875
INFO:root:current train perplexity3.488494873046875
INFO:root:current mean train loss 1558.9483150013707
INFO:root:current train perplexity3.4428985118865967
INFO:root:current mean train loss 1574.0088267103533
INFO:root:current train perplexity3.4578146934509277
INFO:root:current mean train loss 1581.9586006699094
INFO:root:current train perplexity3.4703681468963623
INFO:root:current mean train loss 1581.510180192293
INFO:root:current train perplexity3.472423553466797
INFO:root:current mean train loss 1580.6884160023255
INFO:root:current train perplexity3.475292205810547
INFO:root:current mean train loss 1582.1948202425183
INFO:root:current train perplexity3.4766876697540283
INFO:root:current mean train loss 1581.4995082994135
INFO:root:current train perplexity3.4790384769439697
INFO:root:current mean train loss 1581.4715786120814
INFO:root:current train perplexity3.48093843460083
INFO:root:current mean train loss 1583.0874161000324
INFO:root:current train perplexity3.4821724891662598
INFO:root:current mean train loss 1582.5473613550912
INFO:root:current train perplexity3.484694242477417
INFO:root:current mean train loss 1580.113642968224
INFO:root:current train perplexity3.482475519180298
INFO:root:current mean train loss 1581.2239866555228
INFO:root:current train perplexity3.480252265930176
INFO:root:current mean train loss 1581.3464671328006
INFO:root:current train perplexity3.481215715408325
INFO:root:current mean train loss 1581.7112908478
INFO:root:current train perplexity3.480009078979492
INFO:root:current mean train loss 1581.572974664847
INFO:root:current train perplexity3.479968547821045
INFO:root:current mean train loss 1581.9093106067758
INFO:root:current train perplexity3.4818248748779297
INFO:root:current mean train loss 1581.8693626163442
INFO:root:current train perplexity3.481516122817993
INFO:root:current mean train loss 1582.785653279398
INFO:root:current train perplexity3.484177589416504
INFO:root:current mean train loss 1582.833727861522
INFO:root:current train perplexity3.4837238788604736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.41s/it]
INFO:root:final mean train loss: 1582.8048076312227
INFO:root:final train perplexity: 3.4843971729278564
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2175.4959543647497
INFO:root:eval perplexity: 5.8090291023254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [7:32:52<09:13, 138.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1580.528816469254
INFO:root:current train perplexity3.4721148014068604
INFO:root:current mean train loss 1576.3906669325502
INFO:root:current train perplexity3.4815967082977295
INFO:root:current mean train loss 1571.275968213102
INFO:root:current train perplexity3.4891083240509033
INFO:root:current mean train loss 1575.3430787976774
INFO:root:current train perplexity3.4855804443359375
INFO:root:current mean train loss 1578.4791976326856
INFO:root:current train perplexity3.4770989418029785
INFO:root:current mean train loss 1578.7812322986551
INFO:root:current train perplexity3.475227117538452
INFO:root:current mean train loss 1578.2857549942428
INFO:root:current train perplexity3.4772679805755615
INFO:root:current mean train loss 1580.2335498982025
INFO:root:current train perplexity3.479142189025879
INFO:root:current mean train loss 1581.0895072119904
INFO:root:current train perplexity3.4820146560668945
INFO:root:current mean train loss 1581.8748520995568
INFO:root:current train perplexity3.4836878776550293
INFO:root:current mean train loss 1582.8108040396157
INFO:root:current train perplexity3.483593702316284
INFO:root:current mean train loss 1583.303643264568
INFO:root:current train perplexity3.4815104007720947
INFO:root:current mean train loss 1584.080946004265
INFO:root:current train perplexity3.4822146892547607
INFO:root:current mean train loss 1583.5789568390192
INFO:root:current train perplexity3.4820315837860107
INFO:root:current mean train loss 1582.714511234222
INFO:root:current train perplexity3.482769012451172
INFO:root:current mean train loss 1582.5673108938704
INFO:root:current train perplexity3.4817440509796143
INFO:root:current mean train loss 1582.4116997546319
INFO:root:current train perplexity3.4825825691223145
INFO:root:current mean train loss 1582.9617723875965
INFO:root:current train perplexity3.483649253845215
INFO:root:current mean train loss 1582.482485810243
INFO:root:current train perplexity3.4834706783294678
INFO:root:current mean train loss 1583.0408458897389
INFO:root:current train perplexity3.48345685005188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.65s/it]
INFO:root:final mean train loss: 1582.4348422467438
INFO:root:final train perplexity: 3.4833805561065674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2175.5918271761416
INFO:root:eval perplexity: 5.8094801902771
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [7:35:10<06:55, 138.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1576.0222142537434
INFO:root:current train perplexity3.4691905975341797
INFO:root:current mean train loss 1579.7338999155406
INFO:root:current train perplexity3.4793894290924072
INFO:root:current mean train loss 1580.334486930601
INFO:root:current train perplexity3.4864156246185303
INFO:root:current mean train loss 1580.301171664534
INFO:root:current train perplexity3.4820470809936523
INFO:root:current mean train loss 1583.0750051225934
INFO:root:current train perplexity3.482813835144043
INFO:root:current mean train loss 1581.1976801739993
INFO:root:current train perplexity3.478656530380249
INFO:root:current mean train loss 1580.6978166368272
INFO:root:current train perplexity3.4791595935821533
INFO:root:current mean train loss 1581.1469860382897
INFO:root:current train perplexity3.481565475463867
INFO:root:current mean train loss 1583.8288960007
INFO:root:current train perplexity3.4832663536071777
INFO:root:current mean train loss 1583.6865341250907
INFO:root:current train perplexity3.4839863777160645
INFO:root:current mean train loss 1583.0883692384675
INFO:root:current train perplexity3.482377052307129
INFO:root:current mean train loss 1583.800876099058
INFO:root:current train perplexity3.4851391315460205
INFO:root:current mean train loss 1582.8988214150454
INFO:root:current train perplexity3.4855289459228516
INFO:root:current mean train loss 1582.7068636297117
INFO:root:current train perplexity3.483985185623169
INFO:root:current mean train loss 1582.8450491046378
INFO:root:current train perplexity3.482875347137451
INFO:root:current mean train loss 1582.9281910346767
INFO:root:current train perplexity3.4841418266296387
INFO:root:current mean train loss 1582.6998440640643
INFO:root:current train perplexity3.4833991527557373
INFO:root:current mean train loss 1582.713750284924
INFO:root:current train perplexity3.4821126461029053
INFO:root:current mean train loss 1582.662768079089
INFO:root:current train perplexity3.4823551177978516
INFO:root:current mean train loss 1582.6847170725985
INFO:root:current train perplexity3.4829092025756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.98s/it]
INFO:root:final mean train loss: 1582.1245296938037
INFO:root:final train perplexity: 3.4825284481048584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.81s/it]
INFO:root:eval mean loss: 2175.644935986674
INFO:root:eval perplexity: 5.809728622436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [7:37:29<04:37, 138.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1576.1043926532452
INFO:root:current train perplexity3.454129695892334
INFO:root:current mean train loss 1580.6818300189393
INFO:root:current train perplexity3.465606451034546
INFO:root:current mean train loss 1580.756618514151
INFO:root:current train perplexity3.4666435718536377
INFO:root:current mean train loss 1579.5403658096104
INFO:root:current train perplexity3.471172332763672
INFO:root:current mean train loss 1579.8368022303428
INFO:root:current train perplexity3.4697914123535156
INFO:root:current mean train loss 1578.4140657408047
INFO:root:current train perplexity3.471953868865967
INFO:root:current mean train loss 1579.256267438616
INFO:root:current train perplexity3.4726243019104004
INFO:root:current mean train loss 1579.051624572355
INFO:root:current train perplexity3.4753506183624268
INFO:root:current mean train loss 1580.6979938132226
INFO:root:current train perplexity3.4780113697052
INFO:root:current mean train loss 1581.8647104213892
INFO:root:current train perplexity3.480775833129883
INFO:root:current mean train loss 1580.948104758106
INFO:root:current train perplexity3.480714797973633
INFO:root:current mean train loss 1582.1272518567262
INFO:root:current train perplexity3.482379913330078
INFO:root:current mean train loss 1582.195891682621
INFO:root:current train perplexity3.482938766479492
INFO:root:current mean train loss 1582.5118974287432
INFO:root:current train perplexity3.4817564487457275
INFO:root:current mean train loss 1582.7776287196032
INFO:root:current train perplexity3.484065055847168
INFO:root:current mean train loss 1582.3875319800818
INFO:root:current train perplexity3.4844698905944824
INFO:root:current mean train loss 1583.0203177054007
INFO:root:current train perplexity3.483454465866089
INFO:root:current mean train loss 1582.272215206157
INFO:root:current train perplexity3.481580972671509
INFO:root:current mean train loss 1582.4233603306175
INFO:root:current train perplexity3.480818510055542
INFO:root:current mean train loss 1581.6320580247097
INFO:root:current train perplexity3.4804940223693848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.93s/it]
INFO:root:final mean train loss: 1581.406836590019
INFO:root:final train perplexity: 3.480557680130005
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.73s/it]
INFO:root:eval mean loss: 2175.7451370996787
INFO:root:eval perplexity: 5.8101983070373535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [7:39:48<02:18, 138.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1590.7946881550115
INFO:root:current train perplexity3.4848828315734863
INFO:root:current mean train loss 1581.7828134390024
INFO:root:current train perplexity3.4802944660186768
INFO:root:current mean train loss 1587.4316432222406
INFO:root:current train perplexity3.4812073707580566
INFO:root:current mean train loss 1586.6576748992761
INFO:root:current train perplexity3.478604316711426
INFO:root:current mean train loss 1585.4362646079162
INFO:root:current train perplexity3.4805314540863037
INFO:root:current mean train loss 1585.2410955789574
INFO:root:current train perplexity3.4821531772613525
INFO:root:current mean train loss 1584.9806126569374
INFO:root:current train perplexity3.4883289337158203
INFO:root:current mean train loss 1584.253789174892
INFO:root:current train perplexity3.4877405166625977
INFO:root:current mean train loss 1584.4961383153523
INFO:root:current train perplexity3.485079288482666
INFO:root:current mean train loss 1583.36420162535
INFO:root:current train perplexity3.487168550491333
INFO:root:current mean train loss 1582.696564679666
INFO:root:current train perplexity3.4869847297668457
INFO:root:current mean train loss 1582.4054759585515
INFO:root:current train perplexity3.4846417903900146
INFO:root:current mean train loss 1582.9124884404555
INFO:root:current train perplexity3.4857125282287598
INFO:root:current mean train loss 1583.1213783451858
INFO:root:current train perplexity3.4850265979766846
INFO:root:current mean train loss 1582.520125374942
INFO:root:current train perplexity3.484685182571411
INFO:root:current mean train loss 1582.155663028529
INFO:root:current train perplexity3.4840176105499268
INFO:root:current mean train loss 1581.6288478275258
INFO:root:current train perplexity3.483114719390869
INFO:root:current mean train loss 1581.696425929214
INFO:root:current train perplexity3.482307195663452
INFO:root:current mean train loss 1581.8822615620434
INFO:root:current train perplexity3.4821321964263916
INFO:root:current mean train loss 1582.1225918520593
INFO:root:current train perplexity3.4813618659973145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.58s/it]
INFO:root:final mean train loss: 1581.6867387687926
INFO:root:final train perplexity: 3.4813265800476074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.69s/it]
INFO:root:eval mean loss: 2175.736694768811
INFO:root:eval perplexity: 5.810160160064697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allmini_l6_baseline/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:42:07<00:00, 138.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:42:07<00:00, 138.64s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.70s/it]
INFO:root:eval mean loss: 2175.736694768811
INFO:root:eval perplexity: 5.810160160064697
INFO:root:evalaution complete
INFO:root:save model final: allmini_l6_baseline/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14dbd7fecf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14dbd7fe48e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14dbd7f09e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14dbd7feda3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14dbd7f07948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14dbd7feda3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14dbd7ec2b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14dbd792746a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14dcd4143a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14dcd4143be0]
python(+0x24a989) [0x56106f11d989]
python(+0x24a9bd) [0x56106f11d9bd]
python(+0x24aa14) [0x56106f11da14]
python(+0x108f75) [0x56106efdbf75]
python(Py_RunMain+0x313) [0x56106f120983]
python(Py_BytesMain+0x39) [0x56106f120bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14dcd41210b3]
python(+0x1d6e13) [0x56106f0a9e13]
/bin/bash: line 3: 2999477 Aborted                 (core dumped) python train_script.py --model_path sentence-transformers/all-MiniLM-L6-v2 --data_folder data_for_baseline --output allmini_l6_baseline --epochs 200 --save_head --save_epochs 1 --external_embedding --not_retrieval --not_cross_attention
