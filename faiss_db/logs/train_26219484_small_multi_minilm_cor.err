INFO:root:Output: small_multiqa_minilm_corrected
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23785.82116082702
INFO:root:current train perplexity11904.232421875
INFO:root:current mean train loss 19987.61784017745
INFO:root:current train perplexity2636.8876953125
INFO:root:current mean train loss 17338.20564969168
INFO:root:current train perplexity930.4763793945312
INFO:root:current mean train loss 15548.091625548246
INFO:root:current train perplexity455.62811279296875
INFO:root:current mean train loss 14245.88015875501
INFO:root:current train perplexity272.6911315917969
INFO:root:current mean train loss 13254.003827994575
INFO:root:current train perplexity185.0228729248047
INFO:root:current mean train loss 12481.653157552084
INFO:root:current train perplexity136.4439697265625
INFO:root:current mean train loss 11858.427899376173
INFO:root:current train perplexity106.97503662109375
INFO:root:current mean train loss 11347.208034426272
INFO:root:current train perplexity87.49243927001953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.28s/it]
INFO:root:final mean train loss: 10933.244208674278
INFO:root:final train perplexity: 74.70005798339844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it]
INFO:root:eval mean loss: 6475.136078097296
INFO:root:eval perplexity: 13.713147163391113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 6967.08312209109
INFO:root:eval perplexity: 17.269399642944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/1
  0%|          | 1/200 [06:47<22:31:53, 407.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6879.855050223215
INFO:root:current train perplexity15.232976913452148
INFO:root:current mean train loss 6898.184036397488
INFO:root:current train perplexity14.833925247192383
INFO:root:current mean train loss 6797.625037741546
INFO:root:current train perplexity14.460545539855957
INFO:root:current mean train loss 6709.000609158693
INFO:root:current train perplexity14.06531810760498
INFO:root:current mean train loss 6638.961023878993
INFO:root:current train perplexity13.73155403137207
INFO:root:current mean train loss 6585.316882011218
INFO:root:current train perplexity13.400156021118164
INFO:root:current mean train loss 6531.528997631795
INFO:root:current train perplexity13.110530853271484
INFO:root:current mean train loss 6485.37091487469
INFO:root:current train perplexity12.873228073120117
INFO:root:current mean train loss 6437.999373765683
INFO:root:current train perplexity12.650582313537598
INFO:root:current mean train loss 6392.48464578883
INFO:root:current train perplexity12.438035011291504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.36s/it]
INFO:root:final mean train loss: 6357.441010136758
INFO:root:final train perplexity: 12.282730102539062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 5576.070128961658
INFO:root:eval perplexity: 9.533378601074219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 6178.511694509087
INFO:root:eval perplexity: 12.509373664855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/2
  1%|          | 2/200 [13:40<22:35:27, 410.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5949.5990234375
INFO:root:current train perplexity10.523436546325684
INFO:root:current mean train loss 5858.338510529891
INFO:root:current train perplexity10.242316246032715
INFO:root:current mean train loss 5862.2942291969475
INFO:root:current train perplexity10.160958290100098
INFO:root:current mean train loss 5839.909771825397
INFO:root:current train perplexity10.057626724243164
INFO:root:current mean train loss 5826.690842667545
INFO:root:current train perplexity9.97646713256836
INFO:root:current mean train loss 5816.629374620752
INFO:root:current train perplexity9.902800559997559
INFO:root:current mean train loss 5789.98232660061
INFO:root:current train perplexity9.802342414855957
INFO:root:current mean train loss 5764.537973257212
INFO:root:current train perplexity9.717458724975586
INFO:root:current mean train loss 5750.864904860046
INFO:root:current train perplexity9.653489112854004
INFO:root:current mean train loss 5730.168173134392
INFO:root:current train perplexity9.568272590637207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.09s/it]
INFO:root:final mean train loss: 5709.395597273304
INFO:root:final train perplexity: 9.511693954467773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 5190.03535710328
INFO:root:eval perplexity: 8.155543327331543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 5852.43728529477
INFO:root:eval perplexity: 10.947837829589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/3
  2%|â–         | 3/200 [20:27<22:22:57, 409.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5599.344323199728
INFO:root:current train perplexity8.800718307495117
INFO:root:current mean train loss 5503.858819232723
INFO:root:current train perplexity8.741493225097656
INFO:root:current mean train loss 5493.022682087304
INFO:root:current train perplexity8.72471809387207
INFO:root:current mean train loss 5469.505105033379
INFO:root:current train perplexity8.643004417419434
INFO:root:current mean train loss 5463.075278424202
INFO:root:current train perplexity8.59101390838623
INFO:root:current mean train loss 5442.7630491530235
INFO:root:current train perplexity8.533363342285156
INFO:root:current mean train loss 5434.669922658758
INFO:root:current train perplexity8.497461318969727
INFO:root:current mean train loss 5420.886048123055
INFO:root:current train perplexity8.46019458770752
INFO:root:current mean train loss 5402.853971868355
INFO:root:current train perplexity8.423742294311523
INFO:root:current mean train loss 5389.938215228874
INFO:root:current train perplexity8.374421119689941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.05s/it]
INFO:root:final mean train loss: 5377.775451414047
INFO:root:final train perplexity: 8.345211029052734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 4967.840799534574
INFO:root:eval perplexity: 7.454732894897461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 5665.329915364583
INFO:root:eval perplexity: 10.141450881958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/4
  2%|â–         | 4/200 [27:14<22:13:35, 408.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5197.311728200605
INFO:root:current train perplexity7.842038154602051
INFO:root:current mean train loss 5217.9735955391225
INFO:root:current train perplexity7.848240852355957
INFO:root:current mean train loss 5210.528185031115
INFO:root:current train perplexity7.837165355682373
INFO:root:current mean train loss 5214.623608914747
INFO:root:current train perplexity7.824130535125732
INFO:root:current mean train loss 5215.475610861369
INFO:root:current train perplexity7.808979034423828
INFO:root:current mean train loss 5196.935010777131
INFO:root:current train perplexity7.7670135498046875
INFO:root:current mean train loss 5189.023182138966
INFO:root:current train perplexity7.744487762451172
INFO:root:current mean train loss 5187.207737955284
INFO:root:current train perplexity7.729011535644531
INFO:root:current mean train loss 5174.433712441712
INFO:root:current train perplexity7.693816661834717
INFO:root:current mean train loss 5167.767991931559
INFO:root:current train perplexity7.67417573928833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.24s/it]
INFO:root:final mean train loss: 5161.854330739668
INFO:root:final train perplexity: 7.663746356964111
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 4809.66884488586
INFO:root:eval perplexity: 6.992855072021484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 5524.81912123227
INFO:root:eval perplexity: 9.575180053710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/5
  2%|â–Ž         | 5/200 [33:59<22:02:39, 406.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5143.420447716346
INFO:root:current train perplexity7.487550735473633
INFO:root:current mean train loss 5065.534970070818
INFO:root:current train perplexity7.3458943367004395
INFO:root:current mean train loss 5063.124775268044
INFO:root:current train perplexity7.328144550323486
INFO:root:current mean train loss 5047.992139968197
INFO:root:current train perplexity7.308267593383789
INFO:root:current mean train loss 5041.429483956791
INFO:root:current train perplexity7.298498630523682
INFO:root:current mean train loss 5036.414838858129
INFO:root:current train perplexity7.278609275817871
INFO:root:current mean train loss 5028.718400026897
INFO:root:current train perplexity7.261814117431641
INFO:root:current mean train loss 5021.229585350769
INFO:root:current train perplexity7.244978904724121
INFO:root:current mean train loss 5014.7163417666125
INFO:root:current train perplexity7.22737979888916
INFO:root:current mean train loss 5005.806733705238
INFO:root:current train perplexity7.202071666717529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.85s/it]
INFO:root:final mean train loss: 5004.805735188146
INFO:root:final train perplexity: 7.203310489654541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 4694.063632396941
INFO:root:eval perplexity: 6.673480987548828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it]
INFO:root:eval mean loss: 5428.118600398936
INFO:root:eval perplexity: 9.203948974609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/6
  3%|â–Ž         | 6/200 [40:44<21:54:04, 406.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4960.61602393617
INFO:root:current train perplexity7.008065223693848
INFO:root:current mean train loss 4901.7144152582905
INFO:root:current train perplexity6.924414157867432
INFO:root:current mean train loss 4904.8389344003035
INFO:root:current train perplexity6.934218406677246
INFO:root:current mean train loss 4920.067254761798
INFO:root:current train perplexity6.936162948608398
INFO:root:current mean train loss 4921.336327469589
INFO:root:current train perplexity6.943307399749756
INFO:root:current mean train loss 4908.809231996972
INFO:root:current train perplexity6.919530868530273
INFO:root:current mean train loss 4899.555770473097
INFO:root:current train perplexity6.9083251953125
INFO:root:current mean train loss 4899.056038607555
INFO:root:current train perplexity6.898007392883301
INFO:root:current mean train loss 4894.9203017774125
INFO:root:current train perplexity6.887081146240234
INFO:root:current mean train loss 4887.657176032867
INFO:root:current train perplexity6.867531776428223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.32s/it]
INFO:root:final mean train loss: 4884.0134444698215
INFO:root:final train perplexity: 6.8680806159973145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 4607.515829316268
INFO:root:eval perplexity: 6.443965911865234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 5352.2766961713205
INFO:root:eval perplexity: 8.92288589477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/7
  4%|â–Ž         | 7/200 [47:26<21:42:21, 404.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4803.36142578125
INFO:root:current train perplexity6.634112358093262
INFO:root:current mean train loss 4805.455084425404
INFO:root:current train perplexity6.668990135192871
INFO:root:current mean train loss 4800.068361289828
INFO:root:current train perplexity6.665131568908691
INFO:root:current mean train loss 4796.552800396127
INFO:root:current train perplexity6.655140399932861
INFO:root:current mean train loss 4797.865443638393
INFO:root:current train perplexity6.647496700286865
INFO:root:current mean train loss 4792.376385663007
INFO:root:current train perplexity6.636412143707275
INFO:root:current mean train loss 4791.520384064886
INFO:root:current train perplexity6.631600379943848
INFO:root:current mean train loss 4788.68823209851
INFO:root:current train perplexity6.619058609008789
INFO:root:current mean train loss 4793.335682223136
INFO:root:current train perplexity6.621507167816162
INFO:root:current mean train loss 4788.898549983639
INFO:root:current train perplexity6.608933448791504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.37s/it]
INFO:root:final mean train loss: 4786.222365963844
INFO:root:final train perplexity: 6.608147621154785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it]
INFO:root:eval mean loss: 4534.227409200465
INFO:root:eval perplexity: 6.255795001983643
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it]
INFO:root:eval mean loss: 5285.759187306073
INFO:root:eval perplexity: 8.683454513549805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/8
  4%|â–         | 8/200 [54:08<21:32:45, 403.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4727.301657056051
INFO:root:current train perplexity6.399008274078369
INFO:root:current mean train loss 4734.1553992523
INFO:root:current train perplexity6.4339165687561035
INFO:root:current mean train loss 4736.489142704372
INFO:root:current train perplexity6.436114311218262
INFO:root:current mean train loss 4735.6107174371555
INFO:root:current train perplexity6.4436445236206055
INFO:root:current mean train loss 4731.683640152538
INFO:root:current train perplexity6.428234100341797
INFO:root:current mean train loss 4720.99192558004
INFO:root:current train perplexity6.418426990509033
INFO:root:current mean train loss 4719.3486328125
INFO:root:current train perplexity6.423277378082275
INFO:root:current mean train loss 4714.586359226531
INFO:root:current train perplexity6.412909030914307
INFO:root:current mean train loss 4710.834558091324
INFO:root:current train perplexity6.406984806060791
INFO:root:current mean train loss 4708.845815181237
INFO:root:current train perplexity6.4020676612854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.28s/it]
INFO:root:final mean train loss: 4705.21677718624
INFO:root:final train perplexity: 6.400295257568359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it]
INFO:root:eval mean loss: 4477.497769835993
INFO:root:eval perplexity: 6.1139235496521
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 5239.079442666777
INFO:root:eval perplexity: 8.519277572631836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/9
  4%|â–         | 9/200 [1:00:50<21:24:20, 403.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4662.987903003961
INFO:root:current train perplexity6.287505626678467
INFO:root:current mean train loss 4649.840159276772
INFO:root:current train perplexity6.254417896270752
INFO:root:current mean train loss 4643.928782107645
INFO:root:current train perplexity6.262012004852295
INFO:root:current mean train loss 4633.705313052771
INFO:root:current train perplexity6.244781017303467
INFO:root:current mean train loss 4644.391577200272
INFO:root:current train perplexity6.248206615447998
INFO:root:current mean train loss 4634.240074037461
INFO:root:current train perplexity6.237558364868164
INFO:root:current mean train loss 4632.0166776063015
INFO:root:current train perplexity6.235768795013428
INFO:root:current mean train loss 4632.688906895975
INFO:root:current train perplexity6.223582744598389
INFO:root:current mean train loss 4635.94071531241
INFO:root:current train perplexity6.226606845855713
INFO:root:current mean train loss 4637.226918276503
INFO:root:current train perplexity6.224113941192627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.80s/it]
INFO:root:final mean train loss: 4635.217707234045
INFO:root:final train perplexity: 6.225958824157715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 4427.672098362699
INFO:root:eval perplexity: 5.991973400115967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 5195.214575368462
INFO:root:eval perplexity: 8.367830276489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/10
  5%|â–Œ         | 10/200 [1:07:30<21:14:15, 402.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4596.974909142603
INFO:root:current train perplexity6.081075668334961
INFO:root:current mean train loss 4588.32028249389
INFO:root:current train perplexity6.088644981384277
INFO:root:current mean train loss 4583.038294200829
INFO:root:current train perplexity6.0933122634887695
INFO:root:current mean train loss 4583.053264527333
INFO:root:current train perplexity6.084288597106934
INFO:root:current mean train loss 4585.927313882275
INFO:root:current train perplexity6.0884222984313965
INFO:root:current mean train loss 4584.979731268216
INFO:root:current train perplexity6.086133003234863
INFO:root:current mean train loss 4584.444544481775
INFO:root:current train perplexity6.08939790725708
INFO:root:current mean train loss 4581.567247109175
INFO:root:current train perplexity6.084158420562744
INFO:root:current mean train loss 4580.29510213355
INFO:root:current train perplexity6.081408500671387
INFO:root:current mean train loss 4576.8899112814415
INFO:root:current train perplexity6.0755085945129395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.55s/it]
INFO:root:final mean train loss: 4574.30560007403
INFO:root:final train perplexity: 6.078122615814209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 4392.108036555297
INFO:root:eval perplexity: 5.906418323516846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 5164.632748434729
INFO:root:eval perplexity: 8.263839721679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/11
  6%|â–Œ         | 11/200 [1:14:15<21:09:33, 403.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4520.289960488506
INFO:root:current train perplexity5.992881774902344
INFO:root:current mean train loss 4531.156563335561
INFO:root:current train perplexity5.9937744140625
INFO:root:current mean train loss 4528.078259404943
INFO:root:current train perplexity5.979903697967529
INFO:root:current mean train loss 4522.021278085635
INFO:root:current train perplexity5.965821266174316
INFO:root:current mean train loss 4520.787806203478
INFO:root:current train perplexity5.959014892578125
INFO:root:current mean train loss 4526.560711576341
INFO:root:current train perplexity5.956854343414307
INFO:root:current mean train loss 4527.630118424195
INFO:root:current train perplexity5.961215496063232
INFO:root:current mean train loss 4528.4270599636675
INFO:root:current train perplexity5.963536739349365
INFO:root:current mean train loss 4525.61218192908
INFO:root:current train perplexity5.9559478759765625
INFO:root:current mean train loss 4524.228659586342
INFO:root:current train perplexity5.950610160827637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.30s/it]
INFO:root:final mean train loss: 4520.414070683141
INFO:root:final train perplexity: 5.950254917144775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it]
INFO:root:eval mean loss: 4349.1821323692375
INFO:root:eval perplexity: 5.804779529571533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 5131.877507203014
INFO:root:eval perplexity: 8.153890609741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/12
  6%|â–Œ         | 12/200 [1:21:06<21:11:03, 405.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4472.241467927632
INFO:root:current train perplexity5.869968891143799
INFO:root:current mean train loss 4469.527750651042
INFO:root:current train perplexity5.860671520233154
INFO:root:current mean train loss 4473.316403767214
INFO:root:current train perplexity5.847699165344238
INFO:root:current mean train loss 4475.8481222804585
INFO:root:current train perplexity5.845909595489502
INFO:root:current mean train loss 4470.785161182134
INFO:root:current train perplexity5.83709716796875
INFO:root:current mean train loss 4475.054404789259
INFO:root:current train perplexity5.834970474243164
INFO:root:current mean train loss 4471.643097670301
INFO:root:current train perplexity5.834441661834717
INFO:root:current mean train loss 4470.114922059257
INFO:root:current train perplexity5.832698345184326
INFO:root:current mean train loss 4470.972326728352
INFO:root:current train perplexity5.832882404327393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.22s/it]
INFO:root:final mean train loss: 4471.652008918024
INFO:root:final train perplexity: 5.836878776550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it]
INFO:root:eval mean loss: 4318.247586297651
INFO:root:eval perplexity: 5.732619762420654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 5105.745808053524
INFO:root:eval perplexity: 8.067225456237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/13
  6%|â–‹         | 13/200 [1:28:00<21:11:48, 408.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4549.54052734375
INFO:root:current train perplexity5.8655829429626465
INFO:root:current mean train loss 4448.356075546117
INFO:root:current train perplexity5.757549285888672
INFO:root:current mean train loss 4436.441736982374
INFO:root:current train perplexity5.737344741821289
INFO:root:current mean train loss 4429.551233272741
INFO:root:current train perplexity5.736088752746582
INFO:root:current mean train loss 4433.843811792416
INFO:root:current train perplexity5.740965843200684
INFO:root:current mean train loss 4436.758478426317
INFO:root:current train perplexity5.753380298614502
INFO:root:current mean train loss 4434.656793749352
INFO:root:current train perplexity5.751323699951172
INFO:root:current mean train loss 4431.220861486487
INFO:root:current train perplexity5.747707843780518
INFO:root:current mean train loss 4432.027513401891
INFO:root:current train perplexity5.745632171630859
INFO:root:current mean train loss 4431.491300699059
INFO:root:current train perplexity5.739752292633057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.48s/it]
INFO:root:final mean train loss: 4427.820044671335
INFO:root:final train perplexity: 5.736809253692627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 4287.240565090315
INFO:root:eval perplexity: 5.661190032958984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it]
INFO:root:eval mean loss: 5078.164604457557
INFO:root:eval perplexity: 7.976752758026123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/14
  7%|â–‹         | 14/200 [1:34:51<21:07:21, 408.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4487.647971413352
INFO:root:current train perplexity5.672022342681885
INFO:root:current mean train loss 4394.739957242398
INFO:root:current train perplexity5.65438175201416
INFO:root:current mean train loss 4395.927533045764
INFO:root:current train perplexity5.6612043380737305
INFO:root:current mean train loss 4398.594186470056
INFO:root:current train perplexity5.661245346069336
INFO:root:current mean train loss 4383.764650813565
INFO:root:current train perplexity5.641270637512207
INFO:root:current mean train loss 4389.266631184259
INFO:root:current train perplexity5.644554138183594
INFO:root:current mean train loss 4389.4979150150875
INFO:root:current train perplexity5.6471781730651855
INFO:root:current mean train loss 4390.842951306478
INFO:root:current train perplexity5.645342826843262
INFO:root:current mean train loss 4391.527206778379
INFO:root:current train perplexity5.644467830657959
INFO:root:current mean train loss 4394.1169843621365
INFO:root:current train perplexity5.650706768035889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.40s/it]
INFO:root:final mean train loss: 4387.498660241404
INFO:root:final train perplexity: 5.646270751953125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it]
INFO:root:eval mean loss: 4265.87871924867
INFO:root:eval perplexity: 5.612499237060547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 5061.370659145057
INFO:root:eval perplexity: 7.922160625457764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/15
  8%|â–Š         | 15/200 [1:41:43<21:03:35, 409.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4316.962980571546
INFO:root:current train perplexity5.534339427947998
INFO:root:current mean train loss 4380.538631663603
INFO:root:current train perplexity5.5734639167785645
INFO:root:current mean train loss 4373.171482591324
INFO:root:current train perplexity5.573452472686768
INFO:root:current mean train loss 4363.980417472815
INFO:root:current train perplexity5.578270435333252
INFO:root:current mean train loss 4361.135217197755
INFO:root:current train perplexity5.5739521980285645
INFO:root:current mean train loss 4357.8194032055335
INFO:root:current train perplexity5.565631866455078
INFO:root:current mean train loss 4355.902214777489
INFO:root:current train perplexity5.562419891357422
INFO:root:current mean train loss 4358.734306749283
INFO:root:current train perplexity5.568835735321045
INFO:root:current mean train loss 4357.340445605826
INFO:root:current train perplexity5.568897247314453
INFO:root:current mean train loss 4357.105053790635
INFO:root:current train perplexity5.568536758422852

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.41s/it]
INFO:root:final mean train loss: 4350.2524745695055
INFO:root:final train perplexity: 5.563906669616699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it]
INFO:root:eval mean loss: 4245.079013256316
INFO:root:eval perplexity: 5.565491199493408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 5048.331939480829
INFO:root:eval perplexity: 7.880034446716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/16
  8%|â–Š         | 16/200 [1:48:26<20:50:46, 407.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4259.720287181713
INFO:root:current train perplexity5.312004089355469
INFO:root:current mean train loss 4321.834230437992
INFO:root:current train perplexity5.457183837890625
INFO:root:current mean train loss 4338.41717717511
INFO:root:current train perplexity5.502237796783447
INFO:root:current mean train loss 4323.313236154912
INFO:root:current train perplexity5.483320236206055
INFO:root:current mean train loss 4311.595068473726
INFO:root:current train perplexity5.481083393096924
INFO:root:current mean train loss 4307.448901413514
INFO:root:current train perplexity5.475350379943848
INFO:root:current mean train loss 4309.033604574736
INFO:root:current train perplexity5.47285795211792
INFO:root:current mean train loss 4306.597456773341
INFO:root:current train perplexity5.473768711090088
INFO:root:current mean train loss 4313.77577410586
INFO:root:current train perplexity5.484884738922119
INFO:root:current mean train loss 4316.899592624899
INFO:root:current train perplexity5.486478328704834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.58s/it]
INFO:root:final mean train loss: 4317.81100937628
INFO:root:final train perplexity: 5.493147373199463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.77s/it]
INFO:root:eval mean loss: 4224.793290807846
INFO:root:eval perplexity: 5.520025730133057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 5026.542722877881
INFO:root:eval perplexity: 7.8101372718811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/17
  8%|â–Š         | 17/200 [1:55:05<20:35:37, 405.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4269.378383091518
INFO:root:current train perplexity5.442383289337158
INFO:root:current mean train loss 4281.496721281828
INFO:root:current train perplexity5.397831916809082
INFO:root:current mean train loss 4290.6822546127
INFO:root:current train perplexity5.40712833404541
INFO:root:current mean train loss 4286.359321070429
INFO:root:current train perplexity5.4136552810668945
INFO:root:current mean train loss 4296.456269643499
INFO:root:current train perplexity5.433246612548828
INFO:root:current mean train loss 4290.837696225175
INFO:root:current train perplexity5.433450698852539
INFO:root:current mean train loss 4297.949039969857
INFO:root:current train perplexity5.433344841003418
INFO:root:current mean train loss 4292.552342753507
INFO:root:current train perplexity5.428899765014648
INFO:root:current mean train loss 4290.356594135947
INFO:root:current train perplexity5.425224304199219
INFO:root:current mean train loss 4287.2658020345925
INFO:root:current train perplexity5.422574520111084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.34s/it]
INFO:root:final mean train loss: 4285.137562967116
INFO:root:final train perplexity: 5.422791957855225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 4205.633080881538
INFO:root:eval perplexity: 5.477421760559082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 5016.557205091977
INFO:root:eval perplexity: 7.778308391571045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/18
  9%|â–‰         | 18/200 [2:01:47<20:25:54, 404.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4196.917514534884
INFO:root:current train perplexity5.301383972167969
INFO:root:current mean train loss 4245.168434836648
INFO:root:current train perplexity5.343076705932617
INFO:root:current mean train loss 4246.2581269692
INFO:root:current train perplexity5.34490442276001
INFO:root:current mean train loss 4255.4306042729595
INFO:root:current train perplexity5.36238431930542
INFO:root:current mean train loss 4251.3252476677135
INFO:root:current train perplexity5.357552528381348
INFO:root:current mean train loss 4255.225088214347
INFO:root:current train perplexity5.360642433166504
INFO:root:current mean train loss 4260.340687041335
INFO:root:current train perplexity5.367727756500244
INFO:root:current mean train loss 4258.912633143716
INFO:root:current train perplexity5.365426063537598
INFO:root:current mean train loss 4263.207966108764
INFO:root:current train perplexity5.366760730743408
INFO:root:current mean train loss 4260.217110918031
INFO:root:current train perplexity5.365346431732178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.84s/it]
INFO:root:final mean train loss: 4256.842130045737
INFO:root:final train perplexity: 5.362591743469238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 4189.778744528479
INFO:root:eval perplexity: 5.442417621612549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 5005.324701836768
INFO:root:eval perplexity: 7.742665767669678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/19
 10%|â–‰         | 19/200 [2:08:30<20:18:03, 403.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4247.94149241728
INFO:root:current train perplexity5.307696342468262
INFO:root:current mean train loss 4244.14113753363
INFO:root:current train perplexity5.32302713394165
INFO:root:current mean train loss 4236.172361335906
INFO:root:current train perplexity5.308564186096191
INFO:root:current mean train loss 4227.834999888711
INFO:root:current train perplexity5.293261528015137
INFO:root:current mean train loss 4231.330264884458
INFO:root:current train perplexity5.294559478759766
INFO:root:current mean train loss 4232.290910170429
INFO:root:current train perplexity5.303218364715576
INFO:root:current mean train loss 4229.162388017833
INFO:root:current train perplexity5.301914691925049
INFO:root:current mean train loss 4230.456271520785
INFO:root:current train perplexity5.3072052001953125
INFO:root:current mean train loss 4237.242052663227
INFO:root:current train perplexity5.311668395996094
INFO:root:current mean train loss 4232.330968943053
INFO:root:current train perplexity5.3058552742004395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.72s/it]
INFO:root:final mean train loss: 4229.6833192148515
INFO:root:final train perplexity: 5.305438995361328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it]
INFO:root:eval mean loss: 4174.156023174313
INFO:root:eval perplexity: 5.408144950866699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 4994.0647007286125
INFO:root:eval perplexity: 7.70709753036499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/20
 10%|â–ˆ         | 20/200 [2:15:14<20:12:22, 404.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4190.872728250794
INFO:root:current train perplexity5.230978012084961
INFO:root:current mean train loss 4200.807184183373
INFO:root:current train perplexity5.240647315979004
INFO:root:current mean train loss 4208.906761846947
INFO:root:current train perplexity5.250948905944824
INFO:root:current mean train loss 4210.86404155423
INFO:root:current train perplexity5.252903461456299
INFO:root:current mean train loss 4214.9978809232025
INFO:root:current train perplexity5.26141881942749
INFO:root:current mean train loss 4216.031353508637
INFO:root:current train perplexity5.261844635009766
INFO:root:current mean train loss 4210.21564582049
INFO:root:current train perplexity5.254671573638916
INFO:root:current mean train loss 4206.837254058074
INFO:root:current train perplexity5.252315998077393
INFO:root:current mean train loss 4204.843294119252
INFO:root:current train perplexity5.2527384757995605
INFO:root:current mean train loss 4207.921394101521
INFO:root:current train perplexity5.251895427703857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.18s/it]
INFO:root:final mean train loss: 4204.9232593659435
INFO:root:final train perplexity: 5.253864765167236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 4158.909037705009
INFO:root:eval perplexity: 5.374904155731201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 4977.467918882979
INFO:root:eval perplexity: 7.65496826171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/21
 10%|â–ˆ         | 21/200 [2:21:54<20:01:30, 402.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4199.222772854478
INFO:root:current train perplexity5.2124223709106445
INFO:root:current mean train loss 4199.81983299027
INFO:root:current train perplexity5.22725248336792
INFO:root:current mean train loss 4194.955325008778
INFO:root:current train perplexity5.215031623840332
INFO:root:current mean train loss 4186.578872722241
INFO:root:current train perplexity5.204993724822998
INFO:root:current mean train loss 4189.816939490765
INFO:root:current train perplexity5.2068939208984375
INFO:root:current mean train loss 4191.733485845872
INFO:root:current train perplexity5.210536956787109
INFO:root:current mean train loss 4183.212933450267
INFO:root:current train perplexity5.203847885131836
INFO:root:current mean train loss 4183.408230817613
INFO:root:current train perplexity5.2004852294921875
INFO:root:current mean train loss 4184.522425738448
INFO:root:current train perplexity5.2036542892456055
INFO:root:current mean train loss 4183.73032585073
INFO:root:current train perplexity5.2031121253967285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.55s/it]
INFO:root:final mean train loss: 4180.171349433161
INFO:root:final train perplexity: 5.202808380126953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 4148.904459635417
INFO:root:eval perplexity: 5.353202819824219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 4973.418689051418
INFO:root:eval perplexity: 7.642303466796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/22
 11%|â–ˆ         | 22/200 [2:28:36<19:53:52, 402.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.928977864583
INFO:root:current train perplexity5.116820812225342
INFO:root:current mean train loss 4157.680754743304
INFO:root:current train perplexity5.125441551208496
INFO:root:current mean train loss 4167.9997265625
INFO:root:current train perplexity5.148253917694092
INFO:root:current mean train loss 4154.53252734375
INFO:root:current train perplexity5.141631126403809
INFO:root:current mean train loss 4161.175523745888
INFO:root:current train perplexity5.142196178436279
INFO:root:current mean train loss 4163.962113196331
INFO:root:current train perplexity5.148547172546387
INFO:root:current mean train loss 4168.219169921875
INFO:root:current train perplexity5.159040451049805
INFO:root:current mean train loss 4164.90767546623
INFO:root:current train perplexity5.158904552459717
INFO:root:current mean train loss 4162.960349888393
INFO:root:current train perplexity5.157487869262695
INFO:root:current mean train loss 4161.8599005909455
INFO:root:current train perplexity5.15769100189209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.88s/it]
INFO:root:final mean train loss: 4157.962167247649
INFO:root:final train perplexity: 5.157419681549072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 4139.516624071919
INFO:root:eval perplexity: 5.332920551300049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 4965.223262272828
INFO:root:eval perplexity: 7.616734981536865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/23
 12%|â–ˆâ–        | 23/200 [2:35:17<19:45:46, 401.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4131.861678157944
INFO:root:current train perplexity5.102309226989746
INFO:root:current mean train loss 4142.463819159836
INFO:root:current train perplexity5.1221604347229
INFO:root:current mean train loss 4147.66625804025
INFO:root:current train perplexity5.12272834777832
INFO:root:current mean train loss 4156.173230841016
INFO:root:current train perplexity5.127974510192871
INFO:root:current mean train loss 4147.287514254173
INFO:root:current train perplexity5.121551036834717
INFO:root:current mean train loss 4143.968776801029
INFO:root:current train perplexity5.114479064941406
INFO:root:current mean train loss 4145.876347599057
INFO:root:current train perplexity5.114523410797119
INFO:root:current mean train loss 4142.027504639607
INFO:root:current train perplexity5.112318992614746
INFO:root:current mean train loss 4141.254358587556
INFO:root:current train perplexity5.1157612800598145
INFO:root:current mean train loss 4139.722651282744
INFO:root:current train perplexity5.113295078277588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.80s/it]
INFO:root:final mean train loss: 4135.887583086567
INFO:root:final train perplexity: 5.112699031829834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 4125.520649794991
INFO:root:eval perplexity: 5.302823066711426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 4954.828956117021
INFO:root:eval perplexity: 7.584430694580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/24
 12%|â–ˆâ–        | 24/200 [2:41:53<19:34:27, 400.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4132.360348879636
INFO:root:current train perplexity5.050004482269287
INFO:root:current mean train loss 4120.766985029451
INFO:root:current train perplexity5.059679985046387
INFO:root:current mean train loss 4108.659010215313
INFO:root:current train perplexity5.054564476013184
INFO:root:current mean train loss 4105.581595418398
INFO:root:current train perplexity5.0593953132629395
INFO:root:current mean train loss 4113.456162089486
INFO:root:current train perplexity5.0643768310546875
INFO:root:current mean train loss 4114.741266705663
INFO:root:current train perplexity5.068134307861328
INFO:root:current mean train loss 4118.174924461266
INFO:root:current train perplexity5.0672712326049805
INFO:root:current mean train loss 4119.711722392048
INFO:root:current train perplexity5.067636966705322
INFO:root:current mean train loss 4117.469472009592
INFO:root:current train perplexity5.068440914154053
INFO:root:current mean train loss 4116.976301607042
INFO:root:current train perplexity5.0684003829956055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.30s/it]
INFO:root:final mean train loss: 4113.894793356619
INFO:root:final train perplexity: 5.068528652191162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 4115.603262826906
INFO:root:eval perplexity: 5.281600475311279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it]
INFO:root:eval mean loss: 4949.155910627216
INFO:root:eval perplexity: 7.566858291625977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/25
 12%|â–ˆâ–Ž        | 25/200 [2:48:30<19:24:14, 399.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4104.692548038984
INFO:root:current train perplexity5.034963607788086
INFO:root:current mean train loss 4097.746038542321
INFO:root:current train perplexity5.024119853973389
INFO:root:current mean train loss 4106.4634605586325
INFO:root:current train perplexity5.029863357543945
INFO:root:current mean train loss 4101.695870535715
INFO:root:current train perplexity5.029476642608643
INFO:root:current mean train loss 4096.955104545028
INFO:root:current train perplexity5.0264081954956055
INFO:root:current mean train loss 4099.859861243348
INFO:root:current train perplexity5.028224468231201
INFO:root:current mean train loss 4097.246364435242
INFO:root:current train perplexity5.028241157531738
INFO:root:current mean train loss 4097.086975479603
INFO:root:current train perplexity5.0258402824401855
INFO:root:current mean train loss 4095.413501166661
INFO:root:current train perplexity5.0283894538879395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.94s/it]
INFO:root:final mean train loss: 4095.7507977639475
INFO:root:final train perplexity: 5.032376289367676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4109.990300171764
INFO:root:eval perplexity: 5.269626140594482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 4942.034070603391
INFO:root:eval perplexity: 7.544853687286377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/26
 13%|â–ˆâ–Ž        | 26/200 [2:55:07<19:15:49, 398.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4078.005301339286
INFO:root:current train perplexity4.93105411529541
INFO:root:current mean train loss 4065.0274943414133
INFO:root:current train perplexity4.951742172241211
INFO:root:current mean train loss 4063.340779032684
INFO:root:current train perplexity4.970523834228516
INFO:root:current mean train loss 4076.6297953354033
INFO:root:current train perplexity4.974609851837158
INFO:root:current mean train loss 4075.2525355833463
INFO:root:current train perplexity4.97589635848999
INFO:root:current mean train loss 4074.1623655541175
INFO:root:current train perplexity4.977309703826904
INFO:root:current mean train loss 4072.2404757001646
INFO:root:current train perplexity4.978225231170654
INFO:root:current mean train loss 4076.6843444737888
INFO:root:current train perplexity4.985664367675781
INFO:root:current mean train loss 4076.0656435752594
INFO:root:current train perplexity4.988007068634033
INFO:root:current mean train loss 4078.402770121279
INFO:root:current train perplexity4.994664192199707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.17s/it]
INFO:root:final mean train loss: 4076.187847937307
INFO:root:final train perplexity: 4.993684768676758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 4101.106126717642
INFO:root:eval perplexity: 5.250729560852051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 4935.7711917525485
INFO:root:eval perplexity: 7.52555513381958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/27
 14%|â–ˆâ–Ž        | 27/200 [3:01:43<19:07:36, 398.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4088.4137369791665
INFO:root:current train perplexity4.9947509765625
INFO:root:current mean train loss 4013.791563349185
INFO:root:current train perplexity4.909873008728027
INFO:root:current mean train loss 4041.5075388353926
INFO:root:current train perplexity4.926873207092285
INFO:root:current mean train loss 4053.591187686012
INFO:root:current train perplexity4.946238994598389
INFO:root:current mean train loss 4051.4279132153615
INFO:root:current train perplexity4.951547622680664
INFO:root:current mean train loss 4050.08833481872
INFO:root:current train perplexity4.9515509605407715
INFO:root:current mean train loss 4052.526064691311
INFO:root:current train perplexity4.953412055969238
INFO:root:current mean train loss 4058.071387401661
INFO:root:current train perplexity4.954850196838379
INFO:root:current mean train loss 4059.6974028230443
INFO:root:current train perplexity4.9569807052612305
INFO:root:current mean train loss 4060.127900070441
INFO:root:current train perplexity4.957298755645752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it]
INFO:root:final mean train loss: 4058.436314367479
INFO:root:final train perplexity: 4.958833694458008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 4090.868307776485
INFO:root:eval perplexity: 5.229036331176758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 4928.977462876773
INFO:root:eval perplexity: 7.5046796798706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/28
 14%|â–ˆâ–        | 28/200 [3:08:20<18:59:35, 397.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4040.35352623981
INFO:root:current train perplexity4.906600475311279
INFO:root:current mean train loss 4030.029544985391
INFO:root:current train perplexity4.914680480957031
INFO:root:current mean train loss 4037.2230755587866
INFO:root:current train perplexity4.91060209274292
INFO:root:current mean train loss 4055.1369644023316
INFO:root:current train perplexity4.9270758628845215
INFO:root:current mean train loss 4052.5176825917924
INFO:root:current train perplexity4.926969528198242
INFO:root:current mean train loss 4049.0304475569133
INFO:root:current train perplexity4.925488471984863
INFO:root:current mean train loss 4048.294149089587
INFO:root:current train perplexity4.926633358001709
INFO:root:current mean train loss 4045.898979809604
INFO:root:current train perplexity4.919674873352051
INFO:root:current mean train loss 4043.0970148988076
INFO:root:current train perplexity4.918614864349365
INFO:root:current mean train loss 4043.7789842268758
INFO:root:current train perplexity4.921037197113037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.15s/it]
INFO:root:final mean train loss: 4040.9498642952212
INFO:root:final train perplexity: 4.924740791320801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 4083.6520805629434
INFO:root:eval perplexity: 5.213800430297852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 4926.390595564605
INFO:root:eval perplexity: 7.496743202209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/29
 14%|â–ˆâ–        | 29/200 [3:14:54<18:50:18, 396.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3962.8384970388106
INFO:root:current train perplexity4.851888179779053
INFO:root:current mean train loss 4023.349657830391
INFO:root:current train perplexity4.883999347686768
INFO:root:current mean train loss 4025.783035080154
INFO:root:current train perplexity4.892658233642578
INFO:root:current mean train loss 4026.166571764067
INFO:root:current train perplexity4.896594524383545
INFO:root:current mean train loss 4024.243653476653
INFO:root:current train perplexity4.886892318725586
INFO:root:current mean train loss 4029.7638700381062
INFO:root:current train perplexity4.889636039733887
INFO:root:current mean train loss 4029.6175337850386
INFO:root:current train perplexity4.889074802398682
INFO:root:current mean train loss 4028.2510052849266
INFO:root:current train perplexity4.891565799713135
INFO:root:current mean train loss 4026.112834099541
INFO:root:current train perplexity4.889436721801758
INFO:root:current mean train loss 4027.4259375419574
INFO:root:current train perplexity4.891122817993164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.69s/it]
INFO:root:final mean train loss: 4023.9797946560766
INFO:root:final train perplexity: 4.891878604888916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 4081.874681405142
INFO:root:eval perplexity: 5.210054397583008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 4925.563071392952
INFO:root:eval perplexity: 7.494207382202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/30
 15%|â–ˆâ–Œ        | 30/200 [3:21:29<18:42:28, 396.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4010.946232722356
INFO:root:current train perplexity4.875615119934082
INFO:root:current mean train loss 4010.0679290551934
INFO:root:current train perplexity4.857663154602051
INFO:root:current mean train loss 4006.4617976104864
INFO:root:current train perplexity4.863754749298096
INFO:root:current mean train loss 4013.3214251762997
INFO:root:current train perplexity4.857728958129883
INFO:root:current mean train loss 4015.5215199672552
INFO:root:current train perplexity4.86484432220459
INFO:root:current mean train loss 4017.7282329835343
INFO:root:current train perplexity4.86578893661499
INFO:root:current mean train loss 4017.862995464104
INFO:root:current train perplexity4.865759372711182
INFO:root:current mean train loss 4020.7572925035943
INFO:root:current train perplexity4.8711724281311035
INFO:root:current mean train loss 4014.7521274280207
INFO:root:current train perplexity4.864234447479248
INFO:root:current mean train loss 4011.455502706087
INFO:root:current train perplexity4.863102436065674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it]
INFO:root:final mean train loss: 4008.234370754611
INFO:root:final train perplexity: 4.861584186553955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 4073.778107338763
INFO:root:eval perplexity: 5.193024635314941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 4923.585792054521
INFO:root:eval perplexity: 7.488150596618652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/31
 16%|â–ˆâ–Œ        | 31/200 [3:28:04<18:34:08, 395.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3973.1268076795213
INFO:root:current train perplexity4.81496000289917
INFO:root:current mean train loss 3991.0363586840986
INFO:root:current train perplexity4.829531669616699
INFO:root:current mean train loss 3989.3516801224064
INFO:root:current train perplexity4.824156761169434
INFO:root:current mean train loss 3994.5722480356176
INFO:root:current train perplexity4.824456691741943
INFO:root:current mean train loss 3999.8190519260347
INFO:root:current train perplexity4.827398300170898
INFO:root:current mean train loss 3997.4644541069183
INFO:root:current train perplexity4.8262619972229
INFO:root:current mean train loss 3999.5648417878188
INFO:root:current train perplexity4.830592155456543
INFO:root:current mean train loss 3995.939724065533
INFO:root:current train perplexity4.82763671875
INFO:root:current mean train loss 3994.135895243783
INFO:root:current train perplexity4.825934410095215
INFO:root:current mean train loss 3994.8127181023956
INFO:root:current train perplexity4.829321384429932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.28s/it]
INFO:root:final mean train loss: 3992.10372401822
INFO:root:final train perplexity: 4.830743789672852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 4063.868477462877
INFO:root:eval perplexity: 5.172256946563721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it]
INFO:root:eval mean loss: 4914.4826729416
INFO:root:eval perplexity: 7.460328578948975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/32
 16%|â–ˆâ–Œ        | 32/200 [3:34:38<18:26:25, 395.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3937.0899280894887
INFO:root:current train perplexity4.760461330413818
INFO:root:current mean train loss 3965.4354366179437
INFO:root:current train perplexity4.782632827758789
INFO:root:current mean train loss 3971.4712727864585
INFO:root:current train perplexity4.785438537597656
INFO:root:current mean train loss 3973.1585965008803
INFO:root:current train perplexity4.7870283126831055
INFO:root:current mean train loss 3969.7909249441964
INFO:root:current train perplexity4.783670425415039
INFO:root:current mean train loss 3971.2354615357544
INFO:root:current train perplexity4.787754535675049
INFO:root:current mean train loss 3977.495938692748
INFO:root:current train perplexity4.793325901031494
INFO:root:current mean train loss 3977.5501280525664
INFO:root:current train perplexity4.797153472900391
INFO:root:current mean train loss 3977.803422823008
INFO:root:current train perplexity4.796483516693115
INFO:root:current mean train loss 3977.8126035360765
INFO:root:current train perplexity4.799723148345947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.16s/it]
INFO:root:final mean train loss: 3976.8778510555144
INFO:root:final train perplexity: 4.801811218261719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 4062.3446728861923
INFO:root:eval perplexity: 5.169071197509766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 4914.95925795102
INFO:root:eval perplexity: 7.461781978607178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/33
 16%|â–ˆâ–‹        | 33/200 [3:41:12<18:19:06, 394.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3927.1331457713295
INFO:root:current train perplexity4.734795570373535
INFO:root:current mean train loss 3952.5237640193636
INFO:root:current train perplexity4.751715660095215
INFO:root:current mean train loss 3956.3554121242278
INFO:root:current train perplexity4.757618427276611
INFO:root:current mean train loss 3956.551680467674
INFO:root:current train perplexity4.754223346710205
INFO:root:current mean train loss 3964.590299338553
INFO:root:current train perplexity4.7602996826171875
INFO:root:current mean train loss 3965.732252754496
INFO:root:current train perplexity4.768004894256592
INFO:root:current mean train loss 3959.7011792397248
INFO:root:current train perplexity4.764050483703613
INFO:root:current mean train loss 3964.0055384404695
INFO:root:current train perplexity4.771981716156006
INFO:root:current mean train loss 3961.059198867957
INFO:root:current train perplexity4.768983364105225
INFO:root:current mean train loss 3965.046845338055
INFO:root:current train perplexity4.773500919342041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it]
INFO:root:final mean train loss: 3962.4831136888074
INFO:root:final train perplexity: 4.7746195793151855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 4055.0470221769724
INFO:root:eval perplexity: 5.153839588165283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 4910.884730995124
INFO:root:eval perplexity: 7.449360370635986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/34
 17%|â–ˆâ–‹        | 34/200 [3:47:48<18:13:13, 395.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3910.9857057383365
INFO:root:current train perplexity4.705379486083984
INFO:root:current mean train loss 3923.23998309576
INFO:root:current train perplexity4.7091593742370605
INFO:root:current mean train loss 3935.5592901363584
INFO:root:current train perplexity4.718679428100586
INFO:root:current mean train loss 3949.2463964580525
INFO:root:current train perplexity4.736484050750732
INFO:root:current mean train loss 3951.1706330447187
INFO:root:current train perplexity4.743041038513184
INFO:root:current mean train loss 3948.4982332941113
INFO:root:current train perplexity4.744894504547119
INFO:root:current mean train loss 3947.0481808430745
INFO:root:current train perplexity4.746807098388672
INFO:root:current mean train loss 3949.6452440392954
INFO:root:current train perplexity4.745818614959717
INFO:root:current mean train loss 3949.927135655855
INFO:root:current train perplexity4.748931407928467
INFO:root:current mean train loss 3952.4663362512874
INFO:root:current train perplexity4.748998165130615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.53s/it]
INFO:root:final mean train loss: 3949.0241358972366
INFO:root:final train perplexity: 4.749333381652832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 4054.8732113669103
INFO:root:eval perplexity: 5.153477191925049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4912.855402953236
INFO:root:eval perplexity: 7.4553656578063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/35
 18%|â–ˆâ–Š        | 35/200 [3:54:24<18:07:30, 395.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3945.2798716871043
INFO:root:current train perplexity4.771793365478516
INFO:root:current mean train loss 3935.7275458820704
INFO:root:current train perplexity4.728022575378418
INFO:root:current mean train loss 3937.4964210209455
INFO:root:current train perplexity4.732247352600098
INFO:root:current mean train loss 3938.647907991837
INFO:root:current train perplexity4.731954574584961
INFO:root:current mean train loss 3940.1204729498304
INFO:root:current train perplexity4.727367401123047
INFO:root:current mean train loss 3937.145449201884
INFO:root:current train perplexity4.72062873840332
INFO:root:current mean train loss 3934.5032137391845
INFO:root:current train perplexity4.718734264373779
INFO:root:current mean train loss 3937.4861726773106
INFO:root:current train perplexity4.718647003173828
INFO:root:current mean train loss 3937.469763780752
INFO:root:current train perplexity4.7208075523376465
INFO:root:current mean train loss 3937.279752737168
INFO:root:current train perplexity4.722647190093994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.87s/it]
INFO:root:final mean train loss: 3934.4375166739187
INFO:root:final train perplexity: 4.722080230712891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4046.3226656000666
INFO:root:eval perplexity: 5.135690212249756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 4908.516050947474
INFO:root:eval perplexity: 7.442149639129639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/36
 18%|â–ˆâ–Š        | 36/200 [4:01:00<18:01:34, 395.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3927.2532018902657
INFO:root:current train perplexity4.675899028778076
INFO:root:current mean train loss 3931.364063283339
INFO:root:current train perplexity4.680663108825684
INFO:root:current mean train loss 3919.9316210597235
INFO:root:current train perplexity4.674375534057617
INFO:root:current mean train loss 3916.0800251332366
INFO:root:current train perplexity4.680917739868164
INFO:root:current mean train loss 3915.2095588825077
INFO:root:current train perplexity4.684732913970947
INFO:root:current mean train loss 3919.7039114904974
INFO:root:current train perplexity4.680038928985596
INFO:root:current mean train loss 3921.3311996793122
INFO:root:current train perplexity4.685094356536865
INFO:root:current mean train loss 3921.597269099428
INFO:root:current train perplexity4.689605236053467
INFO:root:current mean train loss 3922.641468620085
INFO:root:current train perplexity4.692353248596191
INFO:root:current mean train loss 3925.4669371259974
INFO:root:current train perplexity4.700113773345947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.57s/it]
INFO:root:final mean train loss: 3922.700624404415
INFO:root:final train perplexity: 4.700264930725098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 4042.7798578789893
INFO:root:eval perplexity: 5.128337383270264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 4905.872028756649
INFO:root:eval perplexity: 7.434107303619385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/37
 18%|â–ˆâ–Š        | 37/200 [4:07:36<17:55:17, 395.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.37173879523
INFO:root:current train perplexity4.6414666175842285
INFO:root:current mean train loss 3910.226652644231
INFO:root:current train perplexity4.656772136688232
INFO:root:current mean train loss 3906.4141146385064
INFO:root:current train perplexity4.66737174987793
INFO:root:current mean train loss 3906.232790249209
INFO:root:current train perplexity4.663754463195801
INFO:root:current mean train loss 3907.8574149700125
INFO:root:current train perplexity4.66284704208374
INFO:root:current mean train loss 3906.926335592831
INFO:root:current train perplexity4.6604790687561035
INFO:root:current mean train loss 3908.8133968216052
INFO:root:current train perplexity4.661955833435059
INFO:root:current mean train loss 3909.5584681480937
INFO:root:current train perplexity4.668391704559326
INFO:root:current mean train loss 3910.8382790677374
INFO:root:current train perplexity4.671623229980469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.50s/it]
INFO:root:final mean train loss: 3908.205777260565
INFO:root:final train perplexity: 4.673462867736816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 4040.9077806405144
INFO:root:eval perplexity: 5.124456882476807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 4907.479223805962
INFO:root:eval perplexity: 7.438993453979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/38
 19%|â–ˆâ–‰        | 38/200 [4:14:12<17:48:15, 395.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.7364908854165
INFO:root:current train perplexity4.747790813446045
INFO:root:current mean train loss 3891.2404168878943
INFO:root:current train perplexity4.630984306335449
INFO:root:current mean train loss 3887.1149794104062
INFO:root:current train perplexity4.629103183746338
INFO:root:current mean train loss 3890.6713931647073
INFO:root:current train perplexity4.633647441864014
INFO:root:current mean train loss 3897.4720674046216
INFO:root:current train perplexity4.64682674407959
INFO:root:current mean train loss 3902.797298241799
INFO:root:current train perplexity4.6482062339782715
INFO:root:current mean train loss 3904.7639216838984
INFO:root:current train perplexity4.650661945343018
INFO:root:current mean train loss 3901.7694617932075
INFO:root:current train perplexity4.649680137634277
INFO:root:current mean train loss 3900.211951458885
INFO:root:current train perplexity4.649352550506592
INFO:root:current mean train loss 3899.458659124533
INFO:root:current train perplexity4.6500020027160645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.96s/it]
INFO:root:final mean train loss: 3895.512269789173
INFO:root:final train perplexity: 4.650116443634033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 4037.9276027814717
INFO:root:eval perplexity: 5.118285179138184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 4905.136576767509
INFO:root:eval perplexity: 7.431872367858887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/39
 20%|â–ˆâ–‰        | 39/200 [4:20:47<17:41:49, 395.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3880.690518465909
INFO:root:current train perplexity4.679211616516113
INFO:root:current mean train loss 3869.8928332629503
INFO:root:current train perplexity4.607608318328857
INFO:root:current mean train loss 3870.380417376333
INFO:root:current train perplexity4.608158588409424
INFO:root:current mean train loss 3869.474410765424
INFO:root:current train perplexity4.6157732009887695
INFO:root:current mean train loss 3876.1604663264143
INFO:root:current train perplexity4.614360809326172
INFO:root:current mean train loss 3878.8795392956517
INFO:root:current train perplexity4.616835594177246
INFO:root:current mean train loss 3876.7565018923897
INFO:root:current train perplexity4.62183952331543
INFO:root:current mean train loss 3879.6472277849202
INFO:root:current train perplexity4.625338077545166
INFO:root:current mean train loss 3885.5390408253697
INFO:root:current train perplexity4.627036094665527
INFO:root:current mean train loss 3886.760684033257
INFO:root:current train perplexity4.627624034881592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.86s/it]
INFO:root:final mean train loss: 3883.8123749148463
INFO:root:final train perplexity: 4.628702163696289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 4031.8158313940603
INFO:root:eval perplexity: 5.105650424957275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 4901.882925047096
INFO:root:eval perplexity: 7.421989917755127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/40
 20%|â–ˆâ–ˆ        | 40/200 [4:27:25<17:36:31, 396.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3873.0220497532896
INFO:root:current train perplexity4.629720687866211
INFO:root:current mean train loss 3871.1454011292017
INFO:root:current train perplexity4.6073198318481445
INFO:root:current mean train loss 3877.9161661226453
INFO:root:current train perplexity4.596668720245361
INFO:root:current mean train loss 3877.1706481742262
INFO:root:current train perplexity4.600245952606201
INFO:root:current mean train loss 3879.7064940240903
INFO:root:current train perplexity4.604925155639648
INFO:root:current mean train loss 3884.2540803001566
INFO:root:current train perplexity4.607325077056885
INFO:root:current mean train loss 3878.712725366645
INFO:root:current train perplexity4.6060333251953125
INFO:root:current mean train loss 3876.1751975535685
INFO:root:current train perplexity4.60483455657959
INFO:root:current mean train loss 3873.416252909417
INFO:root:current train perplexity4.6048455238342285
INFO:root:current mean train loss 3874.199091499337
INFO:root:current train perplexity4.6052727699279785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.49s/it]
INFO:root:final mean train loss: 3870.6518963229273
INFO:root:final train perplexity: 4.60473108291626
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 4029.375657967642
INFO:root:eval perplexity: 5.100615978240967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 4901.206508338874
INFO:root:eval perplexity: 7.419937610626221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/41
 20%|â–ˆâ–ˆ        | 41/200 [4:34:01<17:29:50, 396.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3854.9697175202546
INFO:root:current train perplexity4.56507682800293
INFO:root:current mean train loss 3852.785154327633
INFO:root:current train perplexity4.582427501678467
INFO:root:current mean train loss 3855.756410035793
INFO:root:current train perplexity4.574867248535156
INFO:root:current mean train loss 3860.253232810111
INFO:root:current train perplexity4.578800201416016
INFO:root:current mean train loss 3854.1041811512
INFO:root:current train perplexity4.574692249298096
INFO:root:current mean train loss 3855.811628598642
INFO:root:current train perplexity4.574662208557129
INFO:root:current mean train loss 3859.7030140269885
INFO:root:current train perplexity4.579903602600098
INFO:root:current mean train loss 3860.5346928193776
INFO:root:current train perplexity4.5793561935424805
INFO:root:current mean train loss 3861.085883180925
INFO:root:current train perplexity4.581594467163086
INFO:root:current mean train loss 3861.728882230987
INFO:root:current train perplexity4.584095478057861

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.63s/it]
INFO:root:final mean train loss: 3859.394431083433
INFO:root:final train perplexity: 4.584324359893799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 4026.1593441794103
INFO:root:eval perplexity: 5.093985557556152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 4899.873301404587
INFO:root:eval perplexity: 7.415893077850342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/42
 21%|â–ˆâ–ˆ        | 42/200 [4:40:38<17:24:07, 396.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3877.3081682477678
INFO:root:current train perplexity4.585277080535889
INFO:root:current mean train loss 3834.7647804542826
INFO:root:current train perplexity4.5392165184021
INFO:root:current mean train loss 3839.83218188996
INFO:root:current train perplexity4.540306568145752
INFO:root:current mean train loss 3846.777038392024
INFO:root:current train perplexity4.5484442710876465
INFO:root:current mean train loss 3840.608844625539
INFO:root:current train perplexity4.54914665222168
INFO:root:current mean train loss 3842.898057827103
INFO:root:current train perplexity4.551911354064941
INFO:root:current mean train loss 3850.9212986743355
INFO:root:current train perplexity4.55900764465332
INFO:root:current mean train loss 3850.337491363733
INFO:root:current train perplexity4.5602707862854
INFO:root:current mean train loss 3851.7688900519274
INFO:root:current train perplexity4.562934875488281
INFO:root:current mean train loss 3851.9647972718917
INFO:root:current train perplexity4.563621520996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.55s/it]
INFO:root:final mean train loss: 3847.302346937118
INFO:root:final train perplexity: 4.562506198883057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 4023.11518416168
INFO:root:eval perplexity: 5.087719917297363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 4898.115800573471
INFO:root:eval perplexity: 7.4105658531188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/43
 22%|â–ˆâ–ˆâ–       | 43/200 [4:47:13<17:16:21, 396.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3845.3676133266713
INFO:root:current train perplexity4.530657768249512
INFO:root:current mean train loss 3821.89757873962
INFO:root:current train perplexity4.531406402587891
INFO:root:current mean train loss 3815.6088525591563
INFO:root:current train perplexity4.520574569702148
INFO:root:current mean train loss 3819.8948024382744
INFO:root:current train perplexity4.5159525871276855
INFO:root:current mean train loss 3827.1256905377045
INFO:root:current train perplexity4.520552158355713
INFO:root:current mean train loss 3830.415856011884
INFO:root:current train perplexity4.524190425872803
INFO:root:current mean train loss 3834.1801404700864
INFO:root:current train perplexity4.529863357543945
INFO:root:current mean train loss 3833.6197383259378
INFO:root:current train perplexity4.532083034515381
INFO:root:current mean train loss 3834.2139004925675
INFO:root:current train perplexity4.536019325256348
INFO:root:current mean train loss 3838.1661378247613
INFO:root:current train perplexity4.5422186851501465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.49s/it]
INFO:root:final mean train loss: 3836.859736842494
INFO:root:final train perplexity: 4.543747901916504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.70s/it]
INFO:root:eval mean loss: 4023.4409993489585
INFO:root:eval perplexity: 5.088389873504639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 4897.700053330009
INFO:root:eval perplexity: 7.409307956695557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/44
 22%|â–ˆâ–ˆâ–       | 44/200 [4:53:48<17:08:57, 395.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3838.2169596354165
INFO:root:current train perplexity4.574939727783203
INFO:root:current mean train loss 3835.258900623448
INFO:root:current train perplexity4.529885292053223
INFO:root:current mean train loss 3833.869157160421
INFO:root:current train perplexity4.526768684387207
INFO:root:current mean train loss 3824.0789673199342
INFO:root:current train perplexity4.514118194580078
INFO:root:current mean train loss 3820.742260579788
INFO:root:current train perplexity4.508862495422363
INFO:root:current mean train loss 3818.552682533887
INFO:root:current train perplexity4.511857032775879
INFO:root:current mean train loss 3822.0401545698924
INFO:root:current train perplexity4.51478385925293
INFO:root:current mean train loss 3825.692572013357
INFO:root:current train perplexity4.518372058868408
INFO:root:current mean train loss 3828.824034855593
INFO:root:current train perplexity4.5260467529296875
INFO:root:current mean train loss 3830.975917106171
INFO:root:current train perplexity4.527169704437256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.78s/it]
INFO:root:final mean train loss: 3827.6278818192022
INFO:root:final train perplexity: 4.527228832244873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.61s/it]
INFO:root:eval mean loss: 4021.78584538453
INFO:root:eval perplexity: 5.084985256195068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 4904.1407617880095
INFO:root:eval perplexity: 7.428844928741455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:00:24<17:02:21, 395.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3790.1026921676375
INFO:root:current train perplexity4.492695331573486
INFO:root:current mean train loss 3816.0422670376374
INFO:root:current train perplexity4.502331733703613
INFO:root:current mean train loss 3816.351497458675
INFO:root:current train perplexity4.511427879333496
INFO:root:current mean train loss 3807.1498819420262
INFO:root:current train perplexity4.501160621643066
INFO:root:current mean train loss 3804.903352226307
INFO:root:current train perplexity4.495185852050781
INFO:root:current mean train loss 3810.4353909569263
INFO:root:current train perplexity4.500147342681885
INFO:root:current mean train loss 3808.4247617128226
INFO:root:current train perplexity4.49521541595459
INFO:root:current mean train loss 3811.163253844491
INFO:root:current train perplexity4.499957084655762
INFO:root:current mean train loss 3815.6529690228463
INFO:root:current train perplexity4.50229549407959
INFO:root:current mean train loss 3818.657983933052
INFO:root:current train perplexity4.505370140075684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.69s/it]
INFO:root:final mean train loss: 3815.8685950002364
INFO:root:final train perplexity: 4.50627326965332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 4018.0229613392066
INFO:root:eval perplexity: 5.077253818511963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 4899.805967073914
INFO:root:eval perplexity: 7.415691375732422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:07:00<16:56:21, 395.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3787.079207235308
INFO:root:current train perplexity4.43843412399292
INFO:root:current mean train loss 3803.429494526572
INFO:root:current train perplexity4.478349685668945
INFO:root:current mean train loss 3803.587291703242
INFO:root:current train perplexity4.480810642242432
INFO:root:current mean train loss 3797.6802196866483
INFO:root:current train perplexity4.473751544952393
INFO:root:current mean train loss 3796.0009577422375
INFO:root:current train perplexity4.470966339111328
INFO:root:current mean train loss 3800.6727051642415
INFO:root:current train perplexity4.479722023010254
INFO:root:current mean train loss 3801.0013081837988
INFO:root:current train perplexity4.4816203117370605
INFO:root:current mean train loss 3804.484524603773
INFO:root:current train perplexity4.483713626861572
INFO:root:current mean train loss 3807.6160186098796
INFO:root:current train perplexity4.486141681671143
INFO:root:current mean train loss 3806.303482702624
INFO:root:current train perplexity4.485635280609131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.91s/it]
INFO:root:final mean train loss: 3804.6580682569934
INFO:root:final train perplexity: 4.486386775970459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 4016.829731826241
INFO:root:eval perplexity: 5.074803829193115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 4901.14197556516
INFO:root:eval perplexity: 7.419741153717041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:13:38<16:50:49, 396.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3776.456943359375
INFO:root:current train perplexity4.39551305770874
INFO:root:current mean train loss 3783.614235491071
INFO:root:current train perplexity4.441970348358154
INFO:root:current mean train loss 3791.9826873224433
INFO:root:current train perplexity4.453952789306641
INFO:root:current mean train loss 3788.62727734375
INFO:root:current train perplexity4.457608222961426
INFO:root:current mean train loss 3786.2942177220393
INFO:root:current train perplexity4.455302715301514
INFO:root:current mean train loss 3789.528572944973
INFO:root:current train perplexity4.456539630889893
INFO:root:current mean train loss 3789.278759403935
INFO:root:current train perplexity4.454185962677002
INFO:root:current mean train loss 3795.9788057585683
INFO:root:current train perplexity4.4642415046691895
INFO:root:current mean train loss 3795.1731534598216
INFO:root:current train perplexity4.463203430175781
INFO:root:current mean train loss 3796.437560096154
INFO:root:current train perplexity4.465017318725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.27s/it]
INFO:root:final mean train loss: 3792.9824860480526
INFO:root:final train perplexity: 4.465768337249756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 4013.555180975731
INFO:root:eval perplexity: 5.068089008331299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 4900.905121066046
INFO:root:eval perplexity: 7.419023036956787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:20:13<16:43:26, 396.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3793.1058217243976
INFO:root:current train perplexity4.4375901222229
INFO:root:current mean train loss 3775.5183225537908
INFO:root:current train perplexity4.431438446044922
INFO:root:current mean train loss 3767.9792471841874
INFO:root:current train perplexity4.429924011230469
INFO:root:current mean train loss 3767.8144620492003
INFO:root:current train perplexity4.428061485290527
INFO:root:current mean train loss 3777.7288952308163
INFO:root:current train perplexity4.436532497406006
INFO:root:current mean train loss 3779.6581897244855
INFO:root:current train perplexity4.440036773681641
INFO:root:current mean train loss 3782.3877367770865
INFO:root:current train perplexity4.443641662597656
INFO:root:current mean train loss 3787.4033106466513
INFO:root:current train perplexity4.448964595794678
INFO:root:current mean train loss 3785.5667471621073
INFO:root:current train perplexity4.449003219604492
INFO:root:current mean train loss 3787.0915666426913
INFO:root:current train perplexity4.4499831199646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.86s/it]
INFO:root:final mean train loss: 3784.147873786188
INFO:root:final train perplexity: 4.450230121612549
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 4009.570593001995
INFO:root:eval perplexity: 5.059929370880127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 4900.646165780142
INFO:root:eval perplexity: 7.418237686157227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:26:47<16:35:13, 395.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3785.5080137148007
INFO:root:current train perplexity4.4123640060424805
INFO:root:current mean train loss 3779.005956519961
INFO:root:current train perplexity4.425148963928223
INFO:root:current mean train loss 3774.917903310245
INFO:root:current train perplexity4.419388294219971
INFO:root:current mean train loss 3781.5681352151933
INFO:root:current train perplexity4.427542209625244
INFO:root:current mean train loss 3783.651867402304
INFO:root:current train perplexity4.430947303771973
INFO:root:current mean train loss 3779.758303259835
INFO:root:current train perplexity4.4303412437438965
INFO:root:current mean train loss 3780.108324947992
INFO:root:current train perplexity4.434490203857422
INFO:root:current mean train loss 3778.1864447322414
INFO:root:current train perplexity4.431563854217529
INFO:root:current mean train loss 3777.0981108283354
INFO:root:current train perplexity4.431872844696045
INFO:root:current mean train loss 3778.3135337175204
INFO:root:current train perplexity4.434710502624512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it]
INFO:root:final mean train loss: 3775.2817776587704
INFO:root:final train perplexity: 4.434690475463867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 4011.0346697002437
INFO:root:eval perplexity: 5.062926292419434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 4903.095746412345
INFO:root:eval perplexity: 7.425673484802246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:33:22<16:28:08, 395.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3748.220177852746
INFO:root:current train perplexity4.391301155090332
INFO:root:current mean train loss 3760.066566965688
INFO:root:current train perplexity4.406724452972412
INFO:root:current mean train loss 3758.1467407634823
INFO:root:current train perplexity4.399509906768799
INFO:root:current mean train loss 3752.658368332942
INFO:root:current train perplexity4.393083095550537
INFO:root:current mean train loss 3758.1451623951025
INFO:root:current train perplexity4.397736072540283
INFO:root:current mean train loss 3759.978249067456
INFO:root:current train perplexity4.402583122253418
INFO:root:current mean train loss 3762.1397787156875
INFO:root:current train perplexity4.406232833862305
INFO:root:current mean train loss 3765.2478271789932
INFO:root:current train perplexity4.411935329437256
INFO:root:current mean train loss 3768.937353624253
INFO:root:current train perplexity4.417972087860107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.11s/it]
INFO:root:final mean train loss: 3765.6624563893965
INFO:root:final train perplexity: 4.417892932891846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 4005.8282912234044
INFO:root:eval perplexity: 5.052278995513916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 4896.20095716977
INFO:root:eval perplexity: 7.4047675132751465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:40:00<16:23:34, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3745.4854910714284
INFO:root:current train perplexity4.3405256271362305
INFO:root:current mean train loss 3758.1714551693926
INFO:root:current train perplexity4.383485794067383
INFO:root:current mean train loss 3767.628519399155
INFO:root:current train perplexity4.408504962921143
INFO:root:current mean train loss 3761.1510745368487
INFO:root:current train perplexity4.400533199310303
INFO:root:current mean train loss 3756.184086830083
INFO:root:current train perplexity4.389792442321777
INFO:root:current mean train loss 3758.929227148052
INFO:root:current train perplexity4.394618511199951
INFO:root:current mean train loss 3760.8097452732445
INFO:root:current train perplexity4.398306846618652
INFO:root:current mean train loss 3761.3337174433123
INFO:root:current train perplexity4.399899482727051
INFO:root:current mean train loss 3763.209844463968
INFO:root:current train perplexity4.401498794555664
INFO:root:current mean train loss 3760.961785128256
INFO:root:current train perplexity4.401735782623291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.23s/it]
INFO:root:final mean train loss: 3756.1650879767635
INFO:root:final train perplexity: 4.401370048522949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 4008.055857989805
INFO:root:eval perplexity: 5.0568318367004395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 4902.183186848958
INFO:root:eval perplexity: 7.422903060913086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:46:36<16:17:12, 396.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3788.222802734375
INFO:root:current train perplexity4.397378921508789
INFO:root:current mean train loss 3758.2745817764944
INFO:root:current train perplexity4.378553867340088
INFO:root:current mean train loss 3754.425535973837
INFO:root:current train perplexity4.382561206817627
INFO:root:current mean train loss 3752.0121085999504
INFO:root:current train perplexity4.379594802856445
INFO:root:current mean train loss 3755.098583984375
INFO:root:current train perplexity4.386048793792725
INFO:root:current mean train loss 3754.8955855582526
INFO:root:current train perplexity4.381734848022461
INFO:root:current mean train loss 3754.106729944741
INFO:root:current train perplexity4.382453918457031
INFO:root:current mean train loss 3754.7925678813376
INFO:root:current train perplexity4.387862205505371
INFO:root:current mean train loss 3752.079221985238
INFO:root:current train perplexity4.387292385101318
INFO:root:current mean train loss 3751.0448020726603
INFO:root:current train perplexity4.387252330780029

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.29s/it]
INFO:root:final mean train loss: 3746.01922533589
INFO:root:final train perplexity: 4.383787155151367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 4014.237749681405
INFO:root:eval perplexity: 5.069489002227783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 4910.237169630984
INFO:root:eval perplexity: 7.447389125823975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:53:13<16:10:47, 396.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3718.5208368716035
INFO:root:current train perplexity4.2870025634765625
INFO:root:current mean train loss 3707.400267562246
INFO:root:current train perplexity4.313397407531738
INFO:root:current mean train loss 3724.575816064672
INFO:root:current train perplexity4.329938888549805
INFO:root:current mean train loss 3722.123792902235
INFO:root:current train perplexity4.338816165924072
INFO:root:current mean train loss 3730.143439831745
INFO:root:current train perplexity4.346001625061035
INFO:root:current mean train loss 3733.5333506363527
INFO:root:current train perplexity4.35461950302124
INFO:root:current mean train loss 3732.3125807270767
INFO:root:current train perplexity4.357550144195557
INFO:root:current mean train loss 3735.7213318799704
INFO:root:current train perplexity4.362855911254883
INFO:root:current mean train loss 3733.889509606622
INFO:root:current train perplexity4.364461898803711
INFO:root:current mean train loss 3737.9692049532773
INFO:root:current train perplexity4.3674421310424805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.93s/it]
INFO:root:final mean train loss: 3737.520135941044
INFO:root:final train perplexity: 4.369112491607666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 4009.0669811059397
INFO:root:eval perplexity: 5.058899402618408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 4904.712440436613
INFO:root:eval perplexity: 7.43058443069458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:59:51<16:05:19, 396.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3754.5940965221776
INFO:root:current train perplexity4.347339630126953
INFO:root:current mean train loss 3718.2935856244035
INFO:root:current train perplexity4.31894588470459
INFO:root:current mean train loss 3726.995628720238
INFO:root:current train perplexity4.332226753234863
INFO:root:current mean train loss 3726.4082857345165
INFO:root:current train perplexity4.339391231536865
INFO:root:current mean train loss 3726.911105622825
INFO:root:current train perplexity4.346874237060547
INFO:root:current mean train loss 3729.1085418873586
INFO:root:current train perplexity4.349142074584961
INFO:root:current mean train loss 3727.7928054737026
INFO:root:current train perplexity4.346458911895752
INFO:root:current mean train loss 3729.6480951687545
INFO:root:current train perplexity4.351088047027588
INFO:root:current mean train loss 3731.8677838964727
INFO:root:current train perplexity4.353761196136475
INFO:root:current mean train loss 3731.186233668015
INFO:root:current train perplexity4.352177143096924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.02s/it]
INFO:root:final mean train loss: 3728.3353357007427
INFO:root:final train perplexity: 4.35330867767334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 4008.2571337544327
INFO:root:eval perplexity: 5.057242393493652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 4909.2729526817375
INFO:root:eval perplexity: 7.44445276260376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:06:27<15:58:20, 396.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3761.339831229968
INFO:root:current train perplexity4.316448211669922
INFO:root:current mean train loss 3735.2165615164117
INFO:root:current train perplexity4.314768314361572
INFO:root:current mean train loss 3725.9753857217574
INFO:root:current train perplexity4.312186241149902
INFO:root:current mean train loss 3719.8330495828723
INFO:root:current train perplexity4.320132255554199
INFO:root:current mean train loss 3724.9283906072037
INFO:root:current train perplexity4.324644088745117
INFO:root:current mean train loss 3725.574644071052
INFO:root:current train perplexity4.329136848449707
INFO:root:current mean train loss 3723.10344723506
INFO:root:current train perplexity4.329323768615723
INFO:root:current mean train loss 3721.0698110041017
INFO:root:current train perplexity4.331325531005859
INFO:root:current mean train loss 3719.1692787870606
INFO:root:current train perplexity4.332193374633789
INFO:root:current mean train loss 3721.4290543983793
INFO:root:current train perplexity4.337024211883545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.77s/it]
INFO:root:final mean train loss: 3718.3201104440996
INFO:root:final train perplexity: 4.336141586303711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 4007.1087568567154
INFO:root:eval perplexity: 5.054894924163818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it]
INFO:root:eval mean loss: 4911.985746343085
INFO:root:eval perplexity: 7.452715873718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:13:04<15:52:23, 396.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3709.257500831117
INFO:root:current train perplexity4.316446781158447
INFO:root:current mean train loss 3705.7678106398807
INFO:root:current train perplexity4.297889709472656
INFO:root:current mean train loss 3698.0460041988235
INFO:root:current train perplexity4.3115081787109375
INFO:root:current mean train loss 3700.2838440820874
INFO:root:current train perplexity4.313236713409424
INFO:root:current mean train loss 3698.9294755837527
INFO:root:current train perplexity4.312223434448242
INFO:root:current mean train loss 3700.6501812978463
INFO:root:current train perplexity4.310815334320068
INFO:root:current mean train loss 3702.7947547122535
INFO:root:current train perplexity4.315890789031982
INFO:root:current mean train loss 3709.138640499498
INFO:root:current train perplexity4.320310115814209
INFO:root:current mean train loss 3710.359156801118
INFO:root:current train perplexity4.3232102394104
INFO:root:current mean train loss 3711.9460835925124
INFO:root:current train perplexity4.323570251464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.65s/it]
INFO:root:final mean train loss: 3710.4631761735486
INFO:root:final train perplexity: 4.322720527648926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 4010.8976063829787
INFO:root:eval perplexity: 5.06264591217041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 4914.847221645057
INFO:root:eval perplexity: 7.461440086364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:19:42<15:46:09, 396.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3694.4784446022727
INFO:root:current train perplexity4.306887626647949
INFO:root:current mean train loss 3695.110222404234
INFO:root:current train perplexity4.302678108215332
INFO:root:current mean train loss 3699.065770526961
INFO:root:current train perplexity4.301098346710205
INFO:root:current mean train loss 3696.462812224912
INFO:root:current train perplexity4.2931318283081055
INFO:root:current mean train loss 3698.137091131525
INFO:root:current train perplexity4.296257495880127
INFO:root:current mean train loss 3700.063280810107
INFO:root:current train perplexity4.297646999359131
INFO:root:current mean train loss 3700.72666015625
INFO:root:current train perplexity4.302231788635254
INFO:root:current mean train loss 3703.8512666209645
INFO:root:current train perplexity4.304659843444824
INFO:root:current mean train loss 3703.287750993695
INFO:root:current train perplexity4.30296516418457
INFO:root:current mean train loss 3703.882531546548
INFO:root:current train perplexity4.306567192077637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.55s/it]
INFO:root:final mean train loss: 3701.7494981827276
INFO:root:final train perplexity: 4.307886123657227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 4004.5685307928857
INFO:root:eval perplexity: 5.0497050285339355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 4912.37481299867
INFO:root:eval perplexity: 7.453901290893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:26:17<15:38:25, 396.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3685.320304749504
INFO:root:current train perplexity4.292885780334473
INFO:root:current mean train loss 3695.9844379074
INFO:root:current train perplexity4.289214611053467
INFO:root:current mean train loss 3698.730232963997
INFO:root:current train perplexity4.29246187210083
INFO:root:current mean train loss 3692.6298061402376
INFO:root:current train perplexity4.285058498382568
INFO:root:current mean train loss 3695.0854813841456
INFO:root:current train perplexity4.288041591644287
INFO:root:current mean train loss 3694.56627529002
INFO:root:current train perplexity4.288789749145508
INFO:root:current mean train loss 3693.4904796203336
INFO:root:current train perplexity4.290074348449707
INFO:root:current mean train loss 3696.7927639662516
INFO:root:current train perplexity4.292137622833252
INFO:root:current mean train loss 3696.924632402864
INFO:root:current train perplexity4.291911602020264
INFO:root:current mean train loss 3696.31277938003
INFO:root:current train perplexity4.2923784255981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.48s/it]
INFO:root:final mean train loss: 3692.982619500929
INFO:root:final train perplexity: 4.2930121421813965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 4006.812532898382
INFO:root:eval perplexity: 5.054289817810059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 4913.16763110871
INFO:root:eval perplexity: 7.4563188552856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:32:53<15:31:38, 396.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3674.964334837148
INFO:root:current train perplexity4.277896404266357
INFO:root:current mean train loss 3672.72467219481
INFO:root:current train perplexity4.271873474121094
INFO:root:current mean train loss 3689.9285541830027
INFO:root:current train perplexity4.270353317260742
INFO:root:current mean train loss 3689.3880454009436
INFO:root:current train perplexity4.275635719299316
INFO:root:current mean train loss 3685.2647033820995
INFO:root:current train perplexity4.270974159240723
INFO:root:current mean train loss 3685.070991476029
INFO:root:current train perplexity4.271656513214111
INFO:root:current mean train loss 3687.7712689782043
INFO:root:current train perplexity4.275986671447754
INFO:root:current mean train loss 3686.0181310037697
INFO:root:current train perplexity4.275862693786621
INFO:root:current mean train loss 3685.4773490196253
INFO:root:current train perplexity4.277246475219727
INFO:root:current mean train loss 3688.145200310971
INFO:root:current train perplexity4.27998161315918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.91s/it]
INFO:root:final mean train loss: 3685.4543676068706
INFO:root:final train perplexity: 4.280279636383057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 4006.062853224734
INFO:root:eval perplexity: 5.052757740020752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it]
INFO:root:eval mean loss: 4915.238987699468
INFO:root:eval perplexity: 7.4626359939575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [6:39:30<15:25:20, 396.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3667.8860975820808
INFO:root:current train perplexity4.256154537200928
INFO:root:current mean train loss 3652.802786203736
INFO:root:current train perplexity4.236421585083008
INFO:root:current mean train loss 3658.082303392417
INFO:root:current train perplexity4.234006881713867
INFO:root:current mean train loss 3664.2602983540155
INFO:root:current train perplexity4.2395758628845215
INFO:root:current mean train loss 3665.6898899277467
INFO:root:current train perplexity4.247332572937012
INFO:root:current mean train loss 3669.3539710168393
INFO:root:current train perplexity4.25
INFO:root:current mean train loss 3673.244778123274
INFO:root:current train perplexity4.257627010345459
INFO:root:current mean train loss 3676.2381734395058
INFO:root:current train perplexity4.261904716491699
INFO:root:current mean train loss 3677.684838339466
INFO:root:current train perplexity4.264359474182129
INFO:root:current mean train loss 3679.5064790782208
INFO:root:current train perplexity4.266805648803711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.17s/it]
INFO:root:final mean train loss: 3677.776431791244
INFO:root:final train perplexity: 4.267334461212158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 4005.8385936114805
INFO:root:eval perplexity: 5.0522990226745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 4917.391537497229
INFO:root:eval perplexity: 7.46920919418335
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [6:46:04<15:16:46, 395.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.60777265176
INFO:root:current train perplexity4.197153568267822
INFO:root:current mean train loss 3645.170540712734
INFO:root:current train perplexity4.22868537902832
INFO:root:current mean train loss 3635.609961958297
INFO:root:current train perplexity4.221587657928467
INFO:root:current mean train loss 3637.6734887253715
INFO:root:current train perplexity4.2262043952941895
INFO:root:current mean train loss 3649.9746234118325
INFO:root:current train perplexity4.2315473556518555
INFO:root:current mean train loss 3657.7577085218804
INFO:root:current train perplexity4.236217975616455
INFO:root:current mean train loss 3660.1421961000046
INFO:root:current train perplexity4.2397379875183105
INFO:root:current mean train loss 3666.925710210352
INFO:root:current train perplexity4.244976997375488
INFO:root:current mean train loss 3670.473196827438
INFO:root:current train perplexity4.248845100402832
INFO:root:current mean train loss 3672.5443316829724
INFO:root:current train perplexity4.253444671630859

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.48s/it]
INFO:root:final mean train loss: 3669.2470794185515
INFO:root:final train perplexity: 4.252998352050781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 4004.267231826241
INFO:root:eval perplexity: 5.049090385437012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it]
INFO:root:eval mean loss: 4919.0073103668
INFO:root:eval perplexity: 7.474143981933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:52:39<15:09:45, 395.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3670.693092105263
INFO:root:current train perplexity4.212302207946777
INFO:root:current mean train loss 3667.7380220853365
INFO:root:current train perplexity4.222616195678711
INFO:root:current mean train loss 3663.8547992253707
INFO:root:current train perplexity4.222586154937744
INFO:root:current mean train loss 3659.2301751631726
INFO:root:current train perplexity4.225013256072998
INFO:root:current mean train loss 3658.607059363163
INFO:root:current train perplexity4.224068641662598
INFO:root:current mean train loss 3659.0378930869224
INFO:root:current train perplexity4.229251384735107
INFO:root:current mean train loss 3659.390469733588
INFO:root:current train perplexity4.232186317443848
INFO:root:current mean train loss 3666.2362931161556
INFO:root:current train perplexity4.238128185272217
INFO:root:current mean train loss 3664.472304087378
INFO:root:current train perplexity4.238219738006592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.59s/it]
INFO:root:final mean train loss: 3661.3542092231014
INFO:root:final train perplexity: 4.23977518081665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 4005.3831016594636
INFO:root:eval perplexity: 5.0513691902160645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 4920.098703803746
INFO:root:eval perplexity: 7.477480411529541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [6:59:16<15:04:06, 395.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.0681966145835
INFO:root:current train perplexity4.1061692237854
INFO:root:current mean train loss 3631.8211729179307
INFO:root:current train perplexity4.209782600402832
INFO:root:current mean train loss 3640.4543348791562
INFO:root:current train perplexity4.198358535766602
INFO:root:current mean train loss 3636.9839318404497
INFO:root:current train perplexity4.2061591148376465
INFO:root:current mean train loss 3637.5420866935483
INFO:root:current train perplexity4.204652786254883
INFO:root:current mean train loss 3641.033008006648
INFO:root:current train perplexity4.209748268127441
INFO:root:current mean train loss 3647.097587420968
INFO:root:current train perplexity4.214621543884277
INFO:root:current mean train loss 3652.8618511346463
INFO:root:current train perplexity4.22077751159668
INFO:root:current mean train loss 3656.480053741341
INFO:root:current train perplexity4.22270393371582
INFO:root:current mean train loss 3654.6387135113855
INFO:root:current train perplexity4.223934173583984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.34s/it]
INFO:root:final mean train loss: 3652.3703692036293
INFO:root:final train perplexity: 4.22477388381958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 4006.0485545489805
INFO:root:eval perplexity: 5.052728176116943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 4917.732433995457
INFO:root:eval perplexity: 7.470249652862549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:05:50<14:55:55, 395.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.730379971591
INFO:root:current train perplexity4.129681587219238
INFO:root:current mean train loss 3632.274488844313
INFO:root:current train perplexity4.189899921417236
INFO:root:current mean train loss 3639.8189784045467
INFO:root:current train perplexity4.194943428039551
INFO:root:current mean train loss 3630.899412492464
INFO:root:current train perplexity4.194183349609375
INFO:root:current mean train loss 3636.277787480041
INFO:root:current train perplexity4.19813871383667
INFO:root:current mean train loss 3635.5219769561827
INFO:root:current train perplexity4.194014549255371
INFO:root:current mean train loss 3636.4037862175223
INFO:root:current train perplexity4.198599338531494
INFO:root:current mean train loss 3638.378696790392
INFO:root:current train perplexity4.200042247772217
INFO:root:current mean train loss 3643.0477988811076
INFO:root:current train perplexity4.203469276428223
INFO:root:current mean train loss 3642.83441637795
INFO:root:current train perplexity4.205341815948486

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it]
INFO:root:final mean train loss: 3645.0034722974224
INFO:root:final train perplexity: 4.212512969970703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 4005.3528697778147
INFO:root:eval perplexity: 5.051307678222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it]
INFO:root:eval mean loss: 4923.625886524823
INFO:root:eval perplexity: 7.488274097442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:12:23<14:48:07, 394.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.346551192434
INFO:root:current train perplexity4.204708099365234
INFO:root:current mean train loss 3610.310754086791
INFO:root:current train perplexity4.166696548461914
INFO:root:current mean train loss 3615.9083001123718
INFO:root:current train perplexity4.172773838043213
INFO:root:current mean train loss 3622.0261414148217
INFO:root:current train perplexity4.175207614898682
INFO:root:current mean train loss 3619.7220287095392
INFO:root:current train perplexity4.176187038421631
INFO:root:current mean train loss 3625.0256117157396
INFO:root:current train perplexity4.179362773895264
INFO:root:current mean train loss 3633.204889201964
INFO:root:current train perplexity4.188108921051025
INFO:root:current mean train loss 3638.772163826169
INFO:root:current train perplexity4.193697929382324
INFO:root:current mean train loss 3640.2438464042466
INFO:root:current train perplexity4.195535182952881
INFO:root:current mean train loss 3638.543270007311
INFO:root:current train perplexity4.1970014572143555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.51s/it]
INFO:root:final mean train loss: 3636.567629721857
INFO:root:final train perplexity: 4.19851541519165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 4007.231722351507
INFO:root:eval perplexity: 5.05514669418335
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 4925.83361037234
INFO:root:eval perplexity: 7.495038032531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:18:59<14:42:11, 395.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3689.0910734953704
INFO:root:current train perplexity4.245868682861328
INFO:root:current mean train loss 3637.276540200541
INFO:root:current train perplexity4.184087753295898
INFO:root:current mean train loss 3625.3461892552314
INFO:root:current train perplexity4.173587799072266
INFO:root:current mean train loss 3627.4500728688836
INFO:root:current train perplexity4.1746978759765625
INFO:root:current mean train loss 3627.965933520565
INFO:root:current train perplexity4.180049419403076
INFO:root:current mean train loss 3632.5910746449536
INFO:root:current train perplexity4.184131622314453
INFO:root:current mean train loss 3630.586029393441
INFO:root:current train perplexity4.181589603424072
INFO:root:current mean train loss 3628.779940640582
INFO:root:current train perplexity4.180822849273682
INFO:root:current mean train loss 3630.22825465727
INFO:root:current train perplexity4.182074069976807
INFO:root:current mean train loss 3631.8168824163968
INFO:root:current train perplexity4.188540458679199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.52s/it]
INFO:root:final mean train loss: 3630.6762899583387
INFO:root:final train perplexity: 4.18876838684082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 4006.6088261164673
INFO:root:eval perplexity: 5.0538740158081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 4926.769051626219
INFO:root:eval perplexity: 7.497903347015381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:25:33<14:34:56, 394.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3627.0553850446427
INFO:root:current train perplexity4.185043811798096
INFO:root:current mean train loss 3615.986845341435
INFO:root:current train perplexity4.137912750244141
INFO:root:current mean train loss 3619.857132022939
INFO:root:current train perplexity4.149410724639893
INFO:root:current mean train loss 3626.128994432136
INFO:root:current train perplexity4.164636611938477
INFO:root:current mean train loss 3624.901055136494
INFO:root:current train perplexity4.1656975746154785
INFO:root:current mean train loss 3626.788830224153
INFO:root:current train perplexity4.170279502868652
INFO:root:current mean train loss 3627.214604223056
INFO:root:current train perplexity4.1703948974609375
INFO:root:current mean train loss 3625.718022892751
INFO:root:current train perplexity4.173040390014648
INFO:root:current mean train loss 3626.9078698072603
INFO:root:current train perplexity4.177356719970703
INFO:root:current mean train loss 3628.114651831969
INFO:root:current train perplexity4.177919864654541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.33s/it]
INFO:root:final mean train loss: 3623.826816128146
INFO:root:final train perplexity: 4.177464962005615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 4006.6188583915114
INFO:root:eval perplexity: 5.053892612457275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 4930.142063871343
INFO:root:eval perplexity: 7.508253574371338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [7:32:09<14:29:25, 395.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3619.1702511809594
INFO:root:current train perplexity4.146288871765137
INFO:root:current mean train loss 3597.567136964598
INFO:root:current train perplexity4.155791282653809
INFO:root:current mean train loss 3600.6927374694574
INFO:root:current train perplexity4.148253440856934
INFO:root:current mean train loss 3602.499204941463
INFO:root:current train perplexity4.1475090980529785
INFO:root:current mean train loss 3609.3790004893835
INFO:root:current train perplexity4.151146411895752
INFO:root:current mean train loss 3611.650592052256
INFO:root:current train perplexity4.151960849761963
INFO:root:current mean train loss 3615.4226480486977
INFO:root:current train perplexity4.157276630401611
INFO:root:current mean train loss 3616.5561944029696
INFO:root:current train perplexity4.160347938537598
INFO:root:current mean train loss 3618.662110243828
INFO:root:current train perplexity4.162126064300537
INFO:root:current mean train loss 3617.745369095059
INFO:root:current train perplexity4.164376258850098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.21s/it]
INFO:root:final mean train loss: 3615.953732152139
INFO:root:final train perplexity: 4.164508819580078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 4006.7296237810283
INFO:root:eval perplexity: 5.0541205406188965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 4932.5586422318265
INFO:root:eval perplexity: 7.5156755447387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [7:38:46<14:24:08, 395.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.8980928308824
INFO:root:current train perplexity4.100183486938477
INFO:root:current mean train loss 3600.0459146057533
INFO:root:current train perplexity4.136303901672363
INFO:root:current mean train loss 3612.312255859375
INFO:root:current train perplexity4.150636672973633
INFO:root:current mean train loss 3612.264219974181
INFO:root:current train perplexity4.149744033813477
INFO:root:current mean train loss 3618.1769710972144
INFO:root:current train perplexity4.157693862915039
INFO:root:current mean train loss 3616.6751627013386
INFO:root:current train perplexity4.158280849456787
INFO:root:current mean train loss 3614.5731514316917
INFO:root:current train perplexity4.153987407684326
INFO:root:current mean train loss 3610.219066310024
INFO:root:current train perplexity4.151981353759766
INFO:root:current mean train loss 3610.601077661391
INFO:root:current train perplexity4.152041435241699
INFO:root:current mean train loss 3611.839075644059
INFO:root:current train perplexity4.15334415435791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.51s/it]
INFO:root:final mean train loss: 3610.0352540169993
INFO:root:final train perplexity: 4.154796600341797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 4006.1432759169993
INFO:root:eval perplexity: 5.052922248840332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4932.958806031139
INFO:root:eval perplexity: 7.51690673828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [7:45:21<14:16:31, 395.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3600.4380213850636
INFO:root:current train perplexity4.130718231201172
INFO:root:current mean train loss 3609.4297627383057
INFO:root:current train perplexity4.134700775146484
INFO:root:current mean train loss 3601.358459708313
INFO:root:current train perplexity4.13186502456665
INFO:root:current mean train loss 3599.3728292566157
INFO:root:current train perplexity4.133749485015869
INFO:root:current mean train loss 3597.9941220086125
INFO:root:current train perplexity4.136643409729004
INFO:root:current mean train loss 3600.948153091458
INFO:root:current train perplexity4.141993999481201
INFO:root:current mean train loss 3595.728286303229
INFO:root:current train perplexity4.134228229522705
INFO:root:current mean train loss 3603.4988738651805
INFO:root:current train perplexity4.135899543762207
INFO:root:current mean train loss 3602.565221926386
INFO:root:current train perplexity4.137307643890381
INFO:root:current mean train loss 3605.661392227825
INFO:root:current train perplexity4.141963958740234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.21s/it]
INFO:root:final mean train loss: 3602.515374460528
INFO:root:final train perplexity: 4.1424880027771
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 4007.2694083139404
INFO:root:eval perplexity: 5.0552239418029785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 4938.860157635195
INFO:root:eval perplexity: 7.535068988800049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [7:51:57<14:10:46, 395.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.804873338386
INFO:root:current train perplexity4.114483833312988
INFO:root:current mean train loss 3584.4093653513287
INFO:root:current train perplexity4.1024909019470215
INFO:root:current mean train loss 3594.6290077466642
INFO:root:current train perplexity4.11326789855957
INFO:root:current mean train loss 3587.2153479968492
INFO:root:current train perplexity4.11283016204834
INFO:root:current mean train loss 3589.7088102875737
INFO:root:current train perplexity4.114750385284424
INFO:root:current mean train loss 3593.5321085827272
INFO:root:current train perplexity4.120805740356445
INFO:root:current mean train loss 3597.404464515789
INFO:root:current train perplexity4.126248359680176
INFO:root:current mean train loss 3597.862438375978
INFO:root:current train perplexity4.129894733428955
INFO:root:current mean train loss 3598.122591821655
INFO:root:current train perplexity4.128682613372803
INFO:root:current mean train loss 3597.7945603347985
INFO:root:current train perplexity4.130334854125977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it]
INFO:root:final mean train loss: 3595.5315559756373
INFO:root:final train perplexity: 4.131089687347412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.77s/it]
INFO:root:eval mean loss: 4008.0784574468084
INFO:root:eval perplexity: 5.056877613067627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 4943.536248822585
INFO:root:eval perplexity: 7.549488544464111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [7:58:33<14:04:06, 395.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3587.69185546875
INFO:root:current train perplexity4.139564514160156
INFO:root:current mean train loss 3589.871630859375
INFO:root:current train perplexity4.123494625091553
INFO:root:current mean train loss 3595.823045987216
INFO:root:current train perplexity4.121878147125244
INFO:root:current mean train loss 3592.252087890625
INFO:root:current train perplexity4.114494800567627
INFO:root:current mean train loss 3589.377400287829
INFO:root:current train perplexity4.115455150604248
INFO:root:current mean train loss 3589.9542518682065
INFO:root:current train perplexity4.114468574523926
INFO:root:current mean train loss 3587.7634700520834
INFO:root:current train perplexity4.114833831787109
INFO:root:current mean train loss 3587.382747605847
INFO:root:current train perplexity4.115819454193115
INFO:root:current mean train loss 3591.6423775111607
INFO:root:current train perplexity4.119080066680908
INFO:root:current mean train loss 3590.7426061698716
INFO:root:current train perplexity4.119096279144287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.28s/it]
INFO:root:final mean train loss: 3588.2191819837017
INFO:root:final train perplexity: 4.1191887855529785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 4010.4058171265515
INFO:root:eval perplexity: 5.061639785766602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 4943.972564480829
INFO:root:eval perplexity: 7.550835132598877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:05:06<13:56:08, 395.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.8097909214985
INFO:root:current train perplexity4.076766014099121
INFO:root:current mean train loss 3568.339112662227
INFO:root:current train perplexity4.079671382904053
INFO:root:current mean train loss 3578.6952710909895
INFO:root:current train perplexity4.093345642089844
INFO:root:current mean train loss 3584.854175378386
INFO:root:current train perplexity4.095215797424316
INFO:root:current mean train loss 3588.803860050304
INFO:root:current train perplexity4.101999282836914
INFO:root:current mean train loss 3590.6253241249465
INFO:root:current train perplexity4.10623836517334
INFO:root:current mean train loss 3590.766063595237
INFO:root:current train perplexity4.108083724975586
INFO:root:current mean train loss 3590.55238359824
INFO:root:current train perplexity4.107795238494873
INFO:root:current mean train loss 3588.4836564026223
INFO:root:current train perplexity4.107922554016113
INFO:root:current mean train loss 3585.5267054576234
INFO:root:current train perplexity4.110249996185303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it]
INFO:root:final mean train loss: 3581.8232311125726
INFO:root:final train perplexity: 4.108807563781738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 4008.2743170988474
INFO:root:eval perplexity: 5.057278633117676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 4939.9625910765735
INFO:root:eval perplexity: 7.538466930389404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:11:42<13:49:58, 395.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3567.5130923763736
INFO:root:current train perplexity4.051516056060791
INFO:root:current mean train loss 3578.9676200507197
INFO:root:current train perplexity4.0708465576171875
INFO:root:current mean train loss 3577.195548250913
INFO:root:current train perplexity4.079129219055176
INFO:root:current mean train loss 3580.4581027213876
INFO:root:current train perplexity4.08650016784668
INFO:root:current mean train loss 3578.3626358436227
INFO:root:current train perplexity4.086956977844238
INFO:root:current mean train loss 3577.9795950487787
INFO:root:current train perplexity4.087011337280273
INFO:root:current mean train loss 3576.9095683339365
INFO:root:current train perplexity4.0898919105529785
INFO:root:current mean train loss 3576.539376703737
INFO:root:current train perplexity4.089913368225098
INFO:root:current mean train loss 3576.8623882597676
INFO:root:current train perplexity4.093498706817627
INFO:root:current mean train loss 3577.46926685876
INFO:root:current train perplexity4.097364902496338

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.37s/it]
INFO:root:final mean train loss: 3574.743192118983
INFO:root:final train perplexity: 4.097346782684326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 4007.2368441101507
INFO:root:eval perplexity: 5.055157661437988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 4942.279217226285
INFO:root:eval perplexity: 7.545608997344971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:18:16<13:42:39, 394.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3546.9618968000314
INFO:root:current train perplexity4.04902982711792
INFO:root:current mean train loss 3551.720865067525
INFO:root:current train perplexity4.069382190704346
INFO:root:current mean train loss 3556.4168558280203
INFO:root:current train perplexity4.073318958282471
INFO:root:current mean train loss 3554.503846285636
INFO:root:current train perplexity4.070115089416504
INFO:root:current mean train loss 3559.118934157377
INFO:root:current train perplexity4.071103096008301
INFO:root:current mean train loss 3561.685218365244
INFO:root:current train perplexity4.075433731079102
INFO:root:current mean train loss 3567.682180947671
INFO:root:current train perplexity4.0812554359436035
INFO:root:current mean train loss 3571.698412383155
INFO:root:current train perplexity4.0847649574279785
INFO:root:current mean train loss 3571.49151726745
INFO:root:current train perplexity4.086585521697998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it]
INFO:root:final mean train loss: 3568.296657746838
INFO:root:final train perplexity: 4.086938858032227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it]
INFO:root:eval mean loss: 4010.1641352227393
INFO:root:eval perplexity: 5.0611443519592285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 4947.7763117796985
INFO:root:eval perplexity: 7.56259298324585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:24:50<13:35:26, 394.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3511.300711495536
INFO:root:current train perplexity4.046975612640381
INFO:root:current mean train loss 3584.021482093312
INFO:root:current train perplexity4.071040153503418
INFO:root:current mean train loss 3563.2489833371073
INFO:root:current train perplexity4.06367826461792
INFO:root:current mean train loss 3559.4821602389557
INFO:root:current train perplexity4.07020378112793
INFO:root:current mean train loss 3556.5235022842444
INFO:root:current train perplexity4.071212291717529
INFO:root:current mean train loss 3557.8883670603736
INFO:root:current train perplexity4.070870399475098
INFO:root:current mean train loss 3557.8890201876543
INFO:root:current train perplexity4.067897796630859
INFO:root:current mean train loss 3561.465878326114
INFO:root:current train perplexity4.069998264312744
INFO:root:current mean train loss 3565.54554296633
INFO:root:current train perplexity4.073953628540039
INFO:root:current mean train loss 3565.717261199783
INFO:root:current train perplexity4.0754313468933105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.86s/it]
INFO:root:final mean train loss: 3561.646516615345
INFO:root:final train perplexity: 4.076230049133301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4010.867767550421
INFO:root:eval perplexity: 5.06258487701416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 4949.039760291999
INFO:root:eval perplexity: 7.56649923324585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [8:31:26<13:30:05, 395.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3512.180729166667
INFO:root:current train perplexity4.025519847869873
INFO:root:current mean train loss 3543.714510444973
INFO:root:current train perplexity4.046559810638428
INFO:root:current mean train loss 3544.203421375363
INFO:root:current train perplexity4.047170639038086
INFO:root:current mean train loss 3551.1964270213293
INFO:root:current train perplexity4.045050144195557
INFO:root:current mean train loss 3546.5402149614083
INFO:root:current train perplexity4.045458793640137
INFO:root:current mean train loss 3552.6283828883497
INFO:root:current train perplexity4.051055908203125
INFO:root:current mean train loss 3558.0964561896594
INFO:root:current train perplexity4.058712005615234
INFO:root:current mean train loss 3554.4265252813593
INFO:root:current train perplexity4.0553765296936035
INFO:root:current mean train loss 3555.3840991061156
INFO:root:current train perplexity4.062045097351074
INFO:root:current mean train loss 3557.5964990501197
INFO:root:current train perplexity4.063777923583984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.91s/it]
INFO:root:final mean train loss: 3554.487048549037
INFO:root:final train perplexity: 4.064732551574707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 4008.7807374778367
INFO:root:eval perplexity: 5.058313846588135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 4950.993209081339
INFO:root:eval perplexity: 7.572545051574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [8:38:03<13:24:14, 395.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3499.373736837636
INFO:root:current train perplexity3.98972487449646
INFO:root:current mean train loss 3515.5808978817327
INFO:root:current train perplexity4.014687538146973
INFO:root:current mean train loss 3516.0956834185818
INFO:root:current train perplexity4.027163982391357
INFO:root:current mean train loss 3525.7519659745067
INFO:root:current train perplexity4.037444114685059
INFO:root:current mean train loss 3530.2642184498745
INFO:root:current train perplexity4.0391716957092285
INFO:root:current mean train loss 3535.0584476390713
INFO:root:current train perplexity4.040939807891846
INFO:root:current mean train loss 3540.8246705865017
INFO:root:current train perplexity4.047012805938721
INFO:root:current mean train loss 3544.900498681708
INFO:root:current train perplexity4.050656318664551
INFO:root:current mean train loss 3550.5897618753797
INFO:root:current train perplexity4.056673526763916
INFO:root:current mean train loss 3552.5475711843173
INFO:root:current train perplexity4.056603908538818

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.12s/it]
INFO:root:final mean train loss: 3549.514659881592
INFO:root:final train perplexity: 4.056766986846924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 4012.725861245013
INFO:root:eval perplexity: 5.066390037536621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 4953.671142578125
INFO:root:eval perplexity: 7.580842018127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [8:44:39<13:18:11, 395.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.8202022429437
INFO:root:current train perplexity4.068660259246826
INFO:root:current mean train loss 3538.9642175572517
INFO:root:current train perplexity4.0451483726501465
INFO:root:current mean train loss 3544.1411344189664
INFO:root:current train perplexity4.028611660003662
INFO:root:current mean train loss 3539.5715191890104
INFO:root:current train perplexity4.029703617095947
INFO:root:current mean train loss 3535.277190808077
INFO:root:current train perplexity4.028716087341309
INFO:root:current mean train loss 3534.0993836253824
INFO:root:current train perplexity4.0264973640441895
INFO:root:current mean train loss 3538.3368401625644
INFO:root:current train perplexity4.032048225402832
INFO:root:current mean train loss 3542.6115361956013
INFO:root:current train perplexity4.037949085235596
INFO:root:current mean train loss 3542.988635562387
INFO:root:current train perplexity4.040953159332275
INFO:root:current mean train loss 3542.716833325641
INFO:root:current train perplexity4.042435646057129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it]
INFO:root:final mean train loss: 3542.2250992559616
INFO:root:final train perplexity: 4.045116901397705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 4016.5659976174647
INFO:root:eval perplexity: 5.074263572692871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 4959.890928011414
INFO:root:eval perplexity: 7.600146293640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [8:51:14<13:11:09, 395.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.22119140625
INFO:root:current train perplexity4.020979404449463
INFO:root:current mean train loss 3545.190160957172
INFO:root:current train perplexity4.033641815185547
INFO:root:current mean train loss 3541.1117745243855
INFO:root:current train perplexity4.0364603996276855
INFO:root:current mean train loss 3551.343201223728
INFO:root:current train perplexity4.03564453125
INFO:root:current mean train loss 3548.704102118629
INFO:root:current train perplexity4.036364555358887
INFO:root:current mean train loss 3545.216473467938
INFO:root:current train perplexity4.037842750549316
INFO:root:current mean train loss 3541.2379247817635
INFO:root:current train perplexity4.035621643066406
INFO:root:current mean train loss 3537.744113204605
INFO:root:current train perplexity4.033809185028076
INFO:root:current mean train loss 3537.793796325611
INFO:root:current train perplexity4.0356550216674805
INFO:root:current mean train loss 3538.798010942908
INFO:root:current train perplexity4.0351409912109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.66s/it]
INFO:root:final mean train loss: 3536.003585077101
INFO:root:final train perplexity: 4.035199165344238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it]
INFO:root:eval mean loss: 4014.0984942929963
INFO:root:eval perplexity: 5.069202899932861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4961.178866771941
INFO:root:eval perplexity: 7.60414981842041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [8:57:48<13:03:41, 395.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3492.095012258976
INFO:root:current train perplexity4.026662349700928
INFO:root:current mean train loss 3501.9162149234694
INFO:root:current train perplexity4.01439094543457
INFO:root:current mean train loss 3507.9836326938894
INFO:root:current train perplexity4.012355327606201
INFO:root:current mean train loss 3515.5094272052866
INFO:root:current train perplexity4.016483783721924
INFO:root:current mean train loss 3522.2534414543134
INFO:root:current train perplexity4.013258457183838
INFO:root:current mean train loss 3526.6665815670704
INFO:root:current train perplexity4.017707824707031
INFO:root:current mean train loss 3528.4762444002367
INFO:root:current train perplexity4.017551422119141
INFO:root:current mean train loss 3531.4099487141275
INFO:root:current train perplexity4.020114421844482
INFO:root:current mean train loss 3530.4209707861387
INFO:root:current train perplexity4.021337509155273
INFO:root:current mean train loss 3532.2853248539795
INFO:root:current train perplexity4.025228500366211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.49s/it]
INFO:root:final mean train loss: 3530.5345409147203
INFO:root:final train perplexity: 4.026501655578613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 4012.932560048205
INFO:root:eval perplexity: 5.0668134689331055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 4961.2664422650705
INFO:root:eval perplexity: 7.604423999786377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:04:23<12:56:40, 394.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3499.9386097301135
INFO:root:current train perplexity4.012424945831299
INFO:root:current mean train loss 3511.8009639616935
INFO:root:current train perplexity4.015558242797852
INFO:root:current mean train loss 3510.0473680683212
INFO:root:current train perplexity4.008860111236572
INFO:root:current mean train loss 3511.4523795114437
INFO:root:current train perplexity4.002752304077148
INFO:root:current mean train loss 3518.8494484031594
INFO:root:current train perplexity4.0065598487854
INFO:root:current mean train loss 3523.3980798669763
INFO:root:current train perplexity4.011151313781738
INFO:root:current mean train loss 3523.268630352457
INFO:root:current train perplexity4.014323711395264
INFO:root:current mean train loss 3525.815382799565
INFO:root:current train perplexity4.018298625946045
INFO:root:current mean train loss 3528.8395156592655
INFO:root:current train perplexity4.018716812133789
INFO:root:current mean train loss 3528.129557632526
INFO:root:current train perplexity4.018523693084717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.06s/it]
INFO:root:final mean train loss: 3524.7375521506033
INFO:root:final train perplexity: 4.017303466796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 4016.853482726618
INFO:root:eval perplexity: 5.074852466583252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 4964.841819384419
INFO:root:eval perplexity: 7.6155476570129395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:10:57<12:49:43, 394.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.0519011966767
INFO:root:current train perplexity3.960280179977417
INFO:root:current mean train loss 3490.94873046875
INFO:root:current train perplexity3.9806013107299805
INFO:root:current mean train loss 3499.267859397279
INFO:root:current train perplexity3.9842021465301514
INFO:root:current mean train loss 3513.419278231534
INFO:root:current train perplexity3.99707293510437
INFO:root:current mean train loss 3514.2509275234543
INFO:root:current train perplexity4.000057220458984
INFO:root:current mean train loss 3517.6463243609846
INFO:root:current train perplexity4.004371643066406
INFO:root:current mean train loss 3515.5973782316414
INFO:root:current train perplexity4.0021562576293945
INFO:root:current mean train loss 3518.095525859068
INFO:root:current train perplexity4.004732608795166
INFO:root:current mean train loss 3518.304145468207
INFO:root:current train perplexity4.004944324493408
INFO:root:current mean train loss 3519.946712949442
INFO:root:current train perplexity4.0052876472473145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it]
INFO:root:final mean train loss: 3518.337994360155
INFO:root:final train perplexity: 4.007173538208008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 4018.379008408134
INFO:root:eval perplexity: 5.077985763549805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4969.156504529587
INFO:root:eval perplexity: 7.628997325897217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:17:33<12:43:47, 395.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.3874236630722
INFO:root:current train perplexity3.9651246070861816
INFO:root:current mean train loss 3489.3415984215094
INFO:root:current train perplexity3.9774906635284424
INFO:root:current mean train loss 3489.5577604286786
INFO:root:current train perplexity3.977715253829956
INFO:root:current mean train loss 3505.5062581599564
INFO:root:current train perplexity3.988386869430542
INFO:root:current mean train loss 3507.1771911491505
INFO:root:current train perplexity3.9941372871398926
INFO:root:current mean train loss 3504.787037543783
INFO:root:current train perplexity3.9897027015686035
INFO:root:current mean train loss 3507.189782041729
INFO:root:current train perplexity3.992171287536621
INFO:root:current mean train loss 3510.9304832527764
INFO:root:current train perplexity3.994356870651245
INFO:root:current mean train loss 3512.5029711717852
INFO:root:current train perplexity3.9966073036193848
INFO:root:current mean train loss 3513.039541226828
INFO:root:current train perplexity3.9973793029785156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.33s/it]
INFO:root:final mean train loss: 3512.441947813957
INFO:root:final train perplexity: 3.997863292694092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 4019.942864167775
INFO:root:eval perplexity: 5.0811967849731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 4972.20743295656
INFO:root:eval perplexity: 7.638519763946533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [9:24:06<12:36:19, 394.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.0060633405856
INFO:root:current train perplexity3.967524528503418
INFO:root:current mean train loss 3480.8531664629886
INFO:root:current train perplexity3.9670231342315674
INFO:root:current mean train loss 3496.8801803315414
INFO:root:current train perplexity3.97829532623291
INFO:root:current mean train loss 3496.2016504936923
INFO:root:current train perplexity3.973358631134033
INFO:root:current mean train loss 3497.875753319089
INFO:root:current train perplexity3.975080728530884
INFO:root:current mean train loss 3501.634972237964
INFO:root:current train perplexity3.978008508682251
INFO:root:current mean train loss 3501.353389060199
INFO:root:current train perplexity3.981391429901123
INFO:root:current mean train loss 3503.2125750285823
INFO:root:current train perplexity3.982969045639038
INFO:root:current mean train loss 3508.0912108264006
INFO:root:current train perplexity3.9881961345672607
INFO:root:current mean train loss 3510.8049458551454
INFO:root:current train perplexity3.9916183948516846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.94s/it]
INFO:root:final mean train loss: 3508.306215963056
INFO:root:final train perplexity: 3.991345167160034
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 4018.200600482048
INFO:root:eval perplexity: 5.07761812210083
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 4971.531057804189
INFO:root:eval perplexity: 7.636407375335693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [9:30:41<12:29:29, 394.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.3959427756827
INFO:root:current train perplexity3.9554500579833984
INFO:root:current mean train loss 3487.478204900568
INFO:root:current train perplexity3.9575328826904297
INFO:root:current mean train loss 3493.292164021668
INFO:root:current train perplexity3.960622787475586
INFO:root:current mean train loss 3496.5547846515665
INFO:root:current train perplexity3.9654667377471924
INFO:root:current mean train loss 3499.627025314425
INFO:root:current train perplexity3.9699933528900146
INFO:root:current mean train loss 3501.5480857212256
INFO:root:current train perplexity3.97478985786438
INFO:root:current mean train loss 3502.374002115175
INFO:root:current train perplexity3.9783034324645996
INFO:root:current mean train loss 3505.026356019695
INFO:root:current train perplexity3.981741189956665
INFO:root:current mean train loss 3504.8154759283398
INFO:root:current train perplexity3.9815053939819336
INFO:root:current mean train loss 3504.6465274149887
INFO:root:current train perplexity3.9815328121185303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.17s/it]
INFO:root:final mean train loss: 3501.9987541937057
INFO:root:final train perplexity: 3.9814248085021973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 4022.084928039118
INFO:root:eval perplexity: 5.085601806640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 4972.2828221963655
INFO:root:eval perplexity: 7.63875675201416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [9:37:15<12:23:05, 394.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3509.601619037829
INFO:root:current train perplexity3.9730639457702637
INFO:root:current mean train loss 3501.6058268229167
INFO:root:current train perplexity3.9626882076263428
INFO:root:current mean train loss 3498.624162473517
INFO:root:current train perplexity3.96411395072937
INFO:root:current mean train loss 3497.7465313488924
INFO:root:current train perplexity3.965894937515259
INFO:root:current mean train loss 3499.5124324297662
INFO:root:current train perplexity3.965963125228882
INFO:root:current mean train loss 3497.362161485688
INFO:root:current train perplexity3.965893030166626
INFO:root:current mean train loss 3499.7765674179404
INFO:root:current train perplexity3.9696245193481445
INFO:root:current mean train loss 3499.9970964155855
INFO:root:current train perplexity3.9707438945770264
INFO:root:current mean train loss 3499.6022264533867
INFO:root:current train perplexity3.971952438354492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.11s/it]
INFO:root:final mean train loss: 3496.459580329157
INFO:root:final train perplexity: 3.972733497619629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 4020.572419727948
INFO:root:eval perplexity: 5.082490921020508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 4974.266482089428
INFO:root:eval perplexity: 7.644954681396484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [9:43:53<12:18:00, 395.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.058349609375
INFO:root:current train perplexity4.05118989944458
INFO:root:current mean train loss 3460.6835344925667
INFO:root:current train perplexity3.9217891693115234
INFO:root:current mean train loss 3470.379402949892
INFO:root:current train perplexity3.941023349761963
INFO:root:current mean train loss 3481.167208932807
INFO:root:current train perplexity3.9550466537475586
INFO:root:current mean train loss 3480.118435464485
INFO:root:current train perplexity3.9568428993225098
INFO:root:current mean train loss 3489.5035077620214
INFO:root:current train perplexity3.9640560150146484
INFO:root:current mean train loss 3490.2230246877593
INFO:root:current train perplexity3.962578535079956
INFO:root:current mean train loss 3491.866771801098
INFO:root:current train perplexity3.961787462234497
INFO:root:current mean train loss 3491.7972635575575
INFO:root:current train perplexity3.961970567703247
INFO:root:current mean train loss 3492.350597022512
INFO:root:current train perplexity3.9633848667144775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 342.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 342.00s/it]
INFO:root:final mean train loss: 3491.1134428208875
INFO:root:final train perplexity: 3.9643630981445312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 4021.756352850731
INFO:root:eval perplexity: 5.084924697875977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 4976.811547678413
INFO:root:eval perplexity: 7.652915000915527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [9:50:30<12:12:47, 396.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3547.075372869318
INFO:root:current train perplexity4.0329179763793945
INFO:root:current mean train loss 3493.1551634642456
INFO:root:current train perplexity3.946880578994751
INFO:root:current mean train loss 3477.846596378851
INFO:root:current train perplexity3.9340438842773438
INFO:root:current mean train loss 3471.511049129572
INFO:root:current train perplexity3.9279749393463135
INFO:root:current mean train loss 3480.102295515891
INFO:root:current train perplexity3.939563035964966
INFO:root:current mean train loss 3484.204502889555
INFO:root:current train perplexity3.943610429763794
INFO:root:current mean train loss 3487.0897462535804
INFO:root:current train perplexity3.947139263153076
INFO:root:current mean train loss 3486.7217772063996
INFO:root:current train perplexity3.9479947090148926
INFO:root:current mean train loss 3485.9477096538803
INFO:root:current train perplexity3.948650360107422
INFO:root:current mean train loss 3488.1813696851846
INFO:root:current train perplexity3.9525952339172363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.38s/it]
INFO:root:final mean train loss: 3485.02188497974
INFO:root:final train perplexity: 3.9548470973968506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 4021.552485039894
INFO:root:eval perplexity: 5.084505081176758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 4978.171868074025
INFO:root:eval perplexity: 7.657173156738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [9:57:08<12:06:56, 396.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.534539473684
INFO:root:current train perplexity3.9767134189605713
INFO:root:current mean train loss 3466.033859637605
INFO:root:current train perplexity3.921537160873413
INFO:root:current mean train loss 3460.1467630743437
INFO:root:current train perplexity3.910987138748169
INFO:root:current mean train loss 3465.015225497159
INFO:root:current train perplexity3.9180662631988525
INFO:root:current mean train loss 3470.0343317655506
INFO:root:current train perplexity3.9305379390716553
INFO:root:current mean train loss 3471.549533733743
INFO:root:current train perplexity3.935147523880005
INFO:root:current mean train loss 3475.207845709436
INFO:root:current train perplexity3.9386472702026367
INFO:root:current mean train loss 3480.9803132334405
INFO:root:current train perplexity3.945411443710327
INFO:root:current mean train loss 3483.171880663824
INFO:root:current train perplexity3.949012041091919
INFO:root:current mean train loss 3483.05157902399
INFO:root:current train perplexity3.947507381439209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.25s/it]
INFO:root:final mean train loss: 3481.0352292829944
INFO:root:final train perplexity: 3.948631525039673
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 4024.963410073138
INFO:root:eval perplexity: 5.091522693634033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 4984.759964746786
INFO:root:eval perplexity: 7.677828311920166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:03:45<12:00:45, 396.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3450.746681495949
INFO:root:current train perplexity3.9247958660125732
INFO:root:current mean train loss 3475.643356683686
INFO:root:current train perplexity3.922097682952881
INFO:root:current mean train loss 3479.5643595556858
INFO:root:current train perplexity3.9348361492156982
INFO:root:current mean train loss 3486.6676999713304
INFO:root:current train perplexity3.936298370361328
INFO:root:current mean train loss 3485.418938451405
INFO:root:current train perplexity3.9379851818084717
INFO:root:current mean train loss 3483.0647315472306
INFO:root:current train perplexity3.936622381210327
INFO:root:current mean train loss 3482.0931297192733
INFO:root:current train perplexity3.935108184814453
INFO:root:current mean train loss 3480.054998132845
INFO:root:current train perplexity3.936397075653076
INFO:root:current mean train loss 3478.435798986359
INFO:root:current train perplexity3.9386701583862305
INFO:root:current mean train loss 3478.222238024204
INFO:root:current train perplexity3.9383392333984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.52s/it]
INFO:root:final mean train loss: 3474.974799740699
INFO:root:final train perplexity: 3.939202308654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 28.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 28.00s/it]
INFO:root:eval mean loss: 4026.0087180712544
INFO:root:eval perplexity: 5.0936760902404785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 4986.64456761137
INFO:root:eval perplexity: 7.683748722076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:10:22<11:54:04, 396.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.4401436941966
INFO:root:current train perplexity3.923422336578369
INFO:root:current mean train loss 3470.509669777199
INFO:root:current train perplexity3.901665210723877
INFO:root:current mean train loss 3464.0457176695477
INFO:root:current train perplexity3.907794713973999
INFO:root:current mean train loss 3466.247462395056
INFO:root:current train perplexity3.914930582046509
INFO:root:current mean train loss 3471.3547526041666
INFO:root:current train perplexity3.919001817703247
INFO:root:current mean train loss 3468.677798262266
INFO:root:current train perplexity3.9231011867523193
INFO:root:current mean train loss 3466.9408741387797
INFO:root:current train perplexity3.924596071243286
INFO:root:current mean train loss 3468.023057836416
INFO:root:current train perplexity3.9250097274780273
INFO:root:current mean train loss 3468.5843542407374
INFO:root:current train perplexity3.9266271591186523
INFO:root:current mean train loss 3470.8643071628508
INFO:root:current train perplexity3.9294955730438232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.48s/it]
INFO:root:final mean train loss: 3469.7231839087704
INFO:root:final train perplexity: 3.93104887008667
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 4028.3251918495125
INFO:root:eval perplexity: 5.09844970703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 4989.887142965979
INFO:root:eval perplexity: 7.693943023681641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:16:56<11:46:09, 395.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.510617278343
INFO:root:current train perplexity3.8332669734954834
INFO:root:current mean train loss 3452.453338409637
INFO:root:current train perplexity3.8974828720092773
INFO:root:current mean train loss 3457.877296730324
INFO:root:current train perplexity3.9014792442321777
INFO:root:current mean train loss 3459.5922189606868
INFO:root:current train perplexity3.9014523029327393
INFO:root:current mean train loss 3461.2344460928684
INFO:root:current train perplexity3.904752016067505
INFO:root:current mean train loss 3463.0010624388524
INFO:root:current train perplexity3.911029100418091
INFO:root:current mean train loss 3465.978332234764
INFO:root:current train perplexity3.9159607887268066
INFO:root:current mean train loss 3469.6871323104183
INFO:root:current train perplexity3.918145179748535
INFO:root:current mean train loss 3467.310194130894
INFO:root:current train perplexity3.9182231426239014
INFO:root:current mean train loss 3468.481286608149
INFO:root:current train perplexity3.922281265258789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.60s/it]
INFO:root:final mean train loss: 3463.950493904852
INFO:root:final train perplexity: 3.922105550765991
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 4026.082450271498
INFO:root:eval perplexity: 5.093827724456787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 4989.525350800643
INFO:root:eval perplexity: 7.692805767059326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [10:23:32<11:39:43, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3456.735255821078
INFO:root:current train perplexity3.9151742458343506
INFO:root:current mean train loss 3451.10732486548
INFO:root:current train perplexity3.911931276321411
INFO:root:current mean train loss 3448.192477161666
INFO:root:current train perplexity3.90126633644104
INFO:root:current mean train loss 3453.9738595641916
INFO:root:current train perplexity3.9043397903442383
INFO:root:current mean train loss 3455.7375174308827
INFO:root:current train perplexity3.906741142272949
INFO:root:current mean train loss 3452.858996161099
INFO:root:current train perplexity3.9028995037078857
INFO:root:current mean train loss 3457.9414673789124
INFO:root:current train perplexity3.9088830947875977
INFO:root:current mean train loss 3457.5321023791194
INFO:root:current train perplexity3.9077906608581543
INFO:root:current mean train loss 3458.104348457238
INFO:root:current train perplexity3.911029100418091
INFO:root:current mean train loss 3460.9076750521654
INFO:root:current train perplexity3.912796974182129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.68s/it]
INFO:root:final mean train loss: 3459.1926017884284
INFO:root:final train perplexity: 3.914750814437866
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 4031.10575617797
INFO:root:eval perplexity: 5.104185581207275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 4993.91458714262
INFO:root:eval perplexity: 7.706623554229736
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [10:30:08<11:33:07, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3412.263142213983
INFO:root:current train perplexity3.860100507736206
INFO:root:current mean train loss 3434.3431526999802
INFO:root:current train perplexity3.8800063133239746
INFO:root:current mean train loss 3435.127504562319
INFO:root:current train perplexity3.8868396282196045
INFO:root:current mean train loss 3445.134437157251
INFO:root:current train perplexity3.8936150074005127
INFO:root:current mean train loss 3446.804978447542
INFO:root:current train perplexity3.8969802856445312
INFO:root:current mean train loss 3455.8738255918774
INFO:root:current train perplexity3.9038171768188477
INFO:root:current mean train loss 3455.7821932200777
INFO:root:current train perplexity3.9052464962005615
INFO:root:current mean train loss 3454.029049839427
INFO:root:current train perplexity3.904790163040161
INFO:root:current mean train loss 3455.7716986730575
INFO:root:current train perplexity3.908029556274414
INFO:root:current mean train loss 3456.6765775710373
INFO:root:current train perplexity3.908195972442627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.54s/it]
INFO:root:final mean train loss: 3454.8047970802554
INFO:root:final train perplexity: 3.9079792499542236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it]
INFO:root:eval mean loss: 4028.9682149684177
INFO:root:eval perplexity: 5.0997748374938965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 4991.968270376219
INFO:root:eval perplexity: 7.700494766235352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [10:36:46<11:27:24, 396.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3434.5289215543376
INFO:root:current train perplexity3.8940670490264893
INFO:root:current mean train loss 3451.1097068558197
INFO:root:current train perplexity3.8921217918395996
INFO:root:current mean train loss 3448.523556369967
INFO:root:current train perplexity3.893817901611328
INFO:root:current mean train loss 3451.6098300195845
INFO:root:current train perplexity3.899217367172241
INFO:root:current mean train loss 3446.487932552362
INFO:root:current train perplexity3.8945605754852295
INFO:root:current mean train loss 3449.9631179728835
INFO:root:current train perplexity3.8991518020629883
INFO:root:current mean train loss 3451.444010904704
INFO:root:current train perplexity3.9002251625061035
INFO:root:current mean train loss 3451.832297353732
INFO:root:current train perplexity3.901081085205078
INFO:root:current mean train loss 3449.3518252257245
INFO:root:current train perplexity3.8991260528564453
INFO:root:current mean train loss 3451.582659400853
INFO:root:current train perplexity3.9003069400787354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.20s/it]
INFO:root:final mean train loss: 3450.044122265231
INFO:root:final train perplexity: 3.900646448135376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 4029.7142948664673
INFO:root:eval perplexity: 5.101314067840576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4995.424375277039
INFO:root:eval perplexity: 7.711383819580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [10:43:21<11:19:38, 395.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3417.907425130208
INFO:root:current train perplexity3.8575282096862793
INFO:root:current mean train loss 3421.712939453125
INFO:root:current train perplexity3.8560807704925537
INFO:root:current mean train loss 3434.5463130326702
INFO:root:current train perplexity3.8653342723846436
INFO:root:current mean train loss 3441.6763444010417
INFO:root:current train perplexity3.8771276473999023
INFO:root:current mean train loss 3441.9415532483554
INFO:root:current train perplexity3.8784801959991455
INFO:root:current mean train loss 3443.5946390964673
INFO:root:current train perplexity3.8821516036987305
INFO:root:current mean train loss 3446.313491030093
INFO:root:current train perplexity3.8836488723754883
INFO:root:current mean train loss 3446.0829715851814
INFO:root:current train perplexity3.8863062858581543
INFO:root:current mean train loss 3444.7595669642856
INFO:root:current train perplexity3.888336181640625
INFO:root:current mean train loss 3446.4389443108976
INFO:root:current train perplexity3.891733407974243

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.93s/it]
INFO:root:final mean train loss: 3444.2698567913426
INFO:root:final train perplexity: 3.891770124435425
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 4030.486386995789
INFO:root:eval perplexity: 5.102907180786133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 4995.841732809729
INFO:root:eval perplexity: 7.712698459625244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [10:49:56<11:12:55, 395.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3426.1696600856553
INFO:root:current train perplexity3.856905698776245
INFO:root:current mean train loss 3428.283619364754
INFO:root:current train perplexity3.865851402282715
INFO:root:current mean train loss 3436.7687427534233
INFO:root:current train perplexity3.8737785816192627
INFO:root:current mean train loss 3434.4395774263626
INFO:root:current train perplexity3.871854305267334
INFO:root:current mean train loss 3437.7404603188083
INFO:root:current train perplexity3.873405933380127
INFO:root:current mean train loss 3433.389082265759
INFO:root:current train perplexity3.8710572719573975
INFO:root:current mean train loss 3437.639002519331
INFO:root:current train perplexity3.874831199645996
INFO:root:current mean train loss 3441.321958500459
INFO:root:current train perplexity3.8786494731903076
INFO:root:current mean train loss 3440.6332673259662
INFO:root:current train perplexity3.881032705307007
INFO:root:current mean train loss 3441.3148070419793
INFO:root:current train perplexity3.8823482990264893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.40s/it]
INFO:root:final mean train loss: 3437.9799043593866
INFO:root:final train perplexity: 3.882124185562134
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 4031.0724128019724
INFO:root:eval perplexity: 5.104116916656494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 4998.988596381871
INFO:root:eval perplexity: 7.722630977630615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [10:56:30<11:05:24, 395.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3411.679955786401
INFO:root:current train perplexity3.8606109619140625
INFO:root:current mean train loss 3412.3625155943228
INFO:root:current train perplexity3.86551570892334
INFO:root:current mean train loss 3417.349403827051
INFO:root:current train perplexity3.86612868309021
INFO:root:current mean train loss 3415.828848680267
INFO:root:current train perplexity3.8579792976379395
INFO:root:current mean train loss 3418.858035955798
INFO:root:current train perplexity3.8615028858184814
INFO:root:current mean train loss 3422.645548709153
INFO:root:current train perplexity3.8630387783050537
INFO:root:current mean train loss 3426.8356166900326
INFO:root:current train perplexity3.868115186691284
INFO:root:current mean train loss 3429.58658905608
INFO:root:current train perplexity3.869555950164795
INFO:root:current mean train loss 3431.21398364066
INFO:root:current train perplexity3.8714191913604736
INFO:root:current mean train loss 3436.7363746866326
INFO:root:current train perplexity3.876246213912964

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.36s/it]
INFO:root:final mean train loss: 3434.2150694939396
INFO:root:final train perplexity: 3.8763628005981445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 4036.143909643728
INFO:root:eval perplexity: 5.114593505859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 5005.33532108821
INFO:root:eval perplexity: 7.742700576782227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:03:06<10:58:51, 395.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3424.142856790562
INFO:root:current train perplexity3.8384382724761963
INFO:root:current mean train loss 3430.094589156721
INFO:root:current train perplexity3.844588041305542
INFO:root:current mean train loss 3421.0128137084553
INFO:root:current train perplexity3.8495965003967285
INFO:root:current mean train loss 3428.4280598958335
INFO:root:current train perplexity3.8568038940429688
INFO:root:current mean train loss 3429.227153036542
INFO:root:current train perplexity3.8652799129486084
INFO:root:current mean train loss 3432.0714280473967
INFO:root:current train perplexity3.868572235107422
INFO:root:current mean train loss 3428.251135131661
INFO:root:current train perplexity3.86567759513855
INFO:root:current mean train loss 3430.362128991806
INFO:root:current train perplexity3.8682079315185547
INFO:root:current mean train loss 3432.217480414436
INFO:root:current train perplexity3.8688907623291016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.64s/it]
INFO:root:final mean train loss: 3429.7288263997725
INFO:root:final train perplexity: 3.8695080280303955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it]
INFO:root:eval mean loss: 4038.8974626689937
INFO:root:eval perplexity: 5.1202921867370605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 5007.464609998337
INFO:root:eval perplexity: 7.749446868896484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:09:42<10:52:50, 395.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.084158761161
INFO:root:current train perplexity3.8701717853546143
INFO:root:current mean train loss 3420.64376916618
INFO:root:current train perplexity3.8320817947387695
INFO:root:current mean train loss 3420.013185952597
INFO:root:current train perplexity3.8565022945404053
INFO:root:current mean train loss 3423.0213221447475
INFO:root:current train perplexity3.8572540283203125
INFO:root:current mean train loss 3422.76727639838
INFO:root:current train perplexity3.8524019718170166
INFO:root:current mean train loss 3421.103603265224
INFO:root:current train perplexity3.853436231613159
INFO:root:current mean train loss 3421.112249584921
INFO:root:current train perplexity3.8555490970611572
INFO:root:current mean train loss 3422.2429005840036
INFO:root:current train perplexity3.8592171669006348
INFO:root:current mean train loss 3422.435563816605
INFO:root:current train perplexity3.860612630844116
INFO:root:current mean train loss 3425.7596625314395
INFO:root:current train perplexity3.860734701156616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.92s/it]
INFO:root:final mean train loss: 3425.61004564839
INFO:root:final train perplexity: 3.863224983215332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 4037.587371176862
INFO:root:eval perplexity: 5.117580890655518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 5011.383534532913
INFO:root:eval perplexity: 7.7618727684021
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:16:16<10:45:09, 395.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3409.076236979167
INFO:root:current train perplexity3.842188596725464
INFO:root:current mean train loss 3406.855910326087
INFO:root:current train perplexity3.843325614929199
INFO:root:current mean train loss 3415.2234454487643
INFO:root:current train perplexity3.8450570106506348
INFO:root:current mean train loss 3412.4009951636904
INFO:root:current train perplexity3.846780776977539
INFO:root:current mean train loss 3422.1476327183736
INFO:root:current train perplexity3.8523619174957275
INFO:root:current mean train loss 3428.158412659284
INFO:root:current train perplexity3.856553792953491
INFO:root:current mean train loss 3427.274377937627
INFO:root:current train perplexity3.8531951904296875
INFO:root:current mean train loss 3424.747221918706
INFO:root:current train perplexity3.8552093505859375
INFO:root:current mean train loss 3424.638549654908
INFO:root:current train perplexity3.8550899028778076
INFO:root:current mean train loss 3423.346250640369
INFO:root:current train perplexity3.8550283908843994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.19s/it]
INFO:root:final mean train loss: 3421.360105760636
INFO:root:final train perplexity: 3.856752872467041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 4039.990350385084
INFO:root:eval perplexity: 5.122555255889893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 5011.398044450909
INFO:root:eval perplexity: 7.761919021606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [11:22:51<10:38:47, 395.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.427596382473
INFO:root:current train perplexity3.832188367843628
INFO:root:current mean train loss 3407.8962184006605
INFO:root:current train perplexity3.81712007522583
INFO:root:current mean train loss 3408.7647622968047
INFO:root:current train perplexity3.821964740753174
INFO:root:current mean train loss 3408.9578732706077
INFO:root:current train perplexity3.8307998180389404
INFO:root:current mean train loss 3404.1552111037236
INFO:root:current train perplexity3.83115553855896
INFO:root:current mean train loss 3408.815654222186
INFO:root:current train perplexity3.8365819454193115
INFO:root:current mean train loss 3410.7302935800813
INFO:root:current train perplexity3.8384287357330322
INFO:root:current mean train loss 3412.590447854534
INFO:root:current train perplexity3.8409297466278076
INFO:root:current mean train loss 3415.2585965384833
INFO:root:current train perplexity3.845771074295044
INFO:root:current mean train loss 3417.698707721086
INFO:root:current train perplexity3.8476929664611816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it]
INFO:root:final mean train loss: 3416.6844082493935
INFO:root:final train perplexity: 3.849644660949707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 4040.63971250277
INFO:root:eval perplexity: 5.123900890350342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 5016.123966298205
INFO:root:eval perplexity: 7.776932716369629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [11:29:25<10:31:45, 394.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.6947454637098
INFO:root:current train perplexity3.8078877925872803
INFO:root:current mean train loss 3395.8384627713504
INFO:root:current train perplexity3.8160746097564697
INFO:root:current mean train loss 3397.0666461630817
INFO:root:current train perplexity3.826943874359131
INFO:root:current mean train loss 3399.9025569120563
INFO:root:current train perplexity3.830681562423706
INFO:root:current mean train loss 3404.1988919074465
INFO:root:current train perplexity3.8335187435150146
INFO:root:current mean train loss 3410.900949251854
INFO:root:current train perplexity3.8402786254882812
INFO:root:current mean train loss 3412.4669276508025
INFO:root:current train perplexity3.841914653778076
INFO:root:current mean train loss 3414.41442720802
INFO:root:current train perplexity3.8399157524108887
INFO:root:current mean train loss 3416.6335557921557
INFO:root:current train perplexity3.8397161960601807
INFO:root:current mean train loss 3413.0483267320087
INFO:root:current train perplexity3.8408570289611816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.34s/it]
INFO:root:final mean train loss: 3411.728825538389
INFO:root:final train perplexity: 3.8421249389648438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 4043.6718975094195
INFO:root:eval perplexity: 5.130187034606934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 5019.596316073803
INFO:root:eval perplexity: 7.787981986999512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [11:36:02<10:26:08, 395.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3375.348545172276
INFO:root:current train perplexity3.7853879928588867
INFO:root:current mean train loss 3381.19217555643
INFO:root:current train perplexity3.805788516998291
INFO:root:current mean train loss 3385.0363616304917
INFO:root:current train perplexity3.821767568588257
INFO:root:current mean train loss 3391.169025252351
INFO:root:current train perplexity3.8260998725891113
INFO:root:current mean train loss 3400.625207992241
INFO:root:current train perplexity3.830526351928711
INFO:root:current mean train loss 3401.0509348004116
INFO:root:current train perplexity3.8297030925750732
INFO:root:current mean train loss 3402.553132106441
INFO:root:current train perplexity3.8289401531219482
INFO:root:current mean train loss 3405.160052184646
INFO:root:current train perplexity3.83284068107605
INFO:root:current mean train loss 3405.1361705248064
INFO:root:current train perplexity3.831022262573242
INFO:root:current mean train loss 3407.867995062067
INFO:root:current train perplexity3.833284378051758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.04s/it]
INFO:root:final mean train loss: 3407.185315532069
INFO:root:final train perplexity: 3.8352444171905518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 4042.3665416528147
INFO:root:eval perplexity: 5.1274800300598145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it]
INFO:root:eval mean loss: 5020.790534269725
INFO:root:eval perplexity: 7.791785717010498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [11:42:36<10:18:55, 395.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3377.36606029754
INFO:root:current train perplexity3.8157575130462646
INFO:root:current mean train loss 3397.6057843059098
INFO:root:current train perplexity3.837503671646118
INFO:root:current mean train loss 3395.856948420104
INFO:root:current train perplexity3.8246843814849854
INFO:root:current mean train loss 3399.6208137270355
INFO:root:current train perplexity3.822695732116699
INFO:root:current mean train loss 3405.629685096826
INFO:root:current train perplexity3.8278439044952393
INFO:root:current mean train loss 3402.78870633141
INFO:root:current train perplexity3.8244423866271973
INFO:root:current mean train loss 3402.317080183781
INFO:root:current train perplexity3.8212273120880127
INFO:root:current mean train loss 3404.4974549892277
INFO:root:current train perplexity3.823737144470215
INFO:root:current mean train loss 3403.5726962579324
INFO:root:current train perplexity3.8256032466888428
INFO:root:current mean train loss 3403.8281964117773
INFO:root:current train perplexity3.8283090591430664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.24s/it]
INFO:root:final mean train loss: 3402.7972654527234
INFO:root:final train perplexity: 3.82861065864563
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 4043.1031416223404
INFO:root:eval perplexity: 5.129007339477539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it]
INFO:root:eval mean loss: 5021.580957723848
INFO:root:eval perplexity: 7.794307231903076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [11:49:15<10:13:54, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.2469016335226
INFO:root:current train perplexity3.8069164752960205
INFO:root:current mean train loss 3382.353611706149
INFO:root:current train perplexity3.7890517711639404
INFO:root:current mean train loss 3392.998449946385
INFO:root:current train perplexity3.7981410026550293
INFO:root:current mean train loss 3398.4895968584947
INFO:root:current train perplexity3.8052825927734375
INFO:root:current mean train loss 3396.8992031893886
INFO:root:current train perplexity3.804720640182495
INFO:root:current mean train loss 3401.5987027554897
INFO:root:current train perplexity3.812009334564209
INFO:root:current mean train loss 3402.200806968631
INFO:root:current train perplexity3.8169801235198975
INFO:root:current mean train loss 3399.7002328228477
INFO:root:current train perplexity3.815680742263794
INFO:root:current mean train loss 3400.384324744152
INFO:root:current train perplexity3.8188910484313965
INFO:root:current mean train loss 3400.773589608557
INFO:root:current train perplexity3.8206610679626465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.38s/it]
INFO:root:final mean train loss: 3398.5646748696604
INFO:root:final train perplexity: 3.8222227096557617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 4047.093235746343
INFO:root:eval perplexity: 5.137289524078369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 5025.915626038896
INFO:root:eval perplexity: 7.808134078979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [11:55:52<10:07:53, 396.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3386.5575009300596
INFO:root:current train perplexity3.77559494972229
INFO:root:current mean train loss 3381.648636706768
INFO:root:current train perplexity3.7954494953155518
INFO:root:current mean train loss 3385.6462096007604
INFO:root:current train perplexity3.7936201095581055
INFO:root:current mean train loss 3382.9629451026603
INFO:root:current train perplexity3.798049211502075
INFO:root:current mean train loss 3386.6052430649297
INFO:root:current train perplexity3.7998859882354736
INFO:root:current mean train loss 3388.004053254746
INFO:root:current train perplexity3.8042898178100586
INFO:root:current mean train loss 3395.161133180736
INFO:root:current train perplexity3.8111419677734375
INFO:root:current mean train loss 3397.056070110276
INFO:root:current train perplexity3.813838005065918
INFO:root:current mean train loss 3394.478816628042
INFO:root:current train perplexity3.812804698944092
INFO:root:current mean train loss 3395.0843839239355
INFO:root:current train perplexity3.814690113067627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.18s/it]
INFO:root:final mean train loss: 3393.947707883773
INFO:root:final train perplexity: 3.8152668476104736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 4045.447417996454
INFO:root:eval perplexity: 5.133871555328369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.71s/it]
INFO:root:eval mean loss: 5025.864347850177
INFO:root:eval perplexity: 7.80797004699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [12:02:23<9:58:36, 394.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3337.0484154929577
INFO:root:current train perplexity3.783987045288086
INFO:root:current mean train loss 3362.5078539039655
INFO:root:current train perplexity3.795072078704834
INFO:root:current mean train loss 3365.4989964108627
INFO:root:current train perplexity3.7906293869018555
INFO:root:current mean train loss 3379.518752105795
INFO:root:current train perplexity3.7920660972595215
INFO:root:current mean train loss 3385.522022935742
INFO:root:current train perplexity3.798466205596924
INFO:root:current mean train loss 3386.4605428558725
INFO:root:current train perplexity3.8033134937286377
INFO:root:current mean train loss 3387.4386999639064
INFO:root:current train perplexity3.8025319576263428
INFO:root:current mean train loss 3391.154412137241
INFO:root:current train perplexity3.803701639175415
INFO:root:current mean train loss 3391.4760921579004
INFO:root:current train perplexity3.807837724685669
INFO:root:current mean train loss 3391.078975092125
INFO:root:current train perplexity3.8071210384368896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.02s/it]
INFO:root:final mean train loss: 3388.8605403284873
INFO:root:final train perplexity: 3.807616710662842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 4046.75629744293
INFO:root:eval perplexity: 5.136589527130127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 5029.184094151707
INFO:root:eval perplexity: 7.818575382232666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [12:08:58<9:52:25, 394.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.5255760482596
INFO:root:current train perplexity3.8175125122070312
INFO:root:current mean train loss 3393.3049534632505
INFO:root:current train perplexity3.805877685546875
INFO:root:current mean train loss 3388.5490048863126
INFO:root:current train perplexity3.8042688369750977
INFO:root:current mean train loss 3386.160789469616
INFO:root:current train perplexity3.799276351928711
INFO:root:current mean train loss 3385.0171260316088
INFO:root:current train perplexity3.8010494709014893
INFO:root:current mean train loss 3385.199610892973
INFO:root:current train perplexity3.8019418716430664
INFO:root:current mean train loss 3387.352248179193
INFO:root:current train perplexity3.8010928630828857
INFO:root:current mean train loss 3388.4916450001
INFO:root:current train perplexity3.7998719215393066
INFO:root:current mean train loss 3389.0815238041278
INFO:root:current train perplexity3.8025591373443604
INFO:root:current mean train loss 3387.7311485532114
INFO:root:current train perplexity3.8026065826416016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.27s/it]
INFO:root:final mean train loss: 3385.7714760072768
INFO:root:final train perplexity: 3.8029792308807373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it]
INFO:root:eval mean loss: 4050.457088389295
INFO:root:eval perplexity: 5.144282817840576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 5031.566063414229
INFO:root:eval perplexity: 7.82619571685791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [12:15:36<9:47:14, 395.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.5493416621766
INFO:root:current train perplexity3.796553611755371
INFO:root:current mean train loss 3375.1092392212568
INFO:root:current train perplexity3.792387008666992
INFO:root:current mean train loss 3377.823058444033
INFO:root:current train perplexity3.7889957427978516
INFO:root:current mean train loss 3377.7552928678133
INFO:root:current train perplexity3.7865772247314453
INFO:root:current mean train loss 3380.4773244994867
INFO:root:current train perplexity3.7880468368530273
INFO:root:current mean train loss 3379.183413659897
INFO:root:current train perplexity3.79113507270813
INFO:root:current mean train loss 3380.746854957014
INFO:root:current train perplexity3.7915430068969727
slurmstepd: error: *** JOB 26219484 ON gv010 CANCELLED AT 2022-10-24T11:46:22 ***
