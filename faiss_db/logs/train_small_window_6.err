INFO:root:Output: small_window_6
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97831.6373895202
INFO:root:current train perplexity15176.44140625
INFO:root:current mean train loss 81427.33801821608
INFO:root:current train perplexity3046.05810546875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.28s/it]
INFO:root:final mean train loss: 75055.79644972278
INFO:root:final train perplexity: 1640.7705078125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.37s/it]
INFO:root:eval mean loss: 44166.19800967262
INFO:root:eval perplexity: 96.64181518554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/1

  0%|          | 1/200 [05:39<18:47:33, 339.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42875.27979473039
INFO:root:current train perplexity69.33132934570312
INFO:root:current mean train loss 39106.83666183775
INFO:root:current train perplexity47.228416442871094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 278.00s/it]
INFO:root:final mean train loss: 36518.196470199095
INFO:root:final train perplexity: 36.66677474975586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:eval mean loss: 31773.375093005954
INFO:root:eval perplexity: 26.800138473510742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/2

  1%|          | 2/200 [11:06<18:15:21, 331.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31215.370442708332
INFO:root:current train perplexity22.06291389465332
INFO:root:current mean train loss 29705.66753261529
INFO:root:current train perplexity18.68083953857422
INFO:root:current mean train loss 28794.850561884236
INFO:root:current train perplexity17.077472686767578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it]
INFO:root:final mean train loss: 28412.80724703881
INFO:root:final train perplexity: 16.48447036743164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.56s/it]
INFO:root:eval mean loss: 28536.74683779762
INFO:root:eval perplexity: 19.171611785888672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/3

  2%|â–         | 3/200 [16:37<18:08:07, 331.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26386.431356534093
INFO:root:current train perplexity13.423677444458008
INFO:root:current mean train loss 25906.61168094758
INFO:root:current train perplexity12.843212127685547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.20s/it]
INFO:root:final mean train loss: 25531.425190587197
INFO:root:final train perplexity: 12.406513214111328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.74s/it]
INFO:root:eval mean loss: 27117.625465029763
INFO:root:eval perplexity: 16.55283546447754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/4

  2%|â–         | 4/200 [22:07<18:01:21, 331.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24890.7578125
INFO:root:current train perplexity11.329607009887695
INFO:root:current mean train loss 24371.984009929907
INFO:root:current train perplexity11.011435508728027
INFO:root:current mean train loss 24090.580710295893
INFO:root:current train perplexity10.754704475402832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.66s/it]
INFO:root:final mean train loss: 23979.3341733871
INFO:root:final train perplexity: 10.645480155944824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it]
INFO:root:eval mean loss: 26302.545317150296
INFO:root:eval perplexity: 15.213754653930664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/5

  2%|â–Ž         | 5/200 [27:36<17:53:16, 330.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23354.16015625
INFO:root:current train perplexity10.002480506896973
INFO:root:current mean train loss 23111.04148240959
INFO:root:current train perplexity9.756719589233398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.41s/it]
INFO:root:final mean train loss: 22961.934515183973
INFO:root:final train perplexity: 9.629070281982422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.83s/it]
INFO:root:eval mean loss: 25734.878464471727
INFO:root:eval perplexity: 14.34567642211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/6

  3%|â–Ž         | 6/200 [33:20<18:03:34, 335.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22356.01935369318
INFO:root:current train perplexity9.123744010925293
INFO:root:current mean train loss 22383.35575028153
INFO:root:current train perplexity9.086969375610352
INFO:root:current mean train loss 22264.54874481635
INFO:root:current train perplexity8.978118896484375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.77s/it]
INFO:root:final mean train loss: 22216.949856665826
INFO:root:final train perplexity: 8.94690227508545
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it]
INFO:root:eval mean loss: 25304.938430059523
INFO:root:eval perplexity: 13.721336364746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/7

  4%|â–Ž         | 7/200 [38:57<17:59:31, 335.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21857.933996775795
INFO:root:current train perplexity8.622023582458496
INFO:root:current mean train loss 21764.231798792178
INFO:root:current train perplexity8.527304649353027


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.81s/it]
INFO:root:final mean train loss: 21644.42554498488
INFO:root:final train perplexity: 8.455677032470703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it]
INFO:root:eval mean loss: 24993.25318545387
INFO:root:eval perplexity: 13.285776138305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/8

  4%|â–         | 8/200 [44:32<17:52:57, 335.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21403.510286458335
INFO:root:current train perplexity8.181026458740234
INFO:root:current mean train loss 21332.585088315216
INFO:root:current train perplexity8.168036460876465
INFO:root:current mean train loss 21217.488144985466
INFO:root:current train perplexity8.094208717346191


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.50s/it]
INFO:root:final mean train loss: 21182.036353326614
INFO:root:final train perplexity: 8.078703880310059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it]
INFO:root:eval mean loss: 24706.008370535714
INFO:root:eval perplexity: 12.896620750427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/9

  4%|â–         | 9/200 [49:57<17:37:30, 332.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20942.2421875
INFO:root:current train perplexity7.850913047790527
INFO:root:current mean train loss 20883.473346276198
INFO:root:current train perplexity7.822862148284912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.06s/it]
INFO:root:final mean train loss: 20788.91206605973
INFO:root:final train perplexity: 7.771450042724609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:eval mean loss: 24490.506789434523
INFO:root:eval perplexity: 12.612164497375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/10

  5%|â–Œ         | 10/200 [55:17<17:20:17, 328.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20771.046875
INFO:root:current train perplexity7.625456809997559
INFO:root:current mean train loss 20584.812040441175
INFO:root:current train perplexity7.5693864822387695
INFO:root:current mean train loss 20495.08124643265
INFO:root:current train perplexity7.537492752075195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.05s/it]
INFO:root:final mean train loss: 20469.372873613913
INFO:root:final train perplexity: 7.530336380004883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.85s/it]
INFO:root:eval mean loss: 24270.805803571428
INFO:root:eval perplexity: 12.328624725341797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/11

  6%|â–Œ         | 11/200 [1:00:43<17:11:51, 327.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20285.410651408452
INFO:root:current train perplexity7.347226619720459
INFO:root:current mean train loss 20220.21833881579
INFO:root:current train perplexity7.333240032196045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.99s/it]
INFO:root:final mean train loss: 20172.04830046623
INFO:root:final train perplexity: 7.312711238861084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it]
INFO:root:eval mean loss: 24110.52515811012
INFO:root:eval perplexity: 12.125799179077148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/12

  6%|â–Œ         | 12/200 [1:06:04<17:00:27, 325.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20047.689028532608
INFO:root:current train perplexity7.194312572479248
INFO:root:current mean train loss 19946.69582063008
INFO:root:current train perplexity7.15690803527832
INFO:root:current mean train loss 19922.97338319787
INFO:root:current train perplexity7.131985187530518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.97s/it]
INFO:root:final mean train loss: 19918.192453692038
INFO:root:final train perplexity: 7.131887435913086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it]
INFO:root:eval mean loss: 23946.27855282738
INFO:root:eval perplexity: 11.921417236328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/13

  6%|â–‹         | 13/200 [1:11:27<16:51:55, 324.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19798.9246875
INFO:root:current train perplexity7.004118919372559
INFO:root:current mean train loss 19729.033203125
INFO:root:current train perplexity6.9905524253845215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.77s/it]
INFO:root:final mean train loss: 19691.367132371473
INFO:root:final train perplexity: 6.974101543426514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.08s/it]
INFO:root:eval mean loss: 23816.723074776786
INFO:root:eval perplexity: 11.7626371383667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/14

  7%|â–‹         | 14/200 [1:16:55<16:49:54, 325.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19497.66182002315
INFO:root:current train perplexity6.8698835372924805
INFO:root:current mean train loss 19461.012364665356
INFO:root:current train perplexity6.84635591506958
INFO:root:current mean train loss 19500.764781800663
INFO:root:current train perplexity6.83674955368042


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.38s/it]
INFO:root:final mean train loss: 19480.47028966104
INFO:root:final train perplexity: 6.830529689788818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.84s/it]
INFO:root:eval mean loss: 23709.246163504464
INFO:root:eval perplexity: 11.632524490356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/15

  8%|â–Š         | 15/200 [1:22:24<16:47:17, 326.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19305.23180379747
INFO:root:current train perplexity6.721061706542969
INFO:root:current mean train loss 19313.016214210893
INFO:root:current train perplexity6.716220378875732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.52s/it]
INFO:root:final mean train loss: 19300.233410250756
INFO:root:final train perplexity: 6.710175037384033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it]
INFO:root:eval mean loss: 23591.637672061013
INFO:root:eval perplexity: 11.491791725158691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/16

  8%|â–Š         | 16/200 [1:27:47<16:38:43, 325.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19096.87752016129
INFO:root:current train perplexity6.639891624450684
INFO:root:current mean train loss 19135.94947220897
INFO:root:current train perplexity6.599163055419922
INFO:root:current mean train loss 19131.422754329004
INFO:root:current train perplexity6.595207214355469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.30s/it]
INFO:root:final mean train loss: 19127.907978673134
INFO:root:final train perplexity: 6.59708833694458
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.54s/it]
INFO:root:eval mean loss: 23487.428083147322
INFO:root:eval perplexity: 11.368514060974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/17

  8%|â–Š         | 17/200 [1:33:09<16:30:13, 324.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18970.581607680724
INFO:root:current train perplexity6.493052005767822
INFO:root:current mean train loss 18987.267620816256
INFO:root:current train perplexity6.489473819732666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.80s/it]
INFO:root:final mean train loss: 18971.27590253276
INFO:root:final train perplexity: 6.495952606201172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.94s/it]
INFO:root:eval mean loss: 23419.839890252977
INFO:root:eval perplexity: 11.28926944732666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/18

  9%|â–‰         | 18/200 [1:38:31<16:21:59, 323.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18903.762555803572
INFO:root:current train perplexity6.4429402351379395
INFO:root:current mean train loss 18897.754861111112
INFO:root:current train perplexity6.431396961212158
INFO:root:current mean train loss 18827.840467087764
INFO:root:current train perplexity6.400599479675293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.24s/it]
INFO:root:final mean train loss: 18826.8712827621
INFO:root:final train perplexity: 6.404086589813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it]
INFO:root:eval mean loss: 23338.19656808036
INFO:root:eval perplexity: 11.194276809692383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/19

 10%|â–‰         | 19/200 [1:43:53<16:14:53, 323.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18679.90896641523
INFO:root:current train perplexity6.29710054397583
INFO:root:current mean train loss 18714.69277448195
INFO:root:current train perplexity6.314085960388184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.31s/it]
INFO:root:final mean train loss: 18685.77213410408
INFO:root:final train perplexity: 6.315577983856201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it]
INFO:root:eval mean loss: 23259.703706287204
INFO:root:eval perplexity: 11.103707313537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/20

 10%|â–ˆ         | 20/200 [1:49:14<16:07:35, 322.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18710.362029246793
INFO:root:current train perplexity6.264206886291504
INFO:root:current mean train loss 18595.830457508993
INFO:root:current train perplexity6.245484828948975
INFO:root:current mean train loss 18586.32313186454
INFO:root:current train perplexity6.243126392364502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.39s/it]
INFO:root:final mean train loss: 18564.047973632812
INFO:root:final train perplexity: 6.240208148956299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it]
INFO:root:eval mean loss: 23207.15599423363
INFO:root:eval perplexity: 11.043487548828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/21

 10%|â–ˆ         | 21/200 [1:54:36<16:01:54, 322.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18429.855812156595
INFO:root:current train perplexity6.160894393920898
INFO:root:current mean train loss 18453.50714782395
INFO:root:current train perplexity6.158729553222656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.69s/it]
INFO:root:final mean train loss: 18440.117502520163
INFO:root:final train perplexity: 6.164394855499268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.22s/it]
INFO:root:eval mean loss: 23124.96121651786
INFO:root:eval perplexity: 10.949939727783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/22

 11%|â–ˆ         | 22/200 [2:00:09<16:06:10, 325.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18380.292787063954
INFO:root:current train perplexity6.1201863288879395
INFO:root:current mean train loss 18349.905935861014
INFO:root:current train perplexity6.103307723999023
INFO:root:current mean train loss 18351.486633551955
INFO:root:current train perplexity6.098879814147949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.66s/it]
INFO:root:final mean train loss: 18329.056475239417
INFO:root:final train perplexity: 6.097237586975098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 23094.882463727678
INFO:root:eval perplexity: 10.915904998779297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/23

 12%|â–ˆâ–        | 23/200 [2:05:29<15:55:42, 323.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18284.989720394737
INFO:root:current train perplexity6.0406694412231445
INFO:root:current mean train loss 18246.621264022437
INFO:root:current train perplexity6.032869338989258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.06s/it]
INFO:root:final mean train loss: 18225.006713867188
INFO:root:final train perplexity: 6.034983158111572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.27s/it]
INFO:root:eval mean loss: 23020.997023809523
INFO:root:eval perplexity: 10.832751274108887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/24

 12%|â–ˆâ–        | 24/200 [2:10:52<15:49:19, 323.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18073.547456781915
INFO:root:current train perplexity5.9641923904418945
INFO:root:current mean train loss 18131.036896789967
INFO:root:current train perplexity5.978797435760498
INFO:root:current mean train loss 18138.571245571864
INFO:root:current train perplexity5.976529121398926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.81s/it]
INFO:root:final mean train loss: 18125.718151461693
INFO:root:final train perplexity: 5.976171493530273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it]
INFO:root:eval mean loss: 23015.90799386161
INFO:root:eval perplexity: 10.827045440673828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/25

 12%|â–ˆâ–Ž        | 25/200 [2:16:27<15:53:52, 327.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18079.80472695707
INFO:root:current train perplexity5.937395095825195
INFO:root:current mean train loss 18060.356744660803
INFO:root:current train perplexity5.919609546661377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.21s/it]
INFO:root:final mean train loss: 18031.289216072328
INFO:root:final train perplexity: 5.920769691467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.92s/it]
INFO:root:eval mean loss: 22968.392717633928
INFO:root:eval perplexity: 10.773932456970215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/26

 13%|â–ˆâ–Ž        | 26/200 [2:21:56<15:50:02, 327.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17952.83318014706
INFO:root:current train perplexity5.88497257232666
INFO:root:current mean train loss 17973.115027421358
INFO:root:current train perplexity5.879329204559326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.84s/it]
INFO:root:final mean train loss: 17940.053766066027
INFO:root:final train perplexity: 5.8677287101745605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it]
INFO:root:eval mean loss: 22911.055687313987
INFO:root:eval perplexity: 10.710188865661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/27

 14%|â–ˆâ–Ž        | 27/200 [2:27:26<15:46:53, 328.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18030.811848958332
INFO:root:current train perplexity5.82155179977417
INFO:root:current mean train loss 17892.39466398665
INFO:root:current train perplexity5.836277961730957
INFO:root:current mean train loss 17887.077951816504
INFO:root:current train perplexity5.822789192199707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.33s/it]
INFO:root:final mean train loss: 17859.757584110383
INFO:root:final train perplexity: 5.821440696716309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it]
INFO:root:eval mean loss: 22866.523902529763
INFO:root:eval perplexity: 10.660941123962402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/28

 14%|â–ˆâ–        | 28/200 [2:32:48<15:35:28, 326.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17840.52286931818
INFO:root:current train perplexity5.794338226318359
INFO:root:current mean train loss 17817.586277721774
INFO:root:current train perplexity5.783170700073242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.23s/it]
INFO:root:final mean train loss: 17779.500338646674
INFO:root:final train perplexity: 5.775540351867676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it]
INFO:root:eval mean loss: 22839.780412946428
INFO:root:eval perplexity: 10.631474494934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/29

 14%|â–ˆâ–        | 29/200 [2:38:11<15:27:25, 325.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17816.020089285714
INFO:root:current train perplexity5.737850189208984
INFO:root:current mean train loss 17813.847218165887
INFO:root:current train perplexity5.74234676361084
INFO:root:current mean train loss 17751.107563405796
INFO:root:current train perplexity5.7350969314575195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.43s/it]
INFO:root:final mean train loss: 17705.901571950606
INFO:root:final train perplexity: 5.733766078948975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it]
INFO:root:eval mean loss: 22796.89920479911
INFO:root:eval perplexity: 10.584394454956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/30

 15%|â–ˆâ–Œ        | 30/200 [2:43:31<15:17:53, 323.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17657.543001853814
INFO:root:current train perplexity5.698151588439941
INFO:root:current mean train loss 17650.59211625393
INFO:root:current train perplexity5.694019317626953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.49s/it]
INFO:root:final mean train loss: 17630.04343734249
INFO:root:final train perplexity: 5.691025257110596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it]
INFO:root:eval mean loss: 22757.515206473214
INFO:root:eval perplexity: 10.541340827941895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/31

 16%|â–ˆâ–Œ        | 31/200 [2:49:11<15:25:28, 328.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17486.32830255682
INFO:root:current train perplexity5.619826316833496
INFO:root:current mean train loss 17561.473764780407
INFO:root:current train perplexity5.632323741912842
INFO:root:current mean train loss 17569.90950829384
INFO:root:current train perplexity5.652949333190918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.31s/it]
INFO:root:final mean train loss: 17556.566201486894
INFO:root:final train perplexity: 5.649930477142334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.14s/it]
INFO:root:eval mean loss: 22746.946358816964
INFO:root:eval perplexity: 10.529815673828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/32

 16%|â–ˆâ–Œ        | 32/200 [2:54:38<15:18:34, 328.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17498.179811507936
INFO:root:current train perplexity5.5994343757629395
INFO:root:current mean train loss 17510.1944617523
INFO:root:current train perplexity5.614941596984863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.35s/it]
INFO:root:final mean train loss: 17490.915224136847
INFO:root:final train perplexity: 5.613463878631592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.98s/it]
INFO:root:eval mean loss: 22745.789155505954
INFO:root:eval perplexity: 10.528555870056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/33

 16%|â–ˆâ–‹        | 33/200 [3:00:08<15:15:22, 328.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17268.711197916666
INFO:root:current train perplexity5.528520107269287
INFO:root:current mean train loss 17421.687516983697
INFO:root:current train perplexity5.575383186340332
INFO:root:current mean train loss 17407.547211119185
INFO:root:current train perplexity5.565219402313232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.90s/it]
INFO:root:final mean train loss: 17423.458948935233
INFO:root:final train perplexity: 5.576240539550781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it]
INFO:root:eval mean loss: 22674.73804873512
INFO:root:eval perplexity: 10.451417922973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/34

 17%|â–ˆâ–‹        | 34/200 [3:05:35<15:07:47, 328.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17353.058535447763
INFO:root:current train perplexity5.535926818847656
INFO:root:current mean train loss 17379.300980071108
INFO:root:current train perplexity5.540863990783691


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.29s/it]
INFO:root:final mean train loss: 17359.00267373362
INFO:root:final train perplexity: 5.540902137756348
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.49s/it]
INFO:root:eval mean loss: 22647.669363839286
INFO:root:eval perplexity: 10.42218017578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/35

 18%|â–ˆâ–Š        | 35/200 [3:10:59<14:59:10, 326.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17499.092413651317
INFO:root:current train perplexity5.568079948425293
INFO:root:current mean train loss 17344.746651785714
INFO:root:current train perplexity5.521305084228516
INFO:root:current mean train loss 17319.507067815353
INFO:root:current train perplexity5.5091094970703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.36s/it]
INFO:root:final mean train loss: 17301.708779611894
INFO:root:final train perplexity: 5.509678363800049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it]
INFO:root:eval mean loss: 22662.71554129464
INFO:root:eval perplexity: 10.438423156738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/36

 18%|â–ˆâ–Š        | 36/200 [3:16:22<14:50:39, 325.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17222.430526518485
INFO:root:current train perplexity5.465883731842041
INFO:root:current mean train loss 17237.49496870431
INFO:root:current train perplexity5.478035926818848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.66s/it]
INFO:root:final mean train loss: 17245.024079353578
INFO:root:final train perplexity: 5.478959560394287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it]
INFO:root:eval mean loss: 22607.23953683036
INFO:root:eval perplexity: 10.37865924835205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/37

 18%|â–ˆâ–Š        | 37/200 [3:21:54<14:49:58, 327.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17117.656632133152
INFO:root:current train perplexity5.411911964416504
INFO:root:current mean train loss 17128.94019944106
INFO:root:current train perplexity5.43279504776001
INFO:root:current mean train loss 17200.000253993832
INFO:root:current train perplexity5.447699069976807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.91s/it]
INFO:root:final mean train loss: 17185.5294858871
INFO:root:final train perplexity: 5.446902275085449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it]
INFO:root:eval mean loss: 22597.597214471727
INFO:root:eval perplexity: 10.368309020996094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/38

 19%|â–ˆâ–‰        | 38/200 [3:27:14<14:38:07, 325.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17156.7609765625
INFO:root:current train perplexity5.413493633270264
INFO:root:current mean train loss 17137.26048549107
INFO:root:current train perplexity5.413399696350098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.03s/it]
INFO:root:final mean train loss: 17133.33663841986
INFO:root:final train perplexity: 5.418934345245361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.41s/it]
INFO:root:eval mean loss: 22587.822405133928
INFO:root:eval perplexity: 10.357823371887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/39

 20%|â–ˆâ–‰        | 39/200 [3:32:45<14:37:33, 327.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16999.711769386573
INFO:root:current train perplexity5.353202819824219
INFO:root:current mean train loss 17088.797105684054
INFO:root:current train perplexity5.392404556274414
INFO:root:current mean train loss 17092.41793863574
INFO:root:current train perplexity5.39079475402832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.18s/it]
INFO:root:final mean train loss: 17081.91957141507
INFO:root:final train perplexity: 5.391522407531738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it]
INFO:root:eval mean loss: 22568.542015438987
INFO:root:eval perplexity: 10.337179183959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/40

 20%|â–ˆâ–ˆ        | 40/200 [3:38:06<14:27:00, 325.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17064.414730023735
INFO:root:current train perplexity5.368509769439697
INFO:root:current mean train loss 17080.927363390365
INFO:root:current train perplexity5.3757710456848145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.24s/it]
INFO:root:final mean train loss: 17028.167141822076
INFO:root:final train perplexity: 5.363014221191406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.60s/it]
INFO:root:eval mean loss: 22565.56482514881
INFO:root:eval perplexity: 10.333992958068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/41

 20%|â–ˆâ–ˆ        | 41/200 [3:43:54<14:40:07, 332.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16904.400359122985
INFO:root:current train perplexity5.306527137756348
INFO:root:current mean train loss 16957.56970867128
INFO:root:current train perplexity5.322376728057861
INFO:root:current mean train loss 17000.511807528408
INFO:root:current train perplexity5.337561130523682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.07s/it]
INFO:root:final mean train loss: 16980.44234343498
INFO:root:final train perplexity: 5.33782958984375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.75s/it]
INFO:root:eval mean loss: 22517.271344866072
INFO:root:eval perplexity: 10.282469749450684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/42

 21%|â–ˆâ–ˆ        | 42/200 [3:49:37<14:42:44, 335.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16930.03721526732
INFO:root:current train perplexity5.313601493835449
INFO:root:current mean train loss 16960.806085638662
INFO:root:current train perplexity5.315938472747803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.18s/it]
INFO:root:final mean train loss: 16936.27622936618
INFO:root:final train perplexity: 5.314627647399902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.52s/it]
INFO:root:eval mean loss: 22541.297037760418
INFO:root:eval perplexity: 10.30807113647461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:55:10<14:35:40, 334.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17025.23125
INFO:root:current train perplexity5.329540252685547
INFO:root:current mean train loss 16936.855635127315
INFO:root:current train perplexity5.292878150939941
INFO:root:current mean train loss 16906.226500166224
INFO:root:current train perplexity5.291597366333008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.16s/it]
INFO:root:final mean train loss: 16889.464497227822
INFO:root:final train perplexity: 5.290144920349121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.21s/it]
INFO:root:eval mean loss: 22518.815359933036
INFO:root:eval perplexity: 10.284112930297852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:00:39<14:25:38, 332.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16829.92489448635
INFO:root:current train perplexity5.25297737121582
INFO:root:current mean train loss 16847.865772267713
INFO:root:current train perplexity5.259128093719482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.81s/it]
INFO:root:final mean train loss: 16840.59791220388
INFO:root:final train perplexity: 5.264707565307617
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.78s/it]
INFO:root:eval mean loss: 22500.00695219494
INFO:root:eval perplexity: 10.264114379882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:05:57<14:08:43, 328.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16828.609525240383
INFO:root:current train perplexity5.2502288818359375
INFO:root:current mean train loss 16803.732197054855
INFO:root:current train perplexity5.244097709655762
INFO:root:current mean train loss 16812.646443514644
INFO:root:current train perplexity5.242870807647705


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.29s/it]
INFO:root:final mean train loss: 16796.843210527975
INFO:root:final train perplexity: 5.242037773132324
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.50s/it]
INFO:root:eval mean loss: 22491.1767578125
INFO:root:eval perplexity: 10.254738807678223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:11:18<13:57:42, 326.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16791.22501717033
INFO:root:current train perplexity5.216289043426514
INFO:root:current mean train loss 16786.18427887762
INFO:root:current train perplexity5.2244791984558105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it]
INFO:root:final mean train loss: 16755.14029816658
INFO:root:final train perplexity: 5.220519542694092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it]
INFO:root:eval mean loss: 22481.382347470237
INFO:root:eval perplexity: 10.244348526000977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:16:43<13:50:33, 325.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16714.706849563954
INFO:root:current train perplexity5.195202350616455
INFO:root:current mean train loss 16727.117276278408
INFO:root:current train perplexity5.19850492477417
INFO:root:current mean train loss 16726.01650109311
INFO:root:current train perplexity5.200466632843018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.46s/it]
INFO:root:final mean train loss: 16715.394673009072
INFO:root:final train perplexity: 5.200093746185303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.03s/it]
INFO:root:eval mean loss: 22466.071940104168
INFO:root:eval perplexity: 10.228129386901855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:22:16<13:50:38, 327.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16659.432134046052
INFO:root:current train perplexity5.163332939147949
INFO:root:current mean train loss 16670.198352363783
INFO:root:current train perplexity5.168511867523193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.05s/it]
INFO:root:final mean train loss: 16673.608796150453
INFO:root:final train perplexity: 5.178706645965576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it]
INFO:root:eval mean loss: 22437.236421130954
INFO:root:eval perplexity: 10.197646141052246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:27:56<13:54:38, 331.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16650.33857629654
INFO:root:current train perplexity5.132607460021973
INFO:root:current mean train loss 16641.630905877977
INFO:root:current train perplexity5.155262470245361
INFO:root:current mean train loss 16646.2453978998
INFO:root:current train perplexity5.158928871154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.19s/it]
INFO:root:final mean train loss: 16635.68546811996
INFO:root:final train perplexity: 5.159371376037598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 22455.744675409227
INFO:root:eval perplexity: 10.21720027923584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:33:36<13:55:36, 334.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16614.55358270202
INFO:root:current train perplexity5.1276655197143555
INFO:root:current mean train loss 16581.30865754554
INFO:root:current train perplexity5.135575771331787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.93s/it]
INFO:root:final mean train loss: 16593.440094978578
INFO:root:final train perplexity: 5.137918472290039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it]
INFO:root:eval mean loss: 22447.280087425595
INFO:root:eval perplexity: 10.20825481414795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:39:14<13:52:16, 335.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16562.282149969364
INFO:root:current train perplexity5.111583232879639
INFO:root:current mean train loss 16582.14458945571
INFO:root:current train perplexity5.120378017425537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.12s/it]
INFO:root:final mean train loss: 16560.3905265562
INFO:root:final train perplexity: 5.12119722366333
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it]
INFO:root:eval mean loss: 22432.220842633928
INFO:root:eval perplexity: 10.192354202270508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:44:52<13:49:12, 336.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16633.576822916668
INFO:root:current train perplexity5.222618579864502
INFO:root:current mean train loss 16491.089464502427
INFO:root:current train perplexity5.0853166580200195
INFO:root:current mean train loss 16532.503497344518
INFO:root:current train perplexity5.1014556884765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.83s/it]
INFO:root:final mean train loss: 16524.733996975807
INFO:root:final train perplexity: 5.103219032287598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.59s/it]
INFO:root:eval mean loss: 22422.049618675595
INFO:root:eval perplexity: 10.181633949279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:50:27<13:42:40, 335.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16479.345170454544
INFO:root:current train perplexity5.091423034667969
INFO:root:current mean train loss 16527.86339465726
INFO:root:current train perplexity5.096735000610352


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.02s/it]
INFO:root:final mean train loss: 16487.224751134072
INFO:root:final train perplexity: 5.0843729972839355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it]
INFO:root:eval mean loss: 22420.341006324405
INFO:root:eval perplexity: 10.179832458496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [4:55:58<13:33:36, 334.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16348.80775669643
INFO:root:current train perplexity5.07954740524292
INFO:root:current mean train loss 16453.68504490362
INFO:root:current train perplexity5.070555686950684
INFO:root:current mean train loss 16456.480039439917
INFO:root:current train perplexity5.071839809417725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.96s/it]
INFO:root:final mean train loss: 16454.173367408013
INFO:root:final train perplexity: 5.0678253173828125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it]
INFO:root:eval mean loss: 22399.43908110119
INFO:root:eval perplexity: 10.157835960388184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:01:19<13:18:21, 330.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16440.11159295551
INFO:root:current train perplexity5.039987087249756
INFO:root:current mean train loss 16394.21721452437
INFO:root:current train perplexity5.040265083312988


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.85s/it]
INFO:root:final mean train loss: 16415.570903162803
INFO:root:final train perplexity: 5.048566818237305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.71s/it]
INFO:root:eval mean loss: 22397.746930803572
INFO:root:eval perplexity: 10.15605640411377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:06:40<13:05:59, 327.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16533.413529829544
INFO:root:current train perplexity5.07757043838501
INFO:root:current mean train loss 16376.890237894144
INFO:root:current train perplexity5.027846813201904
INFO:root:current mean train loss 16412.55137829532
INFO:root:current train perplexity5.03685188293457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.63s/it]
INFO:root:final mean train loss: 16384.647685389366
INFO:root:final train perplexity: 5.033191680908203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it]
INFO:root:eval mean loss: 22396.743210565477
INFO:root:eval perplexity: 10.155000686645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:11:59<12:54:51, 325.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16328.378658234127
INFO:root:current train perplexity4.995367527008057
INFO:root:current mean train loss 16355.14922833589
INFO:root:current train perplexity5.014598369598389


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it]
INFO:root:final mean train loss: 16355.001248267388
INFO:root:final train perplexity: 5.018496036529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.39s/it]
INFO:root:eval mean loss: 22390.843680245536
INFO:root:eval perplexity: 10.1488037109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:17:35<12:56:34, 328.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16342.868815104166
INFO:root:current train perplexity5.01888370513916
INFO:root:current mean train loss 16273.621110733695
INFO:root:current train perplexity4.9793524742126465
INFO:root:current mean train loss 16310.801498909883
INFO:root:current train perplexity4.998358249664307


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.03s/it]
INFO:root:final mean train loss: 16327.87829983619
INFO:root:final train perplexity: 5.005088806152344
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.70s/it]
INFO:root:eval mean loss: 22369.324195498513
INFO:root:eval perplexity: 10.126227378845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:23:02<12:50:30, 327.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16298.679847831158
INFO:root:current train perplexity4.969736576080322
INFO:root:current mean train loss 16296.901794068113
INFO:root:current train perplexity4.988566875457764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it]
INFO:root:final mean train loss: 16292.704794606854
INFO:root:final train perplexity: 4.9877543449401855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it]
INFO:root:eval mean loss: 22392.706984747023
INFO:root:eval perplexity: 10.150761604309082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:28:22<12:39:39, 325.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16242.049033717105
INFO:root:current train perplexity4.971158027648926
INFO:root:current mean train loss 16241.696953781513
INFO:root:current train perplexity4.968742847442627
INFO:root:current mean train loss 16263.130841538243
INFO:root:current train perplexity4.970474720001221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.38s/it]
INFO:root:final mean train loss: 16264.621192193801
INFO:root:final train perplexity: 4.973958492279053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it]
INFO:root:eval mean loss: 22363.256440662204
INFO:root:eval perplexity: 10.119867324829102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:33:43<12:30:54, 324.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16262.300561179578
INFO:root:current train perplexity4.962690830230713
INFO:root:current mean train loss 16262.703981633771
INFO:root:current train perplexity4.961838245391846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.21s/it]
INFO:root:final mean train loss: 16234.477184664818
INFO:root:final train perplexity: 4.95919132232666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it]
INFO:root:eval mean loss: 22365.60828218006
INFO:root:eval perplexity: 10.122333526611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:39:03<12:22:26, 322.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16120.550611413044
INFO:root:current train perplexity4.906939506530762
INFO:root:current mean train loss 16216.216002921748
INFO:root:current train perplexity4.936670780181885
INFO:root:current mean train loss 16220.782406109865
INFO:root:current train perplexity4.94702672958374


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.85s/it]
INFO:root:final mean train loss: 16204.26710953251
INFO:root:final train perplexity: 4.944436550140381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it]
INFO:root:eval mean loss: 22359.312313988095
INFO:root:eval perplexity: 10.115739822387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:44:38<12:25:31, 326.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16162.330833333333
INFO:root:current train perplexity4.9308247566223145
INFO:root:current mean train loss 16195.580066964285
INFO:root:current train perplexity4.925970554351807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.49s/it]
INFO:root:final mean train loss: 16173.110485446068
INFO:root:final train perplexity: 4.929265975952148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it]
INFO:root:eval mean loss: 22343.116861979168
INFO:root:eval perplexity: 10.098796844482422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [5:50:01<12:17:53, 325.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16257.652633101852
INFO:root:current train perplexity4.929183006286621
INFO:root:current mean train loss 16124.355868602363
INFO:root:current train perplexity4.9024739265441895
INFO:root:current mean train loss 16150.000985166575
INFO:root:current train perplexity4.913037300109863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.59s/it]
INFO:root:final mean train loss: 16143.815453314011
INFO:root:final train perplexity: 4.915043354034424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.54s/it]
INFO:root:eval mean loss: 22365.701102120536
INFO:root:eval perplexity: 10.122427940368652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [5:55:29<12:14:08, 326.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16143.13556912579
INFO:root:current train perplexity4.900449752807617
INFO:root:current mean train loss 16135.956294736383
INFO:root:current train perplexity4.90354585647583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.16s/it]
INFO:root:final mean train loss: 16125.957086378528
INFO:root:final train perplexity: 4.906393051147461
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.55s/it]
INFO:root:eval mean loss: 22345.402808779763
INFO:root:eval perplexity: 10.101188659667969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:00:58<12:10:34, 327.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16050.463678175403
INFO:root:current train perplexity4.861400127410889
INFO:root:current mean train loss 16107.715812857825
INFO:root:current train perplexity4.88473653793335
INFO:root:current mean train loss 16104.284458705357
INFO:root:current train perplexity4.8903703689575195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.22s/it]
INFO:root:final mean train loss: 16095.34470687374
INFO:root:final train perplexity: 4.8916015625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it]
INFO:root:eval mean loss: 22340.84493582589
INFO:root:eval perplexity: 10.096423149108887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:06:19<12:01:17, 325.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16076.5324030497
INFO:root:current train perplexity4.872876167297363
INFO:root:current mean train loss 16086.278576460041
INFO:root:current train perplexity4.875730037689209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.27s/it]
INFO:root:final mean train loss: 16069.297445974042
INFO:root:final train perplexity: 4.8790507316589355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.57s/it]
INFO:root:eval mean loss: 22339.784272693454
INFO:root:eval perplexity: 10.095314025878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:11:55<12:02:41, 328.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16131.626981026786
INFO:root:current train perplexity4.888492107391357
INFO:root:current mean train loss 16066.332899305555
INFO:root:current train perplexity4.866157054901123
INFO:root:current mean train loss 16062.317316323139
INFO:root:current train perplexity4.866961479187012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.92s/it]
INFO:root:final mean train loss: 16045.982642389114
INFO:root:final train perplexity: 4.8678436279296875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.06s/it]
INFO:root:eval mean loss: 22336.24402436756
INFO:root:eval perplexity: 10.091614723205566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:17:16<11:52:12, 326.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16024.211240571121
INFO:root:current train perplexity4.861649990081787
INFO:root:current mean train loss 16002.097964363302
INFO:root:current train perplexity4.8529534339904785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it]
INFO:root:final mean train loss: 16022.16909888483
INFO:root:final train perplexity: 4.856423377990723
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.14s/it]
INFO:root:eval mean loss: 22349.621047247023
INFO:root:eval perplexity: 10.105596542358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:22:34<11:41:43, 323.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15886.911107772436
INFO:root:current train perplexity4.829334259033203
INFO:root:current mean train loss 15954.001313792716
INFO:root:current train perplexity4.826325416564941
INFO:root:current mean train loss 15999.959446097018
INFO:root:current train perplexity4.83949089050293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.78s/it]
INFO:root:final mean train loss: 15993.535620904739
INFO:root:final train perplexity: 4.842727184295654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it]
INFO:root:eval mean loss: 22324.83814639137
INFO:root:eval perplexity: 10.0797119140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:28:02<11:38:25, 324.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15943.689957503435
INFO:root:current train perplexity4.814900875091553
INFO:root:current mean train loss 15960.169681569045
INFO:root:current train perplexity4.823232173919678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.58s/it]
INFO:root:final mean train loss: 15965.6964859501
INFO:root:final train perplexity: 4.829448699951172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.35s/it]
INFO:root:eval mean loss: 22326.097493489582
INFO:root:eval perplexity: 10.081028938293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:33:37<11:39:42, 327.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15947.846725109011
INFO:root:current train perplexity4.79615592956543
INFO:root:current mean train loss 15949.03663816652
INFO:root:current train perplexity4.814809322357178
INFO:root:current mean train loss 15955.812817483282
INFO:root:current train perplexity4.818183898925781


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.06s/it]
INFO:root:final mean train loss: 15942.065496629284
INFO:root:final train perplexity: 4.818204879760742
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 22328.813034784227
INFO:root:eval perplexity: 10.083858489990234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [6:39:01<11:31:50, 326.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15913.522214226974
INFO:root:current train perplexity4.801061630249023
INFO:root:current mean train loss 15926.584149639422
INFO:root:current train perplexity4.808093070983887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.33s/it]
INFO:root:final mean train loss: 15922.420835433468
INFO:root:final train perplexity: 4.8088788986206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it]
INFO:root:eval mean loss: 22333.242699032737
INFO:root:eval perplexity: 10.088482856750488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [6:44:22<11:22:54, 325.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15882.010991522606
INFO:root:current train perplexity4.778735637664795
INFO:root:current mean train loss 15889.968358046344
INFO:root:current train perplexity4.782073974609375
INFO:root:current mean train loss 15909.618626644737
INFO:root:current train perplexity4.796437740325928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.60s/it]
INFO:root:final mean train loss: 15896.905092300907
INFO:root:final train perplexity: 4.7967915534973145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.59s/it]
INFO:root:eval mean loss: 22320.528506324405
INFO:root:eval perplexity: 10.075214385986328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [6:49:51<11:19:50, 326.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15872.814857559975
INFO:root:current train perplexity4.779107093811035
INFO:root:current mean train loss 15881.168493836369
INFO:root:current train perplexity4.783452033996582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.11s/it]
INFO:root:final mean train loss: 15873.231965095767
INFO:root:final train perplexity: 4.785604476928711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.64s/it]
INFO:root:eval mean loss: 22333.614164806546
INFO:root:eval perplexity: 10.0888671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [6:55:13<11:11:16, 324.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15851.332146139706
INFO:root:current train perplexity4.778159141540527
INFO:root:current mean train loss 15870.083260037252
INFO:root:current train perplexity4.774980545043945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.04s/it]
INFO:root:final mean train loss: 15850.795319587955
INFO:root:final train perplexity: 4.775025367736816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it]
INFO:root:eval mean loss: 22335.65359933036
INFO:root:eval perplexity: 10.090996742248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:00:36<11:05:13, 324.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15446.248372395834
INFO:root:current train perplexity4.648680686950684
INFO:root:current mean train loss 15833.611498786408
INFO:root:current train perplexity4.7562336921691895
INFO:root:current mean train loss 15831.637435537254
INFO:root:current train perplexity4.761200428009033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.48s/it]
INFO:root:final mean train loss: 15830.639223160282
INFO:root:final train perplexity: 4.7655415534973145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.77s/it]
INFO:root:eval mean loss: 22328.365397135418
INFO:root:eval perplexity: 10.083392143249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:06:12<11:06:50, 327.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15786.796147017045
INFO:root:current train perplexity4.760725975036621
INFO:root:current mean train loss 15804.963123739919
INFO:root:current train perplexity4.753173351287842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.63s/it]
INFO:root:final mean train loss: 15806.786455708165
INFO:root:final train perplexity: 4.754344463348389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it]
INFO:root:eval mean loss: 22327.789015997023
INFO:root:eval perplexity: 10.082791328430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:11:38<10:59:43, 327.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15716.429408482143
INFO:root:current train perplexity4.708224296569824
INFO:root:current mean train loss 15814.19218202395
INFO:root:current train perplexity4.745425701141357
INFO:root:current mean train loss 15817.8450756718
INFO:root:current train perplexity4.75177526473999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.81s/it]
INFO:root:final mean train loss: 15788.32531344506
INFO:root:final train perplexity: 4.745694160461426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it]
INFO:root:eval mean loss: 22326.005464099704
INFO:root:eval perplexity: 10.080930709838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:16:54<10:48:03, 324.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15710.162837658898
INFO:root:current train perplexity4.710136413574219
INFO:root:current mean train loss 15758.080311517295
INFO:root:current train perplexity4.727817535400391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.14s/it]
INFO:root:final mean train loss: 15769.049131331905
INFO:root:final train perplexity: 4.736680030822754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it]
INFO:root:eval mean loss: 22319.731422061013
INFO:root:eval perplexity: 10.074385643005371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:22:20<10:43:35, 324.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15846.8974609375
INFO:root:current train perplexity4.803199768066406
INFO:root:current mean train loss 15779.450265695383
INFO:root:current train perplexity4.726090431213379
INFO:root:current mean train loss 15777.941174837086
INFO:root:current train perplexity4.72705078125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.41s/it]
INFO:root:final mean train loss: 15747.253918063256
INFO:root:final train perplexity: 4.726508617401123
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.98s/it]
INFO:root:eval mean loss: 22331.620628720237
INFO:root:eval perplexity: 10.086787223815918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:27:38<10:34:14, 322.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15727.76058717758
INFO:root:current train perplexity4.716976165771484
INFO:root:current mean train loss 15726.776504984662
INFO:root:current train perplexity4.721837997436523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.79s/it]
INFO:root:final mean train loss: 15726.608662266884
INFO:root:final train perplexity: 4.716894149780273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.02s/it]
INFO:root:eval mean loss: 22314.995930989582
INFO:root:eval perplexity: 10.069448471069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [7:32:58<10:27:30, 321.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15719.648893229167
INFO:root:current train perplexity4.681288242340088
INFO:root:current mean train loss 15695.252751358696
INFO:root:current train perplexity4.704668045043945
INFO:root:current mean train loss 15720.06027888808
INFO:root:current train perplexity4.708951473236084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.03s/it]
INFO:root:final mean train loss: 15707.478988155242
INFO:root:final train perplexity: 4.70800256729126
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.03s/it]
INFO:root:eval mean loss: 22329.02615792411
INFO:root:eval perplexity: 10.08407974243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [7:38:16<10:19:41, 320.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15634.478194962687
INFO:root:current train perplexity4.6808271408081055
INFO:root:current mean train loss 15691.340288173653
INFO:root:current train perplexity4.695743560791016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.25s/it]
INFO:root:final mean train loss: 15687.365191059727
INFO:root:final train perplexity: 4.698671817779541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it]
INFO:root:eval mean loss: 22312.348702566964
INFO:root:eval perplexity: 10.066690444946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [7:43:53<10:23:46, 325.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15469.378752055922
INFO:root:current train perplexity4.685510158538818
INFO:root:current mean train loss 15690.47696461397
INFO:root:current train perplexity4.689525127410889
INFO:root:current mean train loss 15683.574673587329
INFO:root:current train perplexity4.6898908615112305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.65s/it]
INFO:root:final mean train loss: 15669.744778540826
INFO:root:final train perplexity: 4.690512657165527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it]
INFO:root:eval mean loss: 22317.660714285714
INFO:root:eval perplexity: 10.072226524353027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [7:49:18<10:18:09, 325.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15590.86738006162
INFO:root:current train perplexity4.67840576171875
INFO:root:current mean train loss 15643.34192822551
INFO:root:current train perplexity4.677706718444824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.49s/it]
INFO:root:final mean train loss: 15649.0238312752
INFO:root:final train perplexity: 4.680936336517334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.52s/it]
INFO:root:eval mean loss: 22326.44189453125
INFO:root:eval perplexity: 10.081384658813477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [7:54:34<10:07:35, 322.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15658.670091711956
INFO:root:current train perplexity4.661590099334717
INFO:root:current mean train loss 15627.726951537094
INFO:root:current train perplexity4.665653228759766
INFO:root:current mean train loss 15636.7816835412
INFO:root:current train perplexity4.670179843902588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.37s/it]
INFO:root:final mean train loss: 15627.302301222278
INFO:root:final train perplexity: 4.6709184646606445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.76s/it]
INFO:root:eval mean loss: 22331.966122581845
INFO:root:eval perplexity: 10.087150573730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [7:59:50<9:58:48, 320.79s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15625.157330729167
INFO:root:current train perplexity4.657047271728516
INFO:root:current mean train loss 15614.420580357142
INFO:root:current train perplexity4.662728309631348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.98s/it]
INFO:root:final mean train loss: 15616.34146216608
INFO:root:final train perplexity: 4.665871620178223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it]
INFO:root:eval mean loss: 22306.917503720237
INFO:root:eval perplexity: 10.06103229522705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:05:08<9:51:49, 319.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15566.57957175926
INFO:root:current train perplexity4.645507335662842
INFO:root:current mean train loss 15557.09365003691
INFO:root:current train perplexity4.639367580413818
INFO:root:current mean train loss 15596.497268206222
INFO:root:current train perplexity4.653056621551514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.51s/it]
INFO:root:final mean train loss: 15596.713879000756
INFO:root:final train perplexity: 4.656847953796387
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.43s/it]
INFO:root:eval mean loss: 22313.398879278273
INFO:root:eval perplexity: 10.067785263061523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:10:25<9:45:00, 319.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15644.149488231804
INFO:root:current train perplexity4.654229164123535
INFO:root:current mean train loss 15583.19714560056
INFO:root:current train perplexity4.6473517417907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.92s/it]
INFO:root:final mean train loss: 15581.286550214214
INFO:root:final train perplexity: 4.64976692199707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it]
INFO:root:eval mean loss: 22299.468680245536
INFO:root:eval perplexity: 10.0532808303833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/91
####################best#################
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:15:45<9:40:12, 319.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15565.314736643146
INFO:root:current train perplexity4.642399787902832
INFO:root:current mean train loss 15552.845233480439
INFO:root:current train perplexity4.640279769897461
INFO:root:current mean train loss 15570.761139576569
INFO:root:current train perplexity4.6416425704956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.55s/it]
INFO:root:final mean train loss: 15560.324651902722
INFO:root:final train perplexity: 4.640163421630859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it]
INFO:root:eval mean loss: 22332.255394345237
INFO:root:eval perplexity: 10.087450981140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:21:20<9:43:04, 323.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15574.827230798193
INFO:root:current train perplexity4.639801979064941
INFO:root:current mean train loss 15555.120213242828
INFO:root:current train perplexity4.63232946395874


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.33s/it]
INFO:root:final mean train loss: 15545.86437594506
INFO:root:final train perplexity: 4.633549690246582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it]
INFO:root:eval mean loss: 22316.343191964286
INFO:root:eval perplexity: 10.070853233337402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:26:37<9:33:47, 321.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15518.784263392858
INFO:root:current train perplexity4.596301078796387
INFO:root:current mean train loss 15510.434447337962
INFO:root:current train perplexity4.617855548858643
INFO:root:current mean train loss 15537.385106382979
INFO:root:current train perplexity4.624128341674805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.15s/it]
INFO:root:final mean train loss: 15527.584563224545
INFO:root:final train perplexity: 4.625203609466553
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it]
INFO:root:eval mean loss: 22328.657761346727
INFO:root:eval perplexity: 10.083697319030762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [8:31:54<9:26:02, 320.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15541.676724137931
INFO:root:current train perplexity4.6113152503967285
INFO:root:current mean train loss 15528.75707616143
INFO:root:current train perplexity4.61848258972168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.54s/it]
INFO:root:final mean train loss: 15509.522224672379
INFO:root:final train perplexity: 4.616970539093018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.38s/it]
INFO:root:eval mean loss: 22324.517717633928
INFO:root:eval perplexity: 10.079375267028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [8:37:09<9:17:56, 318.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15442.52368790064
INFO:root:current train perplexity4.566666126251221
INFO:root:current mean train loss 15498.289111679407
INFO:root:current train perplexity4.594954967498779
INFO:root:current mean train loss 15513.284710872123
INFO:root:current train perplexity4.608633041381836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.29s/it]
INFO:root:final mean train loss: 15490.889455487652
INFO:root:final train perplexity: 4.608493804931641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.97s/it]
INFO:root:eval mean loss: 22326.040108816964
INFO:root:eval perplexity: 10.08096694946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [8:42:35<9:16:06, 320.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15514.322909512362
INFO:root:current train perplexity4.605151176452637
INFO:root:current mean train loss 15477.576299697317
INFO:root:current train perplexity4.602129936218262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.12s/it]
INFO:root:final mean train loss: 15476.47224672379
INFO:root:final train perplexity: 4.601945400238037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it]
INFO:root:eval mean loss: 22336.85472470238
INFO:root:eval perplexity: 10.092252731323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [8:47:51<9:08:30, 319.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15457.10199400436
INFO:root:current train perplexity4.601128101348877
INFO:root:current mean train loss 15472.856411166958
INFO:root:current train perplexity4.598146915435791
INFO:root:current mean train loss 15464.2406483089
INFO:root:current train perplexity4.592650413513184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.71s/it]
INFO:root:final mean train loss: 15454.599495180191
INFO:root:final train perplexity: 4.592027187347412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it]
INFO:root:eval mean loss: 22325.525809151786
INFO:root:eval perplexity: 10.080428123474121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [8:53:08<9:01:51, 318.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15491.276356907894
INFO:root:current train perplexity4.587745189666748
INFO:root:current mean train loss 15461.95
INFO:root:current train perplexity4.588582515716553


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.40s/it]
INFO:root:final mean train loss: 15445.999208511845
INFO:root:final train perplexity: 4.588134288787842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it]
INFO:root:eval mean loss: 22314.60958426339
INFO:root:eval perplexity: 10.069045066833496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [8:58:29<8:57:30, 319.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15360.164145611701
INFO:root:current train perplexity4.535009384155273
INFO:root:current mean train loss 15424.483152636054
INFO:root:current train perplexity4.5697245597839355
INFO:root:current mean train loss 15440.232888410932
INFO:root:current train perplexity4.580020427703857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.41s/it]
INFO:root:final mean train loss: 15429.51216765373
INFO:root:final train perplexity: 4.580678939819336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it]
INFO:root:eval mean loss: 22328.75655691964
INFO:root:eval perplexity: 10.083800315856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:03:48<8:52:00, 319.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15367.503363715277
INFO:root:current train perplexity4.557145118713379
INFO:root:current mean train loss 15431.670319370289
INFO:root:current train perplexity4.572684288024902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it]
INFO:root:final mean train loss: 15413.94017373362
INFO:root:final train perplexity: 4.573648929595947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it]
INFO:root:eval mean loss: 22316.26734561012
INFO:root:eval perplexity: 10.070771217346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:09:22<8:54:04, 323.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15456.083888633579
INFO:root:current train perplexity4.564498424530029
INFO:root:current mean train loss 15427.68842482409
INFO:root:current train perplexity4.569909572601318


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.10s/it]
INFO:root:final mean train loss: 15401.309298607612
INFO:root:final train perplexity: 4.5679545402526855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.05s/it]
INFO:root:eval mean loss: 22317.40848214286
INFO:root:eval perplexity: 10.071962356567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:14:47<8:49:39, 324.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15439.162109375
INFO:root:current train perplexity4.492895126342773
INFO:root:current mean train loss 15420.130593901698
INFO:root:current train perplexity4.554999828338623
INFO:root:current mean train loss 15386.681914832205
INFO:root:current train perplexity4.556413173675537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.69s/it]
INFO:root:final mean train loss: 15388.631509104083
INFO:root:final train perplexity: 4.562245845794678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.75s/it]
INFO:root:eval mean loss: 22319.56103515625
INFO:root:eval perplexity: 10.07420825958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:20:02<8:39:32, 321.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15342.040234375
INFO:root:current train perplexity4.526132583618164
INFO:root:current mean train loss 15364.247838961694
INFO:root:current train perplexity4.550538063049316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.70s/it]
INFO:root:final mean train loss: 15371.817875031502
INFO:root:final train perplexity: 4.554687023162842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it]
INFO:root:eval mean loss: 22321.668922061013
INFO:root:eval perplexity: 10.076403617858887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:25:26<8:35:18, 322.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15178.155831473214
INFO:root:current train perplexity4.492481708526611
INFO:root:current mean train loss 15291.000365070093
INFO:root:current train perplexity4.535794734954834
INFO:root:current mean train loss 15373.877297516607
INFO:root:current train perplexity4.553103446960449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it]
INFO:root:final mean train loss: 15362.654592206402
INFO:root:final train perplexity: 4.550571918487549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it]
INFO:root:eval mean loss: 22329.90636625744
INFO:root:eval perplexity: 10.08499813079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [9:31:20<8:45:20, 331.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15349.34509070445
INFO:root:current train perplexity4.54212760925293
INFO:root:current mean train loss 15382.565736782626
INFO:root:current train perplexity4.545535087585449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.40s/it]
INFO:root:final mean train loss: 15341.200415826614
INFO:root:final train perplexity: 4.540952682495117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.85s/it]
INFO:root:eval mean loss: 22331.334542410714
INFO:root:eval perplexity: 10.086488723754883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [9:36:42<8:35:08, 328.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15073.79287997159
INFO:root:current train perplexity4.498679161071777
INFO:root:current mean train loss 15301.32882882883
INFO:root:current train perplexity4.522121906280518
INFO:root:current mean train loss 15341.282333012441
INFO:root:current train perplexity4.534954071044922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.03s/it]
INFO:root:final mean train loss: 15331.657041488155
INFO:root:final train perplexity: 4.536680698394775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.28s/it]
INFO:root:eval mean loss: 22342.72986421131
INFO:root:eval perplexity: 10.098392486572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [9:42:07<8:27:46, 327.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15287.858630952382
INFO:root:current train perplexity4.522563934326172
INFO:root:current mean train loss 15325.78271184816
INFO:root:current train perplexity4.530025005340576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it]
INFO:root:final mean train loss: 15319.209173387097
INFO:root:final train perplexity: 4.531113147735596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it]
INFO:root:eval mean loss: 22342.383440290178
INFO:root:eval perplexity: 10.098031044006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [9:48:12<8:39:24, 338.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15071.185286458332
INFO:root:current train perplexity4.51062536239624
INFO:root:current mean train loss 15285.888119904892
INFO:root:current train perplexity4.5158233642578125
INFO:root:current mean train loss 15309.01265897529
INFO:root:current train perplexity4.520810604095459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.82s/it]
INFO:root:final mean train loss: 15303.766518869708
INFO:root:final train perplexity: 4.5242180824279785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it]
INFO:root:eval mean loss: 22344.861886160714
INFO:root:eval perplexity: 10.10062026977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [9:53:41<8:29:36, 336.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15218.83931902985
INFO:root:current train perplexity4.499481678009033
INFO:root:current mean train loss 15282.93065236714
INFO:root:current train perplexity4.517043113708496


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.18s/it]
INFO:root:final mean train loss: 15292.20199486517
INFO:root:final train perplexity: 4.519060134887695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it]
INFO:root:eval mean loss: 22341.677315848214
INFO:root:eval perplexity: 10.097291946411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [9:59:41<8:34:51, 343.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15291.084703947368
INFO:root:current train perplexity4.502594947814941
INFO:root:current mean train loss 15330.900702468487
INFO:root:current train perplexity4.515678882598877
INFO:root:current mean train loss 15288.60120576484
INFO:root:current train perplexity4.512535572052002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.62s/it]
INFO:root:final mean train loss: 15280.327341387348
INFO:root:final train perplexity: 4.513770580291748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it]
INFO:root:eval mean loss: 22351.252511160714
INFO:root:eval perplexity: 10.10730266571045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:05:45<8:38:11, 349.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15296.480386223591
INFO:root:current train perplexity4.5120320320129395
INFO:root:current mean train loss 15284.79391675804
INFO:root:current train perplexity4.511688232421875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.11s/it]
INFO:root:final mean train loss: 15266.791751984627
INFO:root:final train perplexity: 4.507749080657959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it]
INFO:root:eval mean loss: 22350.13048735119
INFO:root:eval perplexity: 10.106131553649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:11:50<8:39:29, 354.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15179.907141644022
INFO:root:current train perplexity4.4785027503967285
INFO:root:current mean train loss 15233.081983612805
INFO:root:current train perplexity4.497694492340088
INFO:root:current mean train loss 15257.849057595291
INFO:root:current train perplexity4.502674102783203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.38s/it]
INFO:root:final mean train loss: 15252.169248519405
INFO:root:final train perplexity: 4.501251697540283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.71s/it]
INFO:root:eval mean loss: 22349.837797619046
INFO:root:eval perplexity: 10.105822563171387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:17:30<8:27:04, 349.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15239.074752604167
INFO:root:current train perplexity4.497099876403809
INFO:root:current mean train loss 15256.213353794643
INFO:root:current train perplexity4.500272750854492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.65s/it]
INFO:root:final mean train loss: 15243.503583354335
INFO:root:final train perplexity: 4.497405529022217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.57s/it]
INFO:root:eval mean loss: 22346.102353050595
INFO:root:eval perplexity: 10.10191535949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:22:50<8:08:43, 340.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15201.118200231482
INFO:root:current train perplexity4.50965690612793
INFO:root:current mean train loss 15223.17428949311
INFO:root:current train perplexity4.492549419403076
INFO:root:current mean train loss 15235.159880919604
INFO:root:current train perplexity4.488127708435059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.56s/it]
INFO:root:final mean train loss: 15229.17183562248
INFO:root:final train perplexity: 4.491052627563477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it]
INFO:root:eval mean loss: 22331.287434895832
INFO:root:eval perplexity: 10.086438179016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [10:28:11<7:54:22, 334.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15195.693705498417
INFO:root:current train perplexity4.477757453918457
INFO:root:current mean train loss 15230.368993322276
INFO:root:current train perplexity4.481080532073975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.73s/it]
INFO:root:final mean train loss: 15216.661510836693
INFO:root:final train perplexity: 4.485515117645264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it]
INFO:root:eval mean loss: 22344.766950334822
INFO:root:eval perplexity: 10.100523948669434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [10:33:30<7:42:21, 330.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15265.658581149193
INFO:root:current train perplexity4.4906005859375
INFO:root:current mean train loss 15241.320208134543
INFO:root:current train perplexity4.483757495880127
INFO:root:current mean train loss 15221.17939157197
INFO:root:current train perplexity4.481914043426514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.31s/it]
INFO:root:final mean train loss: 15203.667311145413
INFO:root:final train perplexity: 4.479769229888916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.23s/it]
INFO:root:eval mean loss: 22354.813151041668
INFO:root:eval perplexity: 10.1110258102417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [10:39:13<7:42:03, 334.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15207.007683076054
INFO:root:current train perplexity4.470167636871338
INFO:root:current mean train loss 15220.082522199453
INFO:root:current train perplexity4.475768566131592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.88s/it]
INFO:root:final mean train loss: 15191.64353499874
INFO:root:final train perplexity: 4.474460601806641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.95s/it]
INFO:root:eval mean loss: 22353.064615885418
INFO:root:eval perplexity: 10.109198570251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [10:44:35<7:31:33, 330.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15153.669280133929
INFO:root:current train perplexity4.451351642608643
INFO:root:current mean train loss 15196.701273148148
INFO:root:current train perplexity4.461803436279297
INFO:root:current mean train loss 15193.63926612367
INFO:root:current train perplexity4.470829010009766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.26s/it]
INFO:root:final mean train loss: 15181.980752268146
INFO:root:final train perplexity: 4.470198154449463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it]
INFO:root:eval mean loss: 22358.057059151786
INFO:root:eval perplexity: 10.114423751831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [10:50:04<7:25:29, 330.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15122.011842223419
INFO:root:current train perplexity4.459457874298096
INFO:root:current mean train loss 15173.584840825535
INFO:root:current train perplexity4.463185787200928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.97s/it]
INFO:root:final mean train loss: 15169.32373046875
INFO:root:final train perplexity: 4.464620590209961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it]
INFO:root:eval mean loss: 22363.82254464286
INFO:root:eval perplexity: 10.120463371276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [10:55:25<7:16:10, 327.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15115.63098457532
INFO:root:current train perplexity4.439587593078613
INFO:root:current mean train loss 15135.73884330036
INFO:root:current train perplexity4.45416784286499
INFO:root:current mean train loss 15164.641086722018
INFO:root:current train perplexity4.458035945892334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it]
INFO:root:final mean train loss: 15156.206239761845
INFO:root:final train perplexity: 4.458847999572754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it]
INFO:root:eval mean loss: 22360.46609933036
INFO:root:eval perplexity: 10.116948127746582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:00:58<7:13:13, 329.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15121.202491844093
INFO:root:current train perplexity4.444890975952148
INFO:root:current mean train loss 15140.435352585078
INFO:root:current train perplexity4.444703102111816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.67s/it]
INFO:root:final mean train loss: 15146.498598160282
INFO:root:final train perplexity: 4.454580783843994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it]
INFO:root:eval mean loss: 22351.455589657737
INFO:root:eval perplexity: 10.10751724243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:06:22<7:05:46, 327.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15129.039085210756
INFO:root:current train perplexity4.46776008605957
INFO:root:current mean train loss 15168.680001638986
INFO:root:current train perplexity4.457720756530762
INFO:root:current mean train loss 15154.80987975823
INFO:root:current train perplexity4.453165531158447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it]
INFO:root:final mean train loss: 15142.439173544606
INFO:root:final train perplexity: 4.452797889709473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.85s/it]
INFO:root:eval mean loss: 22368.833054315477
INFO:root:eval perplexity: 10.125710487365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:11:52<7:01:08, 328.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15107.425113075658
INFO:root:current train perplexity4.442553997039795
INFO:root:current mean train loss 15147.672260616988
INFO:root:current train perplexity4.445369243621826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.06s/it]
INFO:root:final mean train loss: 15129.951388451362
INFO:root:final train perplexity: 4.447316646575928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.17s/it]
INFO:root:eval mean loss: 22370.06396484375
INFO:root:eval perplexity: 10.126999855041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:17:16<6:54:20, 327.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15111.588098404256
INFO:root:current train perplexity4.428740501403809
INFO:root:current mean train loss 15133.18316193665
INFO:root:current train perplexity4.43932580947876
INFO:root:current mean train loss 15134.303513252784
INFO:root:current train perplexity4.4435224533081055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.70s/it]
INFO:root:final mean train loss: 15120.685582314769
INFO:root:final train perplexity: 4.443254470825195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.85s/it]
INFO:root:eval mean loss: 22363.877790178572
INFO:root:eval perplexity: 10.120518684387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:22:50<6:51:24, 329.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15103.384371054293
INFO:root:current train perplexity4.435182094573975
INFO:root:current mean train loss 15119.028663826948
INFO:root:current train perplexity4.4360480308532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.71s/it]
INFO:root:final mean train loss: 15110.813385994205
INFO:root:final train perplexity: 4.438929080963135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 22363.83077566964
INFO:root:eval perplexity: 10.120471000671387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [11:28:11<6:42:54, 326.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15099.232938878677
INFO:root:current train perplexity4.426868438720703
INFO:root:current mean train loss 15087.360946554221
INFO:root:current train perplexity4.427858829498291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.88s/it]
INFO:root:final mean train loss: 15101.014924080142
INFO:root:final train perplexity: 4.4346418380737305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22367.83814639137
INFO:root:eval perplexity: 10.124667167663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [11:33:30<6:34:46, 324.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.045247395834
INFO:root:current train perplexity4.442277431488037
INFO:root:current mean train loss 15086.423875530947
INFO:root:current train perplexity4.430659294128418
INFO:root:current mean train loss 15082.571616186884
INFO:root:current train perplexity4.423131942749023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.90s/it]
INFO:root:final mean train loss: 15086.737627583165
INFO:root:final train perplexity: 4.428400993347168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it]
INFO:root:eval mean loss: 22368.505464099704
INFO:root:eval perplexity: 10.125365257263184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [11:38:47<6:26:37, 322.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15103.558966619317
INFO:root:current train perplexity4.428493022918701
INFO:root:current mean train loss 15087.449609375
INFO:root:current train perplexity4.427422046661377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.62s/it]
INFO:root:final mean train loss: 15079.534652217742
INFO:root:final train perplexity: 4.425256252288818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.26s/it]
INFO:root:eval mean loss: 22368.086263020832
INFO:root:eval perplexity: 10.12492847442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [11:44:07<6:20:15, 321.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15133.46568080357
INFO:root:current train perplexity4.392147064208984
INFO:root:current mean train loss 15094.252491603387
INFO:root:current train perplexity4.429861068725586
INFO:root:current mean train loss 15077.222354317633
INFO:root:current train perplexity4.420339584350586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.14s/it]
INFO:root:final mean train loss: 15065.706830424648
INFO:root:final train perplexity: 4.419224262237549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.88s/it]
INFO:root:eval mean loss: 22403.533737909227
INFO:root:eval perplexity: 10.162139892578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [11:49:26<6:14:09, 320.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15097.190396583686
INFO:root:current train perplexity4.425455570220947
INFO:root:current mean train loss 15050.799497592374
INFO:root:current train perplexity4.416148662567139


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.94s/it]
INFO:root:final mean train loss: 15057.605460874496
INFO:root:final train perplexity: 4.4156951904296875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.28s/it]
INFO:root:eval mean loss: 22383.528901599704
INFO:root:eval perplexity: 10.141121864318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [11:54:44<6:08:02, 320.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14937.72567471591
INFO:root:current train perplexity4.419939041137695
INFO:root:current mean train loss 15046.66823268581
INFO:root:current train perplexity4.404591083526611
INFO:root:current mean train loss 15048.226923504148
INFO:root:current train perplexity4.408895969390869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.28s/it]
INFO:root:final mean train loss: 15044.692434003277
INFO:root:final train perplexity: 4.410074710845947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.43s/it]
INFO:root:eval mean loss: 22377.98937406994
INFO:root:eval perplexity: 10.135309219360352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:00:05<6:02:46, 320.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14937.492668030754
INFO:root:current train perplexity4.393894195556641
INFO:root:current mean train loss 14998.06487849885
INFO:root:current train perplexity4.394984722137451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it]
INFO:root:final mean train loss: 15035.172485351562
INFO:root:final train perplexity: 4.405934810638428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it]
INFO:root:eval mean loss: 22378.4482421875
INFO:root:eval perplexity: 10.135794639587402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:05:21<5:56:19, 319.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15001.1109375
INFO:root:current train perplexity4.414764881134033
INFO:root:current mean train loss 15043.062882133152
INFO:root:current train perplexity4.409301280975342
INFO:root:current mean train loss 15038.866896802325
INFO:root:current train perplexity4.401978969573975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.79s/it]
INFO:root:final mean train loss: 15031.244183940273
INFO:root:final train perplexity: 4.404229164123535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it]
INFO:root:eval mean loss: 22387.420758928572
INFO:root:eval perplexity: 10.145206451416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:10:41<5:51:14, 319.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14985.910112523321
INFO:root:current train perplexity4.385649681091309
INFO:root:current mean train loss 15061.354281671032
INFO:root:current train perplexity4.408524990081787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.33s/it]
INFO:root:final mean train loss: 15026.02174032888
INFO:root:final train perplexity: 4.401960849761963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it]
INFO:root:eval mean loss: 22378.301897321428
INFO:root:eval perplexity: 10.135640144348145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:16:00<5:45:37, 319.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15056.759919819078
INFO:root:current train perplexity4.395612716674805
INFO:root:current mean train loss 15048.815380449054
INFO:root:current train perplexity4.406990051269531
INFO:root:current mean train loss 15049.750303224886
INFO:root:current train perplexity4.400880813598633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.73s/it]
INFO:root:final mean train loss: 15016.256670551915
INFO:root:final train perplexity: 4.3977227210998535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it]
INFO:root:eval mean loss: 22389.97205171131
INFO:root:eval perplexity: 10.147887229919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [12:21:20<5:40:37, 319.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14985.893884793133
INFO:root:current train perplexity4.380910873413086
INFO:root:current mean train loss 15026.82412737573
INFO:root:current train perplexity4.391012191772461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.69s/it]
INFO:root:final mean train loss: 14998.905907415574
INFO:root:final train perplexity: 4.390203475952148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it]
INFO:root:eval mean loss: 22380.370744977678
INFO:root:eval perplexity: 10.137809753417969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [12:26:39<5:35:15, 319.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14883.565174932066
INFO:root:current train perplexity4.352701187133789
INFO:root:current mean train loss 14986.091344321647
INFO:root:current train perplexity4.386638164520264
INFO:root:current mean train loss 14997.319708169844
INFO:root:current train perplexity4.387416362762451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.12s/it]
INFO:root:final mean train loss: 14992.89918173513
INFO:root:final train perplexity: 4.387603282928467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.52s/it]
INFO:root:eval mean loss: 22393.03194754464
INFO:root:eval perplexity: 10.151103019714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [12:31:58<5:29:50, 319.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14935.148450520834
INFO:root:current train perplexity4.3661041259765625
INFO:root:current mean train loss 14987.6619140625
INFO:root:current train perplexity4.376381874084473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.51s/it]
INFO:root:final mean train loss: 14986.403477822581
INFO:root:final train perplexity: 4.384792804718018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.10s/it]
INFO:root:eval mean loss: 22382.648763020832
INFO:root:eval perplexity: 10.140198707580566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [12:37:15<5:23:50, 318.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14996.688114872684
INFO:root:current train perplexity4.386569499969482
INFO:root:current mean train loss 14947.39324710876
INFO:root:current train perplexity4.370804309844971
INFO:root:current mean train loss 14989.1992875826
INFO:root:current train perplexity4.3796281814575195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.63s/it]
INFO:root:final mean train loss: 14978.959244266633
INFO:root:final train perplexity: 4.381574630737305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.37s/it]
INFO:root:eval mean loss: 22379.81954520089
INFO:root:eval perplexity: 10.137229919433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [12:42:39<5:20:18, 320.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.29200454905
INFO:root:current train perplexity4.375572204589844
INFO:root:current mean train loss 14958.88792445007
INFO:root:current train perplexity4.3734517097473145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.61s/it]
INFO:root:final mean train loss: 14968.45379048009
INFO:root:final train perplexity: 4.377037048339844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.17s/it]
INFO:root:eval mean loss: 22383.734328497023
INFO:root:eval perplexity: 10.141339302062988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [12:47:59<5:14:55, 320.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14948.62833921371
INFO:root:current train perplexity4.377934455871582
INFO:root:current mean train loss 14972.782323473282
INFO:root:current train perplexity4.377992153167725
INFO:root:current mean train loss 14969.900923295454
INFO:root:current train perplexity4.375053882598877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.76s/it]
INFO:root:final mean train loss: 14959.108055853074
INFO:root:final train perplexity: 4.37300443649292
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it]
INFO:root:eval mean loss: 22408.47972470238
INFO:root:eval perplexity: 10.167343139648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [12:53:37<5:14:39, 325.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15030.961055158132
INFO:root:current train perplexity4.368803024291992
INFO:root:current mean train loss 14976.385256574453
INFO:root:current train perplexity4.366908550262451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.43s/it]
INFO:root:final mean train loss: 14956.55619172127
INFO:root:final train perplexity: 4.371903896331787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.35s/it]
INFO:root:eval mean loss: 22391.47437686012
INFO:root:eval perplexity: 10.14946460723877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [12:58:59<5:08:13, 324.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14886.1421875
INFO:root:current train perplexity4.33358907699585
INFO:root:current mean train loss 14933.087109375
INFO:root:current train perplexity4.354341983795166
INFO:root:current mean train loss 14949.991156914894
INFO:root:current train perplexity4.368155479431152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it]
INFO:root:final mean train loss: 14948.499539283013
INFO:root:final train perplexity: 4.368431091308594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it]
INFO:root:eval mean loss: 22397.697777157737
INFO:root:eval perplexity: 10.156004905700684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:04:28<5:04:11, 325.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14914.388234105603
INFO:root:current train perplexity4.351222515106201
INFO:root:current mean train loss 14958.794195980949
INFO:root:current train perplexity4.365970611572266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.74s/it]
INFO:root:final mean train loss: 14938.78572328629
INFO:root:final train perplexity: 4.364247798919678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.90s/it]
INFO:root:eval mean loss: 22404.881742931546
INFO:root:eval perplexity: 10.163559913635254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:09:49<4:57:09, 324.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14932.673377403846
INFO:root:current train perplexity4.3493804931640625
INFO:root:current mean train loss 14935.156945537321
INFO:root:current train perplexity4.359908580780029
INFO:root:current mean train loss 14942.143383074006
INFO:root:current train perplexity4.360999584197998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.10s/it]
INFO:root:final mean train loss: 14931.634978263608
INFO:root:final train perplexity: 4.361171245574951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it]
INFO:root:eval mean loss: 22396.69910249256
INFO:root:eval perplexity: 10.154953956604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [13:15:03<4:49:10, 321.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14970.34841818338
INFO:root:current train perplexity4.3508076667785645
INFO:root:current mean train loss 14927.831172284032
INFO:root:current train perplexity4.348515033721924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.10s/it]
INFO:root:final mean train loss: 14923.85994203629
INFO:root:final train perplexity: 4.357827663421631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it]
INFO:root:eval mean loss: 22406.286318824405
INFO:root:eval perplexity: 10.16503620147705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [13:20:32<4:45:46, 323.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14902.635378815407
INFO:root:current train perplexity4.3487420082092285
INFO:root:current mean train loss 14907.391246448864
INFO:root:current train perplexity4.345231533050537
INFO:root:current mean train loss 14930.980967078189
INFO:root:current train perplexity4.354242324829102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.19s/it]
INFO:root:final mean train loss: 14915.973841513356
INFO:root:final train perplexity: 4.3544392585754395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.23s/it]
INFO:root:eval mean loss: 22402.600051153273
INFO:root:eval perplexity: 10.16115665435791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [13:25:57<4:40:43, 323.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14925.095600328947
INFO:root:current train perplexity4.350004196166992
INFO:root:current mean train loss 14911.940109174679
INFO:root:current train perplexity4.349459648132324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.72s/it]
INFO:root:final mean train loss: 14911.319753339214
INFO:root:final train perplexity: 4.352440357208252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.70s/it]
INFO:root:eval mean loss: 22400.563616071428
INFO:root:eval perplexity: 10.15902042388916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [13:31:11<4:32:46, 320.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14893.20921293218
INFO:root:current train perplexity4.338691711425781
INFO:root:current mean train loss 14884.718623777637
INFO:root:current train perplexity4.3397746086120605
INFO:root:current mean train loss 14916.174808641194
INFO:root:current train perplexity4.349955081939697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.16s/it]
INFO:root:final mean train loss: 14905.397791708669
INFO:root:final train perplexity: 4.349898815155029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.97s/it]
INFO:root:eval mean loss: 22409.371651785714
INFO:root:eval perplexity: 10.168281555175781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [13:36:41<4:29:48, 323.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14885.606070470329
INFO:root:current train perplexity4.337202072143555
INFO:root:current mean train loss 14880.309069762878
INFO:root:current train perplexity4.343458652496338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.68s/it]
INFO:root:final mean train loss: 14897.533577211441
INFO:root:final train perplexity: 4.346526145935059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it]
INFO:root:eval mean loss: 22411.25597563244
INFO:root:eval perplexity: 10.170267105102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [13:41:56<4:22:12, 321.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14892.037109375
INFO:root:current train perplexity4.347535133361816
INFO:root:current mean train loss 14883.565274472268
INFO:root:current train perplexity4.340993881225586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.07s/it]
INFO:root:final mean train loss: 14899.34427765877
INFO:root:final train perplexity: 4.347302436828613
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.86s/it]
INFO:root:eval mean loss: 22408.70617094494
INFO:root:eval perplexity: 10.167583465576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [13:47:16<4:16:37, 320.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14913.427408854166
INFO:root:current train perplexity4.332624435424805
INFO:root:current mean train loss 14880.320815003033
INFO:root:current train perplexity4.33582878112793
INFO:root:current mean train loss 14897.884756003694
INFO:root:current train perplexity4.341637134552002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.31s/it]
INFO:root:final mean train loss: 14885.85480326991
INFO:root:final train perplexity: 4.341522216796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 22415.10546875
INFO:root:eval perplexity: 10.174320220947266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [13:52:38<4:11:28, 321.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14844.858806818182
INFO:root:current train perplexity4.318991661071777
INFO:root:current mean train loss 14864.167981350807
INFO:root:current train perplexity4.329545497894287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.40s/it]
INFO:root:final mean train loss: 14879.660668157761
INFO:root:final train perplexity: 4.338871002197266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it]
INFO:root:eval mean loss: 22410.083565848214
INFO:root:eval perplexity: 10.16903305053711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [13:57:59<4:06:07, 321.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14978.572963169643
INFO:root:current train perplexity4.388143539428711
INFO:root:current mean train loss 14845.828125
INFO:root:current train perplexity4.332254886627197
INFO:root:current mean train loss 14889.469467089371
INFO:root:current train perplexity4.337557792663574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it]
INFO:root:final mean train loss: 14872.219450919858
INFO:root:final train perplexity: 4.335687637329102
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.04s/it]
INFO:root:eval mean loss: 22416.43629092262
INFO:root:eval perplexity: 10.175719261169434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:03:25<4:01:54, 322.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14899.652145127118
INFO:root:current train perplexity4.3329315185546875
INFO:root:current mean train loss 14860.939465408805
INFO:root:current train perplexity4.3302531242370605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.35s/it]
INFO:root:final mean train loss: 14865.265873078377
INFO:root:final train perplexity: 4.332715034484863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.32s/it]
INFO:root:eval mean loss: 22415.567452566964
INFO:root:eval perplexity: 10.17480754852295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [14:08:41<3:55:04, 320.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14840.689897017046
INFO:root:current train perplexity4.284186840057373
INFO:root:current mean train loss 14872.893572283221
INFO:root:current train perplexity4.326284408569336
INFO:root:current mean train loss 14871.347920060723
INFO:root:current train perplexity4.328423023223877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 271.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 271.00s/it]
INFO:root:final mean train loss: 14861.7498031124
INFO:root:final train perplexity: 4.331212997436523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it]
INFO:root:eval mean loss: 22414.78869047619
INFO:root:eval perplexity: 10.17398738861084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [14:13:58<3:49:01, 319.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14790.150328621032
INFO:root:current train perplexity4.317234992980957
INFO:root:current mean train loss 14867.151720667178
INFO:root:current train perplexity4.3307037353515625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.83s/it]
INFO:root:final mean train loss: 14855.677667433216
INFO:root:final train perplexity: 4.328619003295898
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.62s/it]
INFO:root:eval mean loss: 22415.32933407738
INFO:root:eval perplexity: 10.174552917480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [14:19:12<3:42:28, 317.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14939.671028645833
INFO:root:current train perplexity4.332353591918945
INFO:root:current mean train loss 14871.252258831522
INFO:root:current train perplexity4.3347039222717285
INFO:root:current mean train loss 14865.0439453125
INFO:root:current train perplexity4.3280768394470215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.76s/it]
INFO:root:final mean train loss: 14850.69838000882
INFO:root:final train perplexity: 4.326493740081787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it]
INFO:root:eval mean loss: 22412.56029110863
INFO:root:eval perplexity: 10.171639442443848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [14:24:28<3:36:54, 317.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.754052005597
INFO:root:current train perplexity4.312649250030518
INFO:root:current mean train loss 14838.552202236153
INFO:root:current train perplexity4.318319320678711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.85s/it]
INFO:root:final mean train loss: 14846.463859311996
INFO:root:final train perplexity: 4.324687480926514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.72s/it]
INFO:root:eval mean loss: 22415.89474051339
INFO:root:eval perplexity: 10.175151824951172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [14:29:46<3:31:42, 317.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14821.271330180922
INFO:root:current train perplexity4.301517963409424
INFO:root:current mean train loss 14854.99919577206
INFO:root:current train perplexity4.320677757263184
INFO:root:current mean train loss 14839.510189248002
INFO:root:current train perplexity4.321612358093262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.55s/it]
INFO:root:final mean train loss: 14839.397791708669
INFO:root:final train perplexity: 4.321674346923828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it]
INFO:root:eval mean loss: 22423.95140438988
INFO:root:eval perplexity: 10.183639526367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [14:35:04<3:26:26, 317.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14845.195752640846
INFO:root:current train perplexity4.308546543121338
INFO:root:current mean train loss 14838.476305509868
INFO:root:current train perplexity4.3121562004089355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.70s/it]
INFO:root:final mean train loss: 14834.171800182712
INFO:root:final train perplexity: 4.3194475173950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.30s/it]
INFO:root:eval mean loss: 22421.544828869046
INFO:root:eval perplexity: 10.181099891662598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [14:40:50<3:26:33, 326.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14804.842391304348
INFO:root:current train perplexity4.319540500640869
INFO:root:current mean train loss 14874.675360454776
INFO:root:current train perplexity4.321186542510986
INFO:root:current mean train loss 14836.908238158632
INFO:root:current train perplexity4.3134965896606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.33s/it]
INFO:root:final mean train loss: 14826.076569587955
INFO:root:final train perplexity: 4.315999984741211
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22417.015694754464
INFO:root:eval perplexity: 10.176331520080566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [14:46:15<3:21:03, 326.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14813.238359375
INFO:root:current train perplexity4.325295448303223
INFO:root:current mean train loss 14820.038493303571
INFO:root:current train perplexity4.314922332763672


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.85s/it]
INFO:root:final mean train loss: 14827.106126354587
INFO:root:final train perplexity: 4.316438674926758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.56s/it]
INFO:root:eval mean loss: 22422.455031622023
INFO:root:eval perplexity: 10.182061195373535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [14:51:53<3:17:42, 329.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14860.072410300925
INFO:root:current train perplexity4.305515289306641
INFO:root:current mean train loss 14855.285371555117
INFO:root:current train perplexity4.326097011566162
INFO:root:current mean train loss 14835.960558920704
INFO:root:current train perplexity4.315677165985107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.23s/it]
INFO:root:final mean train loss: 14816.666688980595
INFO:root:final train perplexity: 4.311995983123779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.24s/it]
INFO:root:eval mean loss: 22422.491722470237
INFO:root:eval perplexity: 10.182100296020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [14:57:20<3:11:45, 328.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14849.12284909019
INFO:root:current train perplexity4.31877326965332
INFO:root:current mean train loss 14839.630542946927
INFO:root:current train perplexity4.314262390136719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.28s/it]
INFO:root:final mean train loss: 14812.1404281124
INFO:root:final train perplexity: 4.31007194519043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it]
INFO:root:eval mean loss: 22425.682314918155
INFO:root:eval perplexity: 10.185462951660156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:02:44<3:05:26, 327.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.919165826614
INFO:root:current train perplexity4.306773662567139
INFO:root:current mean train loss 14831.740502743321
INFO:root:current train perplexity4.304812431335449
INFO:root:current mean train loss 14824.558056852002
INFO:root:current train perplexity4.310229301452637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.11s/it]
INFO:root:final mean train loss: 14809.92097719254
INFO:root:final train perplexity: 4.3091278076171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.59s/it]
INFO:root:eval mean loss: 22428.002348400296
INFO:root:eval perplexity: 10.187908172607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [15:08:00<2:58:07, 323.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14791.606963008284
INFO:root:current train perplexity4.297037124633789
INFO:root:current mean train loss 14821.85594902664
INFO:root:current train perplexity4.304275035858154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.41s/it]
INFO:root:final mean train loss: 14801.513471049648
INFO:root:final train perplexity: 4.305556297302246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.53s/it]
INFO:root:eval mean loss: 22426.776832217263
INFO:root:eval perplexity: 10.186615943908691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [15:13:13<2:51:00, 320.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14940.101060267858
INFO:root:current train perplexity4.336459159851074
INFO:root:current mean train loss 14797.780924479166
INFO:root:current train perplexity4.299332141876221
INFO:root:current mean train loss 14817.23280418883
INFO:root:current train perplexity4.306219577789307


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.56s/it]
INFO:root:final mean train loss: 14798.00609170237
INFO:root:final train perplexity: 4.304067134857178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it]
INFO:root:eval mean loss: 22423.845191592263
INFO:root:eval perplexity: 10.183525085449219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [15:18:28<2:44:45, 318.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14790.775278376437
INFO:root:current train perplexity4.302126884460449
INFO:root:current mean train loss 14791.20451934325
INFO:root:current train perplexity4.30027437210083


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it]
INFO:root:final mean train loss: 14793.421229208669
INFO:root:final train perplexity: 4.302121162414551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.11s/it]
INFO:root:eval mean loss: 22431.250790550595
INFO:root:eval perplexity: 10.191333770751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [15:23:44<2:39:06, 318.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14707.514673477564
INFO:root:current train perplexity4.266640663146973
INFO:root:current mean train loss 14765.654416310701
INFO:root:current train perplexity4.297420978546143
INFO:root:current mean train loss 14798.609832635982
INFO:root:current train perplexity4.302188396453857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.98s/it]
INFO:root:final mean train loss: 14790.359615202873
INFO:root:final train perplexity: 4.3008222579956055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.44s/it]
INFO:root:eval mean loss: 22431.082333519345
INFO:root:eval perplexity: 10.191156387329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [15:29:15<2:35:38, 322.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.407934838599
INFO:root:current train perplexity4.318281173706055
INFO:root:current mean train loss 14787.495879008507
INFO:root:current train perplexity4.300176620483398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it]
INFO:root:final mean train loss: 14789.92328077747
INFO:root:final train perplexity: 4.3006367683410645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it]
INFO:root:eval mean loss: 22429.392740885418
INFO:root:eval perplexity: 10.189373016357422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [15:34:33<2:29:42, 320.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14754.467296511628
INFO:root:current train perplexity4.292574405670166
INFO:root:current mean train loss 14805.256999836101
INFO:root:current train perplexity4.300941467285156
INFO:root:current mean train loss 14799.715647505143
INFO:root:current train perplexity4.298645496368408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.08s/it]
INFO:root:final mean train loss: 14785.705633348034
INFO:root:final train perplexity: 4.298848628997803
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it]
INFO:root:eval mean loss: 22433.080264136905
INFO:root:eval perplexity: 10.193263053894043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [15:40:02<2:25:24, 323.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14806.025657894737
INFO:root:current train perplexity4.294853210449219
INFO:root:current mean train loss 14800.299759615385
INFO:root:current train perplexity4.296615123748779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.18s/it]
INFO:root:final mean train loss: 14779.031553206905
INFO:root:final train perplexity: 4.296019554138184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it]
INFO:root:eval mean loss: 22434.41378348214
INFO:root:eval perplexity: 10.194670677185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [15:45:15<2:18:48, 320.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14693.450527759309
INFO:root:current train perplexity4.268033027648926
INFO:root:current mean train loss 14762.537899925595
INFO:root:current train perplexity4.283137321472168
INFO:root:current mean train loss 14784.962953884109
INFO:root:current train perplexity4.293846607208252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.06s/it]
INFO:root:final mean train loss: 14773.088745117188
INFO:root:final train perplexity: 4.293502330780029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it]
INFO:root:eval mean loss: 22432.877883184523
INFO:root:eval perplexity: 10.193052291870117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [15:50:49<2:15:03, 324.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14767.917958885731
INFO:root:current train perplexity4.28732967376709
INFO:root:current mean train loss 14777.953635364322
INFO:root:current train perplexity4.290889263153076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.62s/it]
INFO:root:final mean train loss: 14775.964879189769
INFO:root:final train perplexity: 4.29472017288208
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.17s/it]
INFO:root:eval mean loss: 22431.929013206845
INFO:root:eval perplexity: 10.19205093383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [15:56:16<2:10:06, 325.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14769.062748927696
INFO:root:current train perplexity4.272762298583984
INFO:root:current mean train loss 14766.63710678808
INFO:root:current train perplexity4.283624649047852


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.16s/it]
INFO:root:final mean train loss: 14770.566851215977
INFO:root:final train perplexity: 4.2924346923828125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it]
INFO:root:eval mean loss: 22436.130673363095
INFO:root:eval perplexity: 10.196483612060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:01:36<2:04:01, 323.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14777.361002604166
INFO:root:current train perplexity4.266727447509766
INFO:root:current mean train loss 14754.023883115899
INFO:root:current train perplexity4.2847161293029785
INFO:root:current mean train loss 14783.466262892549
INFO:root:current train perplexity4.2887654304504395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.95s/it]
INFO:root:final mean train loss: 14762.12954810358
INFO:root:final train perplexity: 4.2888641357421875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it]
INFO:root:eval mean loss: 22441.497163318454
INFO:root:eval perplexity: 10.202147483825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [16:06:58<1:58:26, 323.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14828.31436434659
INFO:root:current train perplexity4.283754825592041
INFO:root:current mean train loss 14801.7966796875
INFO:root:current train perplexity4.292097091674805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.43s/it]
INFO:root:final mean train loss: 14767.130729429184
INFO:root:final train perplexity: 4.290979862213135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it]
INFO:root:eval mean loss: 22436.56519717262
INFO:root:eval perplexity: 10.196941375732422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [16:12:14<1:52:22, 321.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14691.41127232143
INFO:root:current train perplexity4.272907733917236
INFO:root:current mean train loss 14744.205561842873
INFO:root:current train perplexity4.287543296813965
INFO:root:current mean train loss 14770.53009888285
INFO:root:current train perplexity4.287649631500244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.34s/it]
INFO:root:final mean train loss: 14762.23804892263
INFO:root:final train perplexity: 4.288909435272217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it]
INFO:root:eval mean loss: 22436.854445684523
INFO:root:eval perplexity: 10.197247505187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [16:17:29<1:46:20, 319.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14734.348566604873
INFO:root:current train perplexity4.2853007316589355
INFO:root:current mean train loss 14743.11484129324
INFO:root:current train perplexity4.278651237487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.49s/it]
INFO:root:final mean train loss: 14757.782545520413
INFO:root:final train perplexity: 4.28702449798584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.69s/it]
INFO:root:eval mean loss: 22441.23514229911
INFO:root:eval perplexity: 10.20186996459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [16:22:57<1:41:57, 321.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14847.425071022728
INFO:root:current train perplexity4.269251823425293
INFO:root:current mean train loss 14782.699280335022
INFO:root:current train perplexity4.288929462432861
INFO:root:current mean train loss 14770.408351229265
INFO:root:current train perplexity4.287212371826172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.28s/it]
INFO:root:final mean train loss: 14751.560680758568
INFO:root:final train perplexity: 4.28439474105835
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it]
INFO:root:eval mean loss: 22439.54747953869
INFO:root:eval perplexity: 10.200089454650879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [16:28:15<1:36:11, 320.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14701.793185763889
INFO:root:current train perplexity4.273748397827148
INFO:root:current mean train loss 14745.755098495016
INFO:root:current train perplexity4.277278423309326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it]
INFO:root:final mean train loss: 14752.614462575604
INFO:root:final train perplexity: 4.2848405838012695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.29s/it]
INFO:root:eval mean loss: 22439.053269159227
INFO:root:eval perplexity: 10.199566841125488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [16:33:29<1:30:18, 318.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14724.910807291666
INFO:root:current train perplexity4.296151161193848
INFO:root:current mean train loss 14762.568147078804
INFO:root:current train perplexity4.287558078765869
INFO:root:current mean train loss 14758.618986191861
INFO:root:current train perplexity4.282737731933594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.66s/it]
INFO:root:final mean train loss: 14747.243467269405
INFO:root:final train perplexity: 4.282570838928223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.13s/it]
INFO:root:eval mean loss: 22437.681315104168
INFO:root:eval perplexity: 10.19811725616455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [16:38:44<1:24:41, 317.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14769.248761077426
INFO:root:current train perplexity4.271541595458984
INFO:root:current mean train loss 14747.388052020959
INFO:root:current train perplexity4.275320053100586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.81s/it]
INFO:root:final mean train loss: 14743.419406029487
INFO:root:final train perplexity: 4.280956268310547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.40s/it]
INFO:root:eval mean loss: 22442.714006696428
INFO:root:eval perplexity: 10.203432083129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [16:43:58<1:19:04, 316.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14684.545230263158
INFO:root:current train perplexity4.259366035461426
INFO:root:current mean train loss 14737.08142397584
INFO:root:current train perplexity4.280370712280273
INFO:root:current mean train loss 14764.291595319635
INFO:root:current train perplexity4.283404350280762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.70s/it]
INFO:root:final mean train loss: 14743.109099357358
INFO:root:final train perplexity: 4.280824661254883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 22435.991234188987
INFO:root:eval perplexity: 10.196335792541504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [16:49:15<1:13:54, 316.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14763.20351012324
INFO:root:current train perplexity4.277407646179199
INFO:root:current mean train loss 14772.916946500365
INFO:root:current train perplexity4.2817583084106445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.52s/it]
INFO:root:final mean train loss: 14741.106331117691
INFO:root:final train perplexity: 4.279979705810547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.57s/it]
INFO:root:eval mean loss: 22440.449893043155
INFO:root:eval perplexity: 10.201043128967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [16:54:35<1:08:49, 317.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14788.514223845108
INFO:root:current train perplexity4.264813423156738
INFO:root:current mean train loss 14736.708595337906
INFO:root:current train perplexity4.2748942375183105
INFO:root:current mean train loss 14756.213039517937
INFO:root:current train perplexity4.281575679779053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it]
INFO:root:final mean train loss: 14742.261517924648
INFO:root:final train perplexity: 4.280466556549072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.62s/it]
INFO:root:eval mean loss: 22439.935128348214
INFO:root:eval perplexity: 10.200498580932617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [16:59:49<1:03:20, 316.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14763.411380208334
INFO:root:current train perplexity4.283489227294922
INFO:root:current mean train loss 14729.733074776786
INFO:root:current train perplexity4.274165630340576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.75s/it]
INFO:root:final mean train loss: 14737.375098443801
INFO:root:final train perplexity: 4.278404712677002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.99s/it]
INFO:root:eval mean loss: 22440.727515811013
INFO:root:eval perplexity: 10.201334953308105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [17:05:04<57:57, 316.16s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14682.874855324075
INFO:root:current train perplexity4.262057781219482
INFO:root:current mean train loss 14722.29055425689
INFO:root:current train perplexity4.276005744934082
INFO:root:current mean train loss 14738.001720814978
INFO:root:current train perplexity4.275611877441406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.46s/it]
INFO:root:final mean train loss: 14736.301950762348
INFO:root:final train perplexity: 4.277952194213867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.72s/it]
INFO:root:eval mean loss: 22444.42940848214
INFO:root:eval perplexity: 10.205244064331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [17:10:18<52:33, 315.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14799.122515328323
INFO:root:current train perplexity4.281904220581055
INFO:root:current mean train loss 14745.82218924581
INFO:root:current train perplexity4.276956081390381


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.86s/it]
INFO:root:final mean train loss: 14736.567430065525
INFO:root:final train perplexity: 4.278064250946045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it]
INFO:root:eval mean loss: 22440.726702008928
INFO:root:eval perplexity: 10.201334953308105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [17:15:48<47:59, 319.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14839.627110635081
INFO:root:current train perplexity4.279713153839111
INFO:root:current mean train loss 14784.627035126432
INFO:root:current train perplexity4.28089714050293
INFO:root:current mean train loss 14739.55527935606
INFO:root:current train perplexity4.275672435760498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it]
INFO:root:final mean train loss: 14734.586815618699
INFO:root:final train perplexity: 4.277228355407715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it]
INFO:root:eval mean loss: 22443.653273809523
INFO:root:eval perplexity: 10.204426765441895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [17:21:06<42:32, 319.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14722.871505553463
INFO:root:current train perplexity4.273467540740967
INFO:root:current mean train loss 14728.089053961749
INFO:root:current train perplexity4.273060321807861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.49s/it]
INFO:root:final mean train loss: 14729.591883505544
INFO:root:final train perplexity: 4.275121688842773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22444.426804315477
INFO:root:eval perplexity: 10.205242156982422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [17:26:20<37:04, 317.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14745.103152901786
INFO:root:current train perplexity4.2990803718566895
INFO:root:current mean train loss 14742.22896412037
INFO:root:current train perplexity4.274877071380615
INFO:root:current mean train loss 14742.231013131648
INFO:root:current train perplexity4.273036003112793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.16s/it]
INFO:root:final mean train loss: 14726.426147460938
INFO:root:final train perplexity: 4.273787021636963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it]
INFO:root:eval mean loss: 22440.187453497023
INFO:root:eval perplexity: 10.200765609741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [17:32:02<32:29, 324.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14700.211801813937
INFO:root:current train perplexity4.2692551612854
INFO:root:current mean train loss 14723.317168699867
INFO:root:current train perplexity4.2715864181518555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.91s/it]
INFO:root:final mean train loss: 14726.24103373866
INFO:root:final train perplexity: 4.273708820343018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.14s/it]
INFO:root:eval mean loss: 22441.75867280506
INFO:root:eval perplexity: 10.202422142028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [17:37:50<27:38, 331.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14803.300881410256
INFO:root:current train perplexity4.292001247406006
INFO:root:current mean train loss 14731.351885678956
INFO:root:current train perplexity4.272871017456055
INFO:root:current mean train loss 14737.202140265428
INFO:root:current train perplexity4.273589611053467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.02s/it]
INFO:root:final mean train loss: 14725.402532762097
INFO:root:final train perplexity: 4.273355484008789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.98s/it]
INFO:root:eval mean loss: 22445.564755394345
INFO:root:eval perplexity: 10.206443786621094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [17:43:37<22:26, 336.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14771.919492616758
INFO:root:current train perplexity4.281890869140625
INFO:root:current mean train loss 14750.883875981675
INFO:root:current train perplexity4.278602123260498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.45s/it]
INFO:root:final mean train loss: 14724.519692697833
INFO:root:final train perplexity: 4.272983551025391
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it]
INFO:root:eval mean loss: 22442.431315104168
INFO:root:eval perplexity: 10.203132629394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [17:49:29<17:03, 341.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14739.17051235465
INFO:root:current train perplexity4.269200801849365
INFO:root:current mean train loss 14735.272597519668
INFO:root:current train perplexity4.267666339874268
INFO:root:current mean train loss 14739.052758487655
INFO:root:current train perplexity4.274238109588623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.99s/it]
INFO:root:final mean train loss: 14726.824092741936
INFO:root:final train perplexity: 4.27395486831665
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it]
INFO:root:eval mean loss: 22444.858979724704
INFO:root:eval perplexity: 10.205697059631348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [17:54:45<11:07, 333.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14756.52855674342
INFO:root:current train perplexity4.282767295837402
INFO:root:current mean train loss 14743.576432291668
INFO:root:current train perplexity4.275873184204102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.93s/it]
INFO:root:final mean train loss: 14726.29529202369
INFO:root:final train perplexity: 4.273731708526611
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it]
INFO:root:eval mean loss: 22444.597958519345
INFO:root:eval perplexity: 10.205421447753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [18:00:03<05:28, 328.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14708.399871176862
INFO:root:current train perplexity4.261585712432861
INFO:root:current mean train loss 14719.349396789967
INFO:root:current train perplexity4.270256519317627
INFO:root:current mean train loss 14733.905925797064
INFO:root:current train perplexity4.272168159484863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.83s/it]
INFO:root:final mean train loss: 14722.114604334678
INFO:root:final train perplexity: 4.271970272064209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.51s/it]
INFO:root:eval mean loss: 22444.10986328125
INFO:root:eval perplexity: 10.204906463623047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_6/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:05:22<00:00, 325.76s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:05:22<00:00, 325.61s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it]
INFO:root:eval mean loss: 22444.10986328125
INFO:root:eval perplexity: 10.204906463623047
INFO:root:evalaution complete
INFO:root:save model final: small_window_6/final
