INFO:root:Output: small_window_0
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97839.11545138889
INFO:root:current train perplexity15187.6044921875
INFO:root:current mean train loss 81434.30078125
INFO:root:current train perplexity3048.1474609375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.43s/it]
INFO:root:final mean train loss: 75063.62662235383
INFO:root:final train perplexity: 1642.03759765625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it]
INFO:root:eval mean loss: 44183.08454241072
INFO:root:eval perplexity: 96.8108139038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/1

  0%|          | 1/200 [05:51<19:26:12, 351.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42895.9173560049
INFO:root:current train perplexity69.47293090820312
INFO:root:current mean train loss 39103.15050703642
INFO:root:current train perplexity47.211246490478516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.21s/it]
INFO:root:final mean train loss: 36511.86847908266
INFO:root:final train perplexity: 36.64388656616211
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it]
INFO:root:eval mean loss: 31759.985863095237
INFO:root:eval perplexity: 26.76303482055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/2

  1%|          | 2/200 [11:15<18:27:18, 335.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31227.666666666668
INFO:root:current train perplexity22.089818954467773
INFO:root:current mean train loss 29689.44447815534
INFO:root:current train perplexity18.650991439819336
INFO:root:current mean train loss 28786.178879310344
INFO:root:current train perplexity17.06288719177246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it]
INFO:root:final mean train loss: 28400.957409274193
INFO:root:final train perplexity: 16.4652156829834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it]
INFO:root:eval mean loss: 28525.874069940477
INFO:root:eval perplexity: 19.150041580200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/3

  2%|â–         | 3/200 [16:58<18:32:24, 338.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26364.474360795455
INFO:root:current train perplexity13.394697189331055
INFO:root:current mean train loss 25883.459627016127
INFO:root:current train perplexity12.813944816589355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.75s/it]
INFO:root:final mean train loss: 25518.34671906502
INFO:root:final train perplexity: 12.390518188476562
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:eval mean loss: 27111.063058035714
INFO:root:eval perplexity: 16.541595458984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/4

  2%|â–         | 4/200 [22:48<18:40:43, 343.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24885.952566964286
INFO:root:current train perplexity11.324297904968262
INFO:root:current mean train loss 24369.2312536507
INFO:root:current train perplexity11.008451461791992
INFO:root:current mean train loss 24085.626754981884
INFO:root:current train perplexity10.749446868896484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.59s/it]
INFO:root:final mean train loss: 23971.687429120462
INFO:root:final train perplexity: 10.637450218200684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it]
INFO:root:eval mean loss: 26298.896623883928
INFO:root:eval perplexity: 15.208009719848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/5

  2%|â–Ž         | 5/200 [28:35<18:39:50, 344.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23338.883309057204
INFO:root:current train perplexity9.987420082092285
INFO:root:current mean train loss 23106.01867138365
INFO:root:current train perplexity9.7518892288208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.56s/it]
INFO:root:final mean train loss: 22955.92255229335
INFO:root:final train perplexity: 9.62336540222168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.64s/it]
INFO:root:eval mean loss: 25738.160993303572
INFO:root:eval perplexity: 14.350557327270508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/6

  3%|â–Ž         | 6/200 [34:31<18:46:56, 348.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22333.572975852272
INFO:root:current train perplexity9.103514671325684
INFO:root:current mean train loss 22383.298036317567
INFO:root:current train perplexity9.086915016174316
INFO:root:current mean train loss 22260.060343231635
INFO:root:current train perplexity8.974148750305176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.70s/it]
INFO:root:final mean train loss: 22210.94320186492
INFO:root:final train perplexity: 8.941604614257812
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it]
INFO:root:eval mean loss: 25296.080961681546
INFO:root:eval perplexity: 13.70876407623291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/7

  4%|â–Ž         | 7/200 [40:18<18:38:51, 347.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21855.506324404763
INFO:root:current train perplexity8.619961738586426
INFO:root:current mean train loss 21759.882117523008
INFO:root:current train perplexity8.523653984069824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 293.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 293.00s/it]
INFO:root:final mean train loss: 21639.794425718246
INFO:root:final train perplexity: 8.451813697814941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 24994.511300223214
INFO:root:eval perplexity: 13.287506103515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/8

  4%|â–         | 8/200 [46:00<18:27:19, 346.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21404.220833333333
INFO:root:current train perplexity8.181597709655762
INFO:root:current mean train loss 21319.64441236413
INFO:root:current train perplexity8.157633781433105
INFO:root:current mean train loss 21209.050363372095
INFO:root:current train perplexity8.087482452392578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.98s/it]
INFO:root:final mean train loss: 21174.026296307962
INFO:root:final train perplexity: 8.072325706481934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it]
INFO:root:eval mean loss: 24701.616652715773
INFO:root:eval perplexity: 12.890762329101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/9

  4%|â–         | 9/200 [51:53<18:29:06, 348.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20946.209217583953
INFO:root:current train perplexity7.853977680206299
INFO:root:current mean train loss 20879.682225392964
INFO:root:current train perplexity7.819941520690918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.10s/it]
INFO:root:final mean train loss: 20785.18425923009
INFO:root:final train perplexity: 7.768595218658447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:eval mean loss: 24481.702055431546
INFO:root:eval perplexity: 12.600679397583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/10

  5%|â–Œ         | 10/200 [57:31<18:12:36, 345.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20771.78392269737
INFO:root:current train perplexity7.626006126403809
INFO:root:current mean train loss 20575.758321297268
INFO:root:current train perplexity7.562652587890625
INFO:root:current mean train loss 20489.606770833332
INFO:root:current train perplexity7.533425331115723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it]
INFO:root:final mean train loss: 20462.062350365424
INFO:root:final train perplexity: 7.524909496307373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.59s/it]
INFO:root:eval mean loss: 24261.652762276786
INFO:root:eval perplexity: 12.3169527053833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/11

  6%|â–Œ         | 11/200 [1:03:16<18:07:04, 345.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20276.051193882042
INFO:root:current train perplexity7.340470790863037
INFO:root:current mean train loss 20219.932634320176
INFO:root:current train perplexity7.333034515380859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.10s/it]
INFO:root:final mean train loss: 20169.27054719002
INFO:root:final train perplexity: 7.310708522796631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it]
INFO:root:eval mean loss: 24092.77071707589
INFO:root:eval perplexity: 12.103538513183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/12

  6%|â–Œ         | 12/200 [1:09:22<18:20:53, 351.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20044.09086277174
INFO:root:current train perplexity7.1917643547058105
INFO:root:current mean train loss 19948.49625254065
INFO:root:current train perplexity7.158180236816406
INFO:root:current mean train loss 19919.860031880606
INFO:root:current train perplexity7.129796028137207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.72s/it]
INFO:root:final mean train loss: 19915.230894027216
INFO:root:final train perplexity: 7.129804611206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.26s/it]
INFO:root:eval mean loss: 23943.982514880954
INFO:root:eval perplexity: 11.918583869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/13

  6%|â–‹         | 13/200 [1:15:13<18:14:42, 351.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19799.234192708333
INFO:root:current train perplexity7.004331111907959
INFO:root:current mean train loss 19727.95174107143
INFO:root:current train perplexity6.989808082580566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.63s/it]
INFO:root:final mean train loss: 19693.788960118447
INFO:root:final train perplexity: 6.975768566131592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.72s/it]
INFO:root:eval mean loss: 23816.863792782737
INFO:root:eval perplexity: 11.762810707092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/14

  7%|â–‹         | 14/200 [1:21:02<18:07:16, 350.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19493.13165509259
INFO:root:current train perplexity6.8668084144592285
INFO:root:current mean train loss 19459.243248646653
INFO:root:current train perplexity6.84515905380249
INFO:root:current mean train loss 19502.455663202094
INFO:root:current train perplexity6.837886333465576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.71s/it]
INFO:root:final mean train loss: 19480.46687169229
INFO:root:final train perplexity: 6.8305253982543945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 48.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 48.00s/it]
INFO:root:eval mean loss: 23700.803176153273
INFO:root:eval perplexity: 11.622361183166504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/15

  8%|â–Š         | 15/200 [1:26:50<17:58:45, 349.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19308.790867286392
INFO:root:current train perplexity6.723422527313232
INFO:root:current mean train loss 19310.470081180167
INFO:root:current train perplexity6.714534282684326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.78s/it]
INFO:root:final mean train loss: 19293.614994172127
INFO:root:final train perplexity: 6.7057952880859375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:eval mean loss: 23600.211239769345
INFO:root:eval perplexity: 11.501994132995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/16

  8%|â–Š         | 16/200 [1:32:43<17:55:54, 350.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19090.69222530242
INFO:root:current train perplexity6.635822772979736
INFO:root:current mean train loss 19129.899272423663
INFO:root:current train perplexity6.5952277183532715
INFO:root:current mean train loss 19127.91933001894
INFO:root:current train perplexity6.592927932739258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.60s/it]
INFO:root:final mean train loss: 19125.345266034525
INFO:root:final train perplexity: 6.595419883728027
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.04s/it]
INFO:root:eval mean loss: 23487.827194940477
INFO:root:eval perplexity: 11.368986129760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/17

  8%|â–Š         | 17/200 [1:38:37<17:52:45, 351.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18966.7644719503
INFO:root:current train perplexity6.490607738494873
INFO:root:current mean train loss 18977.25877305328
INFO:root:current train perplexity6.48307991027832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.84s/it]
INFO:root:final mean train loss: 18959.84714827999
INFO:root:final train perplexity: 6.488635063171387
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:eval mean loss: 23425.892252604168
INFO:root:eval perplexity: 11.296342849731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/18

  9%|â–‰         | 18/200 [1:44:24<17:42:34, 350.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18888.128125
INFO:root:current train perplexity6.433020114898682
INFO:root:current mean train loss 18891.387934027778
INFO:root:current train perplexity6.427365303039551
INFO:root:current mean train loss 18817.830211103723
INFO:root:current train perplexity6.394284725189209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.21s/it]
INFO:root:final mean train loss: 18816.90676190776
INFO:root:final train perplexity: 6.397796154022217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.51s/it]
INFO:root:eval mean loss: 23339.84598214286
INFO:root:eval perplexity: 11.19619083404541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/19

 10%|â–‰         | 19/200 [1:50:18<17:40:16, 351.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18684.856815732757
INFO:root:current train perplexity6.300169467926025
INFO:root:current mean train loss 18718.228776737968
INFO:root:current train perplexity6.316285610198975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.12s/it]
INFO:root:final mean train loss: 18686.846577305947
INFO:root:final train perplexity: 6.316249370574951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.90s/it]
INFO:root:eval mean loss: 23247.030226934523
INFO:root:eval perplexity: 11.089156150817871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/20

 10%|â–ˆ         | 20/200 [1:56:21<17:44:54, 354.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18693.994140625
INFO:root:current train perplexity6.254159927368164
INFO:root:current mean train loss 18587.45479709982
INFO:root:current train perplexity6.2403340339660645
INFO:root:current mean train loss 18577.1773094273
INFO:root:current train perplexity6.237503528594971


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.87s/it]
INFO:root:final mean train loss: 18555.48239824849
INFO:root:final train perplexity: 6.23493766784668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.79s/it]
INFO:root:eval mean loss: 23198.717843191964
INFO:root:eval perplexity: 11.03384780883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/21

 10%|â–ˆ         | 21/200 [2:02:11<17:33:54, 353.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18434.308250343405
INFO:root:current train perplexity6.163599014282227
INFO:root:current mean train loss 18448.95558941427
INFO:root:current train perplexity6.1559672355651855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.33s/it]
INFO:root:final mean train loss: 18434.712433845765
INFO:root:final train perplexity: 6.161109924316406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.55s/it]
INFO:root:eval mean loss: 23125.675316220237
INFO:root:eval perplexity: 10.950745582580566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/22

 11%|â–ˆ         | 22/200 [2:08:06<17:29:30, 353.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18379.346157340115
INFO:root:current train perplexity6.1196160316467285
INFO:root:current mean train loss 18349.643452250875
INFO:root:current train perplexity6.103149890899658
INFO:root:current mean train loss 18353.583325295782
INFO:root:current train perplexity6.100141525268555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it]
INFO:root:final mean train loss: 18330.901394751763
INFO:root:final train perplexity: 6.098346710205078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.53s/it]
INFO:root:eval mean loss: 23099.15552920387
INFO:root:eval perplexity: 10.920736312866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/23

 12%|â–ˆâ–        | 23/200 [2:13:52<17:16:45, 351.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18271.55657894737
INFO:root:current train perplexity6.032693862915039
INFO:root:current mean train loss 18238.328014823717
INFO:root:current train perplexity6.027944087982178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.72s/it]
INFO:root:final mean train loss: 18216.79976530998
INFO:root:final train perplexity: 6.030099868774414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:eval mean loss: 23008.714518229168
INFO:root:eval perplexity: 10.818988800048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/24

 12%|â–ˆâ–        | 24/200 [2:19:40<17:07:59, 350.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18064.21712932181
INFO:root:current train perplexity5.9586944580078125
INFO:root:current mean train loss 18125.597882121598
INFO:root:current train perplexity5.975590229034424
INFO:root:current mean train loss 18134.210779352226
INFO:root:current train perplexity5.973961353302002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.10s/it]
INFO:root:final mean train loss: 18120.98482390373
INFO:root:final train perplexity: 5.973381042480469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it]
INFO:root:eval mean loss: 23011.87572079613
INFO:root:eval perplexity: 10.822525978088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/25

 12%|â–ˆâ–Ž        | 25/200 [2:25:38<17:09:02, 352.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18074.59035669192
INFO:root:current train perplexity5.9343438148498535
INFO:root:current mean train loss 18060.261551900127
INFO:root:current train perplexity5.919554233551025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.83s/it]
INFO:root:final mean train loss: 18029.539897303428
INFO:root:final train perplexity: 5.919746398925781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.71s/it]
INFO:root:eval mean loss: 22946.126860119046
INFO:root:eval perplexity: 10.74913215637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/26

 13%|â–ˆâ–Ž        | 26/200 [2:31:25<16:57:42, 350.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17951.074371936276
INFO:root:current train perplexity5.883950233459473
INFO:root:current mean train loss 17972.644854615068
INFO:root:current train perplexity5.879056453704834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.74s/it]
INFO:root:final mean train loss: 17941.33724483367
INFO:root:final train perplexity: 5.868470668792725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.99s/it]
INFO:root:eval mean loss: 22908.394438244046
INFO:root:eval perplexity: 10.707240104675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/27

 14%|â–ˆâ–Ž        | 27/200 [2:37:16<16:52:10, 351.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18030.477213541668
INFO:root:current train perplexity5.821361541748047
INFO:root:current mean train loss 17880.54088288835
INFO:root:current train perplexity5.82946252822876
INFO:root:current mean train loss 17879.00967903325
INFO:root:current train perplexity5.818164348602295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.57s/it]
INFO:root:final mean train loss: 17853.0671938004
INFO:root:final train perplexity: 5.817600250244141
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it]
INFO:root:eval mean loss: 22851.816359747023
INFO:root:eval perplexity: 10.644726753234863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/28

 14%|â–ˆâ–        | 28/200 [2:43:03<16:43:13, 349.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17847.731178977272
INFO:root:current train perplexity5.798453330993652
INFO:root:current mean train loss 17816.369140625
INFO:root:current train perplexity5.782476425170898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.96s/it]
INFO:root:final mean train loss: 17778.298654863913
INFO:root:final train perplexity: 5.774855613708496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.61s/it]
INFO:root:eval mean loss: 22829.499976748513
INFO:root:eval perplexity: 10.62016773223877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/29

 14%|â–ˆâ–        | 29/200 [2:49:03<16:45:44, 352.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17814.983816964286
INFO:root:current train perplexity5.73726749420166
INFO:root:current mean train loss 17805.533458674065
INFO:root:current train perplexity5.73766565322876
INFO:root:current mean train loss 17743.27351298309
INFO:root:current train perplexity5.730679035186768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.78s/it]
INFO:root:final mean train loss: 17696.725865517892
INFO:root:final train perplexity: 5.728579044342041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.77s/it]
INFO:root:eval mean loss: 22789.62179129464
INFO:root:eval perplexity: 10.576425552368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/30

 15%|â–ˆâ–Œ        | 30/200 [2:54:51<16:35:20, 351.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17644.498079978814
INFO:root:current train perplexity5.690831184387207
INFO:root:current mean train loss 17641.552243022797
INFO:root:current train perplexity5.688950061798096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.78s/it]
INFO:root:final mean train loss: 17623.280517578125
INFO:root:final train perplexity: 5.687230587005615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:eval mean loss: 22760.660086495536
INFO:root:eval perplexity: 10.544771194458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/31

 16%|â–ˆâ–Œ        | 31/200 [3:00:41<16:28:27, 350.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17485.150035511364
INFO:root:current train perplexity5.619173049926758
INFO:root:current mean train loss 17564.82006615991
INFO:root:current train perplexity5.634180545806885
INFO:root:current mean train loss 17564.76288507109
INFO:root:current train perplexity5.650081634521484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.85s/it]
INFO:root:final mean train loss: 17551.37521263861
INFO:root:final train perplexity: 5.64703893661499
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.05s/it]
INFO:root:eval mean loss: 22737.04417782738
INFO:root:eval perplexity: 10.519034385681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/32

 16%|â–ˆâ–Œ        | 32/200 [3:06:22<16:14:19, 347.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17491.120752728173
INFO:root:current train perplexity5.5955424308776855
INFO:root:current mean train loss 17506.01549319402
INFO:root:current train perplexity5.612630844116211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.11s/it]
INFO:root:final mean train loss: 17485.207121818297
INFO:root:final train perplexity: 5.610304832458496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.64s/it]
INFO:root:eval mean loss: 22720.717261904763
INFO:root:eval perplexity: 10.501273155212402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/33

 16%|â–ˆâ–‹        | 33/200 [3:12:11<16:09:16, 348.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17259.409505208332
INFO:root:current train perplexity5.5234293937683105
INFO:root:current mean train loss 17412.505129076086
INFO:root:current train perplexity5.570336818695068
INFO:root:current mean train loss 17396.498273982557
INFO:root:current train perplexity5.559158802032471


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.17s/it]
INFO:root:final mean train loss: 17412.794953377015
INFO:root:final train perplexity: 5.570377349853516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.03s/it]
INFO:root:eval mean loss: 22662.120744977678
INFO:root:eval perplexity: 10.43778133392334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/34

 17%|â–ˆâ–‹        | 34/200 [3:18:06<16:09:16, 350.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17351.141543260263
INFO:root:current train perplexity5.534879684448242
INFO:root:current mean train loss 17369.509525870133
INFO:root:current train perplexity5.5355224609375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.39s/it]
INFO:root:final mean train loss: 17353.22837780368
INFO:root:final train perplexity: 5.537745475769043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.45s/it]
INFO:root:eval mean loss: 22645.724097842263
INFO:root:eval perplexity: 10.420083045959473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/35

 18%|â–ˆâ–Š        | 35/200 [3:23:54<16:01:19, 349.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17496.609375
INFO:root:current train perplexity5.5667243003845215
INFO:root:current mean train loss 17343.265698857667
INFO:root:current train perplexity5.520499229431152
INFO:root:current mean train loss 17316.200445027112
INFO:root:current train perplexity5.507315158843994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.89s/it]
INFO:root:final mean train loss: 17298.298465851814
INFO:root:final train perplexity: 5.5078253746032715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.80s/it]
INFO:root:eval mean loss: 22652.4150390625
INFO:root:eval perplexity: 10.427299499511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/36

 18%|â–ˆâ–Š        | 36/200 [3:29:40<15:52:25, 348.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17204.503177266724
INFO:root:current train perplexity5.456229209899902
INFO:root:current mean train loss 17229.26861179642
INFO:root:current train perplexity5.4735918045043945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.33s/it]
INFO:root:final mean train loss: 17235.098038211945
INFO:root:final train perplexity: 5.473598480224609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.74s/it]
INFO:root:eval mean loss: 22603.302153087796
INFO:root:eval perplexity: 10.374433517456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/37

 18%|â–ˆâ–Š        | 37/200 [3:35:39<15:55:19, 351.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17124.940047554348
INFO:root:current train perplexity5.415801525115967
INFO:root:current mean train loss 17127.956681910568
INFO:root:current train perplexity5.432267665863037
INFO:root:current mean train loss 17194.395980766534
INFO:root:current train perplexity5.444690227508545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.96s/it]
INFO:root:final mean train loss: 17178.6961906187
INFO:root:final train perplexity: 5.443232536315918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:eval mean loss: 22594.718122209822
INFO:root:eval perplexity: 10.365219116210938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/38

 19%|â–ˆâ–‰        | 38/200 [3:41:24<15:44:24, 349.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17147.53546875
INFO:root:current train perplexity5.408578872680664
INFO:root:current mean train loss 17132.120797991072
INFO:root:current train perplexity5.410659313201904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.95s/it]
INFO:root:final mean train loss: 17128.478681010583
INFO:root:final train perplexity: 5.41633939743042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it]
INFO:root:eval mean loss: 22575.282761346727
INFO:root:eval perplexity: 10.344392776489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/39

 20%|â–ˆâ–‰        | 39/200 [3:47:18<15:41:31, 350.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16995.74927662037
INFO:root:current train perplexity5.351109981536865
INFO:root:current mean train loss 17083.370086429626
INFO:root:current train perplexity5.389520168304443
INFO:root:current mean train loss 17085.956532213655
INFO:root:current train perplexity5.387362003326416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.75s/it]
INFO:root:final mean train loss: 17076.596470986642
INFO:root:final train perplexity: 5.388693332672119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:eval mean loss: 22558.126441592263
INFO:root:eval perplexity: 10.326040267944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/40

 20%|â–ˆâ–ˆ        | 40/200 [3:53:08<15:35:06, 350.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17067.732743275315
INFO:root:current train perplexity5.370264053344727
INFO:root:current mean train loss 17077.601660701817
INFO:root:current train perplexity5.3740105628967285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.46s/it]
INFO:root:final mean train loss: 17023.123873802924
INFO:root:final train perplexity: 5.360347747802734
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22549.242373511905
INFO:root:eval perplexity: 10.316549301147461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/41

 20%|â–ˆâ–ˆ        | 41/200 [3:58:58<15:29:13, 350.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16899.1173765121
INFO:root:current train perplexity5.303760051727295
INFO:root:current mean train loss 16951.41887822042
INFO:root:current train perplexity5.319149494171143
INFO:root:current mean train loss 16994.678186722133
INFO:root:current train perplexity5.334494113922119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.12s/it]
INFO:root:final mean train loss: 16975.051399477066
INFO:root:final train perplexity: 5.334990501403809
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.68s/it]
INFO:root:eval mean loss: 22512.46023995536
INFO:root:eval perplexity: 10.277350425720215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/42

 21%|â–ˆâ–ˆ        | 42/200 [4:04:48<15:22:40, 350.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16918.23426910768
INFO:root:current train perplexity5.307417869567871
INFO:root:current mean train loss 16950.852581753756
INFO:root:current train perplexity5.310729026794434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.34s/it]
INFO:root:final mean train loss: 16926.161936113913
INFO:root:final train perplexity: 5.309328079223633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.62s/it]
INFO:root:eval mean loss: 22538.2998046875
INFO:root:eval perplexity: 10.304872512817383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/43

 22%|â–ˆâ–ˆâ–       | 43/200 [4:10:42<15:19:39, 351.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17006.956166294643
INFO:root:current train perplexity5.319976329803467
INFO:root:current mean train loss 16924.32595486111
INFO:root:current train perplexity5.286357402801514
INFO:root:current mean train loss 16895.938268783244
INFO:root:current train perplexity5.286234378814697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.23s/it]
INFO:root:final mean train loss: 16881.08066485005
INFO:root:final train perplexity: 5.285772800445557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it]
INFO:root:eval mean loss: 22513.41378348214
INFO:root:eval perplexity: 10.278365135192871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:16:40<15:19:08, 353.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16825.52956627155
INFO:root:current train perplexity5.250701904296875
INFO:root:current mean train loss 16845.100053267044
INFO:root:current train perplexity5.257694721221924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.64s/it]
INFO:root:final mean train loss: 16835.69038637223
INFO:root:final train perplexity: 5.262160778045654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.77s/it]
INFO:root:eval mean loss: 22493.331449962796
INFO:root:eval perplexity: 10.257022857666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:22:37<15:15:30, 354.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16825.967247596152
INFO:root:current train perplexity5.2488627433776855
INFO:root:current mean train loss 16793.290207677608
INFO:root:current train perplexity5.238701820373535
INFO:root:current mean train loss 16808.31779550209
INFO:root:current train perplexity5.240634441375732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.44s/it]
INFO:root:final mean train loss: 16792.53134450605
INFO:root:final train perplexity: 5.239808559417725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.74s/it]
INFO:root:eval mean loss: 22483.08484468006
INFO:root:eval perplexity: 10.246153831481934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:28:26<15:05:39, 352.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16789.548967633928
INFO:root:current train perplexity5.215428829193115
INFO:root:current mean train loss 16782.64989467441
INFO:root:current train perplexity5.222660541534424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.99s/it]
INFO:root:final mean train loss: 16750.836374590475
INFO:root:final train perplexity: 5.21830415725708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it]
INFO:root:eval mean loss: 22466.81173270089
INFO:root:eval perplexity: 10.228911399841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:34:16<14:57:41, 352.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16720.5607512718
INFO:root:current train perplexity5.198200702667236
INFO:root:current mean train loss 16723.783469460228
INFO:root:current train perplexity5.1967973709106445
INFO:root:current mean train loss 16718.284448945473
INFO:root:current train perplexity5.196505069732666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.93s/it]
INFO:root:final mean train loss: 16707.698565083167
INFO:root:final train perplexity: 5.19614839553833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.86s/it]
INFO:root:eval mean loss: 22465.596586681546
INFO:root:eval perplexity: 10.22762393951416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:40:19<14:59:54, 355.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16654.244675164475
INFO:root:current train perplexity5.160693645477295
INFO:root:current mean train loss 16670.4123046875
INFO:root:current train perplexity5.16862154006958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.30s/it]
INFO:root:final mean train loss: 16671.528430569557
INFO:root:final train perplexity: 5.177643775939941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it]
INFO:root:eval mean loss: 22438.65257626488
INFO:root:eval perplexity: 10.199143409729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:46:18<14:56:57, 356.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16650.337163397606
INFO:root:current train perplexity5.13260555267334
INFO:root:current mean train loss 16637.98296662415
INFO:root:current train perplexity5.153409004211426
INFO:root:current mean train loss 16641.010619622975
INFO:root:current train perplexity5.1562676429748535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.21s/it]
INFO:root:final mean train loss: 16630.319351688508
INFO:root:final train perplexity: 5.156641960144043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it]
INFO:root:eval mean loss: 22442.587332589286
INFO:root:eval perplexity: 10.20329761505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:52:05<14:43:38, 353.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16606.159298058712
INFO:root:current train perplexity5.12343168258667
INFO:root:current mean train loss 16583.44015978329
INFO:root:current train perplexity5.136656284332275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.75s/it]
INFO:root:final mean train loss: 16595.979870211693
INFO:root:final train perplexity: 5.139205455780029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.33s/it]
INFO:root:eval mean loss: 22425.885207403273
INFO:root:eval perplexity: 10.185676574707031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:57:50<14:31:28, 350.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16568.14066329657
INFO:root:current train perplexity5.1145339012146
INFO:root:current mean train loss 16579.431815242137
INFO:root:current train perplexity5.119009971618652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.20s/it]
INFO:root:final mean train loss: 16558.050340221773
INFO:root:final train perplexity: 5.120015621185303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it]
INFO:root:eval mean loss: 22427.222144717263
INFO:root:eval perplexity: 10.187085151672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:03:39<14:24:37, 350.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16650.377278645832
INFO:root:current train perplexity5.231345176696777
INFO:root:current mean train loss 16485.969081841627
INFO:root:current train perplexity5.082748889923096
INFO:root:current mean train loss 16528.18680245536
INFO:root:current train perplexity5.09928560256958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.37s/it]
INFO:root:final mean train loss: 16522.97054167717
INFO:root:final train perplexity: 5.102331161499023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it]
INFO:root:eval mean loss: 22414.276181175595
INFO:root:eval perplexity: 10.173444747924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:09:21<14:12:25, 347.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16473.942365056817
INFO:root:current train perplexity5.088707447052002
INFO:root:current mean train loss 16531.020961441533
INFO:root:current train perplexity5.0983195304870605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.94s/it]
INFO:root:final mean train loss: 16487.107906218498
INFO:root:final train perplexity: 5.084314823150635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 22388.903971354168
INFO:root:eval perplexity: 10.146766662597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:15:01<14:01:05, 345.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16353.96986607143
INFO:root:current train perplexity5.082156181335449
INFO:root:current mean train loss 16449.795122663552
INFO:root:current train perplexity5.068610191345215
INFO:root:current mean train loss 16452.699228185385
INFO:root:current train perplexity5.069949150085449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.09s/it]
INFO:root:final mean train loss: 16452.382721931703
INFO:root:final train perplexity: 5.066930770874023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it]
INFO:root:eval mean loss: 22393.424967447918
INFO:root:eval perplexity: 10.151516914367676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:20:43<13:52:32, 344.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16441.865515757414
INFO:root:current train perplexity5.04085636138916
INFO:root:current mean train loss 16396.129551149763
INFO:root:current train perplexity5.041216850280762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.88s/it]
INFO:root:final mean train loss: 16417.654308688256
INFO:root:final train perplexity: 5.049604415893555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.69s/it]
INFO:root:eval mean loss: 22398.64708891369
INFO:root:eval perplexity: 10.157002449035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:26:22<13:42:35, 342.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16515.30859375
INFO:root:current train perplexity5.068544864654541
INFO:root:current mean train loss 16373.620565878378
INFO:root:current train perplexity5.026226997375488
INFO:root:current mean train loss 16408.210303428612
INFO:root:current train perplexity5.034698486328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.12s/it]
INFO:root:final mean train loss: 16380.007280903477
INFO:root:final train perplexity: 5.030888080596924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.57s/it]
INFO:root:eval mean loss: 22384.970121837796
INFO:root:eval perplexity: 10.142635345458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:32:03<13:35:25, 342.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16314.439034598214
INFO:root:current train perplexity4.988513469696045
INFO:root:current mean train loss 16346.598351226994
INFO:root:current train perplexity5.010373592376709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.05s/it]
INFO:root:final mean train loss: 16346.883871755292
INFO:root:final train perplexity: 5.014480113983154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it]
INFO:root:eval mean loss: 22381.962379092263
INFO:root:eval perplexity: 10.139480590820312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:38:01<13:41:13, 346.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16313.252669270832
INFO:root:current train perplexity5.004233360290527
INFO:root:current mean train loss 16267.057192595108
INFO:root:current train perplexity4.976129055023193
INFO:root:current mean train loss 16300.094622093024
INFO:root:current train perplexity4.993081092834473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it]
INFO:root:final mean train loss: 16315.811196604083
INFO:root:final train perplexity: 4.999134540557861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it]
INFO:root:eval mean loss: 22364.55394345238
INFO:root:eval perplexity: 10.12122631072998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:43:45<13:33:41, 346.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16287.093939482276
INFO:root:current train perplexity4.964075565338135
INFO:root:current mean train loss 16288.604416167665
INFO:root:current train perplexity4.984487056732178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.92s/it]
INFO:root:final mean train loss: 16285.242289881553
INFO:root:final train perplexity: 4.9840850830078125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.88s/it]
INFO:root:eval mean loss: 22369.99793061756
INFO:root:eval perplexity: 10.126932144165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:49:36<13:31:02, 347.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16249.501850328947
INFO:root:current train perplexity4.974817752838135
INFO:root:current mean train loss 16235.974830948004
INFO:root:current train perplexity4.965937614440918
INFO:root:current mean train loss 16255.380725599314
INFO:root:current train perplexity4.966677665710449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.62s/it]
INFO:root:final mean train loss: 16255.393030966481
INFO:root:final train perplexity: 4.969432830810547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.72s/it]
INFO:root:eval mean loss: 22346.07442801339
INFO:root:eval perplexity: 10.101888656616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:55:28<13:28:28, 348.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16255.524964238557
INFO:root:current train perplexity4.95937967300415
INFO:root:current mean train loss 16257.823956048976
INFO:root:current train perplexity4.95945405960083


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.96s/it]
INFO:root:final mean train loss: 16228.295295961441
INFO:root:final train perplexity: 4.956168174743652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it]
INFO:root:eval mean loss: 22359.872907366072
INFO:root:eval perplexity: 10.116323471069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:01:27<13:29:23, 351.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16122.535708220108
INFO:root:current train perplexity4.907900810241699
INFO:root:current mean train loss 16210.119998094513
INFO:root:current train perplexity4.933708190917969
INFO:root:current mean train loss 16214.4476991662
INFO:root:current train perplexity4.943939208984375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.99s/it]
INFO:root:final mean train loss: 16200.037196005544
INFO:root:final train perplexity: 4.942374229431152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it]
INFO:root:eval mean loss: 22355.013137090773
INFO:root:eval perplexity: 10.111238479614258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [6:07:18<13:22:52, 351.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16158.5909375
INFO:root:current train perplexity4.929004669189453
INFO:root:current mean train loss 16196.222823660713
INFO:root:current train perplexity4.9262824058532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.74s/it]
INFO:root:final mean train loss: 16171.847876764114
INFO:root:final train perplexity: 4.928651809692383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it]
INFO:root:eval mean loss: 22339.369652157737
INFO:root:eval perplexity: 10.09488296508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:13:04<13:12:50, 349.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16256.16648582176
INFO:root:current train perplexity4.928464889526367
INFO:root:current mean train loss 16132.289631520669
INFO:root:current train perplexity4.906310558319092
INFO:root:current mean train loss 16154.852306752478
INFO:root:current train perplexity4.915388107299805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.98s/it]
INFO:root:final mean train loss: 16147.696576518398
INFO:root:final train perplexity: 4.916925430297852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.07s/it]
INFO:root:eval mean loss: 22358.761276971727
INFO:root:eval perplexity: 10.115160942077637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:18:50<13:04:30, 348.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16138.84412084652
INFO:root:current train perplexity4.898379802703857
INFO:root:current mean train loss 16130.473823760474
INFO:root:current train perplexity4.900897026062012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.90s/it]
INFO:root:final mean train loss: 16117.865521830898
INFO:root:final train perplexity: 4.902479648590088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.67s/it]
INFO:root:eval mean loss: 22349.380068824405
INFO:root:eval perplexity: 10.105345726013184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:24:37<12:57:54, 348.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16043.20662172379
INFO:root:current train perplexity4.857924938201904
INFO:root:current mean train loss 16100.44590141937
INFO:root:current train perplexity4.881241321563721
INFO:root:current mean train loss 16095.860068317099
INFO:root:current train perplexity4.8863115310668945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.54s/it]
INFO:root:final mean train loss: 16086.417594663559
INFO:root:final train perplexity: 4.887296676635742
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.25s/it]
INFO:root:eval mean loss: 22340.697126116072
INFO:root:eval perplexity: 10.096269607543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:30:34<12:57:46, 350.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16076.229327466115
INFO:root:current train perplexity4.872730255126953
INFO:root:current mean train loss 16081.194736168032
INFO:root:current train perplexity4.873289585113525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.56s/it]
INFO:root:final mean train loss: 16065.228507749496
INFO:root:final train perplexity: 4.877093315124512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:eval mean loss: 22335.831194196428
INFO:root:eval perplexity: 10.091184616088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:36:25<12:51:56, 350.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16124.633231026786
INFO:root:current train perplexity4.885129451751709
INFO:root:current mean train loss 16052.380794270834
INFO:root:current train perplexity4.859475135803223
INFO:root:current mean train loss 16052.28966505984
INFO:root:current train perplexity4.862155437469482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.05s/it]
INFO:root:final mean train loss: 16036.262238533267
INFO:root:final train perplexity: 4.8631792068481445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.75s/it]
INFO:root:eval mean loss: 22332.101399739582
INFO:root:eval perplexity: 10.087286949157715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:42:14<12:44:40, 350.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16012.183818247126
INFO:root:current train perplexity4.855884075164795
INFO:root:current mean train loss 15996.39950284091
INFO:root:current train perplexity4.850224018096924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it]
INFO:root:final mean train loss: 16018.182180097027
INFO:root:final train perplexity: 4.8545145988464355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it]
INFO:root:eval mean loss: 22350.27613467262
INFO:root:eval perplexity: 10.106280326843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:47:57<12:34:18, 348.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15899.8515625
INFO:root:current train perplexity4.8355326652526855
INFO:root:current mean train loss 15953.185019952787
INFO:root:current train perplexity4.825936794281006
INFO:root:current mean train loss 15995.925630066684
INFO:root:current train perplexity4.8375678062438965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.55s/it]
INFO:root:final mean train loss: 15989.538550592239
INFO:root:final train perplexity: 4.840818881988525
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.46s/it]
INFO:root:eval mean loss: 22312.22047061012
INFO:root:eval perplexity: 10.066558837890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:53:47<12:29:48, 348.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15939.127961881868
INFO:root:current train perplexity4.812736511230469
INFO:root:current mean train loss 15956.46243046466
INFO:root:current train perplexity4.821468830108643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.58s/it]
INFO:root:final mean train loss: 15964.015711630544
INFO:root:final train perplexity: 4.828648567199707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it]
INFO:root:eval mean loss: 22313.072800409227
INFO:root:eval perplexity: 10.067441940307617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:59:42<12:27:50, 350.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15950.71609284157
INFO:root:current train perplexity4.797508716583252
INFO:root:current mean train loss 15945.745226453235
INFO:root:current train perplexity4.8132476806640625
INFO:root:current mean train loss 15956.810353973766
INFO:root:current train perplexity4.818657875061035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.78s/it]
INFO:root:final mean train loss: 15942.938212733116
INFO:root:final train perplexity: 4.818620204925537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:eval mean loss: 22316.220563616072
INFO:root:eval perplexity: 10.070723533630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [7:05:30<12:20:25, 349.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15915.604965049342
INFO:root:current train perplexity4.8020477294921875
INFO:root:current mean train loss 15926.164923878205
INFO:root:current train perplexity4.807894229888916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.98s/it]
INFO:root:final mean train loss: 15921.653875535534
INFO:root:final train perplexity: 4.808514595031738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.79s/it]
INFO:root:eval mean loss: 22319.65750558036
INFO:root:eval perplexity: 10.074308395385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [7:11:16<12:12:01, 348.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15884.13536818484
INFO:root:current train perplexity4.779736042022705
INFO:root:current mean train loss 15884.7316711841
INFO:root:current train perplexity4.779608249664307
INFO:root:current mean train loss 15908.511232445597
INFO:root:current train perplexity4.795914649963379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.71s/it]
INFO:root:final mean train loss: 15895.729996219758
INFO:root:final train perplexity: 4.796235084533691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.80s/it]
INFO:root:eval mean loss: 22321.498070126487
INFO:root:eval perplexity: 10.076225280761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:17:04<12:06:09, 348.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15873.359996448864
INFO:root:current train perplexity4.779363632202148
INFO:root:current mean train loss 15879.3795540201
INFO:root:current train perplexity4.782608985900879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.06s/it]
INFO:root:final mean train loss: 15869.792452904487
INFO:root:final train perplexity: 4.783980846405029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.41s/it]
INFO:root:eval mean loss: 22321.216657366072
INFO:root:eval perplexity: 10.075932502746582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:22:59<12:04:30, 350.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15843.079963235294
INFO:root:current train perplexity4.774270057678223
INFO:root:current mean train loss 15866.63842611755
INFO:root:current train perplexity4.773360252380371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.14s/it]
INFO:root:final mean train loss: 15846.813326927924
INFO:root:final train perplexity: 4.77315092086792
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.53s/it]
INFO:root:eval mean loss: 22315.352074032737
INFO:root:eval perplexity: 10.069820404052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:28:43<11:54:20, 348.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15402.490234375
INFO:root:current train perplexity4.628488063812256
INFO:root:current mean train loss 15836.125360285194
INFO:root:current train perplexity4.757410526275635
INFO:root:current mean train loss 15830.186686999692
INFO:root:current train perplexity4.760518550872803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 295.00s/it]
INFO:root:final mean train loss: 15828.555412046371
INFO:root:final train perplexity: 4.764562129974365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:eval mean loss: 22309.88113839286
INFO:root:eval perplexity: 10.064117431640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:34:27<11:45:46, 347.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15778.45186434659
INFO:root:current train perplexity4.756801605224609
INFO:root:current mean train loss 15805.559091481855
INFO:root:current train perplexity4.753454208374023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.94s/it]
INFO:root:final mean train loss: 15809.112489761845
INFO:root:final train perplexity: 4.755434989929199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it]
INFO:root:eval mean loss: 22319.506789434523
INFO:root:eval perplexity: 10.074150085449219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:40:00<11:31:21, 342.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15720.950474330357
INFO:root:current train perplexity4.71032190322876
INFO:root:current mean train loss 15817.245336229556
INFO:root:current train perplexity4.746851921081543
INFO:root:current mean train loss 15817.111469655798
INFO:root:current train perplexity4.751430511474609


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.27s/it]
INFO:root:final mean train loss: 15788.966808688256
INFO:root:final train perplexity: 4.7459940910339355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22309.31994047619
INFO:root:eval perplexity: 10.0635347366333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:45:35<11:21:10, 340.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15713.99265095339
INFO:root:current train perplexity4.711915969848633
INFO:root:current mean train loss 15751.826006043631
INFO:root:current train perplexity4.724903583526611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.18s/it]
INFO:root:final mean train loss: 15763.942678143902
INFO:root:final train perplexity: 4.734294891357422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.55s/it]
INFO:root:eval mean loss: 22311.918108258928
INFO:root:eval perplexity: 10.066241264343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:51:08<11:10:45, 338.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15851.431995738636
INFO:root:current train perplexity4.805357456207275
INFO:root:current mean train loss 15766.959776182432
INFO:root:current train perplexity4.720283031463623
INFO:root:current mean train loss 15769.637352821386
INFO:root:current train perplexity4.72318696975708


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.92s/it]
INFO:root:final mean train loss: 15740.596136277722
INFO:root:final train perplexity: 4.7234063148498535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.88s/it]
INFO:root:eval mean loss: 22312.484072730655
INFO:root:eval perplexity: 10.066831588745117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:57:03<11:15:25, 343.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15721.99234250992
INFO:root:current train perplexity4.71429443359375
INFO:root:current mean train loss 15721.060660707439
INFO:root:current train perplexity4.719174861907959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.49s/it]
INFO:root:final mean train loss: 15724.305892452117
INFO:root:final train perplexity: 4.715823173522949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it]
INFO:root:eval mean loss: 22306.61193266369
INFO:root:eval perplexity: 10.060715675354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [8:02:39<11:05:17, 341.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15721.430533854167
INFO:root:current train perplexity4.682108402252197
INFO:root:current mean train loss 15689.654110054347
INFO:root:current train perplexity4.702070236206055
INFO:root:current mean train loss 15714.228470203489
INFO:root:current train perplexity4.706244945526123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.30s/it]
INFO:root:final mean train loss: 15700.771031533519
INFO:root:final train perplexity: 4.704889297485352
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:eval mean loss: 22317.726539248513
INFO:root:eval perplexity: 10.072294235229492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [8:08:28<11:04:13, 343.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15646.630742770523
INFO:root:current train perplexity4.686446666717529
INFO:root:current mean train loss 15692.964258982036
INFO:root:current train perplexity4.696496486663818


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.38s/it]
INFO:root:final mean train loss: 15688.826282132057
INFO:root:final train perplexity: 4.6993489265441895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.23s/it]
INFO:root:eval mean loss: 22308.8876953125
INFO:root:eval perplexity: 10.06308364868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [8:14:08<10:56:03, 342.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15463.916889391447
INFO:root:current train perplexity4.682956218719482
INFO:root:current mean train loss 15678.990004595587
INFO:root:current train perplexity4.684223651885986
INFO:root:current mean train loss 15674.377853881278
INFO:root:current train perplexity4.685642242431641


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.76s/it]
INFO:root:final mean train loss: 15661.61161951865
INFO:root:final train perplexity: 4.6867523193359375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.52s/it]
INFO:root:eval mean loss: 22313.565569196428
INFO:root:eval perplexity: 10.067957878112793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:19:52<10:51:19, 342.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15595.36709121919
INFO:root:current train perplexity4.680490016937256
INFO:root:current mean train loss 15642.557908442983
INFO:root:current train perplexity4.677345275878906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it]
INFO:root:final mean train loss: 15648.492663967994
INFO:root:final train perplexity: 4.680691242218018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it]
INFO:root:eval mean loss: 22314.341657366072
INFO:root:eval perplexity: 10.068766593933105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:25:29<10:42:36, 341.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15666.236922554348
INFO:root:current train perplexity4.665059566497803
INFO:root:current mean train loss 15636.839804052337
INFO:root:current train perplexity4.669845104217529
INFO:root:current mean train loss 15641.26690372758
INFO:root:current train perplexity4.672244071960449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.71s/it]
INFO:root:final mean train loss: 15630.69187484249
INFO:root:final train perplexity: 4.67248010635376
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it]
INFO:root:eval mean loss: 22321.06222098214
INFO:root:eval perplexity: 10.07577133178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:31:10<10:36:56, 341.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15614.027734375
INFO:root:current train perplexity4.651947498321533
INFO:root:current mean train loss 15606.193571428572
INFO:root:current train perplexity4.658947944641113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it]
INFO:root:final mean train loss: 15610.352164976059
INFO:root:final train perplexity: 4.663115978240967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it]
INFO:root:eval mean loss: 22302.991048177082
INFO:root:eval perplexity: 10.056943893432617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:36:49<10:29:35, 340.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15573.662796585648
INFO:root:current train perplexity4.6487555503845215
INFO:root:current mean train loss 15549.543906865158
INFO:root:current train perplexity4.6359148025512695
INFO:root:current mean train loss 15590.321723568282
INFO:root:current train perplexity4.650224208831787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.85s/it]
INFO:root:final mean train loss: 15591.655442760837
INFO:root:final train perplexity: 4.654523849487305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it]
INFO:root:eval mean loss: 22306.061709449405
INFO:root:eval perplexity: 10.060140609741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:42:24<10:21:06, 338.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15639.353911194621
INFO:root:current train perplexity4.652036190032959
INFO:root:current mean train loss 15580.592107847417
INFO:root:current train perplexity4.646158218383789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.22s/it]
INFO:root:final mean train loss: 15579.114372007309
INFO:root:final train perplexity: 4.648770332336426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22293.938941592263
INFO:root:eval perplexity: 10.047527313232422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/91
########################best#######################
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:47:59<10:13:24, 337.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15573.0732421875
INFO:root:current train perplexity4.64595365524292
INFO:root:current mean train loss 15559.704437022901
INFO:root:current train perplexity4.6434221267700195
INFO:root:current mean train loss 15570.00691203328
INFO:root:current train perplexity4.641297340393066


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.89s/it]
INFO:root:final mean train loss: 15560.932727444557
INFO:root:final train perplexity: 4.640441417694092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.66s/it]
INFO:root:eval mean loss: 22316.51306733631
INFO:root:eval perplexity: 10.071028709411621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:53:26<10:02:12, 334.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15575.459372646837
INFO:root:current train perplexity4.640090465545654
INFO:root:current mean train loss 15551.82141713627
INFO:root:current train perplexity4.630823612213135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it]
INFO:root:final mean train loss: 15542.377957251763
INFO:root:final train perplexity: 4.631956577301025
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.75s/it]
INFO:root:eval mean loss: 22308.926292782737
INFO:root:eval perplexity: 10.063124656677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:59:09<10:01:04, 337.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15519.5107421875
INFO:root:current train perplexity4.5966291427612305
INFO:root:current mean train loss 15506.87630931713
INFO:root:current train perplexity4.61623477935791
INFO:root:current mean train loss 15531.778806515957
INFO:root:current train perplexity4.6215739250183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it]
INFO:root:final mean train loss: 15521.129280336441
INFO:root:final train perplexity: 4.622259616851807
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22321.467796688987
INFO:root:eval perplexity: 10.076196670532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [9:04:44<9:54:07, 336.30s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15538.550657776581
INFO:root:current train perplexity4.609898090362549
INFO:root:current mean train loss 15526.812510444519
INFO:root:current train perplexity4.617598056793213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it]
INFO:root:final mean train loss: 15507.751421528477
INFO:root:final train perplexity: 4.6161651611328125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it]
INFO:root:eval mean loss: 22314.88304501488
INFO:root:eval perplexity: 10.069331169128418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [9:10:17<9:47:10, 335.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15431.83380909455
INFO:root:current train perplexity4.561868190765381
INFO:root:current mean train loss 15496.543179518885
INFO:root:current train perplexity4.594165325164795
INFO:root:current mean train loss 15515.862464042886
INFO:root:current train perplexity4.609803676605225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.79s/it]
INFO:root:final mean train loss: 15492.570269184727
INFO:root:final train perplexity: 4.609257698059082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.01s/it]
INFO:root:eval mean loss: 22315.257277715773
INFO:root:eval perplexity: 10.069720268249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [9:15:48<9:39:00, 334.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15517.33938229739
INFO:root:current train perplexity4.606517791748047
INFO:root:current mean train loss 15473.962205497382
INFO:root:current train perplexity4.600489139556885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.82s/it]
INFO:root:final mean train loss: 15473.495101436492
INFO:root:final train perplexity: 4.6005940437316895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it]
INFO:root:eval mean loss: 22326.163550967263
INFO:root:eval perplexity: 10.081093788146973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:21:16<9:30:38, 332.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15469.949332303779
INFO:root:current train perplexity4.606967926025391
INFO:root:current mean train loss 15480.738062718532
INFO:root:current train perplexity4.60172176361084
INFO:root:current mean train loss 15472.309003665123
INFO:root:current train perplexity4.5963053703308105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it]
INFO:root:final mean train loss: 15463.435822517642
INFO:root:final train perplexity: 4.596031665802002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.68s/it]
INFO:root:eval mean loss: 22310.318382626487
INFO:root:eval perplexity: 10.064574241638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:26:46<9:23:48, 331.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15485.714360608552
INFO:root:current train perplexity4.5852370262146
INFO:root:current mean train loss 15461.183648838141
INFO:root:current train perplexity4.588234901428223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.23s/it]
INFO:root:final mean train loss: 15446.445501512097
INFO:root:final train perplexity: 4.5883355140686035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.50s/it]
INFO:root:eval mean loss: 22307.39915829613
INFO:root:eval perplexity: 10.06153392791748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:32:13<9:15:41, 330.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15359.28474069149
INFO:root:current train perplexity4.534616947174072
INFO:root:current mean train loss 15417.925083705357
INFO:root:current train perplexity4.566772937774658
INFO:root:current mean train loss 15431.259267459514
INFO:root:current train perplexity4.575972080230713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.72s/it]
INFO:root:final mean train loss: 15420.639672064011
INFO:root:final train perplexity: 4.576672077178955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it]
INFO:root:eval mean loss: 22317.270972842263
INFO:root:eval perplexity: 10.071818351745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:37:40<9:08:48, 329.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15367.744328046087
INFO:root:current train perplexity4.557252407073975
INFO:root:current mean train loss 15434.764015389448
INFO:root:current train perplexity4.57407808303833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.22s/it]
INFO:root:final mean train loss: 15414.68267625378
INFO:root:final train perplexity: 4.573983669281006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it]
INFO:root:eval mean loss: 22309.02160063244
INFO:root:eval perplexity: 10.063225746154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:43:07<9:02:17, 328.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15441.609355851715
INFO:root:current train perplexity4.55801248550415
INFO:root:current mean train loss 15423.384972578642
INFO:root:current train perplexity4.567972183227539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.62s/it]
INFO:root:final mean train loss: 15399.849837764617
INFO:root:final train perplexity: 4.567297458648682
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it]
INFO:root:eval mean loss: 22305.799269903273
INFO:root:eval perplexity: 10.059869766235352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:48:35<8:56:27, 328.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15448.9013671875
INFO:root:current train perplexity4.497155666351318
INFO:root:current mean train loss 15410.666650864685
INFO:root:current train perplexity4.55076265335083
INFO:root:current mean train loss 15378.37182015856
INFO:root:current train perplexity4.552683353424072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.09s/it]
INFO:root:final mean train loss: 15379.264908329133
INFO:root:final train perplexity: 4.558033466339111
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.05s/it]
INFO:root:eval mean loss: 22309.03441220238
INFO:root:eval perplexity: 10.063240051269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:54:05<8:51:47, 328.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15347.551775568181
INFO:root:current train perplexity4.528587818145752
INFO:root:current mean train loss 15367.21287172379
INFO:root:current train perplexity4.5518693923950195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.95s/it]
INFO:root:final mean train loss: 15368.988289125504
INFO:root:final train perplexity: 4.553415775299072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it]
INFO:root:eval mean loss: 22309.508277529763
INFO:root:eval perplexity: 10.06373119354248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:59:45<8:51:24, 332.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15188.909458705357
INFO:root:current train perplexity4.4972662925720215
INFO:root:current mean train loss 15280.776869158879
INFO:root:current train perplexity4.531211853027344
INFO:root:current mean train loss 15366.801710635567
INFO:root:current train perplexity4.549928188323975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it]
INFO:root:final mean train loss: 15359.170981130292
INFO:root:final train perplexity: 4.549008369445801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22318.554850260418
INFO:root:eval perplexity: 10.073158264160156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [10:05:36<8:55:00, 337.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15342.447662870763
INFO:root:current train perplexity4.539039611816406
INFO:root:current mean train loss 15376.412533166274
INFO:root:current train perplexity4.542782783508301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.37s/it]
INFO:root:final mean train loss: 15338.97998046875
INFO:root:final train perplexity: 4.539958953857422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it]
INFO:root:eval mean loss: 22323.471144903273
INFO:root:eval perplexity: 10.07828426361084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [10:11:19<8:51:28, 339.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15051.995472301136
INFO:root:current train perplexity4.4889068603515625
INFO:root:current mean train loss 15290.40454321509
INFO:root:current train perplexity4.517252445220947
INFO:root:current mean train loss 15333.270382849527
INFO:root:current train perplexity4.531374931335449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.06s/it]
INFO:root:final mean train loss: 15324.246046496975
INFO:root:final train perplexity: 4.533365726470947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.84s/it]
INFO:root:eval mean loss: 22324.85228329613
INFO:root:eval perplexity: 10.079726219177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [10:17:10<8:51:12, 342.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15278.937065972223
INFO:root:current train perplexity4.518583297729492
INFO:root:current mean train loss 15318.729839675996
INFO:root:current train perplexity4.526876449584961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.25s/it]
INFO:root:final mean train loss: 15316.431309853831
INFO:root:final train perplexity: 4.529872417449951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it]
INFO:root:eval mean loss: 22326.677641369046
INFO:root:eval perplexity: 10.081629753112793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [10:22:50<8:44:31, 342.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15044.898567708333
INFO:root:current train perplexity4.498788356781006
INFO:root:current mean train loss 15276.244004755436
INFO:root:current train perplexity4.51153039932251
INFO:root:current mean train loss 15302.809356831396
INFO:root:current train perplexity4.518046855926514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.93s/it]
INFO:root:final mean train loss: 15298.225589875252
INFO:root:final train perplexity: 4.521745681762695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22341.888834635418
INFO:root:eval perplexity: 10.097514152526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:28:31<8:38:20, 341.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15221.403159981342
INFO:root:current train perplexity4.500621318817139
INFO:root:current mean train loss 15273.977954247754
INFO:root:current train perplexity4.513055324554443


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.10s/it]
INFO:root:final mean train loss: 15282.757060389366
INFO:root:final train perplexity: 4.514852523803711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22336.00720796131
INFO:root:eval perplexity: 10.09136962890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:34:13<8:32:50, 341.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15275.730365953947
INFO:root:current train perplexity4.495797157287598
INFO:root:current mean train loss 15323.207761620273
INFO:root:current train perplexity4.512263298034668
INFO:root:current mean train loss 15283.062361765125
INFO:root:current train perplexity4.510074138641357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.49s/it]
INFO:root:final mean train loss: 15277.364273563508
INFO:root:final train perplexity: 4.512451171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it]
INFO:root:eval mean loss: 22342.897437686013
INFO:root:eval perplexity: 10.098567962646484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:40:01<8:29:47, 343.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15297.351122359154
INFO:root:current train perplexity4.5124192237854
INFO:root:current mean train loss 15280.222170824196
INFO:root:current train perplexity4.509655952453613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.84s/it]
INFO:root:final mean train loss: 15261.371672599545
INFO:root:final train perplexity: 4.505340099334717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:eval mean loss: 22341.09337797619
INFO:root:eval perplexity: 10.096683502197266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:45:52<8:26:58, 345.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15186.113960597826
INFO:root:current train perplexity4.48124885559082
INFO:root:current mean train loss 15237.846282710874
INFO:root:current train perplexity4.499810218811035
INFO:root:current mean train loss 15254.966836287836
INFO:root:current train perplexity4.501395225524902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it]
INFO:root:final mean train loss: 15249.10040873866
INFO:root:final train perplexity: 4.499889850616455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it]
INFO:root:eval mean loss: 22340.614815848214
INFO:root:eval perplexity: 10.096179962158203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:51:35<8:20:26, 345.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15234.377252604167
INFO:root:current train perplexity4.495016098022461
INFO:root:current mean train loss 15256.819564732143
INFO:root:current train perplexity4.500541687011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.47s/it]
INFO:root:final mean train loss: 15241.947269562752
INFO:root:final train perplexity: 4.496715545654297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.34s/it]
INFO:root:eval mean loss: 22332.26746186756
INFO:root:eval perplexity: 10.08746337890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:57:22<8:15:30, 345.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15203.030381944445
INFO:root:current train perplexity4.510511875152588
INFO:root:current mean train loss 15221.330977792815
INFO:root:current train perplexity4.491732597351074
INFO:root:current mean train loss 15234.513628854625
INFO:root:current train perplexity4.487842082977295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.61s/it]
INFO:root:final mean train loss: 15229.288975869456
INFO:root:final train perplexity: 4.491105079650879
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22327.860398065477
INFO:root:eval perplexity: 10.082862854003906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [11:03:09<8:10:02, 345.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15193.691801819621
INFO:root:current train perplexity4.476874351501465
INFO:root:current mean train loss 15224.29748603352
INFO:root:current train perplexity4.478403091430664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.56s/it]
INFO:root:final mean train loss: 15210.707582535282
INFO:root:final train perplexity: 4.482881546020508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:eval mean loss: 22335.040108816964
INFO:root:eval perplexity: 10.09035873413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [11:08:51<8:02:50, 344.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15261.224955897178
INFO:root:current train perplexity4.488642692565918
INFO:root:current mean train loss 15235.370243916985
INFO:root:current train perplexity4.4811320304870605
INFO:root:current mean train loss 15216.103908786527
INFO:root:current train perplexity4.479672908782959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it]
INFO:root:final mean train loss: 15199.139676001763
INFO:root:final train perplexity: 4.477769374847412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.39s/it]
INFO:root:eval mean loss: 22345.000511532737
INFO:root:eval perplexity: 10.100764274597168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [11:14:35<7:56:26, 344.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15201.700442394578
INFO:root:current train perplexity4.467831134796143
INFO:root:current mean train loss 15217.730628842213
INFO:root:current train perplexity4.4747314453125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.36s/it]
INFO:root:final mean train loss: 15190.623247700352
INFO:root:final train perplexity: 4.474009990692139
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:eval mean loss: 22355.58728608631
INFO:root:eval perplexity: 10.111838340759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [11:20:13<7:48:12, 342.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15134.992438616071
INFO:root:current train perplexity4.443166732788086
INFO:root:current mean train loss 15195.12837818287
INFO:root:current train perplexity4.461112976074219
INFO:root:current mean train loss 15190.597668716755
INFO:root:current train perplexity4.469489574432373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.04s/it]
INFO:root:final mean train loss: 15180.149622763356
INFO:root:final train perplexity: 4.469390869140625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.49s/it]
INFO:root:eval mean loss: 22341.65062313988
INFO:root:eval perplexity: 10.09726333618164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [11:25:50<7:40:19, 340.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15127.075172862787
INFO:root:current train perplexity4.461690902709961
INFO:root:current mean train loss 15171.719381893383
INFO:root:current train perplexity4.46236515045166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.29s/it]
INFO:root:final mean train loss: 15168.70259734123
INFO:root:final train perplexity: 4.464346885681152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.67s/it]
INFO:root:eval mean loss: 22351.13648623512
INFO:root:eval perplexity: 10.107181549072266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:31:29<7:33:46, 340.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15111.656700721154
INFO:root:current train perplexity4.437848091125488
INFO:root:current mean train loss 15129.47434942671
INFO:root:current train perplexity4.451414585113525
INFO:root:current mean train loss 15159.633425405334
INFO:root:current train perplexity4.455835819244385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.09s/it]
INFO:root:final mean train loss: 15150.520169165826
INFO:root:final train perplexity: 4.456348419189453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it]
INFO:root:eval mean loss: 22345.224190848214
INFO:root:eval perplexity: 10.101000785827637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:37:15<7:30:21, 342.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15123.082879035028
INFO:root:current train perplexity4.445714950561523
INFO:root:current mean train loss 15136.936232002618
INFO:root:current train perplexity4.443171977996826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it]
INFO:root:final mean train loss: 15144.536979429184
INFO:root:final train perplexity: 4.453719139099121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.53s/it]
INFO:root:eval mean loss: 22344.394484747023
INFO:root:eval perplexity: 10.100131034851074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:42:59<7:25:13, 342.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15114.951081031977
INFO:root:current train perplexity4.461536884307861
INFO:root:current mean train loss 15161.939596536276
INFO:root:current train perplexity4.454761505126953
INFO:root:current mean train loss 15148.06927967464
INFO:root:current train perplexity4.4502081871032715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.61s/it]
INFO:root:final mean train loss: 15136.316595262097
INFO:root:final train perplexity: 4.450109481811523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.52s/it]
INFO:root:eval mean loss: 22350.345145089286
INFO:root:eval perplexity: 10.106352806091309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:48:41<7:19:19, 342.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15101.808172286184
INFO:root:current train perplexity4.440091609954834
INFO:root:current mean train loss 15142.46683193109
INFO:root:current train perplexity4.443090915679932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 292.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 292.00s/it]
INFO:root:final mean train loss: 15125.268621629284
INFO:root:final train perplexity: 4.445262432098389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it]
INFO:root:eval mean loss: 22354.285993303572
INFO:root:eval perplexity: 10.110479354858398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:54:20<7:12:39, 341.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15106.2890625
INFO:root:current train perplexity4.4264302253723145
INFO:root:current mean train loss 15126.286451690052
INFO:root:current train perplexity4.436311721801758
INFO:root:current mean train loss 15127.45415691422
INFO:root:current train perplexity4.440524578094482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.69s/it]
INFO:root:final mean train loss: 15113.698517830142
INFO:root:final train perplexity: 4.440193176269531
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it]
INFO:root:eval mean loss: 22348.626139322918
INFO:root:eval perplexity: 10.1045560836792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:59:52<7:03:18, 338.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15091.826339567551
INFO:root:current train perplexity4.4301300048828125
INFO:root:current mean train loss 15109.141689894786
INFO:root:current train perplexity4.431727886199951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.17s/it]
INFO:root:final mean train loss: 15101.374078566028
INFO:root:final train perplexity: 4.4347991943359375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it]
INFO:root:eval mean loss: 22338.05591982887
INFO:root:eval perplexity: 10.09350872039795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [12:05:25<6:55:27, 336.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15096.911362591913
INFO:root:current train perplexity4.425857067108154
INFO:root:current mean train loss 15084.22485513245
INFO:root:current train perplexity4.42648983001709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.32s/it]
INFO:root:final mean train loss: 15096.23460732737
INFO:root:final train perplexity: 4.432551860809326
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it]
INFO:root:eval mean loss: 22352.702241443454
INFO:root:eval perplexity: 10.108820915222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [12:11:23<6:57:30, 343.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14925.627278645834
INFO:root:current train perplexity4.43898868560791
INFO:root:current mean train loss 15077.15778595267
INFO:root:current train perplexity4.426610469818115
INFO:root:current mean train loss 15077.221063923953
INFO:root:current train perplexity4.420799732208252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.28s/it]
INFO:root:final mean train loss: 15079.214489352318
INFO:root:final train perplexity: 4.425116539001465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it]
INFO:root:eval mean loss: 22349.235212053572
INFO:root:eval perplexity: 10.105191230773926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [12:17:03<6:50:53, 342.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15099.180397727272
INFO:root:current train perplexity4.426583290100098
INFO:root:current mean train loss 15082.753912550403
INFO:root:current train perplexity4.42537260055542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.99s/it]
INFO:root:final mean train loss: 15076.334634104083
INFO:root:final train perplexity: 4.4238600730896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.34s/it]
INFO:root:eval mean loss: 22354.039109002977
INFO:root:eval perplexity: 10.11021900177002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [12:22:51<6:46:54, 343.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15107.680106026786
INFO:root:current train perplexity4.3810858726501465
INFO:root:current mean train loss 15093.969744816004
INFO:root:current train perplexity4.4297380447387695
INFO:root:current mean train loss 15077.020540836353
INFO:root:current train perplexity4.420251846313477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.26s/it]
INFO:root:final mean train loss: 15065.323478452621
INFO:root:final train perplexity: 4.419057369232178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it]
INFO:root:eval mean loss: 22380.532319568454
INFO:root:eval perplexity: 10.13797664642334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [12:28:39<6:42:43, 345.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15098.080011917373
INFO:root:current train perplexity4.42584228515625
INFO:root:current mean train loss 15050.25017197327
INFO:root:current train perplexity4.415909767150879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.39s/it]
INFO:root:final mean train loss: 15058.138695501511
INFO:root:final train perplexity: 4.415927886962891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:eval mean loss: 22354.590494791668
INFO:root:eval perplexity: 10.110796928405762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:34:29<6:38:47, 346.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14973.13290127841
INFO:root:current train perplexity4.435535907745361
INFO:root:current mean train loss 15052.678693341779
INFO:root:current train perplexity4.407200336456299
INFO:root:current mean train loss 15045.622172134183
INFO:root:current train perplexity4.407764434814453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.19s/it]
INFO:root:final mean train loss: 15043.789286951866
INFO:root:final train perplexity: 4.40968132019043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.06s/it]
INFO:root:eval mean loss: 22360.818312872023
INFO:root:eval perplexity: 10.117315292358398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:40:13<6:31:47, 345.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.86951264881
INFO:root:current train perplexity4.392316818237305
INFO:root:current mean train loss 15000.901588861196
INFO:root:current train perplexity4.396216869354248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.73s/it]
INFO:root:final mean train loss: 15032.128792055191
INFO:root:final train perplexity: 4.4046125411987305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it]
INFO:root:eval mean loss: 22359.57068452381
INFO:root:eval perplexity: 10.116007804870605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:45:52<6:23:53, 343.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15010.481575520833
INFO:root:current train perplexity4.4188618659973145
INFO:root:current mean train loss 15040.88187839674
INFO:root:current train perplexity4.408352851867676
INFO:root:current mean train loss 15030.681027434593
INFO:root:current train perplexity4.398429870605469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.35s/it]
INFO:root:final mean train loss: 15022.41656297253
INFO:root:final train perplexity: 4.40039587020874
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it]
INFO:root:eval mean loss: 22375.87976655506
INFO:root:eval perplexity: 10.133095741271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:51:44<6:21:00, 346.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14974.434890974813
INFO:root:current train perplexity4.380688190460205
INFO:root:current mean train loss 15055.092896238772
INFO:root:current train perplexity4.4058074951171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.30s/it]
INFO:root:final mean train loss: 15021.230405745968
INFO:root:final train perplexity: 4.399880886077881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:eval mean loss: 22372.421340215773
INFO:root:eval perplexity: 10.129472732543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:58:55<6:42:40, 371.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15066.057771381578
INFO:root:current train perplexity4.399633884429932
INFO:root:current mean train loss 15038.321165966387
INFO:root:current train perplexity4.402434825897217
INFO:root:current mean train loss 15039.22373091467
INFO:root:current train perplexity4.396322250366211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it]
INFO:root:final mean train loss: 15005.910707535282
INFO:root:final train perplexity: 4.393237113952637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it]
INFO:root:eval mean loss: 22379.2060546875
INFO:root:eval perplexity: 10.136587142944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [13:04:47<6:30:09, 365.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14994.60868727993
INFO:root:current train perplexity4.384675025939941
INFO:root:current mean train loss 15031.783185992324
INFO:root:current train perplexity4.393157005310059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.17s/it]
INFO:root:final mean train loss: 15004.093722435737
INFO:root:final train perplexity: 4.39245080947876
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it]
INFO:root:eval mean loss: 22374.240745907737
INFO:root:eval perplexity: 10.131380081176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [13:10:35<6:18:34, 360.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14897.433763586956
INFO:root:current train perplexity4.358669757843018
INFO:root:current mean train loss 14978.423177083334
INFO:root:current train perplexity4.3833208084106445
INFO:root:current mean train loss 14991.71861862388
INFO:root:current train perplexity4.384994029998779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.60s/it]
INFO:root:final mean train loss: 14984.682254914314
INFO:root:final train perplexity: 4.3840484619140625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it]
INFO:root:eval mean loss: 22381.04124813988
INFO:root:eval perplexity: 10.138513565063477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [13:16:14<6:05:37, 353.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14929.170651041666
INFO:root:current train perplexity4.363529205322266
INFO:root:current mean train loss 14979.069849330357
INFO:root:current train perplexity4.372679233551025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.37s/it]
INFO:root:final mean train loss: 14981.974247101814
INFO:root:final train perplexity: 4.382877349853516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22368.39869326637
INFO:root:eval perplexity: 10.125256538391113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [13:21:49<5:54:03, 348.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14986.84544994213
INFO:root:current train perplexity4.382314205169678
INFO:root:current mean train loss 14952.284940944883
INFO:root:current train perplexity4.372915267944336
INFO:root:current mean train loss 14988.524938911069
INFO:root:current train perplexity4.379337787628174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.09s/it]
INFO:root:final mean train loss: 14976.486521074848
INFO:root:final train perplexity: 4.38050651550293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it]
INFO:root:eval mean loss: 22377.67745535714
INFO:root:eval perplexity: 10.13498306274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [13:27:23<5:44:00, 344.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14923.58964596519
INFO:root:current train perplexity4.371377944946289
INFO:root:current mean train loss 14951.077344841131
INFO:root:current train perplexity4.370083808898926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.45s/it]
INFO:root:final mean train loss: 14960.62533470892
INFO:root:final train perplexity: 4.373658180236816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.16s/it]
INFO:root:eval mean loss: 22379.19015066964
INFO:root:eval perplexity: 10.13656997680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [13:33:04<5:37:20, 343.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14942.33993825605
INFO:root:current train perplexity4.375216960906982
INFO:root:current mean train loss 14970.03441823712
INFO:root:current train perplexity4.376805305480957
INFO:root:current mean train loss 14965.031698119588
INFO:root:current train perplexity4.372954845428467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.14s/it]
INFO:root:final mean train loss: 14954.123787172379
INFO:root:final train perplexity: 4.370854377746582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.54s/it]
INFO:root:eval mean loss: 22405.857026599704
INFO:root:eval perplexity: 10.164583206176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:38:55<5:34:02, 345.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15015.979598079819
INFO:root:current train perplexity4.362386703491211
INFO:root:current mean train loss 14967.248233649249
INFO:root:current train perplexity4.362982273101807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.78s/it]
INFO:root:final mean train loss: 14951.736958165322
INFO:root:final train perplexity: 4.369826316833496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it]
INFO:root:eval mean loss: 22379.60525948661
INFO:root:eval perplexity: 10.137005805969238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:44:44<5:29:10, 346.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14900.399888392858
INFO:root:current train perplexity4.3396806716918945
INFO:root:current mean train loss 14935.977965856482
INFO:root:current train perplexity4.355582237243652
INFO:root:current mean train loss 14948.208793218086
INFO:root:current train perplexity4.367387294769287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.42s/it]
INFO:root:final mean train loss: 14946.084586851059
INFO:root:final train perplexity: 4.3673906326293945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it]
INFO:root:eval mean loss: 22388.768949962796
INFO:root:eval perplexity: 10.146624565124512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:50:28<5:22:36, 345.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14917.568505298132
INFO:root:current train perplexity4.35258674621582
INFO:root:current mean train loss 14958.64119944853
INFO:root:current train perplexity4.365904331207275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.36s/it]
INFO:root:final mean train loss: 14937.34263561618
INFO:root:final train perplexity: 4.363626003265381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.50s/it]
INFO:root:eval mean loss: 22390.656901041668
INFO:root:eval perplexity: 10.148605346679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:56:16<5:17:41, 346.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14941.888822115385
INFO:root:current train perplexity4.353326797485352
INFO:root:current mean train loss 14930.413254552608
INFO:root:current train perplexity4.357870101928711
INFO:root:current mean train loss 14935.751205380491
INFO:root:current train perplexity4.35825252532959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.25s/it]
INFO:root:final mean train loss: 14926.138376543598
INFO:root:final train perplexity: 4.35880708694458
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it]
INFO:root:eval mean loss: 22385.885184151786
INFO:root:eval perplexity: 10.143598556518555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [14:01:51<5:08:37, 342.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14975.200098729396
INFO:root:current train perplexity4.35288143157959
INFO:root:current mean train loss 14929.890389806937
INFO:root:current train perplexity4.3493971824646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it]
INFO:root:final mean train loss: 14923.481630386845
INFO:root:final train perplexity: 4.357664585113525
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.20s/it]
INFO:root:eval mean loss: 22390.384858630954
INFO:root:eval perplexity: 10.148324966430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [14:07:34<5:03:04, 343.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14921.366710574128
INFO:root:current train perplexity4.356784343719482
INFO:root:current mean train loss 14911.077544525786
INFO:root:current train perplexity4.346809387207031
INFO:root:current mean train loss 14929.816285686727
INFO:root:current train perplexity4.353743076324463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.11s/it]
INFO:root:final mean train loss: 14914.77433530746
INFO:root:final train perplexity: 4.353923797607422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 22392.300246465773
INFO:root:eval perplexity: 10.150333404541016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [14:13:12<4:55:56, 341.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14926.975
INFO:root:current train perplexity4.350809574127197
INFO:root:current mean train loss 14909.265865384616
INFO:root:current train perplexity4.348313331604004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it]
INFO:root:final mean train loss: 14910.04400437878
INFO:root:final train perplexity: 4.351893424987793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22388.45007905506
INFO:root:eval perplexity: 10.146289825439453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [14:18:45<4:48:11, 339.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14893.33338181516
INFO:root:current train perplexity4.338743686676025
INFO:root:current mean train loss 14883.353024022108
INFO:root:current train perplexity4.339190483093262
INFO:root:current mean train loss 14913.458169913967
INFO:root:current train perplexity4.348791122436523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.78s/it]
INFO:root:final mean train loss: 14902.499488092239
INFO:root:final train perplexity: 4.348656177520752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.84s/it]
INFO:root:eval mean loss: 22391.521298363095
INFO:root:eval perplexity: 10.149518013000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [14:24:25<4:42:38, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14882.65107125947
INFO:root:current train perplexity4.335939407348633
INFO:root:current mean train loss 14876.473726052136
INFO:root:current train perplexity4.34181547164917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.18s/it]
INFO:root:final mean train loss: 14894.228019468246
INFO:root:final train perplexity: 4.345109462738037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.69s/it]
INFO:root:eval mean loss: 22402.292573474704
INFO:root:eval perplexity: 10.160837173461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [14:30:04<4:37:04, 339.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14878.693167892157
INFO:root:current train perplexity4.341812610626221
INFO:root:current mean train loss 14872.766051841887
INFO:root:current train perplexity4.336373805999756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.12s/it]
INFO:root:final mean train loss: 14886.573663526966
INFO:root:final train perplexity: 4.341830730438232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it]
INFO:root:eval mean loss: 22398.29373604911
INFO:root:eval perplexity: 10.156632423400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [14:35:40<4:30:27, 338.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14915.400716145834
INFO:root:current train perplexity4.333465099334717
INFO:root:current mean train loss 14866.859725804004
INFO:root:current train perplexity4.330079078674316
INFO:root:current mean train loss 14890.434777170567
INFO:root:current train perplexity4.3384504318237305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.29s/it]
INFO:root:final mean train loss: 14879.44400122858
INFO:root:final train perplexity: 4.338778018951416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.85s/it]
INFO:root:eval mean loss: 22408.379813058036
INFO:root:eval perplexity: 10.16723918914795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:41:42<4:30:34, 345.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14839.824591619317
INFO:root:current train perplexity4.316850185394287
INFO:root:current mean train loss 14860.576751512097
INFO:root:current train perplexity4.328012466430664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.18s/it]
INFO:root:final mean train loss: 14873.432955834174
INFO:root:final train perplexity: 4.336205959320068
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it]
INFO:root:eval mean loss: 22402.258882068454
INFO:root:eval perplexity: 10.16080093383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:48:40<4:41:35, 367.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14944.731724330357
INFO:root:current train perplexity4.37350606918335
INFO:root:current mean train loss 14838.463228314837
INFO:root:current train perplexity4.329105854034424
INFO:root:current mean train loss 14880.584894889795
INFO:root:current train perplexity4.333761692047119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.19s/it]
INFO:root:final mean train loss: 14864.681475239415
INFO:root:final train perplexity: 4.332465171813965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:eval mean loss: 22406.69605654762
INFO:root:eval perplexity: 10.165467262268066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:54:42<4:34:13, 365.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14882.673281912077
INFO:root:current train perplexity4.325697898864746
INFO:root:current mean train loss 14848.341956564465
INFO:root:current train perplexity4.32487678527832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.11s/it]
INFO:root:final mean train loss: 14855.142924647178
INFO:root:final train perplexity: 4.328391075134277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.89s/it]
INFO:root:eval mean loss: 22400.941243489582
INFO:root:eval perplexity: 10.159415245056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [15:00:34<4:25:04, 361.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14832.35360440341
INFO:root:current train perplexity4.280685901641846
INFO:root:current mean train loss 14859.903337908221
INFO:root:current train perplexity4.320754051208496
INFO:root:current mean train loss 14865.841570090344
INFO:root:current train perplexity4.326075553894043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.84s/it]
INFO:root:final mean train loss: 14856.199608587449
INFO:root:final train perplexity: 4.328842639923096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.17s/it]
INFO:root:eval mean loss: 22405.750093005954
INFO:root:eval perplexity: 10.164473533630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [15:06:23<4:16:28, 357.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14787.804609995039
INFO:root:current train perplexity4.3162336349487305
INFO:root:current mean train loss 14863.58557802914
INFO:root:current train perplexity4.32918119430542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.84s/it]
INFO:root:final mean train loss: 14853.589674426663
INFO:root:final train perplexity: 4.327728748321533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:eval mean loss: 22409.656575520832
INFO:root:eval perplexity: 10.16858196258545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [15:12:06<4:07:24, 353.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14917.6052734375
INFO:root:current train perplexity4.322982311248779
INFO:root:current mean train loss 14865.50809273098
INFO:root:current train perplexity4.332248210906982
INFO:root:current mean train loss 14858.33534702035
INFO:root:current train perplexity4.3252153396606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.65s/it]
INFO:root:final mean train loss: 14844.433794575352
INFO:root:final train perplexity: 4.323821544647217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22412.35572451637
INFO:root:eval perplexity: 10.171426773071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [15:17:52<3:59:59, 351.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14824.226766557837
INFO:root:current train perplexity4.308603763580322
INFO:root:current mean train loss 14834.593013192365
INFO:root:current train perplexity4.316633224487305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.09s/it]
INFO:root:final mean train loss: 14841.560401178176
INFO:root:final train perplexity: 4.322596549987793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.35s/it]
INFO:root:eval mean loss: 22401.426664806546
INFO:root:eval perplexity: 10.159926414489746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [15:23:31<3:51:32, 347.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14820.438116776315
INFO:root:current train perplexity4.3011651039123535
INFO:root:current mean train loss 14853.277663799894
INFO:root:current train perplexity4.319944858551025
INFO:root:current mean train loss 14835.86078856307
INFO:root:current train perplexity4.320057392120361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.21s/it]
INFO:root:final mean train loss: 14835.738332440777
INFO:root:final train perplexity: 4.320115566253662
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.63s/it]
INFO:root:eval mean loss: 22414.881370907737
INFO:root:eval perplexity: 10.174081802368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [15:29:11<3:44:27, 345.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14837.961501430458
INFO:root:current train perplexity4.305481433868408
INFO:root:current mean train loss 14835.200623629386
INFO:root:current train perplexity4.310764789581299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.14s/it]
INFO:root:final mean train loss: 14830.00160266507
INFO:root:final train perplexity: 4.317671298980713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it]
INFO:root:eval mean loss: 22408.966657366072
INFO:root:eval perplexity: 10.16785717010498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [15:34:43<3:36:10, 341.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14823.628226902174
INFO:root:current train perplexity4.3275675773620605
INFO:root:current mean train loss 14868.64673844004
INFO:root:current train perplexity4.3186235427856445
INFO:root:current mean train loss 14831.303623353419
INFO:root:current train perplexity4.31111478805542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.28s/it]
INFO:root:final mean train loss: 14818.943272744456
INFO:root:final train perplexity: 4.312963962554932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.93s/it]
INFO:root:eval mean loss: 22403.295851934523
INFO:root:eval perplexity: 10.161890983581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [15:40:15<3:28:45, 338.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14801.175338541667
INFO:root:current train perplexity4.320139408111572
INFO:root:current mean train loss 14811.081651785715
INFO:root:current train perplexity4.311111927032471


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.57s/it]
INFO:root:final mean train loss: 14818.012459047379
INFO:root:final train perplexity: 4.3125691413879395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.76s/it]
INFO:root:eval mean loss: 22414.574288504464
INFO:root:eval perplexity: 10.173762321472168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [15:45:59<3:24:06, 340.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14864.069191261575
INFO:root:current train perplexity4.307205677032471
INFO:root:current mean train loss 14859.001122662401
INFO:root:current train perplexity4.327682018280029
INFO:root:current mean train loss 14835.425316629957
INFO:root:current train perplexity4.315449237823486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.66s/it]
INFO:root:final mean train loss: 14817.109977476059
INFO:root:final train perplexity: 4.3121843338012695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.97s/it]
INFO:root:eval mean loss: 22411.93968563988
INFO:root:eval perplexity: 10.170985221862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:52:03<3:22:30, 347.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14844.09240259098
INFO:root:current train perplexity4.316633224487305
INFO:root:current mean train loss 14836.12506001222
INFO:root:current train perplexity4.312772750854492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.89s/it]
INFO:root:final mean train loss: 14810.944836032006
INFO:root:final train perplexity: 4.309563159942627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it]
INFO:root:eval mean loss: 22421.859328497023
INFO:root:eval perplexity: 10.181434631347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:57:43<3:15:29, 344.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14831.01994077621
INFO:root:current train perplexity4.305544376373291
INFO:root:current mean train loss 14830.15091245229
INFO:root:current train perplexity4.304139137268066
INFO:root:current mean train loss 14818.387953192641
INFO:root:current train perplexity4.307610511779785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.81s/it]
INFO:root:final mean train loss: 14804.19091796875
INFO:root:final train perplexity: 4.306694030761719
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.63s/it]
INFO:root:eval mean loss: 22417.95740327381
INFO:root:eval perplexity: 10.177326202392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [16:03:30<3:10:07, 345.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14794.68442912274
INFO:root:current train perplexity4.298341274261475
INFO:root:current mean train loss 14820.379722720287
INFO:root:current train perplexity4.303649425506592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.68s/it]
INFO:root:final mean train loss: 14797.873779296875
INFO:root:final train perplexity: 4.30401086807251
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.33s/it]
INFO:root:eval mean loss: 22414.457868303572
INFO:root:eval perplexity: 10.173638343811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [16:09:11<3:03:35, 344.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14944.601674107143
INFO:root:current train perplexity4.338376045227051
INFO:root:current mean train loss 14793.310814525463
INFO:root:current train perplexity4.297438621520996
INFO:root:current mean train loss 14812.853968583777
INFO:root:current train perplexity4.3043622970581055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.66s/it]
INFO:root:final mean train loss: 14794.937563004032
INFO:root:final train perplexity: 4.302764415740967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.73s/it]
INFO:root:eval mean loss: 22419.721028645832
INFO:root:eval perplexity: 10.179180145263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [16:14:54<2:57:40, 343.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14804.755825700431
INFO:root:current train perplexity4.3080644607543945
INFO:root:current mean train loss 14800.468682110628
INFO:root:current train perplexity4.304203987121582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.04s/it]
INFO:root:final mean train loss: 14799.847313665574
INFO:root:final train perplexity: 4.304848670959473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it]
INFO:root:eval mean loss: 22428.793759300595
INFO:root:eval perplexity: 10.188741683959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [16:20:27<2:50:21, 340.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14714.782627203525
INFO:root:current train perplexity4.26970100402832
INFO:root:current mean train loss 14770.449022032373
INFO:root:current train perplexity4.2994561195373535
INFO:root:current mean train loss 14800.525153634937
INFO:root:current train perplexity4.303000450134277


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.23s/it]
INFO:root:final mean train loss: 14791.081712292087
INFO:root:final train perplexity: 4.30112886428833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.77s/it]
INFO:root:eval mean loss: 22423.93224516369
INFO:root:eval perplexity: 10.18361759185791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [16:26:08<2:44:42, 340.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14831.091303228022
INFO:root:current train perplexity4.317295551300049
INFO:root:current mean train loss 14780.664461305629
INFO:root:current train perplexity4.2972798347473145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it]
INFO:root:final mean train loss: 14782.947415259576
INFO:root:final train perplexity: 4.297679424285889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.92s/it]
INFO:root:eval mean loss: 22419.61788504464
INFO:root:eval perplexity: 10.179070472717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [16:31:37<2:37:23, 337.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14741.004791969477
INFO:root:current train perplexity4.286872386932373
INFO:root:current mean train loss 14793.855175098339
INFO:root:current train perplexity4.296113014221191
INFO:root:current mean train loss 14788.524333686986
INFO:root:current train perplexity4.293907642364502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.65s/it]
INFO:root:final mean train loss: 14775.125027564263
INFO:root:final train perplexity: 4.2943644523620605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it]
INFO:root:eval mean loss: 22428.4033203125
INFO:root:eval perplexity: 10.188333511352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [16:37:06<2:30:38, 334.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14808.064638157895
INFO:root:current train perplexity4.295714855194092
INFO:root:current mean train loss 14796.75181290064
INFO:root:current train perplexity4.295114994049072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.02s/it]
INFO:root:final mean train loss: 14778.561318674396
INFO:root:final train perplexity: 4.295820236206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:eval mean loss: 22427.016694568454
INFO:root:eval perplexity: 10.186866760253906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [16:42:36<2:24:21, 333.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14708.995511968085
INFO:root:current train perplexity4.274590492248535
INFO:root:current mean train loss 14764.376747183249
INFO:root:current train perplexity4.283914089202881
INFO:root:current mean train loss 14786.889442845395
INFO:root:current train perplexity4.294662952423096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.70s/it]
INFO:root:final mean train loss: 14774.989029422883
INFO:root:final train perplexity: 4.29430627822876
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.60s/it]
INFO:root:eval mean loss: 22422.62132626488
INFO:root:eval perplexity: 10.182238578796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [16:48:17<2:19:52, 335.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14766.333619397095
INFO:root:current train perplexity4.286660194396973
INFO:root:current mean train loss 14771.383278698178
INFO:root:current train perplexity4.288111686706543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.22s/it]
INFO:root:final mean train loss: 14768.113072549144
INFO:root:final train perplexity: 4.291395664215088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22421.720679873513
INFO:root:eval perplexity: 10.181286811828613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [16:54:02<2:15:23, 338.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14784.695427389706
INFO:root:current train perplexity4.2793354988098145
INFO:root:current mean train loss 14764.6225553601
INFO:root:current train perplexity4.282773017883301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.66s/it]
INFO:root:final mean train loss: 14766.427017704133
INFO:root:final train perplexity: 4.2906813621521
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it]
INFO:root:eval mean loss: 22429.200753348214
INFO:root:eval perplexity: 10.18917179107666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:59:40<2:09:37, 338.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14796.137044270834
INFO:root:current train perplexity4.274600028991699
INFO:root:current mean train loss 14761.623359754247
INFO:root:current train perplexity4.287928581237793
INFO:root:current mean train loss 14787.847641818042
INFO:root:current train perplexity4.290615558624268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it]
INFO:root:final mean train loss: 14764.980775894657
INFO:root:final train perplexity: 4.290069580078125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.86s/it]
INFO:root:eval mean loss: 22432.252511160714
INFO:root:eval perplexity: 10.192390441894531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [17:05:16<2:03:47, 337.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14825.805894886364
INFO:root:current train perplexity4.282700538635254
INFO:root:current mean train loss 14795.723336693549
INFO:root:current train perplexity4.28953218460083


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.87s/it]
INFO:root:final mean train loss: 14761.868872857864
INFO:root:final train perplexity: 4.288753509521484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.98s/it]
INFO:root:eval mean loss: 22435.19700985863
INFO:root:eval perplexity: 10.195499420166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [17:10:52<1:57:59, 337.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14679.58510044643
INFO:root:current train perplexity4.267914772033691
INFO:root:current mean train loss 14739.433858425818
INFO:root:current train perplexity4.285524368286133
INFO:root:current mean train loss 14767.378726977657
INFO:root:current train perplexity4.286318778991699


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.93s/it]
INFO:root:final mean train loss: 14758.629839497227
INFO:root:final train perplexity: 4.287384033203125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 22428.80296688988
INFO:root:eval perplexity: 10.188754081726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [17:16:24<1:51:55, 335.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14728.782259666314
INFO:root:current train perplexity4.28294563293457
INFO:root:current mean train loss 14739.317745184748
INFO:root:current train perplexity4.277049541473389


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.76s/it]
INFO:root:final mean train loss: 14756.049245526714
INFO:root:final train perplexity: 4.286292552947998
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it]
INFO:root:eval mean loss: 22433.461588541668
INFO:root:eval perplexity: 10.193666458129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [17:21:56<1:45:57, 334.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14848.401988636364
INFO:root:current train perplexity4.26965856552124
INFO:root:current mean train loss 14781.229078688064
INFO:root:current train perplexity4.2883076667785645
INFO:root:current mean train loss 14766.89046301096
INFO:root:current train perplexity4.285726547241211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.87s/it]
INFO:root:final mean train loss: 14750.813791582661
INFO:root:final train perplexity: 4.284079074859619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it]
INFO:root:eval mean loss: 22433.593563988095
INFO:root:eval perplexity: 10.193807601928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [17:27:36<1:40:51, 336.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14703.14130704365
INFO:root:current train perplexity4.274317264556885
INFO:root:current mean train loss 14742.655555023006
INFO:root:current train perplexity4.275972366333008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.57s/it]
INFO:root:final mean train loss: 14749.978113974294
INFO:root:final train perplexity: 4.283726215362549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.78s/it]
INFO:root:eval mean loss: 22431.660202752977
INFO:root:eval perplexity: 10.191766738891602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [17:33:06<1:34:39, 334.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14725.735416666666
INFO:root:current train perplexity4.296501636505127
INFO:root:current mean train loss 14757.220499320652
INFO:root:current train perplexity4.285297393798828
INFO:root:current mean train loss 14752.539643895348
INFO:root:current train perplexity4.280171871185303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.54s/it]
INFO:root:final mean train loss: 14741.15318249118
INFO:root:final train perplexity: 4.279999256134033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.36s/it]
INFO:root:eval mean loss: 22428.157738095237
INFO:root:eval perplexity: 10.18807315826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [17:38:44<1:29:27, 335.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14771.204786613805
INFO:root:current train perplexity4.27236270904541
INFO:root:current mean train loss 14748.864877666541
INFO:root:current train perplexity4.275942325592041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.29s/it]
INFO:root:final mean train loss: 14742.945753528225
INFO:root:final train perplexity: 4.280755996704102
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.73s/it]
INFO:root:eval mean loss: 22432.78955078125
INFO:root:eval perplexity: 10.192956924438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [17:44:23<1:24:06, 336.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14684.58552631579
INFO:root:current train perplexity4.259382724761963
INFO:root:current mean train loss 14739.44605107668
INFO:root:current train perplexity4.281369209289551
INFO:root:current mean train loss 14764.466408925513
INFO:root:current train perplexity4.283478260040283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.06s/it]
INFO:root:final mean train loss: 14741.097672001008
INFO:root:final train perplexity: 4.279976844787598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.44s/it]
INFO:root:eval mean loss: 22430.591331845237
INFO:root:eval perplexity: 10.190638542175293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [17:50:15<1:19:36, 341.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14770.049859705106
INFO:root:current train perplexity4.280291557312012
INFO:root:current mean train loss 14779.775973135966
INFO:root:current train perplexity4.2846503257751465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.79s/it]
INFO:root:final mean train loss: 14745.979460685483
INFO:root:final train perplexity: 4.282036304473877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it]
INFO:root:eval mean loss: 22433.67843191964
INFO:root:eval perplexity: 10.19389533996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [17:55:59<1:14:06, 342.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14786.669497282608
INFO:root:current train perplexity4.264041900634766
INFO:root:current mean train loss 14732.041595210874
INFO:root:current train perplexity4.272927761077881
INFO:root:current mean train loss 14752.474710096692
INFO:root:current train perplexity4.279998779296875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.02s/it]
INFO:root:final mean train loss: 14739.315480878277
INFO:root:final train perplexity: 4.2792229652404785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it]
INFO:root:eval mean loss: 22438.44800967262
INFO:root:eval perplexity: 10.19892692565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [18:01:41<1:08:24, 342.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14758.041536458333
INFO:root:current train perplexity4.281223297119141
INFO:root:current mean train loss 14727.279871651786
INFO:root:current train perplexity4.273131847381592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.88s/it]
INFO:root:final mean train loss: 14732.836209204888
INFO:root:final train perplexity: 4.276490211486816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.07s/it]
INFO:root:eval mean loss: 22433.70682198661
INFO:root:eval perplexity: 10.193926811218262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [18:07:19<1:02:27, 340.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14689.853696469907
INFO:root:current train perplexity4.26499605178833
INFO:root:current mean train loss 14719.42095226378
INFO:root:current train perplexity4.274795055389404
INFO:root:current mean train loss 14737.873094197412
INFO:root:current train perplexity4.275557994842529


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.57s/it]
INFO:root:final mean train loss: 14735.944796654487
INFO:root:final train perplexity: 4.277801513671875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.81s/it]
INFO:root:eval mean loss: 22435.994466145832
INFO:root:eval perplexity: 10.196337699890137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [18:12:53<56:27, 338.73s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14802.869672171677
INFO:root:current train perplexity4.283481121063232
INFO:root:current mean train loss 14744.270900619762
INFO:root:current train perplexity4.276302814483643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it]
INFO:root:final mean train loss: 14735.192686019405
INFO:root:final train perplexity: 4.27748441696167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it]
INFO:root:eval mean loss: 22434.690894717263
INFO:root:eval perplexity: 10.194964408874512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [18:18:22<50:23, 335.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14850.76571950605
INFO:root:current train perplexity4.28438663482666
INFO:root:current mean train loss 14784.699926944179
INFO:root:current train perplexity4.280928134918213
INFO:root:current mean train loss 14739.083544710498
INFO:root:current train perplexity4.275472640991211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.69s/it]
INFO:root:final mean train loss: 14733.06861532888
INFO:root:final train perplexity: 4.27658748626709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it]
INFO:root:eval mean loss: 22435.96484375
INFO:root:eval perplexity: 10.196306228637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [18:24:03<44:58, 337.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14732.148461031626
INFO:root:current train perplexity4.27738094329834
INFO:root:current mean train loss 14730.946230362022
INFO:root:current train perplexity4.274264335632324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 287.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 287.00s/it]
INFO:root:final mean train loss: 14731.919626543598
INFO:root:final train perplexity: 4.276103496551514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it]
INFO:root:eval mean loss: 22437.318312872023
INFO:root:eval perplexity: 10.197735786437988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [18:29:38<39:15, 336.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14734.6947265625
INFO:root:current train perplexity4.294657230377197
INFO:root:current mean train loss 14742.380953414351
INFO:root:current train perplexity4.274941444396973
INFO:root:current mean train loss 14742.900693982712
INFO:root:current train perplexity4.273317337036133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it]
INFO:root:final mean train loss: 14726.726341985886
INFO:root:final train perplexity: 4.273913383483887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22432.65490141369
INFO:root:eval perplexity: 10.192815780639648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [18:35:10<33:32, 335.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14698.911492007903
INFO:root:current train perplexity4.268707752227783
INFO:root:current mean train loss 14724.088438962233
INFO:root:current train perplexity4.271911144256592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.12s/it]
INFO:root:final mean train loss: 14723.695694461945
INFO:root:final train perplexity: 4.272636413574219
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it]
INFO:root:eval mean loss: 22435.39969308036
INFO:root:eval perplexity: 10.195711135864258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [18:40:37<27:43, 332.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14803.330278445514
INFO:root:current train perplexity4.292013645172119
INFO:root:current mean train loss 14733.455359150179
INFO:root:current train perplexity4.273756980895996
INFO:root:current mean train loss 14737.360347476464
INFO:root:current train perplexity4.273656368255615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.46s/it]
INFO:root:final mean train loss: 14725.700439453125
INFO:root:final train perplexity: 4.2734808921813965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.38s/it]
INFO:root:eval mean loss: 22438.224748883928
INFO:root:eval perplexity: 10.198694229125977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [18:46:08<22:09, 332.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14761.215090573489
INFO:root:current train perplexity4.27738094329834
INFO:root:current mean train loss 14750.038801742474
INFO:root:current train perplexity4.2782464027404785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.50s/it]
INFO:root:final mean train loss: 14725.035427954888
INFO:root:final train perplexity: 4.273200511932373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it]
INFO:root:eval mean loss: 22435.33614676339
INFO:root:eval perplexity: 10.195645332336426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [18:51:33<16:30, 330.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14731.392123909884
INFO:root:current train perplexity4.265932083129883
INFO:root:current mean train loss 14727.680213341346
INFO:root:current train perplexity4.264476776123047
INFO:root:current mean train loss 14732.251081050668
INFO:root:current train perplexity4.271373748779297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.77s/it]
INFO:root:final mean train loss: 14719.562110162551
INFO:root:final train perplexity: 4.270895481109619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.30s/it]
INFO:root:eval mean loss: 22435.580240885418
INFO:root:eval perplexity: 10.195902824401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [18:56:57<10:56, 328.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14747.503381990131
INFO:root:current train perplexity4.278958797454834
INFO:root:current mean train loss 14734.738381410256
INFO:root:current train perplexity4.27215051651001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.10s/it]
INFO:root:final mean train loss: 14716.198608398438
INFO:root:final train perplexity: 4.269477367401123
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.99s/it]
INFO:root:eval mean loss: 22436.650483630954
INFO:root:eval perplexity: 10.197031021118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [19:02:22<05:27, 327.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14710.887944647606
INFO:root:current train perplexity4.262630939483643
INFO:root:current mean train loss 14723.21314971301
INFO:root:current train perplexity4.271883010864258
INFO:root:current mean train loss 14734.05235086665
INFO:root:current train perplexity4.27223014831543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.76s/it]
INFO:root:final mean train loss: 14722.255949943295
INFO:root:final train perplexity: 4.272029399871826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22436.738816034227
INFO:root:eval perplexity: 10.197123527526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_0/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [19:07:48<00:00, 326.85s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [19:07:48<00:00, 344.34s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.11s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.11s/it]
INFO:root:eval mean loss: 22436.738816034227
INFO:root:eval perplexity: 10.197123527526855
INFO:root:evalaution complete
INFO:root:save model final: small_window_0/final
