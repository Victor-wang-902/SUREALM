INFO:root:Output: small_allmini_minilm
Traceback (most recent call last):
  File "train_script.py", line 513, in <module>
    raise RuntimeError("Output folder already exists.")
RuntimeError: Output folder already exists.
INFO:root:current mean train loss 16529.455227255236
INFO:root:current train perplexity5.099923133850098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.82s/it]
INFO:root:final mean train loss: 16519.148291803176
INFO:root:final train perplexity: 5.100407123565674
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.95s/it]
INFO:root:eval mean loss: 22272.4892578125
INFO:root:eval perplexity: 10.025247573852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [8:09:41<22:38:48, 554.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16489.429421164772
INFO:root:current train perplexity5.096497535705566
INFO:root:current mean train loss 16535.984797127017
INFO:root:current train perplexity5.1008148193359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.67s/it]
INFO:root:final mean train loss: 16487.28764097152
INFO:root:final train perplexity: 5.084405899047852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.69s/it]
INFO:root:eval mean loss: 22259.43284970238
INFO:root:eval perplexity: 10.011709213256836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:18:52<22:26:39, 553.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16333.39536830357
INFO:root:current train perplexity5.071771144866943
INFO:root:current mean train loss 16450.553373247665
INFO:root:current train perplexity5.068989276885986
INFO:root:current mean train loss 16453.013572803444
INFO:root:current train perplexity5.070106029510498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.73s/it]
INFO:root:final mean train loss: 16451.892144972277
INFO:root:final train perplexity: 5.066686153411865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it]
INFO:root:eval mean loss: 22243.568429129464
INFO:root:eval perplexity: 9.995285987854004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [8:28:16<22:25:34, 556.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16445.842343087923
INFO:root:current train perplexity5.042829513549805
INFO:root:current mean train loss 16389.643001916273
INFO:root:current train perplexity5.037992000579834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.03s/it]
INFO:root:final mean train loss: 16412.80757387223
INFO:root:final train perplexity: 5.047191619873047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.26s/it]
INFO:root:eval mean loss: 22257.48221261161
INFO:root:eval perplexity: 10.009689331054688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [8:37:32<22:15:22, 556.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16528.058327414772
INFO:root:current train perplexity5.074899673461914
INFO:root:current mean train loss 16368.2739037866
INFO:root:current train perplexity5.023576736450195
INFO:root:current mean train loss 16407.739919653435
INFO:root:current train perplexity5.034464359283447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.96s/it]
INFO:root:final mean train loss: 16382.774402249244
INFO:root:final train perplexity: 5.032262325286865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.63s/it]
INFO:root:eval mean loss: 22257.98314267113
INFO:root:eval perplexity: 10.010207176208496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:46:45<22:03:50, 555.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16324.827396453373
INFO:root:current train perplexity4.993621349334717
INFO:root:current mean train loss 16355.126569689417
INFO:root:current train perplexity5.014588356018066


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.59s/it]
INFO:root:final mean train loss: 16353.071631646926
INFO:root:final train perplexity: 5.017541408538818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.96s/it]
INFO:root:eval mean loss: 22243.676199776786
INFO:root:eval perplexity: 9.995397567749023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:55:56<21:51:13, 554.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16317.772265625
INFO:root:current train perplexity5.006466865539551
INFO:root:current mean train loss 16263.652827785327
INFO:root:current train perplexity4.97445821762085
INFO:root:current mean train loss 16300.560019985465
INFO:root:current train perplexity4.993310451507568


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.14s/it]
INFO:root:final mean train loss: 16319.510561050907
INFO:root:final train perplexity: 5.000959873199463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.62s/it]
INFO:root:eval mean loss: 22230.913922991072
INFO:root:eval perplexity: 9.98220157623291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [9:05:08<21:40:49, 553.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16290.208619986008
INFO:root:current train perplexity4.965597629547119
INFO:root:current mean train loss 16293.964411021707
INFO:root:current train perplexity4.987121105194092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.32s/it]
INFO:root:final mean train loss: 16291.461457283267
INFO:root:final train perplexity: 4.987143516540527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it]
INFO:root:eval mean loss: 22218.313406808036
INFO:root:eval perplexity: 9.969194412231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [9:14:29<21:36:22, 555.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16250.824578536185
INFO:root:current train perplexity4.975467205047607
INFO:root:current mean train loss 16235.128717502626
INFO:root:current train perplexity4.965522766113281
INFO:root:current mean train loss 16258.976937071919
INFO:root:current train perplexity4.96843957901001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it]
INFO:root:final mean train loss: 16259.798347719254
INFO:root:final train perplexity: 4.971592426300049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.90s/it]
INFO:root:eval mean loss: 22226.613141741072
INFO:root:eval perplexity: 9.977761268615723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [9:23:52<21:32:36, 557.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16255.788113446302
INFO:root:current train perplexity4.959507942199707
INFO:root:current mean train loss 16261.243626644737
INFO:root:current train perplexity4.961123943328857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.52s/it]
INFO:root:final mean train loss: 16228.579814295616
INFO:root:final train perplexity: 4.956308364868164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.82s/it]
INFO:root:eval mean loss: 22226.06677827381
INFO:root:eval perplexity: 9.977195739746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [9:33:15<21:26:53, 559.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16133.7861328125
INFO:root:current train perplexity4.913352966308594
INFO:root:current mean train loss 16217.455117822663
INFO:root:current train perplexity4.937273025512695
INFO:root:current mean train loss 16218.79584588705
INFO:root:current train perplexity4.946058750152588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.40s/it]
INFO:root:final mean train loss: 16202.719502110634
INFO:root:final train perplexity: 4.9436821937561035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.47s/it]
INFO:root:eval mean loss: 22224.08763485863
INFO:root:eval perplexity: 9.975152015686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [9:42:33<21:16:34, 559.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16168.9684375
INFO:root:current train perplexity4.934057235717773
INFO:root:current mean train loss 16200.113482142857
INFO:root:current train perplexity4.928170204162598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.71s/it]
INFO:root:final mean train loss: 16181.842430853074
INFO:root:final train perplexity: 4.933513164520264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.44s/it]
INFO:root:eval mean loss: 22208.021019345237
INFO:root:eval perplexity: 9.958580017089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:51:53<21:07:16, 559.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16255.537796585648
INFO:root:current train perplexity4.928160667419434
INFO:root:current mean train loss 16132.895284817914
INFO:root:current train perplexity4.90660285949707
INFO:root:current mean train loss 16153.694658590308
INFO:root:current train perplexity4.914827346801758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.60s/it]
INFO:root:final mean train loss: 16147.707283266129
INFO:root:final train perplexity: 4.916930675506592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.02s/it]
INFO:root:eval mean loss: 22222.902483258928
INFO:root:eval perplexity: 9.973930358886719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [10:01:06<20:54:23, 557.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16141.436300929588
INFO:root:current train perplexity4.899629592895508
INFO:root:current mean train loss 16132.239017763617
INFO:root:current train perplexity4.901750087738037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.18s/it]
INFO:root:final mean train loss: 16121.927781628025
INFO:root:final train perplexity: 4.904444217681885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.07s/it]
INFO:root:eval mean loss: 22205.825288318454
INFO:root:eval perplexity: 9.956315040588379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [10:10:14<20:38:45, 554.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16044.992849042339
INFO:root:current train perplexity4.858780860900879
INFO:root:current mean train loss 16105.546584267653
INFO:root:current train perplexity4.883693218231201
INFO:root:current mean train loss 16104.39486522592
INFO:root:current train perplexity4.89042329788208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.03s/it]
INFO:root:final mean train loss: 16094.86669921875
INFO:root:final train perplexity: 4.89137077331543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.54s/it]
INFO:root:eval mean loss: 22203.02908761161
INFO:root:eval perplexity: 9.953435897827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [10:19:38<20:35:25, 557.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16073.444147684488
INFO:root:current train perplexity4.871394634246826
INFO:root:current mean train loss 16083.134477459016
INFO:root:current train perplexity4.874220371246338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.87s/it]
INFO:root:final mean train loss: 16070.489750031502
INFO:root:final train perplexity: 4.879624843597412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it]
INFO:root:eval mean loss: 22199.913481212796
INFO:root:eval perplexity: 9.950228691101074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [10:28:49<20:22:10, 555.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16126.384068080357
INFO:root:current train perplexity4.8859710693359375
INFO:root:current mean train loss 16060.685583043982
INFO:root:current train perplexity4.863451957702637
INFO:root:current mean train loss 16060.59922706117
INFO:root:current train perplexity4.866137504577637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.39s/it]
INFO:root:final mean train loss: 16043.51355374244
INFO:root:final train perplexity: 4.8666582107543945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.11s/it]
INFO:root:eval mean loss: 22199.92117745536
INFO:root:eval perplexity: 9.950235366821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [10:38:00<20:09:36, 554.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16014.753794001437
INFO:root:current train perplexity4.857114791870117
INFO:root:current mean train loss 15998.85676387032
INFO:root:current train perplexity4.851399898529053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.49s/it]
INFO:root:final mean train loss: 16019.686298985634
INFO:root:final train perplexity: 4.8552350997924805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.93s/it]
INFO:root:eval mean loss: 22219.343587239582
INFO:root:eval perplexity: 9.970256805419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [10:47:15<20:01:24, 554.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15903.068960336539
INFO:root:current train perplexity4.837074279785156
INFO:root:current mean train loss 15955.733426540019
INFO:root:current train perplexity4.827150821685791
INFO:root:current mean train loss 15995.353417560147
INFO:root:current train perplexity4.837295055389404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.33s/it]
INFO:root:final mean train loss: 15989.333956810737
INFO:root:final train perplexity: 4.840721607208252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.90s/it]
INFO:root:eval mean loss: 22177.364350818454
INFO:root:eval perplexity: 9.927030563354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [10:56:42<20:00:00, 558.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15943.98391354739
INFO:root:current train perplexity4.815041542053223
INFO:root:current mean train loss 15960.699939667866
INFO:root:current train perplexity4.823484420776367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.63s/it]
INFO:root:final mean train loss: 15969.101023027973
INFO:root:final train perplexity: 4.831070899963379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.72s/it]
INFO:root:eval mean loss: 22195.61007254464
INFO:root:eval perplexity: 9.945795059204102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [11:06:02<19:51:58, 558.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15951.429869186046
INFO:root:current train perplexity4.797844886779785
INFO:root:current mean train loss 15951.28536795236
INFO:root:current train perplexity4.815876483917236
INFO:root:current mean train loss 15960.256124614198
INFO:root:current train perplexity4.8202948570251465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.48s/it]
INFO:root:final mean train loss: 15945.997279013356
INFO:root:final train perplexity: 4.820074558258057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.12s/it]
INFO:root:eval mean loss: 22195.153366815477
INFO:root:eval perplexity: 9.945328712463379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [11:15:30<19:48:14, 561.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15915.017043585527
INFO:root:current train perplexity4.801767826080322
INFO:root:current mean train loss 15924.735606971153
INFO:root:current train perplexity4.807216167449951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.06s/it]
INFO:root:final mean train loss: 15921.436586441532
INFO:root:final train perplexity: 4.808412075042725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.07s/it]
INFO:root:eval mean loss: 22187.967633928572
INFO:root:eval perplexity: 9.937932968139648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [11:24:41<19:32:52, 558.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15894.209670046543
INFO:root:current train perplexity4.784480571746826
INFO:root:current mean train loss 15894.095869207058
INFO:root:current train perplexity4.784018039703369
INFO:root:current mean train loss 15912.45255962171
INFO:root:current train perplexity4.7977776527404785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.46s/it]
INFO:root:final mean train loss: 15899.707141507057
INFO:root:final train perplexity: 4.798117637634277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.53s/it]
INFO:root:eval mean loss: 22181.32507905506
INFO:root:eval perplexity: 9.93110179901123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [11:34:02<19:24:34, 559.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15875.3372494476
INFO:root:current train perplexity4.7802958488464355
INFO:root:current mean train loss 15886.951471223305
INFO:root:current train perplexity4.786179542541504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.17s/it]
INFO:root:final mean train loss: 15876.439208984375
INFO:root:final train perplexity: 4.787118434906006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.89s/it]
INFO:root:eval mean loss: 22186.52306547619
INFO:root:eval perplexity: 9.936447143554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [11:43:15<19:11:59, 557.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15847.681353400736
INFO:root:current train perplexity4.776439189910889
INFO:root:current mean train loss 15869.761938638245
INFO:root:current train perplexity4.774828910827637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.83s/it]
INFO:root:final mean train loss: 15852.565083165322
INFO:root:final train perplexity: 4.775859355926514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it]
INFO:root:eval mean loss: 22198.555013020832
INFO:root:eval perplexity: 9.94882869720459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [11:52:26<18:58:26, 555.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15455.520833333334
INFO:root:current train perplexity4.652970314025879
INFO:root:current mean train loss 15849.95118135619
INFO:root:current train perplexity4.763894081115723
INFO:root:current mean train loss 15841.371983720752
INFO:root:current train perplexity4.765769958496094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:08<00:00, 488.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:08<00:00, 488.26s/it]
INFO:root:final mean train loss: 15840.438996345767
INFO:root:final train perplexity: 4.770150661468506
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it]
INFO:root:eval mean loss: 22188.201822916668
INFO:root:eval perplexity: 9.938175201416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [12:01:53<18:56:11, 558.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15796.747585227273
INFO:root:current train perplexity4.765411376953125
INFO:root:current mean train loss 15815.020217993952
INFO:root:current train perplexity4.7578911781311035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it]
INFO:root:final mean train loss: 15817.45691311744
INFO:root:final train perplexity: 4.759350299835205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.39s/it]
INFO:root:eval mean loss: 22197.180245535714
INFO:root:eval perplexity: 9.947415351867676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [12:10:58<18:38:50, 554.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15738.422572544643
INFO:root:current train perplexity4.718442440032959
INFO:root:current mean train loss 15819.681640625
INFO:root:current train perplexity4.747990608215332
INFO:root:current mean train loss 15821.564736186594
INFO:root:current train perplexity4.753516674041748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.64s/it]
INFO:root:final mean train loss: 15795.594962827621
INFO:root:final train perplexity: 4.749098777770996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.55s/it]
INFO:root:eval mean loss: 22187.08177548363
INFO:root:eval perplexity: 9.937023162841797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [12:20:02<18:23:10, 551.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15729.314668299789
INFO:root:current train perplexity4.719042778015137
INFO:root:current mean train loss 15762.821270636792
INFO:root:current train perplexity4.730026721954346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.51s/it]
INFO:root:final mean train loss: 15773.208492155998
INFO:root:final train perplexity: 4.738624572753906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it]
INFO:root:eval mean loss: 22192.812686011905
INFO:root:eval perplexity: 9.942916870117188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [12:29:15<18:14:51, 552.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15858.644264914772
INFO:root:current train perplexity4.80879020690918
INFO:root:current mean train loss 15783.496815174549
INFO:root:current train perplexity4.727972030639648
INFO:root:current mean train loss 15789.343833308649
INFO:root:current train perplexity4.732358932495117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.42s/it]
INFO:root:final mean train loss: 15757.505032447076
INFO:root:final train perplexity: 4.731289386749268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.79s/it]
INFO:root:eval mean loss: 22179.824148995536
INFO:root:eval perplexity: 9.929558753967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [12:38:25<18:04:25, 551.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15727.06677827381
INFO:root:current train perplexity4.716653823852539
INFO:root:current mean train loss 15725.073823332055
INFO:root:current train perplexity4.721044540405273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.06s/it]
INFO:root:final mean train loss: 15728.223640688004
INFO:root:final train perplexity: 4.717645645141602
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it]
INFO:root:eval mean loss: 22173.804989769345
INFO:root:eval perplexity: 9.92337703704834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [12:47:30<17:51:03, 549.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15731.266341145832
INFO:root:current train perplexity4.6866326332092285
INFO:root:current mean train loss 15698.57023607337
INFO:root:current train perplexity4.706208229064941
INFO:root:current mean train loss 15723.325758539244
INFO:root:current train perplexity4.710467338562012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.96s/it]
INFO:root:final mean train loss: 15710.96398532006
INFO:root:final train perplexity: 4.709620952606201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.68s/it]
INFO:root:eval mean loss: 22188.552734375
INFO:root:eval perplexity: 9.9385347366333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [12:56:39<17:41:55, 549.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15649.039762126866
INFO:root:current train perplexity4.687560558319092
INFO:root:current mean train loss 15701.695751075973
INFO:root:current train perplexity4.700539588928223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.25s/it]
INFO:root:final mean train loss: 15694.915440713206
INFO:root:final train perplexity: 4.702171802520752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.53s/it]
INFO:root:eval mean loss: 22170.745651971727
INFO:root:eval perplexity: 9.920232772827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/85
###################best##################
eval on test: 
INFO:root:eval mean loss: 44.230014102654884
INFO:root:eval perplexity: 10.198779106140137
eval on test multi:
INFO:root:eval mean loss: 44.024289052915094
INFO:root:eval perplexity: 10.089211463928223


 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [13:05:42<17:29:24, 547.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15448.114514802632
INFO:root:current train perplexity4.675573348999023
INFO:root:current mean train loss 15696.184455422794
INFO:root:current train perplexity4.69216251373291
INFO:root:current mean train loss 15688.485467501427
INFO:root:current train perplexity4.692160129547119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.58s/it]
INFO:root:final mean train loss: 15675.548324092742
INFO:root:final train perplexity: 4.693199157714844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.49s/it]
INFO:root:eval mean loss: 22179.97839936756
INFO:root:eval perplexity: 9.929717063903809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [13:14:59<17:25:42, 550.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15602.139387103873
INFO:root:current train perplexity4.683627128601074
INFO:root:current mean train loss 15650.626781798246
INFO:root:current train perplexity4.681068420410156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.15s/it]
INFO:root:final mean train loss: 15658.986320249496
INFO:root:final train perplexity: 4.685538291931152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.36s/it]
INFO:root:eval mean loss: 22195.13643973214
INFO:root:eval perplexity: 9.945306777954102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [13:24:08<17:15:28, 549.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15675.531334918478
INFO:root:current train perplexity4.669322967529297
INFO:root:current mean train loss 15643.895468114837
INFO:root:current train perplexity4.673093318939209
INFO:root:current mean train loss 15647.826995165358
INFO:root:current train perplexity4.675266265869141


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.91s/it]
INFO:root:final mean train loss: 15636.685377551663
INFO:root:final train perplexity: 4.675243377685547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 22187.091610863095
INFO:root:eval perplexity: 9.937030792236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [13:33:22<17:08:57, 551.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15625.004505208333
INFO:root:current train perplexity4.656976699829102
INFO:root:current mean train loss 15616.905876116072
INFO:root:current train perplexity4.6638712882995605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.68s/it]
INFO:root:final mean train loss: 15623.097514490928
INFO:root:final train perplexity: 4.668981552124023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.48s/it]
INFO:root:eval mean loss: 22180.326195126487
INFO:root:eval perplexity: 9.930074691772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [13:42:29<16:57:22, 549.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15578.491825810184
INFO:root:current train perplexity4.650970935821533
INFO:root:current mean train loss 15558.431556040847
INFO:root:current train perplexity4.639980316162109
INFO:root:current mean train loss 15599.50915903772
INFO:root:current train perplexity4.654438018798828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.09s/it]
INFO:root:final mean train loss: 15600.100266979587
INFO:root:final train perplexity: 4.658403396606445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.08s/it]
INFO:root:eval mean loss: 22186.645159040178
INFO:root:eval perplexity: 9.93657112121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [13:51:35<16:45:57, 548.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15639.848336135285
INFO:root:current train perplexity4.6522626876831055
INFO:root:current mean train loss 15582.985935317738
INFO:root:current train perplexity4.647254467010498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.33s/it]
INFO:root:final mean train loss: 15584.61839638987
INFO:root:final train perplexity: 4.651294708251953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it]
INFO:root:eval mean loss: 22175.425153459822
INFO:root:eval perplexity: 9.925040245056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [14:00:40<16:34:40, 547.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15578.840473790322
INFO:root:current train perplexity4.64859676361084
INFO:root:current mean train loss 15561.12929389313
INFO:root:current train perplexity4.644075393676758
INFO:root:current mean train loss 15576.481090198864
INFO:root:current train perplexity4.644260406494141


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.62s/it]
INFO:root:final mean train loss: 15567.77935594128
INFO:root:final train perplexity: 4.643576145172119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.73s/it]
INFO:root:eval mean loss: 22183.867001488095
INFO:root:eval perplexity: 9.933713912963867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [14:09:49<16:26:37, 548.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15583.288956607681
INFO:root:current train perplexity4.64367151260376
INFO:root:current mean train loss 15560.448402279713
INFO:root:current train perplexity4.634762287139893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.12s/it]
INFO:root:final mean train loss: 15549.84859343498
INFO:root:final train perplexity: 4.635371208190918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.36s/it]
INFO:root:eval mean loss: 22187.421293712796
INFO:root:eval perplexity: 9.937369346618652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [14:19:08<16:23:04, 551.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15518.561690848213
INFO:root:current train perplexity4.596200466156006
INFO:root:current mean train loss 15523.789185474538
INFO:root:current train perplexity4.623941898345947
INFO:root:current mean train loss 15546.496754488033
INFO:root:current train perplexity4.6282830238342285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.70s/it]
INFO:root:final mean train loss: 15537.205562468498
INFO:root:final train perplexity: 4.629594326019287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.53s/it]
INFO:root:eval mean loss: 22206.727701822918
INFO:root:eval perplexity: 9.957247734069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [14:28:21<16:14:47, 551.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15537.178632363506
INFO:root:current train perplexity4.609276294708252
INFO:root:current mean train loss 15531.841029202875
INFO:root:current train perplexity4.6198859214782715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.68s/it]
INFO:root:final mean train loss: 15510.278072234123
INFO:root:final train perplexity: 4.617315292358398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.37s/it]
INFO:root:eval mean loss: 22182.697079613095
INFO:root:eval perplexity: 9.932513236999512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [14:37:30<16:04:16, 551.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15462.368865184295
INFO:root:current train perplexity4.575588226318359
INFO:root:current mean train loss 15506.616885397932
INFO:root:current train perplexity4.598721504211426
INFO:root:current mean train loss 15523.44264840481
INFO:root:current train perplexity4.613245964050293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.67s/it]
INFO:root:final mean train loss: 15501.348069713962
INFO:root:final train perplexity: 4.613249778747559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.60s/it]
INFO:root:eval mean loss: 22196.773949032737
INFO:root:eval perplexity: 9.946995735168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [14:46:44<15:56:46, 551.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15529.965541294643
INFO:root:current train perplexity4.612246513366699
INFO:root:current mean train loss 15487.501825302683
INFO:root:current train perplexity4.6066365242004395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.42s/it]
INFO:root:final mean train loss: 15487.516570060483
INFO:root:final train perplexity: 4.606960773468018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.59s/it]
INFO:root:eval mean loss: 22189.861746651786
INFO:root:eval perplexity: 9.939881324768066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [14:55:57<15:48:02, 552.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15462.008607376454
INFO:root:current train perplexity4.603357315063477
INFO:root:current mean train loss 15486.618683074737
INFO:root:current train perplexity4.604390621185303
INFO:root:current mean train loss 15481.000361689816
INFO:root:current train perplexity4.600245475769043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.54s/it]
INFO:root:final mean train loss: 15472.15888829385
INFO:root:final train perplexity: 4.599987506866455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it]
INFO:root:eval mean loss: 22195.981026785714
INFO:root:eval perplexity: 9.94617748260498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [15:05:10<15:39:17, 552.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15496.682144325658
INFO:root:current train perplexity4.590185642242432
INFO:root:current mean train loss 15465.101231971154
INFO:root:current train perplexity4.590007781982422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:10<00:00, 490.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:10<00:00, 490.21s/it]
INFO:root:final mean train loss: 15453.797264837449
INFO:root:final train perplexity: 4.591663837432861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it]
INFO:root:eval mean loss: 22196.726585751487
INFO:root:eval perplexity: 9.946945190429688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [15:14:41<15:39:05, 557.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15375.703083444148
INFO:root:current train perplexity4.541950702667236
INFO:root:current mean train loss 15435.079347363946
INFO:root:current train perplexity4.574496746063232
INFO:root:current mean train loss 15451.683751897774
INFO:root:current train perplexity4.585192680358887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.19s/it]
INFO:root:final mean train loss: 15440.640632875504
INFO:root:final train perplexity: 4.585709571838379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.22s/it]
INFO:root:eval mean loss: 22204.866396949405
INFO:root:eval perplexity: 9.955327987670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [15:23:53<15:27:01, 556.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15381.38629458649
INFO:root:current train perplexity4.5633931159973145
INFO:root:current mean train loss 15445.733368993404
INFO:root:current train perplexity4.579023838043213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.40s/it]
INFO:root:final mean train loss: 15426.655946793095
INFO:root:final train perplexity: 4.5793890953063965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it]
INFO:root:eval mean loss: 22190.828264508928
INFO:root:eval perplexity: 9.940878868103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [15:33:06<15:16:15, 555.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15447.48104319853
INFO:root:current train perplexity4.560642242431641
INFO:root:current mean train loss 15434.070099079056
INFO:root:current train perplexity4.572782516479492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.17s/it]
INFO:root:final mean train loss: 15411.596813571068
INFO:root:final train perplexity: 4.572591304779053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.08s/it]
INFO:root:eval mean loss: 22180.560221354168
INFO:root:eval perplexity: 9.930318832397461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [15:42:18<15:05:02, 554.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15479.026692708334
INFO:root:current train perplexity4.510360240936279
INFO:root:current mean train loss 15431.496491959952
INFO:root:current train perplexity4.560092926025391
INFO:root:current mean train loss 15395.74781596367
INFO:root:current train perplexity4.560486316680908


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.08s/it]
INFO:root:final mean train loss: 15396.968163274949
INFO:root:final train perplexity: 4.565999984741211
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it]
INFO:root:eval mean loss: 22180.010184151786
INFO:root:eval perplexity: 9.929752349853516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [15:51:28<14:53:48, 552.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15344.7625
INFO:root:current train perplexity4.527345657348633
INFO:root:current mean train loss 15368.753622731854
INFO:root:current train perplexity4.5525617599487305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it]
INFO:root:final mean train loss: 15378.059208039314
INFO:root:final train perplexity: 4.557491302490234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it]
INFO:root:eval mean loss: 22189.08279854911
INFO:root:eval perplexity: 9.939080238342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [16:00:33<14:41:00, 550.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15212.34193638393
INFO:root:current train perplexity4.507709503173828
INFO:root:current mean train loss 15285.425297532127
INFO:root:current train perplexity4.533294677734375
INFO:root:current mean train loss 15376.291954445955
INFO:root:current train perplexity4.554187297821045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.16s/it]
INFO:root:final mean train loss: 15366.200494581653
INFO:root:final train perplexity: 4.552164077758789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.88s/it]
INFO:root:eval mean loss: 22204.63155691964
INFO:root:eval perplexity: 9.955085754394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [16:09:45<14:32:25, 551.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15368.87294756356
INFO:root:current train perplexity4.550881385803223
INFO:root:current mean train loss 15393.478896422956
INFO:root:current train perplexity4.55042028427124


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 477.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.00s/it]
INFO:root:final mean train loss: 15352.247751543598
INFO:root:final train perplexity: 4.545903205871582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.33s/it]
INFO:root:eval mean loss: 22187.093703497023
INFO:root:eval perplexity: 9.937032699584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [16:19:03<14:26:39, 553.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15093.727805397728
INFO:root:current train perplexity4.507635593414307
INFO:root:current mean train loss 15315.152774845157
INFO:root:current train perplexity4.52829122543335
INFO:root:current mean train loss 15352.704420912321
INFO:root:current train perplexity4.540061950683594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it]
INFO:root:final mean train loss: 15342.96472561744
INFO:root:final train perplexity: 4.541743278503418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.63s/it]
INFO:root:eval mean loss: 22205.741861979168
INFO:root:eval perplexity: 9.956230163574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [16:28:24<14:20:56, 555.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15286.765935019841
INFO:root:current train perplexity4.52207612991333
INFO:root:current mean train loss 15337.18036450345
INFO:root:current train perplexity4.535116672515869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.14s/it]
INFO:root:final mean train loss: 15329.001004126763
INFO:root:final train perplexity: 4.535491943359375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it]
INFO:root:eval mean loss: 22208.252418154763
INFO:root:eval perplexity: 9.958817481994629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [16:37:41<14:12:27, 555.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15055.9912109375
INFO:root:current train perplexity4.503779411315918
INFO:root:current mean train loss 15291.201783288043
INFO:root:current train perplexity4.518190383911133
INFO:root:current mean train loss 15320.022492732558
INFO:root:current train perplexity4.525718688964844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.51s/it]
INFO:root:final mean train loss: 15315.65517893145
INFO:root:final train perplexity: 4.529526233673096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.67s/it]
INFO:root:eval mean loss: 22212.060965401786
INFO:root:eval perplexity: 9.962745666503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [16:47:00<14:04:35, 556.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15239.091388759329
INFO:root:current train perplexity4.508495330810547
INFO:root:current mean train loss 15302.442125514595
INFO:root:current train perplexity4.525746822357178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.23s/it]
INFO:root:final mean train loss: 15303.633659116684
INFO:root:final train perplexity: 4.524158477783203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 79.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 79.00s/it]
INFO:root:eval mean loss: 22216.291666666668
INFO:root:eval perplexity: 9.967107772827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [16:56:31<14:01:45, 561.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15277.701223273027
INFO:root:current train perplexity4.496669769287109
INFO:root:current mean train loss 15339.575712316177
INFO:root:current train perplexity4.519533157348633
INFO:root:current mean train loss 15296.421767979453
INFO:root:current train perplexity4.516015529632568


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.22s/it]
INFO:root:final mean train loss: 15288.072399508568
INFO:root:final train perplexity: 4.5172200202941895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it]
INFO:root:eval mean loss: 22212.65636625744
INFO:root:eval perplexity: 9.963357925415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [17:05:53<13:52:27, 561.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15302.328647667253
INFO:root:current train perplexity4.514632225036621
INFO:root:current mean train loss 15285.543808251097
INFO:root:current train perplexity4.512021541595459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.62s/it]
INFO:root:final mean train loss: 15272.880205708165
INFO:root:final train perplexity: 4.510456085205078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it]
INFO:root:eval mean loss: 22221.163248697918
INFO:root:eval perplexity: 9.972134590148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [17:15:11<13:42:06, 560.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15197.428541100544
INFO:root:current train perplexity4.486259937286377
INFO:root:current mean train loss 15248.441644435976
INFO:root:current train perplexity4.504519462585449
INFO:root:current mean train loss 15266.497854190022
INFO:root:current train perplexity4.506516933441162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it]
INFO:root:final mean train loss: 15261.389270413307
INFO:root:final train perplexity: 4.505346298217773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it]
INFO:root:eval mean loss: 22221.884091331845
INFO:root:eval perplexity: 9.972878456115723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [17:24:17<13:26:03, 555.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15233.220651041667
INFO:root:current train perplexity4.494503974914551
INFO:root:current mean train loss 15260.708978794642
INFO:root:current train perplexity4.502267360687256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.93s/it]
INFO:root:final mean train loss: 15245.700734784527
INFO:root:final train perplexity: 4.498380184173584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it]
INFO:root:eval mean loss: 22225.65157645089
INFO:root:eval perplexity: 9.976767539978027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [17:33:11<13:07:24, 549.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15222.794270833334
INFO:root:current train perplexity4.519352912902832
INFO:root:current mean train loss 15228.92155973179
INFO:root:current train perplexity4.49509859085083
INFO:root:current mean train loss 15246.849032901982
INFO:root:current train perplexity4.493300914764404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.47s/it]
INFO:root:final mean train loss: 15241.023461126511
INFO:root:final train perplexity: 4.4963059425354
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.04s/it]
INFO:root:eval mean loss: 22214.262369791668
INFO:root:eval perplexity: 9.965014457702637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [17:42:23<12:59:25, 550.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15200.429143591773
INFO:root:current train perplexity4.479849815368652
INFO:root:current mean train loss 15239.88679512919
INFO:root:current train perplexity4.485282897949219


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.22s/it]
INFO:root:final mean train loss: 15226.186007591987
INFO:root:final train perplexity: 4.489730358123779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.16s/it]
INFO:root:eval mean loss: 22230.715192522322
INFO:root:eval perplexity: 9.981996536254883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [17:51:31<12:49:24, 549.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15262.298103578629
INFO:root:current train perplexity4.489116191864014
INFO:root:current mean train loss 15247.506306655534
INFO:root:current train perplexity4.4864888191223145
INFO:root:current mean train loss 15232.113162878788
INFO:root:current train perplexity4.486746788024902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.85s/it]
INFO:root:final mean train loss: 15213.437586630544
INFO:root:final train perplexity: 4.484088897705078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.67s/it]
INFO:root:eval mean loss: 22232.02208891369
INFO:root:eval perplexity: 9.983345985412598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [18:00:38<12:39:17, 548.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15212.787885918675
INFO:root:current train perplexity4.47271203994751
INFO:root:current mean train loss 15229.720062756147
INFO:root:current train perplexity4.480017185211182


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.39s/it]
INFO:root:final mean train loss: 15201.10748094128
INFO:root:final train perplexity: 4.478639125823975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.56s/it]
INFO:root:eval mean loss: 22233.670340401786
INFO:root:eval perplexity: 9.985053062438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [18:09:50<12:31:10, 549.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15153.03989955357
INFO:root:current train perplexity4.451076030731201
INFO:root:current mean train loss 15208.343178530093
INFO:root:current train perplexity4.466917514801025
INFO:root:current mean train loss 15204.628997672873
INFO:root:current train perplexity4.475675106048584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.21s/it]
INFO:root:final mean train loss: 15193.390711630544
INFO:root:final train perplexity: 4.475231170654297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.81s/it]
INFO:root:eval mean loss: 22242.014601934523
INFO:root:eval perplexity: 9.993677139282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [18:19:01<12:22:31, 550.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15134.483723958334
INFO:root:current train perplexity4.464959621429443
INFO:root:current mean train loss 15186.349917488302
INFO:root:current train perplexity4.468806266784668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.55s/it]
INFO:root:final mean train loss: 15179.251811365928
INFO:root:final train perplexity: 4.468994617462158
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it]
INFO:root:eval mean loss: 22235.163643973214
INFO:root:eval perplexity: 9.986593246459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [18:28:15<12:14:59, 551.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15132.23517628205
INFO:root:current train perplexity4.44686222076416
INFO:root:current mean train loss 15150.242082115557
INFO:root:current train perplexity4.460548400878906
INFO:root:current mean train loss 15179.713797724895
INFO:root:current train perplexity4.464664936065674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.06s/it]
INFO:root:final mean train loss: 15170.149658203125
INFO:root:final train perplexity: 4.464983940124512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.67s/it]
INFO:root:eval mean loss: 22240.529227120536
INFO:root:eval perplexity: 9.992142677307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [18:37:24<12:05:04, 550.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15132.61019059066
INFO:root:current train perplexity4.449896335601807
INFO:root:current mean train loss 15156.229727380563
INFO:root:current train perplexity4.451624870300293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.12s/it]
INFO:root:final mean train loss: 15159.820753528225
INFO:root:final train perplexity: 4.460438251495361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.57s/it]
INFO:root:eval mean loss: 22233.599190848214
INFO:root:eval perplexity: 9.984976768493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [18:46:21<11:50:27, 546.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15119.064384992733
INFO:root:current train perplexity4.463353157043457
INFO:root:current mean train loss 15167.63107107736
INFO:root:current train perplexity4.4572601318359375
INFO:root:current mean train loss 15155.836005819187
INFO:root:current train perplexity4.453615665435791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.96s/it]
INFO:root:final mean train loss: 15144.013285975303
INFO:root:final train perplexity: 4.453488826751709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it]
INFO:root:eval mean loss: 22246.193498883928
INFO:root:eval perplexity: 9.998000144958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [18:55:34<11:43:56, 548.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15112.27580180921
INFO:root:current train perplexity4.444681644439697
INFO:root:current mean train loss 15152.888726963141
INFO:root:current train perplexity4.4476542472839355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it]
INFO:root:final mean train loss: 15136.876252205142
INFO:root:final train perplexity: 4.450355529785156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it]
INFO:root:eval mean loss: 22252.148995535714
INFO:root:eval perplexity: 10.004166603088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [19:04:34<11:31:35, 546.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15117.499501329787
INFO:root:current train perplexity4.431319236755371
INFO:root:current mean train loss 15138.662321960033
INFO:root:current train perplexity4.441721439361572
INFO:root:current mean train loss 15138.377202207743
INFO:root:current train perplexity4.44530725479126


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.10s/it]
INFO:root:final mean train loss: 15124.66654328377
INFO:root:final train perplexity: 4.444998741149902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.15s/it]
INFO:root:eval mean loss: 22244.465727306546
INFO:root:eval perplexity: 9.99621295928955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [19:13:38<11:21:47, 545.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15107.64185803346
INFO:root:current train perplexity4.437044143676758
INFO:root:current mean train loss 15123.579759147298
INFO:root:current train perplexity4.438037872314453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.33s/it]
INFO:root:final mean train loss: 15115.953829857612
INFO:root:final train perplexity: 4.44118070602417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.33s/it]
INFO:root:eval mean loss: 22244.65506417411
INFO:root:eval perplexity: 9.996408462524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [19:22:43<11:12:27, 545.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15102.317746629902
INFO:root:current train perplexity4.4282145500183105
INFO:root:current mean train loss 15086.131635451158
INFO:root:current train perplexity4.427321434020996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.78s/it]
INFO:root:final mean train loss: 15102.456897366432
INFO:root:final train perplexity: 4.435272216796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.67s/it]
INFO:root:eval mean loss: 22241.787062872023
INFO:root:eval perplexity: 9.993443489074707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [19:31:42<11:01:12, 543.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14945.784830729166
INFO:root:current train perplexity4.447932720184326
INFO:root:current mean train loss 15094.990490367112
INFO:root:current train perplexity4.434406280517578
INFO:root:current mean train loss 15089.793007235221
INFO:root:current train perplexity4.426281929016113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.69s/it]
INFO:root:final mean train loss: 15092.241195186492
INFO:root:final train perplexity: 4.430805683135986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.65s/it]
INFO:root:eval mean loss: 22248.32849702381
INFO:root:eval perplexity: 10.00020980834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [19:40:33<10:47:25, 539.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15120.128675426136
INFO:root:current train perplexity4.435728073120117
INFO:root:current mean train loss 15098.0373046875
INFO:root:current train perplexity4.432047367095947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.05s/it]
INFO:root:final mean train loss: 15087.45536951865
INFO:root:final train perplexity: 4.428714752197266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.17s/it]
INFO:root:eval mean loss: 22248.398577008928
INFO:root:eval perplexity: 10.000284194946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [19:49:40<10:41:13, 541.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15125.669363839286
INFO:root:current train perplexity4.388799667358398
INFO:root:current mean train loss 15098.357284973716
INFO:root:current train perplexity4.431654930114746
INFO:root:current mean train loss 15086.426922931763
INFO:root:current train perplexity4.424352169036865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.44s/it]
INFO:root:final mean train loss: 15074.860690209174
INFO:root:final train perplexity: 4.423216342926025
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.99s/it]
INFO:root:eval mean loss: 22273.855771019345
INFO:root:eval perplexity: 10.026667594909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [19:58:49<10:34:32, 543.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15106.072116657839
INFO:root:current train perplexity4.4293293952941895
INFO:root:current mean train loss 15058.493071933963
INFO:root:current train perplexity4.419503211975098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.08s/it]
INFO:root:final mean train loss: 15065.442099294354
INFO:root:final train perplexity: 4.419109344482422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it]
INFO:root:eval mean loss: 22253.610444568454
INFO:root:eval perplexity: 10.005681037902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [20:08:04<10:29:18, 547.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14976.2529296875
INFO:root:current train perplexity4.436912536621094
INFO:root:current mean train loss 15060.212855433558
INFO:root:current train perplexity4.4104743003845215
INFO:root:current mean train loss 15058.464760441351
INFO:root:current train perplexity4.413349151611328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.74s/it]
INFO:root:final mean train loss: 15055.811287172379
INFO:root:final train perplexity: 4.414914608001709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it]
INFO:root:eval mean loss: 22251.308500744046
INFO:root:eval perplexity: 10.00329303741455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [20:17:12<10:20:30, 547.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14959.814995659723
INFO:root:current train perplexity4.403624057769775
INFO:root:current mean train loss 15013.924822661043
INFO:root:current train perplexity4.401871204376221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.66s/it]
INFO:root:final mean train loss: 15048.068347561744
INFO:root:final train perplexity: 4.411543369293213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.82s/it]
INFO:root:eval mean loss: 22267.55684988839
INFO:root:eval perplexity: 10.02013111114502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [20:26:14<10:09:46, 546.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14998.293880208334
INFO:root:current train perplexity4.413534164428711
INFO:root:current mean train loss 15054.492849864131
INFO:root:current train perplexity4.414275646209717
INFO:root:current mean train loss 15050.116338117732
INFO:root:current train perplexity4.406862258911133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.88s/it]
INFO:root:final mean train loss: 15042.521614320816
INFO:root:final train perplexity: 4.409130573272705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it]
INFO:root:eval mean loss: 22265.71121651786
INFO:root:eval perplexity: 10.018218040466309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [20:35:10<9:57:03, 542.79s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14996.03119169776
INFO:root:current train perplexity4.390030384063721
INFO:root:current mean train loss 15075.277536723428
INFO:root:current train perplexity4.414575576782227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it]
INFO:root:final mean train loss: 15034.554506363407
INFO:root:final train perplexity: 4.405666351318359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.81s/it]
INFO:root:eval mean loss: 22262.99783761161
INFO:root:eval perplexity: 10.01540470123291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [20:44:21<9:50:53, 545.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15077.876284950658
INFO:root:current train perplexity4.404750347137451
INFO:root:current mean train loss 15058.453650210084
INFO:root:current train perplexity4.4111785888671875
INFO:root:current mean train loss 15060.062161101598
INFO:root:current train perplexity4.4053521156311035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.38s/it]
INFO:root:final mean train loss: 15025.872322328629
INFO:root:final train perplexity: 4.401895046234131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it]
INFO:root:eval mean loss: 22277.977120535714
INFO:root:eval perplexity: 10.0309419631958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [20:53:27<9:41:48, 545.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15005.015281139964
INFO:root:current train perplexity4.389175891876221
INFO:root:current mean train loss 15044.389020239401
INFO:root:current train perplexity4.3986124992370605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.55s/it]
INFO:root:final mean train loss: 15018.212725239415
INFO:root:final train perplexity: 4.398571968078613
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.65s/it]
INFO:root:eval mean loss: 22267.677083333332
INFO:root:eval perplexity: 10.020255088806152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [21:02:35<9:33:30, 546.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14887.37746263587
INFO:root:current train perplexity4.35434103012085
INFO:root:current mean train loss 14999.143022738821
INFO:root:current train perplexity4.3922905921936035
INFO:root:current mean train loss 15009.94354330157
INFO:root:current train perplexity4.392880916595459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.56s/it]
INFO:root:final mean train loss: 15006.345163652973
INFO:root:final train perplexity: 4.393425941467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.63s/it]
INFO:root:eval mean loss: 22261.634207589286
INFO:root:eval perplexity: 10.013991355895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [21:11:42<9:24:55, 546.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14947.415611979166
INFO:root:current train perplexity4.371393203735352
INFO:root:current mean train loss 14994.855619419643
INFO:root:current train perplexity4.379482746124268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.22s/it]
INFO:root:final mean train loss: 14996.412066059727
INFO:root:final train perplexity: 4.389123916625977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.70s/it]
INFO:root:eval mean loss: 22258.468703497023
INFO:root:eval perplexity: 10.010708808898926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [21:20:58<9:18:33, 549.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14996.881872106482
INFO:root:current train perplexity4.386653423309326
INFO:root:current mean train loss 14959.94700418307
INFO:root:current train perplexity4.376223087310791
INFO:root:current mean train loss 15000.682445106002
INFO:root:current train perplexity4.384586811065674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.24s/it]
INFO:root:final mean train loss: 14989.772531817036
INFO:root:final train perplexity: 4.386250019073486
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.23s/it]
INFO:root:eval mean loss: 22270.29464285714
INFO:root:eval perplexity: 10.022969245910645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [21:30:05<9:08:45, 548.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.950158227848
INFO:root:current train perplexity4.375855922698975
INFO:root:current mean train loss 14965.561468880936
INFO:root:current train perplexity4.376331806182861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.24s/it]
INFO:root:final mean train loss: 14977.128803868447
INFO:root:final train perplexity: 4.380784034729004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.78s/it]
INFO:root:eval mean loss: 22270.58251953125
INFO:root:eval perplexity: 10.023268699645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [21:39:17<9:00:30, 549.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14956.487619707661
INFO:root:current train perplexity4.3813347816467285
INFO:root:current mean train loss 14987.043460758588
INFO:root:current train perplexity4.384153842926025
INFO:root:current mean train loss 14986.883269074675
INFO:root:current train perplexity4.382385730743408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.51s/it]
INFO:root:final mean train loss: 14974.89007765247
INFO:root:final train perplexity: 4.379817008972168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it]
INFO:root:eval mean loss: 22282.418154761905
INFO:root:eval perplexity: 10.035552024841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [21:48:34<8:53:16, 551.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15034.226409544428
INFO:root:current train perplexity4.370203495025635
INFO:root:current mean train loss 14991.028613814891
INFO:root:current train perplexity4.37320613861084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.68s/it]
INFO:root:final mean train loss: 14969.58525233115
INFO:root:final train perplexity: 4.377525329589844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.76s/it]
INFO:root:eval mean loss: 22269.426781063987
INFO:root:eval perplexity: 10.022068977355957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [21:57:56<8:47:05, 554.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14919.280106026787
INFO:root:current train perplexity4.347758769989014
INFO:root:current mean train loss 14951.206864872685
INFO:root:current train perplexity4.36212158203125
INFO:root:current mean train loss 14960.902435172873
INFO:root:current train perplexity4.37285852432251


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.85s/it]
INFO:root:final mean train loss: 14959.301675119708
INFO:root:final train perplexity: 4.3730878829956055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it]
INFO:root:eval mean loss: 22275.988932291668
INFO:root:eval perplexity: 10.028878211975098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [22:07:22<8:41:01, 558.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14939.707929238506
INFO:root:current train perplexity4.362098217010498
INFO:root:current mean train loss 14972.548869903076
INFO:root:current train perplexity4.371890544891357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.89s/it]
INFO:root:final mean train loss: 14953.0896468624
INFO:root:final train perplexity: 4.37040901184082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.95s/it]
INFO:root:eval mean loss: 22278.357863653273
INFO:root:eval perplexity: 10.031341552734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [22:16:24<8:27:14, 553.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14942.549278846154
INFO:root:current train perplexity4.353610992431641
INFO:root:current mean train loss 14946.448783160971
INFO:root:current train perplexity4.364765644073486
INFO:root:current mean train loss 14954.907553445346
INFO:root:current train perplexity4.366489410400391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.67s/it]
INFO:root:final mean train loss: 14945.34417921497
INFO:root:final train perplexity: 4.367071628570557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it]
INFO:root:eval mean loss: 22277.951962425595
INFO:root:eval perplexity: 10.03091812133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [22:25:25<8:14:43, 549.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14984.818702781593
INFO:root:current train perplexity4.356996059417725
INFO:root:current mean train loss 14943.206238751636
INFO:root:current train perplexity4.3551025390625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it]
INFO:root:final mean train loss: 14938.101184475807
INFO:root:final train perplexity: 4.363953113555908
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.55s/it]
INFO:root:eval mean loss: 22284.342587425595
INFO:root:eval perplexity: 10.037552833557129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [22:34:26<8:03:08, 546.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14925.665992914244
INFO:root:current train perplexity4.3586320877075195
INFO:root:current mean train loss 14916.31037614729
INFO:root:current train perplexity4.349052429199219
INFO:root:current mean train loss 14941.712890625
INFO:root:current train perplexity4.35884952545166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.44s/it]
INFO:root:final mean train loss: 14926.409872731854
INFO:root:final train perplexity: 4.358923435211182
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.18s/it]
INFO:root:eval mean loss: 22279.159970238095
INFO:root:eval perplexity: 10.032169342041016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [22:43:26<7:52:23, 545.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14942.955283717105
INFO:root:current train perplexity4.357663154602051
INFO:root:current mean train loss 14922.158884214743
INFO:root:current train perplexity4.353844165802002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.81s/it]
INFO:root:final mean train loss: 14921.191910282258
INFO:root:final train perplexity: 4.356680393218994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.97s/it]
INFO:root:eval mean loss: 22274.8203125
INFO:root:eval perplexity: 10.027666091918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [22:52:29<7:42:44, 544.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14895.802942154256
INFO:root:current train perplexity4.3398003578186035
INFO:root:current mean train loss 14893.862344547193
INFO:root:current train perplexity4.343689441680908
INFO:root:current mean train loss 14926.633583470395
INFO:root:current train perplexity4.3544416427612305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.44s/it]
INFO:root:final mean train loss: 14915.82570328251
INFO:root:final train perplexity: 4.354375839233398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.92s/it]
INFO:root:eval mean loss: 22278.658342633928
INFO:root:eval perplexity: 10.03165054321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [23:01:26<7:31:50, 542.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14889.590603298611
INFO:root:current train perplexity4.338906288146973
INFO:root:current mean train loss 14890.890350188442
INFO:root:current train perplexity4.347997188568115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.65s/it]
INFO:root:final mean train loss: 14910.057534494708
INFO:root:final train perplexity: 4.35189962387085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 22288.820219494046
INFO:root:eval perplexity: 10.042205810546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [23:10:34<7:24:15, 543.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14901.22185202206
INFO:root:current train perplexity4.351476669311523
INFO:root:current mean train loss 14892.978593232616
INFO:root:current train perplexity4.345027446746826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.85s/it]
INFO:root:final mean train loss: 14903.596742691532
INFO:root:final train perplexity: 4.34912633895874
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 22284.099307105655
INFO:root:eval perplexity: 10.037301063537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [23:19:35<7:14:25, 543.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14991.397135416666
INFO:root:current train perplexity4.365962982177734
INFO:root:current mean train loss 14884.277647148057
INFO:root:current train perplexity4.337520599365234
INFO:root:current mean train loss 14905.656341402402
INFO:root:current train perplexity4.344963073730469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.42s/it]
INFO:root:final mean train loss: 14895.046020507812
INFO:root:final train perplexity: 4.345460414886475
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it]
INFO:root:eval mean loss: 22280.776343936013
INFO:root:eval perplexity: 10.03385066986084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [23:28:40<7:05:47, 543.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14855.176260653408
INFO:root:current train perplexity4.323385715484619
INFO:root:current mean train loss 14882.230720766129
INFO:root:current train perplexity4.337263107299805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.75s/it]
INFO:root:final mean train loss: 14891.516412550403
INFO:root:final train perplexity: 4.343947410583496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.45s/it]
INFO:root:eval mean loss: 22294.264183407737
INFO:root:eval perplexity: 10.04786491394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [23:37:52<6:58:44, 546.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15021.418666294643
INFO:root:current train perplexity4.4067463874816895
INFO:root:current mean train loss 14864.649906907127
INFO:root:current train perplexity4.340314865112305
INFO:root:current mean train loss 14905.664487092392
INFO:root:current train perplexity4.344486713409424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.10s/it]
INFO:root:final mean train loss: 14888.97257749496
INFO:root:final train perplexity: 4.34285831451416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.88s/it]
INFO:root:eval mean loss: 22293.27464657738
INFO:root:eval perplexity: 10.04683780670166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [23:47:00<6:49:57, 546.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14917.085159560382
INFO:root:current train perplexity4.340371608734131
INFO:root:current mean train loss 14870.343909689465
INFO:root:current train perplexity4.334270000457764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.37s/it]
INFO:root:final mean train loss: 14881.065673828125
INFO:root:final train perplexity: 4.339472770690918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.44s/it]
INFO:root:eval mean loss: 22293.242606026786
INFO:root:eval perplexity: 10.04680347442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [23:56:00<6:39:24, 544.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14841.990767045454
INFO:root:current train perplexity4.284733295440674
INFO:root:current mean train loss 14865.92894847973
INFO:root:current train perplexity4.323318004608154
INFO:root:current mean train loss 14876.896382553317
INFO:root:current train perplexity4.330789566040039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.10s/it]
INFO:root:final mean train loss: 14871.916114068801
INFO:root:final train perplexity: 4.3355584144592285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.86s/it]
INFO:root:eval mean loss: 22300.62830171131
INFO:root:eval perplexity: 10.054486274719238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [24:05:04<6:30:07, 544.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14800.752883184523
INFO:root:current train perplexity4.32176399230957
INFO:root:current mean train loss 14879.04126126342
INFO:root:current train perplexity4.3357834815979


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.74s/it]
INFO:root:final mean train loss: 14869.018913022934
INFO:root:final train perplexity: 4.3343186378479
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.12s/it]
INFO:root:eval mean loss: 22297.76541573661
INFO:root:eval perplexity: 10.051508903503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [24:14:09<6:21:09, 544.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14914.1986328125
INFO:root:current train perplexity4.321537494659424
INFO:root:current mean train loss 14878.829245923913
INFO:root:current train perplexity4.3379435539245605
INFO:root:current mean train loss 14876.70453306686
INFO:root:current train perplexity4.3330535888671875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.10s/it]
INFO:root:final mean train loss: 14861.264384608116
INFO:root:final train perplexity: 4.331005096435547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.09s/it]
INFO:root:eval mean loss: 22294.735677083332
INFO:root:eval perplexity: 10.048356056213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [24:23:22<6:13:53, 547.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14826.041205107276
INFO:root:current train perplexity4.30937385559082
INFO:root:current mean train loss 14842.514701066617
INFO:root:current train perplexity4.320006370544434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.58s/it]
INFO:root:final mean train loss: 14856.103236044606
INFO:root:final train perplexity: 4.328801155090332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it]
INFO:root:eval mean loss: 22295.56322079613
INFO:root:eval perplexity: 10.04921817779541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [24:32:39<6:06:42, 550.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.772666529605
INFO:root:current train perplexity4.306814670562744
INFO:root:current mean train loss 14866.579396993173
INFO:root:current train perplexity4.3256096839904785
INFO:root:current mean train loss 14851.840526005994
INFO:root:current train perplexity4.326871871948242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.48s/it]
INFO:root:final mean train loss: 14851.99259702621
INFO:root:final train perplexity: 4.3270463943481445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.97s/it]
INFO:root:eval mean loss: 22309.754557291668
INFO:root:eval perplexity: 10.063985824584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [24:41:55<5:58:43, 551.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14849.954871808979
INFO:root:current train perplexity4.3105645179748535
INFO:root:current mean train loss 14850.681783397295
INFO:root:current train perplexity4.317343235015869


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.42s/it]
INFO:root:final mean train loss: 14845.02627268145
INFO:root:final train perplexity: 4.3240742683410645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.91s/it]
INFO:root:eval mean loss: 22298.298990885418
INFO:root:eval perplexity: 10.05206298828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [24:51:11<5:50:20, 553.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14838.911939538044
INFO:root:current train perplexity4.334109306335449
INFO:root:current mean train loss 14889.814651613313
INFO:root:current train perplexity4.327627658843994
INFO:root:current mean train loss 14851.095374684697
INFO:root:current train perplexity4.319530010223389


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:54<00:00, 474.20s/it]
INFO:root:final mean train loss: 14841.75308325983
INFO:root:final train perplexity: 4.322678565979004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.27s/it]
INFO:root:eval mean loss: 22305.081566220237
INFO:root:eval perplexity: 10.059121131896973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [25:00:25<5:41:12, 553.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14830.285442708333
INFO:root:current train perplexity4.332590579986572
INFO:root:current mean train loss 14830.150920758928
INFO:root:current train perplexity4.319230079650879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.67s/it]
INFO:root:final mean train loss: 14837.268440492691
INFO:root:final train perplexity: 4.320767402648926
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.20s/it]
INFO:root:eval mean loss: 22308.78538876488
INFO:root:eval perplexity: 10.06297779083252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [25:09:37<5:31:52, 553.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14868.460358796296
INFO:root:current train perplexity4.3090643882751465
INFO:root:current mean train loss 14865.270907664863
INFO:root:current train perplexity4.330358028411865
INFO:root:current mean train loss 14849.252249965584
INFO:root:current train perplexity4.3213348388671875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.24s/it]
INFO:root:final mean train loss: 14831.446663148941
INFO:root:final train perplexity: 4.318285942077637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.05s/it]
INFO:root:eval mean loss: 22309.230794270832
INFO:root:eval perplexity: 10.063443183898926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [25:18:49<5:22:29, 552.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14862.393307456487
INFO:root:current train perplexity4.324423313140869
INFO:root:current mean train loss 14851.639861208101
INFO:root:current train perplexity4.319369316101074


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.09s/it]
INFO:root:final mean train loss: 14823.750204763104
INFO:root:final train perplexity: 4.315009593963623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.73s/it]
INFO:root:eval mean loss: 22317.002883184523
INFO:root:eval perplexity: 10.071539878845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [25:28:02<5:13:13, 552.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.390845514114
INFO:root:current train perplexity4.310367107391357
INFO:root:current mean train loss 14848.894702707537
INFO:root:current train perplexity4.312086582183838
INFO:root:current mean train loss 14838.83683796672
INFO:root:current train perplexity4.3162994384765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.30s/it]
INFO:root:final mean train loss: 14823.473305979083
INFO:root:final train perplexity: 4.314891338348389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.84s/it]
INFO:root:eval mean loss: 22311.20556640625
INFO:root:eval perplexity: 10.065500259399414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [25:37:05<5:02:23, 549.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14817.31701807229
INFO:root:current train perplexity4.307940483093262
INFO:root:current mean train loss 14845.869716956968
INFO:root:current train perplexity4.314465522766113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.78s/it]
INFO:root:final mean train loss: 14821.36215111517
INFO:root:final train perplexity: 4.31399393081665
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.57s/it]
INFO:root:eval mean loss: 22306.089704241072
INFO:root:eval perplexity: 10.060171127319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [25:46:32<4:55:59, 554.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14953.601506696428
INFO:root:current train perplexity4.342212200164795
INFO:root:current mean train loss 14802.394900173611
INFO:root:current train perplexity4.30128812789917
INFO:root:current mean train loss 14824.293417553192
INFO:root:current train perplexity4.309216022491455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.83s/it]
INFO:root:final mean train loss: 14807.07691611013
INFO:root:final train perplexity: 4.307919979095459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.65s/it]
INFO:root:eval mean loss: 22313.349632626487
INFO:root:eval perplexity: 10.067731857299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [25:55:51<4:47:24, 556.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14810.35342582615
INFO:root:current train perplexity4.3104448318481445
INFO:root:current mean train loss 14805.284174465241
INFO:root:current train perplexity4.306249141693115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.83s/it]
INFO:root:final mean train loss: 14803.63048922631
INFO:root:final train perplexity: 4.306456089019775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it]
INFO:root:eval mean loss: 22317.504975818454
INFO:root:eval perplexity: 10.072063446044922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [26:05:04<4:37:32, 555.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14734.599609375
INFO:root:current train perplexity4.278055667877197
INFO:root:current mean train loss 14780.813111229767
INFO:root:current train perplexity4.303857803344727
INFO:root:current mean train loss 14811.291853262292
INFO:root:current train perplexity4.3075714111328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.09s/it]
INFO:root:final mean train loss: 14802.542799426663
INFO:root:final train perplexity: 4.30599308013916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it]
INFO:root:eval mean loss: 22320.33093843006
INFO:root:eval perplexity: 10.075007438659668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [26:14:10<4:27:00, 552.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.071085164835
INFO:root:current train perplexity4.321972370147705
INFO:root:current mean train loss 14798.489631053664
INFO:root:current train perplexity4.304841995239258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.63s/it]
INFO:root:final mean train loss: 14799.65648232737
INFO:root:final train perplexity: 4.304767608642578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it]
INFO:root:eval mean loss: 22313.94115048363
INFO:root:eval perplexity: 10.06834888458252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [26:23:15<4:16:46, 550.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14761.862917877907
INFO:root:current train perplexity4.295710563659668
INFO:root:current mean train loss 14811.13348858173
INFO:root:current train perplexity4.303432464599609
INFO:root:current mean train loss 14806.841230227623
INFO:root:current train perplexity4.301664352416992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it]
INFO:root:final mean train loss: 14792.526292370212
INFO:root:final train perplexity: 4.301741123199463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.19s/it]
INFO:root:eval mean loss: 22323.518508184523
INFO:root:eval perplexity: 10.07833480834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [26:32:12<4:05:46, 546.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14811.942238898026
INFO:root:current train perplexity4.297355651855469
INFO:root:current mean train loss 14807.194556290064
INFO:root:current train perplexity4.299535274505615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.32s/it]
INFO:root:final mean train loss: 14789.411392704133
INFO:root:final train perplexity: 4.300419330596924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it]
INFO:root:eval mean loss: 22313.133347284227
INFO:root:eval perplexity: 10.067508697509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [26:41:14<3:56:11, 545.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14719.763027759309
INFO:root:current train perplexity4.279138565063477
INFO:root:current mean train loss 14785.488546981293
INFO:root:current train perplexity4.292834758758545
INFO:root:current mean train loss 14804.15953551999
INFO:root:current train perplexity4.30197811126709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.05s/it]
INFO:root:final mean train loss: 14791.931849325856
INFO:root:final train perplexity: 4.301488876342773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.24s/it]
INFO:root:eval mean loss: 22314.22586495536
INFO:root:eval perplexity: 10.068644523620605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [26:50:16<3:46:45, 544.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14783.286961410984
INFO:root:current train perplexity4.293829441070557
INFO:root:current mean train loss 14785.896145767902
INFO:root:current train perplexity4.294249057769775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.78s/it]
INFO:root:final mean train loss: 14783.46632828251
INFO:root:final train perplexity: 4.297898292541504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.23s/it]
INFO:root:eval mean loss: 22317.30457124256
INFO:root:eval perplexity: 10.071854591369629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [26:59:30<3:38:45, 546.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14792.912530637255
INFO:root:current train perplexity4.282793998718262
INFO:root:current mean train loss 14781.196010968542
INFO:root:current train perplexity4.2897725105285645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.67s/it]
INFO:root:final mean train loss: 14780.699458952873
INFO:root:final train perplexity: 4.296725749969482
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it]
INFO:root:eval mean loss: 22324.72530691964
INFO:root:eval perplexity: 10.079591751098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [27:08:48<3:30:58, 550.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14801.957682291666
INFO:root:current train perplexity4.27704381942749
INFO:root:current mean train loss 14773.554469432645
INFO:root:current train perplexity4.2929768562316895
INFO:root:current mean train loss 14803.963924915333
INFO:root:current train perplexity4.297431945800781


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it]
INFO:root:final mean train loss: 14779.785648469002
INFO:root:final train perplexity: 4.29633903503418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it]
INFO:root:eval mean loss: 22325.21358816964
INFO:root:eval perplexity: 10.080101013183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [27:17:59<3:21:51, 550.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14822.564595170454
INFO:root:current train perplexity4.281339168548584
INFO:root:current mean train loss 14804.265952620968
INFO:root:current train perplexity4.293139457702637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it]
INFO:root:final mean train loss: 14774.680317540322
INFO:root:final train perplexity: 4.2941765785217285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.98s/it]
INFO:root:eval mean loss: 22325.24288504464
INFO:root:eval perplexity: 10.080132484436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [27:27:08<3:12:30, 550.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14703.377511160714
INFO:root:current train perplexity4.2779645919799805
INFO:root:current mean train loss 14757.97366931951
INFO:root:current train perplexity4.293375015258789
INFO:root:current mean train loss 14781.140436292271
INFO:root:current train perplexity4.292136192321777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.63s/it]
INFO:root:final mean train loss: 14771.607496692288
INFO:root:final train perplexity: 4.292874813079834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.58s/it]
INFO:root:eval mean loss: 22320.50023251488
INFO:root:eval perplexity: 10.075185775756836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [27:36:18<3:03:21, 550.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14740.857041181143
INFO:root:current train perplexity4.288056373596191
INFO:root:current mean train loss 14756.128064809356
INFO:root:current train perplexity4.284144401550293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.01s/it]
INFO:root:final mean train loss: 14765.350641066028
INFO:root:final train perplexity: 4.290226459503174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.98s/it]
INFO:root:eval mean loss: 22324.936104910714
INFO:root:eval perplexity: 10.079813003540039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [27:45:29<2:54:16, 550.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14866.320845170454
INFO:root:current train perplexity4.2771453857421875
INFO:root:current mean train loss 14790.461852477478
INFO:root:current train perplexity4.292210102081299
INFO:root:current mean train loss 14781.592250444313
INFO:root:current train perplexity4.291940212249756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.56s/it]
INFO:root:final mean train loss: 14764.769417055191
INFO:root:final train perplexity: 4.289980411529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.73s/it]
INFO:root:eval mean loss: 22326.595703125
INFO:root:eval perplexity: 10.081543922424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [27:54:37<2:44:53, 549.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14717.091455853175
INFO:root:current train perplexity4.280212879180908
INFO:root:current mean train loss 14755.573865270322
INFO:root:current train perplexity4.28141975402832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.05s/it]
INFO:root:final mean train loss: 14761.16363328503
INFO:root:final train perplexity: 4.288455009460449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it]
INFO:root:eval mean loss: 22327.708961123513
INFO:root:eval perplexity: 10.082707405090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [28:03:46<2:35:40, 549.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14732.465494791666
INFO:root:current train perplexity4.299365520477295
INFO:root:current mean train loss 14771.375416100544
INFO:root:current train perplexity4.291283130645752
INFO:root:current mean train loss 14767.60652252907
INFO:root:current train perplexity4.286532878875732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.30s/it]
INFO:root:final mean train loss: 14756.663022933468
INFO:root:final train perplexity: 4.286551475524902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.52s/it]
INFO:root:eval mean loss: 22323.635602678572
INFO:root:eval perplexity: 10.078454971313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [28:12:48<2:25:58, 547.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14790.46243878265
INFO:root:current train perplexity4.280459403991699
INFO:root:current mean train loss 14766.140239053144
INFO:root:current train perplexity4.2832255363464355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:07<00:00, 487.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:07<00:00, 487.25s/it]
INFO:root:final mean train loss: 14759.845321163055
INFO:root:final train perplexity: 4.287897109985352
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.95s/it]
INFO:root:eval mean loss: 22328.746721540178
INFO:root:eval perplexity: 10.083786010742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [28:22:15<2:18:18, 553.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14683.300729851973
INFO:root:current train perplexity4.258842468261719
INFO:root:current mean train loss 14743.756712841387
INFO:root:current train perplexity4.2831902503967285
INFO:root:current mean train loss 14776.04990278967
INFO:root:current train perplexity4.288369178771973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.47s/it]
INFO:root:final mean train loss: 14754.544894310737
INFO:root:final train perplexity: 4.285655975341797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.69s/it]
INFO:root:eval mean loss: 22326.547526041668
INFO:root:eval perplexity: 10.081493377685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [28:31:57<2:11:06, 561.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14776.497084066901
INFO:root:current train perplexity4.283010005950928
INFO:root:current mean train loss 14786.402834886696
INFO:root:current train perplexity4.287446975708008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.67s/it]
INFO:root:final mean train loss: 14753.816788211945
INFO:root:final train perplexity: 4.285348415374756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.82s/it]
INFO:root:eval mean loss: 22331.259719122023
INFO:root:eval perplexity: 10.08641242980957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [28:41:14<2:01:22, 560.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14819.42972995924
INFO:root:current train perplexity4.277763843536377
INFO:root:current mean train loss 14747.958777947155
INFO:root:current train perplexity4.279637813568115
INFO:root:current mean train loss 14765.599254659473
INFO:root:current train perplexity4.285538673400879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.58s/it]
INFO:root:final mean train loss: 14752.745093560989
INFO:root:final train perplexity: 4.284895896911621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 22329.57373046875
INFO:root:eval perplexity: 10.084649085998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [28:50:23<1:51:24, 557.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14777.433411458333
INFO:root:current train perplexity4.289411544799805
INFO:root:current mean train loss 14741.981099330356
INFO:root:current train perplexity4.279331684112549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.76s/it]
INFO:root:final mean train loss: 14747.167271767894
INFO:root:final train perplexity: 4.282539367675781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.09s/it]
INFO:root:eval mean loss: 22326.529715401786
INFO:root:eval perplexity: 10.081476211547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [28:59:36<1:41:51, 555.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14695.462745949075
INFO:root:current train perplexity4.267358779907227
INFO:root:current mean train loss 14732.589951402559
INFO:root:current train perplexity4.280354976654053
INFO:root:current mean train loss 14746.546281318833
INFO:root:current train perplexity4.2792158126831055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.08s/it]
INFO:root:final mean train loss: 14745.513411983367
INFO:root:final train perplexity: 4.281839847564697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it]
INFO:root:eval mean loss: 22333.647484188987
INFO:root:eval perplexity: 10.088903427124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [29:08:45<1:32:18, 553.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14802.910811412183
INFO:root:current train perplexity4.283497333526611
INFO:root:current mean train loss 14749.587683310056
INFO:root:current train perplexity4.278543949127197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.71s/it]
INFO:root:final mean train loss: 14741.966883505544
INFO:root:final train perplexity: 4.280343055725098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.20s/it]
INFO:root:eval mean loss: 22329.423874627977
INFO:root:eval perplexity: 10.084493637084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [29:17:52<1:22:45, 551.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14852.08146421371
INFO:root:current train perplexity4.284937858581543
INFO:root:current mean train loss 14794.022214933206
INFO:root:current train perplexity4.284854888916016
INFO:root:current mean train loss 14754.557139475108
INFO:root:current train perplexity4.281999588012695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.05s/it]
INFO:root:final mean train loss: 14748.712674048638
INFO:root:final train perplexity: 4.283191680908203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.40s/it]
INFO:root:eval mean loss: 22330.646089099704
INFO:root:eval perplexity: 10.085772514343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [29:26:56<1:13:14, 549.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14746.837267036897
INFO:root:current train perplexity4.283583164215088
INFO:root:current mean train loss 14742.802905140028
INFO:root:current train perplexity4.279264450073242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.54s/it]
INFO:root:final mean train loss: 14742.859764837449
INFO:root:final train perplexity: 4.280719757080078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.73s/it]
INFO:root:eval mean loss: 22332.574660528273
INFO:root:eval perplexity: 10.087785720825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [29:35:59<1:03:51, 547.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14751.631529017857
INFO:root:current train perplexity4.301857948303223
INFO:root:current mean train loss 14758.047294560185
INFO:root:current train perplexity4.281546115875244
INFO:root:current mean train loss 14757.455601728723
INFO:root:current train perplexity4.279448986053467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.21s/it]
INFO:root:final mean train loss: 14741.745365265877
INFO:root:final train perplexity: 4.280249118804932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.38s/it]
INFO:root:eval mean loss: 22329.27462332589
INFO:root:eval perplexity: 10.084339141845703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [29:45:07<54:46, 547.75s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14699.173536278735
INFO:root:current train perplexity4.268816947937012
INFO:root:current mean train loss 14737.383444393383
INFO:root:current train perplexity4.277515411376953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.65s/it]
INFO:root:final mean train loss: 14737.226723947833
INFO:root:final train perplexity: 4.2783427238464355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.07s/it]
INFO:root:eval mean loss: 22332.457333519345
INFO:root:eval perplexity: 10.087662696838379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [29:54:22<45:48, 549.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14811.84192207532
INFO:root:current train perplexity4.295610427856445
INFO:root:current mean train loss 14743.81290748651
INFO:root:current train perplexity4.278123378753662
INFO:root:current mean train loss 14746.285474960774
INFO:root:current train perplexity4.2774176597595215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.65s/it]
INFO:root:final mean train loss: 14736.01870825983
INFO:root:final train perplexity: 4.27783203125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.86s/it]
INFO:root:eval mean loss: 22331.966610863095
INFO:root:eval perplexity: 10.087150573730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [30:03:40<36:49, 552.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14782.290790264424
INFO:root:current train perplexity4.286264896392822
INFO:root:current mean train loss 14766.059135716623
INFO:root:current train perplexity4.285005569458008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.21s/it]
INFO:root:final mean train loss: 14740.308235414566
INFO:root:final train perplexity: 4.279643535614014
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it]
INFO:root:eval mean loss: 22330.296735491072
INFO:root:eval perplexity: 10.085407257080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [30:12:53<27:37, 552.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14747.77707122093
INFO:root:current train perplexity4.272821426391602
INFO:root:current mean train loss 14747.55914007867
INFO:root:current train perplexity4.272833347320557
INFO:root:current mean train loss 14751.096277809927
INFO:root:current train perplexity4.2793145179748535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.46s/it]
INFO:root:final mean train loss: 14739.263191469254
INFO:root:final train perplexity: 4.279201507568359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it]
INFO:root:eval mean loss: 22331.01525297619
INFO:root:eval perplexity: 10.08615493774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [30:21:57<18:20, 550.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14762.750688733553
INFO:root:current train perplexity4.28539514541626
INFO:root:current mean train loss 14748.992758413462
INFO:root:current train perplexity4.278155326843262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.62s/it]
INFO:root:final mean train loss: 14732.746960055443
INFO:root:final train perplexity: 4.276452541351318
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it]
INFO:root:eval mean loss: 22330.080403645832
INFO:root:eval perplexity: 10.08517837524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [30:30:59<09:07, 547.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14727.596056349734
INFO:root:current train perplexity4.269655704498291
INFO:root:current mean train loss 14735.085618622448
INFO:root:current train perplexity4.2768874168396
INFO:root:current mean train loss 14747.92933166751
INFO:root:current train perplexity4.278076648712158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.15s/it]
INFO:root:final mean train loss: 14735.847557806199
INFO:root:final train perplexity: 4.2777605056762695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.24s/it]
INFO:root:eval mean loss: 22330.460867745536
INFO:root:eval perplexity: 10.085582733154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_minilm/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [30:40:22<00:00, 552.16s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [30:40:22<00:00, 552.11s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it]
INFO:root:eval mean loss: 22330.460867745536
INFO:root:eval perplexity: 10.085582733154297
INFO:root:evalaution complete
INFO:root:save model final: small_allmini_minilm/final
