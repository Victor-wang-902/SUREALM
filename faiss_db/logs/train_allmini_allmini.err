INFO:root:Output: small_allmini_allmini
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 98422.9912405303
INFO:root:current train perplexity16085.8408203125
INFO:root:current mean train loss 83164.99071529522
INFO:root:current train perplexity3614.77294921875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.78s/it]
INFO:root:final mean train loss: 76674.38786857358
INFO:root:final train perplexity: 1924.7786865234375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:07<00:00, 67.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:07<00:00, 67.11s/it]
INFO:root:eval mean loss: 45082.44428943453
INFO:root:eval perplexity: 106.25466918945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/1

  0%|          | 1/200 [09:23<31:07:41, 563.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 43644.12362132353
INFO:root:current train perplexity74.80684661865234
INFO:root:current mean train loss 39601.459644039736
INFO:root:current train perplexity49.588253021240234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.18s/it]
INFO:root:final mean train loss: 36899.56441374748
INFO:root:final train perplexity: 38.07228469848633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.30s/it]
INFO:root:eval mean loss: 31961.865885416668
INFO:root:eval perplexity: 27.328100204467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/2

  1%|          | 2/200 [18:37<30:41:04, 557.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31404.770833333332
INFO:root:current train perplexity22.481002807617188
INFO:root:current mean train loss 29856.668556583736
INFO:root:current train perplexity18.960914611816406
INFO:root:current mean train loss 28943.486732219826
INFO:root:current train perplexity17.329463958740234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.68s/it]
INFO:root:final mean train loss: 28556.002780052924
INFO:root:final train perplexity: 16.71893882751465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.94s/it]
INFO:root:eval mean loss: 28661.659644717263
INFO:root:eval perplexity: 19.421058654785156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/3

  2%|â–         | 3/200 [27:53<30:29:12, 557.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26504.183629261363
INFO:root:current train perplexity13.580150604248047
INFO:root:current mean train loss 26011.883392137097
INFO:root:current train perplexity12.977129936218262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.39s/it]
INFO:root:final mean train loss: 25646.54134639617
INFO:root:final train perplexity: 12.548179626464844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.99s/it]
INFO:root:eval mean loss: 27225.007021949405
INFO:root:eval perplexity: 16.73781967163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/4

  2%|â–         | 4/200 [36:54<29:58:32, 550.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24966.222098214286
INFO:root:current train perplexity11.41329288482666
INFO:root:current mean train loss 24493.347126898363
INFO:root:current train perplexity11.14376163482666
INFO:root:current mean train loss 24205.844457653984
INFO:root:current train perplexity10.877628326416016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.89s/it]
INFO:root:final mean train loss: 24090.200856854837
INFO:root:final train perplexity: 10.76252555847168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.90s/it]
INFO:root:eval mean loss: 26386.306942894345
INFO:root:eval perplexity: 15.346221923828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/5

  2%|â–Ž         | 5/200 [46:06<29:50:59, 551.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23452.11225503178
INFO:root:current train perplexity10.099555969238281
INFO:root:current mean train loss 23214.774776434748
INFO:root:current train perplexity9.856989860534668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.37s/it]
INFO:root:final mean train loss: 23064.082196635583
INFO:root:final train perplexity: 9.726574897766113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.53s/it]
INFO:root:eval mean loss: 25810.054268973214
INFO:root:eval perplexity: 14.457732200622559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/6

  3%|â–Ž         | 6/200 [55:06<29:30:19, 547.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22418.062144886364
INFO:root:current train perplexity9.17989730834961
INFO:root:current mean train loss 22489.910772100226
INFO:root:current train perplexity9.182937622070312
INFO:root:current mean train loss 22361.789840047393
INFO:root:current train perplexity9.064598083496094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.01s/it]
INFO:root:final mean train loss: 22311.403028918852
INFO:root:final train perplexity: 9.03064250946045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:29<00:00, 89.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:29<00:00, 89.47s/it]
INFO:root:eval mean loss: 25368.804827008928
INFO:root:eval perplexity: 13.812334060668945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/7

  4%|â–Ž         | 7/200 [1:04:14<29:21:40, 547.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21944.562624007936
INFO:root:current train perplexity8.695953369140625
INFO:root:current mean train loss 21853.44103479678
INFO:root:current train perplexity8.60254955291748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.37s/it]
INFO:root:final mean train loss: 21735.49236863659
INFO:root:final train perplexity: 8.531968116760254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it]
INFO:root:eval mean loss: 25055.327659970237
INFO:root:eval perplexity: 13.371404647827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/8

  4%|â–         | 8/200 [1:13:06<28:56:44, 542.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21518.319010416668
INFO:root:current train perplexity8.273783683776855
INFO:root:current mean train loss 21417.383152173912
INFO:root:current train perplexity8.236510276794434
INFO:root:current mean train loss 21298.064434956395
INFO:root:current train perplexity8.158744812011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.95s/it]
INFO:root:final mean train loss: 21260.462024319557
INFO:root:final train perplexity: 8.141437530517578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:29<00:00, 89.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:29<00:00, 89.10s/it]
INFO:root:eval mean loss: 24766.197405133928
INFO:root:eval perplexity: 12.97720718383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/9

  4%|â–         | 9/200 [1:22:10<28:48:36, 543.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21040.213094682837
INFO:root:current train perplexity7.926959991455078
INFO:root:current mean train loss 20968.573540419162
INFO:root:current train perplexity7.8887152671813965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.69s/it]
INFO:root:final mean train loss: 20871.263624621977
INFO:root:final train perplexity: 7.834830284118652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it]
INFO:root:eval mean loss: 24520.332705543155
INFO:root:eval perplexity: 12.651158332824707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/10

  5%|â–Œ         | 10/200 [1:31:00<28:27:13, 539.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20827.574527138157
INFO:root:current train perplexity7.667734146118164
INFO:root:current mean train loss 20646.509617909665
INFO:root:current train perplexity7.61544942855835
INFO:root:current mean train loss 20558.383632990866
INFO:root:current train perplexity7.584665775299072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.69s/it]
INFO:root:final mean train loss: 20532.971801757812
INFO:root:final train perplexity: 7.577723026275635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:30<00:00, 90.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:30<00:00, 90.70s/it]
INFO:root:eval mean loss: 24320.571242559523
INFO:root:eval perplexity: 12.392285346984863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/11

  6%|â–Œ         | 11/200 [1:40:13<28:31:04, 543.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20355.973123899646
INFO:root:current train perplexity7.398375988006592
INFO:root:current mean train loss 20290.176626461987
INFO:root:current train perplexity7.383965492248535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.22s/it]
INFO:root:final mean train loss: 20240.00716277092
INFO:root:final train perplexity: 7.361893177032471
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.08s/it]
INFO:root:eval mean loss: 24152.278227306546
INFO:root:eval perplexity: 12.178312301635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/12

  6%|â–Œ         | 12/200 [1:49:13<28:19:03, 542.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20113.961701766304
INFO:root:current train perplexity7.241394519805908
INFO:root:current mean train loss 20016.539650025406
INFO:root:current train perplexity7.206399917602539
INFO:root:current mean train loss 19985.571468609865
INFO:root:current train perplexity7.176143646240234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.65s/it]
INFO:root:final mean train loss: 19980.027540637602
INFO:root:final train perplexity: 7.175515651702881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.97s/it]
INFO:root:eval mean loss: 24005.46700613839
INFO:root:eval perplexity: 11.994671821594238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/13

  6%|â–‹         | 13/200 [1:58:02<27:57:14, 538.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19860.550807291667
INFO:root:current train perplexity7.046683311462402
INFO:root:current mean train loss 19790.939363839287
INFO:root:current train perplexity7.033336162567139


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.39s/it]
INFO:root:final mean train loss: 19750.970620432206
INFO:root:final train perplexity: 7.015221118927002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:28<00:00, 88.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:28<00:00, 88.42s/it]
INFO:root:eval mean loss: 23852.711611793155
INFO:root:eval perplexity: 11.80653190612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/14

  7%|â–‹         | 14/200 [2:07:17<28:04:27, 543.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19558.088252314814
INFO:root:current train perplexity6.911036491394043
INFO:root:current mean train loss 19522.471041461613
INFO:root:current train perplexity6.8880743980407715
INFO:root:current mean train loss 19558.43679446586
INFO:root:current train perplexity6.875725746154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.91s/it]
INFO:root:final mean train loss: 19535.957448651712
INFO:root:final train perplexity: 6.868013858795166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:30<00:00, 90.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:30<00:00, 90.48s/it]
INFO:root:eval mean loss: 23740.35616629464
INFO:root:eval perplexity: 11.670036315917969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/15

  8%|â–Š         | 15/200 [2:16:23<27:58:02, 544.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19363.727848101265
INFO:root:current train perplexity6.759973526000977
INFO:root:current mean train loss 19367.06338381634
INFO:root:current train perplexity6.752111911773682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.99s/it]
INFO:root:final mean train loss: 19352.90611611643
INFO:root:final train perplexity: 6.745126724243164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.79s/it]
INFO:root:eval mean loss: 23624.69763764881
INFO:root:eval perplexity: 11.53117847442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/16

  8%|â–Š         | 16/200 [2:25:10<27:33:13, 539.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19145.973979334678
INFO:root:current train perplexity6.6722869873046875
INFO:root:current mean train loss 19176.75035782443
INFO:root:current train perplexity6.625767230987549
INFO:root:current mean train loss 19177.008269074675
INFO:root:current train perplexity6.624917507171631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.43s/it]
INFO:root:final mean train loss: 19173.806416173134
INFO:root:final train perplexity: 6.627020835876465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:22<00:00, 82.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:22<00:00, 82.83s/it]
INFO:root:eval mean loss: 23515.210611979168
INFO:root:eval perplexity: 11.401247024536133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/17

  8%|â–Š         | 17/200 [2:34:00<27:15:04, 536.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19015.792003953313
INFO:root:current train perplexity6.522064685821533
INFO:root:current mean train loss 19032.043843920765
INFO:root:current train perplexity6.518157482147217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.67s/it]
INFO:root:final mean train loss: 19014.389612997733
INFO:root:final train perplexity: 6.523633003234863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.69s/it]
INFO:root:eval mean loss: 23480.52369326637
INFO:root:eval perplexity: 11.360394477844238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/18

  9%|â–‰         | 18/200 [2:42:48<26:59:28, 533.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18956.109709821427
INFO:root:current train perplexity6.4762654304504395
INFO:root:current mean train loss 18942.88258101852
INFO:root:current train perplexity6.460043907165527
INFO:root:current mean train loss 18869.983776595745
INFO:root:current train perplexity6.427250385284424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.81s/it]
INFO:root:final mean train loss: 18870.640321793097
INFO:root:final train perplexity: 6.431792259216309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.37s/it]
INFO:root:eval mean loss: 23388.60277157738
INFO:root:eval perplexity: 11.252828598022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/19

 10%|â–‰         | 19/200 [2:51:37<26:46:11, 532.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18727.533360272988
INFO:root:current train perplexity6.326712131500244
INFO:root:current mean train loss 18762.59433489305
INFO:root:current train perplexity6.34393835067749


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.95s/it]
INFO:root:final mean train loss: 18729.11949108493
INFO:root:final train perplexity: 6.34263801574707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.55s/it]
INFO:root:eval mean loss: 23286.57198660714
INFO:root:eval perplexity: 11.134625434875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/20

 10%|â–ˆ         | 20/200 [3:00:38<26:44:20, 534.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18748.106169871793
INFO:root:current train perplexity6.287437438964844
INFO:root:current mean train loss 18631.239616119605
INFO:root:current train perplexity6.267308235168457
INFO:root:current mean train loss 18622.714827405856
INFO:root:current train perplexity6.265553951263428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.39s/it]
INFO:root:final mean train loss: 18600.289428710938
INFO:root:final train perplexity: 6.26255464553833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it]
INFO:root:eval mean loss: 23239.926571800595
INFO:root:eval perplexity: 11.081003189086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/21

 10%|â–ˆ         | 21/200 [3:09:48<26:49:00, 539.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18480.3313229739
INFO:root:current train perplexity6.191650390625
INFO:root:current mean train loss 18494.30554646597
INFO:root:current train perplexity6.183530807495117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.03s/it]
INFO:root:final mean train loss: 18481.91892562374
INFO:root:final train perplexity: 6.1898627281188965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.72s/it]
INFO:root:eval mean loss: 23169.61253720238
INFO:root:eval perplexity: 11.000658988952637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/22

 11%|â–ˆ         | 22/200 [3:18:39<26:32:51, 536.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18405.342251090115
INFO:root:current train perplexity6.135315418243408
INFO:root:current mean train loss 18386.847041630244
INFO:root:current train perplexity6.12557315826416
INFO:root:current mean train loss 18391.736456725823
INFO:root:current train perplexity6.123114585876465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.57s/it]
INFO:root:final mean train loss: 18368.698817099295
INFO:root:final train perplexity: 6.121124744415283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it]
INFO:root:eval mean loss: 23120.900948660714
INFO:root:eval perplexity: 10.945337295532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/23

 12%|â–ˆâ–        | 23/200 [3:27:31<26:19:24, 535.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18317.874732730263
INFO:root:current train perplexity6.060240268707275
INFO:root:current mean train loss 18284.800560897434
INFO:root:current train perplexity6.055598258972168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.77s/it]
INFO:root:final mean train loss: 18262.682093466483
INFO:root:final train perplexity: 6.057450771331787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.33s/it]
INFO:root:eval mean loss: 23051.865094866072
INFO:root:eval perplexity: 10.867415428161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/24

 12%|â–ˆâ–        | 24/200 [3:36:28<26:11:44, 535.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18094.506856715427
INFO:root:current train perplexity5.976554870605469
INFO:root:current mean train loss 18155.657259778913
INFO:root:current train perplexity5.993333339691162
INFO:root:current mean train loss 18170.58924278846
INFO:root:current train perplexity5.995420455932617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.84s/it]
INFO:root:final mean train loss: 18157.34295457409
INFO:root:final train perplexity: 5.9948410987854
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:28<00:00, 88.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:28<00:00, 88.18s/it]
INFO:root:eval mean loss: 23038.395833333332
INFO:root:eval perplexity: 10.852273941040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/25

 12%|â–ˆâ–Ž        | 25/200 [3:45:53<26:28:28, 544.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18120.290147569445
INFO:root:current train perplexity5.961124420166016
INFO:root:current mean train loss 18096.407143137563
INFO:root:current train perplexity5.940659523010254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.36s/it]
INFO:root:final mean train loss: 18066.32994424143
INFO:root:final train perplexity: 5.9412665367126465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.24s/it]
INFO:root:eval mean loss: 22959.349679129464
INFO:root:eval perplexity: 10.76385498046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/26

 13%|â–ˆâ–Ž        | 26/200 [3:55:07<26:27:28, 547.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17994.94975490196
INFO:root:current train perplexity5.9094929695129395
INFO:root:current mean train loss 18005.955880070363
INFO:root:current train perplexity5.898390769958496


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.38s/it]
INFO:root:final mean train loss: 17976.648469002015
INFO:root:final train perplexity: 5.88894510269165
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.49s/it]
INFO:root:eval mean loss: 22919.471051897322
INFO:root:eval perplexity: 10.719521522521973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/27

 14%|â–ˆâ–Ž        | 27/200 [4:04:24<26:27:05, 550.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18096.229166666668
INFO:root:current train perplexity5.858877658843994
INFO:root:current mean train loss 17920.102491656555
INFO:root:current train perplexity5.852244853973389
INFO:root:current mean train loss 17914.587476908866
INFO:root:current train perplexity5.838589191436768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.52s/it]
INFO:root:final mean train loss: 17886.22939768145
INFO:root:final train perplexity: 5.836660861968994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.28s/it]
INFO:root:eval mean loss: 22877.157203311013
INFO:root:eval perplexity: 10.672677993774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/28

 14%|â–ˆâ–        | 28/200 [4:13:42<26:24:43, 552.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17883.51747159091
INFO:root:current train perplexity5.818923473358154
INFO:root:current mean train loss 17848.94056199597
INFO:root:current train perplexity5.801057815551758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.57s/it]
INFO:root:final mean train loss: 17809.109894783265
INFO:root:final train perplexity: 5.79243278503418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.88s/it]
INFO:root:eval mean loss: 22841.201218377977
INFO:root:eval perplexity: 10.633035659790039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/29

 14%|â–ˆâ–        | 29/200 [4:22:56<26:16:27, 553.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17819.563895089286
INFO:root:current train perplexity5.739843845367432
INFO:root:current mean train loss 17836.309688960282
INFO:root:current train perplexity5.755016803741455
INFO:root:current mean train loss 17775.65518380133
INFO:root:current train perplexity5.748966693878174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.50s/it]
INFO:root:final mean train loss: 17729.608563823083
INFO:root:final train perplexity: 5.747189044952393
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.75s/it]
INFO:root:eval mean loss: 22787.472330729168
INFO:root:eval perplexity: 10.574075698852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/30

 15%|â–ˆâ–Œ        | 30/200 [4:32:11<26:08:26, 553.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17677.02790651483
INFO:root:current train perplexity5.709103107452393
INFO:root:current mean train loss 17671.79599056604
INFO:root:current train perplexity5.705929756164551


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.25s/it]
INFO:root:final mean train loss: 17652.461004441786
INFO:root:final train perplexity: 5.7036237716674805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 22772.40955171131
INFO:root:eval perplexity: 10.557600975036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/31

 16%|â–ˆâ–Œ        | 31/200 [4:41:16<25:51:55, 550.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17488.599076704544
INFO:root:current train perplexity5.621086597442627
INFO:root:current mean train loss 17591.09125140766
INFO:root:current train perplexity5.648767948150635
INFO:root:current mean train loss 17594.630192905806
INFO:root:current train perplexity5.66674280166626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.57s/it]
INFO:root:final mean train loss: 17581.71000031502
INFO:root:final train perplexity: 5.6639604568481445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it]
INFO:root:eval mean loss: 22760.198800223214
INFO:root:eval perplexity: 10.544268608093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/32

 16%|â–ˆâ–Œ        | 32/200 [4:50:10<25:28:58, 546.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17506.83001612103
INFO:root:current train perplexity5.604204177856445
INFO:root:current mean train loss 17532.332258914877
INFO:root:current train perplexity5.627204418182373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.16s/it]
INFO:root:final mean train loss: 17510.520885836693
INFO:root:final train perplexity: 5.624329090118408
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.46s/it]
INFO:root:eval mean loss: 22729.567847842263
INFO:root:eval perplexity: 10.510893821716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/33

 16%|â–ˆâ–‹        | 33/200 [4:59:02<25:07:32, 541.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17288.856510416666
INFO:root:current train perplexity5.5395588874816895
INFO:root:current mean train loss 17444.79777513587
INFO:root:current train perplexity5.588108062744141
INFO:root:current mean train loss 17432.320575944766
INFO:root:current train perplexity5.578830718994141


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.62s/it]
INFO:root:final mean train loss: 17447.12470073085
INFO:root:final train perplexity: 5.589271068572998
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it]
INFO:root:eval mean loss: 22662.994791666668
INFO:root:eval perplexity: 10.438721656799316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/34

 17%|â–ˆâ–‹        | 34/200 [5:07:52<24:49:15, 538.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17388.128060867537
INFO:root:current train perplexity5.555104732513428
INFO:root:current mean train loss 17400.126169535928
INFO:root:current train perplexity5.552244186401367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.40s/it]
INFO:root:final mean train loss: 17382.794937626008
INFO:root:final train perplexity: 5.553919315338135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.74s/it]
INFO:root:eval mean loss: 22656.537039620536
INFO:root:eval perplexity: 10.431748390197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/35

 18%|â–ˆâ–Š        | 35/200 [5:16:52<24:41:40, 538.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17522.14689555921
INFO:root:current train perplexity5.580689907073975
INFO:root:current mean train loss 17364.546751903887
INFO:root:current train perplexity5.532085418701172
INFO:root:current mean train loss 17338.498724671805
INFO:root:current train perplexity5.5194268226623535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.10s/it]
INFO:root:final mean train loss: 17322.986958165322
INFO:root:final train perplexity: 5.5212531089782715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.39s/it]
INFO:root:eval mean loss: 22640.85974702381
INFO:root:eval perplexity: 10.414836883544922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/36

 18%|â–ˆâ–Š        | 36/200 [5:25:57<24:37:59, 540.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17237.957787742078
INFO:root:current train perplexity5.4742608070373535
INFO:root:current mean train loss 17254.671760782163
INFO:root:current train perplexity5.487328052520752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.73s/it]
INFO:root:final mean train loss: 17262.717281218498
INFO:root:final train perplexity: 5.488529682159424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.33s/it]
INFO:root:eval mean loss: 22620.88904389881
INFO:root:eval perplexity: 10.393330574035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/37

 18%|â–ˆâ–Š        | 37/200 [5:34:41<24:14:58, 535.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17136.673403532608
INFO:root:current train perplexity5.422074317932129
INFO:root:current mean train loss 17160.39619855183
INFO:root:current train perplexity5.44970703125
INFO:root:current mean train loss 17231.521677059976
INFO:root:current train perplexity5.464648246765137


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.47s/it]
INFO:root:final mean train loss: 17214.765471427672
INFO:root:final train perplexity: 5.4626336097717285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.07s/it]
INFO:root:eval mean loss: 22589.209542410714
INFO:root:eval perplexity: 10.359314918518066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/38

 19%|â–ˆâ–‰        | 38/200 [5:43:29<24:00:01, 533.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17174.221796875
INFO:root:current train perplexity5.4228057861328125
INFO:root:current mean train loss 17157.122332589286
INFO:root:current train perplexity5.424006462097168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.48s/it]
INFO:root:final mean train loss: 17153.005946005545
INFO:root:final train perplexity: 5.429458141326904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.50s/it]
INFO:root:eval mean loss: 22577.24060639881
INFO:root:eval perplexity: 10.346487045288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/39

 20%|â–ˆâ–‰        | 39/200 [5:52:23<23:51:23, 533.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17019.929759837964
INFO:root:current train perplexity5.363894939422607
INFO:root:current mean train loss 17110.28228038878
INFO:root:current train perplexity5.403839588165283
INFO:root:current mean train loss 17113.161111302314
INFO:root:current train perplexity5.401827335357666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.19s/it]
INFO:root:final mean train loss: 17104.887411794356
INFO:root:final train perplexity: 5.403750419616699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.41s/it]
INFO:root:eval mean loss: 22574.86258370536
INFO:root:eval perplexity: 10.343941688537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/40

 20%|â–ˆâ–ˆ        | 40/200 [6:01:15<23:41:27, 533.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17098.499950553796
INFO:root:current train perplexity5.386560916900635
INFO:root:current mean train loss 17106.182262569833
INFO:root:current train perplexity5.389155864715576


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.25s/it]
INFO:root:final mean train loss: 17050.881694178428
INFO:root:final train perplexity: 5.37504243850708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.46s/it]
INFO:root:eval mean loss: 22530.20386904762
INFO:root:eval perplexity: 10.296244621276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/41

 20%|â–ˆâ–ˆ        | 41/200 [6:10:04<23:29:35, 531.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16916.502394153227
INFO:root:current train perplexity5.312870979309082
INFO:root:current mean train loss 16980.547695014313
INFO:root:current train perplexity5.334448337554932
INFO:root:current mean train loss 17023.342976359578
INFO:root:current train perplexity5.349578857421875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.55s/it]
INFO:root:final mean train loss: 17002.867967174898
INFO:root:final train perplexity: 5.349647521972656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.12s/it]
INFO:root:eval mean loss: 22516.046968005954
INFO:root:eval perplexity: 10.281168937683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/42

 21%|â–ˆâ–ˆ        | 42/200 [6:19:02<23:25:29, 533.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16948.786697571537
INFO:root:current train perplexity5.323439598083496
INFO:root:current mean train loss 16981.049505848703
INFO:root:current train perplexity5.326550006866455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.84s/it]
INFO:root:final mean train loss: 16954.14420441658
INFO:root:final train perplexity: 5.324001789093018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.34s/it]
INFO:root:eval mean loss: 22521.474260602678
INFO:root:eval perplexity: 10.286942481994629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/43

 22%|â–ˆâ–ˆâ–       | 43/200 [6:27:59<23:19:08, 534.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17049.489676339286
INFO:root:current train perplexity5.34226131439209
INFO:root:current mean train loss 16961.809686053242
INFO:root:current train perplexity5.305889129638672
INFO:root:current mean train loss 16924.433784906916
INFO:root:current train perplexity5.301098823547363


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.13s/it]
INFO:root:final mean train loss: 16908.657273815523
INFO:root:final train perplexity: 5.300168991088867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.84s/it]
INFO:root:eval mean loss: 22505.085309709822
INFO:root:eval perplexity: 10.269512176513672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/44

 22%|â–ˆâ–ˆâ–       | 44/200 [6:36:52<23:09:03, 534.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16854.616805854886
INFO:root:current train perplexity5.265778064727783
INFO:root:current mean train loss 16875.094757896055
INFO:root:current train perplexity5.273255348205566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.75s/it]
INFO:root:final mean train loss: 16864.231665826614
INFO:root:final train perplexity: 5.276995658874512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.72s/it]
INFO:root:eval mean loss: 22490.11495535714
INFO:root:eval perplexity: 10.253612518310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [6:45:51<23:03:46, 535.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16860.08991887019
INFO:root:current train perplexity5.26654052734375
INFO:root:current mean train loss 16826.87984768435
INFO:root:current train perplexity5.2560834884643555
INFO:root:current mean train loss 16834.41401755361
INFO:root:current train perplexity5.254129409790039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.05s/it]
INFO:root:final mean train loss: 16818.385226341987
INFO:root:final train perplexity: 5.25318717956543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.71s/it]
INFO:root:eval mean loss: 22469.16720145089
INFO:root:eval perplexity: 10.231404304504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [6:54:44<22:52:50, 534.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16820.58004593063
INFO:root:current train perplexity5.231374263763428
INFO:root:current mean train loss 16806.082614119765
INFO:root:current train perplexity5.234728813171387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.99s/it]
INFO:root:final mean train loss: 16775.91780730217
INFO:root:final train perplexity: 5.231229305267334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.66s/it]
INFO:root:eval mean loss: 22459.95300874256
INFO:root:eval perplexity: 10.221653938293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:03:32<22:38:44, 532.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16754.618232194767
INFO:root:current train perplexity5.215683937072754
INFO:root:current mean train loss 16756.977853201486
INFO:root:current train perplexity5.213825702667236
INFO:root:current mean train loss 16750.89508584105
INFO:root:current train perplexity5.213235855102539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.53s/it]
INFO:root:final mean train loss: 16740.549867691534
INFO:root:final train perplexity: 5.213012218475342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it]
INFO:root:eval mean loss: 22468.85916573661
INFO:root:eval perplexity: 10.231077194213867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/48

 24%|â–ˆâ–ˆâ–       | 48/200 [7:12:38<22:39:55, 536.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16678.21540912829
INFO:root:current train perplexity5.172896862030029
INFO:root:current mean train loss 16693.43615284455
INFO:root:current train perplexity5.180360317230225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.81s/it]
INFO:root:final mean train loss: 16696.100987588205
INFO:root:final train perplexity: 5.190207481384277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it]
INFO:root:eval mean loss: 22425.02322823661
INFO:root:eval perplexity: 10.184767723083496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/49

 24%|â–ˆâ–ˆâ–       | 49/200 [7:21:31<22:27:41, 535.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16700.953478224736
INFO:root:current train perplexity5.1581902503967285
INFO:root:current mean train loss 16668.01996306335
INFO:root:current train perplexity5.168686866760254
INFO:root:current mean train loss 16670.055525683198
INFO:root:current train perplexity5.171051502227783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.53s/it]
INFO:root:final mean train loss: 16659.533687468498
INFO:root:final train perplexity: 5.171522617340088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.38s/it]
INFO:root:eval mean loss: 22429.376069568454
INFO:root:eval perplexity: 10.189358711242676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [7:30:23<22:16:21, 534.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16641.198646622473
INFO:root:current train perplexity5.141124725341797
INFO:root:current mean train loss 16611.9954361652
INFO:root:current train perplexity5.151151180267334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.88s/it]
INFO:root:final mean train loss: 16624.315847089212
INFO:root:final train perplexity: 5.153589248657227
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it]
INFO:root:eval mean loss: 22420.79552641369
INFO:root:eval perplexity: 10.180313110351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [7:39:10<22:01:42, 532.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16601.20201439951
INFO:root:current train perplexity5.131217956542969
INFO:root:current mean train loss 16605.70687603477
INFO:root:current train perplexity5.132274627685547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.97s/it]
INFO:root:final mean train loss: 16584.975845829133
INFO:root:final train perplexity: 5.133631229400635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.15s/it]
INFO:root:eval mean loss: 22419.626278831845
INFO:root:eval perplexity: 10.17908000946045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [7:48:01<21:51:43, 531.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16677.335286458332
INFO:root:current train perplexity5.245378494262695
INFO:root:current mean train loss 16518.50783146238
INFO:root:current train perplexity5.099085330963135
INFO:root:current mean train loss 16557.212919488917
INFO:root:current train perplexity5.113894939422607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.92s/it]
INFO:root:final mean train loss: 16548.753622731856
INFO:root:final train perplexity: 5.115323066711426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it]
INFO:root:eval mean loss: 22398.056687127977
INFO:root:eval perplexity: 10.15638256072998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [7:56:54<21:44:05, 532.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16508.63203125
INFO:root:current train perplexity5.106171607971191
INFO:root:current mean train loss 16560.421881300404
INFO:root:current train perplexity5.11311149597168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.47s/it]
INFO:root:final mean train loss: 16515.160026304184
INFO:root:final train perplexity: 5.098402500152588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.04s/it]
INFO:root:eval mean loss: 22394.769019717263
INFO:root:eval perplexity: 10.152925491333008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:05:42<21:31:58, 530.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16343.256417410714
INFO:root:current train perplexity5.076745986938477
INFO:root:current mean train loss 16480.95944983937
INFO:root:current train perplexity5.084218978881836
INFO:root:current mean train loss 16480.825676517212
INFO:root:current train perplexity5.084038257598877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.90s/it]
INFO:root:final mean train loss: 16478.896358366936
INFO:root:final train perplexity: 5.080199241638184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it]
INFO:root:eval mean loss: 22372.22302827381
INFO:root:eval perplexity: 10.129264831542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [8:14:42<21:29:23, 533.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16482.341581700213
INFO:root:current train perplexity5.060969352722168
INFO:root:current mean train loss 16424.923785131683
INFO:root:current train perplexity5.055558681488037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.66s/it]
INFO:root:final mean train loss: 16443.79585512223
INFO:root:final train perplexity: 5.062641620635986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.19s/it]
INFO:root:eval mean loss: 22378.32005673363
INFO:root:eval perplexity: 10.13565731048584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [8:23:27<21:14:41, 531.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16560.944602272728
INFO:root:current train perplexity5.091327667236328
INFO:root:current mean train loss 16398.352363105292
INFO:root:current train perplexity5.038498878479004
INFO:root:current mean train loss 16440.495978043542
INFO:root:current train perplexity5.0507354736328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.37s/it]
INFO:root:final mean train loss: 16410.186535250756
INFO:root:final train perplexity: 5.0458855628967285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it]
INFO:root:eval mean loss: 22377.86876860119
INFO:root:eval perplexity: 10.135185241699219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:32:18<21:05:50, 531.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16363.252914186507
INFO:root:current train perplexity5.012558937072754
INFO:root:current mean train loss 16390.517464292563
INFO:root:current train perplexity5.032113552093506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.84s/it]
INFO:root:final mean train loss: 16385.925710370462
INFO:root:final train perplexity: 5.0338263511657715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it]
INFO:root:eval mean loss: 22366.516927083332
INFO:root:eval perplexity: 10.123287200927734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:41:07<20:55:31, 530.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16350.293359375
INFO:root:current train perplexity5.02256441116333
INFO:root:current mean train loss 16297.164070991848
INFO:root:current train perplexity4.99092960357666
INFO:root:current mean train loss 16333.773950763081
INFO:root:current train perplexity5.009698867797852


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.53s/it]
INFO:root:final mean train loss: 16350.723644625756
INFO:root:final train perplexity: 5.016379356384277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it]
INFO:root:eval mean loss: 22363.445661272322
INFO:root:eval perplexity: 10.120067596435547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [8:49:56<20:45:14, 529.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16325.111605060634
INFO:root:current train perplexity4.9826765060424805
INFO:root:current mean train loss 16323.56071061003
INFO:root:current train perplexity5.001699924468994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.21s/it]
INFO:root:final mean train loss: 16320.515451738911
INFO:root:final train perplexity: 5.001454830169678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.00s/it]
INFO:root:eval mean loss: 22354.98070126488
INFO:root:eval perplexity: 10.111207008361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [8:58:44<20:35:27, 529.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16267.148077713815
INFO:root:current train perplexity4.983492374420166
INFO:root:current mean train loss 16261.350700827206
INFO:root:current train perplexity4.978390693664551
INFO:root:current mean train loss 16289.618663491723
INFO:root:current train perplexity4.98347282409668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.77s/it]
INFO:root:final mean train loss: 16292.60653981855
INFO:root:final train perplexity: 4.987706184387207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it]
INFO:root:eval mean loss: 22343.985002790178
INFO:root:eval perplexity: 10.09970474243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [9:07:43<20:33:06, 532.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16292.134916923416
INFO:root:current train perplexity4.977296352386475
INFO:root:current mean train loss 16292.024556834795
INFO:root:current train perplexity4.9761881828308105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.68s/it]
INFO:root:final mean train loss: 16262.640920331402
INFO:root:final train perplexity: 4.972986698150635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it]
INFO:root:eval mean loss: 22343.31519717262
INFO:root:eval perplexity: 10.099003791809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [9:17:02<20:42:26, 540.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16160.623301630434
INFO:root:current train perplexity4.926379680633545
INFO:root:current mean train loss 16248.892506669208
INFO:root:current train perplexity4.952579498291016
INFO:root:current mean train loss 16250.193538922365
INFO:root:current train perplexity4.96138858795166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.34s/it]
INFO:root:final mean train loss: 16234.179459110383
INFO:root:final train perplexity: 4.959045886993408
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it]
INFO:root:eval mean loss: 22341.412946428572
INFO:root:eval perplexity: 10.097015380859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [9:25:58<20:30:31, 538.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16189.8079296875
INFO:root:current train perplexity4.944218635559082
INFO:root:current mean train loss 16221.541908482142
INFO:root:current train perplexity4.938578128814697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.57s/it]
INFO:root:final mean train loss: 16202.345340851814
INFO:root:final train perplexity: 4.94350004196167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.73s/it]
INFO:root:eval mean loss: 22329.805478050595
INFO:root:eval perplexity: 10.084892272949219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:35:10<20:30:42, 542.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16293.169596354166
INFO:root:current train perplexity4.9463911056518555
INFO:root:current mean train loss 16164.910271592027
INFO:root:current train perplexity4.922114849090576
INFO:root:current mean train loss 16184.417284726047
INFO:root:current train perplexity4.929732799530029


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.51s/it]
INFO:root:final mean train loss: 16175.468112084174
INFO:root:final train perplexity: 4.9304118156433105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it]
INFO:root:eval mean loss: 22330.984188988095
INFO:root:eval perplexity: 10.086126327514648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [9:44:19<20:25:52, 544.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16167.35802759098
INFO:root:current train perplexity4.912149429321289
INFO:root:current mean train loss 16162.452213905377
INFO:root:current train perplexity4.916364669799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.60s/it]
INFO:root:final mean train loss: 16152.41839796497
INFO:root:final train perplexity: 4.919214725494385
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.38s/it]
INFO:root:eval mean loss: 22328.785714285714
INFO:root:eval perplexity: 10.083829879760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [9:53:31<20:21:28, 546.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16066.809034778225
INFO:root:current train perplexity4.869234561920166
INFO:root:current mean train loss 16139.647684577767
INFO:root:current train perplexity4.900119781494141
INFO:root:current mean train loss 16134.028248444263
INFO:root:current train perplexity4.904728412628174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.95s/it]
INFO:root:final mean train loss: 16125.120459771926
INFO:root:final train perplexity: 4.905989170074463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.54s/it]
INFO:root:eval mean loss: 22320.92517671131
INFO:root:eval perplexity: 10.075627326965332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [10:02:36<20:10:44, 546.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16102.504188629518
INFO:root:current train perplexity4.885359287261963
INFO:root:current mean train loss 16111.204165599385
INFO:root:current train perplexity4.887714385986328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.23s/it]
INFO:root:final mean train loss: 16099.074537707913
INFO:root:final train perplexity: 4.893401622772217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.34s/it]
INFO:root:eval mean loss: 22320.87569754464
INFO:root:eval perplexity: 10.075576782226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [10:11:48<20:05:28, 547.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16155.410435267857
INFO:root:current train perplexity4.899942874908447
INFO:root:current mean train loss 16097.367433449073
INFO:root:current train perplexity4.881052494049072
INFO:root:current mean train loss 16093.618101728724
INFO:root:current train perplexity4.881992816925049


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.81s/it]
INFO:root:final mean train loss: 16075.096116588962
INFO:root:final train perplexity: 4.881842136383057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it]
INFO:root:eval mean loss: 22321.478910900296
INFO:root:eval perplexity: 10.07620620727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [10:20:53<19:54:53, 547.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16038.70269845546
INFO:root:current train perplexity4.868607997894287
INFO:root:current mean train loss 16027.21590909091
INFO:root:current train perplexity4.865000247955322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.00s/it]
INFO:root:final mean train loss: 16046.97029359879
INFO:root:final train perplexity: 4.868317604064941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.04s/it]
INFO:root:eval mean loss: 22329.486909412204
INFO:root:eval perplexity: 10.084558486938477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [10:30:09<19:51:22, 549.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15927.443083934295
INFO:root:current train perplexity4.8487749099731445
INFO:root:current mean train loss 15986.527561544515
INFO:root:current train perplexity4.841838836669922
INFO:root:current mean train loss 16028.834911905073
INFO:root:current train perplexity4.853282451629639


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.21s/it]
INFO:root:final mean train loss: 16023.192146547379
INFO:root:final train perplexity: 4.8569135665893555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it]
INFO:root:eval mean loss: 22316.259812127977
INFO:root:eval perplexity: 10.070764541625977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [10:39:03<19:31:55, 545.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15975.33902815934
INFO:root:current train perplexity4.829946994781494
INFO:root:current mean train loss 15990.28466029941
INFO:root:current train perplexity4.837573051452637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.08s/it]
INFO:root:final mean train loss: 15998.504382717994
INFO:root:final train perplexity: 4.845101833343506
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.88s/it]
INFO:root:eval mean loss: 22308.166968936013
INFO:root:eval perplexity: 10.062335014343262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [10:47:58<19:16:17, 542.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16009.15609102471
INFO:root:current train perplexity4.825150489807129
INFO:root:current mean train loss 15990.628120902535
INFO:root:current train perplexity4.834583282470703
INFO:root:current mean train loss 15992.755280671296
INFO:root:current train perplexity4.835757255554199


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.13s/it]
INFO:root:final mean train loss: 15979.20365265877
INFO:root:final train perplexity: 4.8358869552612305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.74s/it]
INFO:root:eval mean loss: 22315.651018415178
INFO:root:eval perplexity: 10.070133209228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [10:57:02<19:08:36, 542.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15943.411513157895
INFO:root:current train perplexity4.815229415893555
INFO:root:current mean train loss 15957.586853966346
INFO:root:current train perplexity4.822813034057617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.42s/it]
INFO:root:final mean train loss: 15952.32759734123
INFO:root:final train perplexity: 4.823084354400635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.72s/it]
INFO:root:eval mean loss: 22313.349539620536
INFO:root:eval perplexity: 10.067731857299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [11:06:11<19:03:30, 544.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15930.474734042553
INFO:root:current train perplexity4.801599502563477
INFO:root:current mean train loss 15922.511612457483
INFO:root:current train perplexity4.797425270080566
INFO:root:current mean train loss 15942.037836854757
INFO:root:current train perplexity4.81178617477417


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.27s/it]
INFO:root:final mean train loss: 15929.554904076362
INFO:root:final train perplexity: 4.812263488769531
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it]
INFO:root:eval mean loss: 22315.059640066964
INFO:root:eval perplexity: 10.069513320922852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [11:15:02<18:45:54, 540.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15909.685576467804
INFO:root:current train perplexity4.79650354385376
INFO:root:current mean train loss 15915.625745917085
INFO:root:current train perplexity4.799723148345947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.86s/it]
INFO:root:final mean train loss: 15906.922233335434
INFO:root:final train perplexity: 4.801533222198486
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it]
INFO:root:eval mean loss: 22308.00558035714
INFO:root:eval perplexity: 10.062167167663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [11:23:59<18:34:35, 539.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15873.68638939951
INFO:root:current train perplexity4.7887091636657715
INFO:root:current mean train loss 15901.70170866101
INFO:root:current train perplexity4.789876461029053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.37s/it]
INFO:root:final mean train loss: 15882.365616336945
INFO:root:final train perplexity: 4.789917945861816
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it]
INFO:root:eval mean loss: 22327.821963355655
INFO:root:eval perplexity: 10.08282470703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [11:32:56<18:24:26, 538.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15478.71875
INFO:root:current train perplexity4.663720607757568
INFO:root:current mean train loss 15874.057048316141
INFO:root:current train perplexity4.7752180099487305
INFO:root:current mean train loss 15865.244790063116
INFO:root:current train perplexity4.776997089385986


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.55s/it]
INFO:root:final mean train loss: 15864.486611643146
INFO:root:final train perplexity: 4.781477928161621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.09s/it]
INFO:root:eval mean loss: 22306.748883928572
INFO:root:eval perplexity: 10.060857772827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [11:41:48<18:11:01, 536.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15818.458913352273
INFO:root:current train perplexity4.775649070739746
INFO:root:current mean train loss 15839.344096522178
INFO:root:current train perplexity4.769320011138916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.28s/it]
INFO:root:final mean train loss: 15842.786995180191
INFO:root:final train perplexity: 4.771255970001221
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it]
INFO:root:eval mean loss: 22309.973214285714
INFO:root:eval perplexity: 10.064216613769531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [11:50:37<17:57:58, 534.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15790.04115513393
INFO:root:current train perplexity4.742513656616211
INFO:root:current mean train loss 15848.791700131425
INFO:root:current train perplexity4.7616190910339355
INFO:root:current mean train loss 15852.543053668478
INFO:root:current train perplexity4.768047332763672


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.30s/it]
INFO:root:final mean train loss: 15824.778623519405
INFO:root:final train perplexity: 4.762787818908691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it]
INFO:root:eval mean loss: 22305.083891369046
INFO:root:eval perplexity: 10.059125900268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [11:59:24<17:44:12, 532.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15757.802601959746
INFO:root:current train perplexity4.732322692871094
INFO:root:current mean train loss 15795.624539357312
INFO:root:current train perplexity4.745347499847412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.89s/it]
INFO:root:final mean train loss: 15804.84099751134
INFO:root:final train perplexity: 4.75343132019043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.16s/it]
INFO:root:eval mean loss: 22312.687523251487
INFO:root:eval perplexity: 10.06704330444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [12:08:13<17:33:41, 531.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15871.628462357954
INFO:root:current train perplexity4.814977169036865
INFO:root:current mean train loss 15814.018730644708
INFO:root:current train perplexity4.742197036743164
INFO:root:current mean train loss 15814.542195830865
INFO:root:current train perplexity4.744113445281982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.40s/it]
INFO:root:final mean train loss: 15783.796185893398
INFO:root:final train perplexity: 4.743575096130371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.44s/it]
INFO:root:eval mean loss: 22313.48302641369
INFO:root:eval perplexity: 10.06787109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [12:17:03<17:23:59, 530.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15751.164806547618
INFO:root:current train perplexity4.727878093719482
INFO:root:current mean train loss 15760.227023820935
INFO:root:current train perplexity4.737452983856201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.34s/it]
INFO:root:final mean train loss: 15762.695414881553
INFO:root:final train perplexity: 4.733713150024414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.27s/it]
INFO:root:eval mean loss: 22304.984026227678
INFO:root:eval perplexity: 10.0590181350708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [12:25:52<17:13:49, 530.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15754.926888020833
INFO:root:current train perplexity4.697534084320068
INFO:root:current mean train loss 15734.084171195653
INFO:root:current train perplexity4.7227277755737305
INFO:root:current mean train loss 15758.479755632268
INFO:root:current train perplexity4.7268171310424805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.30s/it]
INFO:root:final mean train loss: 15745.260033392136
INFO:root:final train perplexity: 4.725578784942627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.11s/it]
INFO:root:eval mean loss: 22315.32654389881
INFO:root:eval perplexity: 10.069794654846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [12:34:56<17:13:05, 534.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15680.430897271455
INFO:root:current train perplexity4.702109336853027
INFO:root:current mean train loss 15729.388777133234
INFO:root:current train perplexity4.713387966156006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.66s/it]
INFO:root:final mean train loss: 15724.978200604839
INFO:root:final train perplexity: 4.716135501861572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.78s/it]
INFO:root:eval mean loss: 22297.21826171875
INFO:root:eval perplexity: 10.050941467285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [12:43:48<17:02:53, 533.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15489.627107319078
INFO:root:current train perplexity4.694991588592529
INFO:root:current mean train loss 15729.465557707457
INFO:root:current train perplexity4.7075676918029785
INFO:root:current mean train loss 15721.047989797375
INFO:root:current train perplexity4.707239627838135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.20s/it]
INFO:root:final mean train loss: 15708.693406628025
INFO:root:final train perplexity: 4.708566188812256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.23s/it]
INFO:root:eval mean loss: 22307.962076822918
INFO:root:eval perplexity: 10.062121391296387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [12:52:52<17:00:13, 536.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15633.067726672536
INFO:root:current train perplexity4.6979851722717285
INFO:root:current mean train loss 15684.4114126462
INFO:root:current train perplexity4.696691513061523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it]
INFO:root:final mean train loss: 15691.086161951866
INFO:root:final train perplexity: 4.700396537780762
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.54s/it]
INFO:root:eval mean loss: 22305.35379464286
INFO:root:eval perplexity: 10.059401512145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [13:01:42<16:47:02, 534.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15722.309145720108
INFO:root:current train perplexity4.690845012664795
INFO:root:current mean train loss 15677.783790650406
INFO:root:current train perplexity4.688726902008057
INFO:root:current mean train loss 15683.555992502803
INFO:root:current train perplexity4.6917595863342285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.90s/it]
INFO:root:final mean train loss: 15672.480764081402
INFO:root:final train perplexity: 4.691778659820557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.84s/it]
INFO:root:eval mean loss: 22313.07198660714
INFO:root:eval perplexity: 10.067441940307617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [13:10:37<16:38:31, 534.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15654.165364583334
INFO:root:current train perplexity4.670367240905762
INFO:root:current mean train loss 15646.118186383928
INFO:root:current train perplexity4.6773247718811035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.99s/it]
INFO:root:final mean train loss: 15654.00580030872
INFO:root:final train perplexity: 4.683237075805664
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.84s/it]
INFO:root:eval mean loss: 22296.291689918155
INFO:root:eval perplexity: 10.049973487854004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [13:19:36<16:31:37, 536.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15612.011791087964
INFO:root:current train perplexity4.666377544403076
INFO:root:current mean train loss 15595.728500246063
INFO:root:current train perplexity4.6570820808410645
INFO:root:current mean train loss 15634.998167332049
INFO:root:current train perplexity4.670751094818115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.19s/it]
INFO:root:final mean train loss: 15636.457523469002
INFO:root:final train perplexity: 4.675138473510742
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it]
INFO:root:eval mean loss: 22318.706891741072
INFO:root:eval perplexity: 10.07331657409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [13:28:22<16:17:18, 533.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15679.829497132121
INFO:root:current train perplexity4.670582294464111
INFO:root:current mean train loss 15621.36659283345
INFO:root:current train perplexity4.664872169494629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.43s/it]
INFO:root:final mean train loss: 15618.309404926915
INFO:root:final train perplexity: 4.66677713394165
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.97s/it]
INFO:root:eval mean loss: 22295.56824311756
INFO:root:eval perplexity: 10.049222946166992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/91
######################best################
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [13:37:12<16:06:29, 532.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15621.609438004032
INFO:root:current train perplexity4.668248176574707
INFO:root:current mean train loss 15600.203654281966
INFO:root:current train perplexity4.662017345428467
INFO:root:current mean train loss 15611.717228084415
INFO:root:current train perplexity4.660420894622803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.62s/it]
INFO:root:final mean train loss: 15600.929132276966
INFO:root:final train perplexity: 4.658783912658691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.03s/it]
INFO:root:eval mean loss: 22321.182803199405
INFO:root:eval perplexity: 10.075899124145508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [13:46:00<15:55:47, 530.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15612.791074454066
INFO:root:current train perplexity4.657190322875977
INFO:root:current mean train loss 15593.479310749659
INFO:root:current train perplexity4.649874210357666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.81s/it]
INFO:root:final mean train loss: 15583.61365139869
INFO:root:final train perplexity: 4.650834560394287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.27s/it]
INFO:root:eval mean loss: 22304.17015438988
INFO:root:eval perplexity: 10.058174133300781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [13:54:41<15:41:36, 528.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15547.979129464286
INFO:root:current train perplexity4.609508514404297
INFO:root:current mean train loss 15550.1267578125
INFO:root:current train perplexity4.6359710693359375
INFO:root:current mean train loss 15574.823150764627
INFO:root:current train perplexity4.641221523284912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.13s/it]
INFO:root:final mean train loss: 15565.903099798386
INFO:root:final train perplexity: 4.642716407775879
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.54s/it]
INFO:root:eval mean loss: 22315.418387276786
INFO:root:eval perplexity: 10.0698881149292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [14:03:34<15:35:14, 529.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15583.935468301006
INFO:root:current train perplexity4.630520820617676
INFO:root:current mean train loss 15572.69670684325
INFO:root:current train perplexity4.638522148132324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.20s/it]
INFO:root:final mean train loss: 15552.09267893145
INFO:root:final train perplexity: 4.636397838592529
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.10s/it]
INFO:root:eval mean loss: 22303.893601190477
INFO:root:eval perplexity: 10.057886123657227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [14:12:42<15:36:16, 535.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15484.45427684295
INFO:root:current train perplexity4.5855393409729
INFO:root:current mean train loss 15540.901851955936
INFO:root:current train perplexity4.614260673522949
INFO:root:current mean train loss 15560.845809361925
INFO:root:current train perplexity4.63027286529541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 468.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 468.00s/it]
INFO:root:final mean train loss: 15538.82601830267
INFO:root:final train perplexity: 4.630334377288818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.17s/it]
INFO:root:eval mean loss: 22315.985653831845
INFO:root:eval perplexity: 10.070478439331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [14:21:47<15:32:30, 537.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15568.838266225961
INFO:root:current train perplexity4.629929542541504
INFO:root:current mean train loss 15522.899424288285
INFO:root:current train perplexity4.622747421264648


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.76s/it]
INFO:root:final mean train loss: 15522.264912266884
INFO:root:final train perplexity: 4.622777462005615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.70s/it]
INFO:root:eval mean loss: 22329.954520089286
INFO:root:eval perplexity: 10.085050582885742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [14:30:34<15:18:00, 534.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15502.894894622093
INFO:root:current train perplexity4.621979713439941
INFO:root:current mean train loss 15522.29092684659
INFO:root:current train perplexity4.620614051818848
INFO:root:current mean train loss 15516.240061567643
INFO:root:current train perplexity4.61625337600708


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.30s/it]
INFO:root:final mean train loss: 15506.419417842742
INFO:root:final train perplexity: 4.61555814743042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it]
INFO:root:eval mean loss: 22319.495930989582
INFO:root:eval perplexity: 10.074140548706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [14:39:32<15:10:34, 535.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15543.139113898027
INFO:root:current train perplexity4.611203670501709
INFO:root:current mean train loss 15507.354311899038
INFO:root:current train perplexity4.609158039093018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.91s/it]
INFO:root:final mean train loss: 15494.149457377773
INFO:root:final train perplexity: 4.609975814819336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.93s/it]
INFO:root:eval mean loss: 22316.378580729168
INFO:root:eval perplexity: 10.070889472961426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [14:48:21<14:58:35, 533.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15409.18569232048
INFO:root:current train perplexity4.556943893432617
INFO:root:current mean train loss 15465.76120057398
INFO:root:current train perplexity4.588343143463135
INFO:root:current mean train loss 15482.697767744181
INFO:root:current train perplexity4.599228382110596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.51s/it]
INFO:root:final mean train loss: 15471.737068422379
INFO:root:final train perplexity: 4.599795818328857
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it]
INFO:root:eval mean loss: 22321.158389136905
INFO:root:eval perplexity: 10.075872421264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [14:57:11<14:47:46, 532.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15413.088709359217
INFO:root:current train perplexity4.577693462371826
INFO:root:current mean train loss 15481.217950102073
INFO:root:current train perplexity4.595057487487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.97s/it]
INFO:root:final mean train loss: 15462.186499810989
INFO:root:final train perplexity: 4.595464706420898
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.13s/it]
INFO:root:eval mean loss: 22312.125302269345
INFO:root:eval perplexity: 10.066454887390137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [15:06:15<14:44:10, 535.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15498.935049019608
INFO:root:current train perplexity4.583752155303955
INFO:root:current mean train loss 15470.329062758692
INFO:root:current train perplexity4.589141845703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.11s/it]
INFO:root:final mean train loss: 15447.150843466481
INFO:root:final train perplexity: 4.5886549949646
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.94s/it]
INFO:root:eval mean loss: 22320.125651041668
INFO:root:eval perplexity: 10.074793815612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [15:15:21<14:40:14, 538.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15472.662434895834
INFO:root:current train perplexity4.507566928863525
INFO:root:current mean train loss 15460.240566216626
INFO:root:current train perplexity4.572999477386475
INFO:root:current mean train loss 15424.030129117918
INFO:root:current train perplexity4.573216438293457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.10s/it]
INFO:root:final mean train loss: 15425.549009261593
INFO:root:final train perplexity: 4.578888893127441
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it]
INFO:root:eval mean loss: 22305.861793154763
INFO:root:eval perplexity: 10.05993366241455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [15:24:28<14:35:22, 541.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15402.1431640625
INFO:root:current train perplexity4.552983283996582
INFO:root:current mean train loss 15414.91704889113
INFO:root:current train perplexity4.57333517074585


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.21s/it]
INFO:root:final mean train loss: 15421.08341733871
INFO:root:final train perplexity: 4.5768723487854
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.13s/it]
INFO:root:eval mean loss: 22317.118303571428
INFO:root:eval perplexity: 10.071660041809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [15:33:27<14:25:17, 540.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15240.12193080357
INFO:root:current train perplexity4.5201215744018555
INFO:root:current mean train loss 15326.228296582944
INFO:root:current train perplexity4.551621913909912
INFO:root:current mean train loss 15411.747636435688
INFO:root:current train perplexity4.570136070251465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.66s/it]
INFO:root:final mean train loss: 15401.908029863911
INFO:root:final train perplexity: 4.5682244300842285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.80s/it]
INFO:root:eval mean loss: 22319.01341610863
INFO:root:eval perplexity: 10.073636054992676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [15:42:34<14:19:00, 542.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15399.684090307202
INFO:root:current train perplexity4.564727306365967
INFO:root:current mean train loss 15430.203585642688
INFO:root:current train perplexity4.566899299621582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.02s/it]
INFO:root:final mean train loss: 15389.211701423892
INFO:root:final train perplexity: 4.562507152557373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.90s/it]
INFO:root:eval mean loss: 22323.91917782738
INFO:root:eval perplexity: 10.078753471374512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [15:51:37<14:10:10, 542.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15129.631125710228
INFO:root:current train perplexity4.52380895614624
INFO:root:current mean train loss 15350.344304265203
INFO:root:current train perplexity4.544034004211426
INFO:root:current mean train loss 15390.335618150179
INFO:root:current train perplexity4.556928634643555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it]
INFO:root:final mean train loss: 15380.983835527973
INFO:root:final train perplexity: 4.5588059425354
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.44s/it]
INFO:root:eval mean loss: 22313.912946428572
INFO:root:eval perplexity: 10.068320274353027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [16:00:46<14:04:12, 544.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15331.502681671627
INFO:root:current train perplexity4.542090892791748
INFO:root:current mean train loss 15368.315561493482
INFO:root:current train perplexity4.549057483673096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.83s/it]
INFO:root:final mean train loss: 15362.713461599042
INFO:root:final train perplexity: 4.550599098205566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it]
INFO:root:eval mean loss: 22325.395484561013
INFO:root:eval perplexity: 10.080291748046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [16:09:54<13:56:22, 545.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15077.784635416667
INFO:root:current train perplexity4.513601303100586
INFO:root:current mean train loss 15329.136268682065
INFO:root:current train perplexity4.535126686096191
INFO:root:current mean train loss 15351.18304414971
INFO:root:current train perplexity4.539637565612793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.24s/it]
INFO:root:final mean train loss: 15348.571064610634
INFO:root:final train perplexity: 4.544255256652832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it]
INFO:root:eval mean loss: 22327.83875093006
INFO:root:eval perplexity: 10.082839012145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [16:18:53<13:44:28, 543.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15269.219580806903
INFO:root:current train perplexity4.521938323974609
INFO:root:current mean train loss 15333.457744666915
INFO:root:current train perplexity4.53961706161499


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.34s/it]
INFO:root:final mean train loss: 15338.301332535282
INFO:root:final train perplexity: 4.53965425491333
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.85s/it]
INFO:root:eval mean loss: 22324.97765531994
INFO:root:eval perplexity: 10.079855918884277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [16:28:01<13:37:30, 545.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15317.37150493421
INFO:root:current train perplexity4.514256477355957
INFO:root:current mean train loss 15369.93780363708
INFO:root:current train perplexity4.533045768737793
INFO:root:current mean train loss 15328.805360837614
INFO:root:current train perplexity4.530451774597168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.40s/it]
INFO:root:final mean train loss: 15322.81253937752
INFO:root:final train perplexity: 4.532724380493164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.60s/it]
INFO:root:eval mean loss: 22327.201218377977
INFO:root:eval perplexity: 10.082178115844727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [16:36:56<13:24:03, 542.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15339.054426166373
INFO:root:current train perplexity4.530993461608887
INFO:root:current mean train loss 15326.545401589912
INFO:root:current train perplexity4.530294895172119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.34s/it]
INFO:root:final mean train loss: 15309.46326077369
INFO:root:final train perplexity: 4.526760578155518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.40s/it]
INFO:root:eval mean loss: 22332.753487723214
INFO:root:eval perplexity: 10.087970733642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [16:46:02<13:16:30, 543.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15220.779169497282
INFO:root:current train perplexity4.496618270874023
INFO:root:current mean train loss 15277.85490504319
INFO:root:current train perplexity4.517614841461182
INFO:root:current mean train loss 15299.430751646581
INFO:root:current train perplexity4.521176338195801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.25s/it]
INFO:root:final mean train loss: 15293.455361643146
INFO:root:final train perplexity: 4.519618988037109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.68s/it]
INFO:root:eval mean loss: 22341.568917410714
INFO:root:eval perplexity: 10.097179412841797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [16:54:57<13:04:00, 540.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15276.17234375
INFO:root:current train perplexity4.513589382171631
INFO:root:current mean train loss 15296.780675223214
INFO:root:current train perplexity4.518308162689209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.48s/it]
INFO:root:final mean train loss: 15283.902611517136
INFO:root:final train perplexity: 4.515362739562988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.01s/it]
INFO:root:eval mean loss: 22339.857096354168
INFO:root:eval perplexity: 10.095388412475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [17:03:50<12:51:48, 538.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15246.538519965277
INFO:root:current train perplexity4.529998779296875
INFO:root:current mean train loss 15267.172282541831
INFO:root:current train perplexity4.5121002197265625
INFO:root:current mean train loss 15279.113242531663
INFO:root:current train perplexity4.507611274719238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.23s/it]
INFO:root:final mean train loss: 15272.103491998489
INFO:root:final train perplexity: 4.510110378265381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.25s/it]
INFO:root:eval mean loss: 22330.472958519345
INFO:root:eval perplexity: 10.085589408874512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [17:12:42<12:40:11, 536.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15231.652998912183
INFO:root:current train perplexity4.49367094039917
INFO:root:current mean train loss 15278.602429949371
INFO:root:current train perplexity4.502417087554932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.64s/it]
INFO:root:final mean train loss: 15263.179187405494
INFO:root:final train perplexity: 4.506143093109131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.50s/it]
INFO:root:eval mean loss: 22340.168968563987
INFO:root:eval perplexity: 10.095718383789062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [17:21:27<12:26:19, 533.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15310.857894405242
INFO:root:current train perplexity4.510616302490234
INFO:root:current mean train loss 15279.613661438454
INFO:root:current train perplexity4.500691890716553
INFO:root:current mean train loss 15266.318879362825
INFO:root:current train perplexity4.501896858215332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.77s/it]
INFO:root:final mean train loss: 15248.288999495968
INFO:root:final train perplexity: 4.4995293617248535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it]
INFO:root:eval mean loss: 22350.94849795387
INFO:root:eval perplexity: 10.10698413848877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [17:30:13<12:14:14, 530.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15257.78165003765
INFO:root:current train perplexity4.49257230758667
INFO:root:current mean train loss 15274.014605746243
INFO:root:current train perplexity4.499599933624268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.08s/it]
INFO:root:final mean train loss: 15243.585575226814
INFO:root:final train perplexity: 4.497442245483398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.62s/it]
INFO:root:eval mean loss: 22353.466471354168
INFO:root:eval perplexity: 10.109621047973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [17:39:11<12:08:35, 533.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15173.371902901787
INFO:root:current train perplexity4.460001468658447
INFO:root:current mean train loss 15231.85281394676
INFO:root:current train perplexity4.477264881134033
INFO:root:current mean train loss 15234.863725897607
INFO:root:current train perplexity4.489033222198486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.03s/it]
INFO:root:final mean train loss: 15224.561421055947
INFO:root:final train perplexity: 4.489011764526367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it]
INFO:root:eval mean loss: 22359.707356770832
INFO:root:eval perplexity: 10.1161527633667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [17:47:56<11:56:22, 530.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15175.520956806753
INFO:root:current train perplexity4.483111381530762
INFO:root:current mean train loss 15228.307893967247
INFO:root:current train perplexity4.48732852935791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.07s/it]
INFO:root:final mean train loss: 15218.438102476059
INFO:root:final train perplexity: 4.486300945281982
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.59s/it]
INFO:root:eval mean loss: 22352.48388671875
INFO:root:eval perplexity: 10.108589172363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [17:56:45<11:46:47, 530.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15185.27496494391
INFO:root:current train perplexity4.470181465148926
INFO:root:current mean train loss 15194.886901416367
INFO:root:current train perplexity4.480245113372803
INFO:root:current mean train loss 15215.755949267783
INFO:root:current train perplexity4.4805521965026855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it]
INFO:root:final mean train loss: 15207.472455424648
INFO:root:final train perplexity: 4.481451511383057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.08s/it]
INFO:root:eval mean loss: 22350.148530505954
INFO:root:eval perplexity: 10.106147766113281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [18:05:35<11:37:47, 529.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15167.245460594093
INFO:root:current train perplexity4.465127468109131
INFO:root:current mean train loss 15184.00593606839
INFO:root:current train perplexity4.463824272155762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.53s/it]
INFO:root:final mean train loss: 15194.476530997983
INFO:root:final train perplexity: 4.475710391998291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.07s/it]
INFO:root:eval mean loss: 22351.0458984375
INFO:root:eval perplexity: 10.10708999633789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [18:14:22<11:27:56, 529.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15173.033089571221
INFO:root:current train perplexity4.487249851226807
INFO:root:current mean train loss 15210.949949464597
INFO:root:current train perplexity4.476325511932373
INFO:root:current mean train loss 15201.363020029577
INFO:root:current train perplexity4.473644256591797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.57s/it]
INFO:root:final mean train loss: 15188.562015656502
INFO:root:final train perplexity: 4.473100662231445
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.09s/it]
INFO:root:eval mean loss: 22354.691917782737
INFO:root:eval perplexity: 10.110902786254883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [18:23:07<11:17:20, 527.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15156.018616365132
INFO:root:current train perplexity4.463914394378662
INFO:root:current mean train loss 15195.846203926281
INFO:root:current train perplexity4.46651029586792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.10s/it]
INFO:root:final mean train loss: 15177.903781029487
INFO:root:final train perplexity: 4.468400955200195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it]
INFO:root:eval mean loss: 22366.137532552082
INFO:root:eval perplexity: 10.122886657714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [18:32:11<11:14:42, 532.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15158.578478224734
INFO:root:current train perplexity4.449281215667725
INFO:root:current mean train loss 15179.369592368197
INFO:root:current train perplexity4.459566593170166
INFO:root:current mean train loss 15178.033978049089
INFO:root:current train perplexity4.46271276473999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.17s/it]
INFO:root:final mean train loss: 15164.00150422127
INFO:root:final train perplexity: 4.462277412414551
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.73s/it]
INFO:root:eval mean loss: 22354.301339285714
INFO:root:eval perplexity: 10.110493659973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [18:41:28<11:15:12, 540.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15148.003797743055
INFO:root:current train perplexity4.454742431640625
INFO:root:current mean train loss 15164.563010364322
INFO:root:current train perplexity4.455995559692383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.85s/it]
INFO:root:final mean train loss: 15155.501031691028
INFO:root:final train perplexity: 4.458538055419922
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it]
INFO:root:eval mean loss: 22362.193545386905
INFO:root:eval perplexity: 10.118755340576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [18:50:39<11:10:06, 543.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15135.274184283087
INFO:root:current train perplexity4.4426164627075195
INFO:root:current mean train loss 15130.36073960058
INFO:root:current train perplexity4.4466753005981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.59s/it]
INFO:root:final mean train loss: 15143.643586189517
INFO:root:final train perplexity: 4.45332670211792
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.42s/it]
INFO:root:eval mean loss: 22366.475167410714
INFO:root:eval perplexity: 10.123241424560547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [18:59:38<10:59:31, 542.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14956.465494791666
INFO:root:current train perplexity4.45267915725708
INFO:root:current mean train loss 15136.697834496359
INFO:root:current train perplexity4.452692031860352
INFO:root:current mean train loss 15130.36402690117
INFO:root:current train perplexity4.444020748138428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.62s/it]
INFO:root:final mean train loss: 15133.680494739163
INFO:root:final train perplexity: 4.448952674865723
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.61s/it]
INFO:root:eval mean loss: 22361.827101934523
INFO:root:eval perplexity: 10.118371963500977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [19:08:42<10:51:12, 542.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15155.867027698863
INFO:root:current train perplexity4.451374530792236
INFO:root:current mean train loss 15130.596616683468
INFO:root:current train perplexity4.446300983428955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.86s/it]
INFO:root:final mean train loss: 15122.09099751134
INFO:root:final train perplexity: 4.443869590759277
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it]
INFO:root:eval mean loss: 22368.177385602678
INFO:root:eval perplexity: 10.125024795532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [19:17:48<10:43:15, 543.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15128.481166294643
INFO:root:current train perplexity4.390007019042969
INFO:root:current mean train loss 15142.56531103972
INFO:root:current train perplexity4.451015472412109
INFO:root:current mean train loss 15127.118263134058
INFO:root:current train perplexity4.442134380340576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.47s/it]
INFO:root:final mean train loss: 15117.05997983871
INFO:root:final train perplexity: 4.441665172576904
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.49s/it]
INFO:root:eval mean loss: 22403.601260230655
INFO:root:eval perplexity: 10.162213325500488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [19:26:51<10:33:54, 543.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15140.604409427966
INFO:root:current train perplexity4.444423675537109
INFO:root:current mean train loss 15094.234835642688
INFO:root:current train perplexity4.435118198394775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.60s/it]
INFO:root:final mean train loss: 15102.423103578629
INFO:root:final train perplexity: 4.435257911682129
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.74s/it]
INFO:root:eval mean loss: 22366.583333333332
INFO:root:eval perplexity: 10.1233549118042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [19:35:50<10:23:25, 542.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15008.107155539772
INFO:root:current train perplexity4.450996398925781
INFO:root:current mean train loss 15101.624956010699
INFO:root:current train perplexity4.4285078048706055
INFO:root:current mean train loss 15099.920893809242
INFO:root:current train perplexity4.431424617767334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.70s/it]
INFO:root:final mean train loss: 15096.572663337955
INFO:root:final train perplexity: 4.432699680328369
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it]
INFO:root:eval mean loss: 22377.476655505954
INFO:root:eval perplexity: 10.134770393371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [19:44:49<10:13:20, 541.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14998.535063244048
INFO:root:current train perplexity4.420553207397461
INFO:root:current mean train loss 15056.82214580138
INFO:root:current train perplexity4.4205498695373535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.15s/it]
INFO:root:final mean train loss: 15088.312885899697
INFO:root:final train perplexity: 4.429089546203613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.28s/it]
INFO:root:eval mean loss: 22378.32800874256
INFO:root:eval perplexity: 10.135666847229004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [19:53:48<10:03:40, 540.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15036.321549479168
INFO:root:current train perplexity4.430180072784424
INFO:root:current mean train loss 15095.80433933424
INFO:root:current train perplexity4.432298183441162
INFO:root:current mean train loss 15091.017160247093
INFO:root:current train perplexity4.424660682678223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.67s/it]
INFO:root:final mean train loss: 15082.459956999748
INFO:root:final train perplexity: 4.426533222198486
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.61s/it]
INFO:root:eval mean loss: 22384.44666108631
INFO:root:eval perplexity: 10.14208698272705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [20:02:38<9:51:12, 537.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15037.915111940298
INFO:root:current train perplexity4.408206939697266
INFO:root:current mean train loss 15109.059055716692
INFO:root:current train perplexity4.429288864135742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.85s/it]
INFO:root:final mean train loss: 15071.156746156754
INFO:root:final train perplexity: 4.421601295471191
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.16s/it]
INFO:root:eval mean loss: 22385.221493675595
INFO:root:eval perplexity: 10.142901420593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [20:11:26<9:39:04, 534.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15129.09919819079
INFO:root:current train perplexity4.426993370056152
INFO:root:current mean train loss 15102.459435727416
INFO:root:current train perplexity4.430352210998535
INFO:root:current mean train loss 15097.475581478311
INFO:root:current train perplexity4.421609878540039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.74s/it]
INFO:root:final mean train loss: 15064.212201518398
INFO:root:final train perplexity: 4.418574333190918
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it]
INFO:root:eval mean loss: 22389.754720052082
INFO:root:eval perplexity: 10.147659301757812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [20:20:14<9:28:05, 532.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15047.046338578346
INFO:root:current train perplexity4.4073991775512695
INFO:root:current mean train loss 15083.203290615862
INFO:root:current train perplexity4.415455341339111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.40s/it]
INFO:root:final mean train loss: 15054.434133222027
INFO:root:final train perplexity: 4.414313793182373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.76s/it]
INFO:root:eval mean loss: 22390.11007254464
INFO:root:eval perplexity: 10.148032188415527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [20:29:24<9:24:41, 537.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14937.733483355978
INFO:root:current train perplexity4.376062870025635
INFO:root:current mean train loss 15040.068645198171
INFO:root:current train perplexity4.410061359405518
INFO:root:current mean train loss 15052.625201443385
INFO:root:current train perplexity4.411406993865967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.74s/it]
INFO:root:final mean train loss: 15048.172174269153
INFO:root:final train perplexity: 4.411588191986084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.36s/it]
INFO:root:eval mean loss: 22393.39381045387
INFO:root:eval perplexity: 10.151485443115234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [20:38:08<9:11:25, 533.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14988.522890625
INFO:root:current train perplexity4.389162063598633
INFO:root:current mean train loss 15033.718052455357
INFO:root:current train perplexity4.3962788581848145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.54s/it]
INFO:root:final mean train loss: 15033.630245085686
INFO:root:final train perplexity: 4.405265808105469
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it]
INFO:root:eval mean loss: 22385.506742931546
INFO:root:eval perplexity: 10.14319896697998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [20:47:07<9:04:06, 535.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15055.391456886575
INFO:root:current train perplexity4.4120306968688965
INFO:root:current mean train loss 15008.821588951772
INFO:root:current train perplexity4.397378921508789
INFO:root:current mean train loss 15044.602870319382
INFO:root:current train perplexity4.403603553771973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.09s/it]
INFO:root:final mean train loss: 15035.107323431199
INFO:root:final train perplexity: 4.405907154083252
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.18s/it]
INFO:root:eval mean loss: 22392.974702380954
INFO:root:eval perplexity: 10.151041984558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [20:55:54<8:52:51, 532.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14975.457513350475
INFO:root:current train perplexity4.393845558166504
INFO:root:current mean train loss 15007.197047398742
INFO:root:current train perplexity4.394341468811035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.41s/it]
INFO:root:final mean train loss: 15020.426430979083
INFO:root:final train perplexity: 4.399532794952393
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it]
INFO:root:eval mean loss: 22390.695172991072
INFO:root:eval perplexity: 10.148646354675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [21:04:57<8:46:47, 535.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15003.32607736895
INFO:root:current train perplexity4.4016523361206055
INFO:root:current mean train loss 15026.774503518607
INFO:root:current train perplexity4.401365756988525
INFO:root:current mean train loss 15026.59548329275
INFO:root:current train perplexity4.399578094482422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.64s/it]
INFO:root:final mean train loss: 15014.87400374874
INFO:root:final train perplexity: 4.397123336791992
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it]
INFO:root:eval mean loss: 22397.81873139881
INFO:root:eval perplexity: 10.15613079071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [21:13:45<8:35:41, 533.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15071.697524472891
INFO:root:current train perplexity4.38629674911499
INFO:root:current mean train loss 15025.429345969946
INFO:root:current train perplexity4.388039588928223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.54s/it]
INFO:root:final mean train loss: 15007.0535140499
INFO:root:final train perplexity: 4.393733024597168
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.60s/it]
INFO:root:eval mean loss: 22388.18908110119
INFO:root:eval perplexity: 10.146017074584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [21:22:39<8:26:55, 533.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14958.977455357142
INFO:root:current train perplexity4.3647942543029785
INFO:root:current mean train loss 14996.390950520834
INFO:root:current train perplexity4.3815836906433105
INFO:root:current mean train loss 15002.056815159574
INFO:root:current train perplexity4.390641212463379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.14s/it]
INFO:root:final mean train loss: 15000.093368038055
INFO:root:final train perplexity: 4.390717029571533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it]
INFO:root:eval mean loss: 22394.645949590773
INFO:root:eval perplexity: 10.15279769897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [21:31:41<8:20:22, 536.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14964.828933189656
INFO:root:current train perplexity4.372915267944336
INFO:root:current mean train loss 15010.638060870655
INFO:root:current train perplexity4.388327598571777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.35s/it]
INFO:root:final mean train loss: 14990.281691028225
INFO:root:final train perplexity: 4.386470317840576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.99s/it]
INFO:root:eval mean loss: 22397.338216145832
INFO:root:eval perplexity: 10.155627250671387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [21:40:36<8:11:11, 535.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14997.854992988781
INFO:root:current train perplexity4.377377986907959
INFO:root:current mean train loss 14992.85449921313
INFO:root:current train perplexity4.384780406951904
INFO:root:current mean train loss 14995.172438872907
INFO:root:current train perplexity4.383852005004883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.91s/it]
INFO:root:final mean train loss: 14985.413168630292
INFO:root:final train perplexity: 4.384364128112793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.95s/it]
INFO:root:eval mean loss: 22395.12234933036
INFO:root:eval perplexity: 10.153298377990723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [21:49:30<8:01:47, 535.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15033.045587225275
INFO:root:current train perplexity4.377682685852051
INFO:root:current mean train loss 14983.163510307591
INFO:root:current train perplexity4.372270584106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.71s/it]
INFO:root:final mean train loss: 14976.75375267767
INFO:root:final train perplexity: 4.380621910095215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.18s/it]
INFO:root:eval mean loss: 22399.745419456845
INFO:root:eval perplexity: 10.158158302307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [21:58:22<7:51:53, 534.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14965.793105014534
INFO:root:current train perplexity4.375917434692383
INFO:root:current mean train loss 14958.741026551574
INFO:root:current train perplexity4.367275238037109
INFO:root:current mean train loss 14982.94773582176
INFO:root:current train perplexity4.3765950202941895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.88s/it]
INFO:root:final mean train loss: 14967.859130859375
INFO:root:final train perplexity: 4.376780033111572
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.00s/it]
INFO:root:eval mean loss: 22401.004045758928
INFO:root:eval perplexity: 10.159480094909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [22:07:26<7:45:40, 537.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14981.999516858552
INFO:root:current train perplexity4.374454975128174
INFO:root:current mean train loss 14966.132877604166
INFO:root:current train perplexity4.372758388519287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.42s/it]
INFO:root:final mean train loss: 14964.68212890625
INFO:root:final train perplexity: 4.37540864944458
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:24<00:00, 84.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:24<00:00, 84.12s/it]
INFO:root:eval mean loss: 22399.15066964286
INFO:root:eval perplexity: 10.157532691955566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [22:16:33<7:39:02, 540.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14937.634682513299
INFO:root:current train perplexity4.357726573944092
INFO:root:current mean train loss 14931.159883875425
INFO:root:current train perplexity4.3596954345703125
INFO:root:current mean train loss 14967.304185380819
INFO:root:current train perplexity4.371932029724121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.30s/it]
INFO:root:final mean train loss: 14956.542984501008
INFO:root:final train perplexity: 4.3718976974487305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it]
INFO:root:eval mean loss: 22399.227864583332
INFO:root:eval perplexity: 10.157612800598145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [22:25:26<7:28:22, 538.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14932.736722695707
INFO:root:current train perplexity4.357397556304932
INFO:root:current mean train loss 14926.19167124686
INFO:root:current train perplexity4.363173961639404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.98s/it]
INFO:root:final mean train loss: 14946.15267845892
INFO:root:final train perplexity: 4.367420196533203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.40s/it]
INFO:root:eval mean loss: 22407.828659784227
INFO:root:eval perplexity: 10.166657447814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [22:34:24<7:19:24, 538.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14939.659524356617
INFO:root:current train perplexity4.368014812469482
INFO:root:current mean train loss 14928.028449658526
INFO:root:current train perplexity4.360074996948242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.99s/it]
INFO:root:final mean train loss: 14944.264644499748
INFO:root:final train perplexity: 4.36660623550415
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it]
INFO:root:eval mean loss: 22401.088309151786
INFO:root:eval perplexity: 10.15956974029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [22:43:22<7:10:23, 537.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15028.0625
INFO:root:current train perplexity4.3817291259765625
INFO:root:current mean train loss 14919.576058100729
INFO:root:current train perplexity4.352639675140381
INFO:root:current mean train loss 14939.605536099138
INFO:root:current train perplexity4.359525680541992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.46s/it]
INFO:root:final mean train loss: 14929.704861548638
INFO:root:final train perplexity: 4.360340118408203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.06s/it]
INFO:root:eval mean loss: 22409.623604910714
INFO:root:eval perplexity: 10.168545722961426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [22:52:12<6:59:37, 535.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14906.601935369317
INFO:root:current train perplexity4.345353126525879
INFO:root:current mean train loss 14923.029158266128
INFO:root:current train perplexity4.354743480682373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.27s/it]
INFO:root:final mean train loss: 14931.781513829384
INFO:root:final train perplexity: 4.361234188079834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.93s/it]
INFO:root:eval mean loss: 22415.596609933036
INFO:root:eval perplexity: 10.174837112426758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [23:01:12<6:51:32, 536.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15034.58803013393
INFO:root:current train perplexity4.412479400634766
INFO:root:current mean train loss 14899.776102511682
INFO:root:current train perplexity4.355396747589111
INFO:root:current mean train loss 14942.649395191727
INFO:root:current train perplexity4.360349178314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.77s/it]
INFO:root:final mean train loss: 14925.296831684727
INFO:root:final train perplexity: 4.358445167541504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.36s/it]
INFO:root:eval mean loss: 22418.794480096727
INFO:root:eval perplexity: 10.178204536437988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [23:10:02<6:41:14, 534.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14962.546990863348
INFO:root:current train perplexity4.359833240509033
INFO:root:current mean train loss 14915.836969339623
INFO:root:current train perplexity4.353761196136475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.12s/it]
INFO:root:final mean train loss: 14920.786609280494
INFO:root:final train perplexity: 4.356506824493408
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.06s/it]
INFO:root:eval mean loss: 22419.222493489582
INFO:root:eval perplexity: 10.178655624389648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [23:18:52<6:31:14, 533.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14920.660333806818
INFO:root:current train perplexity4.317906379699707
INFO:root:current mean train loss 14927.817461993243
INFO:root:current train perplexity4.349748611450195
INFO:root:current mean train loss 14931.505715898993
INFO:root:current train perplexity4.354153633117676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.59s/it]
INFO:root:final mean train loss: 14920.64533061366
INFO:root:final train perplexity: 4.356445789337158
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.59s/it]
INFO:root:eval mean loss: 22421.43436104911
INFO:root:eval perplexity: 10.180985450744629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [23:27:45<6:22:02, 533.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.758138020834
INFO:root:current train perplexity4.339754104614258
INFO:root:current mean train loss 14919.51190447661
INFO:root:current train perplexity4.353116989135742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.47s/it]
INFO:root:final mean train loss: 14904.543220766129
INFO:root:final train perplexity: 4.3495330810546875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it]
INFO:root:eval mean loss: 22417.073335193454
INFO:root:eval perplexity: 10.17639446258545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [23:36:39<6:13:29, 533.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14975.2162109375
INFO:root:current train perplexity4.347492694854736
INFO:root:current mean train loss 14915.522095788043
INFO:root:current train perplexity4.353670597076416
INFO:root:current mean train loss 14913.852529978198
INFO:root:current train perplexity4.348947525024414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.89s/it]
INFO:root:final mean train loss: 14900.491077053932
INFO:root:final train perplexity: 4.347794532775879
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it]
INFO:root:eval mean loss: 22416.704985119046
INFO:root:eval perplexity: 10.176003456115723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [23:45:30<6:04:02, 532.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14876.326842350747
INFO:root:current train perplexity4.330777168273926
INFO:root:current mean train loss 14884.682973895959
INFO:root:current train perplexity4.3380022048950195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.79s/it]
INFO:root:final mean train loss: 14898.19787203881
INFO:root:final train perplexity: 4.346811771392822
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it]
INFO:root:eval mean loss: 22416.769507998513
INFO:root:eval perplexity: 10.176069259643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [23:54:26<5:55:47, 533.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14879.855725740132
INFO:root:current train perplexity4.326395511627197
INFO:root:current mean train loss 14910.002913274684
INFO:root:current train perplexity4.344152927398682
INFO:root:current mean train loss 14891.056047552796
INFO:root:current train perplexity4.343639850616455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.36s/it]
INFO:root:final mean train loss: 14890.750460716987
INFO:root:final train perplexity: 4.3436198234558105
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.27s/it]
INFO:root:eval mean loss: 22424.860770089286
INFO:root:eval perplexity: 10.184596061706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [24:03:18<5:46:31, 533.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14893.6943359375
INFO:root:current train perplexity4.329155921936035
INFO:root:current mean train loss 14888.048896655702
INFO:root:current train perplexity4.333261013031006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.53s/it]
INFO:root:final mean train loss: 14883.492348947833
INFO:root:final train perplexity: 4.340510845184326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.43s/it]
INFO:root:eval mean loss: 22416.173642113095
INFO:root:eval perplexity: 10.175445556640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [24:12:04<5:36:18, 531.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14873.589928668478
INFO:root:current train perplexity4.348988056182861
INFO:root:current mean train loss 14931.042174796748
INFO:root:current train perplexity4.345217227935791
INFO:root:current mean train loss 14896.29017043862
INFO:root:current train perplexity4.33880615234375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.06s/it]
INFO:root:final mean train loss: 14884.174206149193
INFO:root:final train perplexity: 4.340803146362305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.78s/it]
INFO:root:eval mean loss: 22417.764601934523
INFO:root:eval perplexity: 10.177119255065918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [24:21:07<5:29:37, 534.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14862.8305859375
INFO:root:current train perplexity4.346552848815918
INFO:root:current mean train loss 14873.7444140625
INFO:root:current train perplexity4.337846279144287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.93s/it]
INFO:root:final mean train loss: 14879.61472640499
INFO:root:final train perplexity: 4.338851451873779
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.72s/it]
INFO:root:eval mean loss: 22425.243024553572
INFO:root:eval perplexity: 10.184998512268066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [24:30:03<5:21:04, 535.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14896.262008101852
INFO:root:current train perplexity4.320849895477295
INFO:root:current mean train loss 14908.191759965552
INFO:root:current train perplexity4.348721981048584
INFO:root:current mean train loss 14890.528991430341
INFO:root:current train perplexity4.3389506340026855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.50s/it]
INFO:root:final mean train loss: 14872.335185389366
INFO:root:final train perplexity: 4.3357367515563965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 22428.735909598214
INFO:root:eval perplexity: 10.188680648803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [24:38:56<5:11:48, 534.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14908.101154568829
INFO:root:current train perplexity4.3439412117004395
INFO:root:current mean train loss 14892.237337421438
INFO:root:current train perplexity4.336679458618164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.50s/it]
INFO:root:final mean train loss: 14865.943213678176
INFO:root:final train perplexity: 4.333004951477051
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it]
INFO:root:eval mean loss: 22432.195893787204
INFO:root:eval perplexity: 10.19233226776123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [24:47:45<5:01:57, 532.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14874.791078629032
INFO:root:current train perplexity4.324135780334473
INFO:root:current mean train loss 14890.15736074666
INFO:root:current train perplexity4.329633712768555
INFO:root:current mean train loss 14880.906233089827
INFO:root:current train perplexity4.334232330322266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.65s/it]
INFO:root:final mean train loss: 14865.379036195816
INFO:root:final train perplexity: 4.332763195037842
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.44s/it]
INFO:root:eval mean loss: 22427.52615792411
INFO:root:eval perplexity: 10.187408447265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [24:56:33<4:52:15, 531.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14853.952889683735
INFO:root:current train perplexity4.323525428771973
INFO:root:current mean train loss 14883.552387508538
INFO:root:current train perplexity4.33050537109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.22s/it]
INFO:root:final mean train loss: 14859.783837103074
INFO:root:final train perplexity: 4.3303728103637695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 75.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.00s/it]
INFO:root:eval mean loss: 22423.299293154763
INFO:root:eval perplexity: 10.182950019836426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [25:05:17<4:42:17, 529.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15007.605775669643
INFO:root:current train perplexity4.365300178527832
INFO:root:current mean train loss 14853.46900318287
INFO:root:current train perplexity4.322994232177734
INFO:root:current mean train loss 14875.548495678191
INFO:root:current train perplexity4.331035137176514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.08s/it]
INFO:root:final mean train loss: 14858.158998550907
INFO:root:final train perplexity: 4.329679012298584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.06s/it]
INFO:root:eval mean loss: 22430.725539434523
INFO:root:eval perplexity: 10.190779685974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [25:14:01<4:32:31, 527.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14847.743208961925
INFO:root:current train perplexity4.3263726234436035
INFO:root:current mean train loss 14848.497373203543
INFO:root:current train perplexity4.324639320373535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.35s/it]
INFO:root:final mean train loss: 14849.068509009576
INFO:root:final train perplexity: 4.325798511505127
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.66s/it]
INFO:root:eval mean loss: 22434.327101934523
INFO:root:eval perplexity: 10.194575309753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [25:22:45<4:23:19, 526.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14773.372395833334
INFO:root:current train perplexity4.294449806213379
INFO:root:current mean train loss 14822.56583717401
INFO:root:current train perplexity4.321639537811279
INFO:root:current mean train loss 14853.597174097804
INFO:root:current train perplexity4.325576305389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.99s/it]
INFO:root:final mean train loss: 14845.044705298638
INFO:root:final train perplexity: 4.324082374572754
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.85s/it]
INFO:root:eval mean loss: 22433.631254650296
INFO:root:eval perplexity: 10.193843841552734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [25:31:48<4:16:54, 531.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14881.600918612638
INFO:root:current train perplexity4.3388543128967285
INFO:root:current mean train loss 14833.59172018161
INFO:root:current train perplexity4.319773197174072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.90s/it]
INFO:root:final mean train loss: 14841.20980736517
INFO:root:final train perplexity: 4.322447299957275
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.39s/it]
INFO:root:eval mean loss: 22429.09402901786
INFO:root:eval perplexity: 10.18906021118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [25:40:44<4:08:35, 532.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14816.059116097384
INFO:root:current train perplexity4.318761348724365
INFO:root:current mean train loss 14860.42977627841
INFO:root:current train perplexity4.324387550354004
INFO:root:current mean train loss 14854.22932339892
INFO:root:current train perplexity4.321798324584961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.74s/it]
INFO:root:final mean train loss: 14839.806097215222
INFO:root:final train perplexity: 4.321849346160889
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.15s/it]
INFO:root:eval mean loss: 22435.024251302082
INFO:root:eval perplexity: 10.195314407348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [25:49:29<3:58:46, 530.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14859.852744654605
INFO:root:current train perplexity4.317669868469238
INFO:root:current mean train loss 14855.08645332532
INFO:root:current train perplexity4.319864749908447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.45s/it]
INFO:root:final mean train loss: 14831.304447297127
INFO:root:final train perplexity: 4.318226337432861
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.69s/it]
INFO:root:eval mean loss: 22431.068824404763
INFO:root:eval perplexity: 10.191143989562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [25:58:17<3:49:34, 529.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14759.555560172872
INFO:root:current train perplexity4.295989513397217
INFO:root:current mean train loss 14829.48796901573
INFO:root:current train perplexity4.311488151550293
INFO:root:current mean train loss 14842.967018281883
INFO:root:current train perplexity4.318464756011963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.81s/it]
INFO:root:final mean train loss: 14831.057443926411
INFO:root:final train perplexity: 4.318121433258057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 22437.798665364582
INFO:root:eval perplexity: 10.198241233825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [26:07:08<3:40:54, 530.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14826.92246685606
INFO:root:current train perplexity4.312337875366211
INFO:root:current mean train loss 14834.254392077575
INFO:root:current train perplexity4.314765453338623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.79s/it]
INFO:root:final mean train loss: 14831.491691343246
INFO:root:final train perplexity: 4.318305969238281
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.05s/it]
INFO:root:eval mean loss: 22435.141648065477
INFO:root:eval perplexity: 10.195438385009766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [26:16:00<3:32:15, 530.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14848.58731617647
INFO:root:current train perplexity4.306304931640625
INFO:root:current mean train loss 14827.367355649834
INFO:root:current train perplexity4.309329986572266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.41s/it]
INFO:root:final mean train loss: 14827.308148784023
INFO:root:final train perplexity: 4.316524028778076
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.17s/it]
INFO:root:eval mean loss: 22436.67599051339
INFO:root:eval perplexity: 10.197057723999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [26:24:54<3:23:47, 531.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14835.440104166666
INFO:root:current train perplexity4.291126728057861
INFO:root:current mean train loss 14822.48285800971
INFO:root:current train perplexity4.313741683959961
INFO:root:current mean train loss 14847.307140932882
INFO:root:current train perplexity4.3158159255981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it]
INFO:root:final mean train loss: 14824.533589024697
INFO:root:final train perplexity: 4.315342903137207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.80s/it]
INFO:root:eval mean loss: 22444.677408854168
INFO:root:eval perplexity: 10.205504417419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [26:33:55<3:15:54, 534.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14871.642329545455
INFO:root:current train perplexity4.302003860473633
INFO:root:current mean train loss 14847.732806199596
INFO:root:current train perplexity4.311545372009277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.30s/it]
INFO:root:final mean train loss: 14817.18796859249
INFO:root:final train perplexity: 4.312217712402344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it]
INFO:root:eval mean loss: 22444.34688895089
INFO:root:eval perplexity: 10.205159187316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [26:42:38<3:05:53, 531.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14745.331473214286
INFO:root:current train perplexity4.295743465423584
INFO:root:current mean train loss 14797.79507702979
INFO:root:current train perplexity4.310288906097412
INFO:root:current mean train loss 14826.076940858997
INFO:root:current train perplexity4.311187267303467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.72s/it]
INFO:root:final mean train loss: 14815.349424300655
INFO:root:final train perplexity: 4.311436176300049
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.70s/it]
INFO:root:eval mean loss: 22437.324800037204
INFO:root:eval perplexity: 10.19774341583252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [26:51:24<2:56:27, 529.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14780.664128707627
INFO:root:current train perplexity4.304947376251221
INFO:root:current mean train loss 14797.921051985062
INFO:root:current train perplexity4.301834583282471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.93s/it]
INFO:root:final mean train loss: 14809.667669480847
INFO:root:final train perplexity: 4.309020042419434
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.23s/it]
INFO:root:eval mean loss: 22444.005022321428
INFO:root:eval perplexity: 10.20479679107666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [27:00:09<2:47:14, 528.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14923.596235795454
INFO:root:current train perplexity4.3011603355407715
INFO:root:current mean train loss 14839.927435247748
INFO:root:current train perplexity4.313174247741699
INFO:root:current mean train loss 14829.173980857524
INFO:root:current train perplexity4.312114238739014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.94s/it]
INFO:root:final mean train loss: 14813.657533707157
INFO:root:final train perplexity: 4.31071662902832
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.14s/it]
INFO:root:eval mean loss: 22444.513764880954
INFO:root:eval perplexity: 10.205331802368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [27:08:58<2:38:29, 528.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14759.766183035714
INFO:root:current train perplexity4.298295974731445
INFO:root:current mean train loss 14801.618259921395
INFO:root:current train perplexity4.300893306732178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it]
INFO:root:final mean train loss: 14806.549489667339
INFO:root:final train perplexity: 4.307695388793945
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.01s/it]
INFO:root:eval mean loss: 22442.542085193454
INFO:root:eval perplexity: 10.203248977661133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [27:17:59<2:30:46, 532.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14772.826041666667
INFO:root:current train perplexity4.316577434539795
INFO:root:current mean train loss 14828.186548913043
INFO:root:current train perplexity4.315390586853027
INFO:root:current mean train loss 14818.132957848837
INFO:root:current train perplexity4.307931900024414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.43s/it]
INFO:root:final mean train loss: 14805.983859154487
INFO:root:final train perplexity: 4.307455062866211
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.17s/it]
INFO:root:eval mean loss: 22440.738630022322
INFO:root:eval perplexity: 10.20134449005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [27:27:05<2:23:00, 536.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14823.197615438432
INFO:root:current train perplexity4.294256210327148
INFO:root:current mean train loss 14805.809874391842
INFO:root:current train perplexity4.299997806549072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.02s/it]
INFO:root:final mean train loss: 14800.06023579259
INFO:root:final train perplexity: 4.3049397468566895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it]
INFO:root:eval mean loss: 22441.696614583332
INFO:root:eval perplexity: 10.202359199523926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [27:36:14<2:15:01, 540.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14750.104697779605
INFO:root:current train perplexity4.287011623382568
INFO:root:current mean train loss 14799.268628545167
INFO:root:current train perplexity4.306713581085205
INFO:root:current mean train loss 14826.094436715182
INFO:root:current train perplexity4.309567928314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.45s/it]
INFO:root:final mean train loss: 14802.448061050907
INFO:root:final train perplexity: 4.305953025817871
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.13s/it]
INFO:root:eval mean loss: 22442.13232421875
INFO:root:eval perplexity: 10.202818870544434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [27:45:16<2:06:11, 540.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14827.891587808099
INFO:root:current train perplexity4.304733753204346
INFO:root:current mean train loss 14829.454472770467
INFO:root:current train perplexity4.305656909942627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.43s/it]
INFO:root:final mean train loss: 14796.530115927419
INFO:root:final train perplexity: 4.303440570831299
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it]
INFO:root:eval mean loss: 22447.169782366072
INFO:root:eval perplexity: 10.208137512207031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [27:54:24<1:57:39, 543.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14867.273310122282
INFO:root:current train perplexity4.2978835105896
INFO:root:current mean train loss 14795.592320884147
INFO:root:current train perplexity4.299781799316406
INFO:root:current mean train loss 14815.132523472534
INFO:root:current train perplexity4.3065104484558105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.04s/it]
INFO:root:final mean train loss: 14801.05521515877
INFO:root:final train perplexity: 4.305361270904541
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.40s/it]
INFO:root:eval mean loss: 22445.418131510418
INFO:root:eval perplexity: 10.206290245056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [28:03:31<1:48:48, 544.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14812.363190104166
INFO:root:current train perplexity4.304201126098633
INFO:root:current mean train loss 14786.970440848214
INFO:root:current train perplexity4.298360347747803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.33s/it]
INFO:root:final mean train loss: 14795.092328471523
INFO:root:final train perplexity: 4.302830696105957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.58s/it]
INFO:root:eval mean loss: 22443.941266741072
INFO:root:eval perplexity: 10.204730987548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [28:12:30<1:39:28, 542.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14745.057689525464
INFO:root:current train perplexity4.28830623626709
INFO:root:current mean train loss 14779.177895853838
INFO:root:current train perplexity4.300081253051758
INFO:root:current mean train loss 14794.412049146476
INFO:root:current train perplexity4.2994561195373535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.12s/it]
INFO:root:final mean train loss: 14792.233741021926
INFO:root:final train perplexity: 4.30161714553833
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.23s/it]
INFO:root:eval mean loss: 22447.657645089286
INFO:root:eval perplexity: 10.208653450012207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [28:21:26<1:30:05, 540.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14855.36073477057
INFO:root:current train perplexity4.30563497543335
INFO:root:current mean train loss 14798.71801894204
INFO:root:current train perplexity4.299309730529785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.43s/it]
INFO:root:final mean train loss: 14788.758450415826
INFO:root:final train perplexity: 4.300143241882324
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.96s/it]
INFO:root:eval mean loss: 22446.819010416668
INFO:root:eval perplexity: 10.207765579223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [28:30:18<1:20:42, 538.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14901.151650705646
INFO:root:current train perplexity4.305588722229004
INFO:root:current mean train loss 14838.371063931298
INFO:root:current train perplexity4.303586483001709
INFO:root:current mean train loss 14794.177260890152
INFO:root:current train perplexity4.298756122589111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.68s/it]
INFO:root:final mean train loss: 14788.010757938508
INFO:root:final train perplexity: 4.299825668334961
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.11s/it]
INFO:root:eval mean loss: 22447.13597470238
INFO:root:eval perplexity: 10.20810317993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [28:39:08<1:11:24, 535.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14784.764742564006
INFO:root:current train perplexity4.299640655517578
INFO:root:current mean train loss 14784.06132065403
INFO:root:current train perplexity4.296710014343262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.85s/it]
INFO:root:final mean train loss: 14784.887884324597
INFO:root:final train perplexity: 4.298501014709473
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.67s/it]
INFO:root:eval mean loss: 22448.14867001488
INFO:root:eval perplexity: 10.209172248840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [28:47:59<1:02:20, 534.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14802.541629464286
INFO:root:current train perplexity4.323574542999268
INFO:root:current mean train loss 14805.778190104167
INFO:root:current train perplexity4.301732540130615
INFO:root:current mean train loss 14805.134803025267
INFO:root:current train perplexity4.299597263336182

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.19s/it]
INFO:root:final mean train loss: 14789.657525831653
INFO:root:final train perplexity: 4.3005242347717285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.63s/it]
INFO:root:eval mean loss: 22444.580519903273
INFO:root:eval perplexity: 10.205405235290527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [28:56:47<53:14, 532.39s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14741.960881375719
INFO:root:current train perplexity4.286890983581543
INFO:root:current mean train loss 14775.930883397394
INFO:root:current train perplexity4.2938079833984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.87s/it]
INFO:root:final mean train loss: 14779.63523421749
INFO:root:final train perplexity: 4.2962751388549805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.53s/it]
INFO:root:eval mean loss: 22448.859840029763
INFO:root:eval perplexity: 10.20992374420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [29:05:40<44:23, 532.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14854.080704126603
INFO:root:current train perplexity4.313502788543701
INFO:root:current mean train loss 14786.869569188399
INFO:root:current train perplexity4.296321392059326
INFO:root:current mean train loss 14793.473722705283
INFO:root:current train perplexity4.297357559204102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.99s/it]
INFO:root:final mean train loss: 14782.579302387852
INFO:root:final train perplexity: 4.297523021697998
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.40s/it]
INFO:root:eval mean loss: 22449.052339099704
INFO:root:eval perplexity: 10.210128784179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [29:14:44<35:44, 536.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14828.558765453297
INFO:root:current train perplexity4.305834770202637
INFO:root:current mean train loss 14804.8212890625
INFO:root:current train perplexity4.30140495300293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.91s/it]
INFO:root:final mean train loss: 14779.702546150455
INFO:root:final train perplexity: 4.2963032722473145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.10s/it]
INFO:root:eval mean loss: 22448.294526599704
INFO:root:eval perplexity: 10.209327697753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [29:23:54<27:00, 540.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14798.725018168605
INFO:root:current train perplexity4.294311046600342
INFO:root:current mean train loss 14794.167681927447
INFO:root:current train perplexity4.292490005493164
INFO:root:current mean train loss 14794.867195537552
INFO:root:current train perplexity4.297813892364502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.10s/it]
INFO:root:final mean train loss: 14782.603728263608
INFO:root:final train perplexity: 4.29753303527832
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.87s/it]
INFO:root:eval mean loss: 22449.844377790178
INFO:root:eval perplexity: 10.210966110229492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [29:32:50<17:57, 538.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14810.166673519738
INFO:root:current train perplexity4.305472373962402
INFO:root:current mean train loss 14793.845487780449
INFO:root:current train perplexity4.2971086502075195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.64s/it]
INFO:root:final mean train loss: 14777.300119707661
INFO:root:final train perplexity: 4.295285701751709
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.00s/it]
INFO:root:eval mean loss: 22448.365094866072
INFO:root:eval perplexity: 10.20940113067627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [29:41:49<08:58, 538.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14767.23688912899
INFO:root:current train perplexity4.286370277404785
INFO:root:current mean train loss 14781.682032578656
INFO:root:current train perplexity4.296586990356445
INFO:root:current mean train loss 14790.680877561994
INFO:root:current train perplexity4.296140193939209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.78s/it]
INFO:root:final mean train loss: 14778.517463930191
INFO:root:final train perplexity: 4.295801639556885
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.67s/it]
INFO:root:eval mean loss: 22448.633742559523
INFO:root:eval perplexity: 10.209683418273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_allmini_allmini/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [29:50:55<00:00, 540.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [29:50:55<00:00, 537.28s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.76s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.76s/it]
INFO:root:eval mean loss: 22448.633742559523
INFO:root:eval perplexity: 10.209683418273926
INFO:root:evalaution complete
INFO:root:save model final: small_allmini_allmini/final
