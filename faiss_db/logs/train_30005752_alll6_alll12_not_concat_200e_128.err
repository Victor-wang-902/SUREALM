INFO:root:Output: alll6_alll12_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.9.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23224.41822522096
INFO:root:current train perplexity9854.951171875
INFO:root:current mean train loss 19247.491392509422
INFO:root:current train perplexity2006.6966552734375
INFO:root:current mean train loss 16806.339471415133
INFO:root:current train perplexity763.7174682617188
INFO:root:current mean train loss 15089.315348919174
INFO:root:current train perplexity384.3964538574219
INFO:root:current mean train loss 13813.431230625312
INFO:root:current train perplexity232.83705139160156
INFO:root:current mean train loss 12845.692831966036
INFO:root:current train perplexity158.54373168945312
INFO:root:current mean train loss 12084.021130213921
INFO:root:current train perplexity117.41191864013672
INFO:root:current mean train loss 11469.767585458385
INFO:root:current train perplexity92.13108825683594
INFO:root:current mean train loss 10965.976360452587
INFO:root:current train perplexity75.48709869384766

100%|██████████| 1/1 [08:38<00:00, 518.03s/it][A100%|██████████| 1/1 [08:38<00:00, 518.03s/it]
INFO:root:final mean train loss: 10564.356712833527
INFO:root:final train perplexity: 64.58256530761719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 6190.805726396276
INFO:root:eval perplexity: 12.22374153137207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 6725.57159034242
INFO:root:eval perplexity: 15.645429611206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/1
  0%|          | 1/200 [09:54<32:50:49, 594.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6508.035295758928
INFO:root:current train perplexity13.194169998168945
INFO:root:current mean train loss 6579.0305061696845
INFO:root:current train perplexity13.251904487609863
INFO:root:current mean train loss 6485.97216796875
INFO:root:current train perplexity12.782171249389648
INFO:root:current mean train loss 6412.908904532268
INFO:root:current train perplexity12.478495597839355
INFO:root:current mean train loss 6339.503287200553
INFO:root:current train perplexity12.156903266906738
INFO:root:current mean train loss 6285.903642944095
INFO:root:current train perplexity11.89212703704834
INFO:root:current mean train loss 6230.4108826387455
INFO:root:current train perplexity11.653142929077148
INFO:root:current mean train loss 6189.330933825804
INFO:root:current train perplexity11.445455551147461
INFO:root:current mean train loss 6139.91070745721
INFO:root:current train perplexity11.24893569946289
INFO:root:current mean train loss 6093.516578413554
INFO:root:current train perplexity11.040507316589355

100%|██████████| 1/1 [08:43<00:00, 523.10s/it][A100%|██████████| 1/1 [08:43<00:00, 523.10s/it]
INFO:root:final mean train loss: 6056.8479236479725
INFO:root:final train perplexity: 10.909148216247559
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.51s/it][A100%|██████████| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 5326.028039810505
INFO:root:eval perplexity: 8.616591453552246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 5965.1079066932625
INFO:root:eval perplexity: 11.464029312133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/2
  1%|          | 2/200 [20:01<33:05:50, 601.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5623.398079427084
INFO:root:current train perplexity9.254867553710938
INFO:root:current mean train loss 5616.500891644022
INFO:root:current train perplexity9.20023250579834
INFO:root:current mean train loss 5607.777591297238
INFO:root:current train perplexity9.124884605407715
INFO:root:current mean train loss 5582.810846044147
INFO:root:current train perplexity9.037274360656738
INFO:root:current mean train loss 5567.901694277109
INFO:root:current train perplexity8.970818519592285
INFO:root:current mean train loss 5540.191776016383
INFO:root:current train perplexity8.884937286376953
INFO:root:current mean train loss 5515.506238090701
INFO:root:current train perplexity8.80709457397461
INFO:root:current mean train loss 5494.917087112107
INFO:root:current train perplexity8.729634284973145
INFO:root:current mean train loss 5474.811468318635
INFO:root:current train perplexity8.654952049255371
INFO:root:current mean train loss 5460.129438823429
INFO:root:current train perplexity8.604538917541504

100%|██████████| 1/1 [08:42<00:00, 522.39s/it][A100%|██████████| 1/1 [08:42<00:00, 522.39s/it]
INFO:root:final mean train loss: 5443.526350328999
INFO:root:final train perplexity: 8.564523696899414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.07s/it][A100%|██████████| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 4973.4193262411345
INFO:root:eval perplexity: 7.4715657234191895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 5659.194439827128
INFO:root:eval perplexity: 10.11604118347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/3
  2%|▏         | 3/200 [30:01<32:53:55, 601.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5190.240977411685
INFO:root:current train perplexity7.796987056732178
INFO:root:current mean train loss 5231.258562785823
INFO:root:current train perplexity7.872804164886475
INFO:root:current mean train loss 5233.567829491311
INFO:root:current train perplexity7.833333969116211
INFO:root:current mean train loss 5207.227197416796
INFO:root:current train perplexity7.790554046630859
INFO:root:current mean train loss 5188.208391049793
INFO:root:current train perplexity7.738433837890625
INFO:root:current mean train loss 5165.917079013802
INFO:root:current train perplexity7.687142372131348
INFO:root:current mean train loss 5163.897223458818
INFO:root:current train perplexity7.668752670288086
INFO:root:current mean train loss 5152.43003530753
INFO:root:current train perplexity7.62547492980957
INFO:root:current mean train loss 5142.7586460785615
INFO:root:current train perplexity7.594518184661865
INFO:root:current mean train loss 5128.4800778075905
INFO:root:current train perplexity7.554989337921143

100%|██████████| 1/1 [08:40<00:00, 520.74s/it][A100%|██████████| 1/1 [08:40<00:00, 520.74s/it]
INFO:root:final mean train loss: 5115.586308879237
INFO:root:final train perplexity: 7.525121212005615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.15s/it][A100%|██████████| 1/1 [00:39<00:00, 39.15s/it]
INFO:root:eval mean loss: 4748.468895445479
INFO:root:eval perplexity: 6.82192325592041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.37s/it][A100%|██████████| 1/1 [00:39<00:00, 39.37s/it]
INFO:root:eval mean loss: 5458.735133394282
INFO:root:eval perplexity: 9.31989860534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/4
  2%|▏         | 4/200 [40:02<32:43:25, 601.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5013.28759765625
INFO:root:current train perplexity7.130311965942383
INFO:root:current mean train loss 4962.258595240935
INFO:root:current train perplexity7.053650856018066
INFO:root:current mean train loss 4951.553218428707
INFO:root:current train perplexity7.047727108001709
INFO:root:current mean train loss 4942.5996447790785
INFO:root:current train perplexity7.018843173980713
INFO:root:current mean train loss 4940.168452499637
INFO:root:current train perplexity7.007850646972656
INFO:root:current mean train loss 4932.909714865819
INFO:root:current train perplexity6.985654830932617
INFO:root:current mean train loss 4925.027573574931
INFO:root:current train perplexity6.956604957580566
INFO:root:current mean train loss 4912.156471095887
INFO:root:current train perplexity6.927125453948975
INFO:root:current mean train loss 4902.868473131017
INFO:root:current train perplexity6.906583309173584
INFO:root:current mean train loss 4899.130766543871
INFO:root:current train perplexity6.894394874572754

100%|██████████| 1/1 [08:45<00:00, 525.73s/it][A100%|██████████| 1/1 [08:45<00:00, 525.73s/it]
INFO:root:final mean train loss: 4889.635882346861
INFO:root:final train perplexity: 6.883330821990967
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.74s/it][A100%|██████████| 1/1 [00:38<00:00, 38.74s/it]
INFO:root:eval mean loss: 4592.08410731106
INFO:root:eval perplexity: 6.403879642486572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.58s/it][A100%|██████████| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 5320.3777340287015
INFO:root:eval perplexity: 8.807250022888184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/5
  2%|▎         | 5/200 [50:06<32:36:19, 601.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4801.021709735577
INFO:root:current train perplexity6.70662260055542
INFO:root:current mean train loss 4798.140473948966
INFO:root:current train perplexity6.622281074523926
INFO:root:current mean train loss 4784.131666367024
INFO:root:current train perplexity6.614398956298828
INFO:root:current mean train loss 4780.316298223175
INFO:root:current train perplexity6.596060752868652
INFO:root:current mean train loss 4773.4663630943905
INFO:root:current train perplexity6.573475360870361
INFO:root:current mean train loss 4766.0104423338935
INFO:root:current train perplexity6.558028221130371
INFO:root:current mean train loss 4765.672306735378
INFO:root:current train perplexity6.54512357711792
INFO:root:current mean train loss 4759.951485062162
INFO:root:current train perplexity6.538323402404785
INFO:root:current mean train loss 4755.6652101646305
INFO:root:current train perplexity6.5271830558776855
INFO:root:current mean train loss 4757.162466615914
INFO:root:current train perplexity6.525853633880615

100%|██████████| 1/1 [08:40<00:00, 520.43s/it][A100%|██████████| 1/1 [08:40<00:00, 520.43s/it]
INFO:root:final mean train loss: 4755.5892716069375
INFO:root:final train perplexity: 6.5287628173828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.56s/it][A100%|██████████| 1/1 [00:38<00:00, 38.56s/it]
INFO:root:eval mean loss: 4521.807734929078
INFO:root:eval perplexity: 6.224456787109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.49s/it][A100%|██████████| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 5264.206837322695
INFO:root:eval perplexity: 8.607266426086426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/6
  3%|▎         | 6/200 [1:00:04<32:21:53, 600.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4679.25198948637
INFO:root:current train perplexity6.352237224578857
INFO:root:current mean train loss 4698.568555351828
INFO:root:current train perplexity6.396650791168213
INFO:root:current mean train loss 4722.245544186488
INFO:root:current train perplexity6.418023586273193
INFO:root:current mean train loss 4728.679557338572
INFO:root:current train perplexity6.434867858886719
INFO:root:current mean train loss 4726.853026797574
INFO:root:current train perplexity6.43104887008667
INFO:root:current mean train loss 4722.418557454725
INFO:root:current train perplexity6.425392150878906
INFO:root:current mean train loss 4713.831818051463
INFO:root:current train perplexity6.410097122192383
INFO:root:current mean train loss 4712.778968412714
INFO:root:current train perplexity6.407962322235107
INFO:root:current mean train loss 4703.603232571761
INFO:root:current train perplexity6.392746925354004
INFO:root:current mean train loss 4701.951231169977
INFO:root:current train perplexity6.381037712097168

100%|██████████| 1/1 [08:39<00:00, 519.93s/it][A100%|██████████| 1/1 [08:39<00:00, 519.93s/it]
INFO:root:final mean train loss: 4695.673169535975
INFO:root:final train perplexity: 6.376241207122803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.50s/it][A100%|██████████| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 4439.892295891512
INFO:root:eval perplexity: 6.021655082702637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 5193.453280834441
INFO:root:eval perplexity: 8.36180591583252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/7
  4%|▎         | 7/200 [1:10:01<32:08:23, 599.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4647.955886008523
INFO:root:current train perplexity6.2170844078063965
INFO:root:current mean train loss 4606.666453503024
INFO:root:current train perplexity6.1344475746154785
INFO:root:current mean train loss 4625.1343118106615
INFO:root:current train perplexity6.162393569946289
INFO:root:current mean train loss 4625.5705112511005
INFO:root:current train perplexity6.16309928894043
INFO:root:current mean train loss 4615.926182606456
INFO:root:current train perplexity6.154452800750732
INFO:root:current mean train loss 4609.720876442849
INFO:root:current train perplexity6.148494720458984
INFO:root:current mean train loss 4606.1279572697995
INFO:root:current train perplexity6.143306255340576
INFO:root:current mean train loss 4603.355202297185
INFO:root:current train perplexity6.138233661651611
INFO:root:current mean train loss 4598.595387598228
INFO:root:current train perplexity6.126415252685547
INFO:root:current mean train loss 4594.424064340641
INFO:root:current train perplexity6.119375228881836

100%|██████████| 1/1 [08:39<00:00, 519.02s/it][A100%|██████████| 1/1 [08:39<00:00, 519.03s/it]
INFO:root:final mean train loss: 4588.966681757281
INFO:root:final train perplexity: 6.113381862640381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.42s/it][A100%|██████████| 1/1 [00:38<00:00, 38.42s/it]
INFO:root:eval mean loss: 4368.469319661458
INFO:root:eval perplexity: 5.850228786468506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.84s/it][A100%|██████████| 1/1 [00:38<00:00, 38.84s/it]
INFO:root:eval mean loss: 5136.45833160184
INFO:root:eval perplexity: 8.169179916381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/8
  4%|▍         | 8/200 [1:19:59<31:56:40, 598.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4507.470582992311
INFO:root:current train perplexity5.945985317230225
INFO:root:current mean train loss 4504.75747250048
INFO:root:current train perplexity5.924751281738281
INFO:root:current mean train loss 4517.632948030537
INFO:root:current train perplexity5.936044692993164
INFO:root:current mean train loss 4517.304454792958
INFO:root:current train perplexity5.932808876037598
INFO:root:current mean train loss 4520.381353983868
INFO:root:current train perplexity5.933027744293213
INFO:root:current mean train loss 4520.3833146578045
INFO:root:current train perplexity5.935973167419434
INFO:root:current mean train loss 4512.776412112321
INFO:root:current train perplexity5.929791450500488
INFO:root:current mean train loss 4512.786611494512
INFO:root:current train perplexity5.925704479217529
INFO:root:current mean train loss 4513.511640670264
INFO:root:current train perplexity5.924933433532715
INFO:root:current mean train loss 4509.720609068747
INFO:root:current train perplexity5.9168243408203125

100%|██████████| 1/1 [08:41<00:00, 521.50s/it][A100%|██████████| 1/1 [08:41<00:00, 521.50s/it]
INFO:root:final mean train loss: 4505.282913084953
INFO:root:final train perplexity: 5.914839744567871
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 4299.0699610067595
INFO:root:eval perplexity: 5.6883344650268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 5078.414685837766
INFO:root:eval perplexity: 7.977566719055176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/9
  4%|▍         | 9/200 [1:29:57<31:46:03, 598.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4433.211515184859
INFO:root:current train perplexity5.783464431762695
INFO:root:current mean train loss 4451.184273346125
INFO:root:current train perplexity5.789073467254639
INFO:root:current mean train loss 4435.912479639933
INFO:root:current train perplexity5.764203071594238
INFO:root:current mean train loss 4435.628058009392
INFO:root:current train perplexity5.760919570922852
INFO:root:current mean train loss 4440.134929940453
INFO:root:current train perplexity5.759710788726807
INFO:root:current mean train loss 4440.345885696011
INFO:root:current train perplexity5.754669189453125
INFO:root:current mean train loss 4436.205145800344
INFO:root:current train perplexity5.747034072875977
INFO:root:current mean train loss 4435.5341657547015
INFO:root:current train perplexity5.7445244789123535
INFO:root:current mean train loss 4439.3590854509
INFO:root:current train perplexity5.749851226806641
INFO:root:current mean train loss 4434.407406085061
INFO:root:current train perplexity5.740289211273193

100%|██████████| 1/1 [08:40<00:00, 520.83s/it][A100%|██████████| 1/1 [08:40<00:00, 520.83s/it]
INFO:root:final mean train loss: 4428.467441189674
INFO:root:final train perplexity: 5.738273620605469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.36s/it][A100%|██████████| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 4242.842099886414
INFO:root:eval perplexity: 5.560460090637207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 5033.909311281029
INFO:root:eval perplexity: 7.833698272705078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/10
  5%|▌         | 10/200 [1:39:55<31:35:13, 598.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4412.2787993225875
INFO:root:current train perplexity5.645140171051025
INFO:root:current mean train loss 4400.957939616795
INFO:root:current train perplexity5.629902362823486
INFO:root:current mean train loss 4382.0390362483195
INFO:root:current train perplexity5.612523078918457
INFO:root:current mean train loss 4379.363069962072
INFO:root:current train perplexity5.611269474029541
INFO:root:current mean train loss 4375.064484725665
INFO:root:current train perplexity5.611867427825928
INFO:root:current mean train loss 4376.045754651744
INFO:root:current train perplexity5.606571197509766
INFO:root:current mean train loss 4373.285301871433
INFO:root:current train perplexity5.601221561431885
INFO:root:current mean train loss 4369.77714850018
INFO:root:current train perplexity5.596181869506836
INFO:root:current mean train loss 4366.976318914872
INFO:root:current train perplexity5.590241432189941
INFO:root:current mean train loss 4364.152473925083
INFO:root:current train perplexity5.586976528167725

100%|██████████| 1/1 [08:41<00:00, 521.06s/it][A100%|██████████| 1/1 [08:41<00:00, 521.06s/it]
INFO:root:final mean train loss: 4360.356024588308
INFO:root:final train perplexity: 5.586130142211914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.60s/it][A100%|██████████| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 4196.488205064273
INFO:root:eval perplexity: 5.457204818725586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 4995.598225911458
INFO:root:eval perplexity: 7.7119317054748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/11
  6%|▌         | 11/200 [1:49:53<31:25:17, 598.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4309.18778904005
INFO:root:current train perplexity5.454737663269043
INFO:root:current mean train loss 4312.300065800468
INFO:root:current train perplexity5.475143909454346
INFO:root:current mean train loss 4303.994899417466
INFO:root:current train perplexity5.475198745727539
INFO:root:current mean train loss 4303.878217987928
INFO:root:current train perplexity5.451662540435791
INFO:root:current mean train loss 4304.844461366626
INFO:root:current train perplexity5.449470043182373
INFO:root:current mean train loss 4308.734112559226
INFO:root:current train perplexity5.456026077270508
INFO:root:current mean train loss 4305.532807240493
INFO:root:current train perplexity5.454527378082275
INFO:root:current mean train loss 4304.6692074457
INFO:root:current train perplexity5.455446720123291
INFO:root:current mean train loss 4303.796966380707
INFO:root:current train perplexity5.458053112030029
INFO:root:current mean train loss 4303.122034940556
INFO:root:current train perplexity5.45466423034668

100%|██████████| 1/1 [08:33<00:00, 513.41s/it][A100%|██████████| 1/1 [08:33<00:00, 513.41s/it]
INFO:root:final mean train loss: 4299.739592029202
INFO:root:final train perplexity: 5.454122543334961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 4143.293517633533
INFO:root:eval perplexity: 5.341071128845215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.83s/it][A100%|██████████| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 4951.8259311973625
INFO:root:eval perplexity: 7.5751237869262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/12
  6%|▌         | 12/200 [1:59:43<31:06:54, 595.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4245.584747635691
INFO:root:current train perplexity5.33405876159668
INFO:root:current mean train loss 4245.193045122195
INFO:root:current train perplexity5.325127124786377
INFO:root:current mean train loss 4252.802924721928
INFO:root:current train perplexity5.348677635192871
INFO:root:current mean train loss 4252.796299569818
INFO:root:current train perplexity5.347533226013184
INFO:root:current mean train loss 4250.185165127841
INFO:root:current train perplexity5.341886520385742
INFO:root:current mean train loss 4245.102052832852
INFO:root:current train perplexity5.341220378875732
INFO:root:current mean train loss 4247.04733236848
INFO:root:current train perplexity5.338753700256348
INFO:root:current mean train loss 4249.336691725629
INFO:root:current train perplexity5.341941833496094
INFO:root:current mean train loss 4250.789487222853
INFO:root:current train perplexity5.342614650726318

100%|██████████| 1/1 [08:40<00:00, 520.94s/it][A100%|██████████| 1/1 [08:40<00:00, 520.95s/it]
INFO:root:final mean train loss: 4246.973480224609
INFO:root:final train perplexity: 5.341752529144287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.49s/it][A100%|██████████| 1/1 [00:39<00:00, 39.49s/it]
INFO:root:eval mean loss: 4109.276154213763
INFO:root:eval perplexity: 5.26810359954834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.62s/it][A100%|██████████| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 4929.7182651817375
INFO:root:eval perplexity: 7.506952285766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/13
  6%|▋         | 13/200 [2:09:43<31:00:34, 596.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4198.675211588542
INFO:root:current train perplexity5.236372947692871
INFO:root:current mean train loss 4195.5871013159895
INFO:root:current train perplexity5.252533435821533
INFO:root:current mean train loss 4199.2594998364375
INFO:root:current train perplexity5.238354206085205
INFO:root:current mean train loss 4199.7335499174915
INFO:root:current train perplexity5.228384971618652
INFO:root:current mean train loss 4193.332721871123
INFO:root:current train perplexity5.2308878898620605
INFO:root:current mean train loss 4191.930734926379
INFO:root:current train perplexity5.229982852935791
INFO:root:current mean train loss 4194.099979027389
INFO:root:current train perplexity5.232724666595459
INFO:root:current mean train loss 4201.721726570835
INFO:root:current train perplexity5.242076873779297
INFO:root:current mean train loss 4199.2090807543
INFO:root:current train perplexity5.243227005004883
INFO:root:current mean train loss 4200.296029835445
INFO:root:current train perplexity5.242006301879883

100%|██████████| 1/1 [08:39<00:00, 519.91s/it][A100%|██████████| 1/1 [08:39<00:00, 519.91s/it]
INFO:root:final mean train loss: 4200.331958893807
INFO:root:final train perplexity: 5.24435567855835
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.20s/it][A100%|██████████| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 4087.9746803662456
INFO:root:eval perplexity: 5.222922325134277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.72s/it][A100%|██████████| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 4907.804593999335
INFO:root:eval perplexity: 7.439985275268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/14
  7%|▋         | 14/200 [2:19:40<30:50:59, 597.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4199.286931818182
INFO:root:current train perplexity5.012032508850098
INFO:root:current mean train loss 4169.710688960445
INFO:root:current train perplexity5.148475170135498
INFO:root:current mean train loss 4166.783331559168
INFO:root:current train perplexity5.141633987426758
INFO:root:current mean train loss 4163.964361748895
INFO:root:current train perplexity5.14337682723999
INFO:root:current mean train loss 4159.057235829151
INFO:root:current train perplexity5.141511917114258
INFO:root:current mean train loss 4153.010050853871
INFO:root:current train perplexity5.140106678009033
INFO:root:current mean train loss 4156.308803926709
INFO:root:current train perplexity5.147050380706787
INFO:root:current mean train loss 4155.196871085509
INFO:root:current train perplexity5.1461005210876465
INFO:root:current mean train loss 4161.05385754229
INFO:root:current train perplexity5.1543803215026855
INFO:root:current mean train loss 4161.846166483003
INFO:root:current train perplexity5.157357215881348

100%|██████████| 1/1 [08:38<00:00, 518.57s/it][A100%|██████████| 1/1 [08:38<00:00, 518.57s/it]
INFO:root:final mean train loss: 4160.086834630659
INFO:root:final train perplexity: 5.161744117736816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 4048.9046812666224
INFO:root:eval perplexity: 5.141054153442383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.00s/it][A100%|██████████| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 4879.0647041916
INFO:root:eval perplexity: 7.353060245513916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/15
  8%|▊         | 15/200 [2:29:35<30:39:20, 596.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4102.414717824836
INFO:root:current train perplexity5.110418319702148
INFO:root:current mean train loss 4125.744364249606
INFO:root:current train perplexity5.110253810882568
INFO:root:current mean train loss 4122.728303813499
INFO:root:current train perplexity5.087124347686768
INFO:root:current mean train loss 4137.230657021454
INFO:root:current train perplexity5.106279373168945
INFO:root:current mean train loss 4128.007755397897
INFO:root:current train perplexity5.088878154754639
INFO:root:current mean train loss 4129.497414649566
INFO:root:current train perplexity5.08607816696167
INFO:root:current mean train loss 4125.412201272844
INFO:root:current train perplexity5.0825114250183105
INFO:root:current mean train loss 4128.913472352008
INFO:root:current train perplexity5.080360412597656
INFO:root:current mean train loss 4126.014518467643
INFO:root:current train perplexity5.081935405731201
INFO:root:current mean train loss 4125.390708151268
INFO:root:current train perplexity5.083678245544434

100%|██████████| 1/1 [08:37<00:00, 517.48s/it][A100%|██████████| 1/1 [08:37<00:00, 517.48s/it]
INFO:root:final mean train loss: 4118.264587894563
INFO:root:final train perplexity: 5.077274322509766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.59s/it][A100%|██████████| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 4024.8199887106603
INFO:root:eval perplexity: 5.091228485107422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 4854.24898707613
INFO:root:eval perplexity: 7.27882194519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/16
  8%|▊         | 16/200 [2:39:29<30:27:06, 595.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4143.540400752315
INFO:root:current train perplexity5.032676696777344
INFO:root:current mean train loss 4110.656694066806
INFO:root:current train perplexity5.048781394958496
INFO:root:current mean train loss 4094.96482654185
INFO:root:current train perplexity5.032704830169678
INFO:root:current mean train loss 4095.7256673177085
INFO:root:current train perplexity5.023128032684326
INFO:root:current mean train loss 4095.123391645016
INFO:root:current train perplexity5.02173376083374
INFO:root:current mean train loss 4088.8895154804613
INFO:root:current train perplexity5.0167012214660645
INFO:root:current mean train loss 4083.212685422274
INFO:root:current train perplexity5.0048136711120605
INFO:root:current mean train loss 4087.8928367058547
INFO:root:current train perplexity5.010400772094727
INFO:root:current mean train loss 4089.0016794631388
INFO:root:current train perplexity5.015615463256836
INFO:root:current mean train loss 4085.860442687264
INFO:root:current train perplexity5.009206295013428

100%|██████████| 1/1 [08:42<00:00, 522.00s/it][A100%|██████████| 1/1 [08:42<00:00, 522.00s/it]
INFO:root:final mean train loss: 4085.830323434645
INFO:root:final train perplexity: 5.012718200683594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.12s/it][A100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 4011.287791583555
INFO:root:eval perplexity: 5.063445568084717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.74s/it][A100%|██████████| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 4844.560803136082
INFO:root:eval perplexity: 7.2500433921813965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/17
  8%|▊         | 17/200 [2:49:28<30:19:32, 596.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4113.658663504464
INFO:root:current train perplexity5.01214075088501
INFO:root:current mean train loss 4060.50703125
INFO:root:current train perplexity4.968848705291748
INFO:root:current mean train loss 4055.0053170711435
INFO:root:current train perplexity4.948391914367676
INFO:root:current mean train loss 4056.5196063141325
INFO:root:current train perplexity4.950437545776367
INFO:root:current mean train loss 4053.1473829247484
INFO:root:current train perplexity4.949852466583252
INFO:root:current mean train loss 4054.0085672824184
INFO:root:current train perplexity4.95068359375
INFO:root:current mean train loss 4058.3094930333414
INFO:root:current train perplexity4.955196380615234
INFO:root:current mean train loss 4055.309644052934
INFO:root:current train perplexity4.954018592834473
INFO:root:current mean train loss 4052.5391294559317
INFO:root:current train perplexity4.949310779571533
INFO:root:current mean train loss 4056.4384462733956
INFO:root:current train perplexity4.951115131378174

100%|██████████| 1/1 [08:36<00:00, 516.70s/it][A100%|██████████| 1/1 [08:36<00:00, 516.70s/it]
INFO:root:final mean train loss: 4052.5443002024003
INFO:root:final train perplexity: 4.947319507598877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.37s/it][A100%|██████████| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 4015.5565592447915
INFO:root:eval perplexity: 5.072192668914795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 4860.114598916777
INFO:root:eval perplexity: 7.296302795410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/18
  9%|▉         | 18/200 [2:59:22<30:07:06, 595.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3970.2596804596656
INFO:root:current train perplexity4.868155479431152
INFO:root:current mean train loss 4004.3329651305726
INFO:root:current train perplexity4.859924793243408
INFO:root:current mean train loss 4004.926328808192
INFO:root:current train perplexity4.867903232574463
INFO:root:current mean train loss 4007.4857957133745
INFO:root:current train perplexity4.864938259124756
INFO:root:current mean train loss 4017.4024969578863
INFO:root:current train perplexity4.878870964050293
INFO:root:current mean train loss 4020.2677058154927
INFO:root:current train perplexity4.881260871887207
INFO:root:current mean train loss 4019.0251817955386
INFO:root:current train perplexity4.879714012145996
INFO:root:current mean train loss 4021.455388968918
INFO:root:current train perplexity4.8787031173706055
INFO:root:current mean train loss 4024.297993760658
INFO:root:current train perplexity4.885609149932861
INFO:root:current mean train loss 4025.4975207946713
INFO:root:current train perplexity4.889495849609375

100%|██████████| 1/1 [08:38<00:00, 518.30s/it][A100%|██████████| 1/1 [08:38<00:00, 518.30s/it]
INFO:root:final mean train loss: 4023.283290678455
INFO:root:final train perplexity: 4.890534400939941
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.17s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3978.5885018423096
INFO:root:eval perplexity: 4.996933937072754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.11s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4821.07029864805
INFO:root:eval perplexity: 7.180736541748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/19
 10%|▉         | 19/200 [3:09:17<29:56:34, 595.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4004.9290986902574
INFO:root:current train perplexity4.875527381896973
INFO:root:current mean train loss 3997.6249773644454
INFO:root:current train perplexity4.857899188995361
INFO:root:current mean train loss 3986.0736652997384
INFO:root:current train perplexity4.828658103942871
INFO:root:current mean train loss 3999.2578013710827
INFO:root:current train perplexity4.845511436462402
INFO:root:current mean train loss 3993.408308143362
INFO:root:current train perplexity4.837728023529053
INFO:root:current mean train loss 3996.030192795769
INFO:root:current train perplexity4.834926605224609
INFO:root:current mean train loss 3996.603976154474
INFO:root:current train perplexity4.831653118133545
INFO:root:current mean train loss 3992.6923181201105
INFO:root:current train perplexity4.824548721313477
INFO:root:current mean train loss 3994.170345606731
INFO:root:current train perplexity4.82653284072876
INFO:root:current mean train loss 3994.184578270817
INFO:root:current train perplexity4.828020095825195

100%|██████████| 1/1 [08:41<00:00, 521.98s/it][A100%|██████████| 1/1 [08:41<00:00, 521.98s/it]
INFO:root:final mean train loss: 3991.239551790299
INFO:root:final train perplexity: 4.829096794128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3951.2908251606827
INFO:root:eval perplexity: 4.942078113555908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:40<00:00, 40.55s/it][A100%|██████████| 1/1 [00:40<00:00, 40.55s/it]
INFO:root:eval mean loss: 4797.073874182735
INFO:root:eval perplexity: 7.110620021820068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/20
 10%|█         | 20/200 [3:19:19<29:52:29, 597.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3957.85496805482
INFO:root:current train perplexity4.7698655128479
INFO:root:current mean train loss 3964.939167526533
INFO:root:current train perplexity4.747787952423096
INFO:root:current mean train loss 3958.9122705643704
INFO:root:current train perplexity4.764350891113281
INFO:root:current mean train loss 3966.2837920547527
INFO:root:current train perplexity4.765116214752197
INFO:root:current mean train loss 3970.089448550688
INFO:root:current train perplexity4.774951934814453
INFO:root:current mean train loss 3974.742515058978
INFO:root:current train perplexity4.782739639282227
INFO:root:current mean train loss 3969.13884377371
INFO:root:current train perplexity4.774677753448486
INFO:root:current mean train loss 3970.0626595438075
INFO:root:current train perplexity4.7752861976623535
INFO:root:current mean train loss 3972.818777455162
INFO:root:current train perplexity4.779879570007324
INFO:root:current mean train loss 3967.2019177895268
INFO:root:current train perplexity4.775746822357178

100%|██████████| 1/1 [08:36<00:00, 516.35s/it][A100%|██████████| 1/1 [08:36<00:00, 516.35s/it]
INFO:root:final mean train loss: 3963.6849115433233
INFO:root:final train perplexity: 4.77688455581665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.22s/it][A100%|██████████| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 3936.2748729083555
INFO:root:eval perplexity: 4.912161350250244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4787.619142356494
INFO:root:eval perplexity: 7.083182334899902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/21
 10%|█         | 21/200 [3:29:12<29:38:48, 596.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3967.864042822994
INFO:root:current train perplexity4.755281448364258
INFO:root:current mean train loss 3958.7060429921407
INFO:root:current train perplexity4.750927448272705
INFO:root:current mean train loss 3944.203919600012
INFO:root:current train perplexity4.746558666229248
INFO:root:current mean train loss 3946.9037567055516
INFO:root:current train perplexity4.740262508392334
INFO:root:current mean train loss 3938.218806460787
INFO:root:current train perplexity4.7207560539245605
INFO:root:current mean train loss 3933.9759071525023
INFO:root:current train perplexity4.719416618347168
INFO:root:current mean train loss 3935.553284514969
INFO:root:current train perplexity4.718070983886719
INFO:root:current mean train loss 3936.526275197095
INFO:root:current train perplexity4.716611385345459
INFO:root:current mean train loss 3939.418793252595
INFO:root:current train perplexity4.720620632171631
INFO:root:current mean train loss 3939.2561333073454
INFO:root:current train perplexity4.725063323974609

100%|██████████| 1/1 [08:38<00:00, 518.98s/it][A100%|██████████| 1/1 [08:38<00:00, 518.98s/it]
INFO:root:final mean train loss: 3935.901727737919
INFO:root:final train perplexity: 4.724808692932129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.66s/it][A100%|██████████| 1/1 [00:38<00:00, 38.66s/it]
INFO:root:eval mean loss: 3936.3714608266846
INFO:root:eval perplexity: 4.912352561950684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.25s/it][A100%|██████████| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 4785.40173253269
INFO:root:eval perplexity: 7.076761722564697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/22
 11%|█         | 22/200 [3:39:09<29:29:51, 596.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3946.4253450520832
INFO:root:current train perplexity4.702200412750244
INFO:root:current mean train loss 3938.637193080357
INFO:root:current train perplexity4.679012298583984
INFO:root:current mean train loss 3917.6997247869317
INFO:root:current train perplexity4.66114616394043
INFO:root:current mean train loss 3910.0229153645832
INFO:root:current train perplexity4.653131484985352
INFO:root:current mean train loss 3903.448982319079
INFO:root:current train perplexity4.655350208282471
INFO:root:current mean train loss 3908.8083648947013
INFO:root:current train perplexity4.661121368408203
INFO:root:current mean train loss 3909.519693648727
INFO:root:current train perplexity4.661374568939209
INFO:root:current mean train loss 3906.107231917843
INFO:root:current train perplexity4.656139373779297
INFO:root:current mean train loss 3908.4763970424106
INFO:root:current train perplexity4.662850856781006
INFO:root:current mean train loss 3907.638285506811
INFO:root:current train perplexity4.666001796722412

100%|██████████| 1/1 [08:37<00:00, 517.87s/it][A100%|██████████| 1/1 [08:37<00:00, 517.87s/it]
INFO:root:final mean train loss: 3903.7226815992785
INFO:root:final train perplexity: 4.66520357131958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 3916.510330091977
INFO:root:eval perplexity: 4.873058795928955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4770.0807551390735
INFO:root:eval perplexity: 7.032565116882324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/23
 12%|█▏        | 23/200 [3:49:04<29:18:19, 596.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3875.4217573418673
INFO:root:current train perplexity4.615735054016113
INFO:root:current mean train loss 3871.8267055157103
INFO:root:current train perplexity4.613556861877441
INFO:root:current mean train loss 3886.2570257287985
INFO:root:current train perplexity4.622866630554199
INFO:root:current mean train loss 3881.257250275375
INFO:root:current train perplexity4.620284557342529
INFO:root:current mean train loss 3875.8214432299756
INFO:root:current train perplexity4.613410472869873
INFO:root:current mean train loss 3876.0157502110583
INFO:root:current train perplexity4.611053466796875
INFO:root:current mean train loss 3876.5700948109215
INFO:root:current train perplexity4.615411758422852
INFO:root:current mean train loss 3876.3922526041665
INFO:root:current train perplexity4.61700439453125
INFO:root:current mean train loss 3878.5935528626665
INFO:root:current train perplexity4.618154525756836
INFO:root:current mean train loss 3880.823415544729
INFO:root:current train perplexity4.618227005004883

100%|██████████| 1/1 [08:38<00:00, 518.79s/it][A100%|██████████| 1/1 [08:38<00:00, 518.79s/it]
INFO:root:final mean train loss: 3878.6628374284314
INFO:root:final train perplexity: 4.619307518005371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 3901.3192389738474
INFO:root:eval perplexity: 4.8432159423828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 4762.225617104388
INFO:root:eval perplexity: 7.010012626647949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/24
 12%|█▏        | 24/200 [3:59:00<29:08:05, 595.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3864.909227979052
INFO:root:current train perplexity4.5784525871276855
INFO:root:current mean train loss 3832.6490420995583
INFO:root:current train perplexity4.534742832183838
INFO:root:current mean train loss 3842.901132275558
INFO:root:current train perplexity4.5556817054748535
INFO:root:current mean train loss 3850.4177102481617
INFO:root:current train perplexity4.56842041015625
INFO:root:current mean train loss 3856.7251473793917
INFO:root:current train perplexity4.578017234802246
INFO:root:current mean train loss 3854.502161326142
INFO:root:current train perplexity4.570488452911377
INFO:root:current mean train loss 3852.5120021085836
INFO:root:current train perplexity4.571107387542725
INFO:root:current mean train loss 3858.299326282988
INFO:root:current train perplexity4.5769548416137695
INFO:root:current mean train loss 3856.5916091799068
INFO:root:current train perplexity4.578426361083984
INFO:root:current mean train loss 3858.809490985274
INFO:root:current train perplexity4.578038692474365

100%|██████████| 1/1 [08:39<00:00, 519.17s/it][A100%|██████████| 1/1 [08:39<00:00, 519.17s/it]
INFO:root:final mean train loss: 3855.8885147340834
INFO:root:final train perplexity: 4.577988147735596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 3907.4911884280805
INFO:root:eval perplexity: 4.85531759262085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 4774.156452584774
INFO:root:eval perplexity: 7.0442938804626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/25
 12%|█▎        | 25/200 [4:08:56<28:58:05, 595.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3852.8548201744
INFO:root:current train perplexity4.530722618103027
INFO:root:current mean train loss 3852.983000942211
INFO:root:current train perplexity4.548364639282227
INFO:root:current mean train loss 3835.767439315949
INFO:root:current train perplexity4.531566619873047
INFO:root:current mean train loss 3828.8928663210763
INFO:root:current train perplexity4.528708457946777
INFO:root:current mean train loss 3830.5091379047158
INFO:root:current train perplexity4.530020236968994
INFO:root:current mean train loss 3833.5713094415173
INFO:root:current train perplexity4.525928974151611
INFO:root:current mean train loss 3835.718870847863
INFO:root:current train perplexity4.532041072845459
INFO:root:current mean train loss 3836.2408940741357
INFO:root:current train perplexity4.532693862915039
INFO:root:current mean train loss 3834.294070234288
INFO:root:current train perplexity4.531399250030518

100%|██████████| 1/1 [08:38<00:00, 518.28s/it][A100%|██████████| 1/1 [08:38<00:00, 518.28s/it]
INFO:root:final mean train loss: 3829.4166112099924
INFO:root:final train perplexity: 4.530425071716309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 3905.2708922041224
INFO:root:eval perplexity: 4.850961208343506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.13s/it][A100%|██████████| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 4777.026117852393
INFO:root:eval perplexity: 7.052565574645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/26
 13%|█▎        | 26/200 [4:18:50<28:47:05, 595.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3721.055908203125
INFO:root:current train perplexity4.482048511505127
INFO:root:current mean train loss 3765.2744254709405
INFO:root:current train perplexity4.441531181335449
INFO:root:current mean train loss 3786.2398357299217
INFO:root:current train perplexity4.468598365783691
INFO:root:current mean train loss 3795.621283813874
INFO:root:current train perplexity4.474668025970459
INFO:root:current mean train loss 3802.7183630940954
INFO:root:current train perplexity4.478201866149902
INFO:root:current mean train loss 3802.7408261872843
INFO:root:current train perplexity4.479490756988525
INFO:root:current mean train loss 3799.166201445377
INFO:root:current train perplexity4.474896430969238
INFO:root:current mean train loss 3798.936611839197
INFO:root:current train perplexity4.474720478057861
INFO:root:current mean train loss 3802.210372679
INFO:root:current train perplexity4.477100849151611
INFO:root:current mean train loss 3803.7808378949317
INFO:root:current train perplexity4.478930473327637

100%|██████████| 1/1 [08:36<00:00, 516.48s/it][A100%|██████████| 1/1 [08:36<00:00, 516.48s/it]
INFO:root:final mean train loss: 3802.562649019303
INFO:root:final train perplexity: 4.48267936706543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3892.325371924867
INFO:root:eval perplexity: 4.825633525848389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4766.1020473182625
INFO:root:eval perplexity: 7.021132469177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/27
 14%|█▎        | 27/200 [4:28:44<28:35:08, 594.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3790.05947265625
INFO:root:current train perplexity4.438475131988525
INFO:root:current mean train loss 3779.061328125
INFO:root:current train perplexity4.43520450592041
INFO:root:current mean train loss 3761.9723280795783
INFO:root:current train perplexity4.423430919647217
INFO:root:current mean train loss 3767.0919921875
INFO:root:current train perplexity4.426950454711914
INFO:root:current mean train loss 3774.90849609375
INFO:root:current train perplexity4.433801651000977
INFO:root:current mean train loss 3778.3752517255766
INFO:root:current train perplexity4.4342145919799805
INFO:root:current mean train loss 3773.332222195757
INFO:root:current train perplexity4.42844820022583
INFO:root:current mean train loss 3778.3507566652097
INFO:root:current train perplexity4.440362453460693
INFO:root:current mean train loss 3781.2091781897047
INFO:root:current train perplexity4.443609714508057
INFO:root:current mean train loss 3783.2979228035347
INFO:root:current train perplexity4.447392463684082

100%|██████████| 1/1 [08:37<00:00, 517.43s/it][A100%|██████████| 1/1 [08:37<00:00, 517.43s/it]
INFO:root:final mean train loss: 3781.7799972411126
INFO:root:final train perplexity: 4.446074962615967
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.27s/it][A100%|██████████| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 3861.1100537455673
INFO:root:eval perplexity: 4.765104293823242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4736.020480108599
INFO:root:eval perplexity: 6.935296535491943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/28
 14%|█▍        | 28/200 [4:38:38<28:24:54, 594.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3788.390678074049
INFO:root:current train perplexity4.431057453155518
INFO:root:current mean train loss 3759.0188901327488
INFO:root:current train perplexity4.387396335601807
INFO:root:current mean train loss 3767.4834871163816
INFO:root:current train perplexity4.404873371124268
INFO:root:current mean train loss 3759.1973283608263
INFO:root:current train perplexity4.402236461639404
INFO:root:current mean train loss 3766.194523515994
INFO:root:current train perplexity4.407650470733643
INFO:root:current mean train loss 3769.519012159417
INFO:root:current train perplexity4.407520294189453
INFO:root:current mean train loss 3762.050200877182
INFO:root:current train perplexity4.401339054107666
INFO:root:current mean train loss 3761.3510198527188
INFO:root:current train perplexity4.403454780578613
INFO:root:current mean train loss 3762.5163072885025
INFO:root:current train perplexity4.403482437133789
INFO:root:current mean train loss 3763.660547456917
INFO:root:current train perplexity4.406084060668945

100%|██████████| 1/1 [08:35<00:00, 515.63s/it][A100%|██████████| 1/1 [08:35<00:00, 515.63s/it]
INFO:root:final mean train loss: 3759.2390455430555
INFO:root:final train perplexity: 4.406711101531982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3843.281779837101
INFO:root:eval perplexity: 4.7308759689331055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4715.7065291168
INFO:root:eval perplexity: 6.877926349639893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/29
 14%|█▍        | 29/200 [4:48:31<28:13:05, 594.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3774.3312279485885
INFO:root:current train perplexity4.393927574157715
INFO:root:current mean train loss 3746.8777917760017
INFO:root:current train perplexity4.36557149887085
INFO:root:current mean train loss 3734.232964057427
INFO:root:current train perplexity4.3698554039001465
INFO:root:current mean train loss 3735.335110667249
INFO:root:current train perplexity4.358339309692383
INFO:root:current mean train loss 3735.1888793095636
INFO:root:current train perplexity4.361401557922363
INFO:root:current mean train loss 3742.2523080714454
INFO:root:current train perplexity4.372307777404785
INFO:root:current mean train loss 3743.946852791328
INFO:root:current train perplexity4.373101234436035
INFO:root:current mean train loss 3742.154908061517
INFO:root:current train perplexity4.370269775390625
INFO:root:current mean train loss 3744.3242014163093
INFO:root:current train perplexity4.377079010009766
INFO:root:current mean train loss 3743.509265018713
INFO:root:current train perplexity4.373188495635986

100%|██████████| 1/1 [08:38<00:00, 518.63s/it][A100%|██████████| 1/1 [08:38<00:00, 518.63s/it]
INFO:root:final mean train loss: 3739.795271227437
INFO:root:final train perplexity: 4.373035907745361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3884.849981646166
INFO:root:eval perplexity: 4.811069488525391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 4766.467683399823
INFO:root:eval perplexity: 7.022183895111084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/30
 15%|█▌        | 30/200 [4:58:26<28:04:15, 594.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3721.0721967648237
INFO:root:current train perplexity4.313088893890381
INFO:root:current mean train loss 3704.5994109009666
INFO:root:current train perplexity4.3123016357421875
INFO:root:current mean train loss 3708.0970300650497
INFO:root:current train perplexity4.303893566131592
INFO:root:current mean train loss 3711.0849076442664
INFO:root:current train perplexity4.313697814941406
INFO:root:current mean train loss 3711.6584622811074
INFO:root:current train perplexity4.318994522094727
INFO:root:current mean train loss 3714.266947617115
INFO:root:current train perplexity4.328383445739746
INFO:root:current mean train loss 3715.731031152191
INFO:root:current train perplexity4.33070707321167
INFO:root:current mean train loss 3715.138575077702
INFO:root:current train perplexity4.331246852874756
INFO:root:current mean train loss 3720.0419220589056
INFO:root:current train perplexity4.334120273590088
INFO:root:current mean train loss 3720.5881225455937
INFO:root:current train perplexity4.334169864654541

100%|██████████| 1/1 [08:37<00:00, 517.14s/it][A100%|██████████| 1/1 [08:37<00:00, 517.14s/it]
INFO:root:final mean train loss: 3717.8489070400115
INFO:root:final train perplexity: 4.3353352546691895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3848.0406589372783
INFO:root:eval perplexity: 4.739988327026367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.94s/it][A100%|██████████| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4736.990483710107
INFO:root:eval perplexity: 6.938048362731934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/31
 16%|█▌        | 31/200 [5:08:20<27:53:39, 594.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3739.4759599401596
INFO:root:current train perplexity4.34664249420166
INFO:root:current mean train loss 3709.951352904443
INFO:root:current train perplexity4.305222511291504
INFO:root:current mean train loss 3707.2911826685854
INFO:root:current train perplexity4.294821739196777
INFO:root:current mean train loss 3696.3386997365815
INFO:root:current train perplexity4.287721157073975
INFO:root:current mean train loss 3700.9572874064947
INFO:root:current train perplexity4.296410083770752
INFO:root:current mean train loss 3698.7462754049075
INFO:root:current train perplexity4.29777193069458
INFO:root:current mean train loss 3700.4733007510627
INFO:root:current train perplexity4.302107810974121
INFO:root:current mean train loss 3701.6743549719713
INFO:root:current train perplexity4.3050103187561035
INFO:root:current mean train loss 3702.101082577756
INFO:root:current train perplexity4.304138660430908
INFO:root:current mean train loss 3702.5514309167106
INFO:root:current train perplexity4.306662559509277

100%|██████████| 1/1 [08:36<00:00, 516.58s/it][A100%|██████████| 1/1 [08:36<00:00, 516.58s/it]
INFO:root:final mean train loss: 3702.471423610564
INFO:root:final train perplexity: 4.309113025665283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.10s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 3850.4178059895835
INFO:root:eval perplexity: 4.744547367095947
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.47s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 4737.749385319703
INFO:root:eval perplexity: 6.9402008056640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/32
 16%|█▌        | 32/200 [5:18:13<27:43:13, 594.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.6276677911933
INFO:root:current train perplexity4.327691555023193
INFO:root:current mean train loss 3705.807697517641
INFO:root:current train perplexity4.288478851318359
INFO:root:current mean train loss 3690.498219209559
INFO:root:current train perplexity4.288906574249268
INFO:root:current mean train loss 3685.2175918794014
INFO:root:current train perplexity4.282123565673828
INFO:root:current mean train loss 3688.6952813787775
INFO:root:current train perplexity4.2810845375061035
INFO:root:current mean train loss 3683.3404336465373
INFO:root:current train perplexity4.276437759399414
INFO:root:current mean train loss 3685.2371757216124
INFO:root:current train perplexity4.276377201080322
INFO:root:current mean train loss 3687.0592954521935
INFO:root:current train perplexity4.281215667724609
INFO:root:current mean train loss 3686.967069855629
INFO:root:current train perplexity4.27856969833374
INFO:root:current mean train loss 3686.863309115265
INFO:root:current train perplexity4.277015209197998

100%|██████████| 1/1 [08:37<00:00, 517.83s/it][A100%|██████████| 1/1 [08:37<00:00, 517.83s/it]
INFO:root:final mean train loss: 3684.754521277643
INFO:root:final train perplexity: 4.279098033905029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.20s/it][A100%|██████████| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 3832.5585747035684
INFO:root:eval perplexity: 4.710406303405762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.42s/it][A100%|██████████| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4718.583778327238
INFO:root:eval perplexity: 6.88602352142334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/33
 16%|█▋        | 33/200 [5:28:08<27:34:06, 594.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3651.1966649615574
INFO:root:current train perplexity4.2590742111206055
INFO:root:current mean train loss 3662.0609962135736
INFO:root:current train perplexity4.254549026489258
INFO:root:current mean train loss 3656.6228175870365
INFO:root:current train perplexity4.249852180480957
INFO:root:current mean train loss 3655.8410126657195
INFO:root:current train perplexity4.2396559715271
INFO:root:current mean train loss 3651.8673804923733
INFO:root:current train perplexity4.22825288772583
INFO:root:current mean train loss 3659.086704179618
INFO:root:current train perplexity4.234524726867676
INFO:root:current mean train loss 3665.361015492435
INFO:root:current train perplexity4.242351055145264
INFO:root:current mean train loss 3669.3411572457608
INFO:root:current train perplexity4.245693206787109
INFO:root:current mean train loss 3669.414227712196
INFO:root:current train perplexity4.245116233825684
INFO:root:current mean train loss 3667.4405234902324
INFO:root:current train perplexity4.245412826538086

100%|██████████| 1/1 [08:39<00:00, 519.46s/it][A100%|██████████| 1/1 [08:39<00:00, 519.46s/it]
INFO:root:final mean train loss: 3664.4372416465512
INFO:root:final train perplexity: 4.244935035705566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.19s/it][A100%|██████████| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 3812.048930283134
INFO:root:eval perplexity: 4.671502113342285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4701.882573553857
INFO:root:eval perplexity: 6.839156627655029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/34
 17%|█▋        | 34/200 [5:38:04<27:25:48, 594.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3629.19716934419
INFO:root:current train perplexity4.197701454162598
INFO:root:current mean train loss 3634.0646572893825
INFO:root:current train perplexity4.20502233505249
INFO:root:current mean train loss 3641.620884744004
INFO:root:current train perplexity4.206719875335693
INFO:root:current mean train loss 3641.353062879043
INFO:root:current train perplexity4.20839262008667
INFO:root:current mean train loss 3652.1746984267184
INFO:root:current train perplexity4.219716548919678
INFO:root:current mean train loss 3646.5741028794055
INFO:root:current train perplexity4.217751502990723
INFO:root:current mean train loss 3645.926639198724
INFO:root:current train perplexity4.2149152755737305
INFO:root:current mean train loss 3649.604848107166
INFO:root:current train perplexity4.217020511627197
INFO:root:current mean train loss 3648.777250690657
INFO:root:current train perplexity4.214890956878662
INFO:root:current mean train loss 3650.1477508387775
INFO:root:current train perplexity4.216106414794922

100%|██████████| 1/1 [08:36<00:00, 516.52s/it][A100%|██████████| 1/1 [08:36<00:00, 516.53s/it]
INFO:root:final mean train loss: 3646.499857502599
INFO:root:final train perplexity: 4.215000629425049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.22s/it][A100%|██████████| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 3805.923365816157
INFO:root:eval perplexity: 4.659945011138916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.54s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 4698.832209593861
INFO:root:eval perplexity: 6.830630779266357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/35
 18%|█▊        | 35/200 [5:47:58<27:15:01, 594.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.719426794897
INFO:root:current train perplexity4.181014537811279
INFO:root:current mean train loss 3625.4085618344097
INFO:root:current train perplexity4.166076183319092
INFO:root:current mean train loss 3623.170717300907
INFO:root:current train perplexity4.172449588775635
INFO:root:current mean train loss 3641.352980963473
INFO:root:current train perplexity4.197955131530762
INFO:root:current mean train loss 3640.0117732866324
INFO:root:current train perplexity4.186851978302002
INFO:root:current mean train loss 3633.017341574239
INFO:root:current train perplexity4.186202049255371
INFO:root:current mean train loss 3633.5098281882824
INFO:root:current train perplexity4.185136318206787
INFO:root:current mean train loss 3635.192013310835
INFO:root:current train perplexity4.185489177703857
INFO:root:current mean train loss 3636.04568207169
INFO:root:current train perplexity4.185846328735352
INFO:root:current mean train loss 3633.8345025815565
INFO:root:current train perplexity4.187507152557373

100%|██████████| 1/1 [08:36<00:00, 516.09s/it][A100%|██████████| 1/1 [08:36<00:00, 516.09s/it]
INFO:root:final mean train loss: 3630.0614013671875
INFO:root:final train perplexity: 4.187753200531006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3795.9440208056294
INFO:root:eval perplexity: 4.641178607940674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4696.894593583776
INFO:root:eval perplexity: 6.825221061706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/36
 18%|█▊        | 36/200 [5:57:51<27:03:41, 594.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3616.9151260551366
INFO:root:current train perplexity4.169276714324951
INFO:root:current mean train loss 3621.4474745153743
INFO:root:current train perplexity4.159461498260498
INFO:root:current mean train loss 3620.02251963333
INFO:root:current train perplexity4.155755996704102
INFO:root:current mean train loss 3614.002614260336
INFO:root:current train perplexity4.1527886390686035
INFO:root:current mean train loss 3623.3950180273036
INFO:root:current train perplexity4.163508415222168
INFO:root:current mean train loss 3614.6755063318515
INFO:root:current train perplexity4.156972885131836
INFO:root:current mean train loss 3617.4041426435133
INFO:root:current train perplexity4.162360191345215
INFO:root:current mean train loss 3615.162519791832
INFO:root:current train perplexity4.1591925621032715
INFO:root:current mean train loss 3616.4109987691127
INFO:root:current train perplexity4.159338474273682
INFO:root:current mean train loss 3617.398035051371
INFO:root:current train perplexity4.162283897399902

100%|██████████| 1/1 [08:33<00:00, 513.24s/it][A100%|██████████| 1/1 [08:33<00:00, 513.24s/it]
INFO:root:final mean train loss: 3614.7190159828433
INFO:root:final train perplexity: 4.162481307983398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.67s/it][A100%|██████████| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 3795.997381981383
INFO:root:eval perplexity: 4.641278266906738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.16s/it][A100%|██████████| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 4694.189974304632
INFO:root:eval perplexity: 6.817677021026611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/37
 18%|█▊        | 37/200 [6:07:41<26:50:07, 592.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3625.0309441817435
INFO:root:current train perplexity4.154911518096924
INFO:root:current mean train loss 3592.0891939603366
INFO:root:current train perplexity4.134798526763916
INFO:root:current mean train loss 3596.9564494504766
INFO:root:current train perplexity4.130239486694336
INFO:root:current mean train loss 3598.331996019581
INFO:root:current train perplexity4.130901336669922
INFO:root:current mean train loss 3605.691659268466
INFO:root:current train perplexity4.134176731109619
INFO:root:current mean train loss 3605.639844570641
INFO:root:current train perplexity4.140105247497559
INFO:root:current mean train loss 3604.4008876882867
INFO:root:current train perplexity4.1384358406066895
INFO:root:current mean train loss 3603.751992433176
INFO:root:current train perplexity4.134965896606445
INFO:root:current mean train loss 3602.759663058659
INFO:root:current train perplexity4.13451623916626

100%|██████████| 1/1 [08:36<00:00, 516.20s/it][A100%|██████████| 1/1 [08:36<00:00, 516.21s/it]
INFO:root:final mean train loss: 3598.7526190357826
INFO:root:final train perplexity: 4.136342525482178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.58s/it][A100%|██████████| 1/1 [00:38<00:00, 38.58s/it]
INFO:root:eval mean loss: 3791.572012826906
INFO:root:eval perplexity: 4.632980823516846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 4691.737683884641
INFO:root:eval perplexity: 6.810842990875244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/38
 19%|█▉        | 38/200 [6:17:35<26:41:27, 593.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.6700032552085
INFO:root:current train perplexity4.224935531616211
INFO:root:current mean train loss 3598.2583600386833
INFO:root:current train perplexity4.118148326873779
INFO:root:current mean train loss 3585.4463948968596
INFO:root:current train perplexity4.105374813079834
INFO:root:current mean train loss 3582.9718295560024
INFO:root:current train perplexity4.1052727699279785
INFO:root:current mean train loss 3585.086151956033
INFO:root:current train perplexity4.110658645629883
INFO:root:current mean train loss 3576.223113953001
INFO:root:current train perplexity4.099617958068848
INFO:root:current mean train loss 3576.5995445947347
INFO:root:current train perplexity4.101022720336914
INFO:root:current mean train loss 3582.9468016536275
INFO:root:current train perplexity4.1082987785339355
INFO:root:current mean train loss 3583.2935695244396
INFO:root:current train perplexity4.1062445640563965
INFO:root:current mean train loss 3586.275869443435
INFO:root:current train perplexity4.1111369132995605

100%|██████████| 1/1 [08:41<00:00, 521.30s/it][A100%|██████████| 1/1 [08:41<00:00, 521.30s/it]
INFO:root:final mean train loss: 3584.2741793355635
INFO:root:final train perplexity: 4.112782955169678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.87s/it][A100%|██████████| 1/1 [00:38<00:00, 38.87s/it]
INFO:root:eval mean loss: 3793.890498600953
INFO:root:eval perplexity: 4.637326240539551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 4699.234731687721
INFO:root:eval perplexity: 6.831754207611084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/39
 20%|█▉        | 39/200 [6:27:34<26:36:45, 595.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3530.6549849076705
INFO:root:current train perplexity4.111356258392334
INFO:root:current mean train loss 3560.2539194467904
INFO:root:current train perplexity4.050105094909668
INFO:root:current mean train loss 3556.0852548319017
INFO:root:current train perplexity4.053853988647461
INFO:root:current mean train loss 3561.2934507511054
INFO:root:current train perplexity4.066930294036865
INFO:root:current mean train loss 3571.1091712524712
INFO:root:current train perplexity4.074105739593506
INFO:root:current mean train loss 3580.275730319686
INFO:root:current train perplexity4.0887274742126465
INFO:root:current mean train loss 3577.8905806471207
INFO:root:current train perplexity4.0862908363342285
INFO:root:current mean train loss 3577.5119508724506
INFO:root:current train perplexity4.0868000984191895
INFO:root:current mean train loss 3575.8010506776936
INFO:root:current train perplexity4.087696075439453
INFO:root:current mean train loss 3575.600316605636
INFO:root:current train perplexity4.089094161987305

100%|██████████| 1/1 [08:39<00:00, 519.06s/it][A100%|██████████| 1/1 [08:39<00:00, 519.06s/it]
INFO:root:final mean train loss: 3568.4774254829654
INFO:root:final train perplexity: 4.087230205535889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3816.2948820506426
INFO:root:eval perplexity: 4.679530143737793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4721.799041098737
INFO:root:eval perplexity: 6.895081996917725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/40
 20%|██        | 40/200 [6:37:30<26:27:37, 595.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.098273026316
INFO:root:current train perplexity4.0724287033081055
INFO:root:current mean train loss 3544.4606625853467
INFO:root:current train perplexity4.065125465393066
INFO:root:current mean train loss 3553.3619758222744
INFO:root:current train perplexity4.0740203857421875
INFO:root:current mean train loss 3548.403177960913
INFO:root:current train perplexity4.063160419464111
INFO:root:current mean train loss 3558.02062376473
INFO:root:current train perplexity4.065257549285889
INFO:root:current mean train loss 3557.314851088331
INFO:root:current train perplexity4.068458080291748
INFO:root:current mean train loss 3558.3606876009694
INFO:root:current train perplexity4.063156604766846
INFO:root:current mean train loss 3557.091419288943
INFO:root:current train perplexity4.062262058258057
INFO:root:current mean train loss 3558.9429974864547
INFO:root:current train perplexity4.065061569213867
INFO:root:current mean train loss 3557.3613440645404
INFO:root:current train perplexity4.0652360916137695

100%|██████████| 1/1 [08:39<00:00, 519.23s/it][A100%|██████████| 1/1 [08:39<00:00, 519.23s/it]
INFO:root:final mean train loss: 3554.525320176155
INFO:root:final train perplexity: 4.064794063568115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3805.503662109375
INFO:root:eval perplexity: 4.659154891967773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4717.722760139628
INFO:root:eval perplexity: 6.88360071182251
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/41
 20%|██        | 41/200 [6:47:26<26:18:13, 595.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3532.2681297019676
INFO:root:current train perplexity4.021402835845947
INFO:root:current mean train loss 3566.7857002798964
INFO:root:current train perplexity4.056243419647217
INFO:root:current mean train loss 3564.2473004715034
INFO:root:current train perplexity4.058309555053711
INFO:root:current mean train loss 3557.9832954056765
INFO:root:current train perplexity4.04831600189209
INFO:root:current mean train loss 3556.0816241583725
INFO:root:current train perplexity4.048183917999268
INFO:root:current mean train loss 3553.5601512467388
INFO:root:current train perplexity4.0489115715026855
INFO:root:current mean train loss 3554.1293524783196
INFO:root:current train perplexity4.049503803253174
INFO:root:current mean train loss 3550.671905895375
INFO:root:current train perplexity4.047953128814697
INFO:root:current mean train loss 3549.072284223379
INFO:root:current train perplexity4.045602321624756
INFO:root:current mean train loss 3543.85046478897
INFO:root:current train perplexity4.042664527893066

100%|██████████| 1/1 [08:37<00:00, 517.99s/it][A100%|██████████| 1/1 [08:37<00:00, 517.99s/it]
INFO:root:final mean train loss: 3540.277171104185
INFO:root:final train perplexity: 4.042008399963379
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3810.4494230662676
INFO:root:eval perplexity: 4.668481826782227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.96s/it][A100%|██████████| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 4725.779028493462
INFO:root:eval perplexity: 6.906312465667725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/42
 21%|██        | 42/200 [6:57:21<26:07:28, 595.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3550.0144252232144
INFO:root:current train perplexity4.00252628326416
INFO:root:current mean train loss 3498.037472873264
INFO:root:current train perplexity3.989915609359741
INFO:root:current mean train loss 3513.5358793218084
INFO:root:current train perplexity4.000054359436035
INFO:root:current mean train loss 3522.195518015392
INFO:root:current train perplexity4.017037391662598
INFO:root:current mean train loss 3520.4911357309625
INFO:root:current train perplexity4.010385036468506
INFO:root:current mean train loss 3523.0792836412093
INFO:root:current train perplexity4.01267147064209
INFO:root:current mean train loss 3527.7453970841534
INFO:root:current train perplexity4.01640510559082
INFO:root:current mean train loss 3525.377295254039
INFO:root:current train perplexity4.012948036193848
INFO:root:current mean train loss 3525.692543038922
INFO:root:current train perplexity4.015885353088379
INFO:root:current mean train loss 3532.0082657921125
INFO:root:current train perplexity4.023061752319336

100%|██████████| 1/1 [08:37<00:00, 517.07s/it][A100%|██████████| 1/1 [08:37<00:00, 517.07s/it]
INFO:root:final mean train loss: 3528.088732442548
INFO:root:final train perplexity: 4.022618770599365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.59s/it][A100%|██████████| 1/1 [00:38<00:00, 38.59s/it]
INFO:root:eval mean loss: 3761.8561803939497
INFO:root:eval perplexity: 4.577643394470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.97s/it][A100%|██████████| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 4673.955339580563
INFO:root:eval perplexity: 6.76149845123291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/43
 22%|██▏       | 43/200 [7:07:16<25:57:26, 595.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3482.4247422329213
INFO:root:current train perplexity3.935023784637451
INFO:root:current mean train loss 3497.6402647645323
INFO:root:current train perplexity3.957643747329712
INFO:root:current mean train loss 3506.3517533918466
INFO:root:current train perplexity3.975984573364258
INFO:root:current mean train loss 3509.9898201188958
INFO:root:current train perplexity3.9843575954437256
INFO:root:current mean train loss 3514.4718350998164
INFO:root:current train perplexity3.9891586303710938
INFO:root:current mean train loss 3503.2312933428293
INFO:root:current train perplexity3.983757257461548
INFO:root:current mean train loss 3506.3314309602206
INFO:root:current train perplexity3.987004041671753
INFO:root:current mean train loss 3512.209465755909
INFO:root:current train perplexity3.9928691387176514
INFO:root:current mean train loss 3514.914793763438
INFO:root:current train perplexity3.99639630317688
INFO:root:current mean train loss 3515.384021552724
INFO:root:current train perplexity3.995265483856201

100%|██████████| 1/1 [08:39<00:00, 519.75s/it][A100%|██████████| 1/1 [08:39<00:00, 519.75s/it]
INFO:root:final mean train loss: 3511.297929456157
INFO:root:final train perplexity: 3.9960594177246094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.97s/it][A100%|██████████| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 3823.117480122451
INFO:root:eval perplexity: 4.6924567222595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 4739.870439245346
INFO:root:eval perplexity: 6.946224212646484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/44
 22%|██▏       | 44/200 [7:17:14<25:49:55, 596.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3488.9404679840686
INFO:root:current train perplexity3.9712934494018555
INFO:root:current mean train loss 3505.535214455712
INFO:root:current train perplexity3.986464023590088
INFO:root:current mean train loss 3495.031950323705
INFO:root:current train perplexity3.978215217590332
INFO:root:current mean train loss 3495.4554328592412
INFO:root:current train perplexity3.9751200675964355
INFO:root:current mean train loss 3498.5901371518153
INFO:root:current train perplexity3.9805524349212646
INFO:root:current mean train loss 3501.626443575601
INFO:root:current train perplexity3.98186993598938
INFO:root:current mean train loss 3500.5437555503554
INFO:root:current train perplexity3.9776628017425537
INFO:root:current mean train loss 3501.3838521294524
INFO:root:current train perplexity3.977489709854126
INFO:root:current mean train loss 3504.439015622705
INFO:root:current train perplexity3.9799726009368896
INFO:root:current mean train loss 3504.9297139421496
INFO:root:current train perplexity3.979635715484619

100%|██████████| 1/1 [08:39<00:00, 519.82s/it][A100%|██████████| 1/1 [08:39<00:00, 519.82s/it]
INFO:root:final mean train loss: 3501.5861069463913
INFO:root:final train perplexity: 3.980776786804199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.28s/it][A100%|██████████| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 3752.07903749723
INFO:root:eval perplexity: 4.559579849243164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.27s/it][A100%|██████████| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4671.943205272052
INFO:root:eval perplexity: 6.7559380531311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/45
 22%|██▎       | 45/200 [7:27:11<25:40:30, 596.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.3140848450744
INFO:root:current train perplexity3.9836552143096924
INFO:root:current mean train loss 3473.0394586527123
INFO:root:current train perplexity3.9212398529052734
INFO:root:current mean train loss 3461.654912411016
INFO:root:current train perplexity3.915640354156494
INFO:root:current mean train loss 3474.0814484407642
INFO:root:current train perplexity3.9323484897613525
INFO:root:current mean train loss 3484.465964456529
INFO:root:current train perplexity3.942044258117676
INFO:root:current mean train loss 3488.0253884412737
INFO:root:current train perplexity3.950033664703369
INFO:root:current mean train loss 3483.9518561355985
INFO:root:current train perplexity3.950819253921509
INFO:root:current mean train loss 3485.8881749089055
INFO:root:current train perplexity3.9559741020202637
INFO:root:current mean train loss 3487.537547350207
INFO:root:current train perplexity3.9575541019439697
INFO:root:current mean train loss 3491.602727195891
INFO:root:current train perplexity3.960975170135498

100%|██████████| 1/1 [08:37<00:00, 517.16s/it][A100%|██████████| 1/1 [08:37<00:00, 517.16s/it]
INFO:root:final mean train loss: 3489.103656091998
INFO:root:final train perplexity: 3.961221218109131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3763.2905983349956
INFO:root:eval perplexity: 4.580298900604248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 4681.067651194038
INFO:root:eval perplexity: 6.781190872192383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/46
 23%|██▎       | 46/200 [7:37:05<25:28:30, 595.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.8078686159047
INFO:root:current train perplexity3.932871103286743
INFO:root:current mean train loss 3449.397267964072
INFO:root:current train perplexity3.9068593978881836
INFO:root:current mean train loss 3455.997298908591
INFO:root:current train perplexity3.9213411808013916
INFO:root:current mean train loss 3458.4260307124914
INFO:root:current train perplexity3.9194517135620117
INFO:root:current mean train loss 3460.337249167726
INFO:root:current train perplexity3.92543363571167
INFO:root:current mean train loss 3468.3502156360228
INFO:root:current train perplexity3.9340078830718994
INFO:root:current mean train loss 3473.083357003139
INFO:root:current train perplexity3.9368910789489746
INFO:root:current mean train loss 3476.5706333523467
INFO:root:current train perplexity3.934973955154419
INFO:root:current mean train loss 3479.249296018959
INFO:root:current train perplexity3.9373483657836914
INFO:root:current mean train loss 3477.0310659477605
INFO:root:current train perplexity3.938094139099121

100%|██████████| 1/1 [08:37<00:00, 517.46s/it][A100%|██████████| 1/1 [08:37<00:00, 517.46s/it]
INFO:root:final mean train loss: 3475.069487294843
INFO:root:final train perplexity: 3.9393482208251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.06s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3743.508991647274
INFO:root:eval perplexity: 4.543807029724121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.58s/it][A100%|██████████| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 4665.975994570035
INFO:root:eval perplexity: 6.739473342895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/47
 24%|██▎       | 47/200 [7:46:59<25:17:50, 595.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.601761067708
INFO:root:current train perplexity3.9078752994537354
INFO:root:current mean train loss 3439.574906529018
INFO:root:current train perplexity3.888065814971924
INFO:root:current mean train loss 3441.5811381392045
INFO:root:current train perplexity3.898585557937622
INFO:root:current mean train loss 3451.9288684895832
INFO:root:current train perplexity3.907628059387207
INFO:root:current mean train loss 3464.4303777754935
INFO:root:current train perplexity3.9206924438476562
INFO:root:current mean train loss 3469.9171097995923
INFO:root:current train perplexity3.9229345321655273
INFO:root:current mean train loss 3471.580804759838
INFO:root:current train perplexity3.9231278896331787
INFO:root:current mean train loss 3471.987474483367
INFO:root:current train perplexity3.926755905151367
INFO:root:current mean train loss 3471.5831149553574
INFO:root:current train perplexity3.9283406734466553
INFO:root:current mean train loss 3469.8267039763623
INFO:root:current train perplexity3.9265358448028564

100%|██████████| 1/1 [08:36<00:00, 516.69s/it][A100%|██████████| 1/1 [08:36<00:00, 516.69s/it]
INFO:root:final mean train loss: 3467.084740238805
INFO:root:final train perplexity: 3.9269585609436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.47s/it][A100%|██████████| 1/1 [00:38<00:00, 38.48s/it]
INFO:root:eval mean loss: 3803.716164879765
INFO:root:eval perplexity: 4.655787944793701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.61s/it][A100%|██████████| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 4734.668521096521
INFO:root:eval perplexity: 6.931462287902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/48
 24%|██▍       | 48/200 [7:56:54<25:07:14, 594.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.1679746329064
INFO:root:current train perplexity3.9223408699035645
INFO:root:current mean train loss 3446.489388554474
INFO:root:current train perplexity3.898017168045044
INFO:root:current mean train loss 3447.498439397913
INFO:root:current train perplexity3.89167857170105
INFO:root:current mean train loss 3450.7622816120675
INFO:root:current train perplexity3.8987553119659424
INFO:root:current mean train loss 3445.8894179444874
INFO:root:current train perplexity3.8980367183685303
INFO:root:current mean train loss 3448.8283109321396
INFO:root:current train perplexity3.899550199508667
INFO:root:current mean train loss 3450.779359429333
INFO:root:current train perplexity3.9011166095733643
INFO:root:current mean train loss 3454.2324050377156
INFO:root:current train perplexity3.9069740772247314
INFO:root:current mean train loss 3454.3894665071134
INFO:root:current train perplexity3.906205177307129
INFO:root:current mean train loss 3456.105052245597
INFO:root:current train perplexity3.9059393405914307

100%|██████████| 1/1 [08:38<00:00, 518.17s/it][A100%|██████████| 1/1 [08:38<00:00, 518.17s/it]
INFO:root:final mean train loss: 3453.3370669580277
INFO:root:final train perplexity: 3.905717134475708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3742.29446995512
INFO:root:eval perplexity: 4.5415754318237305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.32s/it][A100%|██████████| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 4671.961948692376
INFO:root:eval perplexity: 6.755989074707031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/49
 24%|██▍       | 49/200 [8:06:49<24:57:30, 595.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3412.48872928829
INFO:root:current train perplexity3.838726043701172
INFO:root:current mean train loss 3429.817543868619
INFO:root:current train perplexity3.851219892501831
INFO:root:current mean train loss 3436.3085274712735
INFO:root:current train perplexity3.860806941986084
INFO:root:current mean train loss 3448.6261463994565
INFO:root:current train perplexity3.8801727294921875
INFO:root:current mean train loss 3450.888165693419
INFO:root:current train perplexity3.8845157623291016
INFO:root:current mean train loss 3447.151437827173
INFO:root:current train perplexity3.882917642593384
INFO:root:current mean train loss 3443.0446371031567
INFO:root:current train perplexity3.882938861846924
INFO:root:current mean train loss 3445.181877666719
INFO:root:current train perplexity3.8876101970672607
INFO:root:current mean train loss 3446.9133555608164
INFO:root:current train perplexity3.8911802768707275
INFO:root:current mean train loss 3446.1523779937406
INFO:root:current train perplexity3.8905045986175537

100%|██████████| 1/1 [08:40<00:00, 520.41s/it][A100%|██████████| 1/1 [08:40<00:00, 520.41s/it]
INFO:root:final mean train loss: 3443.4680336982974
INFO:root:final train perplexity: 3.8905389308929443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.92s/it][A100%|██████████| 1/1 [00:38<00:00, 38.92s/it]
INFO:root:eval mean loss: 3784.8341055795654
INFO:root:eval perplexity: 4.620375156402588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 4724.230416805186
INFO:root:eval perplexity: 6.901941299438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/50
 25%|██▌       | 50/200 [8:16:47<24:50:08, 596.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3427.918464429451
INFO:root:current train perplexity3.8549561500549316
INFO:root:current mean train loss 3420.325576858904
INFO:root:current train perplexity3.8517374992370605
INFO:root:current mean train loss 3420.5897425010453
INFO:root:current train perplexity3.855696439743042
INFO:root:current mean train loss 3428.2858819411813
INFO:root:current train perplexity3.857142448425293
INFO:root:current mean train loss 3424.0332378624435
INFO:root:current train perplexity3.8581173419952393
INFO:root:current mean train loss 3426.5003452205497
INFO:root:current train perplexity3.863558292388916
INFO:root:current mean train loss 3430.2072771369812
INFO:root:current train perplexity3.8694941997528076
INFO:root:current mean train loss 3430.011086245502
INFO:root:current train perplexity3.8696229457855225
INFO:root:current mean train loss 3432.2816877693967
INFO:root:current train perplexity3.8714144229888916

100%|██████████| 1/1 [08:42<00:00, 522.22s/it][A100%|██████████| 1/1 [08:42<00:00, 522.22s/it]
INFO:root:final mean train loss: 3432.1560910132625
INFO:root:final train perplexity: 3.8732147216796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.75s/it][A100%|██████████| 1/1 [00:38<00:00, 38.75s/it]
INFO:root:eval mean loss: 3722.00937777039
INFO:root:eval perplexity: 4.504474639892578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.08s/it][A100%|██████████| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 4649.442878019725
INFO:root:eval perplexity: 6.694064617156982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/51
 26%|██▌       | 51/200 [8:26:48<24:43:31, 597.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3432.416678292411
INFO:root:current train perplexity3.887176036834717
INFO:root:current mean train loss 3401.2171071845796
INFO:root:current train perplexity3.8137526512145996
INFO:root:current mean train loss 3402.9434725996375
INFO:root:current train perplexity3.8241400718688965
INFO:root:current mean train loss 3411.3912914164293
INFO:root:current train perplexity3.834475040435791
INFO:root:current mean train loss 3414.1235021642738
INFO:root:current train perplexity3.8397834300994873
INFO:root:current mean train loss 3424.4281229775333
INFO:root:current train perplexity3.847227096557617
INFO:root:current mean train loss 3429.2709341536242
INFO:root:current train perplexity3.8570361137390137
INFO:root:current mean train loss 3428.9329459313117
INFO:root:current train perplexity3.8576138019561768
INFO:root:current mean train loss 3426.859530499729
INFO:root:current train perplexity3.856224775314331
INFO:root:current mean train loss 3427.266180305523
INFO:root:current train perplexity3.856252670288086

100%|██████████| 1/1 [08:38<00:00, 518.70s/it][A100%|██████████| 1/1 [08:38<00:00, 518.70s/it]
INFO:root:final mean train loss: 3420.0798872055548
INFO:root:final train perplexity: 3.8548054695129395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 3736.4914152537676
INFO:root:eval perplexity: 4.530930519104004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 4666.373881455009
INFO:root:eval perplexity: 6.74057149887085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/52
 26%|██▌       | 52/200 [8:36:44<24:32:44, 597.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.121533203125
INFO:root:current train perplexity3.8351798057556152
INFO:root:current mean train loss 3375.750112516984
INFO:root:current train perplexity3.811886787414551
INFO:root:current mean train loss 3388.170362463663
INFO:root:current train perplexity3.816385269165039
INFO:root:current mean train loss 3393.8849702380953
INFO:root:current train perplexity3.816084146499634
INFO:root:current mean train loss 3398.6217208678463
INFO:root:current train perplexity3.817232131958008
INFO:root:current mean train loss 3405.8749217801883
INFO:root:current train perplexity3.826817035675049
INFO:root:current mean train loss 3407.7490686928354
INFO:root:current train perplexity3.8279011249542236
INFO:root:current mean train loss 3407.8272256064247
INFO:root:current train perplexity3.8300039768218994
INFO:root:current mean train loss 3408.690600436158
INFO:root:current train perplexity3.831791877746582
INFO:root:current mean train loss 3411.312500800461
INFO:root:current train perplexity3.834496021270752

100%|██████████| 1/1 [08:33<00:00, 513.57s/it][A100%|██████████| 1/1 [08:33<00:00, 513.57s/it]
INFO:root:final mean train loss: 3408.4114378652266
INFO:root:final train perplexity: 3.837100028991699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 3820.7609136053857
INFO:root:eval perplexity: 4.687988758087158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.19s/it][A100%|██████████| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 4762.40283203125
INFO:root:eval perplexity: 7.010520935058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/53
 26%|██▋       | 53/200 [8:46:34<24:17:28, 594.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.753948709239
INFO:root:current train perplexity3.772310733795166
INFO:root:current mean train loss 3366.168214875508
INFO:root:current train perplexity3.7882373332977295
INFO:root:current mean train loss 3381.4536734953053
INFO:root:current train perplexity3.807361125946045
INFO:root:current mean train loss 3388.4374992441467
INFO:root:current train perplexity3.809183120727539
INFO:root:current mean train loss 3390.4946196716164
INFO:root:current train perplexity3.80915904045105
INFO:root:current mean train loss 3392.8634936476756
INFO:root:current train perplexity3.8153276443481445
INFO:root:current mean train loss 3398.8739184139245
INFO:root:current train perplexity3.819586753845215
INFO:root:current mean train loss 3398.2684030704313
INFO:root:current train perplexity3.8199689388275146
INFO:root:current mean train loss 3400.8299621359547
INFO:root:current train perplexity3.822214126586914
INFO:root:current mean train loss 3403.7277961640034
INFO:root:current train perplexity3.8240416049957275

100%|██████████| 1/1 [08:38<00:00, 518.89s/it][A100%|██████████| 1/1 [08:38<00:00, 518.89s/it]
INFO:root:final mean train loss: 3400.578304167717
INFO:root:final train perplexity: 3.8252604007720947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.64s/it][A100%|██████████| 1/1 [00:38<00:00, 38.64s/it]
INFO:root:eval mean loss: 3744.408987491689
INFO:root:eval perplexity: 4.545461177825928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.70s/it][A100%|██████████| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 4683.731374321254
INFO:root:eval perplexity: 6.788581848144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/54
 27%|██▋       | 54/200 [8:56:31<24:08:56, 595.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.119203629032
INFO:root:current train perplexity3.8878114223480225
INFO:root:current mean train loss 3414.208143860329
INFO:root:current train perplexity3.8278398513793945
INFO:root:current mean train loss 3397.4972859172076
INFO:root:current train perplexity3.8138794898986816
INFO:root:current mean train loss 3404.8398577641146
INFO:root:current train perplexity3.818485975265503
INFO:root:current mean train loss 3407.086409920606
INFO:root:current train perplexity3.8222711086273193
INFO:root:current mean train loss 3398.0983063721164
INFO:root:current train perplexity3.8126296997070312
INFO:root:current mean train loss 3399.7226589583747
INFO:root:current train perplexity3.816763401031494
INFO:root:current mean train loss 3398.218177555361
INFO:root:current train perplexity3.8152718544006348
INFO:root:current mean train loss 3391.4658940541326
INFO:root:current train perplexity3.8100576400756836
INFO:root:current mean train loss 3395.0014887071193
INFO:root:current train perplexity3.814368724822998

100%|██████████| 1/1 [08:42<00:00, 522.84s/it][A100%|██████████| 1/1 [08:42<00:00, 522.84s/it]
INFO:root:final mean train loss: 3394.503751570179
INFO:root:final train perplexity: 3.81610369682312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.50s/it][A100%|██████████| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 3741.6899691101507
INFO:root:eval perplexity: 4.540465354919434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.92s/it][A100%|██████████| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 4683.741042982602
INFO:root:eval perplexity: 6.788609504699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/55
 28%|██▊       | 55/200 [9:06:31<24:02:54, 597.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.357678535657
INFO:root:current train perplexity3.7858235836029053
INFO:root:current mean train loss 3377.789043179519
INFO:root:current train perplexity3.7783541679382324
INFO:root:current mean train loss 3373.696664977772
INFO:root:current train perplexity3.7812156677246094
INFO:root:current mean train loss 3368.1914523414453
INFO:root:current train perplexity3.777696132659912
INFO:root:current mean train loss 3376.3953982550897
INFO:root:current train perplexity3.787321090698242
INFO:root:current mean train loss 3381.1556276452343
INFO:root:current train perplexity3.79327654838562
INFO:root:current mean train loss 3382.4086929345167
INFO:root:current train perplexity3.7942211627960205
INFO:root:current mean train loss 3386.2633867689656
INFO:root:current train perplexity3.799762010574341
INFO:root:current mean train loss 3384.514765706477
INFO:root:current train perplexity3.79868221282959
INFO:root:current mean train loss 3382.9731801513412
INFO:root:current train perplexity3.7971813678741455

100%|██████████| 1/1 [08:36<00:00, 516.55s/it][A100%|██████████| 1/1 [08:36<00:00, 516.55s/it]
INFO:root:final mean train loss: 3382.4232553051365
INFO:root:final train perplexity: 3.797959089279175
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3729.7965650626106
INFO:root:eval perplexity: 4.518681049346924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4677.201902565381
INFO:root:eval perplexity: 6.770482063293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/56
 28%|██▊       | 56/200 [9:16:25<23:50:13, 595.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3359.7762788813166
INFO:root:current train perplexity3.773562431335449
INFO:root:current mean train loss 3366.758601389775
INFO:root:current train perplexity3.767930030822754
INFO:root:current mean train loss 3369.88981943478
INFO:root:current train perplexity3.7706949710845947
INFO:root:current mean train loss 3367.9301152737753
INFO:root:current train perplexity3.767850160598755
INFO:root:current mean train loss 3367.5458798675195
INFO:root:current train perplexity3.7671570777893066
INFO:root:current mean train loss 3368.293485149823
INFO:root:current train perplexity3.768270969390869
INFO:root:current mean train loss 3368.4395153865194
INFO:root:current train perplexity3.7697577476501465
INFO:root:current mean train loss 3372.3908527992176
INFO:root:current train perplexity3.7731027603149414
INFO:root:current mean train loss 3375.1682391206095
INFO:root:current train perplexity3.7775826454162598
INFO:root:current mean train loss 3372.415756273924
INFO:root:current train perplexity3.7777438163757324

100%|██████████| 1/1 [08:36<00:00, 516.14s/it][A100%|██████████| 1/1 [08:36<00:00, 516.14s/it]
INFO:root:final mean train loss: 3369.7557327516615
INFO:root:final train perplexity: 3.7790253162384033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3767.935193650266
INFO:root:eval perplexity: 4.58890962600708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 4711.048698262965
INFO:root:eval perplexity: 6.86483907699585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/57
 28%|██▊       | 57/200 [9:26:18<23:38:10, 595.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3385.3873979048294
INFO:root:current train perplexity3.7648308277130127
INFO:root:current mean train loss 3359.804014931956
INFO:root:current train perplexity3.7625107765197754
INFO:root:current mean train loss 3360.899347043505
INFO:root:current train perplexity3.763331174850464
INFO:root:current mean train loss 3357.381776105854
INFO:root:current train perplexity3.7553343772888184
INFO:root:current mean train loss 3353.402807885474
INFO:root:current train perplexity3.755197048187256
INFO:root:current mean train loss 3361.8572679124436
INFO:root:current train perplexity3.7661280632019043
INFO:root:current mean train loss 3361.8305850429388
INFO:root:current train perplexity3.7652392387390137
INFO:root:current mean train loss 3360.3114781663908
INFO:root:current train perplexity3.765622615814209
INFO:root:current mean train loss 3364.6352005094113
INFO:root:current train perplexity3.767463445663452
INFO:root:current mean train loss 3365.52312689177
INFO:root:current train perplexity3.7694895267486572

100%|██████████| 1/1 [08:38<00:00, 518.30s/it][A100%|██████████| 1/1 [08:38<00:00, 518.30s/it]
INFO:root:final mean train loss: 3364.5527415121755
INFO:root:final train perplexity: 3.7712762355804443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3707.8836488115026
INFO:root:eval perplexity: 4.478818893432617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4653.472997354277
INFO:root:eval perplexity: 6.705103874206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/58
 29%|██▉       | 58/200 [9:36:13<23:28:13, 595.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3331.723136780754
INFO:root:current train perplexity3.734778881072998
INFO:root:current mean train loss 3341.1562814537
INFO:root:current train perplexity3.7499773502349854
INFO:root:current mean train loss 3346.9959554345887
INFO:root:current train perplexity3.7524256706237793
INFO:root:current mean train loss 3351.6983370189823
INFO:root:current train perplexity3.7541120052337646
INFO:root:current mean train loss 3350.519782772847
INFO:root:current train perplexity3.749915599822998
INFO:root:current mean train loss 3350.2232997752
INFO:root:current train perplexity3.751044988632202
INFO:root:current mean train loss 3354.1894431826217
INFO:root:current train perplexity3.752502679824829
INFO:root:current mean train loss 3353.378517160878
INFO:root:current train perplexity3.750684976577759
INFO:root:current mean train loss 3358.0327465282808
INFO:root:current train perplexity3.758305311203003
INFO:root:current mean train loss 3356.615764740719
INFO:root:current train perplexity3.7562267780303955

100%|██████████| 1/1 [08:38<00:00, 518.54s/it][A100%|██████████| 1/1 [08:38<00:00, 518.54s/it]
INFO:root:final mean train loss: 3353.859812336583
INFO:root:final train perplexity: 3.755399227142334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.59s/it][A100%|██████████| 1/1 [00:38<00:00, 38.59s/it]
INFO:root:eval mean loss: 3727.260068636414
INFO:root:eval perplexity: 4.5140485763549805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 4671.983000193927
INFO:root:eval perplexity: 6.75604772567749
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/59
 30%|██▉       | 59/200 [9:46:09<23:19:12, 595.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3321.5435464348593
INFO:root:current train perplexity3.7145473957061768
INFO:root:current mean train loss 3319.579644097222
INFO:root:current train perplexity3.7033438682556152
INFO:root:current mean train loss 3321.344270713215
INFO:root:current train perplexity3.7088840007781982
INFO:root:current mean train loss 3332.2531955441373
INFO:root:current train perplexity3.7207348346710205
INFO:root:current mean train loss 3338.796744895336
INFO:root:current train perplexity3.7302136421203613
INFO:root:current mean train loss 3346.7733442904446
INFO:root:current train perplexity3.737314224243164
INFO:root:current mean train loss 3344.7918561091187
INFO:root:current train perplexity3.7385966777801514
INFO:root:current mean train loss 3347.2167034619206
INFO:root:current train perplexity3.7438125610351562
INFO:root:current mean train loss 3345.0861317473627
INFO:root:current train perplexity3.739912986755371
INFO:root:current mean train loss 3345.7687186212665
INFO:root:current train perplexity3.7403125762939453

100%|██████████| 1/1 [08:40<00:00, 520.81s/it][A100%|██████████| 1/1 [08:40<00:00, 520.81s/it]
INFO:root:final mean train loss: 3343.4297436744937
INFO:root:final train perplexity: 3.739978551864624
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.78s/it][A100%|██████████| 1/1 [00:38<00:00, 38.78s/it]
INFO:root:eval mean loss: 3702.901502244016
INFO:root:eval perplexity: 4.469804286956787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 4646.634857394171
INFO:root:eval perplexity: 6.6863813400268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/60
 30%|███       | 60/200 [9:56:08<23:11:56, 596.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.612369585641
INFO:root:current train perplexity3.7317423820495605
INFO:root:current mean train loss 3332.0788233240223
INFO:root:current train perplexity3.7178897857666016
INFO:root:current mean train loss 3333.9349098342295
INFO:root:current train perplexity3.723442792892456
INFO:root:current mean train loss 3333.914834216276
INFO:root:current train perplexity3.7285962104797363
INFO:root:current mean train loss 3332.409376427127
INFO:root:current train perplexity3.725879669189453
INFO:root:current mean train loss 3331.924289420067
INFO:root:current train perplexity3.724194049835205
INFO:root:current mean train loss 3333.8654961340208
INFO:root:current train perplexity3.725513219833374
INFO:root:current mean train loss 3334.8241143869345
INFO:root:current train perplexity3.7257447242736816
INFO:root:current mean train loss 3336.565194434816
INFO:root:current train perplexity3.727217197418213
INFO:root:current mean train loss 3336.166574729475
INFO:root:current train perplexity3.725925922393799

100%|██████████| 1/1 [08:34<00:00, 514.82s/it][A100%|██████████| 1/1 [08:34<00:00, 514.82s/it]
INFO:root:final mean train loss: 3333.686616220782
INFO:root:final train perplexity: 3.7256295680999756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.63s/it][A100%|██████████| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 3694.7168834496897
INFO:root:eval perplexity: 4.4550347328186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.57s/it][A100%|██████████| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 4639.3435543412015
INFO:root:eval perplexity: 6.666475296020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/61
 30%|███       | 61/200 [10:05:59<22:57:46, 594.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3320.8416369207976
INFO:root:current train perplexity3.7211191654205322
INFO:root:current mean train loss 3334.8666783297126
INFO:root:current train perplexity3.7273647785186768
INFO:root:current mean train loss 3327.5476644163764
INFO:root:current train perplexity3.7187767028808594
INFO:root:current mean train loss 3329.4890515231345
INFO:root:current train perplexity3.7188007831573486
INFO:root:current mean train loss 3327.1829285043955
INFO:root:current train perplexity3.7155861854553223
INFO:root:current mean train loss 3324.4671570552064
INFO:root:current train perplexity3.7104451656341553
INFO:root:current mean train loss 3327.277558394742
INFO:root:current train perplexity3.717134714126587
INFO:root:current mean train loss 3329.407184062798
INFO:root:current train perplexity3.720175266265869
INFO:root:current mean train loss 3330.0506843644307
INFO:root:current train perplexity3.7195868492126465
INFO:root:current mean train loss 3332.225491200054
INFO:root:current train perplexity3.719066619873047

100%|██████████| 1/1 [08:37<00:00, 517.81s/it][A100%|██████████| 1/1 [08:37<00:00, 517.81s/it]
INFO:root:final mean train loss: 3328.514382023965
INFO:root:final train perplexity: 3.7180347442626953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3746.987129806627
INFO:root:eval perplexity: 4.550201892852783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4705.044572113254
INFO:root:eval perplexity: 6.848005771636963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/62
 31%|███       | 62/200 [10:15:54<22:47:59, 594.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.1590075041117
INFO:root:current train perplexity3.7294938564300537
INFO:root:current mean train loss 3337.620935997596
INFO:root:current train perplexity3.7200021743774414
INFO:root:current mean train loss 3331.4675764698095
INFO:root:current train perplexity3.711522340774536
INFO:root:current mean train loss 3323.2123479529273
INFO:root:current train perplexity3.6986844539642334
INFO:root:current mean train loss 3321.7287242542616
INFO:root:current train perplexity3.696934938430786
INFO:root:current mean train loss 3319.122867154674
INFO:root:current train perplexity3.6966066360473633
INFO:root:current mean train loss 3319.24195881576
INFO:root:current train perplexity3.700000047683716
INFO:root:current mean train loss 3318.5824470568004
INFO:root:current train perplexity3.7016265392303467
INFO:root:current mean train loss 3319.9005051937847
INFO:root:current train perplexity3.702036142349243

100%|██████████| 1/1 [08:42<00:00, 522.68s/it][A100%|██████████| 1/1 [08:42<00:00, 522.68s/it]
INFO:root:final mean train loss: 3316.988055321478
INFO:root:final train perplexity: 3.7011654376983643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3738.5318092724956
INFO:root:eval perplexity: 4.534671306610107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.94s/it][A100%|██████████| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4689.251303814827
INFO:root:eval perplexity: 6.803923606872559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/63
 32%|███▏      | 63/200 [10:25:53<22:41:05, 596.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3364.15283203125
INFO:root:current train perplexity3.552805185317993
INFO:root:current mean train loss 3317.190830267749
INFO:root:current train perplexity3.6818480491638184
INFO:root:current mean train loss 3305.491319177186
INFO:root:current train perplexity3.678969621658325
INFO:root:current mean train loss 3309.4393677160683
INFO:root:current train perplexity3.685758590698242
INFO:root:current mean train loss 3308.3113441183314
INFO:root:current train perplexity3.6876094341278076
INFO:root:current mean train loss 3306.018754174174
INFO:root:current train perplexity3.684697389602661
INFO:root:current mean train loss 3303.278934915267
INFO:root:current train perplexity3.684591770172119
INFO:root:current mean train loss 3306.4602446684967
INFO:root:current train perplexity3.6872682571411133
INFO:root:current mean train loss 3307.089420228343
INFO:root:current train perplexity3.687516927719116
INFO:root:current mean train loss 3308.922375447726
INFO:root:current train perplexity3.6862354278564453

100%|██████████| 1/1 [08:35<00:00, 515.92s/it][A100%|██████████| 1/1 [08:35<00:00, 515.92s/it]
INFO:root:final mean train loss: 3309.288147649457
INFO:root:final train perplexity: 3.689939022064209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.06s/it][A100%|██████████| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 3728.091154490802
INFO:root:eval perplexity: 4.515566825866699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.54s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 4685.832301363032
INFO:root:eval perplexity: 6.794416904449463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/64
 32%|███▏      | 64/200 [10:35:46<22:29:04, 595.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3325.9285999644885
INFO:root:current train perplexity3.6893465518951416
INFO:root:current mean train loss 3306.560082787866
INFO:root:current train perplexity3.681485176086426
INFO:root:current mean train loss 3299.9882800929354
INFO:root:current train perplexity3.671760320663452
INFO:root:current mean train loss 3300.570503259395
INFO:root:current train perplexity3.678204298019409
INFO:root:current mean train loss 3297.1598259770376
INFO:root:current train perplexity3.6719517707824707
INFO:root:current mean train loss 3296.818288664995
INFO:root:current train perplexity3.6737914085388184
INFO:root:current mean train loss 3301.1544191451003
INFO:root:current train perplexity3.6806070804595947
INFO:root:current mean train loss 3299.6294285255144
INFO:root:current train perplexity3.6793932914733887
INFO:root:current mean train loss 3302.637105280903
INFO:root:current train perplexity3.6802713871002197
INFO:root:current mean train loss 3302.7522066453416
INFO:root:current train perplexity3.6810383796691895

100%|██████████| 1/1 [08:36<00:00, 516.11s/it][A100%|██████████| 1/1 [08:36<00:00, 516.11s/it]
INFO:root:final mean train loss: 3303.7785616228657
INFO:root:final train perplexity: 3.6819262504577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 3758.297522578679
INFO:root:eval perplexity: 4.571059703826904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 4721.21403167941
INFO:root:eval perplexity: 6.893433570861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/65
 32%|███▎      | 65/200 [10:45:39<22:17:40, 594.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.6094263980262
INFO:root:current train perplexity3.6527159214019775
INFO:root:current mean train loss 3253.9269506630776
INFO:root:current train perplexity3.6377201080322266
INFO:root:current mean train loss 3269.172800281821
INFO:root:current train perplexity3.6430840492248535
INFO:root:current mean train loss 3287.966369054908
INFO:root:current train perplexity3.663580894470215
INFO:root:current mean train loss 3296.4749216885443
INFO:root:current train perplexity3.6705644130706787
INFO:root:current mean train loss 3297.5344172424434
INFO:root:current train perplexity3.6717376708984375
INFO:root:current mean train loss 3300.345304375126
INFO:root:current train perplexity3.6718220710754395
INFO:root:current mean train loss 3303.7187747875737
INFO:root:current train perplexity3.6756927967071533
INFO:root:current mean train loss 3299.447313618456
INFO:root:current train perplexity3.670315742492676
INFO:root:current mean train loss 3296.557607092458
INFO:root:current train perplexity3.668663501739502

100%|██████████| 1/1 [08:38<00:00, 518.20s/it][A100%|██████████| 1/1 [08:38<00:00, 518.20s/it]
INFO:root:final mean train loss: 3295.4521887994583
INFO:root:final train perplexity: 3.669851541519165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3709.25791292664
INFO:root:eval perplexity: 4.4813079833984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.55s/it][A100%|██████████| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 4665.272275667664
INFO:root:eval perplexity: 6.737534999847412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/66
 33%|███▎      | 66/200 [10:55:34<22:08:12, 594.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.859230324074
INFO:root:current train perplexity3.7230255603790283
INFO:root:current mean train loss 3332.8934585691436
INFO:root:current train perplexity3.707113742828369
INFO:root:current mean train loss 3297.659304446586
INFO:root:current train perplexity3.6708552837371826
INFO:root:current mean train loss 3288.430134717842
INFO:root:current train perplexity3.6612377166748047
INFO:root:current mean train loss 3287.4598282896663
INFO:root:current train perplexity3.6567702293395996
INFO:root:current mean train loss 3286.7993599531546
INFO:root:current train perplexity3.659559488296509
INFO:root:current mean train loss 3280.8044211647725
INFO:root:current train perplexity3.6518971920013428
INFO:root:current mean train loss 3284.4628107000085
INFO:root:current train perplexity3.653764009475708
INFO:root:current mean train loss 3287.8400961565712
INFO:root:current train perplexity3.6551826000213623
INFO:root:current mean train loss 3288.2033583426037
INFO:root:current train perplexity3.656338691711426

100%|██████████| 1/1 [08:39<00:00, 519.07s/it][A100%|██████████| 1/1 [08:39<00:00, 519.07s/it]
INFO:root:final mean train loss: 3284.9290716109736
INFO:root:final train perplexity: 3.6546475887298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3691.2168436253323
INFO:root:eval perplexity: 4.448734760284424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.18s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 4651.791235524712
INFO:root:eval perplexity: 6.700494766235352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/67
 34%|███▎      | 67/200 [11:05:29<21:58:50, 594.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.9167131696427
INFO:root:current train perplexity3.5889196395874023
INFO:root:current mean train loss 3256.6239203559026
INFO:root:current train perplexity3.610690116882324
INFO:root:current mean train loss 3261.145946226729
INFO:root:current train perplexity3.6190311908721924
INFO:root:current mean train loss 3265.1764743178637
INFO:root:current train perplexity3.6269261837005615
INFO:root:current mean train loss 3275.1666279409123
INFO:root:current train perplexity3.639326333999634
INFO:root:current mean train loss 3269.8357741311333
INFO:root:current train perplexity3.632615804672241
INFO:root:current mean train loss 3272.1992875707433
INFO:root:current train perplexity3.6345152854919434
INFO:root:current mean train loss 3278.3826274845874
INFO:root:current train perplexity3.6418161392211914
INFO:root:current mean train loss 3280.2971483790234
INFO:root:current train perplexity3.642904758453369
INFO:root:current mean train loss 3279.129547543449
INFO:root:current train perplexity3.6435961723327637

100%|██████████| 1/1 [08:36<00:00, 516.34s/it][A100%|██████████| 1/1 [08:36<00:00, 516.34s/it]
INFO:root:final mean train loss: 3278.6352187125913
INFO:root:final train perplexity: 3.645583391189575
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.58s/it][A100%|██████████| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 3712.4571974734044
INFO:root:eval perplexity: 4.487109184265137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.37s/it][A100%|██████████| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 4668.762669340093
INFO:root:eval perplexity: 6.747156620025635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/68
 34%|███▍      | 68/200 [11:15:22<21:47:31, 594.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.1409032067586
INFO:root:current train perplexity3.6424036026000977
INFO:root:current mean train loss 3260.7934416657563
INFO:root:current train perplexity3.6080946922302246
INFO:root:current mean train loss 3268.3673241383744
INFO:root:current train perplexity3.6121439933776855
INFO:root:current mean train loss 3262.1265324628735
INFO:root:current train perplexity3.613738536834717
INFO:root:current mean train loss 3271.7207775245133
INFO:root:current train perplexity3.6242425441741943
INFO:root:current mean train loss 3270.854588854598
INFO:root:current train perplexity3.623614549636841
INFO:root:current mean train loss 3271.557568966879
INFO:root:current train perplexity3.6283693313598633
INFO:root:current mean train loss 3270.986750360132
INFO:root:current train perplexity3.628325939178467
INFO:root:current mean train loss 3271.4828209565912
INFO:root:current train perplexity3.6287169456481934
INFO:root:current mean train loss 3272.090888402621
INFO:root:current train perplexity3.6325509548187256

100%|██████████| 1/1 [08:36<00:00, 516.82s/it][A100%|██████████| 1/1 [08:36<00:00, 516.82s/it]
INFO:root:final mean train loss: 3270.8509151089575
INFO:root:final train perplexity: 3.6344046592712402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.69s/it][A100%|██████████| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 3676.661427166445
INFO:root:eval perplexity: 4.422627925872803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4641.0271480912015
INFO:root:eval perplexity: 6.671067714691162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/69
 34%|███▍      | 69/200 [11:25:16<21:36:57, 594.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.9036410462622
INFO:root:current train perplexity3.6621382236480713
INFO:root:current mean train loss 3290.8294362453435
INFO:root:current train perplexity3.6442763805389404
INFO:root:current mean train loss 3265.6048267866036
INFO:root:current train perplexity3.6198108196258545
INFO:root:current mean train loss 3261.93495147792
INFO:root:current train perplexity3.616698741912842
INFO:root:current mean train loss 3263.3126699781733
INFO:root:current train perplexity3.619351387023926
INFO:root:current mean train loss 3257.9971097471926
INFO:root:current train perplexity3.6159017086029053
INFO:root:current mean train loss 3259.9735585577478
INFO:root:current train perplexity3.619699001312256
INFO:root:current mean train loss 3260.1477502652715
INFO:root:current train perplexity3.6213412284851074
INFO:root:current mean train loss 3261.218515039751
INFO:root:current train perplexity3.618736505508423
INFO:root:current mean train loss 3265.133552623472
INFO:root:current train perplexity3.6227641105651855

100%|██████████| 1/1 [08:37<00:00, 517.00s/it][A100%|██████████| 1/1 [08:37<00:00, 517.00s/it]
INFO:root:final mean train loss: 3263.557117708268
INFO:root:final train perplexity: 3.6239609718322754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 3734.6996014101287
INFO:root:eval perplexity: 4.527649402618408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.22s/it][A100%|██████████| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4704.4914585411125
INFO:root:eval perplexity: 6.8464555740356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/70
 35%|███▌      | 70/200 [11:35:09<21:26:44, 593.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.600639731197
INFO:root:current train perplexity3.5775070190429688
INFO:root:current mean train loss 3250.591420683471
INFO:root:current train perplexity3.601670265197754
INFO:root:current mean train loss 3245.3181934724903
INFO:root:current train perplexity3.6028220653533936
INFO:root:current mean train loss 3254.5903102694115
INFO:root:current train perplexity3.6109445095062256
INFO:root:current mean train loss 3257.967914922045
INFO:root:current train perplexity3.6134989261627197
INFO:root:current mean train loss 3253.787017221741
INFO:root:current train perplexity3.6097893714904785
INFO:root:current mean train loss 3250.700858456231
INFO:root:current train perplexity3.6064035892486572
INFO:root:current mean train loss 3255.94909748384
INFO:root:current train perplexity3.6104345321655273
INFO:root:current mean train loss 3256.535092017426
INFO:root:current train perplexity3.6125967502593994
INFO:root:current mean train loss 3259.232824617929
INFO:root:current train perplexity3.6146700382232666

100%|██████████| 1/1 [08:38<00:00, 518.22s/it][A100%|██████████| 1/1 [08:38<00:00, 518.22s/it]
INFO:root:final mean train loss: 3257.2643296026413
INFO:root:final train perplexity: 3.6149754524230957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3693.6148759557846
INFO:root:eval perplexity: 4.4530510902404785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.41s/it][A100%|██████████| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 4660.42876115082
INFO:root:eval perplexity: 6.724203109741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/71
 36%|███▌      | 71/200 [11:45:04<21:17:28, 594.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.6406905900185
INFO:root:current train perplexity3.5613067150115967
INFO:root:current mean train loss 3242.5350860778444
INFO:root:current train perplexity3.5778908729553223
INFO:root:current mean train loss 3245.651673506262
INFO:root:current train perplexity3.588697671890259
INFO:root:current mean train loss 3242.9652475466196
INFO:root:current train perplexity3.5910706520080566
INFO:root:current mean train loss 3239.233965659295
INFO:root:current train perplexity3.5917954444885254
INFO:root:current mean train loss 3248.7797636270943
INFO:root:current train perplexity3.5997653007507324
INFO:root:current mean train loss 3251.083442653673
INFO:root:current train perplexity3.60387921333313
INFO:root:current mean train loss 3252.0274688442187
INFO:root:current train perplexity3.605210304260254
INFO:root:current mean train loss 3254.1540203512473
INFO:root:current train perplexity3.605107069015503
INFO:root:current mean train loss 3256.0865780219915
INFO:root:current train perplexity3.608290433883667

100%|██████████| 1/1 [08:33<00:00, 513.78s/it][A100%|██████████| 1/1 [08:33<00:00, 513.78s/it]
INFO:root:final mean train loss: 3253.5950730846776
INFO:root:final train perplexity: 3.609745979309082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3715.9262158549423
INFO:root:eval perplexity: 4.493408203125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.88s/it][A100%|██████████| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 4682.195437167553
INFO:root:eval perplexity: 6.784319877624512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/72
 36%|███▌      | 72/200 [11:54:54<21:04:53, 592.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.8890006510414
INFO:root:current train perplexity3.5973236560821533
INFO:root:current mean train loss 3238.0978794642856
INFO:root:current train perplexity3.5748958587646484
INFO:root:current mean train loss 3239.3853480113635
INFO:root:current train perplexity3.5745997428894043
INFO:root:current mean train loss 3237.2630006510417
INFO:root:current train perplexity3.5813794136047363
INFO:root:current mean train loss 3239.0706887335527
INFO:root:current train perplexity3.5866665840148926
INFO:root:current mean train loss 3236.4492726732337
INFO:root:current train perplexity3.5850088596343994
INFO:root:current mean train loss 3236.3495732060187
INFO:root:current train perplexity3.5844054222106934
INFO:root:current mean train loss 3241.279807837702
INFO:root:current train perplexity3.589326858520508
INFO:root:current mean train loss 3240.8564104352677
INFO:root:current train perplexity3.5903701782226562
INFO:root:current mean train loss 3243.7755481270033
INFO:root:current train perplexity3.5931777954101562

100%|██████████| 1/1 [08:35<00:00, 515.42s/it][A100%|██████████| 1/1 [08:35<00:00, 515.43s/it]
INFO:root:final mean train loss: 3242.2917304500456
INFO:root:final train perplexity: 3.593684196472168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3704.7438739749555
INFO:root:eval perplexity: 4.473134994506836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4672.546570257092
INFO:root:eval perplexity: 6.757604598999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/73
 36%|███▋      | 73/200 [12:04:46<20:54:31, 592.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.185667474586
INFO:root:current train perplexity3.574936628341675
INFO:root:current mean train loss 3248.5476154264857
INFO:root:current train perplexity3.586494207382202
INFO:root:current mean train loss 3245.2151042816918
INFO:root:current train perplexity3.5847225189208984
INFO:root:current mean train loss 3241.886963528068
INFO:root:current train perplexity3.58412504196167
INFO:root:current mean train loss 3243.6748264225866
INFO:root:current train perplexity3.5852127075195312
INFO:root:current mean train loss 3239.925035008844
INFO:root:current train perplexity3.583383560180664
INFO:root:current mean train loss 3241.1637976270817
INFO:root:current train perplexity3.585965871810913
INFO:root:current mean train loss 3240.0036237577824
INFO:root:current train perplexity3.5850024223327637
INFO:root:current mean train loss 3239.6238644557793
INFO:root:current train perplexity3.584552764892578
INFO:root:current mean train loss 3242.8711456578235
INFO:root:current train perplexity3.5903701782226562

100%|██████████| 1/1 [08:39<00:00, 519.79s/it][A100%|██████████| 1/1 [08:39<00:00, 519.80s/it]
INFO:root:final mean train loss: 3240.263597119239
INFO:root:final train perplexity: 3.5908098220825195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.21s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3692.1572386829566
INFO:root:eval perplexity: 4.450427055358887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.22s/it][A100%|██████████| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4665.554682305518
INFO:root:eval perplexity: 6.738311290740967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/74
 37%|███▋      | 74/200 [12:14:43<20:47:11, 593.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.9156775841348
INFO:root:current train perplexity3.5725958347320557
INFO:root:current mean train loss 3214.91144342073
INFO:root:current train perplexity3.554436683654785
INFO:root:current mean train loss 3219.53899370436
INFO:root:current train perplexity3.5677008628845215
INFO:root:current mean train loss 3228.2538119655133
INFO:root:current train perplexity3.5741820335388184
INFO:root:current mean train loss 3229.908918641007
INFO:root:current train perplexity3.575860023498535
INFO:root:current mean train loss 3227.3136277561866
INFO:root:current train perplexity3.573157548904419
INFO:root:current mean train loss 3229.127648448806
INFO:root:current train perplexity3.571676015853882
INFO:root:current mean train loss 3231.0544553966497
INFO:root:current train perplexity3.57548189163208
INFO:root:current mean train loss 3232.910204749316
INFO:root:current train perplexity3.576627731323242
INFO:root:current mean train loss 3232.5886146707085
INFO:root:current train perplexity3.5764758586883545

100%|██████████| 1/1 [08:38<00:00, 518.96s/it][A100%|██████████| 1/1 [08:38<00:00, 518.96s/it]
INFO:root:final mean train loss: 3230.0968111099737
INFO:root:final train perplexity: 3.5764358043670654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3737.335104651485
INFO:root:eval perplexity: 4.532476902008057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 4711.63008366578
INFO:root:eval perplexity: 6.866471767425537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/75
 38%|███▊      | 75/200 [12:24:38<20:38:20, 594.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3206.7632057883525
INFO:root:current train perplexity3.549699544906616
INFO:root:current mean train loss 3212.5892941268844
INFO:root:current train perplexity3.5572991371154785
INFO:root:current mean train loss 3217.051445900397
INFO:root:current train perplexity3.5552237033843994
INFO:root:current mean train loss 3223.7602282072367
INFO:root:current train perplexity3.5604870319366455
INFO:root:current mean train loss 3226.6217630573647
INFO:root:current train perplexity3.5639665126800537
INFO:root:current mean train loss 3225.0579134984087
INFO:root:current train perplexity3.5644993782043457
INFO:root:current mean train loss 3227.7601997692013
INFO:root:current train perplexity3.568789005279541
INFO:root:current mean train loss 3228.945083942819
INFO:root:current train perplexity3.570197820663452
INFO:root:current mean train loss 3228.742061763505
INFO:root:current train perplexity3.569338321685791

100%|██████████| 1/1 [08:36<00:00, 516.16s/it][A100%|██████████| 1/1 [08:36<00:00, 516.16s/it]
INFO:root:final mean train loss: 3225.028645423151
INFO:root:final train perplexity: 3.569291114807129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.32s/it][A100%|██████████| 1/1 [00:38<00:00, 38.32s/it]
INFO:root:eval mean loss: 3692.9005118295654
INFO:root:eval perplexity: 4.451764106750488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.11s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4661.759033203125
INFO:root:eval perplexity: 6.7278618812561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/76
 38%|███▊      | 76/200 [12:34:31<20:27:35, 593.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3168.3128836495534
INFO:root:current train perplexity3.598158121109009
INFO:root:current mean train loss 3208.2633250584113
INFO:root:current train perplexity3.5747666358947754
INFO:root:current mean train loss 3196.3915791534573
INFO:root:current train perplexity3.5463435649871826
INFO:root:current mean train loss 3196.8396457336626
INFO:root:current train perplexity3.543773651123047
INFO:root:current mean train loss 3206.0114668112715
INFO:root:current train perplexity3.552844285964966
INFO:root:current mean train loss 3208.613018329327
INFO:root:current train perplexity3.550510883331299
INFO:root:current mean train loss 3212.4118616144974
INFO:root:current train perplexity3.5527184009552
INFO:root:current mean train loss 3213.236168932881
INFO:root:current train perplexity3.5513863563537598
INFO:root:current mean train loss 3217.1145285756465
INFO:root:current train perplexity3.5567243099212646
INFO:root:current mean train loss 3219.0061417383026
INFO:root:current train perplexity3.5578010082244873

100%|██████████| 1/1 [08:37<00:00, 517.71s/it][A100%|██████████| 1/1 [08:37<00:00, 517.71s/it]
INFO:root:final mean train loss: 3216.3003655710527
INFO:root:final train perplexity: 3.557021379470825
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.18s/it][A100%|██████████| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 3704.78313905973
INFO:root:eval perplexity: 4.473206520080566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 4674.723257078346
INFO:root:eval perplexity: 6.763622760772705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/77
 38%|███▊      | 77/200 [12:44:26<20:18:04, 594.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3183.24912109375
INFO:root:current train perplexity3.5042338371276855
INFO:root:current mean train loss 3203.548409901495
INFO:root:current train perplexity3.545182228088379
INFO:root:current mean train loss 3205.34776412609
INFO:root:current train perplexity3.5470504760742188
INFO:root:current mean train loss 3196.875570436508
INFO:root:current train perplexity3.5366721153259277
INFO:root:current mean train loss 3204.80810546875
INFO:root:current train perplexity3.541447401046753
INFO:root:current mean train loss 3210.093896484375
INFO:root:current train perplexity3.547503709793091
INFO:root:current mean train loss 3211.457118187881
INFO:root:current train perplexity3.547786235809326
INFO:root:current mean train loss 3213.099358063811
INFO:root:current train perplexity3.547686815261841
INFO:root:current mean train loss 3218.479695887653
INFO:root:current train perplexity3.5542612075805664
INFO:root:current mean train loss 3216.045178556182
INFO:root:current train perplexity3.553168296813965

100%|██████████| 1/1 [08:33<00:00, 513.54s/it][A100%|██████████| 1/1 [08:33<00:00, 513.55s/it]
INFO:root:final mean train loss: 3214.473679019559
INFO:root:final train perplexity: 3.5544590950012207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.41s/it][A100%|██████████| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 3696.0407264655364
INFO:root:eval perplexity: 4.457420349121094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.87s/it][A100%|██████████| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4662.665606992465
INFO:root:eval perplexity: 6.7303547859191895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/78
 39%|███▉      | 78/200 [12:54:16<20:05:49, 593.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.147121263587
INFO:root:current train perplexity3.5543951988220215
INFO:root:current mean train loss 3184.733587001397
INFO:root:current train perplexity3.526360034942627
INFO:root:current mean train loss 3195.733163055283
INFO:root:current train perplexity3.53802227973938
INFO:root:current mean train loss 3187.8676100220105
INFO:root:current train perplexity3.5327539443969727
INFO:root:current mean train loss 3196.0096178708627
INFO:root:current train perplexity3.5336601734161377
INFO:root:current mean train loss 3192.5238931046847
INFO:root:current train perplexity3.532174825668335
INFO:root:current mean train loss 3201.8219172445574
INFO:root:current train perplexity3.53760027885437
INFO:root:current mean train loss 3204.5040261254107
INFO:root:current train perplexity3.5388123989105225
INFO:root:current mean train loss 3208.041110255449
INFO:root:current train perplexity3.5430450439453125
INFO:root:current mean train loss 3210.031505249949
INFO:root:current train perplexity3.5440402030944824

100%|██████████| 1/1 [08:40<00:00, 520.44s/it][A100%|██████████| 1/1 [08:40<00:00, 520.44s/it]
INFO:root:final mean train loss: 3206.881214018791
INFO:root:final train perplexity: 3.543827772140503
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 3695.8641521913787
INFO:root:eval perplexity: 4.457103252410889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.28s/it][A100%|██████████| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 4669.920114070811
INFO:root:eval perplexity: 6.750351428985596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/79
 40%|███▉      | 79/200 [13:04:14<19:58:26, 594.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.745164440524
INFO:root:current train perplexity3.5075173377990723
INFO:root:current mean train loss 3211.1318079824664
INFO:root:current train perplexity3.5314455032348633
INFO:root:current mean train loss 3197.8161716213476
INFO:root:current train perplexity3.525893449783325
INFO:root:current mean train loss 3203.1621484670036
INFO:root:current train perplexity3.5305182933807373
INFO:root:current mean train loss 3200.419575773093
INFO:root:current train perplexity3.533086061477661
INFO:root:current mean train loss 3207.180033710717
INFO:root:current train perplexity3.540667772293091
INFO:root:current mean train loss 3201.703058451367
INFO:root:current train perplexity3.5365865230560303
INFO:root:current mean train loss 3201.03307955177
INFO:root:current train perplexity3.5351943969726562
INFO:root:current mean train loss 3203.1629425673136
INFO:root:current train perplexity3.536304473876953
INFO:root:current mean train loss 3205.2920223445053
INFO:root:current train perplexity3.538005828857422

100%|██████████| 1/1 [08:37<00:00, 517.63s/it][A100%|██████████| 1/1 [08:37<00:00, 517.63s/it]
INFO:root:final mean train loss: 3202.7045126884213
INFO:root:final train perplexity: 3.5379929542541504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 3736.0879373753323
INFO:root:eval perplexity: 4.5301923751831055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4715.514632854056
INFO:root:eval perplexity: 6.877387523651123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/80
 40%|████      | 80/200 [13:14:08<19:48:32, 594.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3179.688144781651
INFO:root:current train perplexity3.491014242172241
INFO:root:current mean train loss 3167.632197757419
INFO:root:current train perplexity3.4851346015930176
INFO:root:current mean train loss 3176.8013114131145
INFO:root:current train perplexity3.498263359069824
INFO:root:current mean train loss 3190.673857652332
INFO:root:current train perplexity3.510207176208496
INFO:root:current mean train loss 3184.0877944146855
INFO:root:current train perplexity3.5093390941619873
INFO:root:current mean train loss 3187.799621695269
INFO:root:current train perplexity3.5136895179748535
INFO:root:current mean train loss 3190.984768528707
INFO:root:current train perplexity3.516219139099121
INFO:root:current mean train loss 3193.1051334283025
INFO:root:current train perplexity3.5182900428771973
INFO:root:current mean train loss 3196.2703885065926
INFO:root:current train perplexity3.5233325958251953
INFO:root:current mean train loss 3193.601623860157
INFO:root:current train perplexity3.5229649543762207

100%|██████████| 1/1 [08:39<00:00, 519.32s/it][A100%|██████████| 1/1 [08:39<00:00, 519.32s/it]
INFO:root:final mean train loss: 3193.252723263156
INFO:root:final train perplexity: 3.524824619293213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.99s/it][A100%|██████████| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 3755.099626689938
INFO:root:eval perplexity: 4.565153121948242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.07s/it][A100%|██████████| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4740.406244805518
INFO:root:eval perplexity: 6.947746276855469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/81
 40%|████      | 81/200 [13:24:04<19:39:31, 594.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.174098238032
INFO:root:current train perplexity3.5603859424591064
INFO:root:current mean train loss 3194.861138791454
INFO:root:current train perplexity3.5273029804229736
INFO:root:current mean train loss 3189.0244041782644
INFO:root:current train perplexity3.5095767974853516
INFO:root:current mean train loss 3194.283176389139
INFO:root:current train perplexity3.5143496990203857
INFO:root:current mean train loss 3190.590419419393
INFO:root:current train perplexity3.511350631713867
INFO:root:current mean train loss 3193.0203806094323
INFO:root:current train perplexity3.5150156021118164
INFO:root:current mean train loss 3195.0404722517387
INFO:root:current train perplexity3.519259452819824
INFO:root:current mean train loss 3188.582677716073
INFO:root:current train perplexity3.514561891555786
INFO:root:current mean train loss 3187.7844053806634
INFO:root:current train perplexity3.514552116394043
INFO:root:current mean train loss 3188.840434895146
INFO:root:current train perplexity3.516218900680542

100%|██████████| 1/1 [08:38<00:00, 518.15s/it][A100%|██████████| 1/1 [08:38<00:00, 518.15s/it]
INFO:root:final mean train loss: 3187.935313194029
INFO:root:final train perplexity: 3.517437219619751
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3674.4416122977614
INFO:root:eval perplexity: 4.418659687042236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4648.565587253435
INFO:root:eval perplexity: 6.691662311553955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/82
 41%|████      | 82/200 [13:33:59<19:29:43, 594.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.0363414417616
INFO:root:current train perplexity3.5126209259033203
INFO:root:current mean train loss 3190.04365234375
INFO:root:current train perplexity3.5208334922790527
INFO:root:current mean train loss 3193.47515893076
INFO:root:current train perplexity3.5170655250549316
INFO:root:current mean train loss 3194.7495990591988
INFO:root:current train perplexity3.5253822803497314
INFO:root:current mean train loss 3192.5475768372253
INFO:root:current train perplexity3.520461320877075
INFO:root:current mean train loss 3194.650680954392
INFO:root:current train perplexity3.5219271183013916
INFO:root:current mean train loss 3190.570955093034
INFO:root:current train perplexity3.5182695388793945
INFO:root:current mean train loss 3185.811885929739
INFO:root:current train perplexity3.511265754699707
INFO:root:current mean train loss 3185.821626576206
INFO:root:current train perplexity3.511539936065674
INFO:root:current mean train loss 3187.162255859375
INFO:root:current train perplexity3.5129666328430176

100%|██████████| 1/1 [08:36<00:00, 516.05s/it][A100%|██████████| 1/1 [08:36<00:00, 516.05s/it]
INFO:root:final mean train loss: 3183.9153613428916
INFO:root:final train perplexity: 3.5118629932403564
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.72s/it][A100%|██████████| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 3691.9823924396055
INFO:root:eval perplexity: 4.450112342834473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4672.578531901042
INFO:root:eval perplexity: 6.757692337036133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/83
 42%|████▏     | 83/200 [13:43:51<19:18:32, 594.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3159.573180183532
INFO:root:current train perplexity3.479142904281616
INFO:root:current mean train loss 3167.517841736963
INFO:root:current train perplexity3.4829511642456055
INFO:root:current mean train loss 3168.368918763367
INFO:root:current train perplexity3.4855988025665283
INFO:root:current mean train loss 3160.9413336131197
INFO:root:current train perplexity3.4853968620300293
INFO:root:current mean train loss 3163.3774994094224
INFO:root:current train perplexity3.489226818084717
INFO:root:current mean train loss 3171.6386358826876
INFO:root:current train perplexity3.4945857524871826
INFO:root:current mean train loss 3171.85226214885
INFO:root:current train perplexity3.496150493621826
INFO:root:current mean train loss 3174.9804319529203
INFO:root:current train perplexity3.4984538555145264
INFO:root:current mean train loss 3173.2673181421096
INFO:root:current train perplexity3.497671127319336
INFO:root:current mean train loss 3177.2982539001655
INFO:root:current train perplexity3.5001471042633057

100%|██████████| 1/1 [08:37<00:00, 517.62s/it][A100%|██████████| 1/1 [08:37<00:00, 517.62s/it]
INFO:root:final mean train loss: 3176.921106153919
INFO:root:final train perplexity: 3.5021860599517822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3720.612278715093
INFO:root:eval perplexity: 4.501931190490723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 4698.310077640182
INFO:root:eval perplexity: 6.829172611236572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/84
 42%|████▏     | 84/200 [13:53:45<19:08:43, 594.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3167.6616245323503
INFO:root:current train perplexity3.489837884902954
INFO:root:current mean train loss 3169.0239372030337
INFO:root:current train perplexity3.4895429611206055
INFO:root:current mean train loss 3163.02486360557
INFO:root:current train perplexity3.4765684604644775
INFO:root:current mean train loss 3177.3354531671157
INFO:root:current train perplexity3.4911906719207764
INFO:root:current mean train loss 3170.0077689589966
INFO:root:current train perplexity3.4839656352996826
INFO:root:current mean train loss 3172.668077779526
INFO:root:current train perplexity3.485450267791748
INFO:root:current mean train loss 3171.3146179472105
INFO:root:current train perplexity3.4851653575897217
INFO:root:current mean train loss 3171.1650317794465
INFO:root:current train perplexity3.4876902103424072
INFO:root:current mean train loss 3172.5520596947654
INFO:root:current train perplexity3.4921228885650635
INFO:root:current mean train loss 3175.1757510781413
INFO:root:current train perplexity3.4959933757781982

100%|██████████| 1/1 [08:37<00:00, 517.97s/it][A100%|██████████| 1/1 [08:37<00:00, 517.97s/it]
INFO:root:final mean train loss: 3172.7749616561396
INFO:root:final train perplexity: 3.496461868286133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3689.9092247063386
INFO:root:eval perplexity: 4.446383476257324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 4672.77773160461
INFO:root:eval perplexity: 6.758242607116699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/85
 42%|████▎     | 85/200 [14:03:40<18:59:01, 594.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3132.1730369857596
INFO:root:current train perplexity3.456660032272339
INFO:root:current mean train loss 3164.0447350187674
INFO:root:current train perplexity3.483736753463745
INFO:root:current mean train loss 3176.2298133330532
INFO:root:current train perplexity3.497330904006958
INFO:root:current mean train loss 3177.3247108962732
INFO:root:current train perplexity3.492508888244629
INFO:root:current mean train loss 3180.4344087413556
INFO:root:current train perplexity3.4947800636291504
INFO:root:current mean train loss 3174.0208130936962
INFO:root:current train perplexity3.490973711013794
INFO:root:current mean train loss 3174.703526267949
INFO:root:current train perplexity3.4912338256835938
INFO:root:current mean train loss 3176.8567862945283
INFO:root:current train perplexity3.4936773777008057
INFO:root:current mean train loss 3172.6961999053433
INFO:root:current train perplexity3.491180181503296
INFO:root:current mean train loss 3171.4461035256
INFO:root:current train perplexity3.4922070503234863

100%|██████████| 1/1 [08:38<00:00, 518.05s/it][A100%|██████████| 1/1 [08:38<00:00, 518.05s/it]
INFO:root:final mean train loss: 3169.369674867199
INFO:root:final train perplexity: 3.491767168045044
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 3668.496176861702
INFO:root:eval perplexity: 4.4080491065979
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4642.518218777704
INFO:root:eval perplexity: 6.675134181976318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/86
 43%|████▎     | 86/200 [14:13:35<18:49:20, 594.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3155.7678952271913
INFO:root:current train perplexity3.4792542457580566
INFO:root:current mean train loss 3151.6083449093417
INFO:root:current train perplexity3.474233388900757
INFO:root:current mean train loss 3143.978844832045
INFO:root:current train perplexity3.4671576023101807
INFO:root:current mean train loss 3149.2618682624757
INFO:root:current train perplexity3.4685702323913574
INFO:root:current mean train loss 3150.095664022395
INFO:root:current train perplexity3.4697070121765137
INFO:root:current mean train loss 3153.529466151379
INFO:root:current train perplexity3.470154285430908
INFO:root:current mean train loss 3157.5792796039163
INFO:root:current train perplexity3.4741933345794678
INFO:root:current mean train loss 3158.4066393220896
INFO:root:current train perplexity3.4723284244537354
INFO:root:current mean train loss 3157.4138453331984
INFO:root:current train perplexity3.4730656147003174
INFO:root:current mean train loss 3161.859271852441
INFO:root:current train perplexity3.477809429168701

100%|██████████| 1/1 [08:37<00:00, 517.80s/it][A100%|██████████| 1/1 [08:37<00:00, 517.80s/it]
INFO:root:final mean train loss: 3159.2590924539873
INFO:root:final train perplexity: 3.4778666496276855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3732.3871602809177
INFO:root:eval perplexity: 4.523417949676514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4721.808749584441
INFO:root:eval perplexity: 6.895109176635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/87
 44%|████▎     | 87/200 [14:23:29<18:39:33, 594.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3164.594801089638
INFO:root:current train perplexity3.4656505584716797
INFO:root:current mean train loss 3156.4015049078525
INFO:root:current train perplexity3.457674264907837
INFO:root:current mean train loss 3153.6708040916315
INFO:root:current train perplexity3.4584343433380127
INFO:root:current mean train loss 3157.0929588607596
INFO:root:current train perplexity3.464055061340332
INFO:root:current mean train loss 3155.2223899147725
INFO:root:current train perplexity3.4678261280059814
INFO:root:current mean train loss 3157.292957261029
INFO:root:current train perplexity3.4710280895233154
INFO:root:current mean train loss 3159.183892339254
INFO:root:current train perplexity3.473688840866089
INFO:root:current mean train loss 3159.394978073408
INFO:root:current train perplexity3.473668098449707
INFO:root:current mean train loss 3162.6648824851604
INFO:root:current train perplexity3.4767842292785645

100%|██████████| 1/1 [08:36<00:00, 516.99s/it][A100%|██████████| 1/1 [08:36<00:00, 516.99s/it]
INFO:root:final mean train loss: 3158.0470467229043
INFO:root:final train perplexity: 3.4762041568756104
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3688.527847614694
INFO:root:eval perplexity: 4.443900108337402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.37s/it][A100%|██████████| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4672.552976784131
INFO:root:eval perplexity: 6.757623195648193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/88
 44%|████▍     | 88/200 [14:33:23<18:29:20, 594.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3021.8741861979165
INFO:root:current train perplexity3.3236477375030518
INFO:root:current mean train loss 3129.5607056849212
INFO:root:current train perplexity3.4384093284606934
INFO:root:current mean train loss 3133.015929273784
INFO:root:current train perplexity3.4452781677246094
INFO:root:current mean train loss 3151.0918669747834
INFO:root:current train perplexity3.465951681137085
INFO:root:current mean train loss 3152.3446108531716
INFO:root:current train perplexity3.465061902999878
INFO:root:current mean train loss 3157.322212719775
INFO:root:current train perplexity3.4706718921661377
INFO:root:current mean train loss 3157.6063926785346
INFO:root:current train perplexity3.4709651470184326
INFO:root:current mean train loss 3157.965265352729
INFO:root:current train perplexity3.469327688217163
INFO:root:current mean train loss 3156.0023936726534
INFO:root:current train perplexity3.4700963497161865
INFO:root:current mean train loss 3153.67847274493
INFO:root:current train perplexity3.466886043548584

100%|██████████| 1/1 [08:38<00:00, 518.31s/it][A100%|██████████| 1/1 [08:38<00:00, 518.31s/it]
INFO:root:final mean train loss: 3150.636529061102
INFO:root:final train perplexity: 3.4660558700561523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3706.9611210383423
INFO:root:eval perplexity: 4.477148056030273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:40<00:00, 40.32s/it][A100%|██████████| 1/1 [00:40<00:00, 40.32s/it]
INFO:root:eval mean loss: 4693.573761635638
INFO:root:eval perplexity: 6.815958499908447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/89
 44%|████▍     | 89/200 [14:43:21<18:21:37, 595.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3168.0906871448865
INFO:root:current train perplexity3.443929672241211
INFO:root:current mean train loss 3120.062277854026
INFO:root:current train perplexity3.408862590789795
INFO:root:current mean train loss 3132.1318972619224
INFO:root:current train perplexity3.4392545223236084
INFO:root:current mean train loss 3148.281967506531
INFO:root:current train perplexity3.454091787338257
INFO:root:current mean train loss 3148.27919589226
INFO:root:current train perplexity3.4631292819976807
INFO:root:current mean train loss 3150.2750150975417
INFO:root:current train perplexity3.4632010459899902
INFO:root:current mean train loss 3151.453391916428
INFO:root:current train perplexity3.4621975421905518
INFO:root:current mean train loss 3148.3142371412405
INFO:root:current train perplexity3.458721399307251
INFO:root:current mean train loss 3147.1447055501503
INFO:root:current train perplexity3.458702802658081
INFO:root:current mean train loss 3146.6121128052964
INFO:root:current train perplexity3.457158327102661

100%|██████████| 1/1 [08:38<00:00, 518.92s/it][A100%|██████████| 1/1 [08:38<00:00, 518.92s/it]
INFO:root:final mean train loss: 3144.4548390911473
INFO:root:final train perplexity: 3.4576127529144287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 3665.6364365165114
INFO:root:eval perplexity: 4.4029541015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.41s/it][A100%|██████████| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 4648.640765250997
INFO:root:eval perplexity: 6.691869258880615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/90
 45%|████▌     | 90/200 [14:53:17<18:11:48, 595.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3064.354672080592
INFO:root:current train perplexity3.3991541862487793
INFO:root:current mean train loss 3134.90301667542
INFO:root:current train perplexity3.4574315547943115
INFO:root:current mean train loss 3143.609779671447
INFO:root:current train perplexity3.4577767848968506
INFO:root:current mean train loss 3143.6622808091693
INFO:root:current train perplexity3.450744867324829
INFO:root:current mean train loss 3143.5396981979043
INFO:root:current train perplexity3.45194411277771
INFO:root:current mean train loss 3142.3137169398783
INFO:root:current train perplexity3.449984312057495
INFO:root:current mean train loss 3146.197818589711
INFO:root:current train perplexity3.457493782043457
INFO:root:current mean train loss 3147.6023166534465
INFO:root:current train perplexity3.459183692932129
INFO:root:current mean train loss 3148.2649748526214
INFO:root:current train perplexity3.4577319622039795
INFO:root:current mean train loss 3144.9076909344394
INFO:root:current train perplexity3.454195499420166

100%|██████████| 1/1 [08:32<00:00, 512.89s/it][A100%|██████████| 1/1 [08:32<00:00, 512.89s/it]
INFO:root:final mean train loss: 3141.118957150367
INFO:root:final train perplexity: 3.4530653953552246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 3692.7973909851507
INFO:root:eval perplexity: 4.451579570770264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4680.999903036348
INFO:root:eval perplexity: 6.781004428863525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/91
 46%|████▌     | 91/200 [15:03:06<17:58:32, 593.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3050.727466724537
INFO:root:current train perplexity3.3562943935394287
INFO:root:current mean train loss 3104.9876276451773
INFO:root:current train perplexity3.4099676609039307
INFO:root:current mean train loss 3110.016995198926
INFO:root:current train perplexity3.4144177436828613
INFO:root:current mean train loss 3121.955131880734
INFO:root:current train perplexity3.427532434463501
INFO:root:current mean train loss 3125.762331674473
INFO:root:current train perplexity3.4341461658477783
INFO:root:current mean train loss 3132.6348828310306
INFO:root:current train perplexity3.439954996109009
INFO:root:current mean train loss 3137.2815576094
INFO:root:current train perplexity3.445732355117798
INFO:root:current mean train loss 3140.75608202319
INFO:root:current train perplexity3.448482036590576
INFO:root:current mean train loss 3141.1767495465538
INFO:root:current train perplexity3.4495961666107178
INFO:root:current mean train loss 3139.9609883297094
INFO:root:current train perplexity3.4492459297180176

100%|██████████| 1/1 [08:38<00:00, 518.59s/it][A100%|██████████| 1/1 [08:38<00:00, 518.61s/it]
INFO:root:final mean train loss: 3138.3408207431917
INFO:root:final train perplexity: 3.44928240776062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 3697.5795292414673
INFO:root:eval perplexity: 4.460196018218994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 37.00s/it][A100%|██████████| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 4692.243295656029
INFO:root:eval perplexity: 6.812252044677734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/92
 46%|████▌     | 92/200 [15:13:02<17:49:24, 594.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3084.6634207589286
INFO:root:current train perplexity3.4023807048797607
INFO:root:current mean train loss 3117.5451605902776
INFO:root:current train perplexity3.4354195594787598
INFO:root:current mean train loss 3122.231028715093
INFO:root:current train perplexity3.4330835342407227
INFO:root:current mean train loss 3122.896204524254
INFO:root:current train perplexity3.4348561763763428
INFO:root:current mean train loss 3131.9566973105243
INFO:root:current train perplexity3.4403538703918457
INFO:root:current mean train loss 3134.9087050963785
INFO:root:current train perplexity3.4399254322052
INFO:root:current mean train loss 3136.012258935162
INFO:root:current train perplexity3.4410712718963623
INFO:root:current mean train loss 3136.411430763712
INFO:root:current train perplexity3.4415316581726074
INFO:root:current mean train loss 3134.1016048956776
INFO:root:current train perplexity3.440615177154541
INFO:root:current mean train loss 3134.4768040294953
INFO:root:current train perplexity3.44010329246521

100%|██████████| 1/1 [08:35<00:00, 515.72s/it][A100%|██████████| 1/1 [08:35<00:00, 515.73s/it]
INFO:root:final mean train loss: 3131.0376610294466
INFO:root:final train perplexity: 3.4393582344055176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.22s/it][A100%|██████████| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 3683.135917068373
INFO:root:eval perplexity: 4.4342217445373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.32s/it][A100%|██████████| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 4669.797171085439
INFO:root:eval perplexity: 6.750010967254639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/93
 46%|████▋     | 93/200 [15:22:54<17:38:45, 593.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3094.8082757994184
INFO:root:current train perplexity3.3928184509277344
INFO:root:current mean train loss 3134.0706402972028
INFO:root:current train perplexity3.4312877655029297
INFO:root:current mean train loss 3124.1666897746272
INFO:root:current train perplexity3.425055980682373
INFO:root:current mean train loss 3124.955155709047
INFO:root:current train perplexity3.4240505695343018
INFO:root:current mean train loss 3123.395918387592
INFO:root:current train perplexity3.425180196762085
INFO:root:current mean train loss 3124.2266636632426
INFO:root:current train perplexity3.4254097938537598
INFO:root:current mean train loss 3124.5766616750097
INFO:root:current train perplexity3.426643133163452
INFO:root:current mean train loss 3124.5872051911592
INFO:root:current train perplexity3.4277360439300537
INFO:root:current mean train loss 3129.456976803455
INFO:root:current train perplexity3.43318510055542
INFO:root:current mean train loss 3128.1904175193035
INFO:root:current train perplexity3.431558609008789

100%|██████████| 1/1 [08:35<00:00, 515.75s/it][A100%|██████████| 1/1 [08:35<00:00, 515.75s/it]
INFO:root:final mean train loss: 3125.780526745704
INFO:root:final train perplexity: 3.432232141494751
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3711.5371388103945
INFO:root:eval perplexity: 4.485440254211426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4700.539869376108
INFO:root:eval perplexity: 6.835402488708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/94
 47%|████▋     | 94/200 [15:32:47<17:28:12, 593.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3133.6930673636643
INFO:root:current train perplexity3.452517509460449
INFO:root:current mean train loss 3113.835855041908
INFO:root:current train perplexity3.4267640113830566
INFO:root:current mean train loss 3109.784221512388
INFO:root:current train perplexity3.4211642742156982
INFO:root:current mean train loss 3110.256020744302
INFO:root:current train perplexity3.4204471111297607
INFO:root:current mean train loss 3122.7650939535406
INFO:root:current train perplexity3.4290695190429688
INFO:root:current mean train loss 3121.9351636052347
INFO:root:current train perplexity3.4254751205444336
INFO:root:current mean train loss 3121.8627850932457
INFO:root:current train perplexity3.424268960952759
INFO:root:current mean train loss 3119.9197264974823
INFO:root:current train perplexity3.419008493423462
INFO:root:current mean train loss 3119.743929763238
INFO:root:current train perplexity3.4213311672210693
INFO:root:current mean train loss 3122.1889638168705
INFO:root:current train perplexity3.423889398574829

100%|██████████| 1/1 [08:31<00:00, 512.00s/it][A100%|██████████| 1/1 [08:31<00:00, 512.00s/it]
INFO:root:final mean train loss: 3119.881598564886
INFO:root:final train perplexity: 3.4242539405822754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.51s/it][A100%|██████████| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 3668.969030501995
INFO:root:eval perplexity: 4.408892631530762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.86s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4657.409408244681
INFO:root:eval perplexity: 6.715906143188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/95
 48%|████▊     | 95/200 [15:42:35<17:15:26, 591.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3101.043812897246
INFO:root:current train perplexity3.4201056957244873
INFO:root:current mean train loss 3126.4756627112815
INFO:root:current train perplexity3.432283639907837
INFO:root:current mean train loss 3123.7601700123673
INFO:root:current train perplexity3.4202280044555664
INFO:root:current mean train loss 3118.4003369004613
INFO:root:current train perplexity3.417708158493042
INFO:root:current mean train loss 3116.755353009259
INFO:root:current train perplexity3.4149019718170166
INFO:root:current mean train loss 3118.0955616195215
INFO:root:current train perplexity3.41611909866333
INFO:root:current mean train loss 3118.3592397779544
INFO:root:current train perplexity3.417976140975952
INFO:root:current mean train loss 3121.1468661864915
INFO:root:current train perplexity3.420921802520752
INFO:root:current mean train loss 3118.498275099589
INFO:root:current train perplexity3.4197466373443604
INFO:root:current mean train loss 3119.9027765331725
INFO:root:current train perplexity3.4208829402923584

100%|██████████| 1/1 [08:41<00:00, 521.42s/it][A100%|██████████| 1/1 [08:41<00:00, 521.42s/it]
INFO:root:final mean train loss: 3118.1661583685104
INFO:root:final train perplexity: 3.4219369888305664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.97s/it][A100%|██████████| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 3691.6660814217644
INFO:root:eval perplexity: 4.449542999267578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4687.899872908355
INFO:root:eval perplexity: 6.800163269042969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/96
 48%|████▊     | 96/200 [15:52:34<17:09:36, 594.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3094.123830311334
INFO:root:current train perplexity3.3780810832977295
INFO:root:current mean train loss 3108.857799050337
INFO:root:current train perplexity3.3973538875579834
INFO:root:current mean train loss 3105.924590721559
INFO:root:current train perplexity3.39566707611084
INFO:root:current mean train loss 3116.1407394201296
INFO:root:current train perplexity3.405449867248535
INFO:root:current mean train loss 3113.8206324444595
INFO:root:current train perplexity3.4073305130004883
INFO:root:current mean train loss 3119.1200874772653
INFO:root:current train perplexity3.4157891273498535
INFO:root:current mean train loss 3115.1823316857194
INFO:root:current train perplexity3.4152820110321045
INFO:root:current mean train loss 3112.832812372678
INFO:root:current train perplexity3.4118926525115967
INFO:root:current mean train loss 3116.4572100611845
INFO:root:current train perplexity3.414264678955078
INFO:root:current mean train loss 3115.737915670243
INFO:root:current train perplexity3.4155731201171875

100%|██████████| 1/1 [08:38<00:00, 518.01s/it][A100%|██████████| 1/1 [08:38<00:00, 518.01s/it]
INFO:root:final mean train loss: 3113.369260849491
INFO:root:final train perplexity: 3.4154672622680664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.86s/it][A100%|██████████| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3706.02779566988
INFO:root:eval perplexity: 4.47545862197876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.04s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 4697.149038328346
INFO:root:eval perplexity: 6.825930595397949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/97
 48%|████▊     | 97/200 [16:02:28<16:59:55, 594.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3136.034296875
INFO:root:current train perplexity3.416147232055664
INFO:root:current mean train loss 3114.25591796875
INFO:root:current train perplexity3.4144864082336426
INFO:root:current mean train loss 3111.5028497869316
INFO:root:current train perplexity3.4103033542633057
INFO:root:current mean train loss 3108.0969518229167
INFO:root:current train perplexity3.409534454345703
INFO:root:current mean train loss 3107.8380910773026
INFO:root:current train perplexity3.4041662216186523
INFO:root:current mean train loss 3107.838844259511
INFO:root:current train perplexity3.4047250747680664
INFO:root:current mean train loss 3109.3123090277777
INFO:root:current train perplexity3.4038655757904053
INFO:root:current mean train loss 3104.8396541078628
INFO:root:current train perplexity3.402844190597534
INFO:root:current mean train loss 3106.599642578125
INFO:root:current train perplexity3.404297351837158
INFO:root:current mean train loss 3110.186669921875
INFO:root:current train perplexity3.4070072174072266

100%|██████████| 1/1 [08:43<00:00, 523.35s/it][A100%|██████████| 1/1 [08:43<00:00, 523.36s/it]
INFO:root:final mean train loss: 3107.7237491607666
INFO:root:final train perplexity: 3.4078683853149414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.62s/it][A100%|██████████| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 3668.7416611258864
INFO:root:eval perplexity: 4.408486366271973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 4659.590638505651
INFO:root:eval perplexity: 6.721898078918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/98
 49%|████▉     | 98/200 [16:12:28<16:52:53, 595.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3090.984416180346
INFO:root:current train perplexity3.3748726844787598
INFO:root:current mean train loss 3093.066064719945
INFO:root:current train perplexity3.3759164810180664
INFO:root:current mean train loss 3092.3528366897635
INFO:root:current train perplexity3.387357473373413
INFO:root:current mean train loss 3097.0472823260034
INFO:root:current train perplexity3.395501136779785
INFO:root:current mean train loss 3099.7996773097825
INFO:root:current train perplexity3.3979294300079346
INFO:root:current mean train loss 3102.374141529535
INFO:root:current train perplexity3.399209976196289
INFO:root:current mean train loss 3100.056952681758
INFO:root:current train perplexity3.398057460784912
INFO:root:current mean train loss 3102.7692309850936
INFO:root:current train perplexity3.4015958309173584
INFO:root:current mean train loss 3105.7859464582743
INFO:root:current train perplexity3.4036524295806885
INFO:root:current mean train loss 3104.571181769774
INFO:root:current train perplexity3.4003570079803467

100%|██████████| 1/1 [08:36<00:00, 516.78s/it][A100%|██████████| 1/1 [08:36<00:00, 516.78s/it]
INFO:root:final mean train loss: 3102.4246684043637
INFO:root:final train perplexity: 3.4007508754730225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 3672.364453471299
INFO:root:eval perplexity: 4.414949893951416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.99s/it][A100%|██████████| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 4666.471636400155
INFO:root:eval perplexity: 6.740837574005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/99
 50%|████▉     | 99/200 [16:22:22<16:42:09, 595.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3088.354663890797
INFO:root:current train perplexity3.398862838745117
INFO:root:current mean train loss 3103.038076989938
INFO:root:current train perplexity3.3928353786468506
INFO:root:current mean train loss 3095.009487925526
INFO:root:current train perplexity3.388284683227539
INFO:root:current mean train loss 3088.992952390705
INFO:root:current train perplexity3.3847854137420654
INFO:root:current mean train loss 3096.8010353352533
INFO:root:current train perplexity3.3882737159729004
INFO:root:current mean train loss 3095.2747218201407
INFO:root:current train perplexity3.3852744102478027
INFO:root:current mean train loss 3100.4694188251856
INFO:root:current train perplexity3.391523599624634
INFO:root:current mean train loss 3102.4945282869785
INFO:root:current train perplexity3.3963029384613037
INFO:root:current mean train loss 3102.3503154921614
INFO:root:current train perplexity3.395472288131714
INFO:root:current mean train loss 3101.3908474611344
INFO:root:current train perplexity3.395974636077881

100%|██████████| 1/1 [08:37<00:00, 517.33s/it][A100%|██████████| 1/1 [08:37<00:00, 517.33s/it]
INFO:root:final mean train loss: 3098.818165194604
INFO:root:final train perplexity: 3.395915985107422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.98s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 3713.068179299645
INFO:root:eval perplexity: 4.488217830657959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4718.59341235871
INFO:root:eval perplexity: 6.886050701141357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/100
 50%|█████     | 100/200 [16:32:16<16:31:30, 594.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3090.7479063091855
INFO:root:current train perplexity3.3766961097717285
INFO:root:current mean train loss 3089.4328318840294
INFO:root:current train perplexity3.379788398742676
INFO:root:current mean train loss 3093.3408023489756
INFO:root:current train perplexity3.3839268684387207
INFO:root:current mean train loss 3086.1415728040806
INFO:root:current train perplexity3.3769078254699707
INFO:root:current mean train loss 3086.1343404582603
INFO:root:current train perplexity3.379056930541992
INFO:root:current mean train loss 3090.4992524976524
INFO:root:current train perplexity3.3833656311035156
INFO:root:current mean train loss 3088.1014755314513
INFO:root:current train perplexity3.382214069366455
INFO:root:current mean train loss 3093.4702695385836
INFO:root:current train perplexity3.3852522373199463
INFO:root:current mean train loss 3094.743778894953
INFO:root:current train perplexity3.386359691619873

100%|██████████| 1/1 [08:36<00:00, 516.88s/it][A100%|██████████| 1/1 [08:36<00:00, 516.88s/it]
INFO:root:final mean train loss: 3092.237162497736
INFO:root:final train perplexity: 3.3871102333068848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.16s/it][A100%|██████████| 1/1 [00:39<00:00, 39.16s/it]
INFO:root:eval mean loss: 3679.572746980275
INFO:root:eval perplexity: 4.427836894989014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 4672.296180670988
INFO:root:eval perplexity: 6.756913661956787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/101
 50%|█████     | 101/200 [16:42:11<16:21:34, 594.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2995.014404296875
INFO:root:current train perplexity3.297053098678589
INFO:root:current mean train loss 3119.9198032272197
INFO:root:current train perplexity3.3996055126190186
INFO:root:current mean train loss 3097.152339032307
INFO:root:current train perplexity3.3916492462158203
INFO:root:current mean train loss 3092.205035181698
INFO:root:current train perplexity3.3833985328674316
INFO:root:current mean train loss 3086.6104631353655
INFO:root:current train perplexity3.3804008960723877
INFO:root:current mean train loss 3085.4780610515286
INFO:root:current train perplexity3.379610538482666
INFO:root:current mean train loss 3088.693411662119
INFO:root:current train perplexity3.382157564163208
INFO:root:current mean train loss 3090.2375792162084
INFO:root:current train perplexity3.3830983638763428
INFO:root:current mean train loss 3091.0630947713366
INFO:root:current train perplexity3.3850960731506348
INFO:root:current mean train loss 3093.3158132601466
INFO:root:current train perplexity3.386976957321167

100%|██████████| 1/1 [08:38<00:00, 518.48s/it][A100%|██████████| 1/1 [08:38<00:00, 518.48s/it]
INFO:root:final mean train loss: 3091.722377038771
INFO:root:final train perplexity: 3.3864219188690186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.12s/it][A100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 3673.02607975953
INFO:root:eval perplexity: 4.416131019592285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4669.483561197917
INFO:root:eval perplexity: 6.749145984649658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/102
 51%|█████     | 102/200 [16:52:07<16:12:01, 595.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3120.459749348958
INFO:root:current train perplexity3.3908884525299072
INFO:root:current mean train loss 3097.6655146059784
INFO:root:current train perplexity3.4002180099487305
INFO:root:current mean train loss 3096.952854742006
INFO:root:current train perplexity3.387486696243286
INFO:root:current mean train loss 3087.0711921812995
INFO:root:current train perplexity3.382394313812256
INFO:root:current mean train loss 3090.0690582643074
INFO:root:current train perplexity3.3826003074645996
INFO:root:current mean train loss 3092.866398190989
INFO:root:current train perplexity3.381718158721924
INFO:root:current mean train loss 3091.2007673558182
INFO:root:current train perplexity3.3808608055114746
INFO:root:current mean train loss 3091.3238421246724
INFO:root:current train perplexity3.3806729316711426
INFO:root:current mean train loss 3090.2367990318253
INFO:root:current train perplexity3.38051176071167
INFO:root:current mean train loss 3091.0558604422813
INFO:root:current train perplexity3.381412982940674

100%|██████████| 1/1 [08:37<00:00, 517.91s/it][A100%|██████████| 1/1 [08:37<00:00, 517.91s/it]
INFO:root:final mean train loss: 3086.630419269685
INFO:root:final train perplexity: 3.3796257972717285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.02s/it][A100%|██████████| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3722.6863243157136
INFO:root:eval perplexity: 4.505707740783691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.72s/it][A100%|██████████| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 4711.765027634641
INFO:root:eval perplexity: 6.866849899291992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/103
 52%|█████▏    | 103/200 [17:02:02<16:02:07, 595.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3133.781016474185
INFO:root:current train perplexity3.3888309001922607
INFO:root:current mean train loss 3097.5498840828254
INFO:root:current train perplexity3.384873628616333
INFO:root:current mean train loss 3085.1121382777465
INFO:root:current train perplexity3.3719775676727295
INFO:root:current mean train loss 3084.699137873694
INFO:root:current train perplexity3.375600814819336
INFO:root:current mean train loss 3087.0586589695995
INFO:root:current train perplexity3.372222423553467
INFO:root:current mean train loss 3090.774050885815
INFO:root:current train perplexity3.3783459663391113
INFO:root:current mean train loss 3088.0372426138642
INFO:root:current train perplexity3.3744964599609375
INFO:root:current mean train loss 3088.2678692027575
INFO:root:current train perplexity3.37682843208313
INFO:root:current mean train loss 3089.008095798052
INFO:root:current train perplexity3.3779687881469727
INFO:root:current mean train loss 3087.308375266624
INFO:root:current train perplexity3.376577615737915

100%|██████████| 1/1 [08:37<00:00, 517.96s/it][A100%|██████████| 1/1 [08:37<00:00, 517.96s/it]
INFO:root:final mean train loss: 3083.0579768150083
INFO:root:final train perplexity: 3.3748652935028076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 3695.933223210328
INFO:root:eval perplexity: 4.4572272300720215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4695.249922082779
INFO:root:eval perplexity: 6.8206329345703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/104
 52%|█████▏    | 104/200 [17:11:57<15:52:11, 595.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3159.3544055569555
INFO:root:current train perplexity3.4064114093780518
INFO:root:current mean train loss 3104.732628742247
INFO:root:current train perplexity3.381868600845337
INFO:root:current mean train loss 3081.527273995536
INFO:root:current train perplexity3.360072612762451
INFO:root:current mean train loss 3081.188497214879
INFO:root:current train perplexity3.363419771194458
INFO:root:current mean train loss 3079.216952082729
INFO:root:current train perplexity3.3621826171875
INFO:root:current mean train loss 3073.740476216749
INFO:root:current train perplexity3.3618979454040527
INFO:root:current mean train loss 3079.358249089986
INFO:root:current train perplexity3.3689188957214355
INFO:root:current mean train loss 3077.05126953125
INFO:root:current train perplexity3.368194341659546
INFO:root:current mean train loss 3078.913809545634
INFO:root:current train perplexity3.36991286277771
INFO:root:current mean train loss 3081.256995114041
INFO:root:current train perplexity3.3710575103759766

100%|██████████| 1/1 [08:37<00:00, 517.54s/it][A100%|██████████| 1/1 [08:37<00:00, 517.54s/it]
INFO:root:final mean train loss: 3079.0713781541394
INFO:root:final train perplexity: 3.3695621490478516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.13s/it][A100%|██████████| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 3655.1254432624114
INFO:root:eval perplexity: 4.384280204772949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4654.064224567819
INFO:root:eval perplexity: 6.706725597381592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/105
 52%|█████▎    | 105/200 [17:21:51<15:41:44, 594.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3044.040289463141
INFO:root:current train perplexity3.3137829303741455
INFO:root:current mean train loss 3055.9765273718526
INFO:root:current train perplexity3.33732008934021
INFO:root:current mean train loss 3064.5813172152853
INFO:root:current train perplexity3.3484013080596924
INFO:root:current mean train loss 3072.6022920411597
INFO:root:current train perplexity3.3517818450927734
INFO:root:current mean train loss 3067.721919935222
INFO:root:current train perplexity3.350491523742676
INFO:root:current mean train loss 3066.477397741767
INFO:root:current train perplexity3.3495492935180664
INFO:root:current mean train loss 3067.819006978066
INFO:root:current train perplexity3.351544141769409
INFO:root:current mean train loss 3071.71749229586
INFO:root:current train perplexity3.355621814727783
INFO:root:current mean train loss 3070.3771632197927
INFO:root:current train perplexity3.355243444442749
INFO:root:current mean train loss 3073.882299258686
INFO:root:current train perplexity3.360504388809204

100%|██████████| 1/1 [08:36<00:00, 516.44s/it][A100%|██████████| 1/1 [08:36<00:00, 516.44s/it]
INFO:root:final mean train loss: 3072.8924558701056
INFO:root:final train perplexity: 3.3613579273223877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.76s/it][A100%|██████████| 1/1 [00:38<00:00, 38.76s/it]
INFO:root:eval mean loss: 3672.257838472407
INFO:root:eval perplexity: 4.414759159088135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4673.049113821476
INFO:root:eval perplexity: 6.758992671966553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/106
 53%|█████▎    | 106/200 [17:31:45<15:31:28, 594.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3075.11767578125
INFO:root:current train perplexity3.3589563369750977
INFO:root:current mean train loss 3077.473435174851
INFO:root:current train perplexity3.360732078552246
INFO:root:current mean train loss 3057.601079160868
INFO:root:current train perplexity3.342860221862793
INFO:root:current mean train loss 3062.117995908006
INFO:root:current train perplexity3.344623327255249
INFO:root:current mean train loss 3062.1436824926595
INFO:root:current train perplexity3.3465938568115234
INFO:root:current mean train loss 3061.5095339815184
INFO:root:current train perplexity3.349292278289795
INFO:root:current mean train loss 3064.0167992899924
INFO:root:current train perplexity3.3508660793304443
INFO:root:current mean train loss 3063.280937225464
INFO:root:current train perplexity3.3507862091064453
INFO:root:current mean train loss 3066.292809928885
INFO:root:current train perplexity3.3517069816589355
INFO:root:current mean train loss 3068.621261838371
INFO:root:current train perplexity3.353700637817383

100%|██████████| 1/1 [08:41<00:00, 521.55s/it][A100%|██████████| 1/1 [08:41<00:00, 521.55s/it]
INFO:root:final mean train loss: 3068.6326097672986
INFO:root:final train perplexity: 3.355713129043579
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.36s/it][A100%|██████████| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 3685.5227258560503
INFO:root:eval perplexity: 4.438503265380859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4688.433811918218
INFO:root:eval perplexity: 6.8016486167907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/107
 54%|█████▎    | 107/200 [17:41:44<15:23:33, 595.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3075.0245472301135
INFO:root:current train perplexity3.3576087951660156
INFO:root:current mean train loss 3069.127751701109
INFO:root:current train perplexity3.3496484756469727
INFO:root:current mean train loss 3060.799888939951
INFO:root:current train perplexity3.343900442123413
INFO:root:current mean train loss 3056.701746121259
INFO:root:current train perplexity3.340528964996338
INFO:root:current mean train loss 3060.2835282881183
INFO:root:current train perplexity3.342649459838867
INFO:root:current mean train loss 3061.6629297754785
INFO:root:current train perplexity3.344508409500122
INFO:root:current mean train loss 3061.258508393965
INFO:root:current train perplexity3.344730854034424
INFO:root:current mean train loss 3065.3509354951366
INFO:root:current train perplexity3.3487050533294678
INFO:root:current mean train loss 3066.0616193804826
INFO:root:current train perplexity3.3484859466552734
INFO:root:current mean train loss 3065.522684115265
INFO:root:current train perplexity3.3475542068481445

100%|██████████| 1/1 [08:39<00:00, 519.33s/it][A100%|██████████| 1/1 [08:39<00:00, 519.33s/it]
INFO:root:final mean train loss: 3064.2583656311035
INFO:root:final train perplexity: 3.3499271869659424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 3723.482092891179
INFO:root:eval perplexity: 4.507157802581787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4730.836271678302
INFO:root:eval perplexity: 6.920608997344971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/108
 54%|█████▍    | 108/200 [17:51:40<15:13:45, 595.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3047.6819932725693
INFO:root:current train perplexity3.382714033126831
INFO:root:current mean train loss 3055.959210542082
INFO:root:current train perplexity3.3483457565307617
INFO:root:current mean train loss 3056.5147904660766
INFO:root:current train perplexity3.343991756439209
INFO:root:current mean train loss 3060.843819274062
INFO:root:current train perplexity3.3444674015045166
INFO:root:current mean train loss 3056.928987770822
INFO:root:current train perplexity3.3413374423980713
INFO:root:current mean train loss 3061.9688553750834
INFO:root:current train perplexity3.3480427265167236
INFO:root:current mean train loss 3062.4726823947726
INFO:root:current train perplexity3.3477797508239746
INFO:root:current mean train loss 3060.763857140297
INFO:root:current train perplexity3.3443410396575928
INFO:root:current mean train loss 3061.130344501376
INFO:root:current train perplexity3.3449900150299072
INFO:root:current mean train loss 3062.8515115422992
INFO:root:current train perplexity3.345404863357544

100%|██████████| 1/1 [08:37<00:00, 517.05s/it][A100%|██████████| 1/1 [08:37<00:00, 517.05s/it]
INFO:root:final mean train loss: 3061.003220342821
INFO:root:final train perplexity: 3.3456273078918457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.99s/it][A100%|██████████| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 3675.3953762189717
INFO:root:eval perplexity: 4.420363426208496
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 4674.004801432292
INFO:root:eval perplexity: 6.7616353034973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/109
 55%|█████▍    | 109/200 [18:01:34<15:02:46, 595.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3058.5562864491635
INFO:root:current train perplexity3.3408193588256836
INFO:root:current mean train loss 3055.7025995979534
INFO:root:current train perplexity3.3335256576538086
INFO:root:current mean train loss 3061.098059847786
INFO:root:current train perplexity3.3402299880981445
INFO:root:current mean train loss 3072.772734690869
INFO:root:current train perplexity3.3476741313934326
INFO:root:current mean train loss 3065.4767081550226
INFO:root:current train perplexity3.342726469039917
INFO:root:current mean train loss 3061.0569228190675
INFO:root:current train perplexity3.336695671081543
INFO:root:current mean train loss 3057.492819500396
INFO:root:current train perplexity3.334460973739624
INFO:root:current mean train loss 3058.5689752680164
INFO:root:current train perplexity3.3360304832458496
INFO:root:current mean train loss 3059.15168196353
INFO:root:current train perplexity3.340200185775757
INFO:root:current mean train loss 3060.102103330571
INFO:root:current train perplexity3.3414499759674072

100%|██████████| 1/1 [08:35<00:00, 515.73s/it][A100%|██████████| 1/1 [08:35<00:00, 515.74s/it]
INFO:root:final mean train loss: 3057.5548270440872
INFO:root:final train perplexity: 3.3410794734954834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.74s/it][A100%|██████████| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 3676.6528043273493
INFO:root:eval perplexity: 4.422611713409424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4683.448067306626
INFO:root:eval perplexity: 6.787796974182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/110
 55%|█████▌    | 110/200 [18:11:26<14:51:30, 594.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3044.1873362094543
INFO:root:current train perplexity3.32308292388916
INFO:root:current mean train loss 3046.9361347219797
INFO:root:current train perplexity3.31897234916687
INFO:root:current mean train loss 3054.8053962953627
INFO:root:current train perplexity3.327782154083252
INFO:root:current mean train loss 3057.0663804831793
INFO:root:current train perplexity3.3306314945220947
INFO:root:current mean train loss 3057.516387493476
INFO:root:current train perplexity3.3342947959899902
INFO:root:current mean train loss 3054.0332309545015
INFO:root:current train perplexity3.3344175815582275
INFO:root:current mean train loss 3050.5373578303343
INFO:root:current train perplexity3.3314638137817383
INFO:root:current mean train loss 3053.913538177451
INFO:root:current train perplexity3.332401752471924
INFO:root:current mean train loss 3057.1472326285198
INFO:root:current train perplexity3.336132764816284
INFO:root:current mean train loss 3055.375874317703
INFO:root:current train perplexity3.335482597351074

100%|██████████| 1/1 [08:39<00:00, 519.06s/it][A100%|██████████| 1/1 [08:39<00:00, 519.06s/it]
INFO:root:final mean train loss: 3053.8308568769885
INFO:root:final train perplexity: 3.336174488067627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 3681.4810228280144
INFO:root:eval perplexity: 4.431255340576172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.04s/it][A100%|██████████| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 4684.498609610483
INFO:root:eval perplexity: 6.790712356567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/111
 56%|█████▌    | 111/200 [18:21:22<14:42:18, 594.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3060.343991334411
INFO:root:current train perplexity3.3512232303619385
INFO:root:current mean train loss 3055.1150594293117
INFO:root:current train perplexity3.3378310203552246
INFO:root:current mean train loss 3063.392945611934
INFO:root:current train perplexity3.341886043548584
INFO:root:current mean train loss 3059.9373044351582
INFO:root:current train perplexity3.340250015258789
INFO:root:current mean train loss 3057.9650031683136
INFO:root:current train perplexity3.3359899520874023
INFO:root:current mean train loss 3058.4286003047805
INFO:root:current train perplexity3.337038516998291
INFO:root:current mean train loss 3054.8710070392103
INFO:root:current train perplexity3.3358027935028076
INFO:root:current mean train loss 3056.1473799709142
INFO:root:current train perplexity3.3369154930114746
INFO:root:current mean train loss 3055.5931260239045
INFO:root:current train perplexity3.336967706680298
INFO:root:current mean train loss 3055.8612106307783
INFO:root:current train perplexity3.3359665870666504

100%|██████████| 1/1 [08:37<00:00, 517.97s/it][A100%|██████████| 1/1 [08:37<00:00, 517.97s/it]
INFO:root:final mean train loss: 3054.28102800923
INFO:root:final train perplexity: 3.336766004562378
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 3718.1989503684617
INFO:root:eval perplexity: 4.497539520263672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4727.436345093639
INFO:root:eval perplexity: 6.910994529724121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/112
 56%|█████▌    | 112/200 [18:31:16<14:32:16, 594.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3047.4038882606906
INFO:root:current train perplexity3.328315258026123
INFO:root:current mean train loss 3038.2195638020835
INFO:root:current train perplexity3.3333704471588135
INFO:root:current mean train loss 3041.0774794756358
INFO:root:current train perplexity3.3286044597625732
INFO:root:current mean train loss 3035.8752577383307
INFO:root:current train perplexity3.3232345581054688
INFO:root:current mean train loss 3038.8332948626894
INFO:root:current train perplexity3.325706720352173
INFO:root:current mean train loss 3043.231968060662
INFO:root:current train perplexity3.3249523639678955
INFO:root:current mean train loss 3046.1583172914793
INFO:root:current train perplexity3.324857711791992
INFO:root:current mean train loss 3048.104279370578
INFO:root:current train perplexity3.32554292678833
INFO:root:current mean train loss 3049.611543350646
INFO:root:current train perplexity3.3253955841064453

100%|██████████| 1/1 [08:40<00:00, 520.67s/it][A100%|██████████| 1/1 [08:40<00:00, 520.67s/it]
INFO:root:final mean train loss: 3047.239049911499
INFO:root:final train perplexity: 3.3275086879730225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.65s/it][A100%|██████████| 1/1 [00:38<00:00, 38.65s/it]
INFO:root:eval mean loss: 3730.220410502549
INFO:root:eval perplexity: 4.519455909729004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4733.68423267121
INFO:root:eval perplexity: 6.928673267364502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/113
 56%|█████▋    | 113/200 [18:41:15<14:23:53, 595.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2957.6964518229165
INFO:root:current train perplexity3.3132612705230713
INFO:root:current mean train loss 3041.2036227624394
INFO:root:current train perplexity3.3239481449127197
INFO:root:current mean train loss 3040.387193801955
INFO:root:current train perplexity3.326042652130127
INFO:root:current mean train loss 3041.978087774598
INFO:root:current train perplexity3.321338653564453
INFO:root:current mean train loss 3033.99261822949
INFO:root:current train perplexity3.3147122859954834
INFO:root:current mean train loss 3039.236513535972
INFO:root:current train perplexity3.3155643939971924
INFO:root:current mean train loss 3041.7348649007567
INFO:root:current train perplexity3.317767381668091
INFO:root:current mean train loss 3046.4524825246713
INFO:root:current train perplexity3.322155714035034
INFO:root:current mean train loss 3047.5110419666485
INFO:root:current train perplexity3.325610399246216
INFO:root:current mean train loss 3046.737427704094
INFO:root:current train perplexity3.3251683712005615

100%|██████████| 1/1 [08:36<00:00, 516.58s/it][A100%|██████████| 1/1 [08:36<00:00, 516.58s/it]
INFO:root:final mean train loss: 3044.6323404004497
INFO:root:final train perplexity: 3.3240888118743896
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3706.169772966534
INFO:root:eval perplexity: 4.475715637207031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 4720.200143367686
INFO:root:eval perplexity: 6.8905768394470215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/114
 57%|█████▋    | 114/200 [18:51:08<14:12:44, 594.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3032.850497159091
INFO:root:current train perplexity3.3234357833862305
INFO:root:current mean train loss 3003.4254975190033
INFO:root:current train perplexity3.28157114982605
INFO:root:current mean train loss 3031.403683630776
INFO:root:current train perplexity3.317039728164673
INFO:root:current mean train loss 3043.8414232063906
INFO:root:current train perplexity3.330479145050049
INFO:root:current mean train loss 3042.629819252775
INFO:root:current train perplexity3.324954032897949
INFO:root:current mean train loss 3040.015859585219
INFO:root:current train perplexity3.3191206455230713
INFO:root:current mean train loss 3036.7341416479135
INFO:root:current train perplexity3.314178466796875
INFO:root:current mean train loss 3039.292925827949
INFO:root:current train perplexity3.3153276443481445
INFO:root:current mean train loss 3036.927961958616
INFO:root:current train perplexity3.3134748935699463
INFO:root:current mean train loss 3038.0536503713297
INFO:root:current train perplexity3.3151895999908447

100%|██████████| 1/1 [08:37<00:00, 517.20s/it][A100%|██████████| 1/1 [08:37<00:00, 517.20s/it]
INFO:root:final mean train loss: 3039.1848832407304
INFO:root:final train perplexity: 3.3169522285461426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.17s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3686.366808302859
INFO:root:eval perplexity: 4.4400177001953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.33s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4690.498439924091
INFO:root:eval perplexity: 6.807392597198486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/115
 57%|█████▊    | 115/200 [19:01:02<14:02:29, 594.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3074.2467747738488
INFO:root:current train perplexity3.332172155380249
INFO:root:current mean train loss 3071.5753040474
INFO:root:current train perplexity3.333555221557617
INFO:root:current mean train loss 3033.909521930294
INFO:root:current train perplexity3.309936761856079
INFO:root:current mean train loss 3035.2459337957976
INFO:root:current train perplexity3.3099939823150635
INFO:root:current mean train loss 3040.6037993874925
INFO:root:current train perplexity3.316734790802002
INFO:root:current mean train loss 3038.2475839956646
INFO:root:current train perplexity3.3163208961486816
INFO:root:current mean train loss 3036.8508296837135
INFO:root:current train perplexity3.3142330646514893
INFO:root:current mean train loss 3036.1832127683847
INFO:root:current train perplexity3.3123199939727783
INFO:root:current mean train loss 3035.55556121938
INFO:root:current train perplexity3.3095173835754395
INFO:root:current mean train loss 3035.8501146584263
INFO:root:current train perplexity3.3102378845214844

100%|██████████| 1/1 [08:37<00:00, 517.48s/it][A100%|██████████| 1/1 [08:37<00:00, 517.48s/it]
INFO:root:final mean train loss: 3034.4748327808998
INFO:root:final train perplexity: 3.3107948303222656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.43s/it][A100%|██████████| 1/1 [00:38<00:00, 38.43s/it]
INFO:root:eval mean loss: 3688.8334181765294
INFO:root:eval perplexity: 4.444449424743652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4696.786222850177
INFO:root:eval perplexity: 6.824917793273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/116
 58%|█████▊    | 116/200 [19:10:56<13:52:32, 594.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3100.143627025463
INFO:root:current train perplexity3.340573310852051
INFO:root:current mean train loss 3046.0306329201526
INFO:root:current train perplexity3.3113677501678467
INFO:root:current mean train loss 3030.9564461729074
INFO:root:current train perplexity3.2974629402160645
INFO:root:current mean train loss 3030.7653151579225
INFO:root:current train perplexity3.301171064376831
INFO:root:current mean train loss 3040.0814446263903
INFO:root:current train perplexity3.3089425563812256
INFO:root:current mean train loss 3035.4884332009015
INFO:root:current train perplexity3.306859254837036
INFO:root:current mean train loss 3030.8050348260567
INFO:root:current train perplexity3.3042397499084473
INFO:root:current mean train loss 3031.5056975101015
INFO:root:current train perplexity3.3051722049713135
INFO:root:current mean train loss 3030.8143887687047
INFO:root:current train perplexity3.305689573287964
INFO:root:current mean train loss 3032.7497785088826
INFO:root:current train perplexity3.3064584732055664

100%|██████████| 1/1 [08:38<00:00, 518.41s/it][A100%|██████████| 1/1 [08:38<00:00, 518.41s/it]
INFO:root:final mean train loss: 3032.001875600507
INFO:root:final train perplexity: 3.307565927505493
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.86s/it][A100%|██████████| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3683.532342572584
INFO:root:eval perplexity: 4.434932708740234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.52s/it][A100%|██████████| 1/1 [00:38<00:00, 38.52s/it]
INFO:root:eval mean loss: 4689.34907088043
INFO:root:eval perplexity: 6.804193496704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/117
 58%|█████▊    | 117/200 [19:20:53<13:43:17, 595.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3052.473863002232
INFO:root:current train perplexity3.312554359436035
INFO:root:current mean train loss 3039.83359375
INFO:root:current train perplexity3.2939863204956055
INFO:root:current mean train loss 3032.227543218085
INFO:root:current train perplexity3.291579008102417
INFO:root:current mean train loss 3036.0638956098414
INFO:root:current train perplexity3.2922465801239014
INFO:root:current mean train loss 3031.9105687634697
INFO:root:current train perplexity3.2950000762939453
INFO:root:current mean train loss 3034.984483608353
INFO:root:current train perplexity3.300872325897217
INFO:root:current mean train loss 3031.8535244678887
INFO:root:current train perplexity3.2997546195983887
INFO:root:current mean train loss 3033.14345138446
INFO:root:current train perplexity3.299359083175659
INFO:root:current mean train loss 3036.8125897618825
INFO:root:current train perplexity3.306467056274414
INFO:root:current mean train loss 3033.820933165525
INFO:root:current train perplexity3.303772211074829

100%|██████████| 1/1 [08:37<00:00, 517.55s/it][A100%|██████████| 1/1 [08:37<00:00, 517.55s/it]
INFO:root:final mean train loss: 3030.4217987060547
INFO:root:final train perplexity: 3.305504322052002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3675.95171036957
INFO:root:eval perplexity: 4.421358585357666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.75s/it][A100%|██████████| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 4689.408539034796
INFO:root:eval perplexity: 6.804360866546631
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/118
 59%|█████▉    | 118/200 [19:30:49<13:34:02, 595.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3009.4512570403344
INFO:root:current train perplexity3.2733771800994873
INFO:root:current mean train loss 3010.1205303485576
INFO:root:current train perplexity3.2689127922058105
INFO:root:current mean train loss 3029.179602101016
INFO:root:current train perplexity3.2888247966766357
INFO:root:current mean train loss 3024.3372222633475
INFO:root:current train perplexity3.29449725151062
INFO:root:current mean train loss 3023.0699724666692
INFO:root:current train perplexity3.2928714752197266
INFO:root:current mean train loss 3027.7142628481815
INFO:root:current train perplexity3.3006484508514404
INFO:root:current mean train loss 3031.671448228519
INFO:root:current train perplexity3.304459810256958
INFO:root:current mean train loss 3032.882113922653
INFO:root:current train perplexity3.305494785308838
INFO:root:current mean train loss 3029.826029387233
INFO:root:current train perplexity3.3026301860809326
INFO:root:current mean train loss 3031.364976253894
INFO:root:current train perplexity3.303110122680664

100%|██████████| 1/1 [08:35<00:00, 515.60s/it][A100%|██████████| 1/1 [08:35<00:00, 515.60s/it]
INFO:root:final mean train loss: 3026.9543618232974
INFO:root:final train perplexity: 3.300985813140869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.02s/it][A100%|██████████| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3704.5818754155584
INFO:root:eval perplexity: 4.472842693328857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.96s/it][A100%|██████████| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 4710.133234984486
INFO:root:eval perplexity: 6.862268924713135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/119
 60%|█████▉    | 119/200 [19:40:41<13:22:38, 594.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3007.61332433364
INFO:root:current train perplexity3.2838902473449707
INFO:root:current mean train loss 3012.031033345406
INFO:root:current train perplexity3.276827335357666
INFO:root:current mean train loss 3022.3370298104455
INFO:root:current train perplexity3.2904882431030273
INFO:root:current mean train loss 3022.3339586393786
INFO:root:current train perplexity3.2920734882354736
INFO:root:current mean train loss 3026.564565180675
INFO:root:current train perplexity3.294179677963257
INFO:root:current mean train loss 3025.203345657044
INFO:root:current train perplexity3.291292190551758
INFO:root:current mean train loss 3022.1365563646073
INFO:root:current train perplexity3.2934112548828125
INFO:root:current mean train loss 3024.593874833555
INFO:root:current train perplexity3.296776294708252
INFO:root:current mean train loss 3024.8968868771117
INFO:root:current train perplexity3.2973690032958984
INFO:root:current mean train loss 3026.249008291026
INFO:root:current train perplexity3.297910690307617

100%|██████████| 1/1 [08:38<00:00, 518.66s/it][A100%|██████████| 1/1 [08:38<00:00, 518.66s/it]
INFO:root:final mean train loss: 3025.3798975175428
INFO:root:final train perplexity: 3.2989354133605957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3666.055127299424
INFO:root:eval perplexity: 4.40369987487793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4673.980565713652
INFO:root:eval perplexity: 6.761568546295166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/120
 60%|██████    | 120/200 [19:50:37<13:13:07, 594.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3018.752114506091
INFO:root:current train perplexity3.271350622177124
INFO:root:current mean train loss 3000.0244033141707
INFO:root:current train perplexity3.2743306159973145
INFO:root:current mean train loss 2997.9628472641166
INFO:root:current train perplexity3.269716739654541
INFO:root:current mean train loss 3004.585103749565
INFO:root:current train perplexity3.2748658657073975
INFO:root:current mean train loss 3010.531586158769
INFO:root:current train perplexity3.2746405601501465
INFO:root:current mean train loss 3013.055931350626
INFO:root:current train perplexity3.2785263061523438
INFO:root:current mean train loss 3014.7821161620354
INFO:root:current train perplexity3.280644416809082
INFO:root:current mean train loss 3019.180828752882
INFO:root:current train perplexity3.2867608070373535
INFO:root:current mean train loss 3022.3574730336873
INFO:root:current train perplexity3.2905123233795166
INFO:root:current mean train loss 3021.8237050109165
INFO:root:current train perplexity3.2905402183532715

100%|██████████| 1/1 [08:39<00:00, 519.77s/it][A100%|██████████| 1/1 [08:39<00:00, 519.77s/it]
INFO:root:final mean train loss: 3019.1780917259953
INFO:root:final train perplexity: 3.2908735275268555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.78s/it][A100%|██████████| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 3684.344820063165
INFO:root:eval perplexity: 4.436389446258545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 4695.99164900543
INFO:root:eval perplexity: 6.8227009773254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/121
 60%|██████    | 121/200 [20:00:33<13:03:44, 595.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3004.1797567339086
INFO:root:current train perplexity3.2716588973999023
INFO:root:current mean train loss 3010.752053997474
INFO:root:current train perplexity3.2747316360473633
INFO:root:current mean train loss 3024.4074871620437
INFO:root:current train perplexity3.285557746887207
INFO:root:current mean train loss 3022.0798566023077
INFO:root:current train perplexity3.2858543395996094
INFO:root:current mean train loss 3025.758406906618
INFO:root:current train perplexity3.2952404022216797
INFO:root:current mean train loss 3021.4699276448137
INFO:root:current train perplexity3.292384386062622
INFO:root:current mean train loss 3017.2195655102137
INFO:root:current train perplexity3.2870771884918213
INFO:root:current mean train loss 3018.0669976623617
INFO:root:current train perplexity3.288745641708374
INFO:root:current mean train loss 3015.8385253343067
INFO:root:current train perplexity3.285346269607544
INFO:root:current mean train loss 3019.0099145836025
INFO:root:current train perplexity3.2870421409606934

100%|██████████| 1/1 [08:39<00:00, 519.91s/it][A100%|██████████| 1/1 [08:39<00:00, 519.91s/it]
INFO:root:final mean train loss: 3016.9286757438413
INFO:root:final train perplexity: 3.287954568862915
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 3694.045469027039
INFO:root:eval perplexity: 4.453826427459717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4707.571701158023
INFO:root:eval perplexity: 6.855084419250488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/122
 61%|██████    | 122/200 [20:10:30<12:54:21, 595.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2992.285221354167
INFO:root:current train perplexity3.2667665481567383
INFO:root:current mean train loss 3014.111358816964
INFO:root:current train perplexity3.2765603065490723
INFO:root:current mean train loss 3004.782862215909
INFO:root:current train perplexity3.2781271934509277
INFO:root:current mean train loss 3008.3589440104165
INFO:root:current train perplexity3.278329372406006
INFO:root:current mean train loss 3017.9482745682567
INFO:root:current train perplexity3.28200101852417
INFO:root:current mean train loss 3020.677953464674
INFO:root:current train perplexity3.2866265773773193
INFO:root:current mean train loss 3020.1877553530094
INFO:root:current train perplexity3.2845306396484375
INFO:root:current mean train loss 3016.55919953377
INFO:root:current train perplexity3.2807183265686035
INFO:root:current mean train loss 3017.949859095982
INFO:root:current train perplexity3.2822957038879395
INFO:root:current mean train loss 3016.8166103265226
INFO:root:current train perplexity3.283328056335449

100%|██████████| 1/1 [08:36<00:00, 516.89s/it][A100%|██████████| 1/1 [08:36<00:00, 516.89s/it]
INFO:root:final mean train loss: 3013.1181472655267
INFO:root:final train perplexity: 3.283015251159668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.13s/it][A100%|██████████| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 3672.0458586131426
INFO:root:eval perplexity: 4.41438102722168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4680.370271290448
INFO:root:eval perplexity: 6.779259204864502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/123
 62%|██████▏   | 123/200 [20:20:23<12:43:39, 595.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2983.730345208961
INFO:root:current train perplexity3.2619097232818604
INFO:root:current mean train loss 3013.2145409088967
INFO:root:current train perplexity3.2818055152893066
INFO:root:current mean train loss 3020.956911336407
INFO:root:current train perplexity3.2916815280914307
INFO:root:current mean train loss 3018.7418560296996
INFO:root:current train perplexity3.2908685207366943
INFO:root:current mean train loss 3018.68407495471
INFO:root:current train perplexity3.2908880710601807
INFO:root:current mean train loss 3015.12780573274
INFO:root:current train perplexity3.2880144119262695
INFO:root:current mean train loss 3011.4008027686905
INFO:root:current train perplexity3.2826924324035645
INFO:root:current mean train loss 3012.6587921181554
INFO:root:current train perplexity3.28045916557312
INFO:root:current mean train loss 3009.820435538027
INFO:root:current train perplexity3.277005195617676
INFO:root:current mean train loss 3012.4938170082814
INFO:root:current train perplexity3.2793619632720947

100%|██████████| 1/1 [08:37<00:00, 517.67s/it][A100%|██████████| 1/1 [08:37<00:00, 517.67s/it]
INFO:root:final mean train loss: 3010.5364702901534
INFO:root:final train perplexity: 3.279672861099243
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 3681.637039076352
INFO:root:eval perplexity: 4.431534767150879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 4700.924241952017
INFO:root:eval perplexity: 6.8364763259887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/124
 62%|██████▏   | 124/200 [20:30:18<12:33:44, 595.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3021.3727598085507
INFO:root:current train perplexity3.2723758220672607
INFO:root:current mean train loss 3010.4851406556772
INFO:root:current train perplexity3.2788476943969727
INFO:root:current mean train loss 3006.8534090756552
INFO:root:current train perplexity3.2766473293304443
INFO:root:current mean train loss 3011.3674116598067
INFO:root:current train perplexity3.27295184135437
INFO:root:current mean train loss 3003.6658689417322
INFO:root:current train perplexity3.2683963775634766
INFO:root:current mean train loss 3002.1141280998836
INFO:root:current train perplexity3.2680227756500244
INFO:root:current mean train loss 3002.5087583241
INFO:root:current train perplexity3.2661964893341064
INFO:root:current mean train loss 3005.907547865143
INFO:root:current train perplexity3.2712273597717285
INFO:root:current mean train loss 3007.225364539492
INFO:root:current train perplexity3.273141860961914
INFO:root:current mean train loss 3010.0592328022517
INFO:root:current train perplexity3.276001214981079

100%|██████████| 1/1 [08:34<00:00, 514.82s/it][A100%|██████████| 1/1 [08:34<00:00, 514.82s/it]
INFO:root:final mean train loss: 3007.5738015943957
INFO:root:final train perplexity: 3.27584171295166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3671.840612533245
INFO:root:eval perplexity: 4.414013862609863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 4686.00902627715
INFO:root:eval perplexity: 6.79490852355957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/125
 62%|██████▎   | 125/200 [20:40:10<12:22:21, 593.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2997.438168304135
INFO:root:current train perplexity3.2513084411621094
INFO:root:current mean train loss 3015.690627208307
INFO:root:current train perplexity3.2743842601776123
INFO:root:current mean train loss 3010.0473894100123
INFO:root:current train perplexity3.2728431224823
INFO:root:current mean train loss 3008.2465098292605
INFO:root:current train perplexity3.2744812965393066
INFO:root:current mean train loss 3003.6613661894103
INFO:root:current train perplexity3.273536443710327
INFO:root:current mean train loss 3005.2971696805876
INFO:root:current train perplexity3.273344039916992
INFO:root:current mean train loss 3006.835956360649
INFO:root:current train perplexity3.274595260620117
INFO:root:current mean train loss 3008.761617610392
INFO:root:current train perplexity3.274596929550171
INFO:root:current mean train loss 3009.950831055774
INFO:root:current train perplexity3.2759270668029785

100%|██████████| 1/1 [08:37<00:00, 517.33s/it][A100%|██████████| 1/1 [08:37<00:00, 517.33s/it]
INFO:root:final mean train loss: 3009.6699480241346
INFO:root:final train perplexity: 3.2785520553588867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3732.755852449025
INFO:root:eval perplexity: 4.524091720581055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.33s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 4757.591692985372
INFO:root:eval perplexity: 6.996741771697998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/126
 63%|██████▎   | 126/200 [20:50:04<12:12:37, 594.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3054.2228655133927
INFO:root:current train perplexity3.327810525894165
INFO:root:current mean train loss 2987.043589369159
INFO:root:current train perplexity3.2426083087921143
INFO:root:current mean train loss 3006.6110615753323
INFO:root:current train perplexity3.262387275695801
INFO:root:current mean train loss 3012.224031230914
INFO:root:current train perplexity3.2630672454833984
INFO:root:current mean train loss 3001.4671165972436
INFO:root:current train perplexity3.2537472248077393
INFO:root:current mean train loss 3003.232363608697
INFO:root:current train perplexity3.259321451187134
INFO:root:current mean train loss 3009.089445965687
INFO:root:current train perplexity3.2683651447296143
INFO:root:current mean train loss 4192.527500870204
INFO:root:current train perplexity5.213049411773682
INFO:root:current mean train loss 5315.192935532354
INFO:root:current train perplexity8.117812156677246
INFO:root:current mean train loss 6340.246885928455
INFO:root:current train perplexity12.166842460632324

100%|██████████| 1/1 [08:37<00:00, 517.40s/it][A100%|██████████| 1/1 [08:37<00:00, 517.40s/it]
INFO:root:final mean train loss: 7094.757379593388
INFO:root:final train perplexity: 16.42963981628418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 14212.612955729166
INFO:root:eval perplexity: 313.3006591796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.85s/it][A100%|██████████| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 14682.340931128103
INFO:root:eval perplexity: 404.9693298339844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/127
 64%|██████▎   | 127/200 [20:59:58<12:02:37, 593.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15885.9474609375
INFO:root:current train perplexity528.7967529296875
INFO:root:current mean train loss 20473.57241847826
INFO:root:current train perplexity3320.77685546875
INFO:root:current mean train loss 20451.63910792151
INFO:root:current train perplexity3296.09716796875
INFO:root:current mean train loss 20465.70851314484
INFO:root:current train perplexity3206.725830078125
INFO:root:current mean train loss 20282.284779743975
INFO:root:current train perplexity2971.672119140625
INFO:root:current mean train loss 19997.073077214805
INFO:root:current train perplexity2646.332275390625
INFO:root:current mean train loss 19716.23378429878
INFO:root:current train perplexity2372.585693359375
INFO:root:current mean train loss 19431.238572170016
INFO:root:current train perplexity2118.45849609375
INFO:root:current mean train loss 19071.09511119632
INFO:root:current train perplexity1834.66552734375
INFO:root:current mean train loss 18703.480900998977
INFO:root:current train perplexity1582.263916015625

100%|██████████| 1/1 [08:35<00:00, 515.71s/it][A100%|██████████| 1/1 [08:35<00:00, 515.71s/it]
INFO:root:final mean train loss: 18423.650025890718
INFO:root:final train perplexity: 1434.6317138671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 14423.604409075799
INFO:root:eval perplexity: 341.2044372558594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 14602.20311114805
INFO:root:eval perplexity: 391.9136962890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/128
 64%|██████▍   | 128/200 [21:09:50<11:52:12, 593.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15576.066576086956
INFO:root:current train perplexity462.4859619140625
INFO:root:current mean train loss 15259.124595083842
INFO:root:current train perplexity412.4526672363281
INFO:root:current mean train loss 14763.154927480382
INFO:root:current train perplexity339.9899597167969
INFO:root:current mean train loss 14419.401599990326
INFO:root:current train perplexity295.4836120605469
INFO:root:current mean train loss 14212.509580932328
INFO:root:current train perplexity270.966064453125
INFO:root:current mean train loss 14062.260118531907
INFO:root:current train perplexity255.565673828125
INFO:root:current mean train loss 13949.082954516954
INFO:root:current train perplexity244.63534545898438
INFO:root:current mean train loss 13867.4233094528
INFO:root:current train perplexity236.70068359375
INFO:root:current mean train loss 13791.975508809235
INFO:root:current train perplexity230.64315795898438
INFO:root:current mean train loss 13750.669016200569
INFO:root:current train perplexity225.89627075195312

100%|██████████| 1/1 [08:35<00:00, 515.24s/it][A100%|██████████| 1/1 [08:35<00:00, 515.24s/it]
INFO:root:final mean train loss: 13704.493332647507
INFO:root:final train perplexity: 222.9213104248047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 12938.72420766844
INFO:root:eval perplexity: 187.17433166503906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.27s/it][A100%|██████████| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 13150.126773049646
INFO:root:eval perplexity: 216.43014526367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/129
 64%|██████▍   | 129/200 [21:19:42<11:41:45, 593.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13376.110509072581
INFO:root:current train perplexity186.83949279785156
INFO:root:current mean train loss 13177.657368201335
INFO:root:current train perplexity184.01693725585938
INFO:root:current mean train loss 13188.56382322105
INFO:root:current train perplexity183.46339416503906
INFO:root:current mean train loss 13178.141757930514
INFO:root:current train perplexity182.7122344970703
INFO:root:current mean train loss 13166.761895482889
INFO:root:current train perplexity182.0137939453125
INFO:root:current mean train loss 13174.096442443502
INFO:root:current train perplexity182.06137084960938
INFO:root:current mean train loss 13169.164424648376
INFO:root:current train perplexity181.56304931640625
INFO:root:current mean train loss 13183.066386211098
INFO:root:current train perplexity181.462646484375
INFO:root:current mean train loss 13191.932796987816
INFO:root:current train perplexity181.268310546875
INFO:root:current mean train loss 13183.580116935755
INFO:root:current train perplexity180.92919921875

100%|██████████| 1/1 [08:36<00:00, 516.70s/it][A100%|██████████| 1/1 [08:36<00:00, 516.70s/it]
INFO:root:final mean train loss: 13173.362495668473
INFO:root:final train perplexity: 180.77854919433594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 12853.196503767731
INFO:root:eval perplexity: 180.8114776611328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:45<00:00, 45.76s/it][A100%|██████████| 1/1 [00:45<00:00, 45.76s/it]
INFO:root:eval mean loss: 13077.01446143617
INFO:root:eval perplexity: 210.0552520751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/130
 65%|██████▌   | 130/200 [21:29:44<11:34:54, 595.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13147.92357772436
INFO:root:current train perplexity177.15538024902344
INFO:root:current mean train loss 13096.22516439973
INFO:root:current train perplexity178.25186157226562
INFO:root:current mean train loss 13136.784249150105
INFO:root:current train perplexity178.93109130859375
INFO:root:current mean train loss 13130.127365067294
INFO:root:current train perplexity178.97161865234375
INFO:root:current mean train loss 13128.893781588127
INFO:root:current train perplexity179.01156616210938
INFO:root:current mean train loss 13140.342003420687
INFO:root:current train perplexity179.33041381835938
INFO:root:current mean train loss 13141.770792070129
INFO:root:current train perplexity179.36837768554688
INFO:root:current mean train loss 13153.524699498901
INFO:root:current train perplexity179.52975463867188
INFO:root:current mean train loss 13154.174749981377
INFO:root:current train perplexity179.5811309814453
INFO:root:current mean train loss 13163.003880249933
INFO:root:current train perplexity179.59165954589844

100%|██████████| 1/1 [08:35<00:00, 515.75s/it][A100%|██████████| 1/1 [08:35<00:00, 515.75s/it]
INFO:root:final mean train loss: 13157.550602820611
INFO:root:final train perplexity: 179.65428161621094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.87s/it][A100%|██████████| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 12874.820132424646
INFO:root:eval perplexity: 182.39938354492188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.43s/it][A100%|██████████| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 13098.411395999557
INFO:root:eval perplexity: 211.9011993408203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/131
 66%|██████▌   | 131/200 [21:39:36<11:23:55, 594.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13149.316510139628
INFO:root:current train perplexity178.6776885986328
INFO:root:current mean train loss 13153.81160980017
INFO:root:current train perplexity179.4425506591797
INFO:root:current mean train loss 13164.929529352226
INFO:root:current train perplexity179.30364990234375
INFO:root:current mean train loss 13163.167414332673
INFO:root:current train perplexity179.28004455566406
INFO:root:current mean train loss 13175.052063671
INFO:root:current train perplexity179.5160675048828
INFO:root:current mean train loss 13178.047546275136
INFO:root:current train perplexity179.63302612304688
INFO:root:current mean train loss 13176.870764707302
INFO:root:current train perplexity179.6187286376953
INFO:root:current mean train loss 13171.618782421352
INFO:root:current train perplexity179.57847595214844
INFO:root:current mean train loss 13163.709548175546
INFO:root:current train perplexity179.5137481689453
INFO:root:current mean train loss 13165.823954758447
INFO:root:current train perplexity179.49484252929688

100%|██████████| 1/1 [08:35<00:00, 515.63s/it][A100%|██████████| 1/1 [08:35<00:00, 515.63s/it]
INFO:root:final mean train loss: 13156.321178313225
INFO:root:final train perplexity: 179.5670928955078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.81s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 12906.722102171985
INFO:root:eval perplexity: 184.76773071289062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 13130.060907025709
INFO:root:eval perplexity: 214.66140747070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/132
 66%|██████▌   | 132/200 [21:49:29<11:13:11, 593.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13235.787553267046
INFO:root:current train perplexity180.807861328125
INFO:root:current mean train loss 13235.74468876008
INFO:root:current train perplexity181.31283569335938
INFO:root:current mean train loss 13205.563606770833
INFO:root:current train perplexity180.8297576904297
INFO:root:current mean train loss 13201.858956866197
INFO:root:current train perplexity180.8282928466797
INFO:root:current mean train loss 13191.735643458105
INFO:root:current train perplexity180.67091369628906
INFO:root:current mean train loss 13179.954258164415
INFO:root:current train perplexity180.630859375
INFO:root:current mean train loss 13183.85330242128
INFO:root:current train perplexity180.5851287841797
INFO:root:current mean train loss 13179.779997930464
INFO:root:current train perplexity180.6479949951172
INFO:root:current mean train loss 13181.329565286915
INFO:root:current train perplexity180.7014923095703
INFO:root:current mean train loss 13186.301879499346
INFO:root:current train perplexity180.95111083984375

100%|██████████| 1/1 [08:37<00:00, 517.01s/it][A100%|██████████| 1/1 [08:37<00:00, 517.01s/it]
INFO:root:final mean train loss: 13176.22791856335
INFO:root:final train perplexity: 180.9829559326172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 12990.60625831117
INFO:root:eval perplexity: 191.14260864257812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.15s/it][A100%|██████████| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 13212.859638187057
INFO:root:eval perplexity: 222.05381774902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/133
 66%|██████▋   | 133/200 [21:59:22<11:03:08, 593.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13304.137462797618
INFO:root:current train perplexity184.71893310546875
INFO:root:current mean train loss 13285.016026409126
INFO:root:current train perplexity184.91465759277344
INFO:root:current mean train loss 13320.06524402923
INFO:root:current train perplexity186.2071075439453
INFO:root:current mean train loss 13313.758205277203
INFO:root:current train perplexity187.38356018066406
INFO:root:current mean train loss 13301.65083144911
INFO:root:current train perplexity188.19447326660156
INFO:root:current mean train loss 13312.790764112455
INFO:root:current train perplexity188.98826599121094
INFO:root:current mean train loss 13331.79213506316
INFO:root:current train perplexity190.47169494628906
INFO:root:current mean train loss 13356.720248761058
INFO:root:current train perplexity192.2300262451172
INFO:root:current mean train loss 13364.830836290555
INFO:root:current train perplexity193.74122619628906
INFO:root:current mean train loss 13381.346446448273
INFO:root:current train perplexity195.3671112060547

100%|██████████| 1/1 [08:38<00:00, 518.42s/it][A100%|██████████| 1/1 [08:38<00:00, 518.42s/it]
INFO:root:final mean train loss: 13375.491338422222
INFO:root:final train perplexity: 195.78518676757812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.42s/it][A100%|██████████| 1/1 [00:38<00:00, 38.42s/it]
INFO:root:eval mean loss: 13491.14784879211
INFO:root:eval perplexity: 234.02403259277344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.43s/it][A100%|██████████| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 13712.676245290337
INFO:root:eval perplexity: 272.4080810546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/134
 67%|██████▋   | 134/200 [22:09:18<10:53:50, 594.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13584.05244553257
INFO:root:current train perplexity213.15020751953125
INFO:root:current mean train loss 13577.480799981726
INFO:root:current train perplexity212.59385681152344
INFO:root:current mean train loss 13603.082896102398
INFO:root:current train perplexity213.77926635742188
INFO:root:current mean train loss 13608.275493282514
INFO:root:current train perplexity214.4192657470703
INFO:root:current mean train loss 13628.54197352707
INFO:root:current train perplexity215.34091186523438
INFO:root:current mean train loss 13609.964783890653
INFO:root:current train perplexity215.25694274902344
INFO:root:current mean train loss 13622.646167101342
INFO:root:current train perplexity216.03956604003906
INFO:root:current mean train loss 13624.201841915938
INFO:root:current train perplexity216.22991943359375
INFO:root:current mean train loss 13637.106663945895
INFO:root:current train perplexity216.53843688964844
INFO:root:current mean train loss 13645.74602033181
INFO:root:current train perplexity216.99322509765625

100%|██████████| 1/1 [08:38<00:00, 518.27s/it][A100%|██████████| 1/1 [08:38<00:00, 518.27s/it]
INFO:root:final mean train loss: 13635.223971213063
INFO:root:final train perplexity: 216.91160583496094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 13366.359264184397
INFO:root:eval perplexity: 222.50799560546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 13597.08147024601
INFO:root:eval perplexity: 259.83148193359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/135
 68%|██████▊   | 135/200 [22:19:13<10:44:11, 594.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13644.702173160602
INFO:root:current train perplexity219.13427734375
INFO:root:current mean train loss 13673.38777169169
INFO:root:current train perplexity219.00672912597656
INFO:root:current mean train loss 13684.15756608423
INFO:root:current train perplexity219.341064453125
INFO:root:current mean train loss 13674.025558109333
INFO:root:current train perplexity218.64590454101562
INFO:root:current mean train loss 13684.682598838726
INFO:root:current train perplexity219.15203857421875
INFO:root:current mean train loss 13670.827263128778
INFO:root:current train perplexity218.7438201904297
INFO:root:current mean train loss 13676.929911864874
INFO:root:current train perplexity219.01832580566406
INFO:root:current mean train loss 13672.395608101331
INFO:root:current train perplexity219.01748657226562
INFO:root:current mean train loss 13667.412760416666
INFO:root:current train perplexity218.60264587402344
INFO:root:current mean train loss 13628.62774315309
INFO:root:current train perplexity215.5294189453125

100%|██████████| 1/1 [08:41<00:00, 521.81s/it][A100%|██████████| 1/1 [08:41<00:00, 521.81s/it]
INFO:root:final mean train loss: 13617.33335310413
INFO:root:final train perplexity: 215.38619995117188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.05s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 13254.020203069593
INFO:root:eval perplexity: 212.6262969970703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.13s/it][A100%|██████████| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 13490.666798260196
INFO:root:eval perplexity: 248.76759338378906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/136
 68%|██████▊   | 136/200 [22:29:12<10:35:30, 595.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13458.230580998563
INFO:root:current train perplexity203.63291931152344
INFO:root:current mean train loss 13513.73723157587
INFO:root:current train perplexity205.25607299804688
INFO:root:current mean train loss 13510.160615608667
INFO:root:current train perplexity205.12359619140625
INFO:root:current mean train loss 13473.234930151808
INFO:root:current train perplexity203.28182983398438
INFO:root:current mean train loss 13450.825740743712
INFO:root:current train perplexity201.5991973876953
INFO:root:current mean train loss 13422.58538017728
INFO:root:current train perplexity198.99717712402344
INFO:root:current mean train loss 13400.794975891558
INFO:root:current train perplexity196.8739471435547
INFO:root:current mean train loss 13362.752603339422
INFO:root:current train perplexity194.70123291015625
INFO:root:current mean train loss 13342.80845062359
INFO:root:current train perplexity192.67391967773438
INFO:root:current mean train loss 13324.187848277608
INFO:root:current train perplexity191.13558959960938

100%|██████████| 1/1 [08:37<00:00, 517.09s/it][A100%|██████████| 1/1 [08:37<00:00, 517.09s/it]
INFO:root:final mean train loss: 13313.77859644736
INFO:root:final train perplexity: 191.07591247558594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 12842.979187444593
INFO:root:eval perplexity: 180.0661163330078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 13064.137085826684
INFO:root:eval perplexity: 208.95217895507812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/137
 68%|██████▊   | 137/200 [22:39:05<10:24:57, 595.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13217.049300986842
INFO:root:current train perplexity178.259765625
INFO:root:current mean train loss 13155.557922676282
INFO:root:current train perplexity178.2568817138672
INFO:root:current mean train loss 13146.516452595339
INFO:root:current train perplexity178.40347290039062
INFO:root:current mean train loss 13130.805562697786
INFO:root:current train perplexity178.2330780029297
INFO:root:current mean train loss 13150.376672979797
INFO:root:current train perplexity178.61346435546875
INFO:root:current mean train loss 13139.168259256829
INFO:root:current train perplexity178.4662628173828
INFO:root:current mean train loss 13133.662169795414
INFO:root:current train perplexity178.4109649658203
INFO:root:current mean train loss 13130.396706711872
INFO:root:current train perplexity178.3111114501953
INFO:root:current mean train loss 13145.21376462116
INFO:root:current train perplexity178.4000701904297

100%|██████████| 1/1 [08:35<00:00, 515.42s/it][A100%|██████████| 1/1 [08:35<00:00, 515.42s/it]
INFO:root:final mean train loss: 13140.907622060467
INFO:root:final train perplexity: 178.47860717773438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.82s/it][A100%|██████████| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 12849.952224623226
INFO:root:eval perplexity: 180.57444763183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.05s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 13073.393831726507
INFO:root:eval perplexity: 209.74447631835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/138
 69%|██████▉   | 138/200 [22:48:57<10:13:59, 594.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13219.921223958334
INFO:root:current train perplexity175.69387817382812
INFO:root:current mean train loss 13131.081377047936
INFO:root:current train perplexity177.98143005371094
INFO:root:current mean train loss 13113.63605969058
INFO:root:current train perplexity177.61264038085938
INFO:root:current mean train loss 13140.555154831889
INFO:root:current train perplexity178.1102294921875
INFO:root:current mean train loss 13145.644572444944
INFO:root:current train perplexity177.96572875976562
INFO:root:current mean train loss 13137.676326804796
INFO:root:current train perplexity177.97039794921875
INFO:root:current mean train loss 13148.422603777984
INFO:root:current train perplexity178.17453002929688
INFO:root:current mean train loss 13151.362750600107
INFO:root:current train perplexity178.21395874023438
INFO:root:current mean train loss 13159.002670649128
INFO:root:current train perplexity178.4420166015625
INFO:root:current mean train loss 13156.198828341292
INFO:root:current train perplexity178.38034057617188

100%|██████████| 1/1 [08:34<00:00, 514.94s/it][A100%|██████████| 1/1 [08:34<00:00, 514.94s/it]
INFO:root:final mean train loss: 13137.863790450558
INFO:root:final train perplexity: 178.26443481445312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 12838.149538730053
INFO:root:eval perplexity: 179.7147674560547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.15s/it][A100%|██████████| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 13064.713860261525
INFO:root:eval perplexity: 209.00140380859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/139
 70%|██████▉   | 139/200 [22:58:49<10:03:17, 593.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13165.184215198864
INFO:root:current train perplexity179.97314453125
INFO:root:current mean train loss 13168.530247043918
INFO:root:current train perplexity178.2837371826172
INFO:root:current mean train loss 13188.232607005331
INFO:root:current train perplexity178.1566925048828
INFO:root:current mean train loss 13182.062986711213
INFO:root:current train perplexity178.07388305664062
INFO:root:current mean train loss 13171.381826433242
INFO:root:current train perplexity178.4364776611328
INFO:root:current mean train loss 13200.530227571551
INFO:root:current train perplexity178.9225616455078
INFO:root:current mean train loss 13198.815675826003
INFO:root:current train perplexity179.1662139892578
INFO:root:current mean train loss 13180.759103595288
INFO:root:current train perplexity179.00917053222656
INFO:root:current mean train loss 13174.913665131782
INFO:root:current train perplexity178.88528442382812
INFO:root:current mean train loss 13161.415920219883
INFO:root:current train perplexity178.7618865966797

100%|██████████| 1/1 [08:37<00:00, 517.59s/it][A100%|██████████| 1/1 [08:37<00:00, 517.59s/it]
INFO:root:final mean train loss: 13142.623998334331
INFO:root:final train perplexity: 178.59933471679688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 12841.730925864362
INFO:root:eval perplexity: 179.97512817382812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 13066.704898049646
INFO:root:eval perplexity: 209.17169189453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/140
 70%|███████   | 140/200 [23:08:43<9:53:40, 593.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13077.718698601973
INFO:root:current train perplexity179.080810546875
INFO:root:current mean train loss 13117.130900407037
INFO:root:current train perplexity178.45631408691406
INFO:root:current mean train loss 13120.05753692209
INFO:root:current train perplexity178.26937866210938
INFO:root:current mean train loss 13157.912767559757
INFO:root:current train perplexity178.7113494873047
INFO:root:current mean train loss 13138.266997781175
INFO:root:current train perplexity178.29623413085938
INFO:root:current mean train loss 13137.39866517642
INFO:root:current train perplexity178.37132263183594
INFO:root:current mean train loss 13148.433339749092
INFO:root:current train perplexity178.34555053710938
INFO:root:current mean train loss 13154.185747892037
INFO:root:current train perplexity178.26571655273438
INFO:root:current mean train loss 13152.642006973061
INFO:root:current train perplexity178.2080078125
INFO:root:current mean train loss 13146.753858431379
INFO:root:current train perplexity178.13137817382812

100%|██████████| 1/1 [08:41<00:00, 521.44s/it][A100%|██████████| 1/1 [08:41<00:00, 521.44s/it]
INFO:root:final mean train loss: 13135.350475680443
INFO:root:final train perplexity: 178.08763122558594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.30s/it][A100%|██████████| 1/1 [00:38<00:00, 38.30s/it]
INFO:root:eval mean loss: 12851.471194869238
INFO:root:eval perplexity: 180.6853790283203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.99s/it][A100%|██████████| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 13076.155411957003
INFO:root:eval perplexity: 209.98155212402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/141
 70%|███████   | 141/200 [23:18:41<9:45:07, 595.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13273.930483217593
INFO:root:current train perplexity177.54244995117188
INFO:root:current mean train loss 13097.064852977363
INFO:root:current train perplexity176.9701385498047
INFO:root:current mean train loss 13123.881526190804
INFO:root:current train perplexity177.61068725585938
INFO:root:current mean train loss 13151.05494731938
INFO:root:current train perplexity178.0381317138672
INFO:root:current mean train loss 13147.83048750366
INFO:root:current train perplexity177.90769958496094
INFO:root:current mean train loss 13142.38697261919
INFO:root:current train perplexity177.7144775390625
INFO:root:current mean train loss 13141.733462295653
INFO:root:current train perplexity177.79330444335938
INFO:root:current mean train loss 13155.930666749055
INFO:root:current train perplexity178.1306915283203
INFO:root:current mean train loss 13155.114110206317
INFO:root:current train perplexity178.22381591796875
INFO:root:current mean train loss 13153.252333426039
INFO:root:current train perplexity178.31256103515625

100%|██████████| 1/1 [08:38<00:00, 518.22s/it][A100%|██████████| 1/1 [08:38<00:00, 518.22s/it]
INFO:root:final mean train loss: 13138.05660124748
INFO:root:final train perplexity: 178.2778778076172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.26s/it][A100%|██████████| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 12854.295205839982
INFO:root:eval perplexity: 180.89193725585938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 13079.571240580673
INFO:root:eval perplexity: 210.27513122558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/142
 71%|███████   | 142/200 [23:28:37<9:35:20, 595.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13367.917494419642
INFO:root:current train perplexity180.5552520751953
INFO:root:current mean train loss 13249.38351417824
INFO:root:current train perplexity179.2744903564453
INFO:root:current mean train loss 13233.532500831117
INFO:root:current train perplexity178.77902221679688
INFO:root:current mean train loss 13183.65881821362
INFO:root:current train perplexity178.51904296875
INFO:root:current mean train loss 13169.267573635057
INFO:root:current train perplexity178.5005645751953
INFO:root:current mean train loss 13156.534108498832
INFO:root:current train perplexity178.10292053222656
INFO:root:current mean train loss 13161.259917876476
INFO:root:current train perplexity178.20452880859375
INFO:root:current mean train loss 13163.026105442177
INFO:root:current train perplexity178.2386932373047
INFO:root:current mean train loss 13160.894464586452
INFO:root:current train perplexity178.23529052734375
INFO:root:current mean train loss 13152.213803475935
INFO:root:current train perplexity178.1453857421875

100%|██████████| 1/1 [08:38<00:00, 518.59s/it][A100%|██████████| 1/1 [08:38<00:00, 518.59s/it]
INFO:root:final mean train loss: 13136.286569656864
INFO:root:final train perplexity: 178.15338134765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12849.26013962766
INFO:root:eval perplexity: 180.52391052246094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 13073.92310782358
INFO:root:eval perplexity: 209.7899932861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/143
 72%|███████▏  | 143/200 [23:38:32<9:25:26, 595.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13213.1474609375
INFO:root:current train perplexity178.55360412597656
INFO:root:current mean train loss 13247.990712412588
INFO:root:current train perplexity179.03982543945312
INFO:root:current mean train loss 13212.696498038837
INFO:root:current train perplexity178.911376953125
INFO:root:current mean train loss 13191.821254897048
INFO:root:current train perplexity178.84869384765625
INFO:root:current mean train loss 13169.23638103132
INFO:root:current train perplexity178.85867309570312
INFO:root:current mean train loss 13173.290013884092
INFO:root:current train perplexity178.8873291015625
INFO:root:current mean train loss 13165.816032635108
INFO:root:current train perplexity178.68605041503906
INFO:root:current mean train loss 13158.096383958613
INFO:root:current train perplexity178.4413299560547
INFO:root:current mean train loss 13147.350349616325
INFO:root:current train perplexity178.35304260253906
INFO:root:current mean train loss 13147.928320519619
INFO:root:current train perplexity178.2567901611328

100%|██████████| 1/1 [08:35<00:00, 515.44s/it][A100%|██████████| 1/1 [08:35<00:00, 515.44s/it]
INFO:root:final mean train loss: 13136.880251484532
INFO:root:final train perplexity: 178.19517517089844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 12849.850911458334
INFO:root:eval perplexity: 180.56712341308594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 13074.236016456118
INFO:root:eval perplexity: 209.81680297851562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/144
 72%|███████▏  | 144/200 [23:48:24<9:14:41, 594.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13142.900543811274
INFO:root:current train perplexity178.23333740234375
INFO:root:current mean train loss 13163.780241100992
INFO:root:current train perplexity178.27378845214844
INFO:root:current mean train loss 13163.13847344995
INFO:root:current train perplexity178.18702697753906
INFO:root:current mean train loss 13159.959610376603
INFO:root:current train perplexity178.41053771972656
INFO:root:current mean train loss 13164.921392132068
INFO:root:current train perplexity178.4036407470703
INFO:root:current mean train loss 13160.783220848458
INFO:root:current train perplexity178.2126007080078
INFO:root:current mean train loss 13159.619638656874
INFO:root:current train perplexity178.2119140625
INFO:root:current mean train loss 13164.386086780127
INFO:root:current train perplexity178.2307891845703
INFO:root:current mean train loss 13156.464983750735
INFO:root:current train perplexity178.2638397216797
INFO:root:current mean train loss 13153.99452262421
INFO:root:current train perplexity178.23910522460938

100%|██████████| 1/1 [08:36<00:00, 516.88s/it][A100%|██████████| 1/1 [08:36<00:00, 516.88s/it]
INFO:root:final mean train loss: 13136.50528224822
INFO:root:final train perplexity: 178.1687469482422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 12847.855932790337
INFO:root:eval perplexity: 180.4215087890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.37s/it][A100%|██████████| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 13070.904753989362
INFO:root:eval perplexity: 209.53115844726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/145
 72%|███████▎  | 145/200 [23:58:18<9:04:36, 594.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13151.951999470339
INFO:root:current train perplexity178.21990966796875
INFO:root:current mean train loss 13133.360247150158
INFO:root:current train perplexity177.52601623535156
INFO:root:current mean train loss 13104.148037825773
INFO:root:current train perplexity177.65524291992188
INFO:root:current mean train loss 13120.349658339137
INFO:root:current train perplexity177.72032165527344
INFO:root:current mean train loss 13127.596505225354
INFO:root:current train perplexity178.0162353515625
INFO:root:current mean train loss 13123.524525869298
INFO:root:current train perplexity177.96514892578125
INFO:root:current mean train loss 13131.328202058043
INFO:root:current train perplexity178.07762145996094
INFO:root:current mean train loss 13131.409959393528
INFO:root:current train perplexity177.9620819091797
INFO:root:current mean train loss 13131.581031950305
INFO:root:current train perplexity177.86749267578125
INFO:root:current mean train loss 13142.34147712461
INFO:root:current train perplexity178.03167724609375

100%|██████████| 1/1 [08:32<00:00, 512.30s/it][A100%|██████████| 1/1 [08:32<00:00, 512.30s/it]
INFO:root:final mean train loss: 13135.629028566422
INFO:root:final train perplexity: 178.1072540283203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 12840.960826684397
INFO:root:eval perplexity: 179.91917419433594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.41s/it][A100%|██████████| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 13064.360268450799
INFO:root:eval perplexity: 208.97120666503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/146
 73%|███████▎  | 146/200 [24:08:07<8:53:15, 592.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13231.964595965484
INFO:root:current train perplexity178.5625457763672
INFO:root:current mean train loss 13175.511133982036
INFO:root:current train perplexity178.22210693359375
INFO:root:current mean train loss 13149.240834211143
INFO:root:current train perplexity177.92848205566406
INFO:root:current mean train loss 13141.717398245914
INFO:root:current train perplexity178.49307250976562
INFO:root:current mean train loss 13155.986930373394
INFO:root:current train perplexity178.62803649902344
INFO:root:current mean train loss 13141.258492821318
INFO:root:current train perplexity178.36868286132812
INFO:root:current mean train loss 13136.618311937782
INFO:root:current train perplexity178.1597442626953
INFO:root:current mean train loss 13141.340428159632
INFO:root:current train perplexity178.1656036376953
INFO:root:current mean train loss 13147.00423852905
INFO:root:current train perplexity178.14157104492188
INFO:root:current mean train loss 13148.461995863496
INFO:root:current train perplexity178.17758178710938

100%|██████████| 1/1 [08:40<00:00, 520.06s/it][A100%|██████████| 1/1 [08:40<00:00, 520.06s/it]
INFO:root:final mean train loss: 13135.707282527801
INFO:root:final train perplexity: 178.11277770996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.65s/it][A100%|██████████| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 12843.944529864804
INFO:root:eval perplexity: 180.13636779785156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.86s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 13068.142501939274
INFO:root:eval perplexity: 209.29470825195312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/147
 74%|███████▎  | 147/200 [24:18:03<8:44:17, 593.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13109.827200520833
INFO:root:current train perplexity177.23312377929688
INFO:root:current mean train loss 13094.347421875
INFO:root:current train perplexity177.53016662597656
INFO:root:current mean train loss 13154.645124289773
INFO:root:current train perplexity178.50567626953125
INFO:root:current mean train loss 13156.298794270833
INFO:root:current train perplexity178.6048583984375
INFO:root:current mean train loss 13142.69888774671
INFO:root:current train perplexity178.2722625732422
INFO:root:current mean train loss 13146.334862432066
INFO:root:current train perplexity178.30430603027344
INFO:root:current mean train loss 13140.171302083334
INFO:root:current train perplexity178.11463928222656
INFO:root:current mean train loss 13148.474947076613
INFO:root:current train perplexity178.16357421875
INFO:root:current mean train loss 13148.194154017858
INFO:root:current train perplexity178.1685028076172
INFO:root:current mean train loss 13145.39941806891
INFO:root:current train perplexity178.13400268554688

100%|██████████| 1/1 [08:38<00:00, 518.02s/it][A100%|██████████| 1/1 [08:38<00:00, 518.02s/it]
INFO:root:final mean train loss: 13136.088419514317
INFO:root:final train perplexity: 178.1395263671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 12846.596499612146
INFO:root:eval perplexity: 180.32965087890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.98s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 13070.522800310284
INFO:root:eval perplexity: 209.49839782714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/148
 74%|███████▍  | 148/200 [24:27:58<8:34:54, 594.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13130.636271649097
INFO:root:current train perplexity178.63722229003906
INFO:root:current mean train loss 13099.584133794398
INFO:root:current train perplexity178.07626342773438
INFO:root:current mean train loss 13117.113667734098
INFO:root:current train perplexity178.2272186279297
INFO:root:current mean train loss 13155.810391338937
INFO:root:current train perplexity178.36434936523438
INFO:root:current mean train loss 13168.95104854102
INFO:root:current train perplexity178.30694580078125
INFO:root:current mean train loss 13146.802871730275
INFO:root:current train perplexity178.01657104492188
INFO:root:current mean train loss 13147.479000331718
INFO:root:current train perplexity177.8752899169922
INFO:root:current mean train loss 13137.127017979725
INFO:root:current train perplexity177.88217163085938
INFO:root:current mean train loss 13139.195172043106
INFO:root:current train perplexity177.81686401367188
INFO:root:current mean train loss 13143.967895631993
INFO:root:current train perplexity177.95436096191406

100%|██████████| 1/1 [08:35<00:00, 515.97s/it][A100%|██████████| 1/1 [08:35<00:00, 515.97s/it]
INFO:root:final mean train loss: 13133.74143317438
INFO:root:final train perplexity: 177.97463989257812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.92s/it][A100%|██████████| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 12832.05799119016
INFO:root:eval perplexity: 179.27261352539062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 13057.169450908688
INFO:root:eval perplexity: 208.35769653320312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/149
 74%|███████▍  | 149/200 [24:37:51<8:24:35, 593.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13125.72116457761
INFO:root:current train perplexity177.89854431152344
INFO:root:current mean train loss 13102.181635512108
INFO:root:current train perplexity177.75973510742188
INFO:root:current mean train loss 13146.824020752792
INFO:root:current train perplexity178.21617126464844
INFO:root:current mean train loss 13130.95164891704
INFO:root:current train perplexity177.57859802246094
INFO:root:current mean train loss 13133.88775498027
INFO:root:current train perplexity177.44520568847656
INFO:root:current mean train loss 13139.26467983291
INFO:root:current train perplexity177.42929077148438
INFO:root:current mean train loss 13141.267179585746
INFO:root:current train perplexity177.53567504882812
INFO:root:current mean train loss 13141.143670739175
INFO:root:current train perplexity177.59071350097656
INFO:root:current mean train loss 13140.12181164948
INFO:root:current train perplexity177.5926513671875
INFO:root:current mean train loss 13136.310961741612
INFO:root:current train perplexity177.4407958984375

100%|██████████| 1/1 [08:35<00:00, 515.76s/it][A100%|██████████| 1/1 [08:35<00:00, 515.76s/it]
INFO:root:final mean train loss: 13126.13691145374
INFO:root:final train perplexity: 177.44139099121094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.87s/it][A100%|██████████| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 12830.04670185062
INFO:root:eval perplexity: 179.12692260742188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 13054.774233987146
INFO:root:eval perplexity: 208.15371704101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/150
 75%|███████▌  | 150/200 [24:47:43<8:14:22, 593.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13123.007822364269
INFO:root:current train perplexity177.07691955566406
INFO:root:current mean train loss 13114.29069173995
INFO:root:current train perplexity176.9569854736328
INFO:root:current mean train loss 13135.899521843645
INFO:root:current train perplexity177.12742614746094
INFO:root:current mean train loss 13159.51067855185
INFO:root:current train perplexity177.54660034179688
INFO:root:current mean train loss 13144.25135818512
INFO:root:current train perplexity177.50164794921875
INFO:root:current mean train loss 13145.696142333576
INFO:root:current train perplexity177.54591369628906
INFO:root:current mean train loss 13141.926461630454
INFO:root:current train perplexity177.44418334960938
INFO:root:current mean train loss 13139.244606294978
INFO:root:current train perplexity177.4044189453125
INFO:root:current mean train loss 13140.706045997289
INFO:root:current train perplexity177.4737091064453

100%|██████████| 1/1 [08:37<00:00, 517.01s/it][A100%|██████████| 1/1 [08:37<00:00, 517.01s/it]
INFO:root:final mean train loss: 13125.790754995038
INFO:root:final train perplexity: 177.4171905517578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12831.725502825799
INFO:root:eval perplexity: 179.24842834472656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.28s/it][A100%|██████████| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 13057.374355884309
INFO:root:eval perplexity: 208.3750762939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/151
 76%|███████▌  | 151/200 [24:57:37<8:04:35, 593.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12897.53111049107
INFO:root:current train perplexity176.95065307617188
INFO:root:current mean train loss 13170.590719918224
INFO:root:current train perplexity178.19338989257812
INFO:root:current mean train loss 13139.722793063103
INFO:root:current train perplexity177.251708984375
INFO:root:current mean train loss 13104.998355430578
INFO:root:current train perplexity176.9774932861328
INFO:root:current mean train loss 13121.078734451781
INFO:root:current train perplexity176.87295532226562
INFO:root:current mean train loss 13118.136520355645
INFO:root:current train perplexity176.79808044433594
INFO:root:current mean train loss 13114.471811611924
INFO:root:current train perplexity176.9834747314453
INFO:root:current mean train loss 13118.493082567185
INFO:root:current train perplexity176.9881134033203
INFO:root:current mean train loss 13130.03778219873
INFO:root:current train perplexity177.27919006347656
INFO:root:current mean train loss 13126.434227923442
INFO:root:current train perplexity177.26345825195312

100%|██████████| 1/1 [08:36<00:00, 516.35s/it][A100%|██████████| 1/1 [08:36<00:00, 516.35s/it]
INFO:root:final mean train loss: 13124.234761638027
INFO:root:final train perplexity: 177.3084259033203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 12831.834469193262
INFO:root:eval perplexity: 179.25637817382812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.18s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 13055.046681072696
INFO:root:eval perplexity: 208.1767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/152
 76%|███████▌  | 152/200 [25:07:30<7:54:33, 593.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13123.7576171875
INFO:root:current train perplexity176.52943420410156
INFO:root:current mean train loss 13133.237618885869
INFO:root:current train perplexity176.92112731933594
INFO:root:current mean train loss 13138.292205668604
INFO:root:current train perplexity176.95108032226562
INFO:root:current mean train loss 13155.856163194445
INFO:root:current train perplexity177.38656616210938
INFO:root:current mean train loss 13141.28857304217
INFO:root:current train perplexity177.4087371826172
INFO:root:current mean train loss 13143.319601410802
INFO:root:current train perplexity177.50833129882812
INFO:root:current mean train loss 13140.849185403964
INFO:root:current train perplexity177.36737060546875
INFO:root:current mean train loss 13139.010585118007
INFO:root:current train perplexity177.293212890625
INFO:root:current mean train loss 13138.791149827453
INFO:root:current train perplexity177.3384552001953
INFO:root:current mean train loss 13131.069706284154
INFO:root:current train perplexity177.20919799804688

100%|██████████| 1/1 [08:40<00:00, 520.45s/it][A100%|██████████| 1/1 [08:40<00:00, 520.45s/it]
INFO:root:final mean train loss: 13123.88738004623
INFO:root:final train perplexity: 177.28399658203125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.99s/it][A100%|██████████| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 12830.409262799201
INFO:root:eval perplexity: 179.15322875976562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.33s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 13055.44295766844
INFO:root:eval perplexity: 208.21051025390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/153
 76%|███████▋  | 153/200 [25:17:27<7:45:38, 594.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13096.822138247282
INFO:root:current train perplexity177.77642822265625
INFO:root:current mean train loss 13114.152454903455
INFO:root:current train perplexity176.4176025390625
INFO:root:current mean train loss 13145.839186869394
INFO:root:current train perplexity177.0694122314453
INFO:root:current mean train loss 13146.040262795084
INFO:root:current train perplexity177.12059020996094
INFO:root:current mean train loss 13147.206050070183
INFO:root:current train perplexity177.19061279296875
INFO:root:current mean train loss 13145.187921994502
INFO:root:current train perplexity177.28485107421875
INFO:root:current mean train loss 13141.834569058487
INFO:root:current train perplexity177.29380798339844
INFO:root:current mean train loss 13142.118150555412
INFO:root:current train perplexity177.3475799560547
INFO:root:current mean train loss 13143.834252544046
INFO:root:current train perplexity177.3225555419922
INFO:root:current mean train loss 13136.361276281486
INFO:root:current train perplexity177.30345153808594

100%|██████████| 1/1 [08:39<00:00, 519.05s/it][A100%|██████████| 1/1 [08:39<00:00, 519.05s/it]
INFO:root:final mean train loss: 13123.766812232232
INFO:root:final train perplexity: 177.2757110595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.81s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 12830.96426889406
INFO:root:eval perplexity: 179.19329833984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.41s/it][A100%|██████████| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 13055.932624113475
INFO:root:eval perplexity: 208.25230407714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/154
 77%|███████▋  | 154/200 [25:27:23<7:36:02, 594.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13074.685578377017
INFO:root:current train perplexity178.07379150390625
INFO:root:current mean train loss 13123.492023497138
INFO:root:current train perplexity178.0370330810547
INFO:root:current mean train loss 13141.833050087933
INFO:root:current train perplexity177.59121704101562
INFO:root:current mean train loss 13152.179973682969
INFO:root:current train perplexity177.57139587402344
INFO:root:current mean train loss 13155.269909639646
INFO:root:current train perplexity177.684814453125
INFO:root:current mean train loss 13149.565455434911
INFO:root:current train perplexity177.39663696289062
INFO:root:current mean train loss 13151.634121805666
INFO:root:current train perplexity177.44003295898438
INFO:root:current mean train loss 13156.488635270605
INFO:root:current train perplexity177.46229553222656
INFO:root:current mean train loss 13141.574269282115
INFO:root:current train perplexity177.29364013671875
INFO:root:current mean train loss 13137.58361829518
INFO:root:current train perplexity177.291015625

100%|██████████| 1/1 [08:39<00:00, 519.04s/it][A100%|██████████| 1/1 [08:39<00:00, 519.04s/it]
INFO:root:final mean train loss: 13122.85115272768
INFO:root:final train perplexity: 177.21165466308594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 12830.937936336437
INFO:root:eval perplexity: 179.19151306152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.99s/it][A100%|██████████| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 13055.061197916666
INFO:root:eval perplexity: 208.1781463623047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/155
 78%|███████▊  | 155/200 [25:37:18<7:26:15, 595.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13093.175580929486
INFO:root:current train perplexity177.10487365722656
INFO:root:current mean train loss 13135.130648606115
INFO:root:current train perplexity177.58055114746094
INFO:root:current mean train loss 13148.299110061454
INFO:root:current train perplexity178.00689697265625
INFO:root:current mean train loss 13147.564245713496
INFO:root:current train perplexity177.62017822265625
INFO:root:current mean train loss 13157.044979712415
INFO:root:current train perplexity177.48387145996094
INFO:root:current mean train loss 13145.237806557281
INFO:root:current train perplexity177.68836975097656
INFO:root:current mean train loss 13144.98577947721
INFO:root:current train perplexity177.87326049804688
INFO:root:current mean train loss 13328.371410901556
INFO:root:current train perplexity191.44198608398438
INFO:root:current mean train loss 13532.721420124404
INFO:root:current train perplexity207.58566284179688
INFO:root:current mean train loss 13560.666370265908
INFO:root:current train perplexity209.46742248535156

100%|██████████| 1/1 [08:38<00:00, 518.71s/it][A100%|██████████| 1/1 [08:38<00:00, 518.71s/it]
INFO:root:final mean train loss: 13550.72010655557
INFO:root:final train perplexity: 209.7991943359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.19s/it][A100%|██████████| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 12977.612824135638
INFO:root:eval perplexity: 190.14093017578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.92s/it][A100%|██████████| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 13246.869189106827
INFO:root:eval perplexity: 225.16358947753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/156
 78%|███████▊  | 156/200 [25:47:14<7:16:38, 595.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13510.012175864362
INFO:root:current train perplexity214.376220703125
INFO:root:current mean train loss 13615.434975552722
INFO:root:current train perplexity215.40560913085938
INFO:root:current mean train loss 13640.390878036438
INFO:root:current train perplexity214.70706176757812
INFO:root:current mean train loss 13608.889763823847
INFO:root:current train perplexity213.6651153564453
INFO:root:current mean train loss 13608.023579505732
INFO:root:current train perplexity213.49371337890625
INFO:root:current mean train loss 13614.335500099976
INFO:root:current train perplexity212.8123321533203
INFO:root:current mean train loss 13595.842035355487
INFO:root:current train perplexity211.96324157714844
INFO:root:current mean train loss 13591.066688629518
INFO:root:current train perplexity211.3203887939453
INFO:root:current mean train loss 13577.767081196502
INFO:root:current train perplexity210.38082885742188
INFO:root:current mean train loss 13557.315670992279
INFO:root:current train perplexity209.45504760742188

100%|██████████| 1/1 [08:37<00:00, 517.90s/it][A100%|██████████| 1/1 [08:37<00:00, 517.90s/it]
INFO:root:final mean train loss: 13540.993114348381
INFO:root:final train perplexity: 208.99562072753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.06s/it][A100%|██████████| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 12908.391954787234
INFO:root:eval perplexity: 184.8925323486328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 13170.626890791224
INFO:root:eval perplexity: 218.25205993652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/157
 78%|███████▊  | 157/200 [25:57:09<7:06:31, 595.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13459.36690340909
INFO:root:current train perplexity200.98193359375
INFO:root:current mean train loss 13414.022095514112
INFO:root:current train perplexity199.66412353515625
INFO:root:current mean train loss 13397.520917585784
INFO:root:current train perplexity199.0994873046875
INFO:root:current mean train loss 13372.473839128521
INFO:root:current train perplexity198.17117309570312
INFO:root:current mean train loss 13382.817047991071
INFO:root:current train perplexity198.26153564453125
INFO:root:current mean train loss 13395.636936936937
INFO:root:current train perplexity198.25340270996094
INFO:root:current mean train loss 13403.232928792939
INFO:root:current train perplexity197.89308166503906
INFO:root:current mean train loss 13398.165321036839
INFO:root:current train perplexity197.34963989257812
INFO:root:current mean train loss 13389.577275219299
INFO:root:current train perplexity196.89291381835938
INFO:root:current mean train loss 13393.020327838678
INFO:root:current train perplexity196.59121704101562

100%|██████████| 1/1 [08:36<00:00, 516.27s/it][A100%|██████████| 1/1 [08:36<00:00, 516.27s/it]
INFO:root:final mean train loss: 13384.771507263184
INFO:root:final train perplexity: 196.50338745117188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.29s/it][A100%|██████████| 1/1 [00:38<00:00, 38.29s/it]
INFO:root:eval mean loss: 12877.933891566932
INFO:root:eval perplexity: 182.6293182373047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.80s/it][A100%|██████████| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 13136.615026595744
INFO:root:eval perplexity: 215.23753356933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/158
 79%|███████▉  | 158/200 [26:07:02<6:56:06, 594.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13332.587131076389
INFO:root:current train perplexity194.53085327148438
INFO:root:current mean train loss 13329.17852521089
INFO:root:current train perplexity194.42764282226562
INFO:root:current mean train loss 13316.993048954373
INFO:root:current train perplexity194.23443603515625
INFO:root:current mean train loss 13335.474571711433
INFO:root:current train perplexity194.07797241210938
INFO:root:current mean train loss 13354.205362867846
INFO:root:current train perplexity194.25564575195312
INFO:root:current mean train loss 13349.633683253775
INFO:root:current train perplexity194.01663208007812
INFO:root:current mean train loss 13351.969515931372
INFO:root:current train perplexity193.98776245117188
INFO:root:current mean train loss 13360.643225753603
INFO:root:current train perplexity194.03550720214844
INFO:root:current mean train loss 13363.799914451767
INFO:root:current train perplexity194.07241821289062
INFO:root:current mean train loss 13370.223736249027
INFO:root:current train perplexity194.27871704101562

100%|██████████| 1/1 [08:38<00:00, 518.73s/it][A100%|██████████| 1/1 [08:38<00:00, 518.73s/it]
INFO:root:final mean train loss: 13355.470738318658
INFO:root:final train perplexity: 194.24481201171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.05s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 12931.995602005762
INFO:root:eval perplexity: 186.66574096679688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 13188.321018949468
INFO:root:eval perplexity: 219.8367462158203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/159
 80%|███████▉  | 159/200 [26:16:57<6:46:27, 594.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13333.196316571302
INFO:root:current train perplexity195.0178985595703
INFO:root:current mean train loss 13361.853498492324
INFO:root:current train perplexity194.90838623046875
INFO:root:current mean train loss 13379.983124567574
INFO:root:current train perplexity194.8647003173828
INFO:root:current mean train loss 13380.114115671327
INFO:root:current train perplexity194.6997528076172
INFO:root:current mean train loss 13359.07754237991
INFO:root:current train perplexity194.3419952392578
INFO:root:current mean train loss 13357.446525079356
INFO:root:current train perplexity193.8583984375
INFO:root:current mean train loss 13357.989823956781
INFO:root:current train perplexity193.07066345214844
INFO:root:current mean train loss 13344.015871990516
INFO:root:current train perplexity192.21188354492188
INFO:root:current mean train loss 13326.357900626077
INFO:root:current train perplexity191.35226440429688
INFO:root:current mean train loss 13315.923812033341
INFO:root:current train perplexity190.61697387695312

100%|██████████| 1/1 [08:41<00:00, 521.83s/it][A100%|██████████| 1/1 [08:41<00:00, 521.86s/it]
INFO:root:final mean train loss: 13306.357070676742
INFO:root:final train perplexity: 190.51730346679688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.59s/it][A100%|██████████| 1/1 [00:38<00:00, 38.59s/it]
INFO:root:eval mean loss: 12815.181155806738
INFO:root:eval perplexity: 178.05325317382812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.47s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 13068.771650598404
INFO:root:eval perplexity: 209.34849548339844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/160
 80%|████████  | 160/200 [26:26:57<6:37:27, 596.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13313.421059137658
INFO:root:current train perplexity185.47479248046875
INFO:root:current mean train loss 13240.714941951815
INFO:root:current train perplexity184.16432189941406
INFO:root:current mean train loss 13211.133393537186
INFO:root:current train perplexity183.495849609375
INFO:root:current mean train loss 13226.420944817777
INFO:root:current train perplexity183.81015014648438
INFO:root:current mean train loss 13212.16253139679
INFO:root:current train perplexity183.61846923828125
INFO:root:current mean train loss 13221.444526527417
INFO:root:current train perplexity183.93377685546875
INFO:root:current mean train loss 13237.519000540777
INFO:root:current train perplexity184.11410522460938
INFO:root:current mean train loss 13224.895804918164
INFO:root:current train perplexity183.99903869628906
INFO:root:current mean train loss 13226.42514576223
INFO:root:current train perplexity184.03843688964844
INFO:root:current mean train loss 13228.865242355081
INFO:root:current train perplexity183.98526000976562

100%|██████████| 1/1 [08:37<00:00, 517.36s/it][A100%|██████████| 1/1 [08:37<00:00, 517.36s/it]
INFO:root:final mean train loss: 13218.127009976295
INFO:root:final train perplexity: 183.99957275390625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 12811.721555019947
INFO:root:eval perplexity: 177.8043975830078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 13065.139080507535
INFO:root:eval perplexity: 209.0376739501953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/161
 80%|████████  | 161/200 [26:36:51<6:27:05, 595.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13281.448736081178
INFO:root:current train perplexity184.09715270996094
INFO:root:current mean train loss 13214.617265833891
INFO:root:current train perplexity183.51869201660156
INFO:root:current mean train loss 13233.946952580574
INFO:root:current train perplexity184.13340759277344
INFO:root:current mean train loss 13240.117197593669
INFO:root:current train perplexity184.32676696777344
INFO:root:current mean train loss 13229.396175564681
INFO:root:current train perplexity183.91868591308594
INFO:root:current mean train loss 13237.927286853173
INFO:root:current train perplexity184.0615234375
INFO:root:current mean train loss 13226.800792621907
INFO:root:current train perplexity183.94332885742188
INFO:root:current mean train loss 13232.500519923364
INFO:root:current train perplexity183.93429565429688
INFO:root:current mean train loss 13219.949905756765
INFO:root:current train perplexity183.82679748535156
INFO:root:current mean train loss 13224.510033759181
INFO:root:current train perplexity183.75941467285156

100%|██████████| 1/1 [08:37<00:00, 517.75s/it][A100%|██████████| 1/1 [08:37<00:00, 517.75s/it]
INFO:root:final mean train loss: 13214.925516928395
INFO:root:final train perplexity: 183.7672882080078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 12811.058344414894
INFO:root:eval perplexity: 177.7567596435547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 13064.731694647606
INFO:root:eval perplexity: 209.00299072265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/162
 81%|████████  | 162/200 [26:46:45<6:16:58, 595.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13310.956280838816
INFO:root:current train perplexity185.44207763671875
INFO:root:current mean train loss 13290.945057091347
INFO:root:current train perplexity184.64442443847656
INFO:root:current mean train loss 13253.668617584746
INFO:root:current train perplexity184.0235137939453
INFO:root:current mean train loss 13241.995579509494
INFO:root:current train perplexity183.9029083251953
INFO:root:current mean train loss 13244.132767124369
INFO:root:current train perplexity184.0441436767578
INFO:root:current mean train loss 13248.981484703256
INFO:root:current train perplexity183.98509216308594
INFO:root:current mean train loss 13240.176340490108
INFO:root:current train perplexity183.90782165527344
INFO:root:current mean train loss 13232.043987077437
INFO:root:current train perplexity183.83924865722656
INFO:root:current mean train loss 13228.495021167946
INFO:root:current train perplexity183.76283264160156

100%|██████████| 1/1 [08:37<00:00, 517.67s/it][A100%|██████████| 1/1 [08:37<00:00, 517.67s/it]
INFO:root:final mean train loss: 13214.236661357265
INFO:root:final train perplexity: 183.7173614501953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 12811.68379460328
INFO:root:eval perplexity: 177.80169677734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.82s/it][A100%|██████████| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 13065.23591256649
INFO:root:eval perplexity: 209.04605102539062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/163
 82%|████████▏ | 163/200 [26:56:39<6:06:51, 594.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13068.620442708334
INFO:root:current train perplexity176.79800415039062
INFO:root:current mean train loss 13182.45941102852
INFO:root:current train perplexity183.57041931152344
INFO:root:current mean train loss 13220.298703048029
INFO:root:current train perplexity183.86204528808594
INFO:root:current mean train loss 13255.34650242368
INFO:root:current train perplexity184.20042419433594
INFO:root:current mean train loss 13245.606326574132
INFO:root:current train perplexity184.23019409179688
INFO:root:current mean train loss 13240.778104808649
INFO:root:current train perplexity183.83056640625
INFO:root:current mean train loss 13227.208375440507
INFO:root:current train perplexity183.61181640625
INFO:root:current mean train loss 13228.461705692123
INFO:root:current train perplexity183.65087890625
INFO:root:current mean train loss 13222.637273311022
INFO:root:current train perplexity183.6584014892578
INFO:root:current mean train loss 13226.33886502457
INFO:root:current train perplexity183.69764709472656

100%|██████████| 1/1 [08:36<00:00, 516.78s/it][A100%|██████████| 1/1 [08:36<00:00, 516.78s/it]
INFO:root:final mean train loss: 13214.512317780525
INFO:root:final train perplexity: 183.73733520507812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12811.115726119238
INFO:root:eval perplexity: 177.76083374023438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.37s/it][A100%|██████████| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 13064.729928523937
INFO:root:eval perplexity: 209.00279235839844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/164
 82%|████████▏ | 164/200 [27:06:33<5:56:41, 594.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13394.86434659091
INFO:root:current train perplexity187.06190490722656
INFO:root:current mean train loss 13225.628079251126
INFO:root:current train perplexity184.21060180664062
INFO:root:current mean train loss 13252.776131146327
INFO:root:current train perplexity183.87081909179688
INFO:root:current mean train loss 13211.601364675442
INFO:root:current train perplexity183.3795166015625
INFO:root:current mean train loss 13217.353301779198
INFO:root:current train perplexity183.43951416015625
INFO:root:current mean train loss 13208.719566031677
INFO:root:current train perplexity183.3553009033203
INFO:root:current mean train loss 13214.9341627455
INFO:root:current train perplexity183.56297302246094
INFO:root:current mean train loss 13205.228040392054
INFO:root:current train perplexity183.56674194335938
INFO:root:current mean train loss 13212.934974905595
INFO:root:current train perplexity183.64825439453125
INFO:root:current mean train loss 13219.88656545863
INFO:root:current train perplexity183.66603088378906

100%|██████████| 1/1 [08:36<00:00, 516.76s/it][A100%|██████████| 1/1 [08:36<00:00, 516.76s/it]
INFO:root:final mean train loss: 13213.309350290607
INFO:root:final train perplexity: 183.65017700195312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 12811.750270113032
INFO:root:eval perplexity: 177.8064422607422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.18s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 13065.084178302304
INFO:root:eval perplexity: 209.03309631347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/165
 82%|████████▎ | 165/200 [27:16:26<5:46:33, 594.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12962.889597039473
INFO:root:current train perplexity182.01873779296875
INFO:root:current mean train loss 13172.288668592437
INFO:root:current train perplexity184.3626251220703
INFO:root:current mean train loss 13237.801806863585
INFO:root:current train perplexity184.25119018554688
INFO:root:current mean train loss 13211.803316026646
INFO:root:current train perplexity183.61952209472656
INFO:root:current mean train loss 13224.44548264096
INFO:root:current train perplexity183.78192138671875
INFO:root:current mean train loss 13226.426061611874
INFO:root:current train perplexity183.7278594970703
INFO:root:current mean train loss 13233.147184849555
INFO:root:current train perplexity183.82347106933594
INFO:root:current mean train loss 13215.3727602899
INFO:root:current train perplexity183.5977325439453
INFO:root:current mean train loss 13216.438644688646
INFO:root:current train perplexity183.7511749267578
INFO:root:current mean train loss 13217.252711847117
INFO:root:current train perplexity183.6693572998047

100%|██████████| 1/1 [08:37<00:00, 517.74s/it][A100%|██████████| 1/1 [08:37<00:00, 517.74s/it]
INFO:root:final mean train loss: 13213.691557607342
INFO:root:final train perplexity: 183.6778564453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 12812.458721187943
INFO:root:eval perplexity: 177.85748291015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.88s/it][A100%|██████████| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 13065.85628601507
INFO:root:eval perplexity: 209.09909057617188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/166
 83%|████████▎ | 166/200 [27:26:20<5:36:39, 594.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13213.126193576389
INFO:root:current train perplexity185.11448669433594
INFO:root:current mean train loss 13303.076502522146
INFO:root:current train perplexity184.9706573486328
INFO:root:current mean train loss 13266.26496678827
INFO:root:current train perplexity184.4324493408203
INFO:root:current mean train loss 13234.634353497706
INFO:root:current train perplexity183.68853759765625
INFO:root:current mean train loss 13242.245885630124
INFO:root:current train perplexity183.995361328125
INFO:root:current mean train loss 13229.395739444972
INFO:root:current train perplexity183.795166015625
INFO:root:current mean train loss 13233.96128015351
INFO:root:current train perplexity183.6285400390625
INFO:root:current mean train loss 13232.076236352304
INFO:root:current train perplexity183.7467041015625
INFO:root:current mean train loss 13238.672145414524
INFO:root:current train perplexity183.86160278320312
INFO:root:current mean train loss 13223.612988386596
INFO:root:current train perplexity183.66830444335938

100%|██████████| 1/1 [08:38<00:00, 518.02s/it][A100%|██████████| 1/1 [08:38<00:00, 518.02s/it]
INFO:root:final mean train loss: 13213.025077819824
INFO:root:final train perplexity: 183.62950134277344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.51s/it][A100%|██████████| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 12810.629862034575
INFO:root:eval perplexity: 177.7259063720703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 13063.996377714982
INFO:root:eval perplexity: 208.94021606445312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/167
 84%|████████▎ | 167/200 [27:36:16<5:27:03, 594.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13371.911216517858
INFO:root:current train perplexity187.31753540039062
INFO:root:current mean train loss 13315.860149016204
INFO:root:current train perplexity185.14370727539062
INFO:root:current mean train loss 13271.872942985372
INFO:root:current train perplexity184.40940856933594
INFO:root:current mean train loss 13265.12650128265
INFO:root:current train perplexity183.95806884765625
INFO:root:current mean train loss 13261.996012931035
INFO:root:current train perplexity183.91201782226562
INFO:root:current mean train loss 13239.322331337617
INFO:root:current train perplexity183.6975555419922
INFO:root:current mean train loss 13220.921126045767
INFO:root:current train perplexity183.49549865722656
INFO:root:current mean train loss 13221.8936370642
INFO:root:current train perplexity183.57505798339844
INFO:root:current mean train loss 13219.131920144087
INFO:root:current train perplexity183.69659423828125
INFO:root:current mean train loss 13225.720271766377
INFO:root:current train perplexity183.6699676513672

100%|██████████| 1/1 [08:37<00:00, 517.82s/it][A100%|██████████| 1/1 [08:37<00:00, 517.82s/it]
INFO:root:final mean train loss: 13213.844573236282
INFO:root:final train perplexity: 183.68898010253906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.07s/it][A100%|██████████| 1/1 [00:39<00:00, 39.08s/it]
INFO:root:eval mean loss: 12811.98609956782
INFO:root:eval perplexity: 177.82339477539062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 13064.76519558954
INFO:root:eval perplexity: 209.0056915283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/168
 84%|████████▍ | 168/200 [27:46:12<5:17:19, 594.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13204.506177325582
INFO:root:current train perplexity182.6180877685547
INFO:root:current mean train loss 13289.923589106207
INFO:root:current train perplexity184.129638671875
INFO:root:current mean train loss 13248.772119341564
INFO:root:current train perplexity183.78587341308594
INFO:root:current mean train loss 13234.186307056305
INFO:root:current train perplexity183.8833465576172
INFO:root:current mean train loss 13232.396962736315
INFO:root:current train perplexity183.68695068359375
INFO:root:current mean train loss 13234.71418011913
INFO:root:current train perplexity183.63949584960938
INFO:root:current mean train loss 13250.71614228956
INFO:root:current train perplexity184.0083465576172
INFO:root:current mean train loss 13240.57170308294
INFO:root:current train perplexity184.00535583496094
INFO:root:current mean train loss 13224.126419085484
INFO:root:current train perplexity183.76194763183594
INFO:root:current mean train loss 13221.333760687301
INFO:root:current train perplexity183.74574279785156

100%|██████████| 1/1 [08:37<00:00, 517.92s/it][A100%|██████████| 1/1 [08:37<00:00, 517.92s/it]
INFO:root:final mean train loss: 13214.913833864273
INFO:root:final train perplexity: 183.76651000976562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 12813.092274767287
INFO:root:eval perplexity: 177.9030303955078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 13065.93577543218
INFO:root:eval perplexity: 209.10586547851562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/169
 84%|████████▍ | 169/200 [27:56:07<5:07:24, 594.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13265.88631663603
INFO:root:current train perplexity182.80059814453125
INFO:root:current mean train loss 13309.707341680463
INFO:root:current train perplexity184.79037475585938
INFO:root:current mean train loss 13279.382738576942
INFO:root:current train perplexity184.6483917236328
INFO:root:current mean train loss 13249.250114071403
INFO:root:current train perplexity183.96237182617188
INFO:root:current mean train loss 13236.489143050167
INFO:root:current train perplexity183.69940185546875
INFO:root:current mean train loss 13222.772558416515
INFO:root:current train perplexity183.54432678222656
INFO:root:current mean train loss 13234.944803967453
INFO:root:current train perplexity183.7775421142578
INFO:root:current mean train loss 13228.071636255825
INFO:root:current train perplexity183.7294464111328
INFO:root:current mean train loss 13221.914015450573
INFO:root:current train perplexity183.5642852783203
INFO:root:current mean train loss 13217.9395537592
INFO:root:current train perplexity183.51255798339844

100%|██████████| 1/1 [08:41<00:00, 521.03s/it][A100%|██████████| 1/1 [08:41<00:00, 521.03s/it]
INFO:root:final mean train loss: 13212.007376147854
INFO:root:final train perplexity: 183.55596923828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.30s/it][A100%|██████████| 1/1 [00:38<00:00, 38.30s/it]
INFO:root:eval mean loss: 12814.024150875443
INFO:root:eval perplexity: 177.97006225585938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 13066.765119403812
INFO:root:eval perplexity: 209.17677307128906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/170
 85%|████████▌ | 170/200 [28:06:05<4:57:55, 595.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13174.848136255298
INFO:root:current train perplexity183.2152862548828
INFO:root:current mean train loss 13239.292415978774
INFO:root:current train perplexity183.5027618408203
INFO:root:current mean train loss 13231.6156906069
INFO:root:current train perplexity183.18453979492188
INFO:root:current mean train loss 13217.741420395196
INFO:root:current train perplexity183.3435821533203
INFO:root:current mean train loss 13233.353847528595
INFO:root:current train perplexity183.80357360839844
INFO:root:current mean train loss 13229.996385495862
INFO:root:current train perplexity183.59947204589844
INFO:root:current mean train loss 13226.10492045239
INFO:root:current train perplexity183.65647888183594
INFO:root:current mean train loss 13221.847582911314
INFO:root:current train perplexity183.58372497558594
INFO:root:current mean train loss 13213.474550258294
INFO:root:current train perplexity183.3972625732422
INFO:root:current mean train loss 13216.515972244852
INFO:root:current train perplexity183.47572326660156

100%|██████████| 1/1 [08:36<00:00, 516.30s/it][A100%|██████████| 1/1 [08:36<00:00, 516.30s/it]
INFO:root:final mean train loss: 13213.249666767735
INFO:root:final train perplexity: 183.64596557617188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.98s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 12813.05444509087
INFO:root:eval perplexity: 177.9003143310547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 13066.117900875443
INFO:root:eval perplexity: 209.12142944335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/171
 86%|████████▌ | 171/200 [28:15:58<4:47:35, 595.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13362.834319612874
INFO:root:current train perplexity185.51132202148438
INFO:root:current mean train loss 13292.523531062874
INFO:root:current train perplexity185.29763793945312
INFO:root:current mean train loss 13280.174625468166
INFO:root:current train perplexity184.67471313476562
INFO:root:current mean train loss 13255.939160422344
INFO:root:current train perplexity184.26348876953125
INFO:root:current mean train loss 13232.283876472162
INFO:root:current train perplexity184.02940368652344
INFO:root:current mean train loss 13230.296070670745
INFO:root:current train perplexity183.9215850830078
INFO:root:current mean train loss 13236.662156226574
INFO:root:current train perplexity183.8775634765625
INFO:root:current mean train loss 13230.788800215938
INFO:root:current train perplexity183.66366577148438
INFO:root:current mean train loss 13229.801336550245
INFO:root:current train perplexity183.69992065429688
INFO:root:current mean train loss 13224.72365805972
INFO:root:current train perplexity183.6941375732422

100%|██████████| 1/1 [08:36<00:00, 516.86s/it][A100%|██████████| 1/1 [08:36<00:00, 516.86s/it]
INFO:root:final mean train loss: 13213.528450504426
INFO:root:final train perplexity: 183.66603088378906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12811.231099013741
INFO:root:eval perplexity: 177.76913452148438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 13064.38047152039
INFO:root:eval perplexity: 208.972900390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/172
 86%|████████▌ | 172/200 [28:25:51<4:37:28, 594.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13176.934375
INFO:root:current train perplexity183.64413452148438
INFO:root:current mean train loss 13181.041646205356
INFO:root:current train perplexity183.0581817626953
INFO:root:current mean train loss 13156.794318181817
INFO:root:current train perplexity182.71885681152344
INFO:root:current mean train loss 13178.92846875
INFO:root:current train perplexity182.5895233154297
INFO:root:current mean train loss 13206.147787828948
INFO:root:current train perplexity182.92022705078125
INFO:root:current mean train loss 13209.481722146738
INFO:root:current train perplexity183.2094268798828
INFO:root:current mean train loss 13217.947058738426
INFO:root:current train perplexity183.21607971191406
INFO:root:current mean train loss 13227.721350806452
INFO:root:current train perplexity183.41458129882812
INFO:root:current mean train loss 13223.901024553572
INFO:root:current train perplexity183.60122680664062
INFO:root:current mean train loss 13223.160216346154
INFO:root:current train perplexity183.63275146484375

100%|██████████| 1/1 [08:38<00:00, 518.60s/it][A100%|██████████| 1/1 [08:38<00:00, 518.60s/it]
INFO:root:final mean train loss: 13212.742743215253
INFO:root:final train perplexity: 183.60911560058594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 38.00s/it][A100%|██████████| 1/1 [00:37<00:00, 38.00s/it]
INFO:root:eval mean loss: 12810.966713763299
INFO:root:eval perplexity: 177.75015258789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 13063.991924312943
INFO:root:eval perplexity: 208.9398193359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/173
 86%|████████▋ | 173/200 [28:35:48<4:27:45, 595.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13220.347597420934
INFO:root:current train perplexity183.2165985107422
INFO:root:current mean train loss 13245.30046640198
INFO:root:current train perplexity183.67556762695312
INFO:root:current mean train loss 13230.565736804328
INFO:root:current train perplexity183.33990478515625
INFO:root:current mean train loss 13234.6754497797
INFO:root:current train perplexity183.29393005371094
INFO:root:current mean train loss 13227.040077478003
INFO:root:current train perplexity183.4893798828125
INFO:root:current mean train loss 13217.126170869962
INFO:root:current train perplexity183.6277618408203
INFO:root:current mean train loss 13203.93395978221
INFO:root:current train perplexity183.29603576660156
INFO:root:current mean train loss 13209.055479475974
INFO:root:current train perplexity183.46514892578125
INFO:root:current mean train loss 13215.398946241507
INFO:root:current train perplexity183.57583618164062
INFO:root:current mean train loss 13219.43665059925
INFO:root:current train perplexity183.52560424804688

100%|██████████| 1/1 [08:40<00:00, 520.66s/it][A100%|██████████| 1/1 [08:40<00:00, 520.66s/it]
INFO:root:final mean train loss: 13212.365957690823
INFO:root:final train perplexity: 183.58187866210938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.61s/it][A100%|██████████| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 12811.33147024601
INFO:root:eval perplexity: 177.77633666992188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.09s/it][A100%|██████████| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 13064.393277648493
INFO:root:eval perplexity: 208.9739990234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/174
 87%|████████▋ | 174/200 [28:45:44<4:18:04, 595.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13163.906539749312
INFO:root:current train perplexity182.51943969726562
INFO:root:current mean train loss 13241.272578534032
INFO:root:current train perplexity183.07373046875
INFO:root:current mean train loss 13193.313127550473
INFO:root:current train perplexity182.63140869140625
INFO:root:current mean train loss 13212.200210298113
INFO:root:current train perplexity183.26063537597656
INFO:root:current mean train loss 13217.232803748728
INFO:root:current train perplexity183.4393310546875
INFO:root:current mean train loss 13215.813559182001
INFO:root:current train perplexity183.3266143798828
INFO:root:current mean train loss 13219.720608436595
INFO:root:current train perplexity183.330810546875
INFO:root:current mean train loss 13226.214169662611
INFO:root:current train perplexity183.4998779296875
INFO:root:current mean train loss 13222.43375925049
INFO:root:current train perplexity183.49610900878906
INFO:root:current mean train loss 13223.030617353052
INFO:root:current train perplexity183.6061248779297

100%|██████████| 1/1 [08:36<00:00, 516.66s/it][A100%|██████████| 1/1 [08:36<00:00, 516.66s/it]
INFO:root:final mean train loss: 13212.706999501874
INFO:root:final train perplexity: 183.6065673828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12811.587066433955
INFO:root:eval perplexity: 177.79473876953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.33s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 13064.817161181294
INFO:root:eval perplexity: 209.01026916503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/175
 88%|████████▊ | 175/200 [28:55:38<4:07:53, 594.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13252.544359611742
INFO:root:current train perplexity184.53289794921875
INFO:root:current mean train loss 13168.773054726758
INFO:root:current train perplexity183.1898651123047
INFO:root:current mean train loss 13195.679439276755
INFO:root:current train perplexity183.50442504882812
INFO:root:current mean train loss 13210.906644051534
INFO:root:current train perplexity183.42849731445312
INFO:root:current mean train loss 13209.48664320829
INFO:root:current train perplexity183.419921875
INFO:root:current mean train loss 13223.806039036415
INFO:root:current train perplexity183.65673828125
INFO:root:current mean train loss 13218.39475198945
INFO:root:current train perplexity183.58485412597656
INFO:root:current mean train loss 13221.026737523467
INFO:root:current train perplexity183.53671264648438
INFO:root:current mean train loss 13217.670596452655
INFO:root:current train perplexity183.49908447265625

100%|██████████| 1/1 [08:38<00:00, 518.42s/it][A100%|██████████| 1/1 [08:38<00:00, 518.42s/it]
INFO:root:final mean train loss: 13213.334100538685
INFO:root:final train perplexity: 183.65200805664062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12812.355544935726
INFO:root:eval perplexity: 177.84994506835938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.49s/it][A100%|██████████| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 13065.515777371455
INFO:root:eval perplexity: 209.0698699951172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/176
 88%|████████▊ | 176/200 [29:05:33<3:58:00, 595.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13233.81556919643
INFO:root:current train perplexity181.04769897460938
INFO:root:current mean train loss 13203.52175817757
INFO:root:current train perplexity183.9459686279297
INFO:root:current mean train loss 13223.433088956825
INFO:root:current train perplexity183.81680297851562
INFO:root:current mean train loss 13224.636321126833
INFO:root:current train perplexity183.48587036132812
INFO:root:current mean train loss 13215.811473049755
INFO:root:current train perplexity183.66348266601562
INFO:root:current mean train loss 13223.001317492604
INFO:root:current train perplexity183.68923950195312
INFO:root:current mean train loss 13223.041673638283
INFO:root:current train perplexity183.6053466796875
INFO:root:current mean train loss 13217.292039150901
INFO:root:current train perplexity183.45578002929688
INFO:root:current mean train loss 13221.633055733038
INFO:root:current train perplexity183.58651733398438
INFO:root:current mean train loss 13219.19364577591
INFO:root:current train perplexity183.64019775390625

100%|██████████| 1/1 [08:36<00:00, 516.14s/it][A100%|██████████| 1/1 [08:36<00:00, 516.16s/it]
INFO:root:final mean train loss: 13214.391151920441
INFO:root:final train perplexity: 183.72865295410156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12813.145293107269
INFO:root:eval perplexity: 177.90676879882812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.16s/it][A100%|██████████| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 13066.372347351507
INFO:root:eval perplexity: 209.14315795898438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/177
 88%|████████▊ | 177/200 [29:15:26<3:47:49, 594.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13190.619921875
INFO:root:current train perplexity180.89779663085938
INFO:root:current mean train loss 13200.85093410326
INFO:root:current train perplexity182.9028778076172
INFO:root:current mean train loss 13210.269926417152
INFO:root:current train perplexity183.9992218017578
INFO:root:current mean train loss 13211.06960875496
INFO:root:current train perplexity184.18276977539062
INFO:root:current mean train loss 13216.946185523344
INFO:root:current train perplexity183.75485229492188
INFO:root:current mean train loss 13217.320521086165
INFO:root:current train perplexity183.49664306640625
INFO:root:current mean train loss 13208.991973132623
INFO:root:current train perplexity183.30276489257812
INFO:root:current mean train loss 13215.067520760489
INFO:root:current train perplexity183.49139404296875
INFO:root:current mean train loss 13209.911580952838
INFO:root:current train perplexity183.4076690673828
INFO:root:current mean train loss 13218.497199453552
INFO:root:current train perplexity183.52857971191406

100%|██████████| 1/1 [08:38<00:00, 518.25s/it][A100%|██████████| 1/1 [08:38<00:00, 518.25s/it]
INFO:root:final mean train loss: 13213.508671422158
INFO:root:final train perplexity: 183.6646270751953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 12815.227885361259
INFO:root:eval perplexity: 178.056640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.30s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 13068.181910738032
INFO:root:eval perplexity: 209.29800415039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/178
 89%|████████▉ | 178/200 [29:25:21<3:37:58, 594.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13045.716881793478
INFO:root:current train perplexity181.3085174560547
INFO:root:current mean train loss 13234.661394817073
INFO:root:current train perplexity184.0801239013672
INFO:root:current mean train loss 13204.89881849075
INFO:root:current train perplexity183.8594207763672
INFO:root:current mean train loss 13212.09236225329
INFO:root:current train perplexity183.812255859375
INFO:root:current mean train loss 13199.030615118942
INFO:root:current train perplexity183.83285522460938
INFO:root:current mean train loss 13217.112670665034
INFO:root:current train perplexity184.02035522460938
INFO:root:current mean train loss 13211.52588282504
INFO:root:current train perplexity183.91912841796875
INFO:root:current mean train loss 13225.187367630533
INFO:root:current train perplexity184.12269592285156
INFO:root:current mean train loss 13227.181300074044
INFO:root:current train perplexity183.92877197265625
INFO:root:current mean train loss 13219.286033357597
INFO:root:current train perplexity183.86431884765625

100%|██████████| 1/1 [08:35<00:00, 515.88s/it][A100%|██████████| 1/1 [08:35<00:00, 515.88s/it]
INFO:root:final mean train loss: 13215.696340253277
INFO:root:final train perplexity: 183.82330322265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.25s/it][A100%|██████████| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 12819.006718195922
INFO:root:eval perplexity: 178.32896423339844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.43s/it][A100%|██████████| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 13071.72893118351
INFO:root:eval perplexity: 209.601806640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/179
 90%|████████▉ | 179/200 [29:35:14<3:27:54, 594.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13230.919575352822
INFO:root:current train perplexity184.02114868164062
INFO:root:current mean train loss 13259.750715648855
INFO:root:current train perplexity183.9769287109375
INFO:root:current mean train loss 13221.918471827652
INFO:root:current train perplexity184.03448486328125
INFO:root:current mean train loss 13223.370754460913
INFO:root:current train perplexity184.02133178710938
INFO:root:current mean train loss 13206.253126812646
INFO:root:current train perplexity183.98167419433594
INFO:root:current mean train loss 13214.386882429966
INFO:root:current train perplexity183.87423706054688
INFO:root:current mean train loss 13215.929049871236
INFO:root:current train perplexity183.95140075683594
INFO:root:current mean train loss 13228.03391116621
INFO:root:current train perplexity184.0441436767578
INFO:root:current mean train loss 13227.421296818593
INFO:root:current train perplexity184.10093688964844
INFO:root:current mean train loss 13228.340617867212
INFO:root:current train perplexity184.0701141357422

100%|██████████| 1/1 [08:37<00:00, 517.51s/it][A100%|██████████| 1/1 [08:37<00:00, 517.51s/it]
INFO:root:final mean train loss: 13219.736216637397
INFO:root:final train perplexity: 184.1163787841797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.74s/it][A100%|██████████| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 12824.732186391844
INFO:root:eval perplexity: 178.74229431152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 13077.025466810726
INFO:root:eval perplexity: 210.05615234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/180
 90%|█████████ | 180/200 [29:45:07<3:17:59, 593.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13383.661708733975
INFO:root:current train perplexity185.5425567626953
INFO:root:current mean train loss 13304.576755002248
INFO:root:current train perplexity185.49380493164062
INFO:root:current mean train loss 13263.528365258891
INFO:root:current train perplexity184.70474243164062
INFO:root:current mean train loss 13267.30523771663
INFO:root:current train perplexity184.80914306640625
INFO:root:current mean train loss 13257.500705171555
INFO:root:current train perplexity184.8984375
INFO:root:current mean train loss 13228.32350127551
INFO:root:current train perplexity184.4375457763672
INFO:root:current mean train loss 13227.176245843115
INFO:root:current train perplexity184.54830932617188
INFO:root:current mean train loss 13232.386622283067
INFO:root:current train perplexity184.6421356201172
INFO:root:current mean train loss 13241.738913280318
INFO:root:current train perplexity185.05844116210938
INFO:root:current mean train loss 13248.315037606497
INFO:root:current train perplexity185.55706787109375

100%|██████████| 1/1 [08:34<00:00, 514.02s/it][A100%|██████████| 1/1 [08:34<00:00, 514.02s/it]
INFO:root:final mean train loss: 13243.82026820029
INFO:root:final train perplexity: 185.874267578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.97s/it][A100%|██████████| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 12953.684230939716
INFO:root:eval perplexity: 188.30999755859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 13197.934604942377
INFO:root:eval perplexity: 220.70285034179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/181
 90%|█████████ | 181/200 [29:54:58<3:07:46, 592.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13285.91489361702
INFO:root:current train perplexity192.35748291015625
INFO:root:current mean train loss 13363.158017113095
INFO:root:current train perplexity195.14468383789062
INFO:root:current mean train loss 13392.013786532136
INFO:root:current train perplexity197.18389892578125
INFO:root:current mean train loss 13420.784947991715
INFO:root:current train perplexity198.9796142578125
INFO:root:current mean train loss 13444.507071885486
INFO:root:current train perplexity201.63832092285156
INFO:root:current mean train loss 13499.394715136541
INFO:root:current train perplexity206.3438720703125
INFO:root:current mean train loss 13610.796782928419
INFO:root:current train perplexity214.6346893310547
INFO:root:current mean train loss 13739.501852461932
INFO:root:current train perplexity225.45925903320312
INFO:root:current mean train loss 13788.8818393964
INFO:root:current train perplexity229.56907653808594
INFO:root:current mean train loss 13738.958025343189
INFO:root:current train perplexity224.63157653808594

100%|██████████| 1/1 [08:37<00:00, 517.42s/it][A100%|██████████| 1/1 [08:37<00:00, 517.42s/it]
INFO:root:final mean train loss: 13698.301618268413
INFO:root:final train perplexity: 222.37753295898438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.78s/it][A100%|██████████| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 12909.178586269947
INFO:root:eval perplexity: 184.95143127441406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 13127.612242353724
INFO:root:eval perplexity: 214.44667053222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/182
 91%|█████████ | 182/200 [30:04:52<2:57:58, 593.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13238.827716619318
INFO:root:current train perplexity181.53543090820312
INFO:root:current mean train loss 13221.328238407257
INFO:root:current train perplexity180.39096069335938
INFO:root:current mean train loss 13162.933256740196
INFO:root:current train perplexity178.72132873535156
INFO:root:current mean train loss 13135.114392605634
INFO:root:current train perplexity177.43089294433594
INFO:root:current mean train loss 13126.388787774726
INFO:root:current train perplexity176.90737915039062
INFO:root:current mean train loss 13111.075837556305
INFO:root:current train perplexity176.51150512695312
INFO:root:current mean train loss 13106.594577468988
INFO:root:current train perplexity176.06314086914062
INFO:root:current mean train loss 13111.14946192053
INFO:root:current train perplexity175.63507080078125
INFO:root:current mean train loss 13108.413416027046
INFO:root:current train perplexity175.49325561523438
INFO:root:current mean train loss 13107.837767915576
INFO:root:current train perplexity175.3622589111328

100%|██████████| 1/1 [08:37<00:00, 517.95s/it][A100%|██████████| 1/1 [08:37<00:00, 517.95s/it]
INFO:root:final mean train loss: 13094.138983695737
INFO:root:final train perplexity: 175.215576171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 12811.15843168218
INFO:root:eval perplexity: 177.76388549804688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 13044.310103612588
INFO:root:eval perplexity: 207.2648162841797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/183
 92%|█████████▏| 183/200 [30:14:47<2:48:12, 593.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13135.934849330357
INFO:root:current train perplexity172.65283203125
INFO:root:current mean train loss 13056.135646328605
INFO:root:current train perplexity172.29835510253906
INFO:root:current mean train loss 13032.649803944867
INFO:root:current train perplexity172.25531005859375
INFO:root:current mean train loss 13049.455053912707
INFO:root:current train perplexity172.38662719726562
INFO:root:current mean train loss 13056.672571038067
INFO:root:current train perplexity172.6396484375
INFO:root:current mean train loss 13051.750412827487
INFO:root:current train perplexity172.54879760742188
INFO:root:current mean train loss 13070.46693091299
INFO:root:current train perplexity172.62681579589844
INFO:root:current mean train loss 13073.140418936353
INFO:root:current train perplexity172.5560302734375
INFO:root:current mean train loss 13069.33262759813
INFO:root:current train perplexity172.45321655273438
INFO:root:current mean train loss 13060.145038291796
INFO:root:current train perplexity172.3392791748047

100%|██████████| 1/1 [08:33<00:00, 513.08s/it][A100%|██████████| 1/1 [08:33<00:00, 513.08s/it]
INFO:root:final mean train loss: 13052.33595251268
INFO:root:final train perplexity: 172.34954833984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.75s/it][A100%|██████████| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 12792.9043245789
INFO:root:eval perplexity: 176.45655822753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.11s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 13024.518042165337
INFO:root:eval perplexity: 205.5943145751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/184
 92%|█████████▏| 184/200 [30:24:36<2:37:58, 592.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12996.544289172536
INFO:root:current train perplexity170.02011108398438
INFO:root:current mean train loss 13061.411800986842
INFO:root:current train perplexity170.98336791992188
INFO:root:current mean train loss 13044.763765567342
INFO:root:current train perplexity171.62196350097656
INFO:root:current mean train loss 13074.11567659198
INFO:root:current train perplexity172.3429718017578
INFO:root:current mean train loss 13081.821228934448
INFO:root:current train perplexity173.33509826660156
INFO:root:current mean train loss 13089.727566426773
INFO:root:current train perplexity174.46141052246094
INFO:root:current mean train loss 13111.471921281203
INFO:root:current train perplexity175.96560668945312
INFO:root:current mean train loss 13141.230698007863
INFO:root:current train perplexity177.7168426513672
INFO:root:current mean train loss 13161.914116317452
INFO:root:current train perplexity179.33262634277344
INFO:root:current mean train loss 13190.006727318809
INFO:root:current train perplexity181.08187866210938

100%|██████████| 1/1 [08:34<00:00, 514.99s/it][A100%|██████████| 1/1 [08:34<00:00, 514.99s/it]
INFO:root:final mean train loss: 13180.797409057617
INFO:root:final train perplexity: 181.30955505371094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 13037.262487533244
INFO:root:eval perplexity: 194.78305053710938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.13s/it][A100%|██████████| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 13249.04726285461
INFO:root:eval perplexity: 225.36424255371094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/185
 92%|█████████▎| 185/200 [30:34:27<2:28:01, 592.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13383.805169600475
INFO:root:current train perplexity194.59022521972656
INFO:root:current mean train loss 13383.369658912361
INFO:root:current train perplexity195.11732482910156
INFO:root:current mean train loss 13344.232183859767
INFO:root:current train perplexity194.64144897460938
INFO:root:current mean train loss 13363.11724934037
INFO:root:current train perplexity194.89183044433594
INFO:root:current mean train loss 13376.6851554345
INFO:root:current train perplexity195.16506958007812
INFO:root:current mean train loss 13395.879936784866
INFO:root:current train perplexity195.37745666503906
INFO:root:current mean train loss 13390.666248619293
INFO:root:current train perplexity195.18479919433594
INFO:root:current mean train loss 13385.612008835446
INFO:root:current train perplexity195.19540405273438
INFO:root:current mean train loss 13377.869976091439
INFO:root:current train perplexity195.12831115722656
INFO:root:current mean train loss 13374.947400288878
INFO:root:current train perplexity195.1833953857422

100%|██████████| 1/1 [08:37<00:00, 517.16s/it][A100%|██████████| 1/1 [08:37<00:00, 517.16s/it]
INFO:root:final mean train loss: 13368.504529399257
INFO:root:final train perplexity: 195.24623107910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 13043.362934951241
INFO:root:eval perplexity: 195.2642059326172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.50s/it][A100%|██████████| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 13255.017647384751
INFO:root:eval perplexity: 225.91500854492188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/186
 93%|█████████▎| 186/200 [30:44:21<2:18:17, 592.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13477.449488146553
INFO:root:current train perplexity195.7763214111328
INFO:root:current mean train loss 13440.21924089238
INFO:root:current train perplexity196.27565002441406
INFO:root:current mean train loss 13417.864404126742
INFO:root:current train perplexity195.9273223876953
INFO:root:current mean train loss 13377.234291727229
INFO:root:current train perplexity195.1794891357422
INFO:root:current mean train loss 13365.893859487294
INFO:root:current train perplexity194.7826690673828
INFO:root:current mean train loss 13366.485183533858
INFO:root:current train perplexity194.82298278808594
INFO:root:current mean train loss 13375.183272493632
INFO:root:current train perplexity194.9707489013672
INFO:root:current mean train loss 13385.29303575683
INFO:root:current train perplexity195.10606384277344
INFO:root:current mean train loss 13376.727122894941
INFO:root:current train perplexity195.19261169433594
INFO:root:current mean train loss 13379.625514501013
INFO:root:current train perplexity195.3100128173828

100%|██████████| 1/1 [08:37<00:00, 517.28s/it][A100%|██████████| 1/1 [08:37<00:00, 517.28s/it]
INFO:root:final mean train loss: 13369.292146498157
INFO:root:final train perplexity: 195.30703735351562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.02s/it][A100%|██████████| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 13043.47503878546
INFO:root:eval perplexity: 195.27304077148438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.30s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 13254.98243572695
INFO:root:eval perplexity: 225.91177368164062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/187
 94%|█████████▎| 187/200 [30:54:15<2:08:29, 593.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13340.267639802632
INFO:root:current train perplexity195.89443969726562
INFO:root:current mean train loss 13383.19016426282
INFO:root:current train perplexity196.1781463623047
INFO:root:current mean train loss 13378.21675052966
INFO:root:current train perplexity195.982177734375
INFO:root:current mean train loss 13378.384810126583
INFO:root:current train perplexity195.66311645507812
INFO:root:current mean train loss 13371.958076862375
INFO:root:current train perplexity195.4269256591797
INFO:root:current mean train loss 13374.550832129727
INFO:root:current train perplexity195.55296325683594
INFO:root:current mean train loss 13393.620880170864
INFO:root:current train perplexity195.60733032226562
INFO:root:current mean train loss 13395.582088983883
INFO:root:current train perplexity195.61329650878906
INFO:root:current mean train loss 13391.131446403631
INFO:root:current train perplexity195.4529266357422

100%|██████████| 1/1 [08:36<00:00, 516.36s/it][A100%|██████████| 1/1 [08:36<00:00, 516.36s/it]
INFO:root:final mean train loss: 13369.441478606193
INFO:root:final train perplexity: 195.3184814453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 13048.37344858156
INFO:root:eval perplexity: 195.66012573242188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.17s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 13259.183489860372
INFO:root:eval perplexity: 226.3001251220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/188
 94%|█████████▍| 188/200 [31:04:08<1:58:36, 593.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13729.260416666666
INFO:root:current train perplexity200.7855682373047
INFO:root:current mean train loss 13448.463364684467
INFO:root:current train perplexity197.8394012451172
INFO:root:current mean train loss 13455.932342980295
INFO:root:current train perplexity197.3368377685547
INFO:root:current mean train loss 13433.932275551773
INFO:root:current train perplexity197.25291442871094
INFO:root:current mean train loss 13423.708691163927
INFO:root:current train perplexity197.44630432128906
INFO:root:current mean train loss 13435.522400751739
INFO:root:current train perplexity197.97056579589844
INFO:root:current mean train loss 13425.900144459993
INFO:root:current train perplexity198.19970703125
INFO:root:current mean train loss 13416.206233886025
INFO:root:current train perplexity198.2815704345703
INFO:root:current mean train loss 13412.960438881539
INFO:root:current train perplexity198.27041625976562
INFO:root:current mean train loss 13417.688705832987
INFO:root:current train perplexity198.35845947265625

100%|██████████| 1/1 [08:37<00:00, 517.12s/it][A100%|██████████| 1/1 [08:37<00:00, 517.12s/it]
INFO:root:final mean train loss: 13409.913723114998
INFO:root:final train perplexity: 198.46224975585938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.06s/it][A100%|██████████| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 13092.129342586437
INFO:root:eval perplexity: 199.1529541015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 13298.430816433955
INFO:root:eval perplexity: 229.9613037109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/189
 94%|█████████▍| 189/200 [31:14:02<1:48:46, 593.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13375.587535511364
INFO:root:current train perplexity200.43841552734375
INFO:root:current mean train loss 13437.409109304617
INFO:root:current train perplexity200.17832946777344
INFO:root:current mean train loss 13430.4619140625
INFO:root:current train perplexity200.5323944091797
INFO:root:current mean train loss 13452.849534013263
INFO:root:current train perplexity200.52139282226562
INFO:root:current mean train loss 13441.722447156326
INFO:root:current train perplexity200.5238800048828
INFO:root:current mean train loss 13438.028213291953
INFO:root:current train perplexity200.43832397460938
INFO:root:current mean train loss 13445.769404984145
INFO:root:current train perplexity200.462890625
INFO:root:current mean train loss 13445.23605479738
INFO:root:current train perplexity200.5714111328125
INFO:root:current mean train loss 13441.961189166539
INFO:root:current train perplexity200.41519165039062
INFO:root:current mean train loss 13443.295424627813
INFO:root:current train perplexity200.42054748535156

100%|██████████| 1/1 [08:36<00:00, 516.03s/it][A100%|██████████| 1/1 [08:36<00:00, 516.03s/it]
INFO:root:final mean train loss: 13434.481047845657
INFO:root:final train perplexity: 200.39532470703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.87s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 13102.38358820922
INFO:root:eval perplexity: 199.98036193847656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 13306.230932790337
INFO:root:eval perplexity: 230.69595336914062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/190
 95%|█████████▌| 190/200 [31:23:55<1:38:51, 593.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13475.89021381579
INFO:root:current train perplexity199.91525268554688
INFO:root:current mean train loss 13442.680573792017
INFO:root:current train perplexity200.1090545654297
INFO:root:current mean train loss 13462.705015696347
INFO:root:current train perplexity201.2445068359375
INFO:root:current mean train loss 13445.232143294475
INFO:root:current train perplexity200.84906005859375
INFO:root:current mean train loss 13451.553671315633
INFO:root:current train perplexity201.03456115722656
INFO:root:current mean train loss 13447.447233637404
INFO:root:current train perplexity201.3571014404297
INFO:root:current mean train loss 13453.285806239903
INFO:root:current train perplexity201.57073974609375
INFO:root:current mean train loss 13455.697641852834
INFO:root:current train perplexity201.5740203857422
INFO:root:current mean train loss 13455.812966222145
INFO:root:current train perplexity201.75364685058594
INFO:root:current mean train loss 13454.64458225653
INFO:root:current train perplexity201.63121032714844

100%|██████████| 1/1 [08:38<00:00, 518.72s/it][A100%|██████████| 1/1 [08:38<00:00, 518.72s/it]
INFO:root:final mean train loss: 13451.611501386089
INFO:root:final train perplexity: 201.75411987304688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 13035.29081477172
INFO:root:eval perplexity: 194.6278076171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.06s/it][A100%|██████████| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 13248.761386303191
INFO:root:eval perplexity: 225.33779907226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/191
 96%|█████████▌| 191/200 [31:33:50<1:29:03, 593.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13495.762080439816
INFO:root:current train perplexity201.7333526611328
INFO:root:current mean train loss 13419.851916215552
INFO:root:current train perplexity200.7105255126953
INFO:root:current mean train loss 13436.954428517345
INFO:root:current train perplexity201.9457550048828
INFO:root:current mean train loss 13448.71848420776
INFO:root:current train perplexity201.9239044189453
INFO:root:current mean train loss 13464.22744072014
INFO:root:current train perplexity201.80300903320312
INFO:root:current mean train loss 13475.290485649904
INFO:root:current train perplexity201.94113159179688
INFO:root:current mean train loss 13468.44327526914
INFO:root:current train perplexity201.7700958251953
INFO:root:current mean train loss 13463.316811919703
INFO:root:current train perplexity201.7574005126953
INFO:root:current mean train loss 13454.993969401829
INFO:root:current train perplexity201.5270233154297
INFO:root:current mean train loss 13460.27084597492
INFO:root:current train perplexity201.4994354248047

100%|██████████| 1/1 [08:36<00:00, 516.11s/it][A100%|██████████| 1/1 [08:36<00:00, 516.11s/it]
INFO:root:final mean train loss: 13448.884116388137
INFO:root:final train perplexity: 201.5373077392578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.23s/it][A100%|██████████| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 12939.12498614805
INFO:root:eval perplexity: 187.20468139648438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 13176.275335217199
INFO:root:eval perplexity: 218.7567596435547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/192
 96%|█████████▌| 192/200 [31:43:43<1:19:08, 593.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13722.316964285714
INFO:root:current train perplexity204.79872131347656
INFO:root:current mean train loss 13450.22097800926
INFO:root:current train perplexity200.90806579589844
INFO:root:current mean train loss 13488.473981881649
INFO:root:current train perplexity201.08929443359375
INFO:root:current mean train loss 13457.039144123135
INFO:root:current train perplexity200.3210906982422
INFO:root:current mean train loss 13455.56107893319
INFO:root:current train perplexity200.2998809814453
INFO:root:current mean train loss 13443.390679760514
INFO:root:current train perplexity199.9894256591797
INFO:root:current mean train loss 13444.830259596456
INFO:root:current train perplexity200.0456085205078
INFO:root:current mean train loss 13432.551420333759
INFO:root:current train perplexity199.81622314453125
INFO:root:current mean train loss 13432.971821201347
INFO:root:current train perplexity199.61080932617188
INFO:root:current mean train loss 13439.079991435494
INFO:root:current train perplexity199.596923828125

100%|██████████| 1/1 [08:41<00:00, 521.55s/it][A100%|██████████| 1/1 [08:41<00:00, 521.55s/it]
INFO:root:final mean train loss: 13422.631155936948
INFO:root:final train perplexity: 199.46047973632812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.41s/it][A100%|██████████| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 12918.37280446587
INFO:root:eval perplexity: 185.6402587890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 13157.394884474734
INFO:root:eval perplexity: 217.07435607910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/193
 96%|█████████▋| 193/200 [31:53:42<1:09:25, 595.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13430.312363735466
INFO:root:current train perplexity198.92022705078125
INFO:root:current mean train loss 13375.556831840035
INFO:root:current train perplexity197.38568115234375
INFO:root:current mean train loss 13403.627383134002
INFO:root:current train perplexity197.3996124267578
INFO:root:current mean train loss 13404.391322544643
INFO:root:current train perplexity197.4584503173828
INFO:root:current mean train loss 13412.607580593962
INFO:root:current train perplexity197.7503662109375
INFO:root:current mean train loss 13411.52450578384
INFO:root:current train perplexity197.6272430419922
INFO:root:current mean train loss 13415.162748772842
INFO:root:current train perplexity197.69265747070312
INFO:root:current mean train loss 13407.928173368102
INFO:root:current train perplexity197.39886474609375
INFO:root:current mean train loss 13399.68518312574
INFO:root:current train perplexity197.21408081054688
INFO:root:current mean train loss 13400.847972105315
INFO:root:current train perplexity197.2031707763672

100%|██████████| 1/1 [08:44<00:00, 524.45s/it][A100%|██████████| 1/1 [08:44<00:00, 524.45s/it]
INFO:root:final mean train loss: 13393.956669715142
INFO:root:final train perplexity: 197.21681213378906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.28s/it][A100%|██████████| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 12904.268083721188
INFO:root:eval perplexity: 184.58438110351562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 13144.53433898493
INFO:root:eval perplexity: 215.93565368652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/194
 97%|█████████▋| 194/200 [32:03:44<59:42, 597.08s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13286.713675704657
INFO:root:current train perplexity196.30990600585938
INFO:root:current mean train loss 13358.992271574918
INFO:root:current train perplexity197.03341674804688
INFO:root:current mean train loss 13413.640683360309
INFO:root:current train perplexity197.16236877441406
INFO:root:current mean train loss 13381.681373530982
INFO:root:current train perplexity196.96043395996094
INFO:root:current mean train loss 13395.174263355737
INFO:root:current train perplexity196.73825073242188
INFO:root:current mean train loss 13384.85346599932
INFO:root:current train perplexity196.58642578125
INFO:root:current mean train loss 13393.025914158507
INFO:root:current train perplexity196.527099609375
INFO:root:current mean train loss 13388.881298893142
INFO:root:current train perplexity196.40774536132812
INFO:root:current mean train loss 13396.303262246622
INFO:root:current train perplexity196.50686645507812
INFO:root:current mean train loss 13395.49933150138
INFO:root:current train perplexity196.3820037841797

100%|██████████| 1/1 [08:40<00:00, 520.39s/it][A100%|██████████| 1/1 [08:40<00:00, 520.39s/it]
INFO:root:final mean train loss: 13383.155034711284
INFO:root:final train perplexity: 196.37815856933594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.37s/it][A100%|██████████| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 12894.58148409796
INFO:root:eval perplexity: 183.8629150390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.54s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 13135.726423980497
INFO:root:eval perplexity: 215.15945434570312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/195
 98%|█████████▊| 195/200 [32:13:41<49:46, 597.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13374.060613082627
INFO:root:current train perplexity196.425537109375
INFO:root:current mean train loss 13412.542465113993
INFO:root:current train perplexity196.70767211914062
INFO:root:current mean train loss 13389.672316149856
INFO:root:current train perplexity196.56890869140625
INFO:root:current mean train loss 13380.167887143105
INFO:root:current train perplexity195.94891357421875
INFO:root:current mean train loss 13389.976888020834
INFO:root:current train perplexity196.07443237304688
INFO:root:current mean train loss 13380.086873881932
INFO:root:current train perplexity195.90948486328125
INFO:root:current mean train loss 13384.48292127039
INFO:root:current train perplexity195.93321228027344
INFO:root:current mean train loss 13397.924543498848
INFO:root:current train perplexity196.18731689453125
INFO:root:current mean train loss 13398.215796438446
INFO:root:current train perplexity196.151123046875
INFO:root:current mean train loss 13394.964175736444
INFO:root:current train perplexity196.17918395996094

100%|██████████| 1/1 [08:39<00:00, 519.34s/it][A100%|██████████| 1/1 [08:39<00:00, 519.34s/it]
INFO:root:final mean train loss: 13380.288004967475
INFO:root:final train perplexity: 196.1561737060547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.13s/it][A100%|██████████| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 12885.950444647606
INFO:root:eval perplexity: 183.22218322753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 13127.903216422872
INFO:root:eval perplexity: 214.47222900390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/196
 98%|█████████▊| 196/200 [32:23:38<39:47, 596.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13386.28907707556
INFO:root:current train perplexity195.60826110839844
INFO:root:current mean train loss 13411.759911816991
INFO:root:current train perplexity195.7205047607422
INFO:root:current mean train loss 13410.314339741339
INFO:root:current train perplexity196.15017700195312
INFO:root:current mean train loss 13415.401715769754
INFO:root:current train perplexity196.58914184570312
INFO:root:current mean train loss 13410.007549016327
INFO:root:current train perplexity196.8344268798828
INFO:root:current mean train loss 13389.4185526207
INFO:root:current train perplexity196.30569458007812
INFO:root:current mean train loss 13391.207548081427
INFO:root:current train perplexity196.17422485351562
INFO:root:current mean train loss 13384.360643130703
INFO:root:current train perplexity196.10940551757812
INFO:root:current mean train loss 13388.475436130335
INFO:root:current train perplexity196.16224670410156
INFO:root:current mean train loss 13391.330681028632
INFO:root:current train perplexity196.24139404296875

100%|██████████| 1/1 [08:37<00:00, 517.18s/it][A100%|██████████| 1/1 [08:37<00:00, 517.18s/it]
INFO:root:final mean train loss: 13381.81357106855
INFO:root:final train perplexity: 196.2742462158203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.22s/it][A100%|██████████| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 12879.548606493794
INFO:root:eval perplexity: 182.74856567382812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 13122.11148742243
INFO:root:eval perplexity: 213.96487426757812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/197
 98%|█████████▊| 197/200 [32:33:32<29:48, 596.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13366.409518229166
INFO:root:current train perplexity196.89385986328125
INFO:root:current mean train loss 13394.428353794643
INFO:root:current train perplexity196.8426055908203
INFO:root:current mean train loss 13410.971235795454
INFO:root:current train perplexity196.30166625976562
INFO:root:current mean train loss 13392.214401041667
INFO:root:current train perplexity196.21585083007812
INFO:root:current mean train loss 13387.146202713815
INFO:root:current train perplexity196.33209228515625
INFO:root:current mean train loss 13383.769060801631
INFO:root:current train perplexity196.36607360839844
INFO:root:current mean train loss 13390.12040798611
INFO:root:current train perplexity196.29483032226562
INFO:root:current mean train loss 13400.717113155242
INFO:root:current train perplexity196.453369140625
INFO:root:current mean train loss 13395.422972098215
INFO:root:current train perplexity196.41168212890625
INFO:root:current mean train loss 13393.054347956731
INFO:root:current train perplexity196.2689971923828

100%|██████████| 1/1 [08:41<00:00, 521.11s/it][A100%|██████████| 1/1 [08:41<00:00, 521.11s/it]
INFO:root:final mean train loss: 13381.614246245354
INFO:root:final train perplexity: 196.2587127685547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.50s/it][A100%|██████████| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 12874.506870567377
INFO:root:eval perplexity: 182.3764190673828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 13117.54645944149
INFO:root:eval perplexity: 213.56581115722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_200e_128/198
 99%|█████████▉| 198/200 [32:43:31<19:53, 596.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13327.21231410015
INFO:root:current train perplexity195.8252410888672
slurmstepd: error: *** JOB 30005752 ON gr053 CANCELLED AT 2023-02-10T15:37:02 ***
