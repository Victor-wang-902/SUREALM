INFO:root:Output: alll6_minil12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11490.621577099117
INFO:root:current train perplexity9024.6298828125
INFO:root:current mean train loss 9524.69016469064
INFO:root:current train perplexity1888.5675048828125
INFO:root:current mean train loss 8356.56325446802
INFO:root:current train perplexity748.6958618164062
INFO:root:current mean train loss 7565.189203477444
INFO:root:current train perplexity394.1578063964844
INFO:root:current mean train loss 6974.185754810402
INFO:root:current train perplexity247.098388671875
INFO:root:current mean train loss 6519.15498772368
INFO:root:current train perplexity172.55381774902344
INFO:root:current mean train loss 6161.404685613935
INFO:root:current train perplexity129.77828979492188
INFO:root:current mean train loss 5876.734342610881
INFO:root:current train perplexity103.1048583984375
INFO:root:current mean train loss 5636.171839152878
INFO:root:current train perplexity85.34228515625
INFO:root:current mean train loss 5430.125018328876
INFO:root:current train perplexity72.62248229980469
INFO:root:current mean train loss 5255.154723843409
INFO:root:current train perplexity63.140167236328125
INFO:root:current mean train loss 5102.794336263292
INFO:root:current train perplexity55.99176788330078
INFO:root:current mean train loss 4968.177739825406
INFO:root:current train perplexity50.33052444458008
INFO:root:current mean train loss 4848.397479086624
INFO:root:current train perplexity45.80131912231445
INFO:root:current mean train loss 4740.360115728194
INFO:root:current train perplexity42.0882453918457
INFO:root:current mean train loss 4644.0422242661425
INFO:root:current train perplexity38.97190856933594
INFO:root:current mean train loss 4555.876716456602
INFO:root:current train perplexity36.34757614135742
INFO:root:current mean train loss 4476.5876268065595
INFO:root:current train perplexity34.133209228515625
INFO:root:current mean train loss 4403.629212486424
INFO:root:current train perplexity32.214576721191406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.85s/it]
INFO:root:final mean train loss: 4344.738144344113
INFO:root:final train perplexity: 30.769441604614258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.56s/it]
INFO:root:eval mean loss: 2831.3349644004875
INFO:root:eval perplexity: 9.873133659362793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it]
INFO:root:eval mean loss: 3126.223638006981
INFO:root:eval perplexity: 12.893349647521973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/1
  1%|          | 1/100 [09:40<15:58:35, 580.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2986.3993225097656
INFO:root:current train perplexity10.54150676727295
INFO:root:current mean train loss 3027.0864994443696
INFO:root:current train perplexity10.74105167388916
INFO:root:current mean train loss 3004.1594023527923
INFO:root:current train perplexity10.58422565460205
INFO:root:current mean train loss 2987.513978595975
INFO:root:current train perplexity10.450550079345703
INFO:root:current mean train loss 2966.641288757324
INFO:root:current train perplexity10.2886381149292
INFO:root:current mean train loss 2951.714613330457
INFO:root:current train perplexity10.199353218078613
INFO:root:current mean train loss 2939.5241382153004
INFO:root:current train perplexity10.115342140197754
INFO:root:current mean train loss 2925.035569856953
INFO:root:current train perplexity10.01333236694336
INFO:root:current mean train loss 2910.7407202627146
INFO:root:current train perplexity9.91370964050293
INFO:root:current mean train loss 2903.417536706383
INFO:root:current train perplexity9.843021392822266
INFO:root:current mean train loss 2889.9132654385303
INFO:root:current train perplexity9.742914199829102
INFO:root:current mean train loss 2877.893871020245
INFO:root:current train perplexity9.656960487365723
INFO:root:current mean train loss 2867.2316832291453
INFO:root:current train perplexity9.584786415100098
INFO:root:current mean train loss 2857.556922611132
INFO:root:current train perplexity9.507552146911621
INFO:root:current mean train loss 2850.4584455759514
INFO:root:current train perplexity9.443915367126465
INFO:root:current mean train loss 2839.739136386358
INFO:root:current train perplexity9.375210762023926
INFO:root:current mean train loss 2830.1720642996306
INFO:root:current train perplexity9.31067943572998
INFO:root:current mean train loss 2821.7181632657707
INFO:root:current train perplexity9.241458892822266
INFO:root:current mean train loss 2811.510569433809
INFO:root:current train perplexity9.17035961151123
INFO:root:current mean train loss 2803.8776897518023
INFO:root:current train perplexity9.119606018066406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.41s/it]
INFO:root:final mean train loss: 2797.6718984537515
INFO:root:final train perplexity: 9.083070755004883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it]
INFO:root:eval mean loss: 2490.2244903348014
INFO:root:eval perplexity: 7.492836952209473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 2825.8230166604335
INFO:root:eval perplexity: 10.08486557006836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/2
  2%|â–         | 2/100 [19:25<15:52:23, 583.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2601.6160999644885
INFO:root:current train perplexity7.832178115844727
INFO:root:current mean train loss 2615.198877320254
INFO:root:current train perplexity7.866830348968506
INFO:root:current mean train loss 2604.6421715732295
INFO:root:current train perplexity7.834887981414795
INFO:root:current mean train loss 2606.1762783291106
INFO:root:current train perplexity7.798515319824219
INFO:root:current mean train loss 2603.7452998700924
INFO:root:current train perplexity7.79168176651001
INFO:root:current mean train loss 2599.4140473843518
INFO:root:current train perplexity7.7562713623046875
INFO:root:current mean train loss 2593.8523670455666
INFO:root:current train perplexity7.7324934005737305
INFO:root:current mean train loss 2592.442838452848
INFO:root:current train perplexity7.713351249694824
INFO:root:current mean train loss 2588.5557519882955
INFO:root:current train perplexity7.689342021942139
INFO:root:current mean train loss 2582.3634277867095
INFO:root:current train perplexity7.656970500946045
INFO:root:current mean train loss 2575.7695059614744
INFO:root:current train perplexity7.624680519104004
INFO:root:current mean train loss 2569.755836318471
INFO:root:current train perplexity7.590566635131836
INFO:root:current mean train loss 2566.0428799445904
INFO:root:current train perplexity7.570889472961426
INFO:root:current mean train loss 2561.7493795751184
INFO:root:current train perplexity7.541831970214844
INFO:root:current mean train loss 2558.1469734229163
INFO:root:current train perplexity7.51753568649292
INFO:root:current mean train loss 2552.8890702558047
INFO:root:current train perplexity7.487583160400391
INFO:root:current mean train loss 2549.0216813469983
INFO:root:current train perplexity7.459961891174316
INFO:root:current mean train loss 2545.647482562189
INFO:root:current train perplexity7.439459800720215
INFO:root:current mean train loss 2542.9823053987443
INFO:root:current train perplexity7.424674987792969
INFO:root:current mean train loss 2539.6374498457103
INFO:root:current train perplexity7.4039716720581055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.76s/it]
INFO:root:final mean train loss: 2537.3364009732136
INFO:root:final train perplexity: 7.397159099578857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it]
INFO:root:eval mean loss: 2365.3102797920824
INFO:root:eval perplexity: 6.772863388061523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it]
INFO:root:eval mean loss: 2725.512914346465
INFO:root:eval perplexity: 9.290565490722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/3
  3%|â–Ž         | 3/100 [28:57<15:34:31, 578.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2418.0585791015624
INFO:root:current train perplexity6.814574718475342
INFO:root:current mean train loss 2430.234951985677
INFO:root:current train perplexity6.869110584259033
INFO:root:current mean train loss 2440.8900190429686
INFO:root:current train perplexity6.859261512756348
INFO:root:current mean train loss 2443.5921125139507
INFO:root:current train perplexity6.834317684173584
INFO:root:current mean train loss 2442.3725477430557
INFO:root:current train perplexity6.83035135269165
INFO:root:current mean train loss 2435.505828746449
INFO:root:current train perplexity6.80930233001709
INFO:root:current mean train loss 2430.8933971228967
INFO:root:current train perplexity6.798748970031738
INFO:root:current mean train loss 2425.5864575195315
INFO:root:current train perplexity6.7862629890441895
INFO:root:current mean train loss 2424.117431784237
INFO:root:current train perplexity6.7656168937683105
INFO:root:current mean train loss 2419.9521725945724
INFO:root:current train perplexity6.743010520935059
INFO:root:current mean train loss 2414.396509486607
INFO:root:current train perplexity6.730051040649414
INFO:root:current mean train loss 2414.302318486753
INFO:root:current train perplexity6.726739883422852
INFO:root:current mean train loss 2413.814921484375
INFO:root:current train perplexity6.718470096588135
INFO:root:current mean train loss 2411.071890914352
INFO:root:current train perplexity6.701406955718994
INFO:root:current mean train loss 2409.3447416318695
INFO:root:current train perplexity6.684155464172363
INFO:root:current mean train loss 2407.1995736989666
INFO:root:current train perplexity6.677083492279053
INFO:root:current mean train loss 2405.431013997396
INFO:root:current train perplexity6.663792133331299
INFO:root:current mean train loss 2403.1884521484376
INFO:root:current train perplexity6.6499786376953125
INFO:root:current mean train loss 2400.0297158730996
INFO:root:current train perplexity6.638042449951172
INFO:root:current mean train loss 2397.6052419496195
INFO:root:current train perplexity6.622509956359863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.43s/it]
INFO:root:final mean train loss: 2396.118414912991
INFO:root:final train perplexity: 6.617536544799805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2241.1661783854165
INFO:root:eval perplexity: 6.125887393951416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it]
INFO:root:eval mean loss: 2612.074378913176
INFO:root:eval perplexity: 8.467422485351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/4
  4%|â–         | 4/100 [38:30<15:21:50, 576.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2344.4119308243935
INFO:root:current train perplexity6.288700103759766
INFO:root:current mean train loss 2324.588772162706
INFO:root:current train perplexity6.213606357574463
INFO:root:current mean train loss 2323.453076994821
INFO:root:current train perplexity6.2358927726745605
INFO:root:current mean train loss 2318.788299144776
INFO:root:current train perplexity6.220393657684326
INFO:root:current mean train loss 2322.070950559171
INFO:root:current train perplexity6.246082782745361
INFO:root:current mean train loss 2322.436857354704
INFO:root:current train perplexity6.234373092651367
INFO:root:current mean train loss 2319.3047559472216
INFO:root:current train perplexity6.2287116050720215
INFO:root:current mean train loss 2321.960664870997
INFO:root:current train perplexity6.230493068695068
INFO:root:current mean train loss 2319.5429662156685
INFO:root:current train perplexity6.226339817047119
INFO:root:current mean train loss 2318.209670468225
INFO:root:current train perplexity6.216526985168457
INFO:root:current mean train loss 2317.5475600581362
INFO:root:current train perplexity6.212011814117432
INFO:root:current mean train loss 2314.6821411446617
INFO:root:current train perplexity6.196730613708496
INFO:root:current mean train loss 2314.9575799401578
INFO:root:current train perplexity6.192601680755615
INFO:root:current mean train loss 2312.455429869668
INFO:root:current train perplexity6.187353134155273
INFO:root:current mean train loss 2310.0010638506783
INFO:root:current train perplexity6.173984527587891
INFO:root:current mean train loss 2309.7903167783033
INFO:root:current train perplexity6.170413017272949
INFO:root:current mean train loss 2306.8013815693894
INFO:root:current train perplexity6.163517951965332
INFO:root:current mean train loss 2307.578071045889
INFO:root:current train perplexity6.16131067276001
INFO:root:current mean train loss 2306.4130512844386
INFO:root:current train perplexity6.159929275512695
INFO:root:current mean train loss 2305.539670741552
INFO:root:current train perplexity6.157268047332764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.74s/it]
INFO:root:final mean train loss: 2304.4471337669015
INFO:root:final train perplexity: 6.155991077423096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 2182.622239998892
INFO:root:eval perplexity: 5.842604160308838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it]
INFO:root:eval mean loss: 2563.753651720412
INFO:root:eval perplexity: 8.139331817626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/5
  5%|â–Œ         | 5/100 [48:10<15:14:15, 577.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2258.95115734282
INFO:root:current train perplexity5.991438865661621
INFO:root:current mean train loss 2274.7270547618036
INFO:root:current train perplexity5.982248783111572
INFO:root:current mean train loss 2263.3254940409056
INFO:root:current train perplexity5.949033260345459
INFO:root:current mean train loss 2262.868413925171
INFO:root:current train perplexity5.957589626312256
INFO:root:current mean train loss 2258.0679828233956
INFO:root:current train perplexity5.949739933013916
INFO:root:current mean train loss 2261.8509582101483
INFO:root:current train perplexity5.9485859870910645
INFO:root:current mean train loss 2256.604886595966
INFO:root:current train perplexity5.936154365539551
INFO:root:current mean train loss 2254.2265213946907
INFO:root:current train perplexity5.925700664520264
INFO:root:current mean train loss 2254.4315105455494
INFO:root:current train perplexity5.9215497970581055
INFO:root:current mean train loss 2250.791907705912
INFO:root:current train perplexity5.9103617668151855
INFO:root:current mean train loss 2250.100777038349
INFO:root:current train perplexity5.903889179229736
INFO:root:current mean train loss 2249.559448860787
INFO:root:current train perplexity5.896962642669678
INFO:root:current mean train loss 2248.591558628736
INFO:root:current train perplexity5.887188911437988
INFO:root:current mean train loss 2247.0579435315435
INFO:root:current train perplexity5.880395412445068
INFO:root:current mean train loss 2243.9157520715758
INFO:root:current train perplexity5.874260425567627
INFO:root:current mean train loss 2241.8492563421078
INFO:root:current train perplexity5.866243839263916
INFO:root:current mean train loss 2241.5177991418545
INFO:root:current train perplexity5.8614888191223145
INFO:root:current mean train loss 2241.011034430944
INFO:root:current train perplexity5.855583190917969
INFO:root:current mean train loss 2239.9745826154253
INFO:root:current train perplexity5.851821422576904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.89s/it]
INFO:root:final mean train loss: 2239.711789745306
INFO:root:final train perplexity: 5.8495893478393555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it]
INFO:root:eval mean loss: 2123.4567866765015
INFO:root:eval perplexity: 5.569621562957764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.89s/it]
INFO:root:eval mean loss: 2512.972796933871
INFO:root:eval perplexity: 7.808228969573975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/6
  6%|â–Œ         | 6/100 [57:42<15:01:30, 575.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2228.55810546875
INFO:root:current train perplexity5.7661871910095215
INFO:root:current mean train loss 2174.1940760848547
INFO:root:current train perplexity5.585635662078857
INFO:root:current mean train loss 2178.9936426267104
INFO:root:current train perplexity5.607269287109375
INFO:root:current mean train loss 2180.2309862307934
INFO:root:current train perplexity5.5917744636535645
INFO:root:current mean train loss 2182.024441459827
INFO:root:current train perplexity5.599283218383789
INFO:root:current mean train loss 2187.2792286520707
INFO:root:current train perplexity5.601312160491943
INFO:root:current mean train loss 2189.9093830026127
INFO:root:current train perplexity5.609455108642578
INFO:root:current mean train loss 2191.446725799082
INFO:root:current train perplexity5.615111827850342
INFO:root:current mean train loss 2189.594799713249
INFO:root:current train perplexity5.60698127746582
INFO:root:current mean train loss 2189.7045410698183
INFO:root:current train perplexity5.607581615447998
INFO:root:current mean train loss 2187.3256298145216
INFO:root:current train perplexity5.606546878814697
INFO:root:current mean train loss 2187.4334271090556
INFO:root:current train perplexity5.60373067855835
INFO:root:current mean train loss 2186.230666847451
INFO:root:current train perplexity5.601727485656738
INFO:root:current mean train loss 2184.6300730958155
INFO:root:current train perplexity5.595637321472168
INFO:root:current mean train loss 2184.766533339049
INFO:root:current train perplexity5.595095157623291
INFO:root:current mean train loss 2184.20037422968
INFO:root:current train perplexity5.595737934112549
INFO:root:current mean train loss 2183.1697070891973
INFO:root:current train perplexity5.592196464538574
INFO:root:current mean train loss 2180.6093757176386
INFO:root:current train perplexity5.585487365722656
INFO:root:current mean train loss 2179.9523462171624
INFO:root:current train perplexity5.581663608551025
INFO:root:current mean train loss 2180.298145019274
INFO:root:current train perplexity5.577874660491943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.76s/it]
INFO:root:final mean train loss: 2178.751428770526
INFO:root:final train perplexity: 5.575011730194092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2089.7315950867132
INFO:root:eval perplexity: 5.419764041900635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it]
INFO:root:eval mean loss: 2485.2534162372563
INFO:root:eval perplexity: 7.633209228515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/7
  7%|â–‹         | 7/100 [1:07:14<14:50:32, 574.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2238.460883246528
INFO:root:current train perplexity5.492212295532227
INFO:root:current mean train loss 2157.1510413218352
INFO:root:current train perplexity5.455165863037109
INFO:root:current mean train loss 2148.799491672341
INFO:root:current train perplexity5.402371406555176
INFO:root:current mean train loss 2137.6831622813484
INFO:root:current train perplexity5.383956432342529
INFO:root:current mean train loss 2148.0347205349135
INFO:root:current train perplexity5.417895793914795
INFO:root:current mean train loss 2145.3547851091184
INFO:root:current train perplexity5.403698444366455
INFO:root:current mean train loss 2145.479932667754
INFO:root:current train perplexity5.402484893798828
INFO:root:current mean train loss 2147.09524952668
INFO:root:current train perplexity5.409470081329346
INFO:root:current mean train loss 2141.1296538933566
INFO:root:current train perplexity5.401186466217041
INFO:root:current mean train loss 2143.085905719167
INFO:root:current train perplexity5.404226779937744
INFO:root:current mean train loss 2141.842046891308
INFO:root:current train perplexity5.402519702911377
INFO:root:current mean train loss 2140.3465589274233
INFO:root:current train perplexity5.401965141296387
INFO:root:current mean train loss 2138.020811685396
INFO:root:current train perplexity5.397078990936279
INFO:root:current mean train loss 2139.082965578765
INFO:root:current train perplexity5.3975324630737305
INFO:root:current mean train loss 2139.2538601077663
INFO:root:current train perplexity5.399016857147217
INFO:root:current mean train loss 2138.5544177069182
INFO:root:current train perplexity5.397566795349121
INFO:root:current mean train loss 2137.2266319850173
INFO:root:current train perplexity5.39204740524292
INFO:root:current mean train loss 2137.850211839598
INFO:root:current train perplexity5.392892837524414
INFO:root:current mean train loss 2136.8276692842624
INFO:root:current train perplexity5.391061782836914
INFO:root:current mean train loss 2135.859671201895
INFO:root:current train perplexity5.388818740844727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.62s/it]
INFO:root:final mean train loss: 2134.934585640542
INFO:root:final train perplexity: 5.385648727416992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2062.727694464068
INFO:root:eval perplexity: 5.302683353424072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.76s/it]
INFO:root:eval mean loss: 2463.1073491522607
INFO:root:eval perplexity: 7.496204853057861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/8
  8%|â–Š         | 8/100 [1:16:56<14:44:18, 576.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2058.8161097935267
INFO:root:current train perplexity5.100810527801514
INFO:root:current mean train loss 2085.867359302662
INFO:root:current train perplexity5.198882579803467
INFO:root:current mean train loss 2082.9222412109375
INFO:root:current train perplexity5.2102437019348145
INFO:root:current mean train loss 2097.4130957760026
INFO:root:current train perplexity5.232893466949463
INFO:root:current mean train loss 2104.2077260686065
INFO:root:current train perplexity5.256570816040039
INFO:root:current mean train loss 2102.7862313814253
INFO:root:current train perplexity5.247158050537109
INFO:root:current mean train loss 2104.564401797798
INFO:root:current train perplexity5.248894214630127
INFO:root:current mean train loss 2104.4655524221407
INFO:root:current train perplexity5.254148960113525
INFO:root:current mean train loss 2103.460076575365
INFO:root:current train perplexity5.255862236022949
INFO:root:current mean train loss 2106.501147330381
INFO:root:current train perplexity5.257105350494385
INFO:root:current mean train loss 2106.381203412779
INFO:root:current train perplexity5.255179405212402
INFO:root:current mean train loss 2106.8635058163545
INFO:root:current train perplexity5.2594757080078125
INFO:root:current mean train loss 2104.3410897567687
INFO:root:current train perplexity5.257176399230957
INFO:root:current mean train loss 2102.181278528792
INFO:root:current train perplexity5.251889705657959
INFO:root:current mean train loss 2102.535403453016
INFO:root:current train perplexity5.250466823577881
INFO:root:current mean train loss 2103.2806037033033
INFO:root:current train perplexity5.25260066986084
INFO:root:current mean train loss 2104.591038097883
INFO:root:current train perplexity5.255945682525635
INFO:root:current mean train loss 2104.4335916392743
INFO:root:current train perplexity5.256258487701416
INFO:root:current mean train loss 2103.7400137836344
INFO:root:current train perplexity5.254363059997559
INFO:root:current mean train loss 2104.068155482881
INFO:root:current train perplexity5.253262519836426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.08s/it]
INFO:root:final mean train loss: 2102.966445438079
INFO:root:final train perplexity: 5.251563549041748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2030.4726069024268
INFO:root:eval perplexity: 5.1661458015441895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it]
INFO:root:eval mean loss: 2438.934887608738
INFO:root:eval perplexity: 7.349468231201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/9
  9%|â–‰         | 9/100 [1:26:37<14:36:53, 578.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.1508131760818
INFO:root:current train perplexity5.099518775939941
INFO:root:current mean train loss 2071.040421335321
INFO:root:current train perplexity5.1570234298706055
INFO:root:current mean train loss 2083.7799551827566
INFO:root:current train perplexity5.1611857414245605
INFO:root:current mean train loss 2077.9801642678
INFO:root:current train perplexity5.153322219848633
INFO:root:current mean train loss 2076.523176615217
INFO:root:current train perplexity5.152069568634033
INFO:root:current mean train loss 2072.3700565946274
INFO:root:current train perplexity5.136367321014404
INFO:root:current mean train loss 2072.8797377135857
INFO:root:current train perplexity5.137896537780762
INFO:root:current mean train loss 2072.6407129815284
INFO:root:current train perplexity5.135138511657715
INFO:root:current mean train loss 2076.3694609879326
INFO:root:current train perplexity5.140342712402344
INFO:root:current mean train loss 2074.593065406094
INFO:root:current train perplexity5.1367506980896
INFO:root:current mean train loss 2075.0808298089205
INFO:root:current train perplexity5.136226654052734
INFO:root:current mean train loss 2076.523963822259
INFO:root:current train perplexity5.1395344734191895
INFO:root:current mean train loss 2074.203885111946
INFO:root:current train perplexity5.1366400718688965
INFO:root:current mean train loss 2074.7048294699403
INFO:root:current train perplexity5.132133483886719
INFO:root:current mean train loss 2075.1167676521072
INFO:root:current train perplexity5.132294654846191
INFO:root:current mean train loss 2074.895074274122
INFO:root:current train perplexity5.132918357849121
INFO:root:current mean train loss 2076.3067283353275
INFO:root:current train perplexity5.136287689208984
INFO:root:current mean train loss 2076.512279632429
INFO:root:current train perplexity5.136651992797852
INFO:root:current mean train loss 2075.3797024753644
INFO:root:current train perplexity5.1340203285217285
INFO:root:current mean train loss 2075.700782213055
INFO:root:current train perplexity5.13444709777832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.86s/it]
INFO:root:final mean train loss: 2073.8389850718413
INFO:root:final train perplexity: 5.132301330566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2013.6281850828348
INFO:root:eval perplexity: 5.09624719619751
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2421.517618382231
INFO:root:eval perplexity: 7.245521068572998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:36:37<14:37:12, 584.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2057.321083842844
INFO:root:current train perplexity5.050629138946533
INFO:root:current mean train loss 2069.5938959065275
INFO:root:current train perplexity5.071671962738037
INFO:root:current mean train loss 2066.6120650848047
INFO:root:current train perplexity5.061422824859619
INFO:root:current mean train loss 2060.285752376567
INFO:root:current train perplexity5.045397758483887
INFO:root:current mean train loss 2058.306706735574
INFO:root:current train perplexity5.044431209564209
INFO:root:current mean train loss 2054.4826132400594
INFO:root:current train perplexity5.044306755065918
INFO:root:current mean train loss 2051.8206079138054
INFO:root:current train perplexity5.03487491607666
INFO:root:current mean train loss 2053.2166455967063
INFO:root:current train perplexity5.041698455810547
INFO:root:current mean train loss 2052.7753033917847
INFO:root:current train perplexity5.044292449951172
INFO:root:current mean train loss 2052.0989937324644
INFO:root:current train perplexity5.042492866516113
INFO:root:current mean train loss 2050.95607295808
INFO:root:current train perplexity5.039316177368164
INFO:root:current mean train loss 2052.4557612592894
INFO:root:current train perplexity5.038925647735596
INFO:root:current mean train loss 2052.0638977002686
INFO:root:current train perplexity5.040952205657959
INFO:root:current mean train loss 2051.8830130377155
INFO:root:current train perplexity5.03721284866333
INFO:root:current mean train loss 2052.257479860476
INFO:root:current train perplexity5.040185451507568
INFO:root:current mean train loss 2051.3157831390167
INFO:root:current train perplexity5.037532806396484
INFO:root:current mean train loss 2050.5415853108384
INFO:root:current train perplexity5.035778522491455
INFO:root:current mean train loss 2050.4624731431513
INFO:root:current train perplexity5.033702850341797
INFO:root:current mean train loss 2049.683749260655
INFO:root:current train perplexity5.030531883239746
INFO:root:current mean train loss 2050.076840626885
INFO:root:current train perplexity5.035243511199951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.59s/it]
INFO:root:final mean train loss: 2049.4157283011555
INFO:root:final train perplexity: 5.034390926361084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 1995.2763425137134
INFO:root:eval perplexity: 5.021166801452637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it]
INFO:root:eval mean loss: 2410.048538532663
INFO:root:eval perplexity: 7.177877902984619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:46:23<14:28:01, 585.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.8644820812137
INFO:root:current train perplexity4.949063777923584
INFO:root:current mean train loss 2022.9075862105174
INFO:root:current train perplexity4.928036689758301
INFO:root:current mean train loss 2022.0239501099486
INFO:root:current train perplexity4.926461696624756
INFO:root:current mean train loss 2024.6399150314726
INFO:root:current train perplexity4.936985969543457
INFO:root:current mean train loss 2019.8216361842528
INFO:root:current train perplexity4.942103862762451
INFO:root:current mean train loss 2023.221349306074
INFO:root:current train perplexity4.942031383514404
INFO:root:current mean train loss 2024.4056574429437
INFO:root:current train perplexity4.9331536293029785
INFO:root:current mean train loss 2024.2221181156071
INFO:root:current train perplexity4.929080486297607
INFO:root:current mean train loss 2023.7309048138138
INFO:root:current train perplexity4.9272942543029785
INFO:root:current mean train loss 2026.4652868429498
INFO:root:current train perplexity4.934536933898926
INFO:root:current mean train loss 2028.1087910632841
INFO:root:current train perplexity4.942183017730713
INFO:root:current mean train loss 2028.2944743524715
INFO:root:current train perplexity4.941892147064209
INFO:root:current mean train loss 2028.795253344309
INFO:root:current train perplexity4.943861961364746
INFO:root:current mean train loss 2028.4260674018365
INFO:root:current train perplexity4.945347309112549
INFO:root:current mean train loss 2026.9895692314467
INFO:root:current train perplexity4.9461669921875
INFO:root:current mean train loss 2028.3825374184762
INFO:root:current train perplexity4.947734355926514
INFO:root:current mean train loss 2027.0926852514735
INFO:root:current train perplexity4.946583271026611
INFO:root:current mean train loss 2027.2373944973492
INFO:root:current train perplexity4.946673393249512
INFO:root:current mean train loss 2026.6669233206853
INFO:root:current train perplexity4.946356296539307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.18s/it]
INFO:root:final mean train loss: 2027.166735488961
INFO:root:final train perplexity: 4.9468231201171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 1987.997444748033
INFO:root:eval perplexity: 4.991695880889893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2402.156632227255
INFO:root:eval perplexity: 7.1317009925842285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:56:13<14:20:44, 586.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2060.16015625
INFO:root:current train perplexity4.726924419403076
INFO:root:current mean train loss 2011.3261244690534
INFO:root:current train perplexity4.887738227844238
INFO:root:current mean train loss 2001.4737675107758
INFO:root:current train perplexity4.848949432373047
INFO:root:current mean train loss 2007.0956007954312
INFO:root:current train perplexity4.858327865600586
INFO:root:current mean train loss 2004.7518171211034
INFO:root:current train perplexity4.8527607917785645
INFO:root:current mean train loss 2007.2572606354063
INFO:root:current train perplexity4.864920616149902
INFO:root:current mean train loss 2010.8781760549466
INFO:root:current train perplexity4.880958080291748
INFO:root:current mean train loss 2008.753787999811
INFO:root:current train perplexity4.871725559234619
INFO:root:current mean train loss 2008.824293086716
INFO:root:current train perplexity4.872166633605957
INFO:root:current mean train loss 2009.3056012023724
INFO:root:current train perplexity4.875894069671631
INFO:root:current mean train loss 2008.0213879844841
INFO:root:current train perplexity4.870382308959961
INFO:root:current mean train loss 2007.6064289331653
INFO:root:current train perplexity4.873968601226807
INFO:root:current mean train loss 2006.68627128062
INFO:root:current train perplexity4.873996257781982
INFO:root:current mean train loss 2006.8699312246679
INFO:root:current train perplexity4.87403678894043
INFO:root:current mean train loss 2007.6428424511648
INFO:root:current train perplexity4.871464252471924
INFO:root:current mean train loss 2007.4746464103043
INFO:root:current train perplexity4.870141983032227
INFO:root:current mean train loss 2008.3797133761648
INFO:root:current train perplexity4.8741607666015625
INFO:root:current mean train loss 2008.6388041954915
INFO:root:current train perplexity4.874398231506348
INFO:root:current mean train loss 2008.7642735604504
INFO:root:current train perplexity4.873794078826904
INFO:root:current mean train loss 2009.8569933780543
INFO:root:current train perplexity4.876246929168701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.67s/it]
INFO:root:final mean train loss: 2008.642198371214
INFO:root:final train perplexity: 4.875078201293945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 1971.357107176003
INFO:root:eval perplexity: 4.924968242645264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2393.558852175449
INFO:root:eval perplexity: 7.081730842590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [2:06:14<14:16:45, 590.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.2444641113282
INFO:root:current train perplexity4.761527061462402
INFO:root:current mean train loss 1976.5221384684244
INFO:root:current train perplexity4.742099761962891
INFO:root:current mean train loss 1980.0909140846945
INFO:root:current train perplexity4.7850542068481445
INFO:root:current mean train loss 1980.4019359588624
INFO:root:current train perplexity4.770389556884766
INFO:root:current mean train loss 1981.76808093843
INFO:root:current train perplexity4.773187160491943
INFO:root:current mean train loss 1987.0770627535308
INFO:root:current train perplexity4.78211784362793
INFO:root:current mean train loss 1983.5699222687751
INFO:root:current train perplexity4.7730607986450195
INFO:root:current mean train loss 1981.1535390218098
INFO:root:current train perplexity4.769880771636963
INFO:root:current mean train loss 1980.2744271627287
INFO:root:current train perplexity4.774509429931641
INFO:root:current mean train loss 1979.4227342688519
INFO:root:current train perplexity4.775330543518066
INFO:root:current mean train loss 1980.6816608503752
INFO:root:current train perplexity4.7766337394714355
INFO:root:current mean train loss 1981.7547336033413
INFO:root:current train perplexity4.781091213226318
INFO:root:current mean train loss 1981.762757248175
INFO:root:current train perplexity4.777011394500732
INFO:root:current mean train loss 1983.7233746152936
INFO:root:current train perplexity4.778087139129639
INFO:root:current mean train loss 1984.3032168965944
INFO:root:current train perplexity4.783819198608398
INFO:root:current mean train loss 1983.5698443764134
INFO:root:current train perplexity4.785704135894775
INFO:root:current mean train loss 1984.4066432623215
INFO:root:current train perplexity4.787841796875
INFO:root:current mean train loss 1986.1483128037564
INFO:root:current train perplexity4.788733959197998
INFO:root:current mean train loss 1985.4520770733172
INFO:root:current train perplexity4.788363456726074
INFO:root:current mean train loss 1986.4120127360027
INFO:root:current train perplexity4.7926249504089355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.30s/it]
INFO:root:final mean train loss: 1987.0610952680302
INFO:root:final train perplexity: 4.792805194854736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 1969.9195573955562
INFO:root:eval perplexity: 4.919246196746826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 2391.214314778646
INFO:root:eval perplexity: 7.06816291809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [2:15:57<14:03:39, 588.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2001.290672508446
INFO:root:current train perplexity4.668172836303711
INFO:root:current mean train loss 1979.4193899335653
INFO:root:current train perplexity4.703476428985596
INFO:root:current mean train loss 1971.4052306871374
INFO:root:current train perplexity4.706660270690918
INFO:root:current mean train loss 1969.6813403392757
INFO:root:current train perplexity4.700531959533691
INFO:root:current mean train loss 1969.4212364353905
INFO:root:current train perplexity4.701613426208496
INFO:root:current mean train loss 1972.156531193625
INFO:root:current train perplexity4.712912082672119
INFO:root:current mean train loss 1969.2291202275683
INFO:root:current train perplexity4.710907936096191
INFO:root:current mean train loss 1968.000954036635
INFO:root:current train perplexity4.711124420166016
INFO:root:current mean train loss 1968.1088645506645
INFO:root:current train perplexity4.709134101867676
INFO:root:current mean train loss 1965.3539597420709
INFO:root:current train perplexity4.704769611358643
INFO:root:current mean train loss 1964.754677164635
INFO:root:current train perplexity4.70706033706665
INFO:root:current mean train loss 1965.5663578298497
INFO:root:current train perplexity4.710978984832764
INFO:root:current mean train loss 1965.500710119619
INFO:root:current train perplexity4.7106523513793945
INFO:root:current mean train loss 1966.6147491980062
INFO:root:current train perplexity4.7137956619262695
INFO:root:current mean train loss 1965.4863879284098
INFO:root:current train perplexity4.7102484703063965
INFO:root:current mean train loss 1967.5527954498668
INFO:root:current train perplexity4.715440273284912
INFO:root:current mean train loss 1968.2016553838005
INFO:root:current train perplexity4.718075275421143
INFO:root:current mean train loss 1968.7045678471998
INFO:root:current train perplexity4.720587730407715
INFO:root:current mean train loss 1968.8547613136652
INFO:root:current train perplexity4.722228527069092
INFO:root:current mean train loss 1969.2553516204787
INFO:root:current train perplexity4.724915504455566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.55s/it]
INFO:root:final mean train loss: 1969.7183831734785
INFO:root:final train perplexity: 4.72769832611084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 1953.3759575160682
INFO:root:eval perplexity: 4.853867053985596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2374.4947873379324
INFO:root:eval perplexity: 6.97217321395874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [2:25:39<13:51:15, 586.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.3289727105034
INFO:root:current train perplexity4.618674278259277
INFO:root:current mean train loss 1942.2027778130073
INFO:root:current train perplexity4.660240173339844
INFO:root:current mean train loss 1950.5622760442297
INFO:root:current train perplexity4.670025825500488
INFO:root:current mean train loss 1945.9769807804776
INFO:root:current train perplexity4.6552815437316895
INFO:root:current mean train loss 1948.166375920636
INFO:root:current train perplexity4.650860786437988
INFO:root:current mean train loss 1951.3134170697483
INFO:root:current train perplexity4.6596221923828125
INFO:root:current mean train loss 1954.7297473405845
INFO:root:current train perplexity4.66527795791626
INFO:root:current mean train loss 1951.821203580902
INFO:root:current train perplexity4.654849052429199
INFO:root:current mean train loss 1951.4508948582954
INFO:root:current train perplexity4.656198501586914
INFO:root:current mean train loss 1950.6320448901417
INFO:root:current train perplexity4.655607223510742
INFO:root:current mean train loss 1954.1944295170185
INFO:root:current train perplexity4.660754680633545
INFO:root:current mean train loss 1950.9947040101683
INFO:root:current train perplexity4.6546454429626465
INFO:root:current mean train loss 1952.2876182933364
INFO:root:current train perplexity4.658746719360352
INFO:root:current mean train loss 1953.4800301443352
INFO:root:current train perplexity4.657238483428955
INFO:root:current mean train loss 1953.931096429838
INFO:root:current train perplexity4.659008026123047
INFO:root:current mean train loss 1952.918683497602
INFO:root:current train perplexity4.658535957336426
INFO:root:current mean train loss 1951.9470943280257
INFO:root:current train perplexity4.657430648803711
INFO:root:current mean train loss 1952.278696823555
INFO:root:current train perplexity4.659877777099609
INFO:root:current mean train loss 1952.4822702418126
INFO:root:current train perplexity4.659940242767334
INFO:root:current mean train loss 1951.218885002019
INFO:root:current train perplexity4.657508850097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.22s/it]
INFO:root:final mean train loss: 1950.7301415670897
INFO:root:final train perplexity: 4.6574273109436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 1949.2997549070535
INFO:root:eval perplexity: 4.837892055511475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2372.8149565568206
INFO:root:eval perplexity: 6.962602615356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [2:35:25<13:40:47, 586.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1967.6573314398108
INFO:root:current train perplexity4.640946865081787
INFO:root:current mean train loss 1945.3509971217106
INFO:root:current train perplexity4.614819049835205
INFO:root:current mean train loss 1942.4829763715118
INFO:root:current train perplexity4.618724822998047
INFO:root:current mean train loss 1941.7083885007792
INFO:root:current train perplexity4.61323881149292
INFO:root:current mean train loss 1940.0375567069732
INFO:root:current train perplexity4.618262767791748
INFO:root:current mean train loss 1938.2390384707476
INFO:root:current train perplexity4.611281394958496
INFO:root:current mean train loss 1937.85827345642
INFO:root:current train perplexity4.604366302490234
INFO:root:current mean train loss 1937.5958171206225
INFO:root:current train perplexity4.604576587677002
INFO:root:current mean train loss 1936.838436087292
INFO:root:current train perplexity4.603405952453613
INFO:root:current mean train loss 1936.0225380014563
INFO:root:current train perplexity4.6033172607421875
INFO:root:current mean train loss 1935.0932278673188
INFO:root:current train perplexity4.603092670440674
INFO:root:current mean train loss 1934.1079735369076
INFO:root:current train perplexity4.598937511444092
INFO:root:current mean train loss 1933.2017341091537
INFO:root:current train perplexity4.593459129333496
INFO:root:current mean train loss 1934.6799884465036
INFO:root:current train perplexity4.59735631942749
INFO:root:current mean train loss 1935.3459222042827
INFO:root:current train perplexity4.5994553565979
INFO:root:current mean train loss 1935.0552108249872
INFO:root:current train perplexity4.601206302642822
INFO:root:current mean train loss 1934.9297520781904
INFO:root:current train perplexity4.601322174072266
INFO:root:current mean train loss 1934.0901734983765
INFO:root:current train perplexity4.597851276397705
INFO:root:current mean train loss 1933.691956708165
INFO:root:current train perplexity4.5965471267700195
INFO:root:current mean train loss 1934.7892713387082
INFO:root:current train perplexity4.597103118896484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.87s/it]
INFO:root:final mean train loss: 1934.5113718376217
INFO:root:final train perplexity: 4.598232746124268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 1940.9926428828678
INFO:root:eval perplexity: 4.805499076843262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2369.162820586076
INFO:root:eval perplexity: 6.941835880279541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [2:45:19<13:34:24, 588.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.1938268488104
INFO:root:current train perplexity4.563042163848877
INFO:root:current mean train loss 1906.734765884724
INFO:root:current train perplexity4.5161004066467285
INFO:root:current mean train loss 1912.442178938124
INFO:root:current train perplexity4.53480863571167
INFO:root:current mean train loss 1919.7342639411847
INFO:root:current train perplexity4.53933572769165
INFO:root:current mean train loss 1914.4738551905898
INFO:root:current train perplexity4.524957180023193
INFO:root:current mean train loss 1917.9999206958173
INFO:root:current train perplexity4.53267765045166
INFO:root:current mean train loss 1913.6712797297987
INFO:root:current train perplexity4.524837970733643
INFO:root:current mean train loss 1913.3225116245637
INFO:root:current train perplexity4.526632308959961
INFO:root:current mean train loss 1915.3466050431534
INFO:root:current train perplexity4.533764362335205
INFO:root:current mean train loss 1914.944103534405
INFO:root:current train perplexity4.532625198364258
INFO:root:current mean train loss 1914.532335169175
INFO:root:current train perplexity4.530826091766357
INFO:root:current mean train loss 1915.3740645386154
INFO:root:current train perplexity4.532608985900879
INFO:root:current mean train loss 1916.6902466768063
INFO:root:current train perplexity4.536344051361084
INFO:root:current mean train loss 1915.927753019745
INFO:root:current train perplexity4.535767555236816
INFO:root:current mean train loss 1915.7787441950973
INFO:root:current train perplexity4.535904407501221
INFO:root:current mean train loss 1915.1818899928173
INFO:root:current train perplexity4.5341362953186035
INFO:root:current mean train loss 1915.1369474872029
INFO:root:current train perplexity4.534369468688965
INFO:root:current mean train loss 1915.9504128953222
INFO:root:current train perplexity4.533389091491699
INFO:root:current mean train loss 1918.2214534565553
INFO:root:current train perplexity4.536986827850342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.49s/it]
INFO:root:final mean train loss: 1916.9185535856045
INFO:root:final train perplexity: 4.534874439239502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 1926.9133491245568
INFO:root:eval perplexity: 4.751091480255127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2359.534763200909
INFO:root:eval perplexity: 6.887391090393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:55:12<13:26:33, 590.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.398974609375
INFO:root:current train perplexity4.23911714553833
INFO:root:current mean train loss 1868.783972749256
INFO:root:current train perplexity4.434478282928467
INFO:root:current mean train loss 1878.0895245807926
INFO:root:current train perplexity4.426121234893799
INFO:root:current mean train loss 1890.142704998079
INFO:root:current train perplexity4.44683313369751
INFO:root:current mean train loss 1885.6042869285302
INFO:root:current train perplexity4.443970680236816
INFO:root:current mean train loss 1888.96541615099
INFO:root:current train perplexity4.446161270141602
INFO:root:current mean train loss 1888.5629229080578
INFO:root:current train perplexity4.4461140632629395
INFO:root:current mean train loss 1890.8107525764628
INFO:root:current train perplexity4.45067024230957
INFO:root:current mean train loss 1892.73995247598
INFO:root:current train perplexity4.457039833068848
INFO:root:current mean train loss 1897.1770201625086
INFO:root:current train perplexity4.465571880340576
INFO:root:current mean train loss 1897.4746801879276
INFO:root:current train perplexity4.466636657714844
INFO:root:current mean train loss 1898.1133298571833
INFO:root:current train perplexity4.46816873550415
INFO:root:current mean train loss 1897.9246222405018
INFO:root:current train perplexity4.468888759613037
INFO:root:current mean train loss 1897.5106900854585
INFO:root:current train perplexity4.467761039733887
INFO:root:current mean train loss 1898.6090292933998
INFO:root:current train perplexity4.468296527862549
INFO:root:current mean train loss 1899.7790249136992
INFO:root:current train perplexity4.47006368637085
INFO:root:current mean train loss 1900.567536370108
INFO:root:current train perplexity4.471887588500977
INFO:root:current mean train loss 1901.4502522309156
INFO:root:current train perplexity4.475370407104492
INFO:root:current mean train loss 1901.5940398578168
INFO:root:current train perplexity4.477581977844238
INFO:root:current mean train loss 1902.1782211824352
INFO:root:current train perplexity4.479815483093262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.28s/it]
INFO:root:final mean train loss: 1901.7265282427488
INFO:root:final train perplexity: 4.480863571166992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 1930.7287515410294
INFO:root:eval perplexity: 4.765774250030518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2364.2200057658742
INFO:root:eval perplexity: 6.91383171081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [3:05:01<13:15:58, 589.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.519248268821
INFO:root:current train perplexity4.474908351898193
INFO:root:current mean train loss 1879.2755727298925
INFO:root:current train perplexity4.439613342285156
INFO:root:current mean train loss 1896.769961245425
INFO:root:current train perplexity4.470180034637451
INFO:root:current mean train loss 1885.1457489203221
INFO:root:current train perplexity4.438636779785156
INFO:root:current mean train loss 1880.41947409101
INFO:root:current train perplexity4.422382831573486
INFO:root:current mean train loss 1885.0418062758172
INFO:root:current train perplexity4.4300031661987305
INFO:root:current mean train loss 1884.2285166062727
INFO:root:current train perplexity4.426296710968018
INFO:root:current mean train loss 1888.1781059962561
INFO:root:current train perplexity4.439913749694824
INFO:root:current mean train loss 1886.3021503086509
INFO:root:current train perplexity4.438812255859375
INFO:root:current mean train loss 1886.7051333346749
INFO:root:current train perplexity4.435069561004639
INFO:root:current mean train loss 1886.8539392878165
INFO:root:current train perplexity4.431262969970703
INFO:root:current mean train loss 1888.2305580723944
INFO:root:current train perplexity4.431782245635986
INFO:root:current mean train loss 1888.7164935972023
INFO:root:current train perplexity4.431257724761963
INFO:root:current mean train loss 1887.62640048444
INFO:root:current train perplexity4.428003787994385
INFO:root:current mean train loss 1886.3764279307863
INFO:root:current train perplexity4.423716068267822
INFO:root:current mean train loss 1886.282514494446
INFO:root:current train perplexity4.423850059509277
INFO:root:current mean train loss 1887.109552611552
INFO:root:current train perplexity4.425317287445068
INFO:root:current mean train loss 1886.5646777003485
INFO:root:current train perplexity4.424579620361328
INFO:root:current mean train loss 1886.9233501614383
INFO:root:current train perplexity4.425260066986084
INFO:root:current mean train loss 1886.893431410457
INFO:root:current train perplexity4.426774024963379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:51<00:00, 531.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:51<00:00, 531.66s/it]
INFO:root:final mean train loss: 1886.4100986005558
INFO:root:final train perplexity: 4.427063465118408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 1922.1605843618406
INFO:root:eval perplexity: 4.732863903045654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.71s/it]
INFO:root:eval mean loss: 2357.128550860899
INFO:root:eval perplexity: 6.8738508224487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [3:15:12<13:14:40, 596.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1834.6443559695513
INFO:root:current train perplexity4.297847747802734
INFO:root:current mean train loss 1861.8178394784172
INFO:root:current train perplexity4.349214553833008
INFO:root:current mean train loss 1873.1053773249541
INFO:root:current train perplexity4.360963821411133
INFO:root:current mean train loss 1872.07620284269
INFO:root:current train perplexity4.35406494140625
INFO:root:current mean train loss 1873.9599097736332
INFO:root:current train perplexity4.373780727386475
INFO:root:current mean train loss 1868.0475227200254
INFO:root:current train perplexity4.3643317222595215
INFO:root:current mean train loss 1872.1813819658403
INFO:root:current train perplexity4.37257194519043
INFO:root:current mean train loss 1871.7712328011355
INFO:root:current train perplexity4.36767053604126
INFO:root:current mean train loss 1872.4646853059353
INFO:root:current train perplexity4.369633197784424
INFO:root:current mean train loss 1873.8339495349107
INFO:root:current train perplexity4.3733978271484375
INFO:root:current mean train loss 1874.5352550576351
INFO:root:current train perplexity4.374810695648193
INFO:root:current mean train loss 1874.1852665098222
INFO:root:current train perplexity4.376622676849365
INFO:root:current mean train loss 1872.6776563445824
INFO:root:current train perplexity4.37550163269043
INFO:root:current mean train loss 1873.642838128384
INFO:root:current train perplexity4.374088287353516
INFO:root:current mean train loss 1875.3477290341057
INFO:root:current train perplexity4.377285957336426
INFO:root:current mean train loss 1874.7836806983278
INFO:root:current train perplexity4.378937721252441
INFO:root:current mean train loss 1875.475602322777
INFO:root:current train perplexity4.379432678222656
INFO:root:current mean train loss 1875.9938603335925
INFO:root:current train perplexity4.380683898925781
INFO:root:current mean train loss 1874.256217288608
INFO:root:current train perplexity4.377142429351807
INFO:root:current mean train loss 1872.56219989212
INFO:root:current train perplexity4.377344608306885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.18s/it]
INFO:root:final mean train loss: 1872.3685102977358
INFO:root:final train perplexity: 4.378308296203613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 1914.6503243953623
INFO:root:eval perplexity: 4.704204559326172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 2353.2386175926695
INFO:root:eval perplexity: 6.852018356323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [3:24:57<13:00:24, 592.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1867.9233136858259
INFO:root:current train perplexity4.355894565582275
INFO:root:current mean train loss 1870.7000693296775
INFO:root:current train perplexity4.336471080780029
INFO:root:current mean train loss 1864.296745300293
INFO:root:current train perplexity4.332975387573242
INFO:root:current mean train loss 1863.1335829831241
INFO:root:current train perplexity4.331648826599121
INFO:root:current mean train loss 1857.8082883065208
INFO:root:current train perplexity4.335328578948975
INFO:root:current mean train loss 1857.6975879257532
INFO:root:current train perplexity4.3328962326049805
INFO:root:current mean train loss 1857.6313056015388
INFO:root:current train perplexity4.33108377456665
INFO:root:current mean train loss 1860.7400076729912
INFO:root:current train perplexity4.3327202796936035
INFO:root:current mean train loss 1855.0767183392961
INFO:root:current train perplexity4.318814277648926
INFO:root:current mean train loss 1857.2707848967868
INFO:root:current train perplexity4.3231401443481445
INFO:root:current mean train loss 1856.7539504080107
INFO:root:current train perplexity4.323222637176514
INFO:root:current mean train loss 1856.340234670672
INFO:root:current train perplexity4.323626518249512
INFO:root:current mean train loss 1857.4193261990881
INFO:root:current train perplexity4.325796604156494
INFO:root:current mean train loss 1857.0425570777736
INFO:root:current train perplexity4.322965621948242
INFO:root:current mean train loss 1856.872708247258
INFO:root:current train perplexity4.321141719818115
INFO:root:current mean train loss 1857.834106759118
INFO:root:current train perplexity4.323212623596191
INFO:root:current mean train loss 1859.703114606332
INFO:root:current train perplexity4.326788902282715
INFO:root:current mean train loss 1858.9287814963652
INFO:root:current train perplexity4.326982021331787
INFO:root:current mean train loss 1859.8643002345643
INFO:root:current train perplexity4.33078670501709
INFO:root:current mean train loss 1859.6648270620647
INFO:root:current train perplexity4.33228874206543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.79s/it]
INFO:root:final mean train loss: 1858.8372585741006
INFO:root:final train perplexity: 4.3318328857421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 1905.52294921875
INFO:root:eval perplexity: 4.669608116149902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 2343.515080878075
INFO:root:eval perplexity: 6.797745704650879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:34:44<12:48:12, 590.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1866.6062078606592
INFO:root:current train perplexity4.3191633224487305
INFO:root:current mean train loss 1861.1538368180998
INFO:root:current train perplexity4.310096740722656
INFO:root:current mean train loss 1865.2345641419129
INFO:root:current train perplexity4.307461738586426
INFO:root:current mean train loss 1858.1921082361134
INFO:root:current train perplexity4.293658256530762
INFO:root:current mean train loss 1853.2470109548428
INFO:root:current train perplexity4.284302234649658
INFO:root:current mean train loss 1848.4941399858885
INFO:root:current train perplexity4.277634143829346
INFO:root:current mean train loss 1844.8247340572182
INFO:root:current train perplexity4.267010688781738
INFO:root:current mean train loss 1846.8638923911506
INFO:root:current train perplexity4.274808883666992
INFO:root:current mean train loss 1843.9551537722384
INFO:root:current train perplexity4.274303913116455
INFO:root:current mean train loss 1845.2312889922437
INFO:root:current train perplexity4.280087947845459
INFO:root:current mean train loss 1846.8159817911594
INFO:root:current train perplexity4.282188892364502
INFO:root:current mean train loss 1846.7700823875746
INFO:root:current train perplexity4.283184051513672
INFO:root:current mean train loss 1848.1307350991751
INFO:root:current train perplexity4.287600040435791
INFO:root:current mean train loss 1847.82617383097
INFO:root:current train perplexity4.284836292266846
INFO:root:current mean train loss 1847.2184689813785
INFO:root:current train perplexity4.28346586227417
INFO:root:current mean train loss 1847.4888203615453
INFO:root:current train perplexity4.282859802246094
INFO:root:current mean train loss 1847.5726207452694
INFO:root:current train perplexity4.284581184387207
INFO:root:current mean train loss 1847.6948750297431
INFO:root:current train perplexity4.288524627685547
INFO:root:current mean train loss 1848.2087123400377
INFO:root:current train perplexity4.29300594329834
INFO:root:current mean train loss 1847.5822307201913
INFO:root:current train perplexity4.291621208190918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.94s/it]
INFO:root:final mean train loss: 1846.9261161277104
INFO:root:final train perplexity: 4.291331768035889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.85s/it]
INFO:root:eval mean loss: 1899.5712202356217
INFO:root:eval perplexity: 4.647185802459717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2334.5585690762136
INFO:root:eval perplexity: 6.748134613037109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:44:48<12:43:35, 595.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.493701171875
INFO:root:current train perplexity4.194292068481445
INFO:root:current mean train loss 1827.0296823601973
INFO:root:current train perplexity4.22699499130249
INFO:root:current mean train loss 1825.756119090113
INFO:root:current train perplexity4.229428291320801
INFO:root:current mean train loss 1830.9281093499599
INFO:root:current train perplexity4.236372470855713
INFO:root:current mean train loss 1830.8813855229591
INFO:root:current train perplexity4.237617015838623
INFO:root:current mean train loss 1834.3080920203258
INFO:root:current train perplexity4.240945816040039
INFO:root:current mean train loss 1832.603341719033
INFO:root:current train perplexity4.2383036613464355
INFO:root:current mean train loss 1831.8220713941357
INFO:root:current train perplexity4.241102695465088
INFO:root:current mean train loss 1832.237236794461
INFO:root:current train perplexity4.241434097290039
INFO:root:current mean train loss 1828.9716922644413
INFO:root:current train perplexity4.234169960021973
INFO:root:current mean train loss 1829.1455549607583
INFO:root:current train perplexity4.23043966293335
INFO:root:current mean train loss 1829.8943834320837
INFO:root:current train perplexity4.234670162200928
INFO:root:current mean train loss 1830.1613461989764
INFO:root:current train perplexity4.237792491912842
INFO:root:current mean train loss 1830.384409074303
INFO:root:current train perplexity4.239297866821289
INFO:root:current mean train loss 1831.0797688528996
INFO:root:current train perplexity4.241387844085693
INFO:root:current mean train loss 1830.5864881215605
INFO:root:current train perplexity4.241098880767822
INFO:root:current mean train loss 1830.175609557022
INFO:root:current train perplexity4.24055290222168
INFO:root:current mean train loss 1831.808596341437
INFO:root:current train perplexity4.241435527801514
INFO:root:current mean train loss 1832.1583466383515
INFO:root:current train perplexity4.241841793060303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.25s/it]
INFO:root:final mean train loss: 1832.8150717869469
INFO:root:final train perplexity: 4.243838787078857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 1894.826260614057
INFO:root:eval perplexity: 4.629385948181152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2336.368548886996
INFO:root:eval perplexity: 6.758130073547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:54:41<12:32:48, 594.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.3623918805804
INFO:root:current train perplexity4.163684844970703
INFO:root:current mean train loss 1810.456814489632
INFO:root:current train perplexity4.162749290466309
INFO:root:current mean train loss 1816.3597188018946
INFO:root:current train perplexity4.1735382080078125
INFO:root:current mean train loss 1810.622283438518
INFO:root:current train perplexity4.166413307189941
INFO:root:current mean train loss 1802.8820422873157
INFO:root:current train perplexity4.148910999298096
INFO:root:current mean train loss 1805.1168412729598
INFO:root:current train perplexity4.158860206604004
INFO:root:current mean train loss 1810.602945896507
INFO:root:current train perplexity4.171689510345459
INFO:root:current mean train loss 1812.4712991458186
INFO:root:current train perplexity4.180460453033447
INFO:root:current mean train loss 1814.5734686301987
INFO:root:current train perplexity4.185754299163818
INFO:root:current mean train loss 1817.0308689845042
INFO:root:current train perplexity4.193948745727539
INFO:root:current mean train loss 1818.2832614326667
INFO:root:current train perplexity4.197751998901367
INFO:root:current mean train loss 1818.776667456209
INFO:root:current train perplexity4.1981048583984375
INFO:root:current mean train loss 1819.0438334568532
INFO:root:current train perplexity4.19740104675293
INFO:root:current mean train loss 1817.4745323222014
INFO:root:current train perplexity4.194230556488037
INFO:root:current mean train loss 1817.9147672456634
INFO:root:current train perplexity4.1962080001831055
INFO:root:current mean train loss 1819.4960071586502
INFO:root:current train perplexity4.199363708496094
INFO:root:current mean train loss 1820.5345011570473
INFO:root:current train perplexity4.203121185302734
INFO:root:current mean train loss 1820.350765717679
INFO:root:current train perplexity4.20308256149292
INFO:root:current mean train loss 1821.0732725193043
INFO:root:current train perplexity4.205734729766846
INFO:root:current mean train loss 1821.0353832354892
INFO:root:current train perplexity4.204400539398193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.64s/it]
INFO:root:final mean train loss: 1821.2740914349115
INFO:root:final train perplexity: 4.205387115478516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 1881.2764970495346
INFO:root:eval perplexity: 4.578933238983154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 2323.615629155585
INFO:root:eval perplexity: 6.68801212310791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [4:04:30<12:21:08, 592.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.3877410888672
INFO:root:current train perplexity4.113832950592041
INFO:root:current mean train loss 1817.0648537912678
INFO:root:current train perplexity4.167421340942383
INFO:root:current mean train loss 1811.3665139334541
INFO:root:current train perplexity4.147838592529297
INFO:root:current mean train loss 1808.676766101225
INFO:root:current train perplexity4.144867420196533
INFO:root:current mean train loss 1815.217360874392
INFO:root:current train perplexity4.169864654541016
INFO:root:current mean train loss 1810.8379323245915
INFO:root:current train perplexity4.16288423538208
INFO:root:current mean train loss 1810.3041700705503
INFO:root:current train perplexity4.160705089569092
INFO:root:current mean train loss 1805.2360160363971
INFO:root:current train perplexity4.158468246459961
INFO:root:current mean train loss 1807.009272306868
INFO:root:current train perplexity4.160224914550781
INFO:root:current mean train loss 1806.5958538633404
INFO:root:current train perplexity4.160808563232422
INFO:root:current mean train loss 1809.0397727489471
INFO:root:current train perplexity4.16347074508667
INFO:root:current mean train loss 1809.109644662443
INFO:root:current train perplexity4.161344051361084
INFO:root:current mean train loss 1810.7846325643702
INFO:root:current train perplexity4.1647114753723145
INFO:root:current mean train loss 1811.284014560665
INFO:root:current train perplexity4.1642746925354
INFO:root:current mean train loss 1810.6149862910925
INFO:root:current train perplexity4.166088104248047
INFO:root:current mean train loss 1809.9491541104053
INFO:root:current train perplexity4.162811279296875
INFO:root:current mean train loss 1811.0199144485548
INFO:root:current train perplexity4.165673732757568
INFO:root:current mean train loss 1811.5283589728194
INFO:root:current train perplexity4.166759490966797
INFO:root:current mean train loss 1810.263093914902
INFO:root:current train perplexity4.166077136993408
INFO:root:current mean train loss 1809.819114129905
INFO:root:current train perplexity4.164636135101318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.93s/it]
INFO:root:final mean train loss: 1809.1676573260409
INFO:root:final train perplexity: 4.165425777435303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 1883.4225247430463
INFO:root:eval perplexity: 4.586886405944824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 2327.2760910142397
INFO:root:eval perplexity: 6.708064079284668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [4:14:12<12:07:06, 589.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1775.4468190262958
INFO:root:current train perplexity4.125004291534424
INFO:root:current mean train loss 1781.7653834566156
INFO:root:current train perplexity4.090503692626953
INFO:root:current mean train loss 1786.4470873314315
INFO:root:current train perplexity4.102399826049805
INFO:root:current mean train loss 1784.731970465428
INFO:root:current train perplexity4.106420040130615
INFO:root:current mean train loss 1787.841436200131
INFO:root:current train perplexity4.111998081207275
INFO:root:current mean train loss 1789.1156908412518
INFO:root:current train perplexity4.108335018157959
INFO:root:current mean train loss 1793.1548099130996
INFO:root:current train perplexity4.121307849884033
INFO:root:current mean train loss 1794.03894207706
INFO:root:current train perplexity4.11899995803833
INFO:root:current mean train loss 1796.3989166368629
INFO:root:current train perplexity4.122580528259277
INFO:root:current mean train loss 1796.501957795065
INFO:root:current train perplexity4.1215386390686035
INFO:root:current mean train loss 1796.684672799967
INFO:root:current train perplexity4.1237568855285645
INFO:root:current mean train loss 1796.2794238666397
INFO:root:current train perplexity4.124190807342529
INFO:root:current mean train loss 1794.3044047021367
INFO:root:current train perplexity4.119123458862305
INFO:root:current mean train loss 1796.7712200258668
INFO:root:current train perplexity4.124598503112793
INFO:root:current mean train loss 1795.876840711881
INFO:root:current train perplexity4.122629165649414
INFO:root:current mean train loss 1797.3517919066353
INFO:root:current train perplexity4.125954627990723
INFO:root:current mean train loss 1797.6862026030956
INFO:root:current train perplexity4.125584602355957
INFO:root:current mean train loss 1798.6137290047477
INFO:root:current train perplexity4.127995491027832
INFO:root:current mean train loss 1798.381079247437
INFO:root:current train perplexity4.127943515777588
INFO:root:current mean train loss 1798.9973676584234
INFO:root:current train perplexity4.129918098449707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.36s/it]
INFO:root:final mean train loss: 1798.4775569144367
INFO:root:final train perplexity: 4.130455493927002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 1893.427284619487
INFO:root:eval perplexity: 4.624150276184082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2342.7854570970467
INFO:root:eval perplexity: 6.793690204620361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [4:24:09<11:59:58, 591.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.8527558425378
INFO:root:current train perplexity4.037532329559326
INFO:root:current mean train loss 1777.2999993819224
INFO:root:current train perplexity4.058628082275391
INFO:root:current mean train loss 1779.7545620230742
INFO:root:current train perplexity4.078019142150879
INFO:root:current mean train loss 1774.7903633330786
INFO:root:current train perplexity4.067722320556641
INFO:root:current mean train loss 1778.8368165128616
INFO:root:current train perplexity4.078430652618408
INFO:root:current mean train loss 1780.725121501526
INFO:root:current train perplexity4.081361293792725
INFO:root:current mean train loss 1781.938704377612
INFO:root:current train perplexity4.085179328918457
INFO:root:current mean train loss 1785.1220131423668
INFO:root:current train perplexity4.088864803314209
INFO:root:current mean train loss 1790.6090518978092
INFO:root:current train perplexity4.108471870422363
INFO:root:current mean train loss 1799.669808214542
INFO:root:current train perplexity4.13143253326416
INFO:root:current mean train loss 1804.9867658705252
INFO:root:current train perplexity4.150092124938965
INFO:root:current mean train loss 1809.7914126170526
INFO:root:current train perplexity4.166996955871582
INFO:root:current mean train loss 1815.1346518997168
INFO:root:current train perplexity4.186525821685791
INFO:root:current mean train loss 1820.6124637025093
INFO:root:current train perplexity4.206441402435303
INFO:root:current mean train loss 1825.575092498821
INFO:root:current train perplexity4.2241411209106445
INFO:root:current mean train loss 1829.874910053454
INFO:root:current train perplexity4.235715866088867
INFO:root:current mean train loss 1832.6475005477703
INFO:root:current train perplexity4.246188163757324
INFO:root:current mean train loss 1835.7234247791346
INFO:root:current train perplexity4.255692958831787
INFO:root:current mean train loss 1837.5788806796202
INFO:root:current train perplexity4.2620134353637695
INFO:root:current mean train loss 1840.1797434852608
INFO:root:current train perplexity4.266154766082764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.94s/it]
INFO:root:final mean train loss: 1839.6838006477915
INFO:root:final train perplexity: 4.266890525817871
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2034.3238386871121
INFO:root:eval perplexity: 5.182262897491455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2467.2889798211713
INFO:root:eval perplexity: 7.521884918212891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:33:55<11:47:54, 589.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4473.140104166667
INFO:root:current train perplexity34.14221954345703
INFO:root:current mean train loss 6575.391805245536
INFO:root:current train perplexity177.30056762695312
INFO:root:current mean train loss 7315.357922585227
INFO:root:current train perplexity317.57623291015625
INFO:root:current mean train loss 7274.21123046875
INFO:root:current train perplexity306.6826171875
INFO:root:current mean train loss 7157.81791015625
INFO:root:current train perplexity280.7723388671875
INFO:root:current mean train loss 7080.37423658288
INFO:root:current train perplexity263.4655456542969
INFO:root:current mean train loss 7014.439314959491
INFO:root:current train perplexity251.8572540283203
INFO:root:current mean train loss 6971.49013734879
INFO:root:current train perplexity243.00848388671875
INFO:root:current mean train loss 6937.477426339286
INFO:root:current train perplexity235.57064819335938
INFO:root:current mean train loss 6899.420747696314
INFO:root:current train perplexity229.22100830078125
INFO:root:current mean train loss 6876.144208303052
INFO:root:current train perplexity224.05422973632812
INFO:root:current mean train loss 6847.614477642952
INFO:root:current train perplexity220.34207153320312
INFO:root:current mean train loss 6829.473043045343
INFO:root:current train perplexity217.62936401367188
INFO:root:current mean train loss 6813.332273082387
INFO:root:current train perplexity215.2232666015625
INFO:root:current mean train loss 6802.760193326271
INFO:root:current train perplexity213.2828826904297
INFO:root:current mean train loss 6794.041420510913
INFO:root:current train perplexity211.5672149658203
INFO:root:current mean train loss 6786.896561625466
INFO:root:current train perplexity210.16526794433594
INFO:root:current mean train loss 6777.997981954225
INFO:root:current train perplexity208.86212158203125
INFO:root:current mean train loss 6768.842881770834
INFO:root:current train perplexity207.5773468017578
INFO:root:current mean train loss 6760.9371402788765
INFO:root:current train perplexity206.51268005371094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.01s/it]
INFO:root:final mean train loss: 6758.307908851212
INFO:root:final train perplexity: 206.43972778320312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 6467.461837876773
INFO:root:eval perplexity: 186.8868865966797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it]
INFO:root:eval mean loss: 6572.2243539796655
INFO:root:eval perplexity: 215.92823791503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:43:40<11:36:26, 588.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6671.1525931980295
INFO:root:current train perplexity189.5176239013672
INFO:root:current mean train loss 6662.795323689778
INFO:root:current train perplexity188.87258911132812
INFO:root:current mean train loss 6649.30002541738
INFO:root:current train perplexity189.0989532470703
INFO:root:current mean train loss 6639.043435855788
INFO:root:current train perplexity188.93563842773438
INFO:root:current mean train loss 6640.738263386052
INFO:root:current train perplexity189.05865478515625
INFO:root:current mean train loss 6656.711307010135
INFO:root:current train perplexity189.4306182861328
INFO:root:current mean train loss 6647.40010979272
INFO:root:current train perplexity189.21026611328125
INFO:root:current mean train loss 6647.918462579901
INFO:root:current train perplexity189.164794921875
INFO:root:current mean train loss 6649.925849675063
INFO:root:current train perplexity189.1094207763672
INFO:root:current mean train loss 6647.198947045111
INFO:root:current train perplexity189.0359344482422
INFO:root:current mean train loss 6650.121612884186
INFO:root:current train perplexity189.06875610351562
INFO:root:current mean train loss 6653.577444191747
INFO:root:current train perplexity189.26177978515625
INFO:root:current mean train loss 6652.526325993494
INFO:root:current train perplexity189.2913818359375
INFO:root:current mean train loss 6653.856593691069
INFO:root:current train perplexity189.4060516357422
INFO:root:current mean train loss 6649.602978581078
INFO:root:current train perplexity189.1943817138672
INFO:root:current mean train loss 6645.1414454474525
INFO:root:current train perplexity188.9997100830078
INFO:root:current mean train loss 6647.095956500259
INFO:root:current train perplexity189.08497619628906
INFO:root:current mean train loss 6651.058187212263
INFO:root:current train perplexity189.25267028808594
INFO:root:current mean train loss 6650.813565857063
INFO:root:current train perplexity189.24337768554688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.09s/it]
INFO:root:final mean train loss: 6648.29756174554
INFO:root:final train perplexity: 189.2838134765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 6470.864015403369
INFO:root:eval perplexity: 187.40187072753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 6576.9140218098955
INFO:root:eval perplexity: 216.7578582763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:53:25<11:25:14, 587.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6765.040256076389
INFO:root:current train perplexity188.4442901611328
INFO:root:current mean train loss 6641.551202336583
INFO:root:current train perplexity188.47987365722656
INFO:root:current mean train loss 6635.8381709778705
INFO:root:current train perplexity188.53839111328125
INFO:root:current mean train loss 6647.86616669195
INFO:root:current train perplexity188.58973693847656
INFO:root:current mean train loss 6650.510998863463
INFO:root:current train perplexity188.6019744873047
INFO:root:current mean train loss 6655.460512532232
INFO:root:current train perplexity188.69947814941406
INFO:root:current mean train loss 6642.869918347188
INFO:root:current train perplexity188.28701782226562
INFO:root:current mean train loss 6647.632360030633
INFO:root:current train perplexity188.1842498779297
INFO:root:current mean train loss 6640.552885868936
INFO:root:current train perplexity188.04412841796875
INFO:root:current mean train loss 6645.917460593716
INFO:root:current train perplexity188.24635314941406
INFO:root:current mean train loss 6641.560806743218
INFO:root:current train perplexity187.67462158203125
INFO:root:current mean train loss 6630.948664425298
INFO:root:current train perplexity187.30404663085938
INFO:root:current mean train loss 6631.486258255144
INFO:root:current train perplexity187.36337280273438
INFO:root:current mean train loss 6630.178813517595
INFO:root:current train perplexity187.47105407714844
INFO:root:current mean train loss 6630.948066489421
INFO:root:current train perplexity187.28717041015625
INFO:root:current mean train loss 6629.821963401881
INFO:root:current train perplexity187.1571044921875
INFO:root:current mean train loss 6631.050694457932
INFO:root:current train perplexity187.10284423828125
INFO:root:current mean train loss 6634.895131244514
INFO:root:current train perplexity187.11436462402344
INFO:root:current mean train loss 6634.120706687914
INFO:root:current train perplexity186.92405700683594
INFO:root:current mean train loss 6634.390394287749
INFO:root:current train perplexity186.83030700683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.56s/it]
INFO:root:final mean train loss: 6631.771349438981
INFO:root:final train perplexity: 186.8327178955078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 6453.4821742713875
INFO:root:eval perplexity: 184.78579711914062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.30s/it]
INFO:root:eval mean loss: 6562.446734922152
INFO:root:eval perplexity: 214.20843505859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [5:03:09<11:14:24, 586.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6641.662184495192
INFO:root:current train perplexity187.380615234375
INFO:root:current mean train loss 6669.9461999317955
INFO:root:current train perplexity185.45498657226562
INFO:root:current mean train loss 6654.932111621958
INFO:root:current train perplexity186.05606079101562
INFO:root:current mean train loss 6639.5188153038725
INFO:root:current train perplexity186.5478515625
INFO:root:current mean train loss 6653.401591842723
INFO:root:current train perplexity186.58120727539062
INFO:root:current mean train loss 6651.0736942653875
INFO:root:current train perplexity186.50035095214844
INFO:root:current mean train loss 6636.54260916908
INFO:root:current train perplexity185.82455444335938
INFO:root:current mean train loss 6630.994557614497
INFO:root:current train perplexity185.67823791503906
INFO:root:current mean train loss 6636.465805534011
INFO:root:current train perplexity185.6217498779297
INFO:root:current mean train loss 6627.376706347867
INFO:root:current train perplexity185.39405822753906
INFO:root:current mean train loss 6626.894344218294
INFO:root:current train perplexity185.43499755859375
INFO:root:current mean train loss 6620.65733497308
INFO:root:current train perplexity185.3100128173828
INFO:root:current mean train loss 6620.01640680758
INFO:root:current train perplexity185.35084533691406
INFO:root:current mean train loss 6621.223576840592
INFO:root:current train perplexity185.33660888671875
INFO:root:current mean train loss 6618.718952708626
INFO:root:current train perplexity185.24649047851562
INFO:root:current mean train loss 6619.1477735526905
INFO:root:current train perplexity185.36595153808594
INFO:root:current mean train loss 6622.86427943381
INFO:root:current train perplexity185.57174682617188
INFO:root:current mean train loss 6627.163370815379
INFO:root:current train perplexity185.82180786132812
INFO:root:current mean train loss 6627.639681060891
INFO:root:current train perplexity186.13600158691406
INFO:root:current mean train loss 6627.775549582603
INFO:root:current train perplexity186.2742462158203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:43<00:00, 523.03s/it]
INFO:root:final mean train loss: 6628.703948897662
INFO:root:final train perplexity: 186.38131713867188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it]
INFO:root:eval mean loss: 6459.034276651152
INFO:root:eval perplexity: 185.6175079345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 6570.237754875887
INFO:root:eval perplexity: 215.57762145996094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [5:13:09<11:09:19, 590.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6656.236066951308
INFO:root:current train perplexity189.84767150878906
INFO:root:current mean train loss 6663.575086046766
INFO:root:current train perplexity189.3813018798828
INFO:root:current mean train loss 6691.374344939558
INFO:root:current train perplexity189.02774047851562
INFO:root:current mean train loss 6668.589825243714
INFO:root:current train perplexity188.5131378173828
INFO:root:current mean train loss 6639.74806010158
INFO:root:current train perplexity187.59034729003906
INFO:root:current mean train loss 6636.31530019855
INFO:root:current train perplexity187.5156707763672
INFO:root:current mean train loss 6634.079540484059
INFO:root:current train perplexity187.45791625976562
INFO:root:current mean train loss 6633.113757044919
INFO:root:current train perplexity187.71490478515625
INFO:root:current mean train loss 6632.910603406732
INFO:root:current train perplexity187.67355346679688
INFO:root:current mean train loss 6636.190523408503
INFO:root:current train perplexity187.46363830566406
INFO:root:current mean train loss 6631.639895621105
INFO:root:current train perplexity187.1995849609375
INFO:root:current mean train loss 6628.304879736713
INFO:root:current train perplexity186.9345703125
INFO:root:current mean train loss 6629.840012664672
INFO:root:current train perplexity186.80465698242188
INFO:root:current mean train loss 6629.700985361015
INFO:root:current train perplexity186.43580627441406
INFO:root:current mean train loss 6628.080972799723
INFO:root:current train perplexity186.2265625
INFO:root:current mean train loss 6626.067727109325
INFO:root:current train perplexity186.1705322265625
INFO:root:current mean train loss 6628.4235752173045
INFO:root:current train perplexity186.30543518066406
INFO:root:current mean train loss 6628.905994233631
INFO:root:current train perplexity186.16796875
INFO:root:current mean train loss 6630.43771565976
INFO:root:current train perplexity186.1654815673828
INFO:root:current mean train loss 6629.196235283711
INFO:root:current train perplexity185.97781372070312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.28s/it]
INFO:root:final mean train loss: 6625.818004675484
INFO:root:final train perplexity: 185.9576873779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 6435.292795600621
INFO:root:eval perplexity: 182.08749389648438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 6547.537717995068
INFO:root:eval perplexity: 211.61241149902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [5:22:55<10:57:59, 589.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6586.641178385416
INFO:root:current train perplexity182.62757873535156
INFO:root:current mean train loss 6576.3436279296875
INFO:root:current train perplexity182.47515869140625
INFO:root:current mean train loss 6590.290123572717
INFO:root:current train perplexity182.67721557617188
INFO:root:current mean train loss 6584.390079752604
INFO:root:current train perplexity182.70143127441406
INFO:root:current mean train loss 6583.52275390625
INFO:root:current train perplexity182.6496124267578
INFO:root:current mean train loss 6581.67668195452
INFO:root:current train perplexity182.1810302734375
INFO:root:current mean train loss 6576.207157019413
INFO:root:current train perplexity182.08958435058594
INFO:root:current mean train loss 6589.498131681744
INFO:root:current train perplexity182.10043334960938
INFO:root:current mean train loss 6587.417036473474
INFO:root:current train perplexity181.8951873779297
INFO:root:current mean train loss 6589.812689717611
INFO:root:current train perplexity181.90438842773438
INFO:root:current mean train loss 6593.535015293337
INFO:root:current train perplexity181.90057373046875
INFO:root:current mean train loss 6596.308272578798
INFO:root:current train perplexity181.8997039794922
INFO:root:current mean train loss 6595.704213944692
INFO:root:current train perplexity181.892333984375
INFO:root:current mean train loss 6598.727013442096
INFO:root:current train perplexity181.83978271484375
INFO:root:current mean train loss 6602.414257143621
INFO:root:current train perplexity181.79478454589844
INFO:root:current mean train loss 6602.580211150341
INFO:root:current train perplexity181.55567932128906
INFO:root:current mean train loss 6600.602837325866
INFO:root:current train perplexity181.3507080078125
INFO:root:current mean train loss 6598.005396617543
INFO:root:current train perplexity181.0979461669922
INFO:root:current mean train loss 6593.15542280956
INFO:root:current train perplexity180.7970733642578
INFO:root:current mean train loss 6589.633204370615
INFO:root:current train perplexity180.51495361328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.90s/it]
INFO:root:final mean train loss: 6587.569975283071
INFO:root:final train perplexity: 180.4320068359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 6378.78580902316
INFO:root:eval perplexity: 173.953369140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.07s/it]
INFO:root:eval mean loss: 6497.2620260901485
INFO:root:eval perplexity: 203.08795166015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [5:32:39<10:46:29, 587.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6580.21822367086
INFO:root:current train perplexity175.27850341796875
INFO:root:current mean train loss 6545.828748455156
INFO:root:current train perplexity175.98733520507812
INFO:root:current mean train loss 6548.662201037906
INFO:root:current train perplexity176.11309814453125
INFO:root:current mean train loss 6546.702262412964
INFO:root:current train perplexity175.77792358398438
INFO:root:current mean train loss 6550.331632026337
INFO:root:current train perplexity175.51150512695312
INFO:root:current mean train loss 6542.917298526863
INFO:root:current train perplexity175.2044677734375
INFO:root:current mean train loss 6541.115146383401
INFO:root:current train perplexity175.1605224609375
INFO:root:current mean train loss 6545.426251307111
INFO:root:current train perplexity174.98446655273438
INFO:root:current mean train loss 6548.46741042795
INFO:root:current train perplexity175.00674438476562
INFO:root:current mean train loss 6550.959799509819
INFO:root:current train perplexity175.00106811523438
INFO:root:current mean train loss 6546.994925411299
INFO:root:current train perplexity174.76156616210938
INFO:root:current mean train loss 6540.114236240176
INFO:root:current train perplexity174.6087188720703
INFO:root:current mean train loss 6540.691636816636
INFO:root:current train perplexity174.5198974609375
INFO:root:current mean train loss 6538.626373357502
INFO:root:current train perplexity174.2525634765625
INFO:root:current mean train loss 6541.678781022554
INFO:root:current train perplexity174.28355407714844
INFO:root:current mean train loss 6544.25339474675
INFO:root:current train perplexity174.2244873046875
INFO:root:current mean train loss 6544.599950327501
INFO:root:current train perplexity174.20254516601562
INFO:root:current mean train loss 6544.388039609858
INFO:root:current train perplexity174.1522979736328
INFO:root:current mean train loss 6546.796653361414
INFO:root:current train perplexity174.26095581054688
INFO:root:current mean train loss 6544.462799242065
INFO:root:current train perplexity174.162109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.73s/it]
INFO:root:final mean train loss: 6542.538836580662
INFO:root:final train perplexity: 174.13661193847656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 6376.331970647717
INFO:root:eval perplexity: 173.6085662841797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it]
INFO:root:eval mean loss: 6493.908816073803
INFO:root:eval perplexity: 202.53179931640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:42:22<10:34:57, 586.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6593.63480198637
INFO:root:current train perplexity172.34906005859375
INFO:root:current mean train loss 6570.081462427513
INFO:root:current train perplexity173.0044708251953
INFO:root:current mean train loss 6549.812518269026
INFO:root:current train perplexity173.0543975830078
INFO:root:current mean train loss 6538.190492891418
INFO:root:current train perplexity172.9925079345703
INFO:root:current mean train loss 6536.964977187184
INFO:root:current train perplexity173.26394653320312
INFO:root:current mean train loss 6534.000628847064
INFO:root:current train perplexity173.07345581054688
INFO:root:current mean train loss 6537.5168956569705
INFO:root:current train perplexity173.28717041015625
INFO:root:current mean train loss 6546.818182265428
INFO:root:current train perplexity173.28170776367188
INFO:root:current mean train loss 6549.2220811267825
INFO:root:current train perplexity173.12950134277344
INFO:root:current mean train loss 6547.798164966361
INFO:root:current train perplexity173.14295959472656
INFO:root:current mean train loss 6540.542003345664
INFO:root:current train perplexity173.0401153564453
INFO:root:current mean train loss 6537.956472630078
INFO:root:current train perplexity173.0872344970703
INFO:root:current mean train loss 6537.545195825686
INFO:root:current train perplexity173.04415893554688
INFO:root:current mean train loss 6537.328725368768
INFO:root:current train perplexity172.7794952392578
INFO:root:current mean train loss 6536.832953559027
INFO:root:current train perplexity172.51119995117188
INFO:root:current mean train loss 6536.30693622814
INFO:root:current train perplexity172.27674865722656
INFO:root:current mean train loss 6536.540195865924
INFO:root:current train perplexity172.0030059814453
INFO:root:current mean train loss 6533.196815176021
INFO:root:current train perplexity171.58522033691406
INFO:root:current mean train loss 6524.8936291929285
INFO:root:current train perplexity171.1227569580078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.46s/it]
INFO:root:final mean train loss: 6516.5877933627235
INFO:root:final train perplexity: 170.6088104248047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 6271.911562222961
INFO:root:eval perplexity: 159.5494384765625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 6387.886711824025
INFO:root:eval perplexity: 185.71055603027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:52:05<10:24:13, 585.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6622.689497514205
INFO:root:current train perplexity170.225830078125
INFO:root:current mean train loss 6462.785283818976
INFO:root:current train perplexity163.4619903564453
INFO:root:current mean train loss 6456.385476062648
INFO:root:current train perplexity163.0399932861328
INFO:root:current mean train loss 6462.833001532355
INFO:root:current train perplexity163.25198364257812
INFO:root:current mean train loss 6477.354703657238
INFO:root:current train perplexity163.6036834716797
INFO:root:current mean train loss 6476.301667036142
INFO:root:current train perplexity163.6795196533203
INFO:root:current mean train loss 6475.005271999028
INFO:root:current train perplexity163.4389190673828
INFO:root:current mean train loss 6466.586420287227
INFO:root:current train perplexity163.24615478515625
INFO:root:current mean train loss 6466.621899323752
INFO:root:current train perplexity163.25534057617188
INFO:root:current mean train loss 6472.092153304233
INFO:root:current train perplexity163.3246307373047
INFO:root:current mean train loss 6470.300510304618
INFO:root:current train perplexity163.3020477294922
INFO:root:current mean train loss 6461.658739750928
INFO:root:current train perplexity162.8292999267578
INFO:root:current mean train loss 6461.860880567455
INFO:root:current train perplexity162.86758422851562
INFO:root:current mean train loss 6460.641591878814
INFO:root:current train perplexity162.689208984375
INFO:root:current mean train loss 6457.586852465007
INFO:root:current train perplexity162.5500946044922
INFO:root:current mean train loss 6457.86848753671
INFO:root:current train perplexity162.5960693359375
INFO:root:current mean train loss 6456.545382877968
INFO:root:current train perplexity162.59056091308594
INFO:root:current mean train loss 6458.250137266675
INFO:root:current train perplexity162.61863708496094
INFO:root:current mean train loss 6461.680005920848
INFO:root:current train perplexity162.88490295410156
INFO:root:current mean train loss 6460.61934631124
INFO:root:current train perplexity162.91317749023438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.16s/it]
INFO:root:final mean train loss: 6458.389064986959
INFO:root:final train perplexity: 162.95497131347656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 6284.314387328236
INFO:root:eval perplexity: 161.15789794921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 6401.27643991024
INFO:root:eval perplexity: 187.75535583496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [6:01:48<10:13:56, 584.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6307.956316266741
INFO:root:current train perplexity159.03164672851562
INFO:root:current mean train loss 6497.625408172607
INFO:root:current train perplexity163.85101318359375
INFO:root:current mean train loss 6465.773491039611
INFO:root:current train perplexity162.97921752929688
INFO:root:current mean train loss 6452.053834496475
INFO:root:current train perplexity163.590576171875
INFO:root:current mean train loss 6452.686497198087
INFO:root:current train perplexity164.27330017089844
INFO:root:current mean train loss 6468.262198708274
INFO:root:current train perplexity164.75425720214844
INFO:root:current mean train loss 6472.864400098279
INFO:root:current train perplexity164.9605255126953
INFO:root:current mean train loss 6471.139342591003
INFO:root:current train perplexity165.01898193359375
INFO:root:current mean train loss 6477.1044373443165
INFO:root:current train perplexity165.17295837402344
INFO:root:current mean train loss 6484.543847445784
INFO:root:current train perplexity165.2939910888672
INFO:root:current mean train loss 6488.488475992522
INFO:root:current train perplexity165.17343139648438
INFO:root:current mean train loss 6483.804366307902
INFO:root:current train perplexity165.1048583984375
INFO:root:current mean train loss 6477.531251988115
INFO:root:current train perplexity165.05392456054688
INFO:root:current mean train loss 6479.797404829278
INFO:root:current train perplexity164.98348999023438
INFO:root:current mean train loss 6480.717885591736
INFO:root:current train perplexity164.96658325195312
INFO:root:current mean train loss 6494.757682760349
INFO:root:current train perplexity166.60923767089844
INFO:root:current mean train loss 6516.5939935407705
INFO:root:current train perplexity169.75601196289062
INFO:root:current mean train loss 6538.958662527579
INFO:root:current train perplexity172.4197540283203
INFO:root:current mean train loss 6549.605445511232
INFO:root:current train perplexity174.5467071533203
INFO:root:current mean train loss 6558.283849945701
INFO:root:current train perplexity175.98464965820312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.37s/it]
INFO:root:final mean train loss: 6557.1522326986415
INFO:root:final train perplexity: 176.15499877929688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it]
INFO:root:eval mean loss: 6407.570587807513
INFO:root:eval perplexity: 178.050537109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 6501.637511774158
INFO:root:eval perplexity: 203.8160400390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [6:11:33<10:04:08, 584.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6533.760894097222
INFO:root:current train perplexity173.13528442382812
INFO:root:current mean train loss 6513.546255387931
INFO:root:current train perplexity170.39100646972656
INFO:root:current mean train loss 6519.289084422831
INFO:root:current train perplexity169.7938995361328
INFO:root:current mean train loss 6518.040949105525
INFO:root:current train perplexity168.36959838867188
INFO:root:current mean train loss 6493.84717674684
INFO:root:current train perplexity167.1422119140625
INFO:root:current mean train loss 6477.722356113819
INFO:root:current train perplexity166.00360107421875
INFO:root:current mean train loss 6478.9793551659395
INFO:root:current train perplexity165.22999572753906
INFO:root:current mean train loss 6480.417790478188
INFO:root:current train perplexity165.8296356201172
INFO:root:current mean train loss 6491.496524824334
INFO:root:current train perplexity167.17193603515625
INFO:root:current mean train loss 6489.46880993717
INFO:root:current train perplexity167.08689880371094
INFO:root:current mean train loss 6486.541747813248
INFO:root:current train perplexity166.95892333984375
INFO:root:current mean train loss 6487.994813131141
INFO:root:current train perplexity167.12149047851562
INFO:root:current mean train loss 6489.809386373619
INFO:root:current train perplexity167.81150817871094
INFO:root:current mean train loss 6495.259850212012
INFO:root:current train perplexity168.0657501220703
INFO:root:current mean train loss 6497.348742971453
INFO:root:current train perplexity168.2001190185547
INFO:root:current mean train loss 6496.9141908120955
INFO:root:current train perplexity168.10157775878906
INFO:root:current mean train loss 6498.448031736797
INFO:root:current train perplexity167.93638610839844
INFO:root:current mean train loss 6497.474218190366
INFO:root:current train perplexity167.67864990234375
INFO:root:current mean train loss 6495.509081766599
INFO:root:current train perplexity167.41404724121094
INFO:root:current mean train loss 6494.357223801012
INFO:root:current train perplexity167.28485107421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.40s/it]
INFO:root:final mean train loss: 6491.202075552351
INFO:root:final train perplexity: 167.22703552246094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 6296.881851520944
INFO:root:eval perplexity: 162.80421447753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.33s/it]
INFO:root:eval mean loss: 6402.1053397537125
INFO:root:eval perplexity: 187.88272094726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [6:21:18<9:54:34, 584.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6476.2746109501
INFO:root:current train perplexity163.55726623535156
INFO:root:current mean train loss 6485.733757113233
INFO:root:current train perplexity161.76358032226562
INFO:root:current mean train loss 6451.238176884542
INFO:root:current train perplexity160.60562133789062
INFO:root:current mean train loss 6448.8739236231
INFO:root:current train perplexity160.67050170898438
INFO:root:current mean train loss 6455.181715663894
INFO:root:current train perplexity160.82794189453125
INFO:root:current mean train loss 6444.029713043538
INFO:root:current train perplexity160.63955688476562
INFO:root:current mean train loss 6446.724351957845
INFO:root:current train perplexity160.92645263671875
INFO:root:current mean train loss 6455.524403169086
INFO:root:current train perplexity161.10411071777344
INFO:root:current mean train loss 6457.971228225601
INFO:root:current train perplexity161.0860595703125
INFO:root:current mean train loss 6462.386608099987
INFO:root:current train perplexity161.2761993408203
INFO:root:current mean train loss 6464.505167413342
INFO:root:current train perplexity161.5574493408203
INFO:root:current mean train loss 6463.566273464393
INFO:root:current train perplexity161.58071899414062
INFO:root:current mean train loss 6460.643806953249
INFO:root:current train perplexity161.44454956054688
INFO:root:current mean train loss 6462.0370240512575
INFO:root:current train perplexity161.4962158203125
INFO:root:current mean train loss 6460.404208369849
INFO:root:current train perplexity161.47720336914062
INFO:root:current mean train loss 6460.1190837317945
INFO:root:current train perplexity161.47219848632812
INFO:root:current mean train loss 6456.260842076565
INFO:root:current train perplexity161.3546600341797
INFO:root:current mean train loss 6454.536949201014
INFO:root:current train perplexity161.256591796875
INFO:root:current mean train loss 6450.897349487698
INFO:root:current train perplexity161.21884155273438
INFO:root:current mean train loss 6446.958526953523
INFO:root:current train perplexity161.0908966064453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.82s/it]
INFO:root:final mean train loss: 6443.808678331246
INFO:root:final train perplexity: 161.09205627441406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 6328.362216381316
INFO:root:eval perplexity: 167.0023193359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 6442.240125290891
INFO:root:eval perplexity: 194.1519317626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [6:31:09<9:46:33, 586.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6464.9421664853635
INFO:root:current train perplexity165.6979522705078
INFO:root:current mean train loss 6437.460610160614
INFO:root:current train perplexity163.71597290039062
INFO:root:current mean train loss 6447.4511806255605
INFO:root:current train perplexity163.76727294921875
INFO:root:current mean train loss 6452.526963689396
INFO:root:current train perplexity163.78359985351562
INFO:root:current mean train loss 6442.464302461182
INFO:root:current train perplexity162.78884887695312
INFO:root:current mean train loss 6443.600856642649
INFO:root:current train perplexity162.633056640625
INFO:root:current mean train loss 6440.079899064571
INFO:root:current train perplexity162.220703125
INFO:root:current mean train loss 6446.37697004874
INFO:root:current train perplexity162.1102752685547
INFO:root:current mean train loss 6453.419581911263
INFO:root:current train perplexity162.06993103027344
INFO:root:current mean train loss 6449.131031944267
INFO:root:current train perplexity161.89947509765625
INFO:root:current mean train loss 6445.173740786463
INFO:root:current train perplexity161.57870483398438
INFO:root:current mean train loss 6453.444989464058
INFO:root:current train perplexity161.71591186523438
INFO:root:current mean train loss 6451.602423768569
INFO:root:current train perplexity161.458251953125
INFO:root:current mean train loss 6450.394670050761
INFO:root:current train perplexity161.31674194335938
INFO:root:current mean train loss 6449.953266301132
INFO:root:current train perplexity161.24237060546875
INFO:root:current mean train loss 6450.097801280973
INFO:root:current train perplexity161.2607421875
INFO:root:current mean train loss 6446.969499725469
INFO:root:current train perplexity161.1409149169922
INFO:root:current mean train loss 6447.078932763754
INFO:root:current train perplexity161.0654754638672
INFO:root:current mean train loss 6444.680579867117
INFO:root:current train perplexity160.96559143066406
INFO:root:current mean train loss 6443.689675183174
INFO:root:current train perplexity160.88255310058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.86s/it]
INFO:root:final mean train loss: 6442.291191682031
INFO:root:final train perplexity: 160.89920043945312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 6284.693653728945
INFO:root:eval perplexity: 161.20730590820312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.02s/it]
INFO:root:eval mean loss: 6402.962499307402
INFO:root:eval perplexity: 188.01437377929688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:40:50<9:35:19, 585.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6448.799489339192
INFO:root:current train perplexity159.9331817626953
INFO:root:current mean train loss 6460.679047253667
INFO:root:current train perplexity161.4717254638672
INFO:root:current mean train loss 6490.7139892578125
INFO:root:current train perplexity162.2499542236328
INFO:root:current mean train loss 6480.571275499132
INFO:root:current train perplexity161.3175811767578
INFO:root:current mean train loss 6454.522866525957
INFO:root:current train perplexity160.74996948242188
INFO:root:current mean train loss 6462.1550456821515
INFO:root:current train perplexity160.81643676757812
INFO:root:current mean train loss 6462.605423149022
INFO:root:current train perplexity160.61619567871094
INFO:root:current mean train loss 6460.553778413552
INFO:root:current train perplexity160.3070831298828
INFO:root:current mean train loss 6451.623748779297
INFO:root:current train perplexity159.86341857910156
INFO:root:current mean train loss 6446.826714082894
INFO:root:current train perplexity159.63482666015625
INFO:root:current mean train loss 6445.255144328096
INFO:root:current train perplexity159.626220703125
INFO:root:current mean train loss 6444.866857624373
INFO:root:current train perplexity159.5670928955078
INFO:root:current mean train loss 6446.772668155623
INFO:root:current train perplexity159.65103149414062
INFO:root:current mean train loss 6446.320649330118
INFO:root:current train perplexity159.6404571533203
INFO:root:current mean train loss 6441.175779944435
INFO:root:current train perplexity159.5301971435547
INFO:root:current mean train loss 6442.037918282033
INFO:root:current train perplexity159.69984436035156
INFO:root:current mean train loss 6438.306239002156
INFO:root:current train perplexity159.6603240966797
INFO:root:current mean train loss 6436.513439152979
INFO:root:current train perplexity159.94195556640625
INFO:root:current mean train loss 6438.104540603574
INFO:root:current train perplexity160.0048065185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.42s/it]
INFO:root:final mean train loss: 6435.293145915083
INFO:root:final train perplexity: 160.01358032226562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.67s/it]
INFO:root:eval mean loss: 6294.723056225066
INFO:root:eval perplexity: 162.5201873779297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.49s/it]
INFO:root:eval mean loss: 6409.506618635029
INFO:root:eval perplexity: 189.02340698242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:50:56<9:31:38, 591.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6345.074969951923
INFO:root:current train perplexity156.30523681640625
INFO:root:current mean train loss 6500.666966261062
INFO:root:current train perplexity162.08306884765625
INFO:root:current mean train loss 6427.92265900088
INFO:root:current train perplexity160.58702087402344
INFO:root:current mean train loss 6428.661162452576
INFO:root:current train perplexity160.50970458984375
INFO:root:current mean train loss 6450.2130667845795
INFO:root:current train perplexity161.90911865234375
INFO:root:current mean train loss 6453.598906935307
INFO:root:current train perplexity162.97012329101562
INFO:root:current mean train loss 6459.819140784309
INFO:root:current train perplexity163.48117065429688
INFO:root:current mean train loss 6465.268923124124
INFO:root:current train perplexity163.96176147460938
INFO:root:current mean train loss 6465.082060078414
INFO:root:current train perplexity164.01641845703125
INFO:root:current mean train loss 6461.516301534262
INFO:root:current train perplexity163.9518280029297
INFO:root:current mean train loss 6464.379460567313
INFO:root:current train perplexity164.00961303710938
INFO:root:current mean train loss 6465.877622592374
INFO:root:current train perplexity163.89320373535156
INFO:root:current mean train loss 6471.236836130719
INFO:root:current train perplexity163.9807586669922
INFO:root:current mean train loss 6467.683900180883
INFO:root:current train perplexity163.8524932861328
INFO:root:current mean train loss 6465.024976294343
INFO:root:current train perplexity163.72674560546875
INFO:root:current mean train loss 6465.445229237235
INFO:root:current train perplexity163.69053649902344
INFO:root:current mean train loss 6465.663450105103
INFO:root:current train perplexity163.69778442382812
INFO:root:current mean train loss 6467.354932011182
INFO:root:current train perplexity163.78009033203125
INFO:root:current mean train loss 6467.249028015978
INFO:root:current train perplexity163.80686950683594
INFO:root:current mean train loss 6468.9455651912895
INFO:root:current train perplexity163.89219665527344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.38s/it]
INFO:root:final mean train loss: 6465.299977174144
INFO:root:final train perplexity: 163.8455352783203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 6310.205538702349
INFO:root:eval perplexity: 164.56793212890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 6428.987741023936
INFO:root:eval perplexity: 192.0591583251953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [7:00:52<9:22:51, 592.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6523.632828776042
INFO:root:current train perplexity165.365966796875
INFO:root:current mean train loss 6470.18534780649
INFO:root:current train perplexity163.8916473388672
INFO:root:current mean train loss 6485.23633873981
INFO:root:current train perplexity164.34678649902344
INFO:root:current mean train loss 6479.482836174242
INFO:root:current train perplexity164.0691375732422
INFO:root:current mean train loss 6476.427913789971
INFO:root:current train perplexity163.52474975585938
INFO:root:current mean train loss 6477.661351157134
INFO:root:current train perplexity163.6233367919922
INFO:root:current mean train loss 6474.833550347223
INFO:root:current train perplexity163.511962890625
INFO:root:current mean train loss 6471.301824031464
INFO:root:current train perplexity163.75344848632812
INFO:root:current mean train loss 6470.732765436747
INFO:root:current train perplexity163.72674560546875
INFO:root:current mean train loss 6467.774259177588
INFO:root:current train perplexity163.67601013183594
INFO:root:current mean train loss 6459.2092621738475
INFO:root:current train perplexity163.474853515625
INFO:root:current mean train loss 6457.556744762859
INFO:root:current train perplexity163.17198181152344
INFO:root:current mean train loss 6457.870065580539
INFO:root:current train perplexity163.02359008789062
INFO:root:current mean train loss 6454.354010514568
INFO:root:current train perplexity163.07864379882812
INFO:root:current mean train loss 6457.9186543924825
INFO:root:current train perplexity163.21292114257812
INFO:root:current mean train loss 6464.194555823631
INFO:root:current train perplexity163.30267333984375
INFO:root:current mean train loss 6462.181116396664
INFO:root:current train perplexity163.22459411621094
INFO:root:current mean train loss 6466.856612965137
INFO:root:current train perplexity163.29901123046875
INFO:root:current mean train loss 6467.590731728142
INFO:root:current train perplexity163.304931640625
INFO:root:current mean train loss 6463.817981905764
INFO:root:current train perplexity163.2252197265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.24s/it]
INFO:root:final mean train loss: 6460.352152352614
INFO:root:final train perplexity: 163.20755004882812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 6298.324594484154
INFO:root:eval perplexity: 162.99429321289062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 6421.124211304576
INFO:root:eval perplexity: 190.827880859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [7:10:38<9:11:15, 590.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6420.518107962101
INFO:root:current train perplexity162.88909912109375
INFO:root:current mean train loss 6477.556311782526
INFO:root:current train perplexity164.6014404296875
INFO:root:current mean train loss 6472.315908084514
INFO:root:current train perplexity164.64312744140625
INFO:root:current mean train loss 6464.692047910663
INFO:root:current train perplexity164.70013427734375
INFO:root:current mean train loss 6464.797122963856
INFO:root:current train perplexity164.53160095214844
INFO:root:current mean train loss 6449.875118722864
INFO:root:current train perplexity163.88624572753906
INFO:root:current mean train loss 6461.312456228265
INFO:root:current train perplexity164.14112854003906
INFO:root:current mean train loss 6458.526118144453
INFO:root:current train perplexity163.83554077148438
INFO:root:current mean train loss 6458.546968390275
INFO:root:current train perplexity163.71145629882812
INFO:root:current mean train loss 6453.7216363763855
INFO:root:current train perplexity163.43798828125
INFO:root:current mean train loss 6454.320806843959
INFO:root:current train perplexity163.3622589111328
INFO:root:current mean train loss 6461.612516261852
INFO:root:current train perplexity163.85992431640625
INFO:root:current mean train loss 6461.79906854576
INFO:root:current train perplexity163.8426513671875
INFO:root:current mean train loss 6463.639882609503
INFO:root:current train perplexity163.81600952148438
INFO:root:current mean train loss 6466.323530701991
INFO:root:current train perplexity163.7312774658203
INFO:root:current mean train loss 6466.1399486026385
INFO:root:current train perplexity163.65899658203125
INFO:root:current mean train loss 6465.01069682804
INFO:root:current train perplexity163.59486389160156
INFO:root:current mean train loss 6467.766126417609
INFO:root:current train perplexity163.58551025390625
INFO:root:current mean train loss 6465.645745740559
INFO:root:current train perplexity163.5015106201172
INFO:root:current mean train loss 6464.55559810566
INFO:root:current train perplexity163.41281127929688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.28s/it]
INFO:root:final mean train loss: 6461.873929622494
INFO:root:final train perplexity: 163.40347290039062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 6279.527073636968
INFO:root:eval perplexity: 160.5351104736328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 6401.640935803136
INFO:root:eval perplexity: 187.8113250732422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [7:20:27<9:00:57, 590.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6507.21053314209
INFO:root:current train perplexity163.86952209472656
INFO:root:current mean train loss 6500.779395126715
INFO:root:current train perplexity163.41383361816406
INFO:root:current mean train loss 6468.105100689512
INFO:root:current train perplexity162.2504119873047
INFO:root:current mean train loss 6459.715246179601
INFO:root:current train perplexity161.5806427001953
INFO:root:current mean train loss 6443.206219903354
INFO:root:current train perplexity161.30442810058594
INFO:root:current mean train loss 6450.963391026707
INFO:root:current train perplexity161.92054748535156
INFO:root:current mean train loss 6461.427700548287
INFO:root:current train perplexity162.10711669921875
INFO:root:current mean train loss 6447.484053526873
INFO:root:current train perplexity161.76974487304688
INFO:root:current mean train loss 6455.415710449219
INFO:root:current train perplexity161.924560546875
INFO:root:current mean train loss 6459.520892258007
INFO:root:current train perplexity161.954833984375
INFO:root:current mean train loss 6457.147253968662
INFO:root:current train perplexity162.11143493652344
INFO:root:current mean train loss 6459.836189191366
INFO:root:current train perplexity162.33236694335938
INFO:root:current mean train loss 6457.460933250717
INFO:root:current train perplexity162.34327697753906
INFO:root:current mean train loss 6453.149536848768
INFO:root:current train perplexity162.2966766357422
INFO:root:current mean train loss 6451.375864164425
INFO:root:current train perplexity162.36480712890625
INFO:root:current mean train loss 6449.830479926771
INFO:root:current train perplexity162.38229370117188
INFO:root:current mean train loss 6453.59506724431
INFO:root:current train perplexity162.64414978027344
INFO:root:current mean train loss 6457.435048352023
INFO:root:current train perplexity162.826416015625
INFO:root:current mean train loss 6459.264748503721
INFO:root:current train perplexity162.87208557128906
INFO:root:current mean train loss 6459.050779261074
INFO:root:current train perplexity162.83201599121094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.21s/it]
INFO:root:final mean train loss: 6457.26844486731
INFO:root:final train perplexity: 162.81112670898438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 6283.978567569814
INFO:root:eval perplexity: 161.11416625976562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 6411.574533881871
INFO:root:eval perplexity: 189.34329223632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [7:30:28<8:54:05, 593.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6467.102068865741
INFO:root:current train perplexity164.9523468017578
INFO:root:current mean train loss 6476.121838311464
INFO:root:current train perplexity165.2837371826172
INFO:root:current mean train loss 6446.471339106984
INFO:root:current train perplexity163.65721130371094
INFO:root:current mean train loss 6456.797799017799
INFO:root:current train perplexity163.35922241210938
INFO:root:current mean train loss 6436.97277705139
INFO:root:current train perplexity162.96002197265625
INFO:root:current mean train loss 6446.416385407702
INFO:root:current train perplexity162.7359161376953
INFO:root:current mean train loss 6448.234610178047
INFO:root:current train perplexity162.56869506835938
INFO:root:current mean train loss 6447.289318832026
INFO:root:current train perplexity162.54367065429688
INFO:root:current mean train loss 6440.128053281959
INFO:root:current train perplexity162.3692169189453
INFO:root:current mean train loss 6444.2689772672975
INFO:root:current train perplexity162.55064392089844
INFO:root:current mean train loss 6446.155708418854
INFO:root:current train perplexity162.71969604492188
INFO:root:current mean train loss 6448.382867901937
INFO:root:current train perplexity162.71559143066406
INFO:root:current mean train loss 6452.069927135172
INFO:root:current train perplexity162.77635192871094
INFO:root:current mean train loss 6457.443774113527
INFO:root:current train perplexity162.96484375
INFO:root:current mean train loss 6462.300487819674
INFO:root:current train perplexity163.06837463378906
INFO:root:current mean train loss 6465.3839521317595
INFO:root:current train perplexity163.16537475585938
INFO:root:current mean train loss 6467.454048115891
INFO:root:current train perplexity163.22467041015625
INFO:root:current mean train loss 6467.612474667497
INFO:root:current train perplexity163.20677185058594
INFO:root:current mean train loss 6461.73911919358
INFO:root:current train perplexity163.0987091064453
INFO:root:current mean train loss 6462.299562149009
INFO:root:current train perplexity163.2572784423828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.53s/it]
INFO:root:final mean train loss: 6460.83737882844
INFO:root:final train perplexity: 163.2698974609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 6312.09043245789
INFO:root:eval perplexity: 164.81900024414062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 6430.372344754266
INFO:root:eval perplexity: 192.27659606933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [7:40:15<8:42:34, 591.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6523.4201062260845
INFO:root:current train perplexity167.33773803710938
INFO:root:current mean train loss 6479.971667357166
INFO:root:current train perplexity164.8372344970703
INFO:root:current mean train loss 6469.52621152737
INFO:root:current train perplexity164.1620330810547
INFO:root:current mean train loss 6451.761545765939
INFO:root:current train perplexity163.7504119873047
INFO:root:current mean train loss 6446.742456152736
INFO:root:current train perplexity163.539794921875
INFO:root:current mean train loss 6450.473430314591
INFO:root:current train perplexity163.56561279296875
INFO:root:current mean train loss 6454.321326138297
INFO:root:current train perplexity163.58526611328125
INFO:root:current mean train loss 6456.2595551378445
INFO:root:current train perplexity163.69833374023438
INFO:root:current mean train loss 6463.216216157433
INFO:root:current train perplexity164.0373077392578
INFO:root:current mean train loss 6468.740596427229
INFO:root:current train perplexity163.9708251953125
INFO:root:current mean train loss 6471.25579889572
INFO:root:current train perplexity164.13385009765625
INFO:root:current mean train loss 6479.1694458211605
INFO:root:current train perplexity164.47763061523438
INFO:root:current mean train loss 6482.762108095989
INFO:root:current train perplexity164.6403045654297
INFO:root:current mean train loss 6479.089267103116
INFO:root:current train perplexity164.61856079101562
INFO:root:current mean train loss 6477.040851995369
INFO:root:current train perplexity164.65585327148438
INFO:root:current mean train loss 6477.306565763357
INFO:root:current train perplexity164.73178100585938
INFO:root:current mean train loss 6473.219378611786
INFO:root:current train perplexity164.6017608642578
INFO:root:current mean train loss 6476.602668329394
INFO:root:current train perplexity164.6382598876953
INFO:root:current mean train loss 6474.312239651937
INFO:root:current train perplexity164.68992614746094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.57s/it]
INFO:root:final mean train loss: 6471.515669937634
INFO:root:final train perplexity: 164.65074157714844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 6312.021579607159
INFO:root:eval perplexity: 164.8098907470703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 6422.484611348903
INFO:root:eval perplexity: 191.040283203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:50:19<8:35:46, 595.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6463.86640625
INFO:root:current train perplexity165.23236083984375
INFO:root:current mean train loss 6508.683856997282
INFO:root:current train perplexity166.5533905029297
INFO:root:current mean train loss 6471.3070198946225
INFO:root:current train perplexity166.07565307617188
INFO:root:current mean train loss 6481.309483506944
INFO:root:current train perplexity166.03701782226562
INFO:root:current mean train loss 6480.762450583585
INFO:root:current train perplexity165.40704345703125
INFO:root:current mean train loss 6476.732811551881
INFO:root:current train perplexity165.16705322265625
INFO:root:current mean train loss 6476.595095750762
INFO:root:current train perplexity165.2840576171875
INFO:root:current mean train loss 6479.423668323863
INFO:root:current train perplexity165.499755859375
INFO:root:current mean train loss 6472.113390888612
INFO:root:current train perplexity165.40420532226562
INFO:root:current mean train loss 6471.556233457138
INFO:root:current train perplexity165.4595947265625
INFO:root:current mean train loss 6470.969102139778
INFO:root:current train perplexity165.75823974609375
INFO:root:current mean train loss 6475.761977560958
INFO:root:current train perplexity165.97021484375
INFO:root:current mean train loss 6479.056080809542
INFO:root:current train perplexity166.03915405273438
INFO:root:current mean train loss 6477.728790399239
INFO:root:current train perplexity165.9441680908203
INFO:root:current mean train loss 6482.077802354793
INFO:root:current train perplexity166.08389282226562
INFO:root:current mean train loss 6481.454665261448
INFO:root:current train perplexity166.1761016845703
INFO:root:current mean train loss 6482.611206886126
INFO:root:current train perplexity166.27835083007812
INFO:root:current mean train loss 6483.289032605229
INFO:root:current train perplexity166.34043884277344
INFO:root:current mean train loss 6482.309919238551
INFO:root:current train perplexity166.3277587890625
INFO:root:current mean train loss 6486.87349308502
INFO:root:current train perplexity166.4788360595703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.87s/it]
INFO:root:final mean train loss: 6485.903227974896
INFO:root:final train perplexity: 166.52972412109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 6316.585160059286
INFO:root:eval perplexity: 165.41928100585938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 6424.683902821643
INFO:root:eval perplexity: 191.38429260253906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [8:00:08<8:24:20, 593.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6406.100662231445
INFO:root:current train perplexity162.7208709716797
INFO:root:current mean train loss 6476.649894945549
INFO:root:current train perplexity164.11656188964844
INFO:root:current mean train loss 6510.658906081627
INFO:root:current train perplexity166.6063690185547
INFO:root:current mean train loss 6503.635730421687
INFO:root:current train perplexity166.37240600585938
INFO:root:current mean train loss 6510.282721625434
INFO:root:current train perplexity167.0223846435547
INFO:root:current mean train loss 6517.649839931861
INFO:root:current train perplexity166.91299438476562
INFO:root:current mean train loss 6518.305069162876
INFO:root:current train perplexity167.22711181640625
INFO:root:current mean train loss 6516.262846066001
INFO:root:current train perplexity167.33718872070312
INFO:root:current mean train loss 6515.5753977848935
INFO:root:current train perplexity167.57601928710938
INFO:root:current mean train loss 6514.403637276187
INFO:root:current train perplexity167.59934997558594
INFO:root:current mean train loss 6508.270644077035
INFO:root:current train perplexity167.459716796875
INFO:root:current mean train loss 6506.152594360783
INFO:root:current train perplexity167.5832061767578
INFO:root:current mean train loss 6506.380375057071
INFO:root:current train perplexity167.66290283203125
INFO:root:current mean train loss 6503.449164496527
INFO:root:current train perplexity167.67672729492188
INFO:root:current mean train loss 6502.744919419954
INFO:root:current train perplexity167.76165771484375
INFO:root:current mean train loss 6502.4703506190845
INFO:root:current train perplexity167.8370361328125
INFO:root:current mean train loss 6495.7193642410575
INFO:root:current train perplexity167.7600555419922
INFO:root:current mean train loss 6497.5833520338665
INFO:root:current train perplexity167.8563232421875
INFO:root:current mean train loss 6498.383299448605
INFO:root:current train perplexity167.8392791748047
INFO:root:current mean train loss 6498.236811857046
INFO:root:current train perplexity167.8301544189453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.88s/it]
INFO:root:final mean train loss: 6495.267962495666
INFO:root:final train perplexity: 167.76414489746094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 6319.239978113918
INFO:root:eval perplexity: 165.77476501464844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it]
INFO:root:eval mean loss: 6434.513619064439
INFO:root:eval perplexity: 192.92893981933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [8:09:59<8:13:58, 592.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6436.688934948979
INFO:root:current train perplexity164.73696899414062
INFO:root:current mean train loss 6514.503372089975
INFO:root:current train perplexity168.25282287597656
INFO:root:current mean train loss 6516.722077764181
INFO:root:current train perplexity169.4228515625
INFO:root:current mean train loss 6509.079077778027
INFO:root:current train perplexity170.00672912597656
INFO:root:current mean train loss 6512.205203185899
INFO:root:current train perplexity170.37338256835938
INFO:root:current mean train loss 6505.6491570255575
INFO:root:current train perplexity170.0634002685547
INFO:root:current mean train loss 6511.655263656828
INFO:root:current train perplexity169.90040588378906
INFO:root:current mean train loss 6512.9154738870575
INFO:root:current train perplexity169.62954711914062
INFO:root:current mean train loss 6514.976555023373
INFO:root:current train perplexity169.65858459472656
INFO:root:current mean train loss 6512.122023491011
INFO:root:current train perplexity169.626953125
INFO:root:current mean train loss 6507.765873562619
INFO:root:current train perplexity169.57827758789062
INFO:root:current mean train loss 6507.103014594893
INFO:root:current train perplexity169.6002655029297
INFO:root:current mean train loss 6510.9988189770565
INFO:root:current train perplexity169.82078552246094
INFO:root:current mean train loss 6507.859874501946
INFO:root:current train perplexity169.75350952148438
INFO:root:current mean train loss 6506.193229975414
INFO:root:current train perplexity169.62501525878906
INFO:root:current mean train loss 6505.33742377895
INFO:root:current train perplexity169.62339782714844
INFO:root:current mean train loss 6506.565639923818
INFO:root:current train perplexity169.7342529296875
INFO:root:current mean train loss 6508.177232693235
INFO:root:current train perplexity169.79164123535156
INFO:root:current mean train loss 6511.684707897428
INFO:root:current train perplexity169.9933624267578
INFO:root:current mean train loss 6514.0135719138825
INFO:root:current train perplexity170.1361541748047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.83s/it]
INFO:root:final mean train loss: 6513.369083252569
INFO:root:final train perplexity: 170.17633056640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 6358.771551903258
INFO:root:eval perplexity: 171.16038513183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it]
INFO:root:eval mean loss: 6480.87621637439
INFO:root:eval perplexity: 200.3847198486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [8:19:47<8:02:56, 591.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6480.542665423769
INFO:root:current train perplexity169.5216064453125
INFO:root:current mean train loss 6514.500379447478
INFO:root:current train perplexity168.4123992919922
INFO:root:current mean train loss 6498.221940348919
INFO:root:current train perplexity167.84384155273438
INFO:root:current mean train loss 6489.838917883368
INFO:root:current train perplexity167.8203125
INFO:root:current mean train loss 6518.347775700778
INFO:root:current train perplexity169.18711853027344
INFO:root:current mean train loss 6521.132080940813
INFO:root:current train perplexity169.82540893554688
INFO:root:current mean train loss 6516.1362737248965
INFO:root:current train perplexity169.92713928222656
INFO:root:current mean train loss 6521.208234742167
INFO:root:current train perplexity170.10743713378906
INFO:root:current mean train loss 6521.142009215322
INFO:root:current train perplexity170.09292602539062
INFO:root:current mean train loss 6521.57759628138
INFO:root:current train perplexity170.1918182373047
INFO:root:current mean train loss 6529.716931541686
INFO:root:current train perplexity170.39012145996094
INFO:root:current mean train loss 6528.479580547143
INFO:root:current train perplexity170.53414916992188
INFO:root:current mean train loss 6526.185399542111
INFO:root:current train perplexity170.4896697998047
INFO:root:current mean train loss 6526.911562471404
INFO:root:current train perplexity170.56057739257812
INFO:root:current mean train loss 6526.762839531996
INFO:root:current train perplexity170.56504821777344
INFO:root:current mean train loss 6526.743506420617
INFO:root:current train perplexity170.52716064453125
INFO:root:current mean train loss 6520.835862469988
INFO:root:current train perplexity170.4373321533203
INFO:root:current mean train loss 6522.666378379813
INFO:root:current train perplexity170.41627502441406
INFO:root:current mean train loss 6521.746258342126
INFO:root:current train perplexity170.4521942138672
INFO:root:current mean train loss 6517.590559034842
INFO:root:current train perplexity170.51609802246094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.12s/it]
INFO:root:final mean train loss: 6515.912443637127
INFO:root:final train perplexity: 170.51788330078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 6352.07694758422
INFO:root:eval perplexity: 170.23614501953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it]
INFO:root:eval mean loss: 6460.949972815548
INFO:root:eval perplexity: 197.14553833007812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [8:29:39<7:53:07, 591.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6459.08733174887
INFO:root:current train perplexity171.76712036132812
INFO:root:current mean train loss 6474.622243745731
INFO:root:current train perplexity170.82518005371094
INFO:root:current mean train loss 6482.964807517115
INFO:root:current train perplexity170.4884490966797
INFO:root:current mean train loss 6504.591210427546
INFO:root:current train perplexity170.9760284423828
INFO:root:current mean train loss 6508.627498018569
INFO:root:current train perplexity171.5498809814453
INFO:root:current mean train loss 6521.848641187821
INFO:root:current train perplexity172.2794647216797
INFO:root:current mean train loss 6522.014342457449
INFO:root:current train perplexity172.4051971435547
INFO:root:current mean train loss 6533.125083562819
INFO:root:current train perplexity172.6101837158203
INFO:root:current mean train loss 6536.319827536629
INFO:root:current train perplexity172.9461669921875
INFO:root:current mean train loss 6536.318242644487
INFO:root:current train perplexity172.974853515625
INFO:root:current mean train loss 6539.899735074735
INFO:root:current train perplexity173.11703491210938
INFO:root:current mean train loss 6539.150603603128
INFO:root:current train perplexity173.040771484375
INFO:root:current mean train loss 6543.169964499708
INFO:root:current train perplexity173.23825073242188
INFO:root:current mean train loss 6540.892959076171
INFO:root:current train perplexity173.36907958984375
INFO:root:current mean train loss 6541.931319274697
INFO:root:current train perplexity173.44869995117188
INFO:root:current mean train loss 6542.878761585498
INFO:root:current train perplexity173.5079345703125
INFO:root:current mean train loss 6540.440684997958
INFO:root:current train perplexity173.39520263671875
INFO:root:current mean train loss 6540.672040955377
INFO:root:current train perplexity173.31492614746094
INFO:root:current mean train loss 6543.343072681559
INFO:root:current train perplexity173.3762664794922
INFO:root:current mean train loss 6537.008690076588
INFO:root:current train perplexity173.3787384033203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.72s/it]
INFO:root:final mean train loss: 6537.008690076588
INFO:root:final train perplexity: 173.3787384033203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 6363.097559286348
INFO:root:eval perplexity: 171.76023864746094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 6474.120255707004
INFO:root:eval perplexity: 199.280517578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [8:39:39<7:45:23, 594.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6469.432612304688
INFO:root:current train perplexity172.51670837402344
INFO:root:current mean train loss 6497.507126464844
INFO:root:current train perplexity172.59841918945312
INFO:root:current mean train loss 6519.1843880208335
INFO:root:current train perplexity172.92430114746094
INFO:root:current mean train loss 6507.173563232422
INFO:root:current train perplexity172.729736328125
INFO:root:current mean train loss 6514.923623046875
INFO:root:current train perplexity172.64764404296875
INFO:root:current mean train loss 6527.289285481771
INFO:root:current train perplexity172.64524841308594
INFO:root:current mean train loss 6523.946025390625
INFO:root:current train perplexity172.03656005859375
INFO:root:current mean train loss 6523.425978393555
INFO:root:current train perplexity172.0637969970703
INFO:root:current mean train loss 6525.634111328125
INFO:root:current train perplexity172.16868591308594
INFO:root:current mean train loss 6528.995182128906
INFO:root:current train perplexity172.3005828857422
INFO:root:current mean train loss 6525.4971786221595
INFO:root:current train perplexity172.1461944580078
INFO:root:current mean train loss 6529.227294921875
INFO:root:current train perplexity172.41769409179688
INFO:root:current mean train loss 6529.149453125
INFO:root:current train perplexity172.3931121826172
INFO:root:current mean train loss 6530.248718261719
INFO:root:current train perplexity172.38711547851562
INFO:root:current mean train loss 6529.0753264973955
INFO:root:current train perplexity172.33229064941406
INFO:root:current mean train loss 6528.762311401367
INFO:root:current train perplexity172.26368713378906
INFO:root:current mean train loss 6533.7201803768385
INFO:root:current train perplexity172.46646118164062
INFO:root:current mean train loss 6534.568082953559
INFO:root:current train perplexity172.4764862060547
INFO:root:current mean train loss 6535.328997224507
INFO:root:current train perplexity172.5811309814453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.78s/it]
INFO:root:final mean train loss: 6530.312770733855
INFO:root:final train perplexity: 172.46554565429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.63s/it]
INFO:root:eval mean loss: 6354.55056654477
INFO:root:eval perplexity: 170.57717895507812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.33s/it]
INFO:root:eval mean loss: 6470.640765250997
INFO:root:eval perplexity: 198.71421813964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [8:49:36<7:36:10, 595.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6434.41463694853
INFO:root:current train perplexity170.47430419921875
INFO:root:current mean train loss 6555.947678786058
INFO:root:current train perplexity173.25668334960938
INFO:root:current mean train loss 6549.213502664171
INFO:root:current train perplexity172.96084594726562
INFO:root:current mean train loss 6540.66982021392
INFO:root:current train perplexity173.09812927246094
INFO:root:current mean train loss 6539.528796884368
INFO:root:current train perplexity174.15113830566406
INFO:root:current mean train loss 6555.475247823984
INFO:root:current train perplexity175.127197265625
INFO:root:current mean train loss 6560.733788587672
INFO:root:current train perplexity175.01258850097656
INFO:root:current mean train loss 6560.955550062108
INFO:root:current train perplexity175.0673370361328
INFO:root:current mean train loss 6562.399915492082
INFO:root:current train perplexity174.97286987304688
INFO:root:current mean train loss 6562.771237305752
INFO:root:current train perplexity174.89077758789062
INFO:root:current mean train loss 6555.195056116335
INFO:root:current train perplexity174.57009887695312
INFO:root:current mean train loss 6554.009087189458
INFO:root:current train perplexity174.41250610351562
INFO:root:current mean train loss 6551.559847553538
INFO:root:current train perplexity174.40377807617188
INFO:root:current mean train loss 6550.8330586056145
INFO:root:current train perplexity174.4415283203125
INFO:root:current mean train loss 6550.432821528207
INFO:root:current train perplexity174.53172302246094
INFO:root:current mean train loss 6548.575833264667
INFO:root:current train perplexity174.49977111816406
INFO:root:current mean train loss 6544.9422593078425
INFO:root:current train perplexity174.4299774169922
INFO:root:current mean train loss 6543.138279998726
INFO:root:current train perplexity174.36477661132812
INFO:root:current mean train loss 6543.490837403688
INFO:root:current train perplexity174.44012451171875
INFO:root:current mean train loss 6547.588109421867
INFO:root:current train perplexity174.61529541015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.75s/it]
INFO:root:final mean train loss: 6545.968060299657
INFO:root:final train perplexity: 174.60804748535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 6367.645163245235
INFO:root:eval perplexity: 172.39320373535156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.61s/it]
INFO:root:eval mean loss: 6488.326784823803
INFO:root:eval perplexity: 201.6092987060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:59:06<7:20:38, 587.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6494.201344209559
INFO:root:current train perplexity175.58474731445312
INFO:root:current mean train loss 6565.09131223764
INFO:root:current train perplexity181.1795654296875
INFO:root:current mean train loss 6660.126237396501
INFO:root:current train perplexity191.2397003173828
INFO:root:current mean train loss 6720.187606720154
INFO:root:current train perplexity198.7474822998047
INFO:root:current mean train loss 6705.9633721558175
INFO:root:current train perplexity198.06886291503906
INFO:root:current mean train loss 6697.361444251814
INFO:root:current train perplexity195.696044921875
INFO:root:current mean train loss 6674.755131574083
INFO:root:current train perplexity193.18264770507812
INFO:root:current mean train loss 6653.277730250554
INFO:root:current train perplexity190.5099334716797
INFO:root:current mean train loss 6641.137720487673
INFO:root:current train perplexity188.5630340576172
INFO:root:current mean train loss 6635.457398245115
INFO:root:current train perplexity187.36917114257812
INFO:root:current mean train loss 6629.485888482985
INFO:root:current train perplexity186.53298950195312
INFO:root:current mean train loss 6625.466689229222
INFO:root:current train perplexity185.71214294433594
INFO:root:current mean train loss 6616.618926952492
INFO:root:current train perplexity184.58631896972656
INFO:root:current mean train loss 6609.3211763259
INFO:root:current train perplexity183.52857971191406
INFO:root:current mean train loss 6602.676781988211
INFO:root:current train perplexity182.54469299316406
INFO:root:current mean train loss 6597.479831819895
INFO:root:current train perplexity181.5926513671875
INFO:root:current mean train loss 6590.154775892653
INFO:root:current train perplexity180.68882751464844
INFO:root:current mean train loss 6586.246333103554
INFO:root:current train perplexity179.93093872070312
INFO:root:current mean train loss 6577.584067175147
INFO:root:current train perplexity179.14674377441406
INFO:root:current mean train loss 6573.78976916971
INFO:root:current train perplexity178.58680725097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.71s/it]
INFO:root:final mean train loss: 6572.878352593726
INFO:root:final train perplexity: 178.35328674316406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 6327.469882396941
INFO:root:eval perplexity: 166.8819580078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it]
INFO:root:eval mean loss: 6455.2968568193155
INFO:root:eval perplexity: 196.2362518310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [9:08:39<7:07:30, 582.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6471.98082299326
INFO:root:current train perplexity167.1361541748047
INFO:root:current mean train loss 6461.88300651904
INFO:root:current train perplexity167.6237335205078
INFO:root:current mean train loss 6498.158288720119
INFO:root:current train perplexity168.8511962890625
INFO:root:current mean train loss 6524.880727219106
INFO:root:current train perplexity170.24928283691406
INFO:root:current mean train loss 6530.90760116408
INFO:root:current train perplexity170.98963928222656
INFO:root:current mean train loss 6527.623373872788
INFO:root:current train perplexity170.901611328125
INFO:root:current mean train loss 6535.221155403946
INFO:root:current train perplexity171.76220703125
INFO:root:current mean train loss 6541.890558031999
INFO:root:current train perplexity172.4331512451172
INFO:root:current mean train loss 6538.887575967612
INFO:root:current train perplexity172.70338439941406
INFO:root:current mean train loss 6540.000141195945
INFO:root:current train perplexity172.98245239257812
INFO:root:current mean train loss 6546.015239392543
INFO:root:current train perplexity173.9857177734375
INFO:root:current mean train loss 6559.364953963266
INFO:root:current train perplexity175.21372985839844
INFO:root:current mean train loss 6562.816560813849
INFO:root:current train perplexity175.93313598632812
INFO:root:current mean train loss 6567.488133428364
INFO:root:current train perplexity176.56832885742188
INFO:root:current mean train loss 6572.231470887535
INFO:root:current train perplexity177.0127716064453
INFO:root:current mean train loss 6575.587788624274
INFO:root:current train perplexity177.31190490722656
INFO:root:current mean train loss 6576.422259473426
INFO:root:current train perplexity177.5831756591797
INFO:root:current mean train loss 6577.677584349122
INFO:root:current train perplexity177.86520385742188
INFO:root:current mean train loss 6575.912249712993
INFO:root:current train perplexity178.04586791992188
INFO:root:current mean train loss 6574.868620559168
INFO:root:current train perplexity178.37319946289062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.32s/it]
INFO:root:final mean train loss: 6573.384427176902
INFO:root:final train perplexity: 178.42465209960938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.78s/it]
INFO:root:eval mean loss: 6430.507743240249
INFO:root:eval perplexity: 181.38409423828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.93s/it]
INFO:root:eval mean loss: 6527.475040516955
INFO:root:eval perplexity: 208.16871643066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [9:18:12<6:55:43, 580.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6584.366447897519
INFO:root:current train perplexity181.4392852783203
INFO:root:current mean train loss 6599.963001069568
INFO:root:current train perplexity180.69692993164062
INFO:root:current mean train loss 6586.962078037546
INFO:root:current train perplexity181.02232360839844
INFO:root:current mean train loss 6585.643721870754
INFO:root:current train perplexity181.11453247070312
INFO:root:current mean train loss 6585.41888792902
INFO:root:current train perplexity180.3604278564453
INFO:root:current mean train loss 6593.71660345373
INFO:root:current train perplexity180.33944702148438
INFO:root:current mean train loss 6595.311071704248
INFO:root:current train perplexity180.49766540527344
INFO:root:current mean train loss 6583.283203125
INFO:root:current train perplexity180.1748504638672
INFO:root:current mean train loss 6580.98571889851
INFO:root:current train perplexity180.0326385498047
INFO:root:current mean train loss 6581.733800966877
INFO:root:current train perplexity180.16677856445312
INFO:root:current mean train loss 6586.660107330436
INFO:root:current train perplexity180.24281311035156
INFO:root:current mean train loss 6581.933809045243
INFO:root:current train perplexity180.07752990722656
INFO:root:current mean train loss 6582.710619038964
INFO:root:current train perplexity180.13369750976562
INFO:root:current mean train loss 6580.5741973341555
INFO:root:current train perplexity180.0481719970703
INFO:root:current mean train loss 6583.283165539318
INFO:root:current train perplexity180.1930694580078
INFO:root:current mean train loss 6584.961004140426
INFO:root:current train perplexity180.21034240722656
INFO:root:current mean train loss 6585.418929797568
INFO:root:current train perplexity180.1577606201172
INFO:root:current mean train loss 6588.623039970571
INFO:root:current train perplexity180.24075317382812
INFO:root:current mean train loss 6588.425485353654
INFO:root:current train perplexity180.14332580566406
INFO:root:current mean train loss 6588.334475881685
INFO:root:current train perplexity180.16368103027344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.10s/it]
INFO:root:final mean train loss: 6585.4431689133025
INFO:root:final train perplexity: 180.12966918945312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 6431.719865082004
INFO:root:eval perplexity: 181.56199645996094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.33s/it]
INFO:root:eval mean loss: 6558.813138055463
INFO:root:eval perplexity: 213.57272338867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [9:27:44<6:44:21, 577.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6584.182772288603
INFO:root:current train perplexity179.35153198242188
INFO:root:current mean train loss 6561.937127850507
INFO:root:current train perplexity179.0802001953125
INFO:root:current mean train loss 6561.455736019737
INFO:root:current train perplexity178.43392944335938
INFO:root:current mean train loss 6555.860331270293
INFO:root:current train perplexity178.27523803710938
INFO:root:current mean train loss 6556.511442896262
INFO:root:current train perplexity177.53880310058594
INFO:root:current mean train loss 6556.5064820379275
INFO:root:current train perplexity176.99334716796875
INFO:root:current mean train loss 6550.724806825958
INFO:root:current train perplexity176.31509399414062
INFO:root:current mean train loss 6544.120209245621
INFO:root:current train perplexity175.85169982910156
INFO:root:current mean train loss 6556.801072011829
INFO:root:current train perplexity176.3697509765625
INFO:root:current mean train loss 6557.090315176872
INFO:root:current train perplexity176.25860595703125
INFO:root:current mean train loss 6552.190814912155
INFO:root:current train perplexity175.9419403076172
INFO:root:current mean train loss 6553.241173852848
INFO:root:current train perplexity175.79837036132812
INFO:root:current mean train loss 6556.459290643239
INFO:root:current train perplexity175.5745391845703
INFO:root:current mean train loss 6553.351489522225
INFO:root:current train perplexity175.43260192871094
INFO:root:current mean train loss 6551.512199468645
INFO:root:current train perplexity175.28961181640625
INFO:root:current mean train loss 6552.575564989156
INFO:root:current train perplexity175.13446044921875
INFO:root:current mean train loss 6548.414575412648
INFO:root:current train perplexity174.81900024414062
INFO:root:current mean train loss 6548.546949404762
INFO:root:current train perplexity174.6160430908203
INFO:root:current mean train loss 6546.682510205985
INFO:root:current train perplexity174.64869689941406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.06s/it]
INFO:root:final mean train loss: 6546.817074281786
INFO:root:final train perplexity: 174.72506713867188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 6358.566335258754
INFO:root:eval perplexity: 171.13197326660156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it]
INFO:root:eval mean loss: 6467.086700223016
INFO:root:eval perplexity: 198.1375274658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [9:37:17<6:33:48, 576.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6728.6279296875
INFO:root:current train perplexity179.4398956298828
INFO:root:current mean train loss 6534.345219630821
INFO:root:current train perplexity174.36834716796875
INFO:root:current mean train loss 6529.923924814357
INFO:root:current train perplexity173.74951171875
INFO:root:current mean train loss 6532.723758924876
INFO:root:current train perplexity172.90286254882812
INFO:root:current mean train loss 6531.25487552472
INFO:root:current train perplexity172.55224609375
INFO:root:current mean train loss 6527.475654997199
INFO:root:current train perplexity172.60804748535156
INFO:root:current mean train loss 6527.282234673484
INFO:root:current train perplexity172.50125122070312
INFO:root:current mean train loss 6528.796804053151
INFO:root:current train perplexity172.53497314453125
INFO:root:current mean train loss 6533.377722076644
INFO:root:current train perplexity172.58071899414062
INFO:root:current mean train loss 6537.482070009354
INFO:root:current train perplexity172.82489013671875
INFO:root:current mean train loss 6536.015255621569
INFO:root:current train perplexity173.14056396484375
INFO:root:current mean train loss 6543.050099339978
INFO:root:current train perplexity173.40933227539062
INFO:root:current mean train loss 6544.189096054102
INFO:root:current train perplexity173.3394012451172
INFO:root:current mean train loss 6538.289011496736
INFO:root:current train perplexity173.23355102539062
INFO:root:current mean train loss 6535.518364181192
INFO:root:current train perplexity173.28286743164062
INFO:root:current mean train loss 6534.886016561251
INFO:root:current train perplexity173.1903533935547
INFO:root:current mean train loss 6530.159351896555
INFO:root:current train perplexity172.94467163085938
INFO:root:current mean train loss 6531.200837938822
INFO:root:current train perplexity172.88275146484375
INFO:root:current mean train loss 6532.712942379561
INFO:root:current train perplexity172.83164978027344
INFO:root:current mean train loss 6532.286050918852
INFO:root:current train perplexity172.80181884765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.43s/it]
INFO:root:final mean train loss: 6533.66502404225
INFO:root:final train perplexity: 172.9220733642578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it]
INFO:root:eval mean loss: 6395.532782372008
INFO:root:eval perplexity: 176.325439453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 6520.988431024213
INFO:root:eval perplexity: 207.06724548339844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [9:46:49<6:23:15, 574.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6544.552194695723
INFO:root:current train perplexity179.1525421142578
INFO:root:current mean train loss 6572.594763491334
INFO:root:current train perplexity179.51246643066406
INFO:root:current mean train loss 6608.720634007563
INFO:root:current train perplexity181.23106384277344
INFO:root:current mean train loss 6596.0483275984525
INFO:root:current train perplexity180.79139709472656
INFO:root:current mean train loss 6585.725576614707
INFO:root:current train perplexity180.4320831298828
INFO:root:current mean train loss 6590.443496733502
INFO:root:current train perplexity180.2061309814453
INFO:root:current mean train loss 6577.775150034077
INFO:root:current train perplexity179.90013122558594
INFO:root:current mean train loss 6576.154651371262
INFO:root:current train perplexity179.6658477783203
INFO:root:current mean train loss 6572.213203029609
INFO:root:current train perplexity179.05519104003906
INFO:root:current mean train loss 6567.472478258467
INFO:root:current train perplexity178.51400756835938
INFO:root:current mean train loss 6565.280572443879
INFO:root:current train perplexity178.15609741210938
INFO:root:current mean train loss 6567.114888781836
INFO:root:current train perplexity178.38995361328125
INFO:root:current mean train loss 6572.236361371385
INFO:root:current train perplexity178.83734130859375
INFO:root:current mean train loss 6573.971581587021
INFO:root:current train perplexity179.10009765625
INFO:root:current mean train loss 6574.878260713971
INFO:root:current train perplexity178.91795349121094
INFO:root:current mean train loss 6573.428579143351
INFO:root:current train perplexity178.51605224609375
INFO:root:current mean train loss 6571.746258722109
INFO:root:current train perplexity178.20010375976562
INFO:root:current mean train loss 6568.5529783736
INFO:root:current train perplexity177.70294189453125
INFO:root:current mean train loss 6564.193652773244
INFO:root:current train perplexity177.3179931640625
INFO:root:current mean train loss 6566.353778212936
INFO:root:current train perplexity177.3643341064453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.68s/it]
INFO:root:final mean train loss: 6567.302828190006
INFO:root:final train perplexity: 177.57098388671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 6346.52735760195
INFO:root:eval perplexity: 169.4738311767578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 6461.478906076851
INFO:root:eval perplexity: 197.23081970214844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [9:56:26<6:14:01, 575.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6544.49553765191
INFO:root:current train perplexity176.45394897460938
INFO:root:current mean train loss 6563.376425350413
INFO:root:current train perplexity179.35093688964844
INFO:root:current mean train loss 6556.399958206435
INFO:root:current train perplexity178.79855346679688
INFO:root:current mean train loss 6574.679751441592
INFO:root:current train perplexity179.2498779296875
INFO:root:current mean train loss 6570.396150641485
INFO:root:current train perplexity179.5071563720703
INFO:root:current mean train loss 6574.587775842468
INFO:root:current train perplexity179.69239807128906
INFO:root:current mean train loss 6578.779864233245
INFO:root:current train perplexity180.0878448486328
INFO:root:current mean train loss 6592.0534296450405
INFO:root:current train perplexity181.0482940673828
INFO:root:current mean train loss 6589.024200877505
INFO:root:current train perplexity181.0884552001953
INFO:root:current mean train loss 6588.463127462273
INFO:root:current train perplexity180.6816864013672
INFO:root:current mean train loss 6584.569730427274
INFO:root:current train perplexity180.03065490722656
INFO:root:current mean train loss 6580.283708169427
INFO:root:current train perplexity179.5491943359375
INFO:root:current mean train loss 6574.33727829819
INFO:root:current train perplexity179.2482452392578
INFO:root:current mean train loss 6577.048039419208
INFO:root:current train perplexity179.3218536376953
INFO:root:current mean train loss 6572.783196664454
INFO:root:current train perplexity179.20176696777344
INFO:root:current mean train loss 6573.766520182292
INFO:root:current train perplexity179.26756286621094
INFO:root:current mean train loss 6575.248553063875
INFO:root:current train perplexity179.20150756835938
INFO:root:current mean train loss 6576.893641599312
INFO:root:current train perplexity179.29774475097656
INFO:root:current mean train loss 6581.458816561564
INFO:root:current train perplexity179.4616241455078
INFO:root:current mean train loss 6584.155228291661
INFO:root:current train perplexity179.5998077392578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.19s/it]
INFO:root:final mean train loss: 6581.590894059466
INFO:root:final train perplexity: 179.58319091796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 6377.631557166999
INFO:root:eval perplexity: 173.79110717773438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.56s/it]
INFO:root:eval mean loss: 6498.515160093916
INFO:root:eval perplexity: 203.2962646484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [10:06:03<6:04:46, 575.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6638.861291273585
INFO:root:current train perplexity184.05010986328125
INFO:root:current mean train loss 6605.465762867647
INFO:root:current train perplexity182.4029541015625
INFO:root:current mean train loss 6612.130961663167
INFO:root:current train perplexity181.91427612304688
INFO:root:current mean train loss 6608.71403317546
INFO:root:current train perplexity182.17251586914062
INFO:root:current mean train loss 6604.746873059809
INFO:root:current train perplexity181.69400024414062
INFO:root:current mean train loss 6595.509126356239
INFO:root:current train perplexity180.59933471679688
INFO:root:current mean train loss 6595.10836852747
INFO:root:current train perplexity179.8780059814453
INFO:root:current mean train loss 6595.50130921626
INFO:root:current train perplexity179.0386199951172
INFO:root:current mean train loss 6588.335347898959
INFO:root:current train perplexity178.3327178955078
INFO:root:current mean train loss 6578.2047722447205
INFO:root:current train perplexity177.52188110351562
INFO:root:current mean train loss 6570.74685515343
INFO:root:current train perplexity176.80018615722656
INFO:root:current mean train loss 6564.207229865704
INFO:root:current train perplexity176.28465270996094
INFO:root:current mean train loss 6560.210841246633
INFO:root:current train perplexity175.79208374023438
INFO:root:current mean train loss 6556.134651223554
INFO:root:current train perplexity175.55929565429688
INFO:root:current mean train loss 6554.31034322845
INFO:root:current train perplexity175.47267150878906
INFO:root:current mean train loss 6548.18066783544
INFO:root:current train perplexity175.2233428955078
INFO:root:current mean train loss 6552.199196300287
INFO:root:current train perplexity175.36619567871094
INFO:root:current mean train loss 6551.102797269413
INFO:root:current train perplexity175.27749633789062
INFO:root:current mean train loss 6550.572739676791
INFO:root:current train perplexity175.2689666748047
INFO:root:current mean train loss 6550.780727966589
INFO:root:current train perplexity175.20286560058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.46s/it]
INFO:root:final mean train loss: 6550.771303393296
INFO:root:final train perplexity: 175.27081298828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it]
INFO:root:eval mean loss: 6349.162026263298
INFO:root:eval perplexity: 169.83535766601562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it]
INFO:root:eval mean loss: 6467.02078138852
INFO:root:eval perplexity: 198.12686157226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [10:15:51<5:57:25, 579.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6596.650167410714
INFO:root:current train perplexity176.5103302001953
INFO:root:current mean train loss 6589.25239832261
INFO:root:current train perplexity175.10256958007812
INFO:root:current mean train loss 6575.669174985533
INFO:root:current train perplexity175.85714721679688
INFO:root:current mean train loss 6549.564977037585
INFO:root:current train perplexity175.13522338867188
INFO:root:current mean train loss 6553.026173952792
INFO:root:current train perplexity175.11834716796875
INFO:root:current mean train loss 6548.33408203125
INFO:root:current train perplexity174.9727020263672
INFO:root:current mean train loss 6546.940767840485
INFO:root:current train perplexity174.64669799804688
INFO:root:current mean train loss 6548.602098341112
INFO:root:current train perplexity174.7404022216797
INFO:root:current mean train loss 6544.070416329921
INFO:root:current train perplexity174.77740478515625
INFO:root:current mean train loss 6545.000574359698
INFO:root:current train perplexity174.77774047851562
INFO:root:current mean train loss 6542.087388197284
INFO:root:current train perplexity175.01901245117188
INFO:root:current mean train loss 6540.410385783921
INFO:root:current train perplexity175.01759338378906
INFO:root:current mean train loss 6538.848025728962
INFO:root:current train perplexity175.013671875
INFO:root:current mean train loss 6543.007546261975
INFO:root:current train perplexity175.11358642578125
INFO:root:current mean train loss 6545.1231913663905
INFO:root:current train perplexity175.10507202148438
INFO:root:current mean train loss 6543.939656212679
INFO:root:current train perplexity175.0479736328125
INFO:root:current mean train loss 6548.367256795003
INFO:root:current train perplexity175.33810424804688
INFO:root:current mean train loss 6550.237178065413
INFO:root:current train perplexity175.2106475830078
INFO:root:current mean train loss 6553.225027939087
INFO:root:current train perplexity175.34913635253906
INFO:root:current mean train loss 6554.6474973727
INFO:root:current train perplexity175.47067260742188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.97s/it]
INFO:root:final mean train loss: 6552.036595485454
INFO:root:final train perplexity: 175.44573974609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it]
INFO:root:eval mean loss: 6336.112586920988
INFO:root:eval perplexity: 168.0523681640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.59s/it]
INFO:root:eval mean loss: 6453.53940014129
INFO:root:eval perplexity: 195.9544219970703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [10:25:28<5:47:22, 578.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6596.284611844469
INFO:root:current train perplexity175.61456298828125
INFO:root:current mean train loss 6548.071644176136
INFO:root:current train perplexity174.1460723876953
INFO:root:current mean train loss 6550.9607129246515
INFO:root:current train perplexity175.59922790527344
INFO:root:current mean train loss 6550.452226663437
INFO:root:current train perplexity175.3257293701172
INFO:root:current mean train loss 6543.55749586916
INFO:root:current train perplexity175.26795959472656
INFO:root:current mean train loss 6557.083828823733
INFO:root:current train perplexity175.32981872558594
INFO:root:current mean train loss 6549.945219392513
INFO:root:current train perplexity175.48397827148438
INFO:root:current mean train loss 6551.381788164113
INFO:root:current train perplexity175.943115234375
INFO:root:current mean train loss 6561.619241363973
INFO:root:current train perplexity177.24461364746094
INFO:root:current mean train loss 6563.392250130604
INFO:root:current train perplexity177.9946746826172
INFO:root:current mean train loss 6565.0190887872295
INFO:root:current train perplexity178.5227813720703
INFO:root:current mean train loss 6569.072486112574
INFO:root:current train perplexity178.87001037597656
INFO:root:current mean train loss 6570.796525956682
INFO:root:current train perplexity179.06134033203125
INFO:root:current mean train loss 6570.53937405653
INFO:root:current train perplexity179.29295349121094
INFO:root:current mean train loss 6576.915255456141
INFO:root:current train perplexity179.7023468017578
INFO:root:current mean train loss 6579.191679773649
INFO:root:current train perplexity179.8262939453125
INFO:root:current mean train loss 6580.258645501445
INFO:root:current train perplexity179.61538696289062
INFO:root:current mean train loss 6575.629893195649
INFO:root:current train perplexity179.3162078857422
INFO:root:current mean train loss 6580.316018367862
INFO:root:current train perplexity179.5212860107422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.79s/it]
INFO:root:final mean train loss: 6583.6470897403315
INFO:root:final train perplexity: 179.87466430664062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 6345.919154823249
INFO:root:eval perplexity: 169.39053344726562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 6463.343446122839
INFO:root:eval perplexity: 197.5319061279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [10:35:25<5:40:49, 584.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6387.392822265625
INFO:root:current train perplexity172.0885772705078
INFO:root:current mean train loss 6543.797443096454
INFO:root:current train perplexity177.5725860595703
INFO:root:current mean train loss 6534.668148265166
INFO:root:current train perplexity176.51808166503906
INFO:root:current mean train loss 6520.112519916735
INFO:root:current train perplexity175.38375854492188
INFO:root:current mean train loss 6528.578479124768
INFO:root:current train perplexity175.19769287109375
INFO:root:current mean train loss 6529.63762749566
INFO:root:current train perplexity174.4657440185547
INFO:root:current mean train loss 6539.369751784975
INFO:root:current train perplexity174.53854370117188
INFO:root:current mean train loss 6538.872630726208
INFO:root:current train perplexity174.3321075439453
INFO:root:current mean train loss 6539.304924352845
INFO:root:current train perplexity174.12033081054688
INFO:root:current mean train loss 6541.289286655662
INFO:root:current train perplexity174.4693145751953
INFO:root:current mean train loss 6540.279442775772
INFO:root:current train perplexity174.2803955078125
INFO:root:current mean train loss 6541.3743931867075
INFO:root:current train perplexity173.927734375
INFO:root:current mean train loss 6542.680255674444
INFO:root:current train perplexity173.81788635253906
INFO:root:current mean train loss 6542.581852637917
INFO:root:current train perplexity173.7833251953125
INFO:root:current mean train loss 6542.811081063034
INFO:root:current train perplexity173.84042358398438
INFO:root:current mean train loss 6545.8150040646815
INFO:root:current train perplexity174.017333984375
INFO:root:current mean train loss 6547.614881558311
INFO:root:current train perplexity174.30674743652344
INFO:root:current mean train loss 6548.922698831334
INFO:root:current train perplexity174.66351318359375
INFO:root:current mean train loss 6551.759758317021
INFO:root:current train perplexity175.1607666015625
INFO:root:current mean train loss 6551.9689772149095
INFO:root:current train perplexity175.22860717773438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.67s/it]
INFO:root:final mean train loss: 6549.867443459838
INFO:root:final train perplexity: 175.14590454101562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 6338.112195603391
INFO:root:eval perplexity: 168.32440185546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 6465.24518991024
INFO:root:eval perplexity: 197.83929443359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [10:45:04<5:30:11, 582.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6577.843215215774
INFO:root:current train perplexity176.2731475830078
INFO:root:current mean train loss 6560.8649276859505
INFO:root:current train perplexity176.01654052734375
INFO:root:current mean train loss 6592.429128517392
INFO:root:current train perplexity177.70904541015625
INFO:root:current mean train loss 6572.733620521807
INFO:root:current train perplexity177.34986877441406
INFO:root:current mean train loss 6565.74247861305
INFO:root:current train perplexity177.17845153808594
INFO:root:current mean train loss 6564.93418231166
INFO:root:current train perplexity177.373046875
INFO:root:current mean train loss 6563.51747826716
INFO:root:current train perplexity177.488525390625
INFO:root:current mean train loss 6570.9707281824285
INFO:root:current train perplexity177.89947509765625
INFO:root:current mean train loss 6569.744649722137
INFO:root:current train perplexity177.7822723388672
INFO:root:current mean train loss 6562.742801960335
INFO:root:current train perplexity177.49961853027344
INFO:root:current mean train loss 6556.688444520538
INFO:root:current train perplexity177.18038940429688
INFO:root:current mean train loss 6561.854892482298
INFO:root:current train perplexity177.1712646484375
INFO:root:current mean train loss 6554.093636027718
INFO:root:current train perplexity176.55966186523438
INFO:root:current mean train loss 6552.071111270463
INFO:root:current train perplexity176.54307556152344
INFO:root:current mean train loss 6558.088578548338
INFO:root:current train perplexity176.98077392578125
INFO:root:current mean train loss 6565.949635763375
INFO:root:current train perplexity177.18655395507812
INFO:root:current mean train loss 6569.134349938309
INFO:root:current train perplexity177.32948303222656
INFO:root:current mean train loss 6570.044553039657
INFO:root:current train perplexity177.74082946777344
INFO:root:current mean train loss 6571.874829999829
INFO:root:current train perplexity178.06666564941406
INFO:root:current mean train loss 6576.862771109204
INFO:root:current train perplexity178.69601440429688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.45s/it]
INFO:root:final mean train loss: 6576.40470537656
INFO:root:final train perplexity: 178.8502197265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 6402.60188628934
INFO:root:eval perplexity: 177.3365020751953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 6509.029412885085
INFO:root:eval perplexity: 205.05191040039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [10:54:52<5:21:17, 584.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6508.4219777960525
INFO:root:current train perplexity178.65383911132812
INFO:root:current mean train loss 6567.142659505208
INFO:root:current train perplexity178.48907470703125
INFO:root:current mean train loss 6550.993354861476
INFO:root:current train perplexity175.2013702392578
INFO:root:current mean train loss 6545.762030787722
INFO:root:current train perplexity174.15139770507812
INFO:root:current mean train loss 6532.924876034532
INFO:root:current train perplexity173.04638671875
INFO:root:current mean train loss 6529.8142280436805
INFO:root:current train perplexity172.171142578125
INFO:root:current mean train loss 6526.917914411491
INFO:root:current train perplexity171.85781860351562
INFO:root:current mean train loss 6517.571459100822
INFO:root:current train perplexity171.6177978515625
INFO:root:current mean train loss 6516.442674732436
INFO:root:current train perplexity171.34207153320312
INFO:root:current mean train loss 6516.259570937167
INFO:root:current train perplexity171.1252899169922
INFO:root:current mean train loss 6512.9991814938585
INFO:root:current train perplexity170.8673095703125
INFO:root:current mean train loss 6513.791404791164
INFO:root:current train perplexity170.7118377685547
INFO:root:current mean train loss 6517.141871734274
INFO:root:current train perplexity170.691162109375
INFO:root:current mean train loss 6518.2401212455625
INFO:root:current train perplexity170.75628662109375
INFO:root:current mean train loss 6519.701072045593
INFO:root:current train perplexity170.6240234375
INFO:root:current mean train loss 6519.798364607038
INFO:root:current train perplexity170.57359313964844
INFO:root:current mean train loss 6519.828028416896
INFO:root:current train perplexity170.56065368652344
INFO:root:current mean train loss 6516.795119659811
INFO:root:current train perplexity170.52789306640625
INFO:root:current mean train loss 6515.251138348834
INFO:root:current train perplexity170.5403289794922
INFO:root:current mean train loss 6519.5252878289475
INFO:root:current train perplexity170.76043701171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.37s/it]
INFO:root:final mean train loss: 6517.589291940479
INFO:root:final train perplexity: 170.74359130859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it]
INFO:root:eval mean loss: 6382.181159269725
INFO:root:eval perplexity: 174.43179321289062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.56s/it]
INFO:root:eval mean loss: 6503.520572743518
INFO:root:eval perplexity: 204.13009643554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [11:04:28<5:10:18, 581.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6564.378293678978
INFO:root:current train perplexity173.05389404296875
INFO:root:current mean train loss 6545.15945375504
INFO:root:current train perplexity171.74017333984375
INFO:root:current mean train loss 6535.530585554534
INFO:root:current train perplexity170.99070739746094
INFO:root:current mean train loss 6527.556109705106
INFO:root:current train perplexity170.73944091796875
INFO:root:current mean train loss 6538.54899660886
INFO:root:current train perplexity170.92141723632812
INFO:root:current mean train loss 6542.131004539696
INFO:root:current train perplexity170.956298828125
INFO:root:current mean train loss 6533.099758468511
INFO:root:current train perplexity170.92703247070312
INFO:root:current mean train loss 6532.204728890729
INFO:root:current train perplexity170.9492950439453
INFO:root:current mean train loss 6531.169827645285
INFO:root:current train perplexity171.0753631591797
INFO:root:current mean train loss 6530.328241573953
INFO:root:current train perplexity171.0015411376953
INFO:root:current mean train loss 6532.57684991484
INFO:root:current train perplexity171.01345825195312
INFO:root:current mean train loss 6529.658406892587
INFO:root:current train perplexity170.99388122558594
INFO:root:current mean train loss 6526.007880587027
INFO:root:current train perplexity170.91000366210938
INFO:root:current mean train loss 6523.069963315844
INFO:root:current train perplexity170.8950958251953
INFO:root:current mean train loss 6524.203816983462
INFO:root:current train perplexity170.8417205810547
INFO:root:current mean train loss 6525.931139783461
INFO:root:current train perplexity170.94561767578125
INFO:root:current mean train loss 6524.19805130051
INFO:root:current train perplexity170.9529571533203
INFO:root:current mean train loss 6526.2263159944805
INFO:root:current train perplexity171.0062713623047
INFO:root:current mean train loss 6520.8762969065865
INFO:root:current train perplexity170.89346313476562
INFO:root:current mean train loss 6520.610017882833
INFO:root:current train perplexity170.97659301757812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.02s/it]
INFO:root:final mean train loss: 6519.308517910048
INFO:root:final train perplexity: 170.9752197265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 6376.319460605053
INFO:root:eval perplexity: 173.60682678222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.29s/it]
INFO:root:eval mean loss: 6496.498684930463
INFO:root:eval perplexity: 202.9612274169922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [11:14:06<5:00:05, 580.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6549.615939670139
INFO:root:current train perplexity169.55999755859375
INFO:root:current mean train loss 6545.216569767442
INFO:root:current train perplexity170.45089721679688
INFO:root:current mean train loss 6530.83536305147
INFO:root:current train perplexity170.31951904296875
INFO:root:current mean train loss 6527.63185562626
INFO:root:current train perplexity170.2593536376953
INFO:root:current mean train loss 6514.152038574219
INFO:root:current train perplexity169.8966064453125
INFO:root:current mean train loss 6509.415646853146
INFO:root:current train perplexity169.7122344970703
INFO:root:current mean train loss 6509.173608689081
INFO:root:current train perplexity169.52418518066406
INFO:root:current mean train loss 6511.0842949269345
INFO:root:current train perplexity169.5133514404297
INFO:root:current mean train loss 6508.4188484401875
INFO:root:current train perplexity169.48611450195312
INFO:root:current mean train loss 6514.863732859922
INFO:root:current train perplexity169.8673553466797
INFO:root:current mean train loss 6507.066998382113
INFO:root:current train perplexity169.8497772216797
INFO:root:current mean train loss 6508.170759702299
INFO:root:current train perplexity169.78451538085938
INFO:root:current mean train loss 6502.144116287711
INFO:root:current train perplexity169.49322509765625
INFO:root:current mean train loss 6504.316002670599
INFO:root:current train perplexity169.57212829589844
INFO:root:current mean train loss 6506.097803862199
INFO:root:current train perplexity169.68682861328125
INFO:root:current mean train loss 6505.699075558106
INFO:root:current train perplexity169.56080627441406
INFO:root:current mean train loss 6508.799224415464
INFO:root:current train perplexity169.67630004882812
INFO:root:current mean train loss 6512.471482391013
INFO:root:current train perplexity169.81373596191406
INFO:root:current mean train loss 6512.85605353983
INFO:root:current train perplexity169.7620086669922
INFO:root:current mean train loss 6511.097645850501
INFO:root:current train perplexity169.6415252685547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.90s/it]
INFO:root:final mean train loss: 6509.393370135409
INFO:root:final train perplexity: 169.64353942871094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 6355.783357227948
INFO:root:eval perplexity: 170.74725341796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 6473.945024206283
INFO:root:eval perplexity: 199.25192260742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [11:23:56<4:51:43, 583.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6419.718130047401
INFO:root:current train perplexity165.30091857910156
INFO:root:current mean train loss 6459.935309193122
INFO:root:current train perplexity167.68968200683594
INFO:root:current mean train loss 6510.551125919118
INFO:root:current train perplexity169.1087188720703
INFO:root:current mean train loss 6494.194900787275
INFO:root:current train perplexity168.37225341796875
INFO:root:current mean train loss 6494.691290420501
INFO:root:current train perplexity168.45480346679688
INFO:root:current mean train loss 6494.519771660123
INFO:root:current train perplexity168.54608154296875
INFO:root:current mean train loss 6497.439952036466
INFO:root:current train perplexity168.69676208496094
INFO:root:current mean train loss 6502.781019164884
INFO:root:current train perplexity168.5639190673828
INFO:root:current mean train loss 6501.825674256538
INFO:root:current train perplexity168.54824829101562
INFO:root:current mean train loss 6502.141702279765
INFO:root:current train perplexity168.55789184570312
INFO:root:current mean train loss 6498.334440373193
INFO:root:current train perplexity168.4001922607422
INFO:root:current mean train loss 6498.964950112358
INFO:root:current train perplexity168.4281463623047
INFO:root:current mean train loss 6498.169499506037
INFO:root:current train perplexity168.37513732910156
INFO:root:current mean train loss 6496.715949325617
INFO:root:current train perplexity168.35130310058594
INFO:root:current mean train loss 6499.1173334269015
INFO:root:current train perplexity168.45994567871094
INFO:root:current mean train loss 6499.652308104547
INFO:root:current train perplexity168.56288146972656
INFO:root:current mean train loss 6499.471363128608
INFO:root:current train perplexity168.4965057373047
INFO:root:current mean train loss 6503.02983100938
INFO:root:current train perplexity168.5443115234375
INFO:root:current mean train loss 6503.169856219395
INFO:root:current train perplexity168.60829162597656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.40s/it]
INFO:root:final mean train loss: 6502.042192129192
INFO:root:final train perplexity: 168.66281127929688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 6363.833541112589
INFO:root:eval perplexity: 171.86256408691406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 6481.87215688719
INFO:root:eval perplexity: 200.5479736328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [11:33:32<4:40:54, 581.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6615.44580078125
INFO:root:current train perplexity162.513671875
INFO:root:current mean train loss 6461.060141509434
INFO:root:current train perplexity165.7139892578125
INFO:root:current mean train loss 6511.628285232099
INFO:root:current train perplexity166.9999237060547
INFO:root:current mean train loss 6513.7433427798205
INFO:root:current train perplexity167.53350830078125
INFO:root:current mean train loss 6521.838939347291
INFO:root:current train perplexity168.09725952148438
INFO:root:current mean train loss 6504.775511247838
INFO:root:current train perplexity167.70616149902344
INFO:root:current mean train loss 6507.441946904652
INFO:root:current train perplexity167.84671020507812
INFO:root:current mean train loss 6500.501883271733
INFO:root:current train perplexity167.61692810058594
INFO:root:current mean train loss 6490.908685953978
INFO:root:current train perplexity167.63595581054688
INFO:root:current mean train loss 6486.153220069329
INFO:root:current train perplexity167.50491333007812
INFO:root:current mean train loss 6492.170013609748
INFO:root:current train perplexity167.6318817138672
INFO:root:current mean train loss 6496.476937319874
INFO:root:current train perplexity167.87472534179688
INFO:root:current mean train loss 6498.018277751866
INFO:root:current train perplexity167.94134521484375
INFO:root:current mean train loss 6496.271369595257
INFO:root:current train perplexity167.90835571289062
INFO:root:current mean train loss 6496.868694017825
INFO:root:current train perplexity167.89089965820312
INFO:root:current mean train loss 6498.731391491327
INFO:root:current train perplexity168.0013427734375
INFO:root:current mean train loss 6498.676957867956
INFO:root:current train perplexity167.9752197265625
INFO:root:current mean train loss 6501.990062932756
INFO:root:current train perplexity168.02249145507812
INFO:root:current mean train loss 6501.204027211811
INFO:root:current train perplexity167.9906768798828
INFO:root:current mean train loss 6501.2768014145295
INFO:root:current train perplexity168.0187225341797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.81s/it]
INFO:root:final mean train loss: 6497.381984416367
INFO:root:final train perplexity: 168.04403686523438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 6361.042658812611
INFO:root:eval perplexity: 171.47512817382812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 6479.612150584552
INFO:root:eval perplexity: 200.1775665283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [11:43:18<4:31:56, 582.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6614.963612432065
INFO:root:current train perplexity170.6573944091797
INFO:root:current mean train loss 6539.238813198679
INFO:root:current train perplexity169.0767059326172
INFO:root:current mean train loss 6524.647353647001
INFO:root:current train perplexity168.8827667236328
INFO:root:current mean train loss 6517.113966053115
INFO:root:current train perplexity168.29623413085938
INFO:root:current mean train loss 6519.510070367908
INFO:root:current train perplexity168.1983642578125
INFO:root:current mean train loss 6512.046416594467
INFO:root:current train perplexity168.01519775390625
INFO:root:current mean train loss 6510.068614096358
INFO:root:current train perplexity168.13966369628906
INFO:root:current mean train loss 6500.167658086964
INFO:root:current train perplexity167.7287139892578
INFO:root:current mean train loss 6497.311465294653
INFO:root:current train perplexity167.72486877441406
INFO:root:current mean train loss 6497.517734184555
INFO:root:current train perplexity167.82919311523438
INFO:root:current mean train loss 6491.168801166911
INFO:root:current train perplexity167.7157440185547
INFO:root:current mean train loss 6493.272324844863
INFO:root:current train perplexity167.79342651367188
INFO:root:current mean train loss 6492.929041914733
INFO:root:current train perplexity167.6980743408203
INFO:root:current mean train loss 6492.131424792139
INFO:root:current train perplexity167.5350341796875
INFO:root:current mean train loss 6492.243363767129
INFO:root:current train perplexity167.56874084472656
INFO:root:current mean train loss 6496.673919497394
INFO:root:current train perplexity167.68824768066406
INFO:root:current mean train loss 6492.949286140634
INFO:root:current train perplexity167.54501342773438
INFO:root:current mean train loss 6493.257659469312
INFO:root:current train perplexity167.53878784179688
INFO:root:current mean train loss 6492.2133877451315
INFO:root:current train perplexity167.53575134277344
INFO:root:current mean train loss 6494.3233155693415
INFO:root:current train perplexity167.61093139648438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.19s/it]
INFO:root:final mean train loss: 6494.2788818482495
INFO:root:final train perplexity: 167.63339233398438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 6352.150293661348
INFO:root:eval perplexity: 170.24620056152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it]
INFO:root:eval mean loss: 6469.563931079621
INFO:root:eval perplexity: 198.53929138183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [11:52:54<4:21:20, 580.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6487.830700683594
INFO:root:current train perplexity166.2781982421875
INFO:root:current mean train loss 6503.416967773437
INFO:root:current train perplexity167.1419677734375
INFO:root:current mean train loss 6530.674188232422
INFO:root:current train perplexity167.973388671875
INFO:root:current mean train loss 6503.888821231618
INFO:root:current train perplexity167.2240753173828
INFO:root:current mean train loss 6504.850726873225
INFO:root:current train perplexity167.34396362304688
INFO:root:current mean train loss 6509.669460720486
INFO:root:current train perplexity167.2239990234375
INFO:root:current mean train loss 6503.514671325684
INFO:root:current train perplexity167.11248779296875
INFO:root:current mean train loss 6501.367015941723
INFO:root:current train perplexity167.1765594482422
INFO:root:current mean train loss 6501.672405715216
INFO:root:current train perplexity167.1456298828125
INFO:root:current mean train loss 6502.424229138963
INFO:root:current train perplexity167.25318908691406
INFO:root:current mean train loss 6497.226590200571
INFO:root:current train perplexity167.0955047607422
INFO:root:current mean train loss 6496.794487561678
INFO:root:current train perplexity167.1151885986328
INFO:root:current mean train loss 6496.741145964592
INFO:root:current train perplexity167.13758850097656
INFO:root:current mean train loss 6496.404554133629
INFO:root:current train perplexity167.22145080566406
INFO:root:current mean train loss 6496.088955349393
INFO:root:current train perplexity167.21539306640625
INFO:root:current mean train loss 6494.009416535613
INFO:root:current train perplexity167.03448486328125
INFO:root:current mean train loss 6491.486668433213
INFO:root:current train perplexity167.06149291992188
INFO:root:current mean train loss 6495.00002188847
INFO:root:current train perplexity167.11009216308594
INFO:root:current mean train loss 6494.359300430961
INFO:root:current train perplexity167.0132293701172
INFO:root:current mean train loss 6492.835075960455
INFO:root:current train perplexity166.9618682861328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.19s/it]
INFO:root:final mean train loss: 6488.968532452605
INFO:root:final train perplexity: 166.93272399902344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 6348.277090951906
INFO:root:eval perplexity: 169.71392822265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.55s/it]
INFO:root:eval mean loss: 6463.841460099457
INFO:root:eval perplexity: 197.61236572265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [12:02:33<4:11:25, 580.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6377.409222519189
INFO:root:current train perplexity162.95791625976562
INFO:root:current mean train loss 6475.089193745024
INFO:root:current train perplexity165.93482971191406
INFO:root:current mean train loss 6495.974033697106
INFO:root:current train perplexity166.75730895996094
INFO:root:current mean train loss 6478.025966441264
INFO:root:current train perplexity166.43112182617188
INFO:root:current mean train loss 6490.705793985913
INFO:root:current train perplexity166.69703674316406
INFO:root:current mean train loss 6471.838477088476
INFO:root:current train perplexity166.1815643310547
INFO:root:current mean train loss 6477.618781660245
INFO:root:current train perplexity166.23451232910156
INFO:root:current mean train loss 6479.116194811963
INFO:root:current train perplexity166.32846069335938
INFO:root:current mean train loss 6475.1909612702375
INFO:root:current train perplexity166.2350616455078
INFO:root:current mean train loss 6482.3578586239555
INFO:root:current train perplexity166.5191650390625
INFO:root:current mean train loss 6484.502086166627
INFO:root:current train perplexity166.55274963378906
INFO:root:current mean train loss 6482.502852879214
INFO:root:current train perplexity166.47097778320312
INFO:root:current mean train loss 6484.594781722355
INFO:root:current train perplexity166.5392608642578
INFO:root:current mean train loss 6486.344586950765
INFO:root:current train perplexity166.6251983642578
INFO:root:current mean train loss 6487.9926402577
INFO:root:current train perplexity166.70777893066406
INFO:root:current mean train loss 6487.272392885457
INFO:root:current train perplexity166.7948455810547
INFO:root:current mean train loss 6487.484776940631
INFO:root:current train perplexity166.8458251953125
INFO:root:current mean train loss 6489.152467974086
INFO:root:current train perplexity166.8618927001953
INFO:root:current mean train loss 6491.486741205153
INFO:root:current train perplexity166.9613800048828
INFO:root:current mean train loss 6490.282830863566
INFO:root:current train perplexity166.88218688964844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.28s/it]
INFO:root:final mean train loss: 6488.366409278673
INFO:root:final train perplexity: 166.85354614257812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 6347.147552706671
INFO:root:eval perplexity: 169.55886840820312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it]
INFO:root:eval mean loss: 6463.653457966257
INFO:root:eval perplexity: 197.58201599121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [12:12:24<4:03:05, 583.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6497.877467799831
INFO:root:current train perplexity166.5954132080078
INFO:root:current mean train loss 6481.541071749281
INFO:root:current train perplexity166.4368438720703
INFO:root:current mean train loss 6465.21142578125
INFO:root:current train perplexity166.125244140625
INFO:root:current mean train loss 6467.773899669954
INFO:root:current train perplexity165.94647216796875
INFO:root:current mean train loss 6476.159938892734
INFO:root:current train perplexity166.31625366210938
INFO:root:current mean train loss 6487.441076192291
INFO:root:current train perplexity166.49598693847656
INFO:root:current mean train loss 6488.411721068249
INFO:root:current train perplexity166.65380859375
INFO:root:current mean train loss 6492.220972499798
INFO:root:current train perplexity166.58285522460938
INFO:root:current mean train loss 6485.986649362664
INFO:root:current train perplexity166.47955322265625
INFO:root:current mean train loss 6491.918580354851
INFO:root:current train perplexity166.60572814941406
INFO:root:current mean train loss 6495.972827193901
INFO:root:current train perplexity166.6637420654297
INFO:root:current mean train loss 6491.7596142328575
INFO:root:current train perplexity166.6942596435547
INFO:root:current mean train loss 6487.207407617494
INFO:root:current train perplexity166.56903076171875
INFO:root:current mean train loss 6491.817497597684
INFO:root:current train perplexity166.7095184326172
INFO:root:current mean train loss 6490.738312057433
INFO:root:current train perplexity166.69775390625
INFO:root:current mean train loss 6488.331384447963
INFO:root:current train perplexity166.60946655273438
INFO:root:current mean train loss 6490.540619516316
INFO:root:current train perplexity166.6435546875
INFO:root:current mean train loss 6492.018246415234
INFO:root:current train perplexity166.6846466064453
INFO:root:current mean train loss 6490.033143457761
INFO:root:current train perplexity166.6080322265625
INFO:root:current mean train loss 6487.809468896435
INFO:root:current train perplexity166.57420349121094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.27s/it]
INFO:root:final mean train loss: 6486.192996796009
INFO:root:final train perplexity: 166.56776428222656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 6343.869618517288
INFO:root:eval perplexity: 169.11000061035156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it]
INFO:root:eval mean loss: 6460.214072369515
INFO:root:eval perplexity: 197.0270233154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [12:21:53<3:51:37, 579.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6382.611113495879
INFO:root:current train perplexity166.1176300048828
INFO:root:current mean train loss 6458.456064913285
INFO:root:current train perplexity167.206298828125
INFO:root:current mean train loss 6439.237059707903
INFO:root:current train perplexity166.6236114501953
INFO:root:current mean train loss 6455.754062350144
INFO:root:current train perplexity166.33639526367188
INFO:root:current mean train loss 6454.536946283096
INFO:root:current train perplexity166.47470092773438
INFO:root:current mean train loss 6457.604576459391
INFO:root:current train perplexity166.3181610107422
INFO:root:current mean train loss 6471.709311544636
INFO:root:current train perplexity166.58428955078125
INFO:root:current mean train loss 6470.611100960019
INFO:root:current train perplexity166.78036499023438
INFO:root:current mean train loss 6473.7156816647375
INFO:root:current train perplexity166.82260131835938
INFO:root:current mean train loss 6477.599367944311
INFO:root:current train perplexity166.7666015625
INFO:root:current mean train loss 6477.1202850201935
INFO:root:current train perplexity166.8436737060547
INFO:root:current mean train loss 6481.23563280594
INFO:root:current train perplexity166.86062622070312
INFO:root:current mean train loss 6480.281901293813
INFO:root:current train perplexity166.71826171875
INFO:root:current mean train loss 6485.266790065039
INFO:root:current train perplexity166.7514190673828
INFO:root:current mean train loss 6486.738039238033
INFO:root:current train perplexity166.777099609375
INFO:root:current mean train loss 6487.359856529403
INFO:root:current train perplexity166.88671875
INFO:root:current mean train loss 6486.148277819615
INFO:root:current train perplexity166.8482208251953
INFO:root:current mean train loss 6490.075801370132
INFO:root:current train perplexity166.87765502929688
INFO:root:current mean train loss 6488.108770781002
INFO:root:current train perplexity166.84255981445312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.51s/it]
INFO:root:final mean train loss: 6488.073273951636
INFO:root:final train perplexity: 166.81495666503906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 6342.0253871620125
INFO:root:eval perplexity: 168.8579559326172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.37s/it]
INFO:root:eval mean loss: 6458.535915510029
INFO:root:eval perplexity: 196.75672912597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [12:31:23<3:40:54, 576.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6307.273376464844
INFO:root:current train perplexity158.2299346923828
INFO:root:current mean train loss 6502.948300962095
INFO:root:current train perplexity166.17031860351562
INFO:root:current mean train loss 6475.136793870192
INFO:root:current train perplexity165.75137329101562
INFO:root:current mean train loss 6462.916890726461
INFO:root:current train perplexity165.9241485595703
INFO:root:current mean train loss 6474.355380189185
INFO:root:current train perplexity166.38955688476562
INFO:root:current mean train loss 6476.1046632781745
INFO:root:current train perplexity166.5009765625
INFO:root:current mean train loss 6472.41914608604
INFO:root:current train perplexity166.5474395751953
INFO:root:current mean train loss 6470.6889758783545
INFO:root:current train perplexity166.4434356689453
INFO:root:current mean train loss 6484.620588548112
INFO:root:current train perplexity166.91012573242188
INFO:root:current mean train loss 6489.956858630748
INFO:root:current train perplexity167.25079345703125
INFO:root:current mean train loss 6489.822138226222
INFO:root:current train perplexity167.24609375
INFO:root:current mean train loss 6492.294902484769
INFO:root:current train perplexity167.35626220703125
INFO:root:current mean train loss 6492.676498312035
INFO:root:current train perplexity167.342529296875
INFO:root:current mean train loss 6495.169153989273
INFO:root:current train perplexity167.37405395507812
INFO:root:current mean train loss 6493.926478992809
INFO:root:current train perplexity167.35450744628906
INFO:root:current mean train loss 6494.6481600086
INFO:root:current train perplexity167.3818817138672
INFO:root:current mean train loss 6498.347093572664
INFO:root:current train perplexity167.46226501464844
INFO:root:current mean train loss 6496.669025072728
INFO:root:current train perplexity167.3944091796875
INFO:root:current mean train loss 6493.823751804048
INFO:root:current train perplexity167.3074188232422
INFO:root:current mean train loss 6492.02270354265
INFO:root:current train perplexity167.20932006835938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.99s/it]
INFO:root:final mean train loss: 6490.614007269801
INFO:root:final train perplexity: 167.1494598388672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 6346.639830244349
INFO:root:eval perplexity: 169.48934936523438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.67s/it]
INFO:root:eval mean loss: 6462.37661548371
INFO:root:eval perplexity: 197.37579345703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [12:41:02<3:31:35, 577.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6465.95322265625
INFO:root:current train perplexity165.10501098632812
INFO:root:current mean train loss 6411.0344453125
INFO:root:current train perplexity164.4228973388672
INFO:root:current mean train loss 6455.566584201389
INFO:root:current train perplexity166.18093872070312
INFO:root:current mean train loss 6465.138649338943
INFO:root:current train perplexity166.38677978515625
INFO:root:current mean train loss 6465.337454044117
INFO:root:current train perplexity166.40431213378906
INFO:root:current mean train loss 6471.814228980655
INFO:root:current train perplexity166.30911254882812
INFO:root:current mean train loss 6456.81254296875
INFO:root:current train perplexity166.1802215576172
INFO:root:current mean train loss 6463.344037580819
INFO:root:current train perplexity166.3774871826172
INFO:root:current mean train loss 6475.139161339962
INFO:root:current train perplexity166.56211853027344
INFO:root:current mean train loss 6474.450070734797
INFO:root:current train perplexity166.4171600341797
INFO:root:current mean train loss 6468.226619188262
INFO:root:current train perplexity166.294921875
INFO:root:current mean train loss 6475.904712239583
INFO:root:current train perplexity166.47764587402344
INFO:root:current mean train loss 6481.646771763393
INFO:root:current train perplexity166.63775634765625
INFO:root:current mean train loss 6482.953003021816
INFO:root:current train perplexity166.60549926757812
INFO:root:current mean train loss 6485.496238007127
INFO:root:current train perplexity166.6756591796875
INFO:root:current mean train loss 6486.984391329405
INFO:root:current train perplexity166.64791870117188
INFO:root:current mean train loss 6485.047104867788
INFO:root:current train perplexity166.64498901367188
INFO:root:current mean train loss 6488.506702615489
INFO:root:current train perplexity166.66818237304688
INFO:root:current mean train loss 6491.275900042809
INFO:root:current train perplexity166.74465942382812
INFO:root:current mean train loss 6490.185094105113
INFO:root:current train perplexity166.75340270996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.41s/it]
INFO:root:final mean train loss: 6487.837911308623
INFO:root:final train perplexity: 166.783935546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 6351.963860261525
INFO:root:eval perplexity: 170.22064208984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.84s/it]
INFO:root:eval mean loss: 6469.278388706505
INFO:root:eval perplexity: 198.4929962158203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [12:50:42<3:22:20, 578.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6505.719366164434
INFO:root:current train perplexity166.18878173828125
INFO:root:current mean train loss 6538.601094850352
INFO:root:current train perplexity168.39361572265625
INFO:root:current mean train loss 6524.390641141529
INFO:root:current train perplexity168.0973358154297
INFO:root:current mean train loss 6512.462793539839
INFO:root:current train perplexity168.08058166503906
INFO:root:current mean train loss 6494.464661473063
INFO:root:current train perplexity167.50347900390625
INFO:root:current mean train loss 6492.695201690786
INFO:root:current train perplexity167.20669555664062
INFO:root:current mean train loss 6497.28905413381
INFO:root:current train perplexity167.15264892578125
INFO:root:current mean train loss 6497.357533087306
INFO:root:current train perplexity167.22909545898438
INFO:root:current mean train loss 6490.783475101136
INFO:root:current train perplexity167.0023193359375
INFO:root:current mean train loss 6486.354103428543
INFO:root:current train perplexity166.812255859375
INFO:root:current mean train loss 6492.406366212812
INFO:root:current train perplexity166.963134765625
INFO:root:current mean train loss 6485.185926981858
INFO:root:current train perplexity166.79373168945312
INFO:root:current mean train loss 6484.23014440859
INFO:root:current train perplexity166.73997497558594
INFO:root:current mean train loss 6483.939496786513
INFO:root:current train perplexity166.8208465576172
INFO:root:current mean train loss 6484.724613099753
INFO:root:current train perplexity166.91903686523438
INFO:root:current mean train loss 6487.430094717696
INFO:root:current train perplexity166.8704071044922
INFO:root:current mean train loss 6488.308417112325
INFO:root:current train perplexity166.77615356445312
INFO:root:current mean train loss 6486.7775749968605
INFO:root:current train perplexity166.72970581054688
INFO:root:current mean train loss 6490.252197530707
INFO:root:current train perplexity166.84678649902344
INFO:root:current mean train loss 6488.775242280027
INFO:root:current train perplexity166.7943572998047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.54s/it]
INFO:root:final mean train loss: 6488.243895745674
INFO:root:final train perplexity: 166.83738708496094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it]
INFO:root:eval mean loss: 6344.322894157247
INFO:root:eval perplexity: 169.17202758789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.24s/it]
INFO:root:eval mean loss: 6462.019887071975
INFO:root:eval perplexity: 197.31820678710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [13:00:10<3:11:42, 575.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6500.727034229343
INFO:root:current train perplexity165.8997039794922
INFO:root:current mean train loss 6488.018996904481
INFO:root:current train perplexity165.9545440673828
INFO:root:current mean train loss 6467.924225913972
INFO:root:current train perplexity165.29721069335938
INFO:root:current mean train loss 6481.745719718402
INFO:root:current train perplexity165.5536651611328
INFO:root:current mean train loss 6476.699676181236
INFO:root:current train perplexity165.40467834472656
INFO:root:current mean train loss 6489.176389199463
INFO:root:current train perplexity165.69384765625
INFO:root:current mean train loss 6492.607718252087
INFO:root:current train perplexity165.9831085205078
INFO:root:current mean train loss 6488.486077229496
INFO:root:current train perplexity166.0157928466797
INFO:root:current mean train loss 6482.515452197323
INFO:root:current train perplexity166.00352478027344
INFO:root:current mean train loss 6484.437210799009
INFO:root:current train perplexity166.15011596679688
INFO:root:current mean train loss 6486.019734124174
INFO:root:current train perplexity166.26470947265625
INFO:root:current mean train loss 6484.950582061583
INFO:root:current train perplexity166.17031860351562
INFO:root:current mean train loss 6488.352374621475
INFO:root:current train perplexity166.23403930664062
INFO:root:current mean train loss 6487.86868647673
INFO:root:current train perplexity166.1338653564453
INFO:root:current mean train loss 6488.47730345592
INFO:root:current train perplexity166.08270263671875
INFO:root:current mean train loss 6485.332134606519
INFO:root:current train perplexity166.02609252929688
INFO:root:current mean train loss 6488.272996016049
INFO:root:current train perplexity166.09861755371094
INFO:root:current mean train loss 6485.520000655113
INFO:root:current train perplexity166.1158905029297
INFO:root:current mean train loss 6483.942201841128
INFO:root:current train perplexity166.12539672851562
INFO:root:current mean train loss 6483.788756420687
INFO:root:current train perplexity166.20550537109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.43s/it]
INFO:root:final mean train loss: 6483.7307806048675
INFO:root:final train perplexity: 166.2445831298828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 6340.533448997119
INFO:root:eval perplexity: 168.65420532226562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it]
INFO:root:eval mean loss: 6456.125995608932
INFO:root:eval perplexity: 196.36935424804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [13:09:48<3:02:22, 575.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6470.7454255756575
INFO:root:current train perplexity167.50611877441406
INFO:root:current mean train loss 6491.512170965021
INFO:root:current train perplexity166.6185302734375
INFO:root:current mean train loss 6481.326702615489
INFO:root:current train perplexity165.9941864013672
INFO:root:current mean train loss 6481.753749116938
INFO:root:current train perplexity166.34735107421875
INFO:root:current mean train loss 6492.8888616481745
INFO:root:current train perplexity166.43994140625
INFO:root:current mean train loss 6504.324967278375
INFO:root:current train perplexity166.84877014160156
INFO:root:current mean train loss 6500.078105497642
INFO:root:current train perplexity166.7443389892578
INFO:root:current mean train loss 6499.858249310366
INFO:root:current train perplexity166.68814086914062
INFO:root:current mean train loss 6497.528611274614
INFO:root:current train perplexity166.46731567382812
INFO:root:current mean train loss 6498.121685590901
INFO:root:current train perplexity166.3555145263672
INFO:root:current mean train loss 6493.144009388069
INFO:root:current train perplexity166.22222900390625
INFO:root:current mean train loss 6491.165077676578
INFO:root:current train perplexity166.09173583984375
INFO:root:current mean train loss 6491.788819507372
INFO:root:current train perplexity166.11122131347656
INFO:root:current mean train loss 6489.93353058571
INFO:root:current train perplexity166.02554321289062
INFO:root:current mean train loss 6483.758995821159
INFO:root:current train perplexity165.85818481445312
INFO:root:current mean train loss 6483.628191488044
INFO:root:current train perplexity165.85098266601562
INFO:root:current mean train loss 6481.7926943103
INFO:root:current train perplexity165.8224334716797
INFO:root:current mean train loss 6479.675446931306
INFO:root:current train perplexity165.75192260742188
INFO:root:current mean train loss 6480.703939409398
INFO:root:current train perplexity165.748046875
INFO:root:current mean train loss 6481.833430857793
INFO:root:current train perplexity165.80836486816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.66s/it]
INFO:root:final mean train loss: 6480.7196224056825
INFO:root:final train perplexity: 165.85035705566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it]
INFO:root:eval mean loss: 6336.300150986259
INFO:root:eval perplexity: 168.07794189453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it]
INFO:root:eval mean loss: 6452.893868087876
INFO:root:eval perplexity: 195.85101318359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [13:19:25<2:52:53, 576.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6478.832803049395
INFO:root:current train perplexity165.56439208984375
INFO:root:current mean train loss 6469.584599153983
INFO:root:current train perplexity165.2976837158203
INFO:root:current mean train loss 6473.905525077325
INFO:root:current train perplexity165.61642456054688
INFO:root:current mean train loss 6484.660796109653
INFO:root:current train perplexity165.76283264160156
INFO:root:current mean train loss 6490.221999595905
INFO:root:current train perplexity166.203369140625
INFO:root:current mean train loss 6496.57502322012
INFO:root:current train perplexity166.55831909179688
INFO:root:current mean train loss 6485.700527174648
INFO:root:current train perplexity166.57720947265625
INFO:root:current mean train loss 6483.11268151994
INFO:root:current train perplexity166.41891479492188
INFO:root:current mean train loss 6482.4635855919305
INFO:root:current train perplexity166.0135040283203
INFO:root:current mean train loss 6487.9832184667675
INFO:root:current train perplexity166.2548065185547
INFO:root:current mean train loss 6490.070396039427
INFO:root:current train perplexity166.27455139160156
INFO:root:current mean train loss 6485.329550552048
INFO:root:current train perplexity166.04200744628906
INFO:root:current mean train loss 6481.625899147452
INFO:root:current train perplexity165.91734313964844
INFO:root:current mean train loss 6480.3894612571785
INFO:root:current train perplexity165.85296630859375
INFO:root:current mean train loss 6480.573747802244
INFO:root:current train perplexity165.748046875
INFO:root:current mean train loss 6485.819419310067
INFO:root:current train perplexity165.79991149902344
INFO:root:current mean train loss 6481.7935513419225
INFO:root:current train perplexity165.72654724121094
INFO:root:current mean train loss 6480.152550445744
INFO:root:current train perplexity165.62606811523438
INFO:root:current mean train loss 6481.526565027816
INFO:root:current train perplexity165.63546752929688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.26s/it]
INFO:root:final mean train loss: 6478.979755534347
INFO:root:final train perplexity: 165.62290954589844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 6334.57027613863
INFO:root:eval perplexity: 167.84295654296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.02s/it]
INFO:root:eval mean loss: 6450.270164110982
INFO:root:eval perplexity: 195.43121337890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [13:28:51<2:42:22, 573.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6419.971533203125
INFO:root:current train perplexity164.49998474121094
INFO:root:current mean train loss 6459.112837357955
INFO:root:current train perplexity163.80117797851562
INFO:root:current mean train loss 6477.571781994047
INFO:root:current train perplexity164.65882873535156
INFO:root:current mean train loss 6484.735422442036
INFO:root:current train perplexity165.03244018554688
INFO:root:current mean train loss 6477.429571979802
INFO:root:current train perplexity165.01324462890625
INFO:root:current mean train loss 6477.028359566483
INFO:root:current train perplexity164.86544799804688
INFO:root:current mean train loss 6468.641190125512
INFO:root:current train perplexity164.8575897216797
INFO:root:current mean train loss 6463.37001953125
INFO:root:current train perplexity164.69651794433594
INFO:root:current mean train loss 6461.668312355324
INFO:root:current train perplexity164.6717071533203
INFO:root:current mean train loss 6460.692133306147
INFO:root:current train perplexity164.7061004638672
INFO:root:current mean train loss 6469.961373085551
INFO:root:current train perplexity164.8546905517578
INFO:root:current mean train loss 6469.204279279279
INFO:root:current train perplexity164.7922821044922
INFO:root:current mean train loss 6472.59591659672
INFO:root:current train perplexity164.9923095703125
INFO:root:current mean train loss 6470.509851353769
INFO:root:current train perplexity165.03842163085938
INFO:root:current mean train loss 6468.777522786459
INFO:root:current train perplexity164.96902465820312
INFO:root:current mean train loss 6471.30703060327
INFO:root:current train perplexity165.0103302001953
INFO:root:current mean train loss 6472.47131029212
INFO:root:current train perplexity165.10658264160156
INFO:root:current mean train loss 6468.788397466648
INFO:root:current train perplexity164.91758728027344
INFO:root:current mean train loss 6472.511699326657
INFO:root:current train perplexity165.03244018554688
INFO:root:current mean train loss 6476.217196703206
INFO:root:current train perplexity165.1094207763672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.97s/it]
INFO:root:final mean train loss: 6475.586428366703
INFO:root:final train perplexity: 165.18020629882812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.42s/it]
INFO:root:eval mean loss: 6331.55536278258
INFO:root:eval perplexity: 167.43423461914062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.04s/it]
INFO:root:eval mean loss: 6447.411434958167
INFO:root:eval perplexity: 194.97474670410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [13:38:16<2:32:09, 570.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6422.286277488426
INFO:root:current train perplexity164.9193115234375
INFO:root:current mean train loss 6481.255290354331
INFO:root:current train perplexity166.07113647460938
INFO:root:current mean train loss 6496.319916712555
INFO:root:current train perplexity165.94076538085938
INFO:root:current mean train loss 6469.215010990061
INFO:root:current train perplexity164.9102783203125
INFO:root:current mean train loss 6470.769669615413
INFO:root:current train perplexity164.47113037109375
INFO:root:current mean train loss 6475.00992962079
INFO:root:current train perplexity164.4306640625
INFO:root:current mean train loss 6479.475898998206
INFO:root:current train perplexity164.8199462890625
INFO:root:current mean train loss 6483.690807148384
INFO:root:current train perplexity164.9102783203125
INFO:root:current mean train loss 6481.693006891437
INFO:root:current train perplexity164.7244110107422
INFO:root:current mean train loss 6479.6485597019955
INFO:root:current train perplexity164.70602416992188
INFO:root:current mean train loss 6479.4013724173865
INFO:root:current train perplexity164.6774444580078
INFO:root:current mean train loss 6486.6684795606425
INFO:root:current train perplexity164.9185333251953
INFO:root:current mean train loss 6484.06936896712
INFO:root:current train perplexity164.9260711669922
INFO:root:current mean train loss 6483.285831454291
INFO:root:current train perplexity164.96421813964844
INFO:root:current mean train loss 6484.163885254248
INFO:root:current train perplexity164.9488067626953
INFO:root:current mean train loss 6480.527597323694
INFO:root:current train perplexity164.9004364013672
INFO:root:current mean train loss 6479.2762456423825
INFO:root:current train perplexity164.90798950195312
INFO:root:current mean train loss 6477.313598420762
INFO:root:current train perplexity164.9266357421875
INFO:root:current mean train loss 6476.425480316947
INFO:root:current train perplexity164.94503784179688
INFO:root:current mean train loss 6477.136783871059
INFO:root:current train perplexity164.98797607421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.60s/it]
INFO:root:final mean train loss: 6473.3687349551265
INFO:root:final train perplexity: 164.89163208007812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 6334.2179327349295
INFO:root:eval perplexity: 167.79502868652344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 34.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it]
INFO:root:eval mean loss: 6451.446373039949
INFO:root:eval perplexity: 195.61917114257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [13:47:54<2:23:14, 572.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6462.9909335049715
INFO:root:current train perplexity164.7010040283203
INFO:root:current mean train loss 6459.950347900391
INFO:root:current train perplexity165.4271697998047
INFO:root:current mean train loss 6460.652689949411
INFO:root:current train perplexity165.2976837158203
INFO:root:current mean train loss 6470.126521620639
INFO:root:current train perplexity164.94039916992188
INFO:root:current mean train loss 6475.212929115639
INFO:root:current train perplexity165.1602783203125
INFO:root:current mean train loss 6478.233385871438
INFO:root:current train perplexity165.3164520263672
INFO:root:current mean train loss 6484.403379452155
INFO:root:current train perplexity165.51553344726562
INFO:root:current mean train loss 6490.05410077495
INFO:root:current train perplexity165.53921508789062
INFO:root:current mean train loss 6492.910240715714
INFO:root:current train perplexity165.64051818847656
INFO:root:current mean train loss 6492.6463105799785
INFO:root:current train perplexity165.5245361328125
INFO:root:current mean train loss 6488.030534883112
INFO:root:current train perplexity165.41311645507812
INFO:root:current mean train loss 6484.369160685505
INFO:root:current train perplexity165.27066040039062
INFO:root:current mean train loss 6486.950607839504
INFO:root:current train perplexity165.3099822998047
INFO:root:current mean train loss 6487.072788783482
INFO:root:current train perplexity165.3313446044922
INFO:root:current mean train loss 6488.272695610068
INFO:root:current train perplexity165.4077606201172
INFO:root:current mean train loss 6486.251166625344
INFO:root:current train perplexity165.27105712890625
INFO:root:current mean train loss 6482.916559446757
INFO:root:current train perplexity165.1595001220703
INFO:root:current mean train loss 6479.539418351759
INFO:root:current train perplexity165.1265106201172
INFO:root:current mean train loss 6476.515572305874
INFO:root:current train perplexity165.04290771484375
INFO:root:current mean train loss 6474.66144075119
INFO:root:current train perplexity164.9735870361328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.83s/it]
INFO:root:final mean train loss: 6474.098693262851
INFO:root:final train perplexity: 164.98648071289062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 6330.43791555851
INFO:root:eval perplexity: 167.28292846679688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.23s/it]
INFO:root:eval mean loss: 6446.766232754322
INFO:root:eval perplexity: 194.8719482421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [13:57:30<2:13:53, 573.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6487.727883260758
INFO:root:current train perplexity165.81761169433594
INFO:root:current mean train loss 6451.502735588121
INFO:root:current train perplexity164.1908416748047
INFO:root:current mean train loss 6455.472394336686
INFO:root:current train perplexity164.5479278564453
INFO:root:current mean train loss 6462.0290561158245
INFO:root:current train perplexity164.97909545898438
INFO:root:current mean train loss 6462.244757066838
INFO:root:current train perplexity164.94801330566406
INFO:root:current mean train loss 6453.167006113525
INFO:root:current train perplexity164.62490844726562
INFO:root:current mean train loss 6462.4485162455085
INFO:root:current train perplexity164.8799285888672
INFO:root:current mean train loss 6463.013775177604
INFO:root:current train perplexity164.76242065429688
INFO:root:current mean train loss 6463.700041625835
INFO:root:current train perplexity164.73681640625
INFO:root:current mean train loss 6461.897918224831
INFO:root:current train perplexity164.7007598876953
INFO:root:current mean train loss 6463.445762123733
INFO:root:current train perplexity164.66644287109375
INFO:root:current mean train loss 6467.55242483581
INFO:root:current train perplexity164.73382568359375
INFO:root:current mean train loss 6466.318152213645
INFO:root:current train perplexity164.63291931152344
INFO:root:current mean train loss 6471.772014631934
INFO:root:current train perplexity164.74530029296875
INFO:root:current mean train loss 6473.707800936324
INFO:root:current train perplexity164.7970733642578
INFO:root:current mean train loss 6474.8465908522185
INFO:root:current train perplexity164.74969482421875
INFO:root:current mean train loss 6472.066493558568
INFO:root:current train perplexity164.63912963867188
INFO:root:current mean train loss 6471.335695993487
INFO:root:current train perplexity164.55709838867188
INFO:root:current mean train loss 6469.836037465157
INFO:root:current train perplexity164.63433837890625
INFO:root:current mean train loss 6474.510117705412
INFO:root:current train perplexity164.72817993164062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.99s/it]
INFO:root:final mean train loss: 6471.99630994311
INFO:root:final train perplexity: 164.7130889892578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it]
INFO:root:eval mean loss: 6328.80262009641
INFO:root:eval perplexity: 167.0618133544922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.26s/it]
INFO:root:eval mean loss: 6444.749993939772
INFO:root:eval perplexity: 194.55079650878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [14:07:00<2:04:04, 572.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6481.227451422275
INFO:root:current train perplexity164.3485107421875
INFO:root:current mean train loss 6506.030687653617
INFO:root:current train perplexity165.38259887695312
INFO:root:current mean train loss 6491.281587230216
INFO:root:current train perplexity165.20635986328125
INFO:root:current mean train loss 6493.367470393106
INFO:root:current train perplexity165.0030059814453
INFO:root:current mean train loss 6488.477526804393
INFO:root:current train perplexity165.02590942382812
INFO:root:current mean train loss 6489.0337209734535
INFO:root:current train perplexity165.0086669921875
INFO:root:current mean train loss 6489.816128981149
INFO:root:current train perplexity165.1870574951172
INFO:root:current mean train loss 6488.980072099936
INFO:root:current train perplexity165.27798461914062
INFO:root:current mean train loss 6480.034575651338
INFO:root:current train perplexity165.1947784423828
INFO:root:current mean train loss 6478.58026185455
INFO:root:current train perplexity165.15989685058594
INFO:root:current mean train loss 6471.7694447363465
INFO:root:current train perplexity164.9121551513672
INFO:root:current mean train loss 6477.4893220600325
INFO:root:current train perplexity164.9886932373047
INFO:root:current mean train loss 6476.044088587515
INFO:root:current train perplexity165.00253295898438
INFO:root:current mean train loss 6476.916888720065
INFO:root:current train perplexity164.95745849609375
INFO:root:current mean train loss 6479.758957549264
INFO:root:current train perplexity164.9828643798828
INFO:root:current mean train loss 6476.930244165379
INFO:root:current train perplexity164.81491088867188
INFO:root:current mean train loss 6478.093947291232
INFO:root:current train perplexity164.90155029296875
INFO:root:current mean train loss 6477.2856879218225
INFO:root:current train perplexity164.85861206054688
INFO:root:current mean train loss 6475.056001023363
INFO:root:current train perplexity164.78646850585938
INFO:root:current mean train loss 6474.119287504344
INFO:root:current train perplexity164.77711486816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.78s/it]
INFO:root:final mean train loss: 6472.438729321301
INFO:root:final train perplexity: 164.7706756591797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.12s/it]
INFO:root:eval mean loss: 6328.113147924978
INFO:root:eval perplexity: 166.9687042236328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.14s/it]
INFO:root:eval mean loss: 6444.80566146526
INFO:root:eval perplexity: 194.55979919433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [14:16:25<1:54:02, 570.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6483.629404810856
INFO:root:current train perplexity166.03717041015625
INFO:root:current mean train loss 6472.965642528045
INFO:root:current train perplexity165.16217041015625
INFO:root:current mean train loss 6481.85759235964
INFO:root:current train perplexity165.14500427246094
INFO:root:current mean train loss 6463.60849362144
INFO:root:current train perplexity164.92237854003906
INFO:root:current mean train loss 6473.883229758523
INFO:root:current train perplexity165.1461944580078
INFO:root:current mean train loss 6475.357196198792
INFO:root:current train perplexity164.9583282470703
INFO:root:current mean train loss 6472.887600466502
INFO:root:current train perplexity164.94786071777344
INFO:root:current mean train loss 6475.177703665488
INFO:root:current train perplexity164.9377899169922
INFO:root:current mean train loss 6487.371220321229
INFO:root:current train perplexity165.21156311035156
INFO:root:current mean train loss 6479.815312401853
INFO:root:current train perplexity165.24859619140625
INFO:root:current mean train loss 6483.864672071204
INFO:root:current train perplexity165.22125244140625
INFO:root:current mean train loss 6479.520263467573
INFO:root:current train perplexity165.2194366455078
INFO:root:current mean train loss 6481.202133732505
INFO:root:current train perplexity165.3206329345703
INFO:root:current mean train loss 6483.587515751008
INFO:root:current train perplexity165.2999725341797
INFO:root:current mean train loss 6480.60142238451
INFO:root:current train perplexity165.18234252929688
INFO:root:current mean train loss 6475.0998809144785
INFO:root:current train perplexity165.0170135498047
INFO:root:current mean train loss 6476.587322547935
INFO:root:current train perplexity164.99624633789062
INFO:root:current mean train loss 6474.5851094620475
INFO:root:current train perplexity164.83087158203125
INFO:root:current mean train loss 6472.87102186057
INFO:root:current train perplexity164.69471740722656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.20s/it]
INFO:root:final mean train loss: 6472.056368044393
INFO:root:final train perplexity: 164.7210235595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 6326.838836020612
INFO:root:eval perplexity: 166.79666137695312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it]
INFO:root:eval mean loss: 6444.312342434065
INFO:root:eval perplexity: 194.48123168945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [14:26:04<1:45:03, 573.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6654.4320068359375
INFO:root:current train perplexity166.47740173339844
INFO:root:current mean train loss 6498.950474330357
INFO:root:current train perplexity165.2418212890625
INFO:root:current mean train loss 6500.827880859375
INFO:root:current train perplexity165.51869201660156
INFO:root:current mean train loss 6484.238771096254
INFO:root:current train perplexity165.3426971435547
INFO:root:current mean train loss 6478.7255776414595
INFO:root:current train perplexity165.19833374023438
INFO:root:current mean train loss 6476.281334877014
INFO:root:current train perplexity164.97389221191406
INFO:root:current mean train loss 6486.393296185662
INFO:root:current train perplexity165.36659240722656
INFO:root:current mean train loss 6480.830201566889
INFO:root:current train perplexity165.30816650390625
INFO:root:current mean train loss 6472.111845871498
INFO:root:current train perplexity165.22605895996094
INFO:root:current mean train loss 6471.956456769976
INFO:root:current train perplexity165.24977111816406
INFO:root:current mean train loss 6473.5289885630245
INFO:root:current train perplexity164.99183654785156
INFO:root:current mean train loss 6476.6946094979485
INFO:root:current train perplexity164.9749298095703
INFO:root:current mean train loss 6477.7333267262275
INFO:root:current train perplexity164.87945556640625
INFO:root:current mean train loss 6476.9416474133
INFO:root:current train perplexity164.8218231201172
INFO:root:current mean train loss 6475.913854669241
INFO:root:current train perplexity164.68882751464844
INFO:root:current mean train loss 6475.400608284764
INFO:root:current train perplexity164.68026733398438
INFO:root:current mean train loss 6472.126058649485
INFO:root:current train perplexity164.5819854736328
INFO:root:current mean train loss 6471.23911378094
INFO:root:current train perplexity164.5159149169922
INFO:root:current mean train loss 6473.160085918098
INFO:root:current train perplexity164.60662841796875
INFO:root:current mean train loss 6472.360466482251
INFO:root:current train perplexity164.6124267578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.67s/it]
INFO:root:final mean train loss: 6471.048690357295
INFO:root:final train perplexity: 164.59014892578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 6333.858933469082
INFO:root:eval perplexity: 167.7463836669922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it]
INFO:root:eval mean loss: 6452.582454600232
INFO:root:eval perplexity: 195.80105590820312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [14:35:28<1:35:03, 570.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6339.3082906788795
INFO:root:current train perplexity160.52523803710938
INFO:root:current mean train loss 6454.537116945252
INFO:root:current train perplexity164.27235412597656
INFO:root:current mean train loss 6443.450807263237
INFO:root:current train perplexity163.9830322265625
INFO:root:current mean train loss 6440.482214095745
INFO:root:current train perplexity163.71090698242188
INFO:root:current mean train loss 6463.694178868007
INFO:root:current train perplexity164.37892150878906
INFO:root:current mean train loss 6478.451427553462
INFO:root:current train perplexity164.69549560546875
INFO:root:current mean train loss 6479.596674253527
INFO:root:current train perplexity164.76351928710938
INFO:root:current mean train loss 6479.235178755144
INFO:root:current train perplexity165.06832885742188
INFO:root:current mean train loss 6480.161311279591
INFO:root:current train perplexity165.16217041015625
INFO:root:current mean train loss 6481.746376522134
INFO:root:current train perplexity165.1448516845703
INFO:root:current mean train loss 6479.325056278091
INFO:root:current train perplexity165.06124877929688
INFO:root:current mean train loss 6475.504331820195
INFO:root:current train perplexity164.9427490234375
INFO:root:current mean train loss 6475.675860709926
INFO:root:current train perplexity164.95880126953125
INFO:root:current mean train loss 6473.412402931598
INFO:root:current train perplexity164.9149169921875
INFO:root:current mean train loss 6473.96319029096
INFO:root:current train perplexity164.9274139404297
INFO:root:current mean train loss 6477.013996970038
INFO:root:current train perplexity165.0708465576172
INFO:root:current mean train loss 6479.703045568121
INFO:root:current train perplexity165.10122680664062
INFO:root:current mean train loss 6479.746552096136
INFO:root:current train perplexity165.10997009277344
INFO:root:current mean train loss 6477.562264268811
INFO:root:current train perplexity165.12728881835938
INFO:root:current mean train loss 6476.700639296591
INFO:root:current train perplexity165.08517456054688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.13s/it]
INFO:root:final mean train loss: 6474.470857882824
INFO:root:final train perplexity: 165.03488159179688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 6332.447102864583
INFO:root:eval perplexity: 167.5550079345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.74s/it]
INFO:root:eval mean loss: 6449.412609776707
INFO:root:eval perplexity: 195.294189453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [14:45:05<1:25:50, 572.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6470.407757302989
INFO:root:current train perplexity166.19955444335938
INFO:root:current mean train loss 6443.634013136772
INFO:root:current train perplexity164.26617431640625
INFO:root:current mean train loss 6460.7975439056145
INFO:root:current train perplexity164.6772003173828
INFO:root:current mean train loss 6452.426838251897
INFO:root:current train perplexity164.46578979492188
INFO:root:current mean train loss 6461.599531644129
INFO:root:current train perplexity164.38104248046875
INFO:root:current mean train loss 6458.936561891885
INFO:root:current train perplexity164.54588317871094
INFO:root:current mean train loss 6467.044491794456
INFO:root:current train perplexity164.91986083984375
INFO:root:current mean train loss 6471.054963712718
INFO:root:current train perplexity164.83189392089844
INFO:root:current mean train loss 6465.519934110889
INFO:root:current train perplexity164.67782592773438
INFO:root:current mean train loss 6464.430327014237
INFO:root:current train perplexity164.66793823242188
INFO:root:current mean train loss 6472.9099746616575
INFO:root:current train perplexity164.843994140625
INFO:root:current mean train loss 6469.36331917062
INFO:root:current train perplexity164.7503204345703
INFO:root:current mean train loss 6472.488811070425
INFO:root:current train perplexity164.8520965576172
INFO:root:current mean train loss 6473.69619438092
INFO:root:current train perplexity164.8074493408203
INFO:root:current mean train loss 6477.316923909168
INFO:root:current train perplexity164.96209716796875
INFO:root:current mean train loss 6475.877732606323
INFO:root:current train perplexity164.89218139648438
INFO:root:current mean train loss 6476.082858598971
INFO:root:current train perplexity164.94354248046875
INFO:root:current mean train loss 6474.113429188592
INFO:root:current train perplexity164.864990234375
INFO:root:current mean train loss 6472.770643769468
INFO:root:current train perplexity164.7830810546875
INFO:root:current mean train loss 6473.220853674204
INFO:root:current train perplexity164.76840209960938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.20s/it]
INFO:root:final mean train loss: 6472.36390212805
INFO:root:final train perplexity: 164.76092529296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 6327.053304036458
INFO:root:eval perplexity: 166.82562255859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it]
INFO:root:eval mean loss: 6443.105234132591
INFO:root:eval perplexity: 194.28936767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [14:54:32<1:16:05, 570.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6421.558120969742
INFO:root:current train perplexity163.6968536376953
INFO:root:current mean train loss 6420.881158934049
INFO:root:current train perplexity163.43402099609375
INFO:root:current mean train loss 6445.3803562410885
INFO:root:current train perplexity164.09848022460938
INFO:root:current mean train loss 6448.790162814222
INFO:root:current train perplexity163.8563995361328
INFO:root:current mean train loss 6457.3377503627835
INFO:root:current train perplexity164.3148193359375
INFO:root:current mean train loss 6453.654106939664
INFO:root:current train perplexity164.08274841308594
INFO:root:current mean train loss 6456.319549514517
INFO:root:current train perplexity164.18504333496094
INFO:root:current mean train loss 6461.8483531546935
INFO:root:current train perplexity164.2811279296875
INFO:root:current mean train loss 6467.095399292983
INFO:root:current train perplexity164.523681640625
INFO:root:current mean train loss 6471.825995424455
INFO:root:current train perplexity164.75048828125
INFO:root:current mean train loss 6478.521119656926
INFO:root:current train perplexity164.97169494628906
INFO:root:current mean train loss 6478.010933217568
INFO:root:current train perplexity164.83990478515625
INFO:root:current mean train loss 6477.332092720086
INFO:root:current train perplexity164.76329040527344
INFO:root:current mean train loss 6479.6565785061675
INFO:root:current train perplexity164.88880920410156
INFO:root:current mean train loss 6476.100783853277
INFO:root:current train perplexity164.80760192871094
INFO:root:current mean train loss 6477.641626554502
INFO:root:current train perplexity164.8636474609375
INFO:root:current mean train loss 6474.949262204976
INFO:root:current train perplexity164.9452667236328
INFO:root:current mean train loss 6475.007144748387
INFO:root:current train perplexity164.93441772460938
INFO:root:current mean train loss 6475.942611096434
INFO:root:current train perplexity164.95872497558594
INFO:root:current mean train loss 6475.531036081572
INFO:root:current train perplexity164.86489868164062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.98s/it]
INFO:root:final mean train loss: 6472.980620553021
INFO:root:final train perplexity: 164.84107971191406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it]
INFO:root:eval mean loss: 6326.6491733848625
INFO:root:eval perplexity: 166.77113342285156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it]
INFO:root:eval mean loss: 6442.209690824468
INFO:root:eval perplexity: 194.1470184326172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [15:03:57<1:06:23, 569.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6461.027282714844
INFO:root:current train perplexity164.05027770996094
INFO:root:current mean train loss 6498.411002604166
INFO:root:current train perplexity165.5404052734375
INFO:root:current mean train loss 6491.765654645647
INFO:root:current train perplexity165.34042358398438
INFO:root:current mean train loss 6492.9248034025495
INFO:root:current train perplexity165.1224822998047
INFO:root:current mean train loss 6479.096519978842
INFO:root:current train perplexity164.88140869140625
INFO:root:current mean train loss 6477.2140523976295
INFO:root:current train perplexity164.88275146484375
INFO:root:current mean train loss 6478.449636661305
INFO:root:current train perplexity164.77908325195312
INFO:root:current mean train loss 6480.210278320313
INFO:root:current train perplexity164.8774871826172
INFO:root:current mean train loss 6473.378142200817
INFO:root:current train perplexity164.64736938476562
INFO:root:current mean train loss 6476.816618004624
INFO:root:current train perplexity164.78646850585938
INFO:root:current mean train loss 6475.476595956308
INFO:root:current train perplexity164.79212951660156
INFO:root:current mean train loss 6476.362691174523
INFO:root:current train perplexity164.7704315185547
INFO:root:current mean train loss 6473.77237701416
INFO:root:current train perplexity164.6614990234375
INFO:root:current mean train loss 6476.686898494112
INFO:root:current train perplexity164.7353973388672
INFO:root:current mean train loss 6473.555270138302
INFO:root:current train perplexity164.66998291015625
INFO:root:current mean train loss 6475.827039346816
INFO:root:current train perplexity164.8074493408203
INFO:root:current mean train loss 6476.581931268601
INFO:root:current train perplexity164.91734313964844
INFO:root:current mean train loss 6476.369317558374
INFO:root:current train perplexity164.9092559814453
INFO:root:current mean train loss 6475.980924825465
INFO:root:current train perplexity164.9168701171875
INFO:root:current mean train loss 6475.205179233743
INFO:root:current train perplexity164.90908813476562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.19s/it]
INFO:root:final mean train loss: 6473.482178596193
INFO:root:final train perplexity: 164.90626525878906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 6328.667385236591
INFO:root:eval perplexity: 167.04348754882812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it]
INFO:root:eval mean loss: 6444.7777619057515
INFO:root:eval perplexity: 194.5553436279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [15:13:33<57:06, 571.12s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6430.150833601804
INFO:root:current train perplexity162.38462829589844
INFO:root:current mean train loss 6450.118245855806
INFO:root:current train perplexity163.50135803222656
INFO:root:current mean train loss 6450.871907552083
INFO:root:current train perplexity164.16986083984375
INFO:root:current mean train loss 6456.240444692617
INFO:root:current train perplexity164.25184631347656
INFO:root:current mean train loss 6452.293634856011
INFO:root:current train perplexity164.79251098632812
INFO:root:current mean train loss 6451.424449722571
INFO:root:current train perplexity164.7208709716797
INFO:root:current mean train loss 6454.665638030174
INFO:root:current train perplexity164.80752563476562
INFO:root:current mean train loss 6462.677103959183
INFO:root:current train perplexity164.84957885742188
INFO:root:current mean train loss 6468.173727964743
INFO:root:current train perplexity164.94212341308594
INFO:root:current mean train loss 6469.160560783915
INFO:root:current train perplexity165.0625762939453
INFO:root:current mean train loss 6472.856646055293
INFO:root:current train perplexity165.13665771484375
INFO:root:current mean train loss 6474.6295772797885
INFO:root:current train perplexity165.04495239257812
INFO:root:current mean train loss 6475.022444372831
INFO:root:current train perplexity165.07461547851562
INFO:root:current mean train loss 6478.049143393208
INFO:root:current train perplexity165.0965118408203
INFO:root:current mean train loss 6478.231809647942
INFO:root:current train perplexity164.94337463378906
INFO:root:current mean train loss 6479.517339029235
INFO:root:current train perplexity164.96705627441406
INFO:root:current mean train loss 6474.584165933909
INFO:root:current train perplexity164.86529541015625
INFO:root:current mean train loss 6474.655370441621
INFO:root:current train perplexity164.8829803466797
INFO:root:current mean train loss 6475.741652372579
INFO:root:current train perplexity164.92938232421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.03s/it]
INFO:root:final mean train loss: 6473.77635561452
INFO:root:final train perplexity: 164.94464111328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 6328.946505499224
INFO:root:eval perplexity: 167.08132934570312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.15s/it]
INFO:root:eval mean loss: 6445.165181044991
INFO:root:eval perplexity: 194.6168670654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [15:22:58<47:26, 569.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6622.524867466518
INFO:root:current train perplexity171.0570831298828
INFO:root:current mean train loss 6450.305659779331
INFO:root:current train perplexity166.4384307861328
INFO:root:current mean train loss 6489.658511152891
INFO:root:current train perplexity165.43772888183594
INFO:root:current mean train loss 6479.932234648686
INFO:root:current train perplexity165.52122497558594
INFO:root:current mean train loss 6490.239989054951
INFO:root:current train perplexity165.60885620117188
INFO:root:current mean train loss 6489.059368920233
INFO:root:current train perplexity165.538818359375
INFO:root:current mean train loss 6480.374341536034
INFO:root:current train perplexity165.38095092773438
INFO:root:current mean train loss 6481.149209586179
INFO:root:current train perplexity165.381103515625
INFO:root:current mean train loss 6482.466543736563
INFO:root:current train perplexity165.3696746826172
INFO:root:current mean train loss 6481.526884316876
INFO:root:current train perplexity165.2964324951172
INFO:root:current mean train loss 6476.916113377558
INFO:root:current train perplexity165.12445068359375
INFO:root:current mean train loss 6483.0383594451305
INFO:root:current train perplexity165.3478240966797
INFO:root:current mean train loss 6478.6801520509425
INFO:root:current train perplexity165.105712890625
INFO:root:current mean train loss 6477.07985739512
INFO:root:current train perplexity164.9805145263672
INFO:root:current mean train loss 6481.658796383265
INFO:root:current train perplexity164.99356079101562
INFO:root:current mean train loss 6478.707684979257
INFO:root:current train perplexity164.9615478515625
INFO:root:current mean train loss 6476.863298796662
INFO:root:current train perplexity164.91357421875
INFO:root:current mean train loss 6474.023874218295
INFO:root:current train perplexity164.82395935058594
INFO:root:current mean train loss 6474.480798487889
INFO:root:current train perplexity164.8394317626953
INFO:root:current mean train loss 6475.51612731232
INFO:root:current train perplexity164.95399475097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.40s/it]
INFO:root:final mean train loss: 6473.73293059364
INFO:root:final train perplexity: 164.93890380859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 6328.640112477837
INFO:root:eval perplexity: 167.03990173339844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.49s/it]
INFO:root:eval mean loss: 6445.651267626607
INFO:root:eval perplexity: 194.69427490234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [15:32:39<38:10, 572.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6555.404186617943
INFO:root:current train perplexity166.7738494873047
INFO:root:current mean train loss 6497.282461384781
INFO:root:current train perplexity165.07415771484375
INFO:root:current mean train loss 6496.906636820211
INFO:root:current train perplexity165.28697204589844
INFO:root:current mean train loss 6492.608323203833
INFO:root:current train perplexity165.41983032226562
INFO:root:current mean train loss 6501.057311303654
INFO:root:current train perplexity165.3141632080078
INFO:root:current mean train loss 6485.432600635593
INFO:root:current train perplexity164.96588134765625
INFO:root:current mean train loss 6488.194579691214
INFO:root:current train perplexity165.23062133789062
INFO:root:current mean train loss 6494.096850018169
INFO:root:current train perplexity165.2391357421875
INFO:root:current mean train loss 6492.903928460627
INFO:root:current train perplexity165.23495483398438
INFO:root:current mean train loss 6486.15414425433
INFO:root:current train perplexity165.2141571044922
INFO:root:current mean train loss 6487.495119555499
INFO:root:current train perplexity165.262939453125
INFO:root:current mean train loss 6483.370022639671
INFO:root:current train perplexity165.13595581054688
INFO:root:current mean train loss 6479.6358814131045
INFO:root:current train perplexity165.15603637695312
INFO:root:current mean train loss 6475.049075383875
INFO:root:current train perplexity164.94825744628906
INFO:root:current mean train loss 6474.62604821803
INFO:root:current train perplexity164.81515502929688
INFO:root:current mean train loss 6473.602617838116
INFO:root:current train perplexity164.78073120117188
INFO:root:current mean train loss 6475.243237110093
INFO:root:current train perplexity164.75299072265625
INFO:root:current mean train loss 6477.3759413024445
INFO:root:current train perplexity164.80123901367188
INFO:root:current mean train loss 6475.084046510189
INFO:root:current train perplexity164.7332763671875
INFO:root:current mean train loss 6473.613679005777
INFO:root:current train perplexity164.80532836914062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.71s/it]
INFO:root:final mean train loss: 6473.4482972207115
INFO:root:final train perplexity: 164.90185546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.95s/it]
INFO:root:eval mean loss: 6330.257637619126
INFO:root:eval perplexity: 167.25852966308594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it]
INFO:root:eval mean loss: 6447.08287968196
INFO:root:eval perplexity: 194.9223175048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [15:42:06<28:33, 571.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6540.810323079427
INFO:root:current train perplexity166.91824340820312
INFO:root:current mean train loss 6525.256129909206
INFO:root:current train perplexity166.04193115234375
INFO:root:current mean train loss 6502.657856602823
INFO:root:current train perplexity166.16461181640625
INFO:root:current mean train loss 6476.043633822737
INFO:root:current train perplexity165.45169067382812
INFO:root:current mean train loss 6471.438413347517
INFO:root:current train perplexity165.388671875
INFO:root:current mean train loss 6479.2329386690235
INFO:root:current train perplexity165.44949340820312
INFO:root:current mean train loss 6469.498673050492
INFO:root:current train perplexity165.18453979492188
INFO:root:current mean train loss 6468.656924324239
INFO:root:current train perplexity165.10997009277344
INFO:root:current mean train loss 6476.779122982385
INFO:root:current train perplexity165.2353515625
INFO:root:current mean train loss 6479.0758056640625
INFO:root:current train perplexity165.24984741210938
INFO:root:current mean train loss 6476.105991509125
INFO:root:current train perplexity165.0442352294922
INFO:root:current mean train loss 6476.357246638175
INFO:root:current train perplexity165.07162475585938
INFO:root:current mean train loss 6479.700839702899
INFO:root:current train perplexity165.21542358398438
INFO:root:current mean train loss 6480.907316032432
INFO:root:current train perplexity165.07044982910156
INFO:root:current mean train loss 6475.457575171034
INFO:root:current train perplexity164.9661865234375
INFO:root:current mean train loss 6471.416795991804
INFO:root:current train perplexity164.83912658691406
INFO:root:current mean train loss 6470.1976970191145
INFO:root:current train perplexity164.83047485351562
INFO:root:current mean train loss 6473.386398909021
INFO:root:current train perplexity164.87953186035156
INFO:root:current mean train loss 6474.35480449726
INFO:root:current train perplexity164.8428955078125
INFO:root:current mean train loss 6477.153125802105
INFO:root:current train perplexity164.94125366210938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.51s/it]
INFO:root:final mean train loss: 6473.762868537845
INFO:root:final train perplexity: 164.9428253173828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.64s/it]
INFO:root:eval mean loss: 6329.770268866357
INFO:root:eval perplexity: 167.19265747070312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.26s/it]
INFO:root:eval mean loss: 6446.7855224609375
INFO:root:eval perplexity: 194.87510681152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [15:51:30<18:57, 568.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6421.906452824519
INFO:root:current train perplexity163.40853881835938
INFO:root:current mean train loss 6488.193983783144
INFO:root:current train perplexity165.1557159423828
INFO:root:current mean train loss 6482.471707326062
INFO:root:current train perplexity164.67013549804688
INFO:root:current mean train loss 6486.498676958476
INFO:root:current train perplexity164.57781982421875
INFO:root:current mean train loss 6480.034684769826
INFO:root:current train perplexity164.32626342773438
INFO:root:current mean train loss 6463.8080657148785
INFO:root:current train perplexity164.12774658203125
INFO:root:current mean train loss 6461.9767607495305
INFO:root:current train perplexity164.23452758789062
INFO:root:current mean train loss 6463.706742749183
INFO:root:current train perplexity164.44619750976562
INFO:root:current mean train loss 6465.220900695448
INFO:root:current train perplexity164.48289489746094
INFO:root:current mean train loss 6465.871641232189
INFO:root:current train perplexity164.47425842285156
INFO:root:current mean train loss 6470.485803165347
INFO:root:current train perplexity164.6006622314453
INFO:root:current mean train loss 6471.350279137608
INFO:root:current train perplexity164.7891387939453
INFO:root:current mean train loss 6470.45169528162
INFO:root:current train perplexity164.74851989746094
INFO:root:current mean train loss 6467.043165493361
INFO:root:current train perplexity164.70343017578125
INFO:root:current mean train loss 6471.806478642278
INFO:root:current train perplexity164.88417053222656
INFO:root:current mean train loss 6469.528870057908
INFO:root:current train perplexity164.83895874023438
INFO:root:current mean train loss 6473.145391387481
INFO:root:current train perplexity164.91175842285156
INFO:root:current mean train loss 6472.448695057985
INFO:root:current train perplexity164.88015747070312
INFO:root:current mean train loss 6473.36754670744
INFO:root:current train perplexity164.887939453125
INFO:root:current mean train loss 6474.882186058762
INFO:root:current train perplexity164.88990783691406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.40s/it]
INFO:root:final mean train loss: 6473.280038038168
INFO:root:final train perplexity: 164.8800048828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it]
INFO:root:eval mean loss: 6329.741460272607
INFO:root:eval perplexity: 167.1886749267578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it]
INFO:root:eval mean loss: 6446.703332779255
INFO:root:eval perplexity: 194.86192321777344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [16:01:06<09:31, 571.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6437.743515386814
INFO:root:current train perplexity164.43333435058594
INFO:root:current mean train loss 6440.94863656851
INFO:root:current train perplexity164.53419494628906
INFO:root:current mean train loss 6468.863087322695
INFO:root:current train perplexity164.6082000732422
INFO:root:current mean train loss 6483.036553347923
INFO:root:current train perplexity164.8016357421875
INFO:root:current mean train loss 6478.312455426608
INFO:root:current train perplexity165.09674072265625
INFO:root:current mean train loss 6475.969943856046
INFO:root:current train perplexity165.13926696777344
INFO:root:current mean train loss 6467.740477083715
INFO:root:current train perplexity164.84469604492188
INFO:root:current mean train loss 6464.369819348425
INFO:root:current train perplexity164.55514526367188
INFO:root:current mean train loss 6470.332310821464
INFO:root:current train perplexity164.75755310058594
INFO:root:current mean train loss 6477.875893524853
INFO:root:current train perplexity164.8974609375
INFO:root:current mean train loss 6475.978399195645
INFO:root:current train perplexity164.86656188964844
INFO:root:current mean train loss 6479.034500251163
INFO:root:current train perplexity164.8518524169922
INFO:root:current mean train loss 6480.372141536052
INFO:root:current train perplexity164.85240173339844
INFO:root:current mean train loss 6480.40475371122
INFO:root:current train perplexity164.89053344726562
INFO:root:current mean train loss 6478.981155374916
INFO:root:current train perplexity164.8739471435547
INFO:root:current mean train loss 6477.04253972918
INFO:root:current train perplexity164.8740234375
INFO:root:current mean train loss 6479.061759740079
INFO:root:current train perplexity164.97901916503906
INFO:root:current mean train loss 6479.125586923927
INFO:root:current train perplexity165.01551818847656
INFO:root:current mean train loss 6474.6525339254285
INFO:root:current train perplexity164.87142944335938
INFO:root:current mean train loss 6475.02736198048
INFO:root:current train perplexity164.8450164794922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.45s/it]
INFO:root:final mean train loss: 6472.966748490096
INFO:root:final train perplexity: 164.8392791748047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it]
INFO:root:eval mean loss: 6329.386235663232
INFO:root:eval perplexity: 167.14077758789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it]
INFO:root:eval mean loss: 6446.417694308234
INFO:root:eval perplexity: 194.81639099121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_minil12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [16:10:32<00:00, 569.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [16:10:32<00:00, 582.32s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.41s/it]
INFO:root:eval mean loss: 6329.386235663232
INFO:root:eval perplexity: 167.14077758789062
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it]
INFO:root:eval mean loss: 6446.417694308234
INFO:root:eval perplexity: 194.81639099121094
INFO:root:evalaution complete
INFO:root:save model final: alll6_minil12_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x151a81c6af06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x151a81c628e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x151a81b87e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x151a81c6ba3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x151a81b85948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x151a81c6ba3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x151a81b40b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x151a815a546a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x151b7ddc1a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x151b7ddc1be0]
python(+0x24a989) [0x5618f68e4989]
python(+0x24a9bd) [0x5618f68e49bd]
python(+0x24aa14) [0x5618f68e4a14]
python(+0x108f75) [0x5618f67a2f75]
python(Py_RunMain+0x313) [0x5618f68e7983]
python(Py_BytesMain+0x39) [0x5618f68e7bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x151b7dd9f0b3]
python(+0x1d6e13) [0x5618f6870e13]
/opt/slurm/data/slurmd/job29854551/slurm_script: line 239: 3506686 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path microsoft/MiniLM-L12-H384-uncased --data_config data_config.json --data_folder fast_processed_data_opt_allmini --output alll6_minil12_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
