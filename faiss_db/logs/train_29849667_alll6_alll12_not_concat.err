INFO:root:Output: alll6_alll12_not_concat
INFO:root:Steps per epochs:1983
INFO:root:Total steps:99150
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11652.298611111111
INFO:root:current train perplexity10258.4892578125
INFO:root:current mean train loss 9683.913112927921
INFO:root:current train perplexity2142.390869140625
INFO:root:current mean train loss 8524.964169301316
INFO:root:current train perplexity855.5159301757812
INFO:root:current mean train loss 7712.389942140508
INFO:root:current train perplexity442.7677001953125
INFO:root:current mean train loss 7095.068531594439
INFO:root:current train perplexity271.8598327636719
INFO:root:current mean train loss 6618.556558701352
INFO:root:current train perplexity186.65185546875
INFO:root:current mean train loss 6243.035372798194
INFO:root:current train perplexity138.4202117919922
INFO:root:current mean train loss 5945.699659058687
INFO:root:current train perplexity108.869384765625
INFO:root:current mean train loss 5694.69511534083
INFO:root:current train perplexity89.37510681152344
INFO:root:current mean train loss 5480.784956098677
INFO:root:current train perplexity75.58467102050781
INFO:root:current mean train loss 5299.016538694623
INFO:root:current train perplexity65.36297607421875
INFO:root:current mean train loss 5140.967004363988
INFO:root:current train perplexity57.703392028808594
INFO:root:current mean train loss 5001.586363007602
INFO:root:current train perplexity51.67438888549805
INFO:root:current mean train loss 4878.0982401631745
INFO:root:current train perplexity46.886985778808594
INFO:root:current mean train loss 4766.781192832982
INFO:root:current train perplexity42.97475814819336
INFO:root:current mean train loss 4667.865402632016
INFO:root:current train perplexity39.71108627319336
INFO:root:current mean train loss 4577.3004366654095
INFO:root:current train perplexity36.966957092285156
INFO:root:current mean train loss 4496.0143478419
INFO:root:current train perplexity34.6601676940918
INFO:root:current mean train loss 4421.001716055325
INFO:root:current train perplexity32.65892028808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.85s/it]
INFO:root:final mean train loss: 4360.716688285977
INFO:root:final train perplexity: 31.159631729125977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it]
INFO:root:eval mean loss: 2814.8648110247673
INFO:root:eval perplexity: 9.742496490478516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it]
INFO:root:eval mean loss: 3117.593337904477
INFO:root:eval perplexity: 12.802667617797852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/1
  2%|â–         | 1/50 [06:36<5:24:03, 396.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2967.6675720214844
INFO:root:current train perplexity10.386919975280762
INFO:root:current mean train loss 3007.949113516972
INFO:root:current train perplexity10.58104419708252
INFO:root:current mean train loss 2986.1130291974105
INFO:root:current train perplexity10.435273170471191
INFO:root:current mean train loss 2970.518104263499
INFO:root:current train perplexity10.311963081359863
INFO:root:current mean train loss 2949.8781978900615
INFO:root:current train perplexity10.154012680053711
INFO:root:current mean train loss 2934.4787564536396
INFO:root:current train perplexity10.061975479125977
INFO:root:current mean train loss 2923.100793219232
INFO:root:current train perplexity9.985405921936035
INFO:root:current mean train loss 2908.9992399588646
INFO:root:current train perplexity9.88764762878418
INFO:root:current mean train loss 2895.7105760761337
INFO:root:current train perplexity9.796971321105957
INFO:root:current mean train loss 2889.0611625571437
INFO:root:current train perplexity9.732353210449219
INFO:root:current mean train loss 2876.347900871217
INFO:root:current train perplexity9.639354705810547
INFO:root:current mean train loss 2865.4315205235634
INFO:root:current train perplexity9.562593460083008
INFO:root:current mean train loss 2855.735098989386
INFO:root:current train perplexity9.498316764831543
INFO:root:current mean train loss 2847.442962739243
INFO:root:current train perplexity9.43206787109375
INFO:root:current mean train loss 2841.0210705773306
INFO:root:current train perplexity9.373968124389648
INFO:root:current mean train loss 2830.9875390045245
INFO:root:current train perplexity9.310768127441406
INFO:root:current mean train loss 2822.076495935421
INFO:root:current train perplexity9.251443862915039
INFO:root:current mean train loss 2814.0780476034383
INFO:root:current train perplexity9.185981750488281
INFO:root:current mean train loss 2804.286701488075
INFO:root:current train perplexity9.11829662322998
INFO:root:current mean train loss 2797.2637177469337
INFO:root:current train perplexity9.07217788696289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:14<00:00, 374.37s/it]
INFO:root:final mean train loss: 2791.279563607559
INFO:root:final train perplexity: 9.037392616271973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 2492.7134996779423
INFO:root:eval perplexity: 7.507935047149658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.70s/it]
INFO:root:eval mean loss: 2837.5548407372007
INFO:root:eval perplexity: 10.182089805603027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/2
  4%|â–         | 2/50 [13:44<5:32:10, 415.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2610.037020596591
INFO:root:current train perplexity7.8845295906066895
INFO:root:current mean train loss 2617.198016403313
INFO:root:current train perplexity7.879245281219482
INFO:root:current mean train loss 2607.4387636634924
INFO:root:current train perplexity7.852225303649902
INFO:root:current mean train loss 2610.4399575356606
INFO:root:current train perplexity7.824764728546143
INFO:root:current mean train loss 2607.501852198506
INFO:root:current train perplexity7.814795970916748
INFO:root:current mean train loss 2602.861798542302
INFO:root:current train perplexity7.777372360229492
INFO:root:current mean train loss 2596.149902729438
INFO:root:current train perplexity7.746515274047852
INFO:root:current mean train loss 2593.9231729754647
INFO:root:current train perplexity7.722352981567383
INFO:root:current mean train loss 2589.9567953157825
INFO:root:current train perplexity7.697836399078369
INFO:root:current mean train loss 2583.5021012317457
INFO:root:current train perplexity7.663845062255859
INFO:root:current mean train loss 2576.581297646418
INFO:root:current train perplexity7.629563331604004
INFO:root:current mean train loss 2569.706677860216
INFO:root:current train perplexity7.590271949768066
INFO:root:current mean train loss 2565.8719684387356
INFO:root:current train perplexity7.5698699951171875
INFO:root:current mean train loss 2561.0801901219934
INFO:root:current train perplexity7.537850379943848
INFO:root:current mean train loss 2557.4681559188
INFO:root:current train perplexity7.513513088226318
INFO:root:current mean train loss 2552.003873283849
INFO:root:current train perplexity7.482356071472168
INFO:root:current mean train loss 2548.338011125517
INFO:root:current train perplexity7.455941677093506
INFO:root:current mean train loss 2545.0260457051536
INFO:root:current train perplexity7.435815811157227
INFO:root:current mean train loss 2542.4309790611787
INFO:root:current train perplexity7.421446800231934
INFO:root:current mean train loss 2539.1349078403873
INFO:root:current train perplexity7.40103816986084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.85s/it]
INFO:root:final mean train loss: 2536.7159214529556
INFO:root:final train perplexity: 7.393540859222412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2340.8445620705897
INFO:root:eval perplexity: 6.640170097351074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.79s/it]
INFO:root:eval mean loss: 2703.314472604305
INFO:root:eval perplexity: 9.123419761657715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/3
  6%|â–Œ         | 3/50 [20:39<5:25:03, 414.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2419.817373046875
INFO:root:current train perplexity6.824092864990234
INFO:root:current mean train loss 2429.669375
INFO:root:current train perplexity6.86603307723999
INFO:root:current mean train loss 2439.8453984375
INFO:root:current train perplexity6.853610515594482
INFO:root:current mean train loss 2442.4441336495534
INFO:root:current train perplexity6.828149795532227
INFO:root:current mean train loss 2442.279508192274
INFO:root:current train perplexity6.829854488372803
INFO:root:current mean train loss 2435.986062011719
INFO:root:current train perplexity6.811878204345703
INFO:root:current mean train loss 2432.0240221228964
INFO:root:current train perplexity6.804813385009766
INFO:root:current mean train loss 2427.151350423177
INFO:root:current train perplexity6.794651031494141
INFO:root:current mean train loss 2426.1208112649356
INFO:root:current train perplexity6.776313304901123
INFO:root:current mean train loss 2422.822166298314
INFO:root:current train perplexity6.758291721343994
INFO:root:current mean train loss 2418.2990892392113
INFO:root:current train perplexity6.750824451446533
INFO:root:current mean train loss 2419.1836387567937
INFO:root:current train perplexity6.752711772918701
INFO:root:current mean train loss 2420.0885783203125
INFO:root:current train perplexity6.751815319061279
INFO:root:current mean train loss 2419.0373524305555
INFO:root:current train perplexity6.743656158447266
INFO:root:current mean train loss 2419.49880859375
INFO:root:current train perplexity6.737887382507324
INFO:root:current mean train loss 2419.284206857989
INFO:root:current train perplexity6.741031169891357
INFO:root:current mean train loss 2419.5456007339017
INFO:root:current train perplexity6.738369464874268
INFO:root:current mean train loss 2419.0618364955358
INFO:root:current train perplexity6.733720779418945
INFO:root:current mean train loss 2417.399510597023
INFO:root:current train perplexity6.729602336883545
INFO:root:current mean train loss 2416.3367337114382
INFO:root:current train perplexity6.72104549407959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.89s/it]
INFO:root:final mean train loss: 2415.141429722219
INFO:root:final train perplexity: 6.717565536499023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.78s/it]
INFO:root:eval mean loss: 2269.233053004488
INFO:root:eval perplexity: 6.266529560089111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it]
INFO:root:eval mean loss: 2642.026095775848
INFO:root:eval perplexity: 8.677396774291992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/4
  8%|â–Š         | 4/50 [27:28<5:16:11, 412.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2393.4960864622203
INFO:root:current train perplexity6.535519123077393
INFO:root:current mean train loss 2369.7305550032747
INFO:root:current train perplexity6.437984466552734
INFO:root:current mean train loss 2367.3224210703415
INFO:root:current train perplexity6.455163478851318
INFO:root:current mean train loss 2361.6595402439543
INFO:root:current train perplexity6.434199810028076
INFO:root:current mean train loss 2365.64045979992
INFO:root:current train perplexity6.464514255523682
INFO:root:current mean train loss 2366.8198913897154
INFO:root:current train perplexity6.456270694732666
INFO:root:current mean train loss 2363.664751913594
INFO:root:current train perplexity6.450484275817871
INFO:root:current mean train loss 2366.160761667821
INFO:root:current train perplexity6.451290607452393
INFO:root:current mean train loss 2363.8242211435354
INFO:root:current train perplexity6.4475555419921875
INFO:root:current mean train loss 2362.571625734189
INFO:root:current train perplexity6.43773889541626
INFO:root:current mean train loss 2361.7382933769477
INFO:root:current train perplexity6.43217134475708
INFO:root:current mean train loss 2358.707578526671
INFO:root:current train perplexity6.415487766265869
INFO:root:current mean train loss 2358.894861234862
INFO:root:current train perplexity6.410660266876221
INFO:root:current mean train loss 2356.2421243663416
INFO:root:current train perplexity6.404603481292725
INFO:root:current mean train loss 2353.7869270600345
INFO:root:current train perplexity6.390733242034912
INFO:root:current mean train loss 2353.304633592753
INFO:root:current train perplexity6.3856201171875
INFO:root:current mean train loss 2349.974324446634
INFO:root:current train perplexity6.376915454864502
INFO:root:current mean train loss 2350.369882096796
INFO:root:current train perplexity6.3726019859313965
INFO:root:current mean train loss 2348.919130346771
INFO:root:current train perplexity6.369820594787598
INFO:root:current mean train loss 2347.649461599795
INFO:root:current train perplexity6.365109920501709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.51s/it]
INFO:root:final mean train loss: 2346.454649924751
INFO:root:final train perplexity: 6.363352298736572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.46s/it]
INFO:root:eval mean loss: 2205.2770498289283
INFO:root:eval perplexity: 5.950639247894287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.17s/it]
INFO:root:eval mean loss: 2590.0950940720577
INFO:root:eval perplexity: 8.316577911376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/5
 10%|â–ˆ         | 5/50 [34:31<5:12:19, 416.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2296.465066092355
INFO:root:current train perplexity6.172250270843506
INFO:root:current mean train loss 2313.613351573115
INFO:root:current train perplexity6.168007850646973
INFO:root:current mean train loss 2302.1092052191075
INFO:root:current train perplexity6.133625030517578
INFO:root:current mean train loss 2300.743402481079
INFO:root:current train perplexity6.138234615325928
INFO:root:current mean train loss 2295.8829002695634
INFO:root:current train perplexity6.130108833312988
INFO:root:current mean train loss 2299.041863010354
INFO:root:current train perplexity6.125580787658691
INFO:root:current mean train loss 2293.756484003792
INFO:root:current train perplexity6.112794399261475
INFO:root:current mean train loss 2290.876009104203
INFO:root:current train perplexity6.099624156951904
INFO:root:current mean train loss 2290.766659973973
INFO:root:current train perplexity6.093754768371582
INFO:root:current mean train loss 2287.2680786877145
INFO:root:current train perplexity6.083015441894531
INFO:root:current mean train loss 2286.5449509286354
INFO:root:current train perplexity6.076145648956299
INFO:root:current mean train loss 2286.1423609965555
INFO:root:current train perplexity6.069606781005859
INFO:root:current mean train loss 2285.917348891404
INFO:root:current train perplexity6.063008785247803
INFO:root:current mean train loss 2284.8974545870215
INFO:root:current train perplexity6.058471202850342
INFO:root:current mean train loss 2282.239503927308
INFO:root:current train perplexity6.054610252380371
INFO:root:current mean train loss 2280.212625368677
INFO:root:current train perplexity6.046562671661377
INFO:root:current mean train loss 2280.2342814900812
INFO:root:current train perplexity6.043288230895996
INFO:root:current mean train loss 2279.828807061029
INFO:root:current train perplexity6.0376176834106445
INFO:root:current mean train loss 2279.0002113552864
INFO:root:current train perplexity6.034747123718262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.65s/it]
INFO:root:final mean train loss: 2279.0176886223326
INFO:root:final train perplexity: 6.0337605476379395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.08s/it]
INFO:root:eval mean loss: 2154.8577707709997
INFO:root:eval perplexity: 5.712876319885254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.02s/it]
INFO:root:eval mean loss: 2545.6255190152647
INFO:root:eval perplexity: 8.019553184509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/6
 12%|â–ˆâ–        | 6/50 [41:20<5:03:33, 413.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2323.61279296875
INFO:root:current train perplexity6.213595390319824
INFO:root:current mean train loss 2218.1226504486385
INFO:root:current train perplexity5.783180236816406
INFO:root:current mean train loss 2223.584119198927
INFO:root:current train perplexity5.808629512786865
INFO:root:current mean train loss 2224.9013757040334
INFO:root:current train perplexity5.792500019073486
INFO:root:current mean train loss 2226.595549395554
INFO:root:current train perplexity5.799813270568848
INFO:root:current mean train loss 2232.145294372193
INFO:root:current train perplexity5.802817344665527
INFO:root:current mean train loss 2235.7247407884647
INFO:root:current train perplexity5.815524101257324
INFO:root:current mean train loss 2237.4679393904357
INFO:root:current train perplexity5.822307586669922
INFO:root:current mean train loss 2235.7483266766153
INFO:root:current train perplexity5.814483642578125
INFO:root:current mean train loss 2235.6457400306085
INFO:root:current train perplexity5.8141374588012695
INFO:root:current mean train loss 2233.462821968071
INFO:root:current train perplexity5.814168930053711
INFO:root:current mean train loss 2233.925675699648
INFO:root:current train perplexity5.812800884246826
INFO:root:current mean train loss 2232.452466674093
INFO:root:current train perplexity5.809558391571045
INFO:root:current mean train loss 2230.561391890553
INFO:root:current train perplexity5.801936149597168
INFO:root:current mean train loss 2230.5831410355604
INFO:root:current train perplexity5.800824165344238
INFO:root:current mean train loss 2230.0594087990817
INFO:root:current train perplexity5.801754474639893
INFO:root:current mean train loss 2228.822948029308
INFO:root:current train perplexity5.797161102294922
INFO:root:current mean train loss 2225.9953410907187
INFO:root:current train perplexity5.789085388183594
INFO:root:current mean train loss 2225.266317228818
INFO:root:current train perplexity5.784773826599121
INFO:root:current mean train loss 2225.8722714941355
INFO:root:current train perplexity5.781917572021484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.15s/it]
INFO:root:final mean train loss: 2224.4218276615884
INFO:root:final train perplexity: 5.779473781585693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it]
INFO:root:eval mean loss: 2128.7807179985316
INFO:root:eval perplexity: 5.593653678894043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.45s/it]
INFO:root:eval mean loss: 2525.647332806959
INFO:root:eval perplexity: 7.889585971832275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/7
 14%|â–ˆâ–        | 7/50 [48:06<4:54:46, 411.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2295.8787977430557
INFO:root:current train perplexity5.737494468688965
INFO:root:current mean train loss 2204.8080071918034
INFO:root:current train perplexity5.66351318359375
INFO:root:current mean train loss 2197.058153064973
INFO:root:current train perplexity5.610959053039551
INFO:root:current mean train loss 2183.9152989417503
INFO:root:current train perplexity5.583585262298584
INFO:root:current mean train loss 2194.5434768895784
INFO:root:current train perplexity5.619781017303467
INFO:root:current mean train loss 2191.595018541491
INFO:root:current train perplexity5.603808879852295
INFO:root:current mean train loss 2191.5713346907237
INFO:root:current train perplexity5.60185432434082
INFO:root:current mean train loss 2193.0047024272612
INFO:root:current train perplexity5.608296871185303
INFO:root:current mean train loss 2186.7496387136594
INFO:root:current train perplexity5.598814010620117
INFO:root:current mean train loss 2188.1343116510925
INFO:root:current train perplexity5.5993266105651855
INFO:root:current mean train loss 2186.824900569054
INFO:root:current train perplexity5.597348690032959
INFO:root:current mean train loss 2185.2005179580933
INFO:root:current train perplexity5.596331596374512
INFO:root:current mean train loss 2182.9686864592954
INFO:root:current train perplexity5.591792583465576
INFO:root:current mean train loss 2184.0592913475675
INFO:root:current train perplexity5.592298984527588
INFO:root:current mean train loss 2184.0158229983913
INFO:root:current train perplexity5.592907905578613
INFO:root:current mean train loss 2183.084952735147
INFO:root:current train perplexity5.590420246124268
INFO:root:current mean train loss 2181.710488223912
INFO:root:current train perplexity5.584500789642334
INFO:root:current mean train loss 2182.0841596645582
INFO:root:current train perplexity5.584237575531006
INFO:root:current mean train loss 2180.7238997825566
INFO:root:current train perplexity5.580907344818115
INFO:root:current mean train loss 2179.5659942786065
INFO:root:current train perplexity5.577790260314941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.56s/it]
INFO:root:final mean train loss: 2178.53823700182
INFO:root:final train perplexity: 5.574075222015381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 2092.6824449038677
INFO:root:eval perplexity: 5.432713985443115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.98s/it]
INFO:root:eval mean loss: 2493.9351083741967
INFO:root:eval perplexity: 7.687600612640381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/8
 16%|â–ˆâ–Œ        | 8/50 [55:06<4:49:53, 414.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2104.336812918527
INFO:root:current train perplexity5.287924289703369
INFO:root:current mean train loss 2132.120617223669
INFO:root:current train perplexity5.3924360275268555
INFO:root:current mean train loss 2127.6075938123336
INFO:root:current train perplexity5.3980512619018555
INFO:root:current mean train loss 2140.6606459888058
INFO:root:current train perplexity5.414546966552734
INFO:root:current mean train loss 2147.1301564183727
INFO:root:current train perplexity5.437555313110352
INFO:root:current mean train loss 2144.5224102840243
INFO:root:current train perplexity5.422670364379883
INFO:root:current mean train loss 2145.094293645423
INFO:root:current train perplexity5.4191975593566895
INFO:root:current mean train loss 2143.5269373472047
INFO:root:current train perplexity5.418458461761475
INFO:root:current mean train loss 2143.0714096708925
INFO:root:current train perplexity5.4226908683776855
INFO:root:current mean train loss 2146.064171775777
INFO:root:current train perplexity5.4235453605651855
INFO:root:current mean train loss 2146.6410301319065
INFO:root:current train perplexity5.424507141113281
INFO:root:current mean train loss 2147.490028845161
INFO:root:current train perplexity5.430556774139404
INFO:root:current mean train loss 2144.568794479061
INFO:root:current train perplexity5.426638126373291
INFO:root:current mean train loss 2142.4528690638167
INFO:root:current train perplexity5.421441078186035
INFO:root:current mean train loss 2142.7024127388663
INFO:root:current train perplexity5.419466018676758
INFO:root:current mean train loss 2143.1164634282113
INFO:root:current train perplexity5.420236110687256
INFO:root:current mean train loss 2144.189982544319
INFO:root:current train perplexity5.422634124755859
INFO:root:current mean train loss 2143.83166539085
INFO:root:current train perplexity5.422116279602051
INFO:root:current mean train loss 2143.136997216664
INFO:root:current train perplexity5.420175075531006
INFO:root:current mean train loss 2143.325161624879
INFO:root:current train perplexity5.418395042419434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 354.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 354.00s/it]
INFO:root:final mean train loss: 2142.2339310408
INFO:root:final train perplexity: 5.416742324829102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.54s/it]
INFO:root:eval mean loss: 2065.390254460328
INFO:root:eval perplexity: 5.314114093780518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it]
INFO:root:eval mean loss: 2475.1410539775875
INFO:root:eval perplexity: 7.570343017578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/9
 18%|â–ˆâ–Š        | 9/50 [1:01:51<4:41:00, 411.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2071.5396399864785
INFO:root:current train perplexity5.245975494384766
INFO:root:current mean train loss 2107.7811391730056
INFO:root:current train perplexity5.309300422668457
INFO:root:current mean train loss 2120.494834294395
INFO:root:current train perplexity5.312607765197754
INFO:root:current mean train loss 2115.0735716386275
INFO:root:current train perplexity5.306382179260254
INFO:root:current mean train loss 2112.784389529608
INFO:root:current train perplexity5.301694869995117
INFO:root:current mean train loss 2108.653515138488
INFO:root:current train perplexity5.28564977645874
INFO:root:current mean train loss 2110.049738597285
INFO:root:current train perplexity5.2909159660339355
INFO:root:current mean train loss 2109.4828565881608
INFO:root:current train perplexity5.286674976348877
INFO:root:current mean train loss 2113.2699460311674
INFO:root:current train perplexity5.29209566116333
INFO:root:current mean train loss 2111.66524524849
INFO:root:current train perplexity5.289178848266602
INFO:root:current mean train loss 2111.895105166127
INFO:root:current train perplexity5.287518501281738
INFO:root:current mean train loss 2113.201984829373
INFO:root:current train perplexity5.290307521820068
INFO:root:current mean train loss 2110.830477778523
INFO:root:current train perplexity5.287231922149658
INFO:root:current mean train loss 2111.325499675683
INFO:root:current train perplexity5.282450199127197
INFO:root:current mean train loss 2111.678693534914
INFO:root:current train perplexity5.282344818115234
INFO:root:current mean train loss 2111.364590752985
INFO:root:current train perplexity5.282628536224365
INFO:root:current mean train loss 2112.5522033100265
INFO:root:current train perplexity5.285122394561768
INFO:root:current mean train loss 2112.7628318751786
INFO:root:current train perplexity5.285508632659912
INFO:root:current mean train loss 2111.7544232691853
INFO:root:current train perplexity5.283352851867676
INFO:root:current mean train loss 2112.071183939449
INFO:root:current train perplexity5.28375768661499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.81s/it]
INFO:root:final mean train loss: 2110.135520484913
INFO:root:final train perplexity: 5.281339168548584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it]
INFO:root:eval mean loss: 2046.5982315388133
INFO:root:eval perplexity: 5.2339606285095215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.68s/it]
INFO:root:eval mean loss: 2453.896275729998
INFO:root:eval perplexity: 7.439947605133057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/10
 20%|â–ˆâ–ˆ        | 10/50 [1:08:49<4:35:36, 413.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2099.8756156589675
INFO:root:current train perplexity5.222684383392334
INFO:root:current mean train loss 2107.4581645536705
INFO:root:current train perplexity5.22459077835083
INFO:root:current mean train loss 2103.62633551275
INFO:root:current train perplexity5.210586071014404
INFO:root:current mean train loss 2096.370498285061
INFO:root:current train perplexity5.190465450286865
INFO:root:current mean train loss 2094.220551383012
INFO:root:current train perplexity5.188897132873535
INFO:root:current mean train loss 2090.663557699569
INFO:root:current train perplexity5.190132141113281
INFO:root:current mean train loss 2087.607049825124
INFO:root:current train perplexity5.178836822509766
INFO:root:current mean train loss 2089.338274297231
INFO:root:current train perplexity5.187248229980469
INFO:root:current mean train loss 2088.5424407151268
INFO:root:current train perplexity5.188545227050781
INFO:root:current mean train loss 2087.6271417104053
INFO:root:current train perplexity5.185734272003174
INFO:root:current mean train loss 2086.4373312255175
INFO:root:current train perplexity5.182300090789795
INFO:root:current mean train loss 2087.7909962023496
INFO:root:current train perplexity5.18118953704834
INFO:root:current mean train loss 2087.1930039378017
INFO:root:current train perplexity5.182493686676025
INFO:root:current mean train loss 2086.9846172681073
INFO:root:current train perplexity5.178483486175537
INFO:root:current mean train loss 2087.3245088435747
INFO:root:current train perplexity5.181425094604492
INFO:root:current mean train loss 2086.1392504058117
INFO:root:current train perplexity5.177724361419678
INFO:root:current mean train loss 2085.3474303211833
INFO:root:current train perplexity5.175871849060059
INFO:root:current mean train loss 2085.356633903887
INFO:root:current train perplexity5.174067497253418
INFO:root:current mean train loss 2084.6592734772103
INFO:root:current train perplexity5.171138286590576
INFO:root:current mean train loss 2085.018434353078
INFO:root:current train perplexity5.175898551940918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.96s/it]
INFO:root:final mean train loss: 2084.314512621196
INFO:root:final train perplexity: 5.17487907409668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.30s/it]
INFO:root:eval mean loss: 2024.309001949662
INFO:root:eval perplexity: 5.140458106994629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.75s/it]
INFO:root:eval mean loss: 2437.263840695645
INFO:root:eval perplexity: 7.339430332183838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/11
 22%|â–ˆâ–ˆâ–       | 11/50 [1:15:39<4:27:55, 412.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2083.5946229446768
INFO:root:current train perplexity5.109404563903809
INFO:root:current mean train loss 2061.573693060106
INFO:root:current train perplexity5.08058500289917
INFO:root:current mean train loss 2060.3844258768577
INFO:root:current train perplexity5.077774524688721
INFO:root:current mean train loss 2061.5245237992835
INFO:root:current train perplexity5.082710266113281
INFO:root:current mean train loss 2055.534425837513
INFO:root:current train perplexity5.083712100982666
INFO:root:current mean train loss 2058.702884400664
INFO:root:current train perplexity5.082467555999756
INFO:root:current mean train loss 2058.8220784267946
INFO:root:current train perplexity5.068836688995361
INFO:root:current mean train loss 2058.3338385429092
INFO:root:current train perplexity5.063375949859619
INFO:root:current mean train loss 2057.4130787731024
INFO:root:current train perplexity5.059830665588379
INFO:root:current mean train loss 2059.8059744380307
INFO:root:current train perplexity5.065848350524902
INFO:root:current mean train loss 2061.157379318996
INFO:root:current train perplexity5.0725507736206055
INFO:root:current mean train loss 2061.3282943133763
INFO:root:current train perplexity5.072177410125732
INFO:root:current mean train loss 2061.4987423720295
INFO:root:current train perplexity5.072878360748291
INFO:root:current mean train loss 2060.8838068534114
INFO:root:current train perplexity5.073466777801514
INFO:root:current mean train loss 2059.4633933641067
INFO:root:current train perplexity5.074478626251221
INFO:root:current mean train loss 2060.8786922806
INFO:root:current train perplexity5.076112270355225
INFO:root:current mean train loss 2059.508287604028
INFO:root:current train perplexity5.074672222137451
INFO:root:current mean train loss 2059.5296088172768
INFO:root:current train perplexity5.0742645263671875
INFO:root:current mean train loss 2058.8787486459646
INFO:root:current train perplexity5.0736494064331055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.27s/it]
INFO:root:final mean train loss: 2059.315727014585
INFO:root:final train perplexity: 5.073851585388184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 2016.9323864659518
INFO:root:eval perplexity: 5.109882831573486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.23s/it]
INFO:root:eval mean loss: 2428.5556393887136
INFO:root:eval perplexity: 7.287347793579102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/12
 24%|â–ˆâ–ˆâ–       | 12/50 [1:22:32<4:21:16, 412.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2095.390421549479
INFO:root:current train perplexity4.854164123535156
INFO:root:current mean train loss 2042.8458038626366
INFO:root:current train perplexity5.01079797744751
INFO:root:current mean train loss 2032.6917544209898
INFO:root:current train perplexity4.969836235046387
INFO:root:current mean train loss 2036.7952308780682
INFO:root:current train perplexity4.973303318023682
INFO:root:current mean train loss 2034.6573304585725
INFO:root:current train perplexity4.968461990356445
INFO:root:current mean train loss 2036.231893793489
INFO:root:current train perplexity4.977298736572266
INFO:root:current mean train loss 2039.8693886119534
INFO:root:current train perplexity4.993802547454834
INFO:root:current mean train loss 2037.5868011952125
INFO:root:current train perplexity4.983720302581787
INFO:root:current mean train loss 2037.671031301078
INFO:root:current train perplexity4.984226226806641
INFO:root:current mean train loss 2038.0932288692638
INFO:root:current train perplexity4.98783540725708
INFO:root:current mean train loss 2036.4314165657324
INFO:root:current train perplexity4.980705261230469
INFO:root:current mean train loss 2036.4151998677257
INFO:root:current train perplexity4.986016750335693
INFO:root:current mean train loss 2035.4916372196137
INFO:root:current train perplexity4.986083030700684
INFO:root:current mean train loss 2035.5017446779966
INFO:root:current train perplexity4.985432147979736
INFO:root:current mean train loss 2036.2581162401718
INFO:root:current train perplexity4.982656002044678
INFO:root:current mean train loss 2035.9646987762756
INFO:root:current train perplexity4.980800151824951
INFO:root:current mean train loss 2036.899853378553
INFO:root:current train perplexity4.985037803649902
INFO:root:current mean train loss 2036.9373316963631
INFO:root:current train perplexity4.9843974113464355
INFO:root:current mean train loss 2036.916040404664
INFO:root:current train perplexity4.983187198638916
INFO:root:current mean train loss 2038.018760212083
INFO:root:current train perplexity4.985710144042969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.70s/it]
INFO:root:final mean train loss: 2036.8144437373435
INFO:root:final train perplexity: 4.98460578918457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it]
INFO:root:eval mean loss: 2004.764554936835
INFO:root:eval perplexity: 5.059845447540283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.96s/it]
INFO:root:eval mean loss: 2425.407210979056
INFO:root:eval perplexity: 7.268606662750244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/13
 26%|â–ˆâ–ˆâ–Œ       | 13/50 [1:29:30<4:15:22, 414.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1992.131121826172
INFO:root:current train perplexity4.879998207092285
INFO:root:current mean train loss 2008.112158203125
INFO:root:current train perplexity4.861547470092773
INFO:root:current mean train loss 2009.728692072088
INFO:root:current train perplexity4.898502826690674
INFO:root:current mean train loss 2010.141785812378
INFO:root:current train perplexity4.883641242980957
INFO:root:current mean train loss 2011.577082170759
INFO:root:current train perplexity4.886735439300537
INFO:root:current mean train loss 2016.8161031869743
INFO:root:current train perplexity4.8954386711120605
INFO:root:current mean train loss 2012.7359619140625
INFO:root:current train perplexity4.884023666381836
INFO:root:current mean train loss 2010.0849178738065
INFO:root:current train perplexity4.879956245422363
INFO:root:current mean train loss 2008.5950501976943
INFO:root:current train perplexity4.8824567794799805
INFO:root:current mean train loss 2007.700544672427
INFO:root:current train perplexity4.883190155029297
INFO:root:current mean train loss 2008.8629830154719
INFO:root:current train perplexity4.88409948348999
INFO:root:current mean train loss 2009.676583971296
INFO:root:current train perplexity4.887660026550293
INFO:root:current mean train loss 2009.5916709024398
INFO:root:current train perplexity4.8830742835998535
INFO:root:current mean train loss 2011.5400369355173
INFO:root:current train perplexity4.884036064147949
INFO:root:current mean train loss 2012.2781908491968
INFO:root:current train perplexity4.890555381774902
INFO:root:current mean train loss 2011.2608234606291
INFO:root:current train perplexity4.891455173492432
INFO:root:current mean train loss 2011.8618458688995
INFO:root:current train perplexity4.892714500427246
INFO:root:current mean train loss 2013.6703864518986
INFO:root:current train perplexity4.893803119659424
INFO:root:current mean train loss 2012.6525591169084
INFO:root:current train perplexity4.892215251922607
INFO:root:current mean train loss 2013.1669340133667
INFO:root:current train perplexity4.894856929779053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.15s/it]
INFO:root:final mean train loss: 2013.8963225071802
INFO:root:final train perplexity: 4.895320892333984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it]
INFO:root:eval mean loss: 1996.8830627008533
INFO:root:eval perplexity: 5.027696132659912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.13s/it]
INFO:root:eval mean loss: 2416.1684340889574
INFO:root:eval perplexity: 7.213892936706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/14
 28%|â–ˆâ–ˆâ–Š       | 14/50 [1:36:16<4:06:59, 411.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2028.8819415118244
INFO:root:current train perplexity4.768395900726318
INFO:root:current mean train loss 2007.8938906036153
INFO:root:current train perplexity4.80941104888916
INFO:root:current mean train loss 1997.4769920638844
INFO:root:current train perplexity4.80407190322876
INFO:root:current mean train loss 1993.9444706857382
INFO:root:current train perplexity4.7910051345825195
INFO:root:current mean train loss 1994.722470770166
INFO:root:current train perplexity4.796044826507568
INFO:root:current mean train loss 1997.8434222059766
INFO:root:current train perplexity4.809044361114502
INFO:root:current mean train loss 1994.336120318019
INFO:root:current train perplexity4.804923057556152
INFO:root:current mean train loss 1993.1465039195004
INFO:root:current train perplexity4.805351734161377
INFO:root:current mean train loss 1993.139446007878
INFO:root:current train perplexity4.802855968475342
INFO:root:current mean train loss 1990.359587483116
INFO:root:current train perplexity4.798387050628662
INFO:root:current mean train loss 1989.7237345181413
INFO:root:current train perplexity4.800642013549805
INFO:root:current mean train loss 1990.3439900608785
INFO:root:current train perplexity4.80392599105835
INFO:root:current mean train loss 1990.3305553538046
INFO:root:current train perplexity4.803790092468262
INFO:root:current mean train loss 1991.7443010420075
INFO:root:current train perplexity4.8081183433532715
INFO:root:current mean train loss 1990.3727375792396
INFO:root:current train perplexity4.803586959838867
INFO:root:current mean train loss 1992.1610657810468
INFO:root:current train perplexity4.807796478271484
INFO:root:current mean train loss 1992.848276071892
INFO:root:current train perplexity4.810630798339844
INFO:root:current mean train loss 1993.2075898077685
INFO:root:current train perplexity4.812655448913574
INFO:root:current mean train loss 1993.3127111145252
INFO:root:current train perplexity4.814171314239502
INFO:root:current mean train loss 1993.6311154264608
INFO:root:current train perplexity4.816612720489502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.26s/it]
INFO:root:final mean train loss: 1994.0985164363397
INFO:root:final train perplexity: 4.819479942321777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 1976.183808022357
INFO:root:eval perplexity: 4.9442315101623535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it]
INFO:root:eval mean loss: 2395.7280684667276
INFO:root:eval perplexity: 7.094305515289307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/15
 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [1:43:16<4:01:40, 414.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1951.2087583188656
INFO:root:current train perplexity4.714652061462402
INFO:root:current mean train loss 1969.0588363052962
INFO:root:current train perplexity4.760481357574463
INFO:root:current mean train loss 1978.3100451371802
INFO:root:current train perplexity4.7735419273376465
INFO:root:current mean train loss 1974.460438528977
INFO:root:current train perplexity4.761268138885498
INFO:root:current mean train loss 1976.0552395051795
INFO:root:current train perplexity4.754330635070801
INFO:root:current mean train loss 1978.9214171261563
INFO:root:current train perplexity4.7621917724609375
INFO:root:current mean train loss 1981.9176072053588
INFO:root:current train perplexity4.766293525695801
INFO:root:current mean train loss 1978.360194198649
INFO:root:current train perplexity4.75321102142334
INFO:root:current mean train loss 1977.8696629258452
INFO:root:current train perplexity4.754177093505859
INFO:root:current mean train loss 1977.421335920098
INFO:root:current train perplexity4.7549943923950195
INFO:root:current mean train loss 1980.8123633368418
INFO:root:current train perplexity4.759498596191406
INFO:root:current mean train loss 1977.7283562142886
INFO:root:current train perplexity4.753772258758545
INFO:root:current mean train loss 1978.7780182517506
INFO:root:current train perplexity4.757039546966553
INFO:root:current mean train loss 1979.9275948145541
INFO:root:current train perplexity4.755258560180664
INFO:root:current mean train loss 1980.1063602662643
INFO:root:current train perplexity4.756046772003174
INFO:root:current mean train loss 1979.191908120802
INFO:root:current train perplexity4.755975246429443
INFO:root:current mean train loss 1978.0252270773503
INFO:root:current train perplexity4.754150390625
INFO:root:current mean train loss 1978.171799001835
INFO:root:current train perplexity4.755970478057861
INFO:root:current mean train loss 1978.3852269770387
INFO:root:current train perplexity4.7560625076293945
INFO:root:current mean train loss 1977.0031166037616
INFO:root:current train perplexity4.753166675567627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.06s/it]
INFO:root:final mean train loss: 1976.4887750099479
INFO:root:final train perplexity: 4.753009796142578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.50s/it]
INFO:root:eval mean loss: 1974.4542011233932
INFO:root:eval perplexity: 4.937319755554199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it]
INFO:root:eval mean loss: 2398.39625971368
INFO:root:eval perplexity: 7.10980224609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/16
 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [1:50:03<3:53:25, 411.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1994.7693146181778
INFO:root:current train perplexity4.740145683288574
INFO:root:current mean train loss 1971.4113434016356
INFO:root:current train perplexity4.710334777832031
INFO:root:current mean train loss 1968.4490993823513
INFO:root:current train perplexity4.714169025421143
INFO:root:current mean train loss 1967.897758710095
INFO:root:current train perplexity4.709359645843506
INFO:root:current mean train loss 1966.2197218973924
INFO:root:current train perplexity4.714615345001221
INFO:root:current mean train loss 1964.4110468715794
INFO:root:current train perplexity4.707444667816162
INFO:root:current mean train loss 1964.0050398120227
INFO:root:current train perplexity4.700215816497803
INFO:root:current mean train loss 1963.8016870402178
INFO:root:current train perplexity4.7006659507751465
INFO:root:current mean train loss 1962.6501330300123
INFO:root:current train perplexity4.698031425476074
INFO:root:current mean train loss 1961.885855457687
INFO:root:current train perplexity4.698171615600586
INFO:root:current mean train loss 1960.450785831911
INFO:root:current train perplexity4.696110248565674
INFO:root:current mean train loss 1959.552760748859
INFO:root:current train perplexity4.6921868324279785
INFO:root:current mean train loss 1958.713611905918
INFO:root:current train perplexity4.686817169189453
INFO:root:current mean train loss 1959.870341116629
INFO:root:current train perplexity4.6895833015441895
INFO:root:current mean train loss 1960.6600971649814
INFO:root:current train perplexity4.6921796798706055
INFO:root:current mean train loss 1960.348203429593
INFO:root:current train perplexity4.6939239501953125
INFO:root:current mean train loss 1960.3189341501159
INFO:root:current train perplexity4.694406509399414
INFO:root:current mean train loss 1959.562392817992
INFO:root:current train perplexity4.691165924072266
INFO:root:current mean train loss 1959.0779544538766
INFO:root:current train perplexity4.689520359039307
INFO:root:current mean train loss 1960.193115544041
INFO:root:current train perplexity4.690106391906738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.72s/it]
INFO:root:final mean train loss: 1959.9518539113224
INFO:root:final train perplexity: 4.691422939300537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it]
INFO:root:eval mean loss: 1967.5958018201463
INFO:root:eval perplexity: 4.910009860992432
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it]
INFO:root:eval mean loss: 2391.6178502292496
INFO:root:eval perplexity: 7.070496559143066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/17
 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [1:56:54<3:46:25, 411.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1963.2333956631746
INFO:root:current train perplexity4.67568302154541
INFO:root:current mean train loss 1935.0525233491937
INFO:root:current train perplexity4.6183600425720215
INFO:root:current mean train loss 1941.097501542833
INFO:root:current train perplexity4.638704299926758
INFO:root:current mean train loss 1949.8591110386799
INFO:root:current train perplexity4.648384094238281
INFO:root:current mean train loss 1943.9549760662142
INFO:root:current train perplexity4.631379127502441
INFO:root:current mean train loss 1947.86432964299
INFO:root:current train perplexity4.640605449676514
INFO:root:current mean train loss 1943.2741718735806
INFO:root:current train perplexity4.631745338439941
INFO:root:current mean train loss 1942.7766652373493
INFO:root:current train perplexity4.63308572769165
INFO:root:current mean train loss 1944.4508508905635
INFO:root:current train perplexity4.639103412628174
INFO:root:current mean train loss 1943.7725851082125
INFO:root:current train perplexity4.636932849884033
INFO:root:current mean train loss 1943.6135554594152
INFO:root:current train perplexity4.636012554168701
INFO:root:current mean train loss 1944.4472821681989
INFO:root:current train perplexity4.637788772583008
INFO:root:current mean train loss 1945.5852945458075
INFO:root:current train perplexity4.640942096710205
INFO:root:current mean train loss 1944.9443966208687
INFO:root:current train perplexity4.640831470489502
INFO:root:current mean train loss 1944.4692206434024
INFO:root:current train perplexity4.639786243438721
INFO:root:current mean train loss 1943.7514579254073
INFO:root:current train perplexity4.637540817260742
INFO:root:current mean train loss 1943.6411880565481
INFO:root:current train perplexity4.637546062469482
INFO:root:current mean train loss 1944.3428558417882
INFO:root:current train perplexity4.6360764503479
INFO:root:current mean train loss 1946.5268717620331
INFO:root:current train perplexity4.63936710357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.54s/it]
INFO:root:final mean train loss: 1945.1754761665563
INFO:root:final train perplexity: 4.637068271636963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 1957.4597193941156
INFO:root:eval perplexity: 4.869925498962402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.73s/it]
INFO:root:eval mean loss: 2388.4554473660514
INFO:root:eval perplexity: 7.0522356033325195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/18
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [2:03:58<3:41:36, 415.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1850.309423828125
INFO:root:current train perplexity4.362048149108887
INFO:root:current mean train loss 1900.1297886439731
INFO:root:current train perplexity4.546657562255859
INFO:root:current mean train loss 1907.5241127572408
INFO:root:current train perplexity4.53052282333374
INFO:root:current mean train loss 1918.8211874039446
INFO:root:current train perplexity4.5486602783203125
INFO:root:current mean train loss 1914.4822015456211
INFO:root:current train perplexity4.546652793884277
INFO:root:current mean train loss 1918.03388671875
INFO:root:current train perplexity4.549427509307861
INFO:root:current mean train loss 1916.8251614152894
INFO:root:current train perplexity4.546504974365234
INFO:root:current mean train loss 1918.9142256067155
INFO:root:current train perplexity4.550541877746582
INFO:root:current mean train loss 1921.2739642978454
INFO:root:current train perplexity4.558596611022949
INFO:root:current mean train loss 1925.8022914148826
INFO:root:current train perplexity4.56754207611084
INFO:root:current mean train loss 1925.855862533038
INFO:root:current train perplexity4.567751884460449
INFO:root:current mean train loss 1926.9477159042704
INFO:root:current train perplexity4.570940971374512
INFO:root:current mean train loss 1926.4457875105356
INFO:root:current train perplexity4.570570468902588
INFO:root:current mean train loss 1926.014941219169
INFO:root:current train perplexity4.569361686706543
INFO:root:current mean train loss 1927.231243918205
INFO:root:current train perplexity4.570282936096191
INFO:root:current mean train loss 1928.5158339389534
INFO:root:current train perplexity4.57246732711792
INFO:root:current mean train loss 1929.0738420432974
INFO:root:current train perplexity4.573487281799316
INFO:root:current mean train loss 1930.1136725193594
INFO:root:current train perplexity4.577621936798096
INFO:root:current mean train loss 1930.1639983200962
INFO:root:current train perplexity4.579572677612305
INFO:root:current mean train loss 1930.9225112394397
INFO:root:current train perplexity4.582489490509033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.14s/it]
INFO:root:final mean train loss: 1930.263778586491
INFO:root:final train perplexity: 4.582855224609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.79s/it]
INFO:root:eval mean loss: 1952.0706691877217
INFO:root:eval perplexity: 4.848746299743652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.09s/it]
INFO:root:eval mean loss: 2378.9353023015015
INFO:root:eval perplexity: 6.99753999710083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/19
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [2:10:45<3:33:16, 412.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1894.937344637784
INFO:root:current train perplexity4.56330680847168
INFO:root:current mean train loss 1911.0949787077357
INFO:root:current train perplexity4.553085803985596
INFO:root:current mean train loss 1926.5047667907165
INFO:root:current train perplexity4.576357364654541
INFO:root:current mean train loss 1916.465962475131
INFO:root:current train perplexity4.549912929534912
INFO:root:current mean train loss 1911.5243784827644
INFO:root:current train perplexity4.532486438751221
INFO:root:current mean train loss 1915.9346072609853
INFO:root:current train perplexity4.539391040802002
INFO:root:current mean train loss 1916.0130784013263
INFO:root:current train perplexity4.5387725830078125
INFO:root:current mean train loss 1920.0678215555206
INFO:root:current train perplexity4.553109645843506
INFO:root:current mean train loss 1917.8598411541495
INFO:root:current train perplexity4.550881385803223
INFO:root:current mean train loss 1917.9228965775826
INFO:root:current train perplexity4.54573392868042
INFO:root:current mean train loss 1918.1960270054885
INFO:root:current train perplexity4.542206287384033
INFO:root:current mean train loss 1919.6597459762493
INFO:root:current train perplexity4.542977809906006
INFO:root:current mean train loss 1920.2143101169318
INFO:root:current train perplexity4.542646884918213
INFO:root:current mean train loss 1918.7377778253829
INFO:root:current train perplexity4.537938594818115
INFO:root:current mean train loss 1916.9973273297403
INFO:root:current train perplexity4.531792640686035
INFO:root:current mean train loss 1916.7581542487526
INFO:root:current train perplexity4.5314202308654785
INFO:root:current mean train loss 1917.6000599514248
INFO:root:current train perplexity4.532952308654785
INFO:root:current mean train loss 1917.108724241888
INFO:root:current train perplexity4.532406330108643
INFO:root:current mean train loss 1917.5174413821308
INFO:root:current train perplexity4.533272743225098
INFO:root:current mean train loss 1917.2514693531111
INFO:root:current train perplexity4.534007549285889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.54s/it]
INFO:root:final mean train loss: 1916.7341632083155
INFO:root:final train perplexity: 4.534214973449707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.46s/it]
INFO:root:eval mean loss: 1939.9670514045877
INFO:root:eval perplexity: 4.801514148712158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.98s/it]
INFO:root:eval mean loss: 2373.1197375574857
INFO:root:eval perplexity: 6.964337348937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/20
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [2:17:29<3:25:08, 410.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.2974665715144
INFO:root:current train perplexity4.414350986480713
INFO:root:current mean train loss 1890.7908847726505
INFO:root:current train perplexity4.44985294342041
INFO:root:current mean train loss 1905.4994892455543
INFO:root:current train perplexity4.4734601974487305
INFO:root:current mean train loss 1903.8692155235988
INFO:root:current train perplexity4.464214324951172
INFO:root:current mean train loss 1906.1605716783529
INFO:root:current train perplexity4.486099720001221
INFO:root:current mean train loss 1899.765182919759
INFO:root:current train perplexity4.474896430969238
INFO:root:current mean train loss 1903.1283673449116
INFO:root:current train perplexity4.480517387390137
INFO:root:current mean train loss 1903.7617136293238
INFO:root:current train perplexity4.479116916656494
INFO:root:current mean train loss 1905.3596693364032
INFO:root:current train perplexity4.484316349029541
INFO:root:current mean train loss 1906.2800042068109
INFO:root:current train perplexity4.486576080322266
INFO:root:current mean train loss 1907.1885216779956
INFO:root:current train perplexity4.488739490509033
INFO:root:current mean train loss 1906.5274041957034
INFO:root:current train perplexity4.489552021026611
INFO:root:current mean train loss 1904.6693285679605
INFO:root:current train perplexity4.487234592437744
INFO:root:current mean train loss 1905.722734834473
INFO:root:current train perplexity4.486013889312744
INFO:root:current mean train loss 1907.2397489779687
INFO:root:current train perplexity4.488582134246826
INFO:root:current mean train loss 1906.8542388459937
INFO:root:current train perplexity4.490970134735107
INFO:root:current mean train loss 1907.556164260315
INFO:root:current train perplexity4.491479873657227
INFO:root:current mean train loss 1908.2553684263137
INFO:root:current train perplexity4.493393421173096
INFO:root:current mean train loss 1906.446257864541
INFO:root:current train perplexity4.489552021026611
INFO:root:current mean train loss 1904.5354398006382
INFO:root:current train perplexity4.489099025726318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.03s/it]
INFO:root:final mean train loss: 1904.526171647234
INFO:root:final train perplexity: 4.4907684326171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it]
INFO:root:eval mean loss: 1935.5879897530197
INFO:root:eval perplexity: 4.784539699554443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.59s/it]
INFO:root:eval mean loss: 2370.640181304715
INFO:root:eval perplexity: 6.950228691101074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/21
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [2:24:31<3:19:58, 413.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.8239201136998
INFO:root:current train perplexity4.487912178039551
INFO:root:current mean train loss 1906.4973441882012
INFO:root:current train perplexity4.459935188293457
INFO:root:current mean train loss 1900.7573924064636
INFO:root:current train perplexity4.459027290344238
INFO:root:current mean train loss 1898.9819699405284
INFO:root:current train perplexity4.455566883087158
INFO:root:current mean train loss 1893.0053630628083
INFO:root:current train perplexity4.457494258880615
INFO:root:current mean train loss 1892.4746508701242
INFO:root:current train perplexity4.453476905822754
INFO:root:current mean train loss 1892.5367506073742
INFO:root:current train perplexity4.452033519744873
INFO:root:current mean train loss 1895.458567947307
INFO:root:current train perplexity4.452887058258057
INFO:root:current mean train loss 1889.5385402786399
INFO:root:current train perplexity4.437799453735352
INFO:root:current mean train loss 1891.6693692386898
INFO:root:current train perplexity4.441962718963623
INFO:root:current mean train loss 1890.963397401752
INFO:root:current train perplexity4.441420555114746
INFO:root:current mean train loss 1890.5676001314473
INFO:root:current train perplexity4.441932678222656
INFO:root:current mean train loss 1891.6540051114027
INFO:root:current train perplexity4.444159030914307
INFO:root:current mean train loss 1890.8714288132028
INFO:root:current train perplexity4.439802169799805
INFO:root:current mean train loss 1890.7589767791412
INFO:root:current train perplexity4.438106060028076
INFO:root:current mean train loss 1891.933089229319
INFO:root:current train perplexity4.440953254699707
INFO:root:current mean train loss 1893.805585409708
INFO:root:current train perplexity4.444587707519531
INFO:root:current mean train loss 1893.011733974031
INFO:root:current train perplexity4.444770336151123
INFO:root:current mean train loss 1893.8533333745495
INFO:root:current train perplexity4.448360919952393
INFO:root:current mean train loss 1893.5378831734686
INFO:root:current train perplexity4.449538707733154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.85s/it]
INFO:root:final mean train loss: 1892.7593203422944
INFO:root:final train perplexity: 4.449286460876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it]
INFO:root:eval mean loss: 1922.7080437409963
INFO:root:eval perplexity: 4.734960079193115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.81s/it]
INFO:root:eval mean loss: 2354.1011036541445
INFO:root:eval perplexity: 6.85685396194458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/22
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [2:31:17<3:12:03, 411.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1901.701200302333
INFO:root:current train perplexity4.43962287902832
INFO:root:current mean train loss 1894.0302466243677
INFO:root:current train perplexity4.42277717590332
INFO:root:current mean train loss 1899.2003862429888
INFO:root:current train perplexity4.423546314239502
INFO:root:current mean train loss 1893.2203500047126
INFO:root:current train perplexity4.4132304191589355
INFO:root:current mean train loss 1888.3275595537955
INFO:root:current train perplexity4.403936862945557
INFO:root:current mean train loss 1883.937146358257
INFO:root:current train perplexity4.398517608642578
INFO:root:current mean train loss 1880.6491064380573
INFO:root:current train perplexity4.388944149017334
INFO:root:current mean train loss 1882.058664970842
INFO:root:current train perplexity4.394805908203125
INFO:root:current mean train loss 1879.258989157136
INFO:root:current train perplexity4.394845962524414
INFO:root:current mean train loss 1881.2866044078798
INFO:root:current train perplexity4.403430461883545
INFO:root:current mean train loss 1882.7240337218955
INFO:root:current train perplexity4.405015468597412
INFO:root:current mean train loss 1882.407239778979
INFO:root:current train perplexity4.405121326446533
INFO:root:current mean train loss 1883.3053062900444
INFO:root:current train perplexity4.408052921295166
INFO:root:current mean train loss 1882.9021553545213
INFO:root:current train perplexity4.4048357009887695
INFO:root:current mean train loss 1882.3276099511254
INFO:root:current train perplexity4.4035563468933105
INFO:root:current mean train loss 1882.7582967458677
INFO:root:current train perplexity4.403459548950195
INFO:root:current mean train loss 1882.8939154260684
INFO:root:current train perplexity4.405436038970947
INFO:root:current mean train loss 1882.970114185658
INFO:root:current train perplexity4.4094014167785645
INFO:root:current mean train loss 1883.5277911021756
INFO:root:current train perplexity4.414214611053467
INFO:root:current mean train loss 1883.0178430540816
INFO:root:current train perplexity4.413211345672607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.92s/it]
INFO:root:final mean train loss: 1882.2309268984118
INFO:root:final train perplexity: 4.412496089935303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it]
INFO:root:eval mean loss: 1919.7451730281748
INFO:root:eval perplexity: 4.723628044128418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it]
INFO:root:eval mean loss: 2353.0685498393173
INFO:root:eval perplexity: 6.851064205169678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/23
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [2:38:18<3:06:28, 414.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.20543484158
INFO:root:current train perplexity4.3176727294921875
INFO:root:current mean train loss 1863.620613178454
INFO:root:current train perplexity4.350805282592773
INFO:root:current mean train loss 1864.1402583681304
INFO:root:current train perplexity4.359618186950684
INFO:root:current mean train loss 1869.7422450921474
INFO:root:current train perplexity4.368032932281494
INFO:root:current mean train loss 1867.5958513532366
INFO:root:current train perplexity4.362116813659668
INFO:root:current mean train loss 1871.939819956634
INFO:root:current train perplexity4.368531227111816
INFO:root:current mean train loss 1870.682394453408
INFO:root:current train perplexity4.3674139976501465
INFO:root:current mean train loss 1869.8840894481805
INFO:root:current train perplexity4.370355129241943
INFO:root:current mean train loss 1870.5952199185833
INFO:root:current train perplexity4.3716936111450195
INFO:root:current mean train loss 1867.9186122701626
INFO:root:current train perplexity4.36631441116333
INFO:root:current mean train loss 1867.963633014084
INFO:root:current train perplexity4.361929416656494
INFO:root:current mean train loss 1868.5354360884978
INFO:root:current train perplexity4.365720272064209
INFO:root:current mean train loss 1868.8015763157098
INFO:root:current train perplexity4.368983745574951
INFO:root:current mean train loss 1868.8073621571493
INFO:root:current train perplexity4.369803428649902
INFO:root:current mean train loss 1869.4630911807885
INFO:root:current train perplexity4.371816635131836
INFO:root:current mean train loss 1869.0343816025452
INFO:root:current train perplexity4.371771335601807
INFO:root:current mean train loss 1868.750612662953
INFO:root:current train perplexity4.371665000915527
INFO:root:current mean train loss 1870.6070135191167
INFO:root:current train perplexity4.3732452392578125
INFO:root:current mean train loss 1870.9752792116196
INFO:root:current train perplexity4.373712062835693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.56s/it]
INFO:root:final mean train loss: 1871.622788360488
INFO:root:final train perplexity: 4.375734329223633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it]
INFO:root:eval mean loss: 1919.7275845142121
INFO:root:eval perplexity: 4.723560333251953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.97s/it]
INFO:root:eval mean loss: 2357.4008823692375
INFO:root:eval perplexity: 6.875382423400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/24
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [2:45:07<2:58:47, 412.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.018589564732
INFO:root:current train perplexity4.329535007476807
INFO:root:current mean train loss 1850.5731680326373
INFO:root:current train perplexity4.296399116516113
INFO:root:current mean train loss 1858.306369357639
INFO:root:current train perplexity4.313543796539307
INFO:root:current mean train loss 1852.2529777999032
INFO:root:current train perplexity4.305388450622559
INFO:root:current mean train loss 1844.8615644675215
INFO:root:current train perplexity4.288668632507324
INFO:root:current mean train loss 1845.9326781022714
INFO:root:current train perplexity4.29506778717041
INFO:root:current mean train loss 1851.8235289622373
INFO:root:current train perplexity4.309571266174316
INFO:root:current mean train loss 1853.1624767945545
INFO:root:current train perplexity4.316890716552734
INFO:root:current mean train loss 1855.7562942599423
INFO:root:current train perplexity4.323995590209961
INFO:root:current mean train loss 1857.572134133605
INFO:root:current train perplexity4.330270767211914
INFO:root:current mean train loss 1858.8873143125077
INFO:root:current train perplexity4.334403991699219
INFO:root:current mean train loss 1858.7503601460169
INFO:root:current train perplexity4.332583904266357
INFO:root:current mean train loss 1859.1506396201196
INFO:root:current train perplexity4.332277297973633
INFO:root:current mean train loss 1857.7872891648635
INFO:root:current train perplexity4.329752445220947
INFO:root:current mean train loss 1858.5447880054248
INFO:root:current train perplexity4.332890033721924
INFO:root:current mean train loss 1860.341595260529
INFO:root:current train perplexity4.336838245391846
INFO:root:current mean train loss 1861.1392032264848
INFO:root:current train perplexity4.339901924133301
INFO:root:current mean train loss 1860.7162666879485
INFO:root:current train perplexity4.33905553817749
INFO:root:current mean train loss 1861.235524365964
INFO:root:current train perplexity4.341104984283447
INFO:root:current mean train loss 1861.197628059247
INFO:root:current train perplexity4.339700222015381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.02s/it]
INFO:root:final mean train loss: 1861.3304954909702
INFO:root:final train perplexity: 4.340359210968018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.62s/it]
INFO:root:eval mean loss: 1918.0097941946476
INFO:root:eval perplexity: 4.71700382232666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.49s/it]
INFO:root:eval mean loss: 2359.931538466866
INFO:root:eval perplexity: 6.889626502990723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/25
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [2:51:55<2:51:24, 411.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1839.7566680908203
INFO:root:current train perplexity4.294887542724609
INFO:root:current mean train loss 1863.604234264743
INFO:root:current train perplexity4.322586536407471
INFO:root:current mean train loss 1856.2962488446917
INFO:root:current train perplexity4.296813488006592
INFO:root:current mean train loss 1853.6731337559077
INFO:root:current train perplexity4.29410982131958
INFO:root:current mean train loss 1859.5058492984413
INFO:root:current train perplexity4.3176960945129395
INFO:root:current mean train loss 1854.3040331192599
INFO:root:current train perplexity4.307862281799316
INFO:root:current mean train loss 1854.1619775234124
INFO:root:current train perplexity4.306925296783447
INFO:root:current mean train loss 1848.35757631755
INFO:root:current train perplexity4.3024702072143555
INFO:root:current mean train loss 1849.4913448592993
INFO:root:current train perplexity4.302016258239746
INFO:root:current mean train loss 1848.5274642349837
INFO:root:current train perplexity4.300797939300537
INFO:root:current mean train loss 1851.485524058342
INFO:root:current train perplexity4.305166721343994
INFO:root:current mean train loss 1851.4964196690462
INFO:root:current train perplexity4.302710056304932
INFO:root:current mean train loss 1853.3636471617456
INFO:root:current train perplexity4.306792736053467
INFO:root:current mean train loss 1853.9202252068187
INFO:root:current train perplexity4.306483745574951
INFO:root:current mean train loss 1853.1986944648656
INFO:root:current train perplexity4.308279037475586
INFO:root:current mean train loss 1852.3146501676304
INFO:root:current train perplexity4.304123401641846
INFO:root:current mean train loss 1853.243500206858
INFO:root:current train perplexity4.30658483505249
INFO:root:current mean train loss 1853.653502214259
INFO:root:current train perplexity4.307360649108887
INFO:root:current mean train loss 1852.4531288816218
INFO:root:current train perplexity4.3069586753845215
INFO:root:current mean train loss 1852.1893111326094
INFO:root:current train perplexity4.306081295013428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.65s/it]
INFO:root:final mean train loss: 1851.43832626766
INFO:root:final train perplexity: 4.306629657745361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.50s/it]
INFO:root:eval mean loss: 1908.946221534242
INFO:root:eval perplexity: 4.682553291320801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it]
INFO:root:eval mean loss: 2349.1858832176695
INFO:root:eval perplexity: 6.829345226287842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/26
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [2:58:41<2:43:47, 409.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1824.0973049256859
INFO:root:current train perplexity4.288329601287842
INFO:root:current mean train loss 1827.6081110095301
INFO:root:current train perplexity4.241477012634277
INFO:root:current mean train loss 1832.7902599033973
INFO:root:current train perplexity4.255407810211182
INFO:root:current mean train loss 1830.0181147332066
INFO:root:current train perplexity4.25627326965332
INFO:root:current mean train loss 1832.822394338595
INFO:root:current train perplexity4.260907173156738
INFO:root:current mean train loss 1833.5340605504853
INFO:root:current train perplexity4.25501823425293
INFO:root:current mean train loss 1837.7694754518695
INFO:root:current train perplexity4.269111633300781
INFO:root:current mean train loss 1839.114968489056
INFO:root:current train perplexity4.268141269683838
INFO:root:current mean train loss 1841.0651745155508
INFO:root:current train perplexity4.270364284515381
INFO:root:current mean train loss 1841.2308192643297
INFO:root:current train perplexity4.269459247589111
INFO:root:current mean train loss 1840.4031523925312
INFO:root:current train perplexity4.268397808074951
INFO:root:current mean train loss 1839.9553591755794
INFO:root:current train perplexity4.268748760223389
INFO:root:current mean train loss 1838.246688264882
INFO:root:current train perplexity4.264433860778809
INFO:root:current mean train loss 1840.513562912909
INFO:root:current train perplexity4.2693634033203125
INFO:root:current mean train loss 1839.349120670189
INFO:root:current train perplexity4.266439437866211
INFO:root:current mean train loss 1840.8146623318107
INFO:root:current train perplexity4.269812107086182
INFO:root:current mean train loss 1841.051585604838
INFO:root:current train perplexity4.269066333770752
INFO:root:current mean train loss 1841.7347590902768
INFO:root:current train perplexity4.27072286605835
INFO:root:current mean train loss 1841.4264480284153
INFO:root:current train perplexity4.270431041717529
INFO:root:current mean train loss 1842.1186199551817
INFO:root:current train perplexity4.272729396820068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.13s/it]
INFO:root:final mean train loss: 1841.805985705154
INFO:root:final train perplexity: 4.274038314819336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 1913.1193150729998
INFO:root:eval perplexity: 4.698383808135986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.14s/it]
INFO:root:eval mean loss: 2354.741062029034
INFO:root:eval perplexity: 6.860442638397217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/27
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [3:05:44<2:38:37, 413.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1828.325927734375
INFO:root:current train perplexity4.190575122833252
INFO:root:current mean train loss 1824.1159791584257
INFO:root:current train perplexity4.211187839508057
INFO:root:current mean train loss 1827.5586500537488
INFO:root:current train perplexity4.234927177429199
INFO:root:current mean train loss 1822.411981167074
INFO:root:current train perplexity4.223781585693359
INFO:root:current mean train loss 1826.180220025075
INFO:root:current train perplexity4.2339067459106445
INFO:root:current mean train loss 1827.4628578103998
INFO:root:current train perplexity4.234835147857666
INFO:root:current mean train loss 1827.3955037311218
INFO:root:current train perplexity4.234508037567139
INFO:root:current mean train loss 1829.692104852923
INFO:root:current train perplexity4.2351908683776855
INFO:root:current mean train loss 1829.8459633424843
INFO:root:current train perplexity4.237674236297607
INFO:root:current mean train loss 1831.8929615379127
INFO:root:current train perplexity4.237717151641846
INFO:root:current mean train loss 1831.0080187965204
INFO:root:current train perplexity4.236115455627441
INFO:root:current mean train loss 1829.556662445859
INFO:root:current train perplexity4.232456207275391
INFO:root:current mean train loss 1829.5288488633682
INFO:root:current train perplexity4.234334468841553
INFO:root:current mean train loss 1830.2233558621076
INFO:root:current train perplexity4.238463401794434
INFO:root:current mean train loss 1831.3968494137946
INFO:root:current train perplexity4.243594169616699
INFO:root:current mean train loss 1832.6545370197418
INFO:root:current train perplexity4.245014190673828
INFO:root:current mean train loss 1832.9380543229088
INFO:root:current train perplexity4.247161388397217
INFO:root:current mean train loss 1833.703442674448
INFO:root:current train perplexity4.248917102813721
INFO:root:current mean train loss 1833.6839078609603
INFO:root:current train perplexity4.248936653137207
INFO:root:current mean train loss 1835.0491092981918
INFO:root:current train perplexity4.248934745788574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.85s/it]
INFO:root:final mean train loss: 1834.0177605533263
INFO:root:final train perplexity: 4.247865200042725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it]
INFO:root:eval mean loss: 1903.2132875699524
INFO:root:eval perplexity: 4.660894393920898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it]
INFO:root:eval mean loss: 2345.5471940277316
INFO:root:eval perplexity: 6.809052467346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/28
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [3:12:32<2:31:03, 411.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1828.7645882161457
INFO:root:current train perplexity4.2350568771362305
INFO:root:current mean train loss 1824.0654757254465
INFO:root:current train perplexity4.205425262451172
INFO:root:current mean train loss 1820.4194224964488
INFO:root:current train perplexity4.1935553550720215
INFO:root:current mean train loss 1824.73659375
INFO:root:current train perplexity4.205196380615234
INFO:root:current mean train loss 1826.7046412417762
INFO:root:current train perplexity4.215315818786621
INFO:root:current mean train loss 1828.07203570822
INFO:root:current train perplexity4.216997146606445
INFO:root:current mean train loss 1825.4639091435185
INFO:root:current train perplexity4.215852737426758
INFO:root:current mean train loss 1828.3925741872479
INFO:root:current train perplexity4.223475933074951
INFO:root:current mean train loss 1829.5992332589285
INFO:root:current train perplexity4.222718238830566
INFO:root:current mean train loss 1830.8659729316907
INFO:root:current train perplexity4.229892730712891
INFO:root:current mean train loss 1830.2694242823402
INFO:root:current train perplexity4.222885608673096
INFO:root:current mean train loss 1826.606892869016
INFO:root:current train perplexity4.217190265655518
INFO:root:current mean train loss 1826.4422997089462
INFO:root:current train perplexity4.218792915344238
INFO:root:current mean train loss 1825.8769573863635
INFO:root:current train perplexity4.218727111816406
INFO:root:current mean train loss 1826.9427030091367
INFO:root:current train perplexity4.22145414352417
INFO:root:current mean train loss 1827.3040769159227
INFO:root:current train perplexity4.221292018890381
INFO:root:current mean train loss 1827.8459377915112
INFO:root:current train perplexity4.221937656402588
INFO:root:current mean train loss 1827.5434165933098
INFO:root:current train perplexity4.221832275390625
INFO:root:current mean train loss 1827.1459374348958
INFO:root:current train perplexity4.221700668334961
INFO:root:current mean train loss 1827.1721178426621
INFO:root:current train perplexity4.223031520843506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.24s/it]
INFO:root:final mean train loss: 1826.5953667083295
INFO:root:final train perplexity: 4.223072528839111
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.16s/it]
INFO:root:eval mean loss: 1899.838544696781
INFO:root:eval perplexity: 4.648189544677734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it]
INFO:root:eval mean loss: 2340.581222642398
INFO:root:eval perplexity: 6.7814555168151855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/29
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [3:19:17<2:23:23, 409.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1824.7502414869225
INFO:root:current train perplexity4.197610378265381
INFO:root:current mean train loss 1823.6873016357422
INFO:root:current train perplexity4.197733402252197
INFO:root:current mean train loss 1818.7665572493045
INFO:root:current train perplexity4.1950507164001465
INFO:root:current mean train loss 1816.2557155064173
INFO:root:current train perplexity4.195034503936768
INFO:root:current mean train loss 1817.1125197992092
INFO:root:current train perplexity4.197083473205566
INFO:root:current mean train loss 1819.5984839362068
INFO:root:current train perplexity4.193110942840576
INFO:root:current mean train loss 1816.329948116589
INFO:root:current train perplexity4.189387321472168
INFO:root:current mean train loss 1816.7975266581834
INFO:root:current train perplexity4.190188884735107
INFO:root:current mean train loss 1817.8902114389189
INFO:root:current train perplexity4.191651344299316
INFO:root:current mean train loss 1820.0441303868447
INFO:root:current train perplexity4.200798988342285
INFO:root:current mean train loss 1820.576640370128
INFO:root:current train perplexity4.200112342834473
INFO:root:current mean train loss 1821.5097094030189
INFO:root:current train perplexity4.201242923736572
INFO:root:current mean train loss 1821.3884007126185
INFO:root:current train perplexity4.2019734382629395
INFO:root:current mean train loss 1821.2187013297246
INFO:root:current train perplexity4.200902938842773
INFO:root:current mean train loss 1819.7711011462172
INFO:root:current train perplexity4.198678970336914
INFO:root:current mean train loss 1819.9852873835732
INFO:root:current train perplexity4.202251434326172
INFO:root:current mean train loss 1820.663713676146
INFO:root:current train perplexity4.203244209289551
INFO:root:current mean train loss 1821.6666264533997
INFO:root:current train perplexity4.203991413116455
INFO:root:current mean train loss 1820.8628996189755
INFO:root:current train perplexity4.2014946937561035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.05s/it]
INFO:root:final mean train loss: 1820.0010749943858
INFO:root:final train perplexity: 4.201167106628418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 1900.3695514219028
INFO:root:eval perplexity: 4.650186061859131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.92s/it]
INFO:root:eval mean loss: 2342.763231642703
INFO:root:eval perplexity: 6.793567180633545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/30
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [3:26:16<2:17:35, 412.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.6949462890625
INFO:root:current train perplexity4.18546199798584
INFO:root:current mean train loss 1802.6767354142776
INFO:root:current train perplexity4.145354270935059
INFO:root:current mean train loss 1796.3049176229815
INFO:root:current train perplexity4.1299519538879395
INFO:root:current mean train loss 1806.6258509367415
INFO:root:current train perplexity4.153319358825684
INFO:root:current mean train loss 1805.4658015094935
INFO:root:current train perplexity4.147250175476074
INFO:root:current mean train loss 1805.5229305124938
INFO:root:current train perplexity4.143631458282471
INFO:root:current mean train loss 1805.372688681817
INFO:root:current train perplexity4.151849269866943
INFO:root:current mean train loss 1807.3193874170818
INFO:root:current train perplexity4.15336799621582
INFO:root:current mean train loss 1806.7990864493202
INFO:root:current train perplexity4.157128810882568
INFO:root:current mean train loss 1809.613601130621
INFO:root:current train perplexity4.162786960601807
INFO:root:current mean train loss 1809.4935656000293
INFO:root:current train perplexity4.162837505340576
INFO:root:current mean train loss 1808.8683996174764
INFO:root:current train perplexity4.16804313659668
INFO:root:current mean train loss 1809.338349827466
INFO:root:current train perplexity4.169466495513916
INFO:root:current mean train loss 1809.639785335299
INFO:root:current train perplexity4.172287940979004
INFO:root:current mean train loss 1810.3601211970204
INFO:root:current train perplexity4.172851085662842
INFO:root:current mean train loss 1809.8828471229913
INFO:root:current train perplexity4.1715006828308105
INFO:root:current mean train loss 1810.7826291138226
INFO:root:current train perplexity4.173027515411377
INFO:root:current mean train loss 1810.9760492904065
INFO:root:current train perplexity4.1702799797058105
INFO:root:current mean train loss 1811.0541421311411
INFO:root:current train perplexity4.170073986053467
INFO:root:current mean train loss 1811.8343131783247
INFO:root:current train perplexity4.1718268394470215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.98s/it]
INFO:root:final mean train loss: 1811.4595502506165
INFO:root:final train perplexity: 4.172961711883545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 1897.7419524497175
INFO:root:eval perplexity: 4.64031457901001
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.30s/it]
INFO:root:eval mean loss: 2343.7544404158357
INFO:root:eval perplexity: 6.79907751083374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/31
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [3:33:17<2:11:25, 415.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.24560546875
INFO:root:current train perplexity4.196369647979736
INFO:root:current mean train loss 1828.1466568235367
INFO:root:current train perplexity4.184996604919434
INFO:root:current mean train loss 1817.3064175496058
INFO:root:current train perplexity4.1666460037231445
INFO:root:current mean train loss 1811.4380025103048
INFO:root:current train perplexity4.164206027984619
INFO:root:current mean train loss 1812.0910710437756
INFO:root:current train perplexity4.154163360595703
INFO:root:current mean train loss 1809.4330804048836
INFO:root:current train perplexity4.147069454193115
INFO:root:current mean train loss 1806.0045657416883
INFO:root:current train perplexity4.144687175750732
INFO:root:current mean train loss 1804.6054099006758
INFO:root:current train perplexity4.14415979385376
INFO:root:current mean train loss 1805.9970796229475
INFO:root:current train perplexity4.143499374389648
INFO:root:current mean train loss 1805.4956915507307
INFO:root:current train perplexity4.148557662963867
INFO:root:current mean train loss 1805.4865745261864
INFO:root:current train perplexity4.149207592010498
INFO:root:current mean train loss 1804.9273014915561
INFO:root:current train perplexity4.152176380157471
INFO:root:current mean train loss 1804.6828300637872
INFO:root:current train perplexity4.152198791503906
INFO:root:current mean train loss 1804.4333721638445
INFO:root:current train perplexity4.150216102600098
INFO:root:current mean train loss 1803.5378045594375
INFO:root:current train perplexity4.148968696594238
INFO:root:current mean train loss 1804.11720677847
INFO:root:current train perplexity4.151212692260742
INFO:root:current mean train loss 1805.1306611796588
INFO:root:current train perplexity4.152470111846924
INFO:root:current mean train loss 1804.7522331936195
INFO:root:current train perplexity4.148921966552734
INFO:root:current mean train loss 1805.9630467894303
INFO:root:current train perplexity4.154370307922363
INFO:root:current mean train loss 1805.4807172004803
INFO:root:current train perplexity4.153509616851807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.70s/it]
INFO:root:final mean train loss: 1806.1749298049535
INFO:root:final train perplexity: 4.155605792999268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it]
INFO:root:eval mean loss: 1892.205726569426
INFO:root:eval perplexity: 4.619585037231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.50s/it]
INFO:root:eval mean loss: 2338.198077262716
INFO:root:eval perplexity: 6.768250465393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/32
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [3:40:02<2:03:38, 412.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1808.4702829760174
INFO:root:current train perplexity4.159420967102051
INFO:root:current mean train loss 1811.9315945285184
INFO:root:current train perplexity4.16144323348999
INFO:root:current mean train loss 1814.588495953093
INFO:root:current train perplexity4.143387317657471
INFO:root:current mean train loss 1804.68945348089
INFO:root:current train perplexity4.128242015838623
INFO:root:current mean train loss 1799.1835463547545
INFO:root:current train perplexity4.13024377822876
INFO:root:current mean train loss 1798.84066586995
INFO:root:current train perplexity4.131710529327393
INFO:root:current mean train loss 1799.9487650205335
INFO:root:current train perplexity4.136956214904785
INFO:root:current mean train loss 1800.08009701879
INFO:root:current train perplexity4.139779090881348
INFO:root:current mean train loss 1800.9819218645741
INFO:root:current train perplexity4.142658710479736
INFO:root:current mean train loss 1800.5377067816726
INFO:root:current train perplexity4.137042999267578
INFO:root:current mean train loss 1799.5966628340723
INFO:root:current train perplexity4.136420726776123
INFO:root:current mean train loss 1798.0463641843353
INFO:root:current train perplexity4.132724761962891
INFO:root:current mean train loss 1798.3802987157771
INFO:root:current train perplexity4.131677150726318
INFO:root:current mean train loss 1798.740020592889
INFO:root:current train perplexity4.130756378173828
INFO:root:current mean train loss 1799.4596112225506
INFO:root:current train perplexity4.133275032043457
INFO:root:current mean train loss 1798.4754705126225
INFO:root:current train perplexity4.131511211395264
INFO:root:current mean train loss 1799.3487655816105
INFO:root:current train perplexity4.133086204528809
INFO:root:current mean train loss 1798.6417012217396
INFO:root:current train perplexity4.129527568817139
INFO:root:current mean train loss 1800.1072059503017
INFO:root:current train perplexity4.132931709289551
INFO:root:current mean train loss 1799.092091401827
INFO:root:current train perplexity4.129592418670654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.24s/it]
INFO:root:final mean train loss: 1798.7054744995548
INFO:root:final train perplexity: 4.131197452545166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 1888.81348911583
INFO:root:eval perplexity: 4.606928825378418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.48s/it]
INFO:root:eval mean loss: 2334.878857768174
INFO:root:eval perplexity: 6.749903678894043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/33
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [3:47:05<1:57:41, 415.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1781.3978352864583
INFO:root:current train perplexity4.089352607727051
INFO:root:current mean train loss 1788.1330261230469
INFO:root:current train perplexity4.119361400604248
INFO:root:current mean train loss 1792.744424673227
INFO:root:current train perplexity4.123269557952881
INFO:root:current mean train loss 1787.9004991319443
INFO:root:current train perplexity4.1128692626953125
INFO:root:current mean train loss 1789.3456829568613
INFO:root:current train perplexity4.11802339553833
INFO:root:current mean train loss 1784.746741594587
INFO:root:current train perplexity4.101836204528809
INFO:root:current mean train loss 1783.8737288041548
INFO:root:current train perplexity4.103259086608887
INFO:root:current mean train loss 1787.850164794922
INFO:root:current train perplexity4.104528427124023
INFO:root:current mean train loss 1785.3632116983104
INFO:root:current train perplexity4.097047805786133
INFO:root:current mean train loss 1787.104144668579
INFO:root:current train perplexity4.100636005401611
INFO:root:current mean train loss 1788.5077940742924
INFO:root:current train perplexity4.101888656616211
INFO:root:current mean train loss 1789.463536545326
INFO:root:current train perplexity4.102541923522949
INFO:root:current mean train loss 1790.059704202319
INFO:root:current train perplexity4.104957103729248
INFO:root:current mean train loss 1792.2132570154527
INFO:root:current train perplexity4.108953475952148
INFO:root:current mean train loss 1793.961100957165
INFO:root:current train perplexity4.111094951629639
INFO:root:current mean train loss 1794.7196434607872
INFO:root:current train perplexity4.111936092376709
INFO:root:current mean train loss 1795.1315551022449
INFO:root:current train perplexity4.113749027252197
INFO:root:current mean train loss 1794.589710374312
INFO:root:current train perplexity4.112722396850586
INFO:root:current mean train loss 1793.8723959645918
INFO:root:current train perplexity4.112812519073486
INFO:root:current mean train loss 1793.2367127087653
INFO:root:current train perplexity4.112112045288086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.86s/it]
INFO:root:final mean train loss: 1792.8851295890559
INFO:root:final train perplexity: 4.112277507781982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.74s/it]
INFO:root:eval mean loss: 1898.1340340688719
INFO:root:eval perplexity: 4.641786098480225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.94s/it]
INFO:root:eval mean loss: 2345.1494357061724
INFO:root:eval perplexity: 6.806837558746338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/34
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [3:53:54<1:50:14, 413.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.683563628754
INFO:root:current train perplexity4.069732189178467
INFO:root:current mean train loss 1783.0596351408014
INFO:root:current train perplexity4.089411735534668
INFO:root:current mean train loss 1784.6315750507672
INFO:root:current train perplexity4.092792987823486
INFO:root:current mean train loss 1783.3991449897421
INFO:root:current train perplexity4.088414192199707
INFO:root:current mean train loss 1784.1086712403367
INFO:root:current train perplexity4.0858259201049805
INFO:root:current mean train loss 1785.1276531781439
INFO:root:current train perplexity4.093685626983643
INFO:root:current mean train loss 1782.6534387765994
INFO:root:current train perplexity4.087002277374268
INFO:root:current mean train loss 1782.5581379894124
INFO:root:current train perplexity4.081788539886475
INFO:root:current mean train loss 1785.8159896520008
INFO:root:current train perplexity4.089759349822998
INFO:root:current mean train loss 1786.7356681706594
INFO:root:current train perplexity4.0904974937438965
INFO:root:current mean train loss 1785.0634018695232
INFO:root:current train perplexity4.08706521987915
INFO:root:current mean train loss 1784.9814670922499
INFO:root:current train perplexity4.091880798339844
INFO:root:current mean train loss 1785.224054562084
INFO:root:current train perplexity4.091587066650391
INFO:root:current mean train loss 1784.479818772127
INFO:root:current train perplexity4.089292049407959
INFO:root:current mean train loss 1785.4091512567704
INFO:root:current train perplexity4.08980131149292
INFO:root:current mean train loss 1786.343226034277
INFO:root:current train perplexity4.090169906616211
INFO:root:current mean train loss 1786.0903482636172
INFO:root:current train perplexity4.088908672332764
INFO:root:current mean train loss 1786.5843707134566
INFO:root:current train perplexity4.090365886688232
INFO:root:current mean train loss 1787.3992685796609
INFO:root:current train perplexity4.091569423675537
INFO:root:current mean train loss 1787.0176044902116
INFO:root:current train perplexity4.091760635375977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.08s/it]
INFO:root:final mean train loss: 1786.3682019209177
INFO:root:final train perplexity: 4.091196537017822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it]
INFO:root:eval mean loss: 1886.7283203990746
INFO:root:eval perplexity: 4.599166393280029
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it]
INFO:root:eval mean loss: 2335.3241282794493
INFO:root:eval perplexity: 6.75236177444458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/35
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [4:00:59<1:44:14, 416.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1797.263844591506
INFO:root:current train perplexity4.069963455200195
INFO:root:current mean train loss 1787.3970255114368
INFO:root:current train perplexity4.063175678253174
INFO:root:current mean train loss 1786.365099018123
INFO:root:current train perplexity4.07785177230835
INFO:root:current mean train loss 1780.869295536564
INFO:root:current train perplexity4.069985866546631
INFO:root:current mean train loss 1781.5243221391067
INFO:root:current train perplexity4.074901103973389
INFO:root:current mean train loss 1780.1438746596828
INFO:root:current train perplexity4.071838855743408
INFO:root:current mean train loss 1785.7650668889025
INFO:root:current train perplexity4.0882134437561035
INFO:root:current mean train loss 1788.9886122542605
INFO:root:current train perplexity4.090377330780029
INFO:root:current mean train loss 1787.8380356347002
INFO:root:current train perplexity4.083581924438477
INFO:root:current mean train loss 1785.2999051437532
INFO:root:current train perplexity4.0767645835876465
INFO:root:current mean train loss 1783.7188957256199
INFO:root:current train perplexity4.077381610870361
INFO:root:current mean train loss 1783.1105931472139
INFO:root:current train perplexity4.0779948234558105
INFO:root:current mean train loss 1783.343180684439
INFO:root:current train perplexity4.078826904296875
INFO:root:current mean train loss 1783.6273842241021
INFO:root:current train perplexity4.078227519989014
INFO:root:current mean train loss 1784.213242292085
INFO:root:current train perplexity4.07881498336792
INFO:root:current mean train loss 1784.2792545256382
INFO:root:current train perplexity4.077974796295166
INFO:root:current mean train loss 1784.8735196632647
INFO:root:current train perplexity4.077907562255859
INFO:root:current mean train loss 1784.3357509923487
INFO:root:current train perplexity4.076406002044678
INFO:root:current mean train loss 1783.1792687614466
INFO:root:current train perplexity4.076970100402832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.95s/it]
INFO:root:final mean train loss: 1781.8916421910458
INFO:root:final train perplexity: 4.076777935028076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it]
INFO:root:eval mean loss: 1886.490676338791
INFO:root:eval perplexity: 4.598282814025879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.76s/it]
INFO:root:eval mean loss: 2338.4308748718695
INFO:root:eval perplexity: 6.769539833068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/36
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [4:08:03<1:37:45, 418.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1842.4235506924715
INFO:root:current train perplexity4.175115585327148
INFO:root:current mean train loss 1773.3439006633587
INFO:root:current train perplexity4.048986911773682
INFO:root:current mean train loss 1776.2342916913508
INFO:root:current train perplexity4.060975551605225
INFO:root:current mean train loss 1776.5807928839681
INFO:root:current train perplexity4.057859420776367
INFO:root:current mean train loss 1779.1910391480383
INFO:root:current train perplexity4.055848121643066
INFO:root:current mean train loss 1778.7608783520363
INFO:root:current train perplexity4.055914878845215
INFO:root:current mean train loss 1777.6396494364387
INFO:root:current train perplexity4.051835060119629
INFO:root:current mean train loss 1775.7946109476638
INFO:root:current train perplexity4.052011489868164
INFO:root:current mean train loss 1775.972457716409
INFO:root:current train perplexity4.052610874176025
INFO:root:current mean train loss 1778.873153401782
INFO:root:current train perplexity4.057547092437744
INFO:root:current mean train loss 1779.459627689169
INFO:root:current train perplexity4.060843467712402
INFO:root:current mean train loss 1777.2212285437529
INFO:root:current train perplexity4.058049201965332
INFO:root:current mean train loss 1777.5685578526593
INFO:root:current train perplexity4.059243202209473
INFO:root:current mean train loss 1777.7464320272275
INFO:root:current train perplexity4.059661388397217
INFO:root:current mean train loss 1777.0270102411023
INFO:root:current train perplexity4.059095859527588
INFO:root:current mean train loss 1776.5845147466755
INFO:root:current train perplexity4.057746410369873
INFO:root:current mean train loss 1775.2943263749466
INFO:root:current train perplexity4.054746150970459
INFO:root:current mean train loss 1775.8544697853504
INFO:root:current train perplexity4.055230617523193
INFO:root:current mean train loss 1776.7287302422694
INFO:root:current train perplexity4.056835174560547
INFO:root:current mean train loss 1776.2108775827037
INFO:root:current train perplexity4.056304454803467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.44s/it]
INFO:root:final mean train loss: 1775.8193409237306
INFO:root:final train perplexity: 4.057301044464111
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it]
INFO:root:eval mean loss: 1877.3309023160461
INFO:root:eval perplexity: 4.564344882965088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it]
INFO:root:eval mean loss: 2325.8914911797706
INFO:root:eval perplexity: 6.700471878051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/37
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [4:14:50<1:30:02, 415.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.2799508231026
INFO:root:current train perplexity4.06214714050293
INFO:root:current mean train loss 1791.5182065963745
INFO:root:current train perplexity4.079111099243164
INFO:root:current mean train loss 1783.070526658443
INFO:root:current train perplexity4.074188709259033
INFO:root:current mean train loss 1772.9598172815834
INFO:root:current train perplexity4.058061599731445
INFO:root:current mean train loss 1769.3382494204511
INFO:root:current train perplexity4.050535678863525
INFO:root:current mean train loss 1770.3568748705316
INFO:root:current train perplexity4.043392181396484
INFO:root:current mean train loss 1772.7853790088823
INFO:root:current train perplexity4.048509120941162
INFO:root:current mean train loss 1770.8926685039814
INFO:root:current train perplexity4.044366359710693
INFO:root:current mean train loss 1773.0053637223543
INFO:root:current train perplexity4.046931266784668
INFO:root:current mean train loss 1774.8895541223987
INFO:root:current train perplexity4.047257900238037
INFO:root:current mean train loss 1776.6783956683564
INFO:root:current train perplexity4.048708915710449
INFO:root:current mean train loss 1776.2358935200575
INFO:root:current train perplexity4.05092716217041
INFO:root:current mean train loss 1774.8158297958125
INFO:root:current train perplexity4.051538467407227
INFO:root:current mean train loss 1774.2304178260895
INFO:root:current train perplexity4.047214508056641
INFO:root:current mean train loss 1774.092088116985
INFO:root:current train perplexity4.045857906341553
INFO:root:current mean train loss 1774.162169131933
INFO:root:current train perplexity4.044806957244873
INFO:root:current mean train loss 1772.8978860091227
INFO:root:current train perplexity4.042444229125977
INFO:root:current mean train loss 1773.5737555468525
INFO:root:current train perplexity4.042347431182861
INFO:root:current mean train loss 1772.3126581972485
INFO:root:current train perplexity4.042571544647217
INFO:root:current mean train loss 1771.542969826346
INFO:root:current train perplexity4.041609287261963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.76s/it]
INFO:root:final mean train loss: 1771.043682673575
INFO:root:final train perplexity: 4.042048454284668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 1872.015217666085
INFO:root:eval perplexity: 4.544764041900635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.80s/it]
INFO:root:eval mean loss: 2320.3417856202905
INFO:root:eval perplexity: 6.670130252838135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/38
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [4:21:49<1:23:16, 416.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1762.5027777777777
INFO:root:current train perplexity4.016165256500244
INFO:root:current mean train loss 1768.3938409213363
INFO:root:current train perplexity4.0348381996154785
INFO:root:current mean train loss 1771.3692143654337
INFO:root:current train perplexity4.035493850708008
INFO:root:current mean train loss 1774.843010855412
INFO:root:current train perplexity4.03835916519165
INFO:root:current mean train loss 1771.2699224236305
INFO:root:current train perplexity4.039910316467285
INFO:root:current mean train loss 1768.595116291571
INFO:root:current train perplexity4.0378737449646
INFO:root:current mean train loss 1768.4269538820251
INFO:root:current train perplexity4.031101703643799
INFO:root:current mean train loss 1768.7975009175755
INFO:root:current train perplexity4.035019397735596
INFO:root:current mean train loss 1767.9379208175387
INFO:root:current train perplexity4.0315423011779785
INFO:root:current mean train loss 1765.068783327133
INFO:root:current train perplexity4.023624897003174
INFO:root:current mean train loss 1764.4148573003888
INFO:root:current train perplexity4.023237228393555
INFO:root:current mean train loss 1764.2058955163413
INFO:root:current train perplexity4.022385120391846
INFO:root:current mean train loss 1762.8850033924762
INFO:root:current train perplexity4.02113151550293
INFO:root:current mean train loss 1764.366827460647
INFO:root:current train perplexity4.02278995513916
INFO:root:current mean train loss 1765.1211917441608
INFO:root:current train perplexity4.024257183074951
INFO:root:current mean train loss 1765.7705792374595
INFO:root:current train perplexity4.026051044464111
INFO:root:current mean train loss 1766.7182853165368
INFO:root:current train perplexity4.0266618728637695
INFO:root:current mean train loss 1767.3780355983613
INFO:root:current train perplexity4.027914524078369
INFO:root:current mean train loss 1767.5631698318937
INFO:root:current train perplexity4.028468608856201
INFO:root:current mean train loss 1767.2455743392513
INFO:root:current train perplexity4.027609825134277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.52s/it]
INFO:root:final mean train loss: 1767.0293635735293
INFO:root:final train perplexity: 4.029272079467773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it]
INFO:root:eval mean loss: 1879.5684061253326
INFO:root:eval perplexity: 4.572612285614014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.27s/it]
INFO:root:eval mean loss: 2330.293967389046
INFO:root:eval perplexity: 6.724640846252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/39
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [4:28:36<1:15:49, 413.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1761.1907840851813
INFO:root:current train perplexity3.999415397644043
INFO:root:current mean train loss 1766.5314172815395
INFO:root:current train perplexity3.996105670928955
INFO:root:current mean train loss 1757.190872308862
INFO:root:current train perplexity3.988466739654541
INFO:root:current mean train loss 1756.5476229335723
INFO:root:current train perplexity3.988908529281616
INFO:root:current mean train loss 1757.6950961026278
INFO:root:current train perplexity3.9881808757781982
INFO:root:current mean train loss 1756.7804858659085
INFO:root:current train perplexity3.993581771850586
INFO:root:current mean train loss 1760.279313470662
INFO:root:current train perplexity4.004240036010742
INFO:root:current mean train loss 1763.8050375310142
INFO:root:current train perplexity4.008987903594971
INFO:root:current mean train loss 1764.4039354789008
INFO:root:current train perplexity4.008646488189697
INFO:root:current mean train loss 1766.4919144279495
INFO:root:current train perplexity4.012719631195068
INFO:root:current mean train loss 1770.1230934272378
INFO:root:current train perplexity4.024281024932861
INFO:root:current mean train loss 1768.3624954617578
INFO:root:current train perplexity4.01968240737915
INFO:root:current mean train loss 1766.4536447177409
INFO:root:current train perplexity4.0152482986450195
INFO:root:current mean train loss 1767.154118698949
INFO:root:current train perplexity4.016610145568848
INFO:root:current mean train loss 1767.3789999318678
INFO:root:current train perplexity4.01860237121582
INFO:root:current mean train loss 1767.4994805368967
INFO:root:current train perplexity4.019195556640625
INFO:root:current mean train loss 1766.1534771970894
INFO:root:current train perplexity4.017477512359619
INFO:root:current mean train loss 1765.8582767828639
INFO:root:current train perplexity4.017366886138916
INFO:root:current mean train loss 1764.876196315286
INFO:root:current train perplexity4.017153263092041
INFO:root:current mean train loss 1763.8185152915153
INFO:root:current train perplexity4.016343116760254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.25s/it]
INFO:root:final mean train loss: 1762.971147515109
INFO:root:final train perplexity: 4.016396522521973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 1876.8523447023215
INFO:root:eval perplexity: 4.562579154968262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 2327.7830104963155
INFO:root:eval perplexity: 6.710846900939941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/40
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [4:35:40<1:09:29, 416.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.149250271954
INFO:root:current train perplexity4.010538578033447
INFO:root:current mean train loss 1751.2422863837728
INFO:root:current train perplexity4.0023932456970215
INFO:root:current mean train loss 1752.6112773717518
INFO:root:current train perplexity3.998467206954956
INFO:root:current mean train loss 1758.1900731391202
INFO:root:current train perplexity4.011865139007568
INFO:root:current mean train loss 1755.889926472387
INFO:root:current train perplexity4.006608963012695
INFO:root:current mean train loss 1756.069070924749
INFO:root:current train perplexity4.00515079498291
INFO:root:current mean train loss 1753.9196250589678
INFO:root:current train perplexity3.998619794845581
INFO:root:current mean train loss 1756.0061884477295
INFO:root:current train perplexity3.999051332473755
INFO:root:current mean train loss 1760.134106667511
INFO:root:current train perplexity4.005752086639404
INFO:root:current mean train loss 1759.5562196756896
INFO:root:current train perplexity4.006471157073975
INFO:root:current mean train loss 1759.389654207274
INFO:root:current train perplexity4.007190227508545
INFO:root:current mean train loss 1761.0660636455352
INFO:root:current train perplexity4.006282329559326
INFO:root:current mean train loss 1759.668877739567
INFO:root:current train perplexity4.001717567443848
INFO:root:current mean train loss 1759.8679108927438
INFO:root:current train perplexity4.002427577972412
INFO:root:current mean train loss 1759.120440479869
INFO:root:current train perplexity3.9999465942382812
INFO:root:current mean train loss 1760.0489410728953
INFO:root:current train perplexity4.002874851226807
INFO:root:current mean train loss 1758.994400397023
INFO:root:current train perplexity4.001429080963135
INFO:root:current mean train loss 1759.374053903615
INFO:root:current train perplexity4.002021789550781
INFO:root:current mean train loss 1759.0427832732878
INFO:root:current train perplexity4.002363681793213
INFO:root:current mean train loss 1758.6189129536895
INFO:root:current train perplexity4.001316547393799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.42s/it]
INFO:root:final mean train loss: 1758.2657833897701
INFO:root:final train perplexity: 4.001519680023193
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 1877.4174285239362
INFO:root:eval perplexity: 4.564663887023926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.21s/it]
INFO:root:eval mean loss: 2329.3147829745676
INFO:root:eval perplexity: 6.7192583084106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/41
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [4:42:26<1:02:01, 413.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.2555465698242
INFO:root:current train perplexity3.9705440998077393
INFO:root:current mean train loss 1761.4671325683594
INFO:root:current train perplexity3.9996767044067383
INFO:root:current mean train loss 1774.134577158335
INFO:root:current train perplexity4.0190110206604
INFO:root:current mean train loss 1769.35022774128
INFO:root:current train perplexity4.006356716156006
INFO:root:current mean train loss 1762.7478330058436
INFO:root:current train perplexity4.00410795211792
INFO:root:current mean train loss 1764.2295462589136
INFO:root:current train perplexity4.002663612365723
INFO:root:current mean train loss 1764.7849550795281
INFO:root:current train perplexity4.002663612365723
INFO:root:current mean train loss 1761.9060340766332
INFO:root:current train perplexity3.993274688720703
INFO:root:current mean train loss 1760.841311591012
INFO:root:current train perplexity3.994561195373535
INFO:root:current mean train loss 1759.1871818328
INFO:root:current train perplexity3.9919180870056152
INFO:root:current mean train loss 1759.8020678889143
INFO:root:current train perplexity3.99514102935791
INFO:root:current mean train loss 1759.3279379139776
INFO:root:current train perplexity3.9935789108276367
INFO:root:current mean train loss 1759.945974185143
INFO:root:current train perplexity3.994459629058838
INFO:root:current mean train loss 1760.2887965860887
INFO:root:current train perplexity3.9958536624908447
INFO:root:current mean train loss 1758.739725775897
INFO:root:current train perplexity3.9946448802948
INFO:root:current mean train loss 1757.9193022687334
INFO:root:current train perplexity3.9924845695495605
INFO:root:current mean train loss 1756.30180920295
INFO:root:current train perplexity3.990330457687378
INFO:root:current mean train loss 1754.8045334847839
INFO:root:current train perplexity3.9890763759613037
INFO:root:current mean train loss 1754.8129456596535
INFO:root:current train perplexity3.988166332244873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.81s/it]
INFO:root:final mean train loss: 1754.0034520413258
INFO:root:final train perplexity: 3.9880902767181396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it]
INFO:root:eval mean loss: 1871.7550425428026
INFO:root:eval perplexity: 4.543808460235596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it]
INFO:root:eval mean loss: 2324.8165768021386
INFO:root:eval perplexity: 6.694583415985107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/42
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [4:49:12<54:50, 411.33s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.0265549879807
INFO:root:current train perplexity3.955160617828369
INFO:root:current mean train loss 1753.1008019911505
INFO:root:current train perplexity3.9438676834106445
INFO:root:current mean train loss 1739.3198110374487
INFO:root:current train perplexity3.952202558517456
INFO:root:current mean train loss 1738.35889451877
INFO:root:current train perplexity3.948065996170044
INFO:root:current mean train loss 1743.7232275863537
INFO:root:current train perplexity3.955897569656372
INFO:root:current mean train loss 1744.8792160658809
INFO:root:current train perplexity3.963641881942749
INFO:root:current mean train loss 1748.0587186082153
INFO:root:current train perplexity3.971688747406006
INFO:root:current mean train loss 1749.2556023938794
INFO:root:current train perplexity3.973973512649536
INFO:root:current mean train loss 1747.042427916955
INFO:root:current train perplexity3.967557668685913
INFO:root:current mean train loss 1745.6865143457353
INFO:root:current train perplexity3.9659078121185303
INFO:root:current mean train loss 1745.8178331350646
INFO:root:current train perplexity3.9642770290374756
INFO:root:current mean train loss 1747.3426787863953
INFO:root:current train perplexity3.9670190811157227
INFO:root:current mean train loss 1748.750505288573
INFO:root:current train perplexity3.967465400695801
INFO:root:current mean train loss 1746.8849526817164
INFO:root:current train perplexity3.9637959003448486
INFO:root:current mean train loss 1746.5032177146918
INFO:root:current train perplexity3.9640257358551025
INFO:root:current mean train loss 1745.7059377807698
INFO:root:current train perplexity3.9609429836273193
INFO:root:current mean train loss 1747.4119234315667
INFO:root:current train perplexity3.9661381244659424
INFO:root:current mean train loss 1748.7669176056033
INFO:root:current train perplexity3.96948504447937
INFO:root:current mean train loss 1749.895708255589
INFO:root:current train perplexity3.97328519821167
INFO:root:current mean train loss 1751.5479026750563
INFO:root:current train perplexity3.977583885192871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.55s/it]
INFO:root:final mean train loss: 1750.1982790917625
INFO:root:final train perplexity: 3.9761409759521484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it]
INFO:root:eval mean loss: 1876.796315294631
INFO:root:eval perplexity: 4.562371730804443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it]
INFO:root:eval mean loss: 2329.6831872818316
INFO:root:eval perplexity: 6.721282958984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/43
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [4:56:14<48:21, 414.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.0454386393228
INFO:root:current train perplexity3.980032444000244
INFO:root:current mean train loss 1739.7297335111177
INFO:root:current train perplexity3.939661979675293
INFO:root:current mean train loss 1741.6256406037703
INFO:root:current train perplexity3.9359352588653564
INFO:root:current mean train loss 1745.83994103634
INFO:root:current train perplexity3.952024221420288
INFO:root:current mean train loss 1747.127519474473
INFO:root:current train perplexity3.9550511837005615
INFO:root:current mean train loss 1749.2053943562057
INFO:root:current train perplexity3.9611308574676514
INFO:root:current mean train loss 1747.025754704551
INFO:root:current train perplexity3.9559905529022217
INFO:root:current mean train loss 1747.7391188530073
INFO:root:current train perplexity3.962764263153076
INFO:root:current mean train loss 1748.0084299110504
INFO:root:current train perplexity3.963911294937134
INFO:root:current mean train loss 1746.0767483618952
INFO:root:current train perplexity3.96004319190979
INFO:root:current mean train loss 1744.2139059418614
INFO:root:current train perplexity3.9601328372955322
INFO:root:current mean train loss 1743.2485313753111
INFO:root:current train perplexity3.956528663635254
INFO:root:current mean train loss 1742.9480683117379
INFO:root:current train perplexity3.954355478286743
INFO:root:current mean train loss 1742.9694000014686
INFO:root:current train perplexity3.9577457904815674
INFO:root:current mean train loss 1744.4903033489948
INFO:root:current train perplexity3.960369348526001
INFO:root:current mean train loss 1746.8024721232894
INFO:root:current train perplexity3.9628846645355225
INFO:root:current mean train loss 1746.5630490168471
INFO:root:current train perplexity3.963325023651123
INFO:root:current mean train loss 1748.4913339956647
INFO:root:current train perplexity3.965888500213623
INFO:root:current mean train loss 1748.6554337298285
INFO:root:current train perplexity3.9658203125
INFO:root:current mean train loss 1747.1875510418354
INFO:root:current train perplexity3.963897705078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.93s/it]
INFO:root:final mean train loss: 1746.5040599305523
INFO:root:final train perplexity: 3.964573860168457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it]
INFO:root:eval mean loss: 1864.6665969740413
INFO:root:eval perplexity: 4.5178351402282715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.04s/it]
INFO:root:eval mean loss: 2317.8485609555073
INFO:root:eval perplexity: 6.65654182434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/44
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [5:03:05<41:20, 413.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1718.6429287524934
INFO:root:current train perplexity3.9091179370880127
INFO:root:current mean train loss 1744.4457908163265
INFO:root:current train perplexity3.9527487754821777
INFO:root:current mean train loss 1744.2041257788778
INFO:root:current train perplexity3.956665515899658
INFO:root:current mean train loss 1743.7802565516931
INFO:root:current train perplexity3.9621331691741943
INFO:root:current mean train loss 1743.8261273616645
INFO:root:current train perplexity3.9610936641693115
INFO:root:current mean train loss 1739.4139129806044
INFO:root:current train perplexity3.9556853771209717
INFO:root:current mean train loss 1742.0561319672527
INFO:root:current train perplexity3.955962657928467
INFO:root:current mean train loss 1742.7132462140228
INFO:root:current train perplexity3.9583752155303955
INFO:root:current mean train loss 1743.4805570960466
INFO:root:current train perplexity3.9599449634552
INFO:root:current mean train loss 1743.3843620324462
INFO:root:current train perplexity3.9619314670562744
INFO:root:current mean train loss 1744.0038551833363
INFO:root:current train perplexity3.962867259979248
INFO:root:current mean train loss 1745.2276207974608
INFO:root:current train perplexity3.963789463043213
INFO:root:current mean train loss 1743.5306150777492
INFO:root:current train perplexity3.9582157135009766
INFO:root:current mean train loss 1744.351695082678
INFO:root:current train perplexity3.9590542316436768
INFO:root:current mean train loss 1744.557267511311
INFO:root:current train perplexity3.9568839073181152
INFO:root:current mean train loss 1745.5739743726517
INFO:root:current train perplexity3.9597396850585938
INFO:root:current mean train loss 1745.1863474101824
INFO:root:current train perplexity3.95906138420105
INFO:root:current mean train loss 1745.2520819032404
INFO:root:current train perplexity3.95688533782959
INFO:root:current mean train loss 1744.4398405511895
INFO:root:current train perplexity3.9555883407592773
INFO:root:current mean train loss 1744.7676530474569
INFO:root:current train perplexity3.9569485187530518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.07s/it]
INFO:root:final mean train loss: 1744.0666301994688
INFO:root:final train perplexity: 3.9569597244262695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 1866.660485233821
INFO:root:eval perplexity: 4.525125503540039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it]
INFO:root:eval mean loss: 2320.6884484257257
INFO:root:eval perplexity: 6.672021389007568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/45
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [5:09:54<34:19, 411.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1768.7247695922852
INFO:root:current train perplexity3.9987356662750244
INFO:root:current mean train loss 1752.5570626607755
INFO:root:current train perplexity3.9507970809936523
INFO:root:current mean train loss 1741.6678781220407
INFO:root:current train perplexity3.9367432594299316
INFO:root:current mean train loss 1737.1179447383672
INFO:root:current train perplexity3.9252755641937256
INFO:root:current mean train loss 1733.0139373253132
INFO:root:current train perplexity3.9245095252990723
INFO:root:current mean train loss 1737.6635348272662
INFO:root:current train perplexity3.936483860015869
INFO:root:current mean train loss 1740.8116982701313
INFO:root:current train perplexity3.938727617263794
INFO:root:current mean train loss 1737.6383398565322
INFO:root:current train perplexity3.9383294582366943
INFO:root:current mean train loss 1740.708595417164
INFO:root:current train perplexity3.9422402381896973
INFO:root:current mean train loss 1741.814245453514
INFO:root:current train perplexity3.942434787750244
INFO:root:current mean train loss 1741.3070001817287
INFO:root:current train perplexity3.943875551223755
INFO:root:current mean train loss 1742.3271121519947
INFO:root:current train perplexity3.946241617202759
INFO:root:current mean train loss 1741.2938004505786
INFO:root:current train perplexity3.945091485977173
INFO:root:current mean train loss 1741.0059842196379
INFO:root:current train perplexity3.9475085735321045
INFO:root:current mean train loss 1740.626464176699
INFO:root:current train perplexity3.9482645988464355
INFO:root:current mean train loss 1740.2435498640054
INFO:root:current train perplexity3.9484856128692627
INFO:root:current mean train loss 1741.5892686843872
INFO:root:current train perplexity3.951230764389038
INFO:root:current mean train loss 1741.6211839879181
INFO:root:current train perplexity3.9492955207824707
INFO:root:current mean train loss 1742.308844701415
INFO:root:current train perplexity3.9501988887786865
INFO:root:current mean train loss 1742.4799954478465
INFO:root:current train perplexity3.9506492614746094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.07s/it]
INFO:root:final mean train loss: 1742.1774692429597
INFO:root:final train perplexity: 3.95106840133667
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 1865.8756653264904
INFO:root:eval perplexity: 4.52225399017334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it]
INFO:root:eval mean loss: 2319.5107214095747
INFO:root:eval perplexity: 6.665597915649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/46
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [5:16:53<27:36, 414.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.5450876494986
INFO:root:current train perplexity3.9360616207122803
INFO:root:current mean train loss 1736.233154296875
INFO:root:current train perplexity3.9328036308288574
INFO:root:current mean train loss 1725.2649764200123
INFO:root:current train perplexity3.9130380153656006
INFO:root:current mean train loss 1730.4066229392224
INFO:root:current train perplexity3.9184768199920654
INFO:root:current mean train loss 1729.2113212220634
INFO:root:current train perplexity3.9286885261535645
INFO:root:current mean train loss 1731.2383245313845
INFO:root:current train perplexity3.9256553649902344
INFO:root:current mean train loss 1731.3936672574798
INFO:root:current train perplexity3.9235403537750244
INFO:root:current mean train loss 1732.9971232982055
INFO:root:current train perplexity3.929135322570801
INFO:root:current mean train loss 1732.7646828000852
INFO:root:current train perplexity3.9332590103149414
INFO:root:current mean train loss 1733.8087560126785
INFO:root:current train perplexity3.9342236518859863
INFO:root:current mean train loss 1735.7204386581434
INFO:root:current train perplexity3.939690589904785
INFO:root:current mean train loss 1736.610850386656
INFO:root:current train perplexity3.9405689239501953
INFO:root:current mean train loss 1737.4074599350179
INFO:root:current train perplexity3.9403538703918457
INFO:root:current mean train loss 1737.7546289486786
INFO:root:current train perplexity3.938164710998535
INFO:root:current mean train loss 1738.3463257577755
INFO:root:current train perplexity3.9366180896759033
INFO:root:current mean train loss 1739.0958103708342
INFO:root:current train perplexity3.936997652053833
INFO:root:current mean train loss 1740.2464847961826
INFO:root:current train perplexity3.9392261505126953
INFO:root:current mean train loss 1740.0397212410294
INFO:root:current train perplexity3.9383363723754883
INFO:root:current mean train loss 1738.452771898155
INFO:root:current train perplexity3.937612533569336
INFO:root:current mean train loss 1738.8021836105108
INFO:root:current train perplexity3.9392590522766113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.94s/it]
INFO:root:final mean train loss: 1738.5466358456056
INFO:root:final train perplexity: 3.939770460128784
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.81s/it]
INFO:root:eval mean loss: 1862.9691763803469
INFO:root:eval perplexity: 4.511637210845947
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.31s/it]
INFO:root:eval mean loss: 2316.5373591429798
INFO:root:eval perplexity: 6.649407863616943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/47
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [5:23:43<20:39, 413.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.9747476383131
INFO:root:current train perplexity3.961552143096924
INFO:root:current mean train loss 1738.2703358043325
INFO:root:current train perplexity3.9330661296844482
INFO:root:current mean train loss 1730.2355420413433
INFO:root:current train perplexity3.912562847137451
INFO:root:current mean train loss 1728.3565468332874
INFO:root:current train perplexity3.9188201427459717
INFO:root:current mean train loss 1727.7942855406
INFO:root:current train perplexity3.9198927879333496
INFO:root:current mean train loss 1730.8948072350543
INFO:root:current train perplexity3.9265708923339844
INFO:root:current mean train loss 1733.160761879645
INFO:root:current train perplexity3.9305243492126465
INFO:root:current mean train loss 1734.2593593358397
INFO:root:current train perplexity3.933048963546753
INFO:root:current mean train loss 1737.0186018572088
INFO:root:current train perplexity3.9380011558532715
INFO:root:current mean train loss 1737.3561474756152
INFO:root:current train perplexity3.9340133666992188
INFO:root:current mean train loss 1737.700960753394
INFO:root:current train perplexity3.934037446975708
INFO:root:current mean train loss 1740.1553369181383
INFO:root:current train perplexity3.937269449234009
INFO:root:current mean train loss 1740.013942254159
INFO:root:current train perplexity3.9348857402801514
INFO:root:current mean train loss 1739.0245925401243
INFO:root:current train perplexity3.9347357749938965
INFO:root:current mean train loss 1739.1719900622704
INFO:root:current train perplexity3.937138080596924
INFO:root:current mean train loss 1739.13887232087
INFO:root:current train perplexity3.93730092048645
INFO:root:current mean train loss 1738.4822100851645
INFO:root:current train perplexity3.937833547592163
INFO:root:current mean train loss 1739.247517247354
INFO:root:current train perplexity3.9376237392425537
INFO:root:current mean train loss 1737.9373963881594
INFO:root:current train perplexity3.9357991218566895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.37s/it]
INFO:root:final mean train loss: 1736.6635233715094
INFO:root:final train perplexity: 3.9339234828948975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 1860.457590955369
INFO:root:eval perplexity: 4.502483367919922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.72s/it]
INFO:root:eval mean loss: 2313.9936839435118
INFO:root:eval perplexity: 6.63559103012085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/48
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [5:30:42<13:49, 414.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1718.7239013671874
INFO:root:current train perplexity3.888528347015381
INFO:root:current mean train loss 1745.4208315641984
INFO:root:current train perplexity3.9423000812530518
INFO:root:current mean train loss 1731.4114246457123
INFO:root:current train perplexity3.926877975463867
INFO:root:current mean train loss 1737.7516314794148
INFO:root:current train perplexity3.937998056411743
INFO:root:current mean train loss 1737.716888354198
INFO:root:current train perplexity3.9343338012695312
INFO:root:current mean train loss 1734.4296882110891
INFO:root:current train perplexity3.925964832305908
INFO:root:current mean train loss 1733.036041507876
INFO:root:current train perplexity3.922510862350464
INFO:root:current mean train loss 1734.7879215267155
INFO:root:current train perplexity3.9269585609436035
INFO:root:current mean train loss 1731.487416572805
INFO:root:current train perplexity3.9221911430358887
INFO:root:current mean train loss 1731.2423769424522
INFO:root:current train perplexity3.9222452640533447
INFO:root:current mean train loss 1731.1407470703125
INFO:root:current train perplexity3.9243106842041016
INFO:root:current mean train loss 1733.0558699945698
INFO:root:current train perplexity3.9276130199432373
INFO:root:current mean train loss 1732.964133833269
INFO:root:current train perplexity3.925034999847412
INFO:root:current mean train loss 1732.4494937098978
INFO:root:current train perplexity3.923938751220703
INFO:root:current mean train loss 1734.6344641156415
INFO:root:current train perplexity3.927987575531006
INFO:root:current mean train loss 1734.4889418800278
INFO:root:current train perplexity3.928636074066162
INFO:root:current mean train loss 1733.5766898612858
INFO:root:current train perplexity3.9254977703094482
INFO:root:current mean train loss 1733.82336831496
INFO:root:current train perplexity3.9260926246643066
INFO:root:current mean train loss 1733.192555795885
INFO:root:current train perplexity3.924870252609253
INFO:root:current mean train loss 1734.2251505002653
INFO:root:current train perplexity3.9252426624298096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.98s/it]
INFO:root:final mean train loss: 1734.276715761955
INFO:root:final train perplexity: 3.926525592803955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.83s/it]
INFO:root:eval mean loss: 1858.654325011774
INFO:root:eval perplexity: 4.495920658111572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it]
INFO:root:eval mean loss: 2312.593897609846
INFO:root:eval perplexity: 6.6279988288879395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/49
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [5:37:29<06:52, 412.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1728.4455871582031
INFO:root:current train perplexity3.9507081508636475
INFO:root:current mean train loss 1726.2978543368254
INFO:root:current train perplexity3.89431095123291
INFO:root:current mean train loss 1733.5968933105469
INFO:root:current train perplexity3.9045515060424805
INFO:root:current mean train loss 1733.2427739522543
INFO:root:current train perplexity3.9077463150024414
INFO:root:current mean train loss 1736.7536793461552
INFO:root:current train perplexity3.9171624183654785
INFO:root:current mean train loss 1736.980524278225
INFO:root:current train perplexity3.9111344814300537
INFO:root:current mean train loss 1739.1980971324292
INFO:root:current train perplexity3.9193787574768066
INFO:root:current mean train loss 1740.1982376849064
INFO:root:current train perplexity3.924828052520752
INFO:root:current mean train loss 1738.7890111483061
INFO:root:current train perplexity3.9225432872772217
INFO:root:current mean train loss 1738.5647051242288
INFO:root:current train perplexity3.9229612350463867
INFO:root:current mean train loss 1736.5580689186274
INFO:root:current train perplexity3.920947551727295
INFO:root:current mean train loss 1735.513736576579
INFO:root:current train perplexity3.9202394485473633
INFO:root:current mean train loss 1734.7865719485592
INFO:root:current train perplexity3.9183061122894287
INFO:root:current mean train loss 1733.8456957934497
INFO:root:current train perplexity3.9178998470306396
INFO:root:current mean train loss 1733.5922621401994
INFO:root:current train perplexity3.918227195739746
INFO:root:current mean train loss 1733.4403692101064
INFO:root:current train perplexity3.9184534549713135
INFO:root:current mean train loss 1732.3371542388318
INFO:root:current train perplexity3.920125961303711
INFO:root:current mean train loss 1732.5293505098198
INFO:root:current train perplexity3.919783353805542
INFO:root:current mean train loss 1732.640332617614
INFO:root:current train perplexity3.919361114501953
INFO:root:current mean train loss 1732.4657515057866
INFO:root:current train perplexity3.9188854694366455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.42s/it]
INFO:root:final mean train loss: 1731.7628467769498
INFO:root:final train perplexity: 3.918748140335083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.25s/it]
INFO:root:eval mean loss: 1858.5420783293162
INFO:root:eval perplexity: 4.495512962341309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.86s/it]
INFO:root:eval mean loss: 2312.7623654629324
INFO:root:eval perplexity: 6.628911018371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat/50
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [5:44:27<00:00, 414.15s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [5:44:27<00:00, 413.36s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it]
INFO:root:eval mean loss: 1858.5420783293162
INFO:root:eval perplexity: 4.495512962341309
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.58s/it]
INFO:root:eval mean loss: 2312.7623654629324
INFO:root:eval perplexity: 6.628911018371582
INFO:root:evalaution complete
INFO:root:save model final: alll6_alll12_not_concat/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x1467d239cf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1467d23948e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x1467d22b9e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1467d239da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x1467d22b7948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1467d239da3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x1467d2272b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x1467d1cd746a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x1468ce4f3a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x1468ce4f3be0]
python(+0x24a989) [0x55aaa90af989]
python(+0x24a9bd) [0x55aaa90af9bd]
python(+0x24aa14) [0x55aaa90afa14]
python(+0x108f75) [0x55aaa8f6df75]
python(Py_RunMain+0x313) [0x55aaa90b2983]
python(Py_BytesMain+0x39) [0x55aaa90b2bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x1468ce4d10b3]
python(+0x1d6e13) [0x55aaa903be13]
/opt/slurm/data/slurmd/job29849667/slurm_script: line 232: 3728687 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L12-v1 --data_config data_config.json --data_folder fast_processed_data_opt_allmini --output alll6_alll12_not_concat --epochs 50 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
