INFO:root:Output: small_val_1100
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24481.523772885103
INFO:root:current train perplexity15664.271484375
INFO:root:current mean train loss 20577.97547306847
INFO:root:current train perplexity3327.646728515625
INFO:root:current mean train loss 17778.857477398622
INFO:root:current train perplexity1107.01904296875
INFO:root:current mean train loss 15880.760353031015
INFO:root:current train perplexity519.3907470703125
INFO:root:current mean train loss 14503.653480789704
INFO:root:current train perplexity301.81683349609375
INFO:root:current mean train loss 13457.020988757304
INFO:root:current train perplexity200.4257049560547
INFO:root:current mean train loss 12644.30092864248
INFO:root:current train perplexity145.47042846679688
INFO:root:current mean train loss 11991.272135212961
INFO:root:current train perplexity112.72382354736328
INFO:root:current mean train loss 11457.213334368917
INFO:root:current train perplexity91.36853790283203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.90s/it]
INFO:root:final mean train loss: 11026.690938888058
INFO:root:final train perplexity: 77.5054702758789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 6416.098269198803
INFO:root:eval perplexity: 13.389649391174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/1
  0%|          | 1/200 [08:17<27:28:56, 497.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6826.449428013393
INFO:root:current train perplexity14.526715278625488
INFO:root:current mean train loss 6733.2013863536795
INFO:root:current train perplexity14.410506248474121
INFO:root:current mean train loss 6706.635074633907
INFO:root:current train perplexity14.183504104614258
INFO:root:current mean train loss 6635.121723585098
INFO:root:current train perplexity13.763970375061035
INFO:root:current mean train loss 6581.523856198172
INFO:root:current train perplexity13.463216781616211
INFO:root:current mean train loss 6531.694851184973
INFO:root:current train perplexity13.19353199005127
INFO:root:current mean train loss 6489.032647272704
INFO:root:current train perplexity12.922647476196289
INFO:root:current mean train loss 6441.599206732894
INFO:root:current train perplexity12.681798934936523
INFO:root:current mean train loss 6397.362095942728
INFO:root:current train perplexity12.455216407775879
INFO:root:current mean train loss 6352.944088297616
INFO:root:current train perplexity12.25117301940918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.76s/it]
INFO:root:final mean train loss: 6315.820232760521
INFO:root:final train perplexity: 12.082690238952637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 5548.918876052749
INFO:root:eval perplexity: 9.429279327392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/2
  1%|          | 2/200 [16:42<27:35:38, 501.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5991.715299479167
INFO:root:current train perplexity10.656923294067383
INFO:root:current mean train loss 5891.27683423913
INFO:root:current train perplexity10.279273986816406
INFO:root:current mean train loss 5868.191260901162
INFO:root:current train perplexity10.13473892211914
INFO:root:current mean train loss 5848.383052765377
INFO:root:current train perplexity10.02298641204834
INFO:root:current mean train loss 5823.188358904367
INFO:root:current train perplexity9.929624557495117
INFO:root:current mean train loss 5797.364947094964
INFO:root:current train perplexity9.841331481933594
INFO:root:current mean train loss 5771.735475419207
INFO:root:current train perplexity9.757710456848145
INFO:root:current mean train loss 5753.084336074082
INFO:root:current train perplexity9.68025016784668
INFO:root:current mean train loss 5739.763785108321
INFO:root:current train perplexity9.6085844039917
INFO:root:current mean train loss 5720.9451774889
INFO:root:current train perplexity9.524774551391602

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.22s/it]
INFO:root:final mean train loss: 5696.882194519043
INFO:root:final train perplexity: 9.464848518371582
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 5186.135091145833
INFO:root:eval perplexity: 8.142691612243652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/3
  2%|â–         | 3/200 [25:05<27:30:24, 502.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5566.533033288043
INFO:root:current train perplexity8.827128410339355
INFO:root:current mean train loss 5486.039999364837
INFO:root:current train perplexity8.71963119506836
INFO:root:current mean train loss 5486.509224793302
INFO:root:current train perplexity8.664405822753906
INFO:root:current mean train loss 5461.054944490132
INFO:root:current train perplexity8.588577270507812
INFO:root:current mean train loss 5447.292441221557
INFO:root:current train perplexity8.559581756591797
INFO:root:current mean train loss 5431.809974568296
INFO:root:current train perplexity8.508691787719727
INFO:root:current mean train loss 5422.131731697683
INFO:root:current train perplexity8.476497650146484
INFO:root:current mean train loss 5411.93782957296
INFO:root:current train perplexity8.440349578857422
INFO:root:current mean train loss 5401.48834117273
INFO:root:current train perplexity8.405207633972168
INFO:root:current mean train loss 5390.261874280539
INFO:root:current train perplexity8.368425369262695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.68s/it]
INFO:root:final mean train loss: 5378.9918040613975
INFO:root:final train perplexity: 8.34921932220459
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4963.137189716312
INFO:root:eval perplexity: 7.440568447113037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/4
  2%|â–         | 4/200 [33:21<27:13:12, 499.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5319.432191910282
INFO:root:current train perplexity7.965593338012695
INFO:root:current mean train loss 5241.461217050334
INFO:root:current train perplexity7.887362957000732
INFO:root:current mean train loss 5245.33609180533
INFO:root:current train perplexity7.914050579071045
INFO:root:current mean train loss 5235.3213480692975
INFO:root:current train perplexity7.869814872741699
INFO:root:current mean train loss 5228.177176986659
INFO:root:current train perplexity7.835824012756348
INFO:root:current mean train loss 5217.10979063677
INFO:root:current train perplexity7.804111957550049
INFO:root:current mean train loss 5209.066670123068
INFO:root:current train perplexity7.778395652770996
INFO:root:current mean train loss 5200.673799402573
INFO:root:current train perplexity7.760953426361084
INFO:root:current mean train loss 5187.137407984545
INFO:root:current train perplexity7.735509872436523
INFO:root:current mean train loss 5179.309870833613
INFO:root:current train perplexity7.7066216468811035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.93s/it]
INFO:root:final mean train loss: 5169.5142812421245
INFO:root:final train perplexity: 7.686940670013428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 4822.506953679078
INFO:root:eval perplexity: 7.029252052307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/5
  2%|â–Ž         | 5/200 [41:32<26:54:22, 496.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5077.560621995192
INFO:root:current train perplexity7.330924034118652
INFO:root:current mean train loss 5071.1708773606115
INFO:root:current train perplexity7.396709442138672
INFO:root:current mean train loss 5076.889601448091
INFO:root:current train perplexity7.401336669921875
INFO:root:current mean train loss 5061.012758688237
INFO:root:current train perplexity7.342776775360107
INFO:root:current mean train loss 5058.911288528616
INFO:root:current train perplexity7.333266258239746
INFO:root:current mean train loss 5046.402304796208
INFO:root:current train perplexity7.308847904205322
INFO:root:current mean train loss 5037.951242939407
INFO:root:current train perplexity7.286868095397949
INFO:root:current mean train loss 5038.075410050533
INFO:root:current train perplexity7.282495021820068
INFO:root:current mean train loss 5033.897200792424
INFO:root:current train perplexity7.2652907371521
INFO:root:current mean train loss 5025.853965426151
INFO:root:current train perplexity7.249700546264648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.71s/it]
INFO:root:final mean train loss: 5017.251288690874
INFO:root:final train perplexity: 7.238767623901367
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4703.240691489362
INFO:root:eval perplexity: 6.698291301727295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/6
  3%|â–Ž         | 6/200 [49:46<26:42:41, 495.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4889.96258934508
INFO:root:current train perplexity6.9280266761779785
INFO:root:current mean train loss 4943.147052375638
INFO:root:current train perplexity7.002971649169922
INFO:root:current mean train loss 4925.654617124241
INFO:root:current train perplexity6.987834453582764
INFO:root:current mean train loss 4925.377565235501
INFO:root:current train perplexity6.978721618652344
INFO:root:current mean train loss 4922.1837805421565
INFO:root:current train perplexity6.967249393463135
INFO:root:current mean train loss 4912.746133026737
INFO:root:current train perplexity6.943996906280518
INFO:root:current mean train loss 4911.439237285065
INFO:root:current train perplexity6.938390254974365
INFO:root:current mean train loss 4909.145744436078
INFO:root:current train perplexity6.928491592407227
INFO:root:current mean train loss 4905.470592440231
INFO:root:current train perplexity6.919564723968506
INFO:root:current mean train loss 4903.482244505676
INFO:root:current train perplexity6.909319877624512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.80s/it]
INFO:root:final mean train loss: 4898.525288858721
INFO:root:final train perplexity: 6.907514572143555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 4617.825590093085
INFO:root:eval perplexity: 6.470886707305908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/7
  4%|â–Ž         | 7/200 [58:24<26:58:08, 503.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4790.935875355113
INFO:root:current train perplexity6.7085041999816895
INFO:root:current mean train loss 4841.933653603831
INFO:root:current train perplexity6.766963005065918
INFO:root:current mean train loss 4834.134876685049
INFO:root:current train perplexity6.721049785614014
INFO:root:current mean train loss 4833.043324988997
INFO:root:current train perplexity6.712888717651367
INFO:root:current mean train loss 4826.997024167239
INFO:root:current train perplexity6.695312976837158
INFO:root:current mean train loss 4821.006168179899
INFO:root:current train perplexity6.677590370178223
INFO:root:current mean train loss 4819.293919966603
INFO:root:current train perplexity6.6747589111328125
INFO:root:current mean train loss 4820.352846259313
INFO:root:current train perplexity6.668175220489502
INFO:root:current mean train loss 4811.336353252924
INFO:root:current train perplexity6.651578426361084
INFO:root:current mean train loss 4803.9627566672125
INFO:root:current train perplexity6.643181324005127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it]
INFO:root:final mean train loss: 4799.700209402269
INFO:root:final train perplexity: 6.643379211425781
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 4546.2700749390515
INFO:root:eval perplexity: 6.286335468292236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/8
  4%|â–         | 8/200 [1:06:48<26:50:42, 503.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4743.5434492807535
INFO:root:current train perplexity6.440545082092285
INFO:root:current mean train loss 4737.0681332079175
INFO:root:current train perplexity6.474259376525879
INFO:root:current mean train loss 4730.056216395853
INFO:root:current train perplexity6.470369338989258
INFO:root:current mean train loss 4739.617715462508
INFO:root:current train perplexity6.467482089996338
INFO:root:current mean train loss 4743.07377423478
INFO:root:current train perplexity6.474827289581299
INFO:root:current mean train loss 4734.42407313291
INFO:root:current train perplexity6.460068702697754
INFO:root:current mean train loss 4731.594108293858
INFO:root:current train perplexity6.457265853881836
INFO:root:current mean train loss 4729.6304379684425
INFO:root:current train perplexity6.449856758117676
INFO:root:current mean train loss 4724.602538213807
INFO:root:current train perplexity6.441051006317139
INFO:root:current mean train loss 4721.184321608499
INFO:root:current train perplexity6.432056903839111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.35s/it]
INFO:root:final mean train loss: 4719.115041117514
INFO:root:final train perplexity: 6.43548583984375
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 4484.809426598515
INFO:root:eval perplexity: 6.132026672363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/9
  4%|â–         | 9/200 [1:14:59<26:29:59, 499.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4637.306523712588
INFO:root:current train perplexity6.202498912811279
INFO:root:current mean train loss 4654.008000959429
INFO:root:current train perplexity6.266612529754639
INFO:root:current mean train loss 4678.529204984433
INFO:root:current train perplexity6.30816125869751
INFO:root:current mean train loss 4673.192432825134
INFO:root:current train perplexity6.297323703765869
INFO:root:current mean train loss 4665.333615313163
INFO:root:current train perplexity6.290162086486816
INFO:root:current mean train loss 4665.555508428196
INFO:root:current train perplexity6.285210132598877
INFO:root:current mean train loss 4666.818208378935
INFO:root:current train perplexity6.289792060852051
INFO:root:current mean train loss 4656.7714140777
INFO:root:current train perplexity6.27516508102417
INFO:root:current mean train loss 4659.118449407111
INFO:root:current train perplexity6.272266387939453
INFO:root:current mean train loss 4654.768819696994
INFO:root:current train perplexity6.265002727508545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.92s/it]
INFO:root:final mean train loss: 4650.463306303947
INFO:root:final train perplexity: 6.263519763946533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 4442.379605773493
INFO:root:eval perplexity: 6.027714252471924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/10
  5%|â–Œ         | 10/200 [1:23:37<26:39:57, 505.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4641.001733707476
INFO:root:current train perplexity6.151967525482178
INFO:root:current mean train loss 4601.7002280464385
INFO:root:current train perplexity6.114978313446045
INFO:root:current mean train loss 4610.035425767249
INFO:root:current train perplexity6.124718189239502
INFO:root:current mean train loss 4603.887371938902
INFO:root:current train perplexity6.12651252746582
INFO:root:current mean train loss 4607.436584600078
INFO:root:current train perplexity6.12476921081543
INFO:root:current mean train loss 4600.975749962894
INFO:root:current train perplexity6.1244635581970215
INFO:root:current mean train loss 4600.909735206301
INFO:root:current train perplexity6.1228251457214355
INFO:root:current mean train loss 4598.135892307345
INFO:root:current train perplexity6.117546081542969
INFO:root:current mean train loss 4592.530477304643
INFO:root:current train perplexity6.113211154937744
INFO:root:current mean train loss 4591.983103174476
INFO:root:current train perplexity6.113717079162598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.01s/it]
INFO:root:final mean train loss: 4589.115277198053
INFO:root:final train perplexity: 6.11374044418335
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 4392.53963735594
INFO:root:eval perplexity: 5.907449722290039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/11
  6%|â–Œ         | 11/200 [1:32:13<26:41:34, 508.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4542.553090764188
INFO:root:current train perplexity5.984470844268799
INFO:root:current mean train loss 4560.245622441093
INFO:root:current train perplexity6.009224891662598
INFO:root:current mean train loss 4547.650430606217
INFO:root:current train perplexity5.9837446212768555
INFO:root:current mean train loss 4548.215481543726
INFO:root:current train perplexity5.997622489929199
INFO:root:current mean train loss 4544.497349545207
INFO:root:current train perplexity5.993929862976074
INFO:root:current mean train loss 4541.073401481979
INFO:root:current train perplexity5.987773895263672
INFO:root:current mean train loss 4539.772068251342
INFO:root:current train perplexity5.987332820892334
INFO:root:current mean train loss 4536.683429024877
INFO:root:current train perplexity5.9805707931518555
INFO:root:current mean train loss 4537.705034636591
INFO:root:current train perplexity5.982205867767334
INFO:root:current mean train loss 4537.132361074832
INFO:root:current train perplexity5.981606483459473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.97s/it]
INFO:root:final mean train loss: 4533.748471536944
INFO:root:final train perplexity: 5.9816412925720215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 4355.782934743462
INFO:root:eval perplexity: 5.8202924728393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/12
  6%|â–Œ         | 12/200 [1:40:20<26:13:07, 502.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4500.213250411184
INFO:root:current train perplexity5.888803482055664
INFO:root:current mean train loss 4484.6981244991985
INFO:root:current train perplexity5.882253170013428
INFO:root:current mean train loss 4488.841959083687
INFO:root:current train perplexity5.891043663024902
INFO:root:current mean train loss 4482.810056739518
INFO:root:current train perplexity5.877228736877441
INFO:root:current mean train loss 4487.94322965988
INFO:root:current train perplexity5.876494884490967
INFO:root:current mean train loss 4482.193960904674
INFO:root:current train perplexity5.87201452255249
INFO:root:current mean train loss 4480.176899730216
INFO:root:current train perplexity5.869155406951904
INFO:root:current mean train loss 4484.321027417453
INFO:root:current train perplexity5.863965034484863
INFO:root:current mean train loss 4485.789542870548
INFO:root:current train perplexity5.86589241027832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.41s/it]
INFO:root:final mean train loss: 4484.914076282132
INFO:root:final train perplexity: 5.86749792098999
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 4324.067715259309
INFO:root:eval perplexity: 5.7461256980896
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/13
  6%|â–‹         | 13/200 [1:48:40<26:02:38, 501.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4721.126139322917
INFO:root:current train perplexity6.072634220123291
INFO:root:current mean train loss 4460.785910004551
INFO:root:current train perplexity5.767371654510498
INFO:root:current mean train loss 4458.8724972579275
INFO:root:current train perplexity5.767467975616455
INFO:root:current mean train loss 4456.261717944255
INFO:root:current train perplexity5.771622180938721
INFO:root:current mean train loss 4457.5502469273415
INFO:root:current train perplexity5.7751665115356445
INFO:root:current mean train loss 4454.289491566227
INFO:root:current train perplexity5.778693199157715
INFO:root:current mean train loss 4448.984203737174
INFO:root:current train perplexity5.776353359222412
INFO:root:current mean train loss 4445.543965107686
INFO:root:current train perplexity5.769824028015137
INFO:root:current mean train loss 4443.935414315458
INFO:root:current train perplexity5.766885757446289
INFO:root:current mean train loss 4443.926442295214
INFO:root:current train perplexity5.765657424926758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.77s/it]
INFO:root:final mean train loss: 4440.732555635514
INFO:root:final train perplexity: 5.766109466552734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 4297.39506974457
INFO:root:eval perplexity: 5.684484004974365
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/14
  7%|â–‹         | 14/200 [1:56:38<25:32:25, 494.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4387.582075639205
INFO:root:current train perplexity5.587993621826172
INFO:root:current mean train loss 4390.770263671875
INFO:root:current train perplexity5.674012184143066
INFO:root:current mean train loss 4383.835892374482
INFO:root:current train perplexity5.67437744140625
INFO:root:current mean train loss 4389.426299361938
INFO:root:current train perplexity5.674782752990723
INFO:root:current mean train loss 4387.2092326737375
INFO:root:current train perplexity5.670267581939697
INFO:root:current mean train loss 4390.60821067377
INFO:root:current train perplexity5.674498558044434
INFO:root:current mean train loss 4398.503654117865
INFO:root:current train perplexity5.680593013763428
INFO:root:current mean train loss 4399.712975782349
INFO:root:current train perplexity5.6774067878723145
INFO:root:current mean train loss 4402.169158747399
INFO:root:current train perplexity5.681790351867676
INFO:root:current mean train loss 4404.750324538197
INFO:root:current train perplexity5.67881441116333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.37s/it]
INFO:root:final mean train loss: 4400.983053453507
INFO:root:final train perplexity: 5.676388263702393
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 4269.801044437057
INFO:root:eval perplexity: 5.6214094161987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/15
  8%|â–Š         | 15/200 [2:04:42<25:14:08, 491.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4428.015894839638
INFO:root:current train perplexity5.678527355194092
INFO:root:current mean train loss 4363.416142824317
INFO:root:current train perplexity5.573178768157959
INFO:root:current mean train loss 4362.826756028824
INFO:root:current train perplexity5.591097831726074
INFO:root:current mean train loss 4360.200495322296
INFO:root:current train perplexity5.589356422424316
INFO:root:current mean train loss 4365.627750223747
INFO:root:current train perplexity5.596071720123291
INFO:root:current mean train loss 4363.0745254546
INFO:root:current train perplexity5.591238021850586
INFO:root:current mean train loss 4361.399071713449
INFO:root:current train perplexity5.589676856994629
INFO:root:current mean train loss 4364.666113417073
INFO:root:current train perplexity5.593488693237305
INFO:root:current mean train loss 4364.196318574004
INFO:root:current train perplexity5.593845367431641
INFO:root:current mean train loss 4364.213276361875
INFO:root:current train perplexity5.591216087341309

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.25s/it]
INFO:root:final mean train loss: 4364.621490109352
INFO:root:final train perplexity: 5.595538139343262
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 4249.757758823693
INFO:root:eval perplexity: 5.576031684875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/16
  8%|â–Š         | 16/200 [2:12:42<24:55:53, 487.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4364.394847728588
INFO:root:current train perplexity5.601668834686279
INFO:root:current mean train loss 4312.869286724902
INFO:root:current train perplexity5.5296549797058105
INFO:root:current mean train loss 4324.057080508329
INFO:root:current train perplexity5.522829532623291
INFO:root:current mean train loss 4320.884396800937
INFO:root:current train perplexity5.512440204620361
INFO:root:current mean train loss 4327.145029822892
INFO:root:current train perplexity5.515069961547852
INFO:root:current mean train loss 4327.310369444527
INFO:root:current train perplexity5.510380744934082
INFO:root:current mean train loss 4327.680233019961
INFO:root:current train perplexity5.508512496948242
INFO:root:current mean train loss 4326.7064741257955
INFO:root:current train perplexity5.51365852355957
INFO:root:current mean train loss 4326.906552297461
INFO:root:current train perplexity5.510524272918701
INFO:root:current mean train loss 4329.775794365645
INFO:root:current train perplexity5.517075538635254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.43s/it]
INFO:root:final mean train loss: 4330.261067790369
INFO:root:final train perplexity: 5.5201945304870605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 4227.9416538536125
INFO:root:eval perplexity: 5.527057647705078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/17
  8%|â–Š         | 17/200 [2:21:16<25:11:30, 495.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4258.571372767857
INFO:root:current train perplexity5.414114475250244
INFO:root:current mean train loss 4296.204890046296
INFO:root:current train perplexity5.440706729888916
INFO:root:current mean train loss 4291.610437790891
INFO:root:current train perplexity5.445467948913574
INFO:root:current mean train loss 4295.8864024603545
INFO:root:current train perplexity5.447184085845947
INFO:root:current mean train loss 4295.675988348599
INFO:root:current train perplexity5.450812816619873
INFO:root:current mean train loss 4306.814672167056
INFO:root:current train perplexity5.453814506530762
INFO:root:current mean train loss 4302.2236758735235
INFO:root:current train perplexity5.447307109832764
INFO:root:current mean train loss 4300.905208665497
INFO:root:current train perplexity5.443936824798584
INFO:root:current mean train loss 4301.569163723335
INFO:root:current train perplexity5.450745582580566
INFO:root:current mean train loss 4300.583942596925
INFO:root:current train perplexity5.453139781951904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.14s/it]
INFO:root:final mean train loss: 4299.60776482859
INFO:root:final train perplexity: 5.45383882522583
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 4208.843583776596
INFO:root:eval perplexity: 5.484537601470947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/18
  9%|â–‰         | 18/200 [2:29:34<25:05:28, 496.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4266.36561478016
INFO:root:current train perplexity5.400694370269775
INFO:root:current mean train loss 4281.414724923514
INFO:root:current train perplexity5.404572010040283
INFO:root:current mean train loss 4273.217290179719
INFO:root:current train perplexity5.391806125640869
INFO:root:current mean train loss 4278.638534501412
INFO:root:current train perplexity5.4035773277282715
INFO:root:current mean train loss 4279.699400064369
INFO:root:current train perplexity5.400200843811035
INFO:root:current mean train loss 4280.225610216678
INFO:root:current train perplexity5.398326873779297
INFO:root:current mean train loss 4276.770256837456
INFO:root:current train perplexity5.393619537353516
INFO:root:current mean train loss 4274.185863633496
INFO:root:current train perplexity5.390727519989014
INFO:root:current mean train loss 4270.7632316688905
INFO:root:current train perplexity5.388521194458008
INFO:root:current mean train loss 4269.923007936771
INFO:root:current train perplexity5.3859477043151855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.81s/it]
INFO:root:final mean train loss: 4269.1668285246815
INFO:root:final train perplexity: 5.388731956481934
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 4191.724955673759
INFO:root:eval perplexity: 5.446703910827637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/19
 10%|â–‰         | 19/200 [2:37:44<24:51:58, 494.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4220.029124540441
INFO:root:current train perplexity5.265344142913818
INFO:root:current mean train loss 4213.08661980029
INFO:root:current train perplexity5.266192436218262
INFO:root:current mean train loss 4243.5327119257345
INFO:root:current train perplexity5.296893119812012
INFO:root:current mean train loss 4234.903197198852
INFO:root:current train perplexity5.30661678314209
INFO:root:current mean train loss 4239.862220239745
INFO:root:current train perplexity5.308852672576904
INFO:root:current mean train loss 4239.108295198361
INFO:root:current train perplexity5.315930366516113
INFO:root:current mean train loss 4247.228111349126
INFO:root:current train perplexity5.329957485198975
INFO:root:current mean train loss 4247.902622024801
INFO:root:current train perplexity5.330092430114746
INFO:root:current mean train loss 4248.076527327685
INFO:root:current train perplexity5.3337273597717285
INFO:root:current mean train loss 4250.127575670757
INFO:root:current train perplexity5.336338043212891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.71s/it]
INFO:root:final mean train loss: 4243.538161800754
INFO:root:final train perplexity: 5.3345184326171875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 4177.944798246343
INFO:root:eval perplexity: 5.41643762588501
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/20
 10%|â–ˆ         | 20/200 [2:45:45<24:30:58, 490.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4248.011011155985
INFO:root:current train perplexity5.281065940856934
INFO:root:current mean train loss 4237.674081478479
INFO:root:current train perplexity5.273369312286377
INFO:root:current mean train loss 4231.202937417049
INFO:root:current train perplexity5.276918888092041
INFO:root:current mean train loss 4228.763539943854
INFO:root:current train perplexity5.285310745239258
INFO:root:current mean train loss 4224.394247749013
INFO:root:current train perplexity5.279754161834717
INFO:root:current mean train loss 4221.624475032145
INFO:root:current train perplexity5.277541637420654
INFO:root:current mean train loss 4223.459570090217
INFO:root:current train perplexity5.278327941894531
INFO:root:current mean train loss 4226.981058676095
INFO:root:current train perplexity5.287262916564941
INFO:root:current mean train loss 4224.951383899338
INFO:root:current train perplexity5.286059379577637
INFO:root:current mean train loss 4222.326485515511
INFO:root:current train perplexity5.2823662757873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.68s/it]
INFO:root:final mean train loss: 4217.826809360135
INFO:root:final train perplexity: 5.280679225921631
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.07s/it]
INFO:root:eval mean loss: 4166.89977940769
INFO:root:eval perplexity: 5.392299652099609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/21
 10%|â–ˆ         | 21/200 [2:54:05<24:32:03, 493.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4167.36522708722
INFO:root:current train perplexity5.2121782302856445
INFO:root:current mean train loss 4183.729316757111
INFO:root:current train perplexity5.238067150115967
INFO:root:current mean train loss 4188.682491916842
INFO:root:current train perplexity5.227040767669678
INFO:root:current mean train loss 4185.585922864867
INFO:root:current train perplexity5.216640949249268
INFO:root:current mean train loss 4189.433730196902
INFO:root:current train perplexity5.220427513122559
INFO:root:current mean train loss 4189.740961199294
INFO:root:current train perplexity5.216945171356201
INFO:root:current mean train loss 4192.415114464252
INFO:root:current train perplexity5.219851493835449
INFO:root:current mean train loss 4193.033188801234
INFO:root:current train perplexity5.2193098068237305
INFO:root:current mean train loss 4194.733006742449
INFO:root:current train perplexity5.220692157745361
INFO:root:current mean train loss 4194.274724350844
INFO:root:current train perplexity5.22513484954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.77s/it]
INFO:root:final mean train loss: 4192.388840460008
INFO:root:final train perplexity: 5.22794771194458
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it]
INFO:root:eval mean loss: 4148.4688573526155
INFO:root:eval perplexity: 5.352261066436768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/22
 11%|â–ˆ         | 22/200 [3:03:12<25:11:32, 509.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4181.934560546875
INFO:root:current train perplexity5.1748809814453125
INFO:root:current mean train loss 4173.073794642857
INFO:root:current train perplexity5.183181285858154
INFO:root:current mean train loss 4166.636334339489
INFO:root:current train perplexity5.165706157684326
INFO:root:current mean train loss 4166.574778645833
INFO:root:current train perplexity5.172269821166992
INFO:root:current mean train loss 4167.29650390625
INFO:root:current train perplexity5.174952983856201
INFO:root:current mean train loss 4172.680309527853
INFO:root:current train perplexity5.181066513061523
INFO:root:current mean train loss 4170.6053403501155
INFO:root:current train perplexity5.183175086975098
INFO:root:current mean train loss 4174.975627205141
INFO:root:current train perplexity5.185924053192139
INFO:root:current mean train loss 4175.231901506696
INFO:root:current train perplexity5.185827255249023
INFO:root:current mean train loss 4177.074322415865
INFO:root:current train perplexity5.18698263168335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.49s/it]
INFO:root:final mean train loss: 4171.838258743286
INFO:root:final train perplexity: 5.185731887817383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it]
INFO:root:eval mean loss: 4136.928837336547
INFO:root:eval perplexity: 5.327342987060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/23
 12%|â–ˆâ–        | 23/200 [3:11:28<24:50:36, 505.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4160.215170251317
INFO:root:current train perplexity5.110527515411377
INFO:root:current mean train loss 4153.723936987705
INFO:root:current train perplexity5.124885082244873
INFO:root:current mean train loss 4151.8635564473825
INFO:root:current train perplexity5.123161315917969
INFO:root:current mean train loss 4157.401919213038
INFO:root:current train perplexity5.132357120513916
INFO:root:current mean train loss 4160.080842391304
INFO:root:current train perplexity5.13956880569458
INFO:root:current mean train loss 4153.9120846678015
INFO:root:current train perplexity5.134032249450684
INFO:root:current mean train loss 4147.897150310556
INFO:root:current train perplexity5.1262664794921875
INFO:root:current mean train loss 4152.653291314955
INFO:root:current train perplexity5.136236190795898
INFO:root:current mean train loss 4151.830361527198
INFO:root:current train perplexity5.139047145843506
INFO:root:current mean train loss 4152.779556662481
INFO:root:current train perplexity5.140588760375977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.17s/it]
INFO:root:final mean train loss: 4149.48701612411
INFO:root:final train perplexity: 5.14020299911499
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 4128.469601894947
INFO:root:eval perplexity: 5.309150218963623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/24
 12%|â–ˆâ–        | 24/200 [3:19:41<24:31:21, 501.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4101.899371136676
INFO:root:current train perplexity5.064821720123291
INFO:root:current mean train loss 4114.799410994764
INFO:root:current train perplexity5.083324432373047
INFO:root:current mean train loss 4111.7734878382735
INFO:root:current train perplexity5.071567058563232
INFO:root:current mean train loss 4120.808455757473
INFO:root:current train perplexity5.087575912475586
INFO:root:current mean train loss 4121.718541660037
INFO:root:current train perplexity5.091951370239258
INFO:root:current mean train loss 4127.809089467005
INFO:root:current train perplexity5.096162796020508
INFO:root:current mean train loss 4130.653274734873
INFO:root:current train perplexity5.100072860717773
INFO:root:current mean train loss 4134.1579099093315
INFO:root:current train perplexity5.100029468536377
INFO:root:current mean train loss 4132.926690680678
INFO:root:current train perplexity5.102575778961182
INFO:root:current mean train loss 4132.195743379872
INFO:root:current train perplexity5.098660469055176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it]
INFO:root:final mean train loss: 4128.863594055176
INFO:root:final train perplexity: 5.098549842834473
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 4119.970945534131
INFO:root:eval perplexity: 5.290936470031738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/25
 12%|â–ˆâ–Ž        | 25/200 [3:27:45<24:07:34, 496.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4084.818859986585
INFO:root:current train perplexity5.071423053741455
INFO:root:current mean train loss 4096.055660381988
INFO:root:current train perplexity5.044458389282227
INFO:root:current mean train loss 4107.619948167067
INFO:root:current train perplexity5.051135540008545
INFO:root:current mean train loss 4113.557352242912
INFO:root:current train perplexity5.060202598571777
INFO:root:current mean train loss 4113.082235760584
INFO:root:current train perplexity5.057254314422607
INFO:root:current mean train loss 4112.047321708055
INFO:root:current train perplexity5.053096294403076
INFO:root:current mean train loss 4111.931754836709
INFO:root:current train perplexity5.05363655090332
INFO:root:current mean train loss 4114.936605938086
INFO:root:current train perplexity5.0563530921936035
INFO:root:current mean train loss 4115.0681271834155
INFO:root:current train perplexity5.061230659484863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.95s/it]
INFO:root:final mean train loss: 4109.330052837248
INFO:root:final train perplexity: 5.059409141540527
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.15s/it]
INFO:root:eval mean loss: 4110.775068567154
INFO:root:eval perplexity: 5.271299362182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/26
 13%|â–ˆâ–Ž        | 26/200 [3:36:03<24:00:44, 496.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4143.514439174107
INFO:root:current train perplexity5.107727527618408
INFO:root:current mean train loss 4080.496312792056
INFO:root:current train perplexity5.021429538726807
INFO:root:current mean train loss 4089.8553177838166
INFO:root:current train perplexity5.029523849487305
INFO:root:current mean train loss 4092.2570928020664
INFO:root:current train perplexity5.026614665985107
INFO:root:current mean train loss 4100.345757111871
INFO:root:current train perplexity5.039879322052002
INFO:root:current mean train loss 4091.4221263637205
INFO:root:current train perplexity5.027805328369141
INFO:root:current mean train loss 4094.272649975546
INFO:root:current train perplexity5.021633625030518
INFO:root:current mean train loss 4095.827774846402
INFO:root:current train perplexity5.025842666625977
INFO:root:current mean train loss 4093.0870541332674
INFO:root:current train perplexity5.021573543548584
INFO:root:current mean train loss 4091.362825000431
INFO:root:current train perplexity5.019320011138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.24s/it]
INFO:root:final mean train loss: 4089.3655962790212
INFO:root:final train perplexity: 5.01971435546875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 4101.874544617132
INFO:root:eval perplexity: 5.252360820770264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/27
 14%|â–ˆâ–Ž        | 27/200 [3:44:39<24:09:44, 502.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4106.381966145834
INFO:root:current train perplexity4.961143493652344
INFO:root:current mean train loss 4050.0550908627715
INFO:root:current train perplexity4.959622383117676
INFO:root:current mean train loss 4050.2960517351016
INFO:root:current train perplexity4.9612531661987305
INFO:root:current mean train loss 4063.1235886346726
INFO:root:current train perplexity4.974221229553223
INFO:root:current mean train loss 4074.2018354668676
INFO:root:current train perplexity4.989045143127441
INFO:root:current mean train loss 4069.1837103686285
INFO:root:current train perplexity4.979269027709961
INFO:root:current mean train loss 4072.203000746316
INFO:root:current train perplexity4.980779647827148
INFO:root:current mean train loss 4073.3701004561844
INFO:root:current train perplexity4.980135440826416
INFO:root:current mean train loss 4076.5297710769746
INFO:root:current train perplexity4.983345031738281
INFO:root:current mean train loss 4073.5802491568475
INFO:root:current train perplexity4.982289791107178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.24s/it]
INFO:root:final mean train loss: 4072.3836941872873
INFO:root:final train perplexity: 4.986195087432861
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.36s/it]
INFO:root:eval mean loss: 4092.882928510084
INFO:root:eval perplexity: 5.233298301696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/28
 14%|â–ˆâ–        | 28/200 [3:53:44<24:37:26, 515.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4089.085215692935
INFO:root:current train perplexity4.96785831451416
INFO:root:current mean train loss 4057.6960250730435
INFO:root:current train perplexity4.936060905456543
INFO:root:current mean train loss 4065.2178183243414
INFO:root:current train perplexity4.958447456359863
INFO:root:current mean train loss 4054.5524086022156
INFO:root:current train perplexity4.947093486785889
INFO:root:current mean train loss 4066.5049561124038
INFO:root:current train perplexity4.956686973571777
INFO:root:current mean train loss 4067.2452138167723
INFO:root:current train perplexity4.955846309661865
INFO:root:current mean train loss 4059.5471638148324
INFO:root:current train perplexity4.95046854019165
INFO:root:current mean train loss 4056.222227737617
INFO:root:current train perplexity4.948620319366455
INFO:root:current mean train loss 4059.6830268572485
INFO:root:current train perplexity4.951171875
INFO:root:current mean train loss 4057.4805465152695
INFO:root:current train perplexity4.950082778930664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.22s/it]
INFO:root:final mean train loss: 4053.241279971215
INFO:root:final train perplexity: 4.948680400848389
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 4086.3879844719636
INFO:root:eval perplexity: 5.2195725440979
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/29
 14%|â–ˆâ–        | 29/200 [4:02:23<24:31:49, 516.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4063.615462764617
INFO:root:current train perplexity4.913485527038574
INFO:root:current mean train loss 4042.9383106959685
INFO:root:current train perplexity4.905514717102051
INFO:root:current mean train loss 4059.8851101697783
INFO:root:current train perplexity4.922806262969971
INFO:root:current mean train loss 4061.9713322849793
INFO:root:current train perplexity4.922764778137207
INFO:root:current mean train loss 4059.100515131054
INFO:root:current train perplexity4.918567180633545
INFO:root:current mean train loss 4054.6620840873647
INFO:root:current train perplexity4.919300079345703
INFO:root:current mean train loss 4049.1383085658927
INFO:root:current train perplexity4.9154157638549805
INFO:root:current mean train loss 4049.339915556066
INFO:root:current train perplexity4.919244289398193
INFO:root:current mean train loss 4046.3159543988795
INFO:root:current train perplexity4.9161858558654785
INFO:root:current mean train loss 4040.908551110617
INFO:root:current train perplexity4.917665481567383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.77s/it]
INFO:root:final mean train loss: 4038.3699264526367
INFO:root:final train perplexity: 4.919731140136719
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 4076.916997381981
INFO:root:eval perplexity: 5.199620246887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/30
 15%|â–ˆâ–Œ        | 30/200 [4:10:47<24:12:57, 512.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4024.71432416867
INFO:root:current train perplexity4.912725448608398
INFO:root:current mean train loss 4019.916349342401
INFO:root:current train perplexity4.898112773895264
INFO:root:current mean train loss 4024.115226202929
INFO:root:current train perplexity4.8829240798950195
INFO:root:current mean train loss 4019.302625627996
INFO:root:current train perplexity4.877978324890137
INFO:root:current mean train loss 4026.1706214852647
INFO:root:current train perplexity4.881934642791748
INFO:root:current mean train loss 4023.60504841141
INFO:root:current train perplexity4.882880687713623
INFO:root:current mean train loss 4022.5535416819494
INFO:root:current train perplexity4.88361120223999
INFO:root:current mean train loss 4026.7495622647793
INFO:root:current train perplexity4.886641025543213
INFO:root:current mean train loss 4026.3400753780543
INFO:root:current train perplexity4.889413356781006
INFO:root:current mean train loss 4025.112047286841
INFO:root:current train perplexity4.8884501457214355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.11s/it]
INFO:root:final mean train loss: 4021.529821703511
INFO:root:final train perplexity: 4.887152671813965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it]
INFO:root:eval mean loss: 4070.934663813165
INFO:root:eval perplexity: 5.187056064605713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/31
 16%|â–ˆâ–Œ        | 31/200 [4:19:08<23:53:50, 509.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3991.4408971908247
INFO:root:current train perplexity4.820714950561523
INFO:root:current mean train loss 3992.9082446455145
INFO:root:current train perplexity4.822436809539795
INFO:root:current mean train loss 3985.2795677030617
INFO:root:current train perplexity4.8095927238464355
INFO:root:current mean train loss 3997.533889110906
INFO:root:current train perplexity4.825706958770752
INFO:root:current mean train loss 4002.8650770763425
INFO:root:current train perplexity4.835792064666748
INFO:root:current mean train loss 4004.774646152308
INFO:root:current train perplexity4.8458757400512695
INFO:root:current mean train loss 4008.783312176995
INFO:root:current train perplexity4.85160493850708
INFO:root:current mean train loss 4004.8138475124456
INFO:root:current train perplexity4.852850914001465
INFO:root:current mean train loss 4006.993545406121
INFO:root:current train perplexity4.856141567230225
INFO:root:current mean train loss 4006.96509304671
INFO:root:current train perplexity4.8551344871521

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.06s/it]
INFO:root:final mean train loss: 4005.814474413472
INFO:root:final train perplexity: 4.856945514678955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 4064.057878643063
INFO:root:eval perplexity: 5.1726531982421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/32
 16%|â–ˆâ–Œ        | 32/200 [4:27:06<23:19:42, 499.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3983.7802867542614
INFO:root:current train perplexity4.75374174118042
INFO:root:current mean train loss 4004.873851751512
INFO:root:current train perplexity4.814768314361572
INFO:root:current mean train loss 3982.657053270527
INFO:root:current train perplexity4.800784587860107
INFO:root:current mean train loss 3977.0591556172976
INFO:root:current train perplexity4.808934688568115
INFO:root:current mean train loss 3987.0603880494505
INFO:root:current train perplexity4.821187973022461
INFO:root:current mean train loss 3988.520084195524
INFO:root:current train perplexity4.822381019592285
INFO:root:current mean train loss 3992.706533277672
INFO:root:current train perplexity4.824331283569336
INFO:root:current mean train loss 3994.5203125
INFO:root:current train perplexity4.825006008148193
INFO:root:current mean train loss 3995.3375017132676
INFO:root:current train perplexity4.825872421264648
INFO:root:current mean train loss 3994.2791478341787
INFO:root:current train perplexity4.828754425048828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.27s/it]
INFO:root:final mean train loss: 3990.5304834919593
INFO:root:final train perplexity: 4.8277459144592285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.51s/it]
INFO:root:eval mean loss: 4057.1981711962544
INFO:root:eval perplexity: 5.158324241638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/33
 16%|â–ˆâ–‹        | 33/200 [4:35:46<23:27:40, 505.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3926.4110165550596
INFO:root:current train perplexity4.750205993652344
INFO:root:current mean train loss 3955.811944317964
INFO:root:current train perplexity4.791925430297852
INFO:root:current mean train loss 3955.307995002079
INFO:root:current train perplexity4.791996479034424
INFO:root:current mean train loss 3964.931197405518
INFO:root:current train perplexity4.792843818664551
INFO:root:current mean train loss 3974.6241663362243
INFO:root:current train perplexity4.795792102813721
INFO:root:current mean train loss 3971.7220391769815
INFO:root:current train perplexity4.790609359741211
INFO:root:current mean train loss 3974.396126449378
INFO:root:current train perplexity4.796934127807617
INFO:root:current mean train loss 3972.5520048328963
INFO:root:current train perplexity4.793079376220703
INFO:root:current mean train loss 3974.1041034862037
INFO:root:current train perplexity4.793814659118652
INFO:root:current mean train loss 3981.2235189816165
INFO:root:current train perplexity4.804131507873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.72s/it]
INFO:root:final mean train loss: 3977.8709698953935
INFO:root:final train perplexity: 4.803693771362305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 4052.414071157469
INFO:root:eval perplexity: 5.148355007171631
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/34
 17%|â–ˆâ–‹        | 34/200 [4:44:27<23:32:22, 510.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3996.809412136884
INFO:root:current train perplexity4.782835960388184
INFO:root:current mean train loss 3960.57885028326
INFO:root:current train perplexity4.758930683135986
INFO:root:current mean train loss 3956.0396733020066
INFO:root:current train perplexity4.760864734649658
INFO:root:current mean train loss 3957.755285545822
INFO:root:current train perplexity4.755278587341309
INFO:root:current mean train loss 3957.032703440154
INFO:root:current train perplexity4.754845142364502
INFO:root:current mean train loss 3961.5340492796354
INFO:root:current train perplexity4.765379905700684
INFO:root:current mean train loss 3964.8745350048903
INFO:root:current train perplexity4.77109956741333
INFO:root:current mean train loss 3963.4208712052123
INFO:root:current train perplexity4.769964694976807
INFO:root:current mean train loss 3966.691250403631
INFO:root:current train perplexity4.7732744216918945
INFO:root:current mean train loss 3965.460755965982
INFO:root:current train perplexity4.774862766265869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.12s/it]
INFO:root:final mean train loss: 3962.7815622514295
INFO:root:final train perplexity: 4.775182247161865
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it]
INFO:root:eval mean loss: 4054.6300542303857
INFO:root:eval perplexity: 5.152970314025879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/35
 18%|â–ˆâ–Š        | 35/200 [4:52:25<22:56:52, 500.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3976.1020260581486
INFO:root:current train perplexity4.771464824676514
INFO:root:current mean train loss 3953.5485266999826
INFO:root:current train perplexity4.736317157745361
INFO:root:current mean train loss 3956.390358107919
INFO:root:current train perplexity4.746814250946045
INFO:root:current mean train loss 3953.218764815922
INFO:root:current train perplexity4.74177360534668
INFO:root:current mean train loss 3951.721211793776
INFO:root:current train perplexity4.744991302490234
INFO:root:current mean train loss 3954.1638655851953
INFO:root:current train perplexity4.74262809753418
INFO:root:current mean train loss 3954.276196037371
INFO:root:current train perplexity4.745488166809082
INFO:root:current mean train loss 3952.663204717085
INFO:root:current train perplexity4.74655818939209
INFO:root:current mean train loss 3950.7435365227707
INFO:root:current train perplexity4.744964122772217
INFO:root:current mean train loss 3951.0167439570832
INFO:root:current train perplexity4.747818470001221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.85s/it]
INFO:root:final mean train loss: 3947.9952389501755
INFO:root:final train perplexity: 4.747406005859375
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 4047.1958665780144
INFO:root:eval perplexity: 5.137503147125244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/36
 18%|â–ˆâ–Š        | 36/200 [5:00:59<22:59:45, 504.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3904.8212385506467
INFO:root:current train perplexity4.699968338012695
INFO:root:current mean train loss 3912.792423023897
INFO:root:current train perplexity4.693273067474365
INFO:root:current mean train loss 3924.2713788926394
INFO:root:current train perplexity4.702075958251953
INFO:root:current mean train loss 3930.523438130854
INFO:root:current train perplexity4.712950706481934
INFO:root:current mean train loss 3926.2068041541
INFO:root:current train perplexity4.714965343475342
INFO:root:current mean train loss 3927.3970059292483
INFO:root:current train perplexity4.7176032066345215
INFO:root:current mean train loss 3932.3686054346344
INFO:root:current train perplexity4.719955921173096
INFO:root:current mean train loss 3935.7993058588786
INFO:root:current train perplexity4.723210334777832
INFO:root:current mean train loss 3937.1355456639303
INFO:root:current train perplexity4.721661567687988
INFO:root:current mean train loss 3939.052612675722
INFO:root:current train perplexity4.725627899169922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.58s/it]
INFO:root:final mean train loss: 3936.118358489006
INFO:root:final train perplexity: 4.725212574005127
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it]
INFO:root:eval mean loss: 4039.561379723515
INFO:root:eval perplexity: 5.12166690826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/37
 18%|â–ˆâ–Š        | 37/200 [5:09:32<22:57:31, 507.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.7886590254934
INFO:root:current train perplexity4.657179832458496
INFO:root:current mean train loss 3901.994854266827
INFO:root:current train perplexity4.667263507843018
INFO:root:current mean train loss 3910.7808088916845
INFO:root:current train perplexity4.68277645111084
INFO:root:current mean train loss 3903.535735388647
INFO:root:current train perplexity4.683117866516113
INFO:root:current mean train loss 3909.6022954150885
INFO:root:current train perplexity4.687457084655762
INFO:root:current mean train loss 3913.4692694655987
INFO:root:current train perplexity4.690053462982178
INFO:root:current mean train loss 3914.466059183903
INFO:root:current train perplexity4.6906280517578125
INFO:root:current mean train loss 3920.594511903007
INFO:root:current train perplexity4.696604251861572
INFO:root:current mean train loss 3926.215896964473
INFO:root:current train perplexity4.700839042663574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.96s/it]
INFO:root:final mean train loss: 3922.7754579974758
INFO:root:final train perplexity: 4.700403690338135
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it]
INFO:root:eval mean loss: 4037.504479374446
INFO:root:eval perplexity: 5.117408752441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/38
 19%|â–ˆâ–‰        | 38/200 [5:17:37<22:31:30, 500.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.2548828125
INFO:root:current train perplexity4.510341167449951
INFO:root:current mean train loss 3912.333977264108
INFO:root:current train perplexity4.660397052764893
INFO:root:current mean train loss 3906.155132725908
INFO:root:current train perplexity4.659451961517334
INFO:root:current mean train loss 3907.606163301877
INFO:root:current train perplexity4.657588005065918
INFO:root:current mean train loss 3903.5267082574055
INFO:root:current train perplexity4.654918193817139
INFO:root:current mean train loss 3906.5267816926566
INFO:root:current train perplexity4.655927658081055
INFO:root:current mean train loss 3911.690640628239
INFO:root:current train perplexity4.664709091186523
INFO:root:current mean train loss 3909.608036567612
INFO:root:current train perplexity4.669142723083496
INFO:root:current mean train loss 3911.318863770139
INFO:root:current train perplexity4.669709205627441
INFO:root:current mean train loss 3913.659861821273
INFO:root:current train perplexity4.67339563369751

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.84s/it]
INFO:root:final mean train loss: 3910.253886745822
INFO:root:final train perplexity: 4.67724084854126
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it]
INFO:root:eval mean loss: 4031.8491661125886
INFO:root:eval perplexity: 5.105719566345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/39
 20%|â–ˆâ–‰        | 39/200 [5:25:48<22:15:24, 497.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.8575550426135
INFO:root:current train perplexity4.578501224517822
INFO:root:current mean train loss 3876.4298986486488
INFO:root:current train perplexity4.613513946533203
INFO:root:current mean train loss 3887.8409973433795
INFO:root:current train perplexity4.623722553253174
INFO:root:current mean train loss 3888.373101826266
INFO:root:current train perplexity4.638761520385742
INFO:root:current mean train loss 3892.2768780413626
INFO:root:current train perplexity4.6478071212768555
INFO:root:current mean train loss 3896.8867622270977
INFO:root:current train perplexity4.650064468383789
INFO:root:current mean train loss 3895.1217322716348
INFO:root:current train perplexity4.645769119262695
INFO:root:current mean train loss 3897.8396579833643
INFO:root:current train perplexity4.651627063751221
INFO:root:current mean train loss 3899.1171053170274
INFO:root:current train perplexity4.6519455909729
INFO:root:current mean train loss 3900.294460660932
INFO:root:current train perplexity4.653701305389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.87s/it]
INFO:root:final mean train loss: 3897.9522753069477
INFO:root:final train perplexity: 4.654595375061035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 4028.0365414450353
INFO:root:eval perplexity: 5.097854137420654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/40
 20%|â–ˆâ–ˆ        | 40/200 [5:34:07<22:07:55, 497.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3892.1001490542762
INFO:root:current train perplexity4.638493537902832
INFO:root:current mean train loss 3883.87763630843
INFO:root:current train perplexity4.632104396820068
INFO:root:current mean train loss 3880.779889947203
INFO:root:current train perplexity4.627243518829346
INFO:root:current mean train loss 3889.5235239824156
INFO:root:current train perplexity4.628756046295166
INFO:root:current mean train loss 3889.683888000634
INFO:root:current train perplexity4.6304931640625
INFO:root:current mean train loss 3892.7368041756986
INFO:root:current train perplexity4.633174896240234
INFO:root:current mean train loss 3891.1716809496165
INFO:root:current train perplexity4.6313276290893555
INFO:root:current mean train loss 3896.2082777593664
INFO:root:current train perplexity4.639227390289307
INFO:root:current mean train loss 3892.443374875992
INFO:root:current train perplexity4.6348700523376465
INFO:root:current mean train loss 3889.419380461949
INFO:root:current train perplexity4.6342973709106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.70s/it]
INFO:root:final mean train loss: 3885.900631812311
INFO:root:final train perplexity: 4.632515907287598
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it]
INFO:root:eval mean loss: 4023.9230766566934
INFO:root:eval perplexity: 5.089382648468018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/41
 20%|â–ˆâ–ˆ        | 41/200 [5:42:41<22:12:24, 502.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3832.212664568866
INFO:root:current train perplexity4.589369297027588
INFO:root:current mean train loss 3854.398141455463
INFO:root:current train perplexity4.578841686248779
INFO:root:current mean train loss 3861.368030699339
INFO:root:current train perplexity4.593767166137695
INFO:root:current mean train loss 3863.8868800172017
INFO:root:current train perplexity4.590418338775635
INFO:root:current mean train loss 3865.8385607252635
INFO:root:current train perplexity4.598076820373535
INFO:root:current mean train loss 3865.724030757086
INFO:root:current train perplexity4.592815399169922
INFO:root:current mean train loss 3868.962190521581
INFO:root:current train perplexity4.593911647796631
INFO:root:current mean train loss 3874.0717132022655
INFO:root:current train perplexity4.602386474609375
INFO:root:current mean train loss 3878.5386524500263
INFO:root:current train perplexity4.609043598175049
INFO:root:current mean train loss 3878.47682586637
INFO:root:current train perplexity4.610334396362305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.84s/it]
INFO:root:final mean train loss: 3874.6299158527004
INFO:root:final train perplexity: 4.611963272094727
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 4021.9144642065603
INFO:root:eval perplexity: 5.085249423980713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/42
 21%|â–ˆâ–ˆ        | 42/200 [5:51:07<22:06:53, 503.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3808.8560965401784
INFO:root:current train perplexity4.56296968460083
INFO:root:current mean train loss 3832.122674334491
INFO:root:current train perplexity4.573716640472412
INFO:root:current mean train loss 3846.846600731383
INFO:root:current train perplexity4.571532249450684
INFO:root:current mean train loss 3858.7199284340018
INFO:root:current train perplexity4.584508895874023
INFO:root:current mean train loss 3861.058986619971
INFO:root:current train perplexity4.58344030380249
INFO:root:current mean train loss 3863.6278219918227
INFO:root:current train perplexity4.585991382598877
INFO:root:current mean train loss 3863.875858913632
INFO:root:current train perplexity4.589413166046143
INFO:root:current mean train loss 3867.747515412415
INFO:root:current train perplexity4.590515613555908
INFO:root:current mean train loss 3864.9889414530317
INFO:root:current train perplexity4.588293552398682
INFO:root:current mean train loss 3865.0352883731616
INFO:root:current train perplexity4.588914394378662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.09s/it]
INFO:root:final mean train loss: 3863.7986450195312
INFO:root:final train perplexity: 4.592297554016113
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it]
INFO:root:eval mean loss: 4017.190185546875
INFO:root:eval perplexity: 5.075544357299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:59:41<22:06:11, 506.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3897.192740506904
INFO:root:current train perplexity4.583765506744385
INFO:root:current mean train loss 3872.345822634397
INFO:root:current train perplexity4.583420753479004
INFO:root:current mean train loss 3863.8700920701517
INFO:root:current train perplexity4.566168785095215
INFO:root:current mean train loss 3859.8099454206904
INFO:root:current train perplexity4.565005779266357
INFO:root:current mean train loss 3858.5171196035553
INFO:root:current train perplexity4.560829162597656
INFO:root:current mean train loss 3859.6426455671617
INFO:root:current train perplexity4.5667314529418945
INFO:root:current mean train loss 3857.6565947584563
INFO:root:current train perplexity4.565610885620117
INFO:root:current mean train loss 3854.7097844859313
INFO:root:current train perplexity4.56649112701416
INFO:root:current mean train loss 3855.846678818672
INFO:root:current train perplexity4.570967197418213
INFO:root:current mean train loss 3854.8399206426466
INFO:root:current train perplexity4.570593357086182

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.24s/it]
INFO:root:final mean train loss: 3852.0098368737004
INFO:root:final train perplexity: 4.570988178253174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it]
INFO:root:eval mean loss: 4016.061369334552
INFO:root:eval perplexity: 5.073227405548096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/44
 22%|â–ˆâ–ˆâ–       | 44/200 [6:08:16<22:04:14, 509.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3796.390189376532
INFO:root:current train perplexity4.5088725090026855
INFO:root:current mean train loss 3830.364946580091
INFO:root:current train perplexity4.5219807624816895
INFO:root:current mean train loss 3834.0514436395047
INFO:root:current train perplexity4.533982753753662
INFO:root:current mean train loss 3833.3082828358706
INFO:root:current train perplexity4.533683776855469
INFO:root:current mean train loss 3839.775134575076
INFO:root:current train perplexity4.534097671508789
INFO:root:current mean train loss 3843.5719262207917
INFO:root:current train perplexity4.544065475463867
INFO:root:current mean train loss 3839.0221804195467
INFO:root:current train perplexity4.542052745819092
INFO:root:current mean train loss 3842.0030987329396
INFO:root:current train perplexity4.546426296234131
INFO:root:current mean train loss 3840.2422422953696
INFO:root:current train perplexity4.546848297119141
INFO:root:current mean train loss 3842.89049638333
INFO:root:current train perplexity4.548640727996826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.93s/it]
INFO:root:final mean train loss: 3840.810028568391
INFO:root:final train perplexity: 4.5508341789245605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 4013.959850121897
INFO:root:eval perplexity: 5.068918228149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [6:16:57<22:04:50, 512.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3829.582821603549
INFO:root:current train perplexity4.505364894866943
INFO:root:current mean train loss 3837.3281572449882
INFO:root:current train perplexity4.534885406494141
INFO:root:current mean train loss 3832.461657667712
INFO:root:current train perplexity4.533907890319824
INFO:root:current mean train loss 3829.9252576057625
INFO:root:current train perplexity4.5306715965271
INFO:root:current mean train loss 3829.662809351171
INFO:root:current train perplexity4.531693935394287
INFO:root:current mean train loss 3830.566275663154
INFO:root:current train perplexity4.531376838684082
INFO:root:current mean train loss 3835.5842603761616
INFO:root:current train perplexity4.534022808074951
INFO:root:current mean train loss 3838.6163148339715
INFO:root:current train perplexity4.532747745513916
INFO:root:current mean train loss 3835.950752089548
INFO:root:current train perplexity4.5341315269470215
INFO:root:current mean train loss 3834.8148991462463
INFO:root:current train perplexity4.533657550811768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.91s/it]
INFO:root:final mean train loss: 3831.19154923962
INFO:root:final train perplexity: 4.53359842300415
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.13s/it]
INFO:root:eval mean loss: 4010.662705008865
INFO:root:eval perplexity: 5.062166213989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [6:25:32<21:58:20, 513.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3840.3507936392257
INFO:root:current train perplexity4.51875114440918
INFO:root:current mean train loss 3828.9846980843004
INFO:root:current train perplexity4.497438430786133
INFO:root:current mean train loss 3820.888050093633
INFO:root:current train perplexity4.499874114990234
INFO:root:current mean train loss 3826.287879715174
INFO:root:current train perplexity4.508138179779053
INFO:root:current mean train loss 3831.026758753513
INFO:root:current train perplexity4.5116777420043945
INFO:root:current mean train loss 3828.841620335924
INFO:root:current train perplexity4.5115966796875
INFO:root:current mean train loss 3830.3512586968236
INFO:root:current train perplexity4.518674850463867
INFO:root:current mean train loss 3826.39801988266
INFO:root:current train perplexity4.515514373779297
INFO:root:current mean train loss 3825.720516429228
INFO:root:current train perplexity4.515682220458984
INFO:root:current mean train loss 3824.68535474365
INFO:root:current train perplexity4.515462398529053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.31s/it]
INFO:root:final mean train loss: 3820.798185225456
INFO:root:final train perplexity: 4.515046119689941
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it]
INFO:root:eval mean loss: 4011.760413203679
INFO:root:eval perplexity: 5.064413070678711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [6:34:37<22:13:15, 522.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3807.6695930989586
INFO:root:current train perplexity4.438552379608154
INFO:root:current mean train loss 3800.522373046875
INFO:root:current train perplexity4.475849151611328
INFO:root:current mean train loss 3801.595827414773
INFO:root:current train perplexity4.476037502288818
INFO:root:current mean train loss 3809.4059108072915
INFO:root:current train perplexity4.48733377456665
INFO:root:current mean train loss 3809.5678931949014
INFO:root:current train perplexity4.489983081817627
INFO:root:current mean train loss 3811.429555027174
INFO:root:current train perplexity4.4914445877075195
INFO:root:current mean train loss 3810.6118608940974
INFO:root:current train perplexity4.492833137512207
INFO:root:current mean train loss 3810.1026256930445
INFO:root:current train perplexity4.495504856109619
INFO:root:current mean train loss 3811.289314174107
INFO:root:current train perplexity4.497065544128418
INFO:root:current mean train loss 3812.140754707532
INFO:root:current train perplexity4.4954729080200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.06s/it]
INFO:root:final mean train loss: 3809.661801430487
INFO:root:final train perplexity: 4.49525260925293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 4007.3583949745125
INFO:root:eval perplexity: 5.055405616760254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/48
 24%|â–ˆâ–ˆâ–       | 48/200 [6:42:52<21:43:36, 514.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3802.616578619164
INFO:root:current train perplexity4.450991630554199
INFO:root:current mean train loss 3808.1552614305842
INFO:root:current train perplexity4.455589294433594
INFO:root:current mean train loss 3797.2122841555324
INFO:root:current train perplexity4.454042911529541
INFO:root:current mean train loss 3793.471126387076
INFO:root:current train perplexity4.461912155151367
INFO:root:current mean train loss 3795.210621583042
INFO:root:current train perplexity4.468393802642822
INFO:root:current mean train loss 3798.481103180612
INFO:root:current train perplexity4.461739540100098
INFO:root:current mean train loss 3800.143445306781
INFO:root:current train perplexity4.466241836547852
INFO:root:current mean train loss 3799.4291443416746
INFO:root:current train perplexity4.470121383666992
INFO:root:current mean train loss 3800.1540662823827
INFO:root:current train perplexity4.4721598625183105
INFO:root:current mean train loss 3802.8345446814596
INFO:root:current train perplexity4.479013442993164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.34s/it]
INFO:root:final mean train loss: 3800.5396110780775
INFO:root:final train perplexity: 4.4791035652160645
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 4003.314733626995
INFO:root:eval perplexity: 5.047145843505859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/49
 24%|â–ˆâ–ˆâ–       | 49/200 [6:51:26<21:34:23, 514.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3792.062714629121
INFO:root:current train perplexity4.410865783691406
INFO:root:current mean train loss 3790.331762823135
INFO:root:current train perplexity4.433163642883301
INFO:root:current mean train loss 3781.2046829695555
INFO:root:current train perplexity4.440229892730713
INFO:root:current mean train loss 3785.403857296995
INFO:root:current train perplexity4.446442127227783
INFO:root:current mean train loss 3785.5483607274696
INFO:root:current train perplexity4.448511600494385
INFO:root:current mean train loss 3788.4095601503013
INFO:root:current train perplexity4.452012062072754
INFO:root:current mean train loss 3786.51123117538
INFO:root:current train perplexity4.450286388397217
INFO:root:current mean train loss 3789.3410805028248
INFO:root:current train perplexity4.453437328338623
INFO:root:current mean train loss 3789.3687866073933
INFO:root:current train perplexity4.455959796905518
INFO:root:current mean train loss 3793.577617010122
INFO:root:current train perplexity4.461634635925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.33s/it]
INFO:root:final mean train loss: 3790.6750419985865
INFO:root:final train perplexity: 4.461705684661865
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.42s/it]
INFO:root:eval mean loss: 4002.6709590397827
INFO:root:eval perplexity: 5.045832633972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [6:59:34<21:06:21, 506.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3768.966488616635
INFO:root:current train perplexity4.39718770980835
INFO:root:current mean train loss 3772.768409920697
INFO:root:current train perplexity4.411096572875977
INFO:root:current mean train loss 3775.750588713681
INFO:root:current train perplexity4.420036792755127
INFO:root:current mean train loss 3778.6584913210763
INFO:root:current train perplexity4.424182891845703
INFO:root:current mean train loss 3783.5238186333604
INFO:root:current train perplexity4.4372758865356445
INFO:root:current mean train loss 3782.21011541045
INFO:root:current train perplexity4.441807270050049
INFO:root:current mean train loss 3777.9546055609576
INFO:root:current train perplexity4.441893577575684
INFO:root:current mean train loss 3777.8038126882234
INFO:root:current train perplexity4.441629409790039
INFO:root:current mean train loss 3779.0651437252327
INFO:root:current train perplexity4.442174911499023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.42s/it]
INFO:root:final mean train loss: 3781.0378601320326
INFO:root:final train perplexity: 4.444772720336914
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it]
INFO:root:eval mean loss: 4004.053918716755
INFO:root:eval perplexity: 5.048655033111572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [7:08:26<21:16:41, 514.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.89306640625
INFO:root:current train perplexity4.3920698165893555
INFO:root:current mean train loss 3770.849148474007
INFO:root:current train perplexity4.408781051635742
INFO:root:current mean train loss 3771.1298120471015
INFO:root:current train perplexity4.419343948364258
INFO:root:current mean train loss 3779.968790557563
INFO:root:current train perplexity4.419073581695557
INFO:root:current mean train loss 3781.6202539542383
INFO:root:current train perplexity4.426367282867432
INFO:root:current mean train loss 3778.325954700598
INFO:root:current train perplexity4.424621105194092
INFO:root:current mean train loss 3774.594281317571
INFO:root:current train perplexity4.424295425415039
INFO:root:current mean train loss 3770.904187754155
INFO:root:current train perplexity4.425093173980713
INFO:root:current mean train loss 3774.3391461189203
INFO:root:current train perplexity4.4291768074035645
INFO:root:current mean train loss 3774.8432797533937
INFO:root:current train perplexity4.428359508514404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.35s/it]
INFO:root:final mean train loss: 3772.2451053127165
INFO:root:final train perplexity: 4.429381847381592
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 4003.280650903147
INFO:root:eval perplexity: 5.047077178955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [7:17:23<21:25:10, 521.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3780.128108723958
INFO:root:current train perplexity4.484764575958252
INFO:root:current mean train loss 3743.7615934952446
INFO:root:current train perplexity4.385593891143799
INFO:root:current mean train loss 3747.2319733375725
INFO:root:current train perplexity4.3904805183410645
INFO:root:current mean train loss 3748.614855375744
INFO:root:current train perplexity4.3981032371521
INFO:root:current mean train loss 3754.302807323042
INFO:root:current train perplexity4.397663116455078
INFO:root:current mean train loss 3756.7216142672937
INFO:root:current train perplexity4.400393962860107
INFO:root:current mean train loss 3754.92740726626
INFO:root:current train perplexity4.405717372894287
INFO:root:current mean train loss 3759.1172885708042
INFO:root:current train perplexity4.409605979919434
INFO:root:current mean train loss 3764.877125371453
INFO:root:current train perplexity4.411835670471191
INFO:root:current mean train loss 3765.3491739241804
INFO:root:current train perplexity4.411979675292969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.05s/it]
INFO:root:final mean train loss: 3763.4423909341135
INFO:root:final train perplexity: 4.4140238761901855
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it]
INFO:root:eval mean loss: 3998.596466713763
INFO:root:eval perplexity: 5.037524700164795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [7:26:02<21:15:13, 520.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.441013502038
INFO:root:current train perplexity4.465733528137207
INFO:root:current mean train loss 3757.7484815644057
INFO:root:current train perplexity4.4068074226379395
INFO:root:current mean train loss 3745.149537775014
INFO:root:current train perplexity4.390192985534668
INFO:root:current mean train loss 3755.2841796875
INFO:root:current train perplexity4.396434307098389
INFO:root:current mean train loss 3749.347608922503
INFO:root:current train perplexity4.392915725708008
INFO:root:current mean train loss 3755.28579997834
INFO:root:current train perplexity4.398867130279541
INFO:root:current mean train loss 3758.4513729089335
INFO:root:current train perplexity4.399936199188232
INFO:root:current mean train loss 3753.480322535767
INFO:root:current train perplexity4.393041610717773
INFO:root:current mean train loss 3756.017989871279
INFO:root:current train perplexity4.396346092224121
INFO:root:current mean train loss 3758.1719673131943
INFO:root:current train perplexity4.397836208343506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.77s/it]
INFO:root:final mean train loss: 3753.0003169890374
INFO:root:final train perplexity: 4.395877838134766
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 3999.75990241301
INFO:root:eval perplexity: 5.039895534515381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [7:34:44<21:07:33, 520.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3731.6619754914313
INFO:root:current train perplexity4.3958740234375
INFO:root:current mean train loss 3734.533676496899
INFO:root:current train perplexity4.363726615905762
INFO:root:current mean train loss 3746.239459677692
INFO:root:current train perplexity4.378735542297363
INFO:root:current mean train loss 3737.658687718325
INFO:root:current train perplexity4.3705973625183105
INFO:root:current mean train loss 3740.7624290802637
INFO:root:current train perplexity4.376899719238281
INFO:root:current mean train loss 3742.8664605954273
INFO:root:current train perplexity4.381770133972168
INFO:root:current mean train loss 3741.409221473851
INFO:root:current train perplexity4.383541584014893
INFO:root:current mean train loss 3743.171567736833
INFO:root:current train perplexity4.383780479431152
INFO:root:current mean train loss 3744.3053441237025
INFO:root:current train perplexity4.38330078125
INFO:root:current mean train loss 3746.393346997516
INFO:root:current train perplexity4.382444858551025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.76s/it]
INFO:root:final mean train loss: 3744.6459494559995
INFO:root:final train perplexity: 4.381412506103516
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it]
INFO:root:eval mean loss: 4000.418786015071
INFO:root:eval perplexity: 5.041239261627197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [7:43:21<20:55:49, 519.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3694.126458583734
INFO:root:current train perplexity4.315267562866211
INFO:root:current mean train loss 3736.078688806767
INFO:root:current train perplexity4.349570274353027
INFO:root:current mean train loss 3738.43367649222
INFO:root:current train perplexity4.354432106018066
INFO:root:current mean train loss 3733.635431790422
INFO:root:current train perplexity4.348344802856445
INFO:root:current mean train loss 3729.8169095467324
INFO:root:current train perplexity4.347987174987793
INFO:root:current mean train loss 3726.989277742347
INFO:root:current train perplexity4.3525495529174805
INFO:root:current mean train loss 3729.000725926741
INFO:root:current train perplexity4.356161117553711
INFO:root:current mean train loss 3732.5300828162003
INFO:root:current train perplexity4.362775802612305
INFO:root:current mean train loss 3735.0161025146194
INFO:root:current train perplexity4.3645195960998535
INFO:root:current mean train loss 3739.023932541267
INFO:root:current train perplexity4.367533206939697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.48s/it]
INFO:root:final mean train loss: 3736.6389587156236
INFO:root:final train perplexity: 4.367592811584473
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.33s/it]
INFO:root:eval mean loss: 3995.4618430712544
INFO:root:eval perplexity: 5.031144618988037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [7:51:54<20:42:21, 517.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3732.431328956117
INFO:root:current train perplexity4.352250576019287
INFO:root:current mean train loss 3713.227215202487
INFO:root:current train perplexity4.326709747314453
INFO:root:current mean train loss 3720.7136408384995
INFO:root:current train perplexity4.331892490386963
INFO:root:current mean train loss 3723.312392352981
INFO:root:current train perplexity4.335143566131592
INFO:root:current mean train loss 3721.759893976335
INFO:root:current train perplexity4.340768337249756
INFO:root:current mean train loss 3725.397309632798
INFO:root:current train perplexity4.344188213348389
INFO:root:current mean train loss 3730.293618533858
INFO:root:current train perplexity4.348089694976807
INFO:root:current mean train loss 3729.956878948084
INFO:root:current train perplexity4.3490095138549805
INFO:root:current mean train loss 3731.7720435636807
INFO:root:current train perplexity4.351461410522461
INFO:root:current mean train loss 3731.2045986090943
INFO:root:current train perplexity4.350821018218994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.06s/it]
INFO:root:final mean train loss: 3726.851151927825
INFO:root:final train perplexity: 4.350759983062744
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 3997.094473764406
INFO:root:eval perplexity: 5.034466743469238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:00:28<20:31:26, 516.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.8000932173295
INFO:root:current train perplexity4.270360946655273
INFO:root:current mean train loss 3697.606525642641
INFO:root:current train perplexity4.305496692657471
INFO:root:current mean train loss 3705.677393535539
INFO:root:current train perplexity4.30789852142334
INFO:root:current mean train loss 3702.614083131602
INFO:root:current train perplexity4.305967330932617
INFO:root:current mean train loss 3713.9404806619164
INFO:root:current train perplexity4.318936824798584
INFO:root:current mean train loss 3714.4220601949605
INFO:root:current train perplexity4.323799133300781
INFO:root:current mean train loss 3715.388668520396
INFO:root:current train perplexity4.32859468460083
INFO:root:current mean train loss 3716.6902133562708
INFO:root:current train perplexity4.334591865539551
INFO:root:current mean train loss 3718.290346879569
INFO:root:current train perplexity4.3342061042785645
INFO:root:current mean train loss 3720.7326371277813
INFO:root:current train perplexity4.335779190063477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.36s/it]
INFO:root:final mean train loss: 3718.7381698239233
INFO:root:final train perplexity: 4.336856842041016
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it]
INFO:root:eval mean loss: 3994.802240899269
INFO:root:eval perplexity: 5.0298027992248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:09:08<20:24:35, 517.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3707.4173254588295
INFO:root:current train perplexity4.32208776473999
INFO:root:current mean train loss 3687.7218714052915
INFO:root:current train perplexity4.279287815093994
INFO:root:current mean train loss 3695.825217591492
INFO:root:current train perplexity4.285973072052002
INFO:root:current mean train loss 3688.941429117166
INFO:root:current train perplexity4.288469314575195
INFO:root:current mean train loss 3696.6338038269437
INFO:root:current train perplexity4.299363136291504
INFO:root:current mean train loss 3700.490921698074
INFO:root:current train perplexity4.30348539352417
INFO:root:current mean train loss 3703.2418012201874
INFO:root:current train perplexity4.30751371383667
INFO:root:current mean train loss 3705.101430670462
INFO:root:current train perplexity4.313892841339111
INFO:root:current mean train loss 3707.0986101806925
INFO:root:current train perplexity4.318130016326904
INFO:root:current mean train loss 3712.174010153005
INFO:root:current train perplexity4.322547435760498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.00s/it]
INFO:root:final mean train loss: 3711.0070822315834
INFO:root:final train perplexity: 4.323648452758789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 3993.043138436392
INFO:root:eval perplexity: 5.026226997375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [8:17:44<20:14:58, 517.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.1584919674297
INFO:root:current train perplexity4.288450717926025
INFO:root:current mean train loss 3682.7212670755666
INFO:root:current train perplexity4.266891956329346
INFO:root:current mean train loss 3699.3053712739274
INFO:root:current train perplexity4.2866973876953125
INFO:root:current mean train loss 3703.3874235333137
INFO:root:current train perplexity4.298115253448486
INFO:root:current mean train loss 3701.24063816597
INFO:root:current train perplexity4.304461479187012
INFO:root:current mean train loss 3702.2779697077494
INFO:root:current train perplexity4.307313442230225
INFO:root:current mean train loss 3702.6834645846916
INFO:root:current train perplexity4.308231353759766
INFO:root:current mean train loss 3704.948391965082
INFO:root:current train perplexity4.307873725891113
INFO:root:current mean train loss 3705.167188677257
INFO:root:current train perplexity4.308966159820557
INFO:root:current mean train loss 3704.971311339389
INFO:root:current train perplexity4.309597969055176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.20s/it]
INFO:root:final mean train loss: 3703.3313839204848
INFO:root:final train perplexity: 4.310575485229492
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 3994.5027634640956
INFO:root:eval perplexity: 5.02919340133667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [8:26:14<20:01:53, 515.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.6989591574365
INFO:root:current train perplexity4.294355392456055
INFO:root:current mean train loss 3703.9898606625347
INFO:root:current train perplexity4.303308010101318
INFO:root:current mean train loss 3698.4056295852934
INFO:root:current train perplexity4.301758289337158
INFO:root:current mean train loss 3688.68078903158
INFO:root:current train perplexity4.2949113845825195
INFO:root:current mean train loss 3689.3760851260763
INFO:root:current train perplexity4.291255950927734
INFO:root:current mean train loss 3692.0205175106594
INFO:root:current train perplexity4.294546127319336
INFO:root:current mean train loss 3690.7032530030374
INFO:root:current train perplexity4.291482925415039
INFO:root:current mean train loss 3693.5967812299423
INFO:root:current train perplexity4.294482231140137
INFO:root:current mean train loss 3695.056662567104
INFO:root:current train perplexity4.293940544128418
INFO:root:current mean train loss 3699.4183500482795
INFO:root:current train perplexity4.298209190368652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.98s/it]
INFO:root:final mean train loss: 3696.224361296623
INFO:root:final train perplexity: 4.298505783081055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 3994.340323373781
INFO:root:eval perplexity: 5.028863430023193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [8:34:46<19:50:45, 514.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3675.0852275278376
INFO:root:current train perplexity4.242020606994629
INFO:root:current mean train loss 3685.66084950493
INFO:root:current train perplexity4.2734198570251465
INFO:root:current mean train loss 3690.745108680858
INFO:root:current train perplexity4.280144691467285
INFO:root:current mean train loss 3692.1510309421433
INFO:root:current train perplexity4.281832218170166
INFO:root:current mean train loss 3693.0824864444303
INFO:root:current train perplexity4.285012722015381
INFO:root:current mean train loss 3693.291696473728
INFO:root:current train perplexity4.283488750457764
INFO:root:current mean train loss 3691.8991798722936
INFO:root:current train perplexity4.282722473144531
INFO:root:current mean train loss 3690.1395311755477
INFO:root:current train perplexity4.284181594848633
INFO:root:current mean train loss 3689.3136433598156
INFO:root:current train perplexity4.283369064331055
INFO:root:current mean train loss 3690.908339418297
INFO:root:current train perplexity4.2846174240112305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it]
INFO:root:final mean train loss: 3687.991709432294
INFO:root:final train perplexity: 4.284566879272461
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it]
INFO:root:eval mean loss: 3995.773321489916
INFO:root:eval perplexity: 5.031777381896973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [8:43:20<19:42:17, 514.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3654.147607421875
INFO:root:current train perplexity4.234013080596924
INFO:root:current mean train loss 3670.3182792467946
INFO:root:current train perplexity4.256408214569092
INFO:root:current mean train loss 3675.105263506356
INFO:root:current train perplexity4.259562015533447
INFO:root:current mean train loss 3676.78779049644
INFO:root:current train perplexity4.260849475860596
INFO:root:current mean train loss 3680.302934619634
INFO:root:current train perplexity4.260254859924316
INFO:root:current mean train loss 3682.2015518316703
INFO:root:current train perplexity4.267453193664551
INFO:root:current mean train loss 3681.778799460432
INFO:root:current train perplexity4.2667460441589355
INFO:root:current mean train loss 3683.5423422759436
INFO:root:current train perplexity4.272727966308594
INFO:root:current mean train loss 3682.970056356931
INFO:root:current train perplexity4.271295070648193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.66s/it]
INFO:root:final mean train loss: 3679.811062658987
INFO:root:final train perplexity: 4.2707600593566895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 3994.3335255291445
INFO:root:eval perplexity: 5.028848648071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [8:52:00<19:37:54, 515.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3698.932861328125
INFO:root:current train perplexity4.327214241027832
INFO:root:current mean train loss 3677.5059494462985
INFO:root:current train perplexity4.250398635864258
INFO:root:current mean train loss 3666.630359067118
INFO:root:current train perplexity4.243798732757568
INFO:root:current mean train loss 3667.435029586943
INFO:root:current train perplexity4.254003047943115
INFO:root:current mean train loss 3674.6290595194246
INFO:root:current train perplexity4.257672309875488
INFO:root:current mean train loss 3677.8122063517335
INFO:root:current train perplexity4.253385066986084
INFO:root:current mean train loss 3677.794825514355
INFO:root:current train perplexity4.252598285675049
INFO:root:current mean train loss 3674.3111758062546
INFO:root:current train perplexity4.249995231628418
INFO:root:current mean train loss 3675.2338079735173
INFO:root:current train perplexity4.252410888671875
INFO:root:current mean train loss 3675.5460820161097
INFO:root:current train perplexity4.253956317901611

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.65s/it]
INFO:root:final mean train loss: 3671.98613825152
INFO:root:final train perplexity: 4.257596015930176
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 3989.64203963043
INFO:root:eval perplexity: 5.019317626953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:00:40<19:31:47, 516.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3648.331387606534
INFO:root:current train perplexity4.2264180183410645
INFO:root:current mean train loss 3680.3769135346283
INFO:root:current train perplexity4.24367618560791
INFO:root:current mean train loss 3657.3440635644993
INFO:root:current train perplexity4.234569072723389
INFO:root:current mean train loss 3646.525626130426
INFO:root:current train perplexity4.228370189666748
INFO:root:current mean train loss 3652.6434929098236
INFO:root:current train perplexity4.22865629196167
INFO:root:current mean train loss 3659.175549531403
INFO:root:current train perplexity4.234440326690674
INFO:root:current mean train loss 3662.840726012684
INFO:root:current train perplexity4.2391157150268555
INFO:root:current mean train loss 3664.712401313621
INFO:root:current train perplexity4.2423577308654785
INFO:root:current mean train loss 3668.610911490444
INFO:root:current train perplexity4.2454938888549805
INFO:root:current mean train loss 3666.799706870455
INFO:root:current train perplexity4.244466781616211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.35s/it]
INFO:root:final mean train loss: 3664.8943051984234
INFO:root:final train perplexity: 4.245700836181641
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 3989.363871689384
INFO:root:eval perplexity: 5.018754005432129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [9:09:14<19:21:19, 516.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3600.2648540296054
INFO:root:current train perplexity4.20889949798584
INFO:root:current mean train loss 3653.3622698102677
INFO:root:current train perplexity4.217815399169922
INFO:root:current mean train loss 3654.910596594963
INFO:root:current train perplexity4.21901273727417
INFO:root:current mean train loss 3656.0782390343356
INFO:root:current train perplexity4.218355655670166
INFO:root:current mean train loss 3659.2298348001195
INFO:root:current train perplexity4.225796222686768
INFO:root:current mean train loss 3655.203513555214
INFO:root:current train perplexity4.219640731811523
INFO:root:current mean train loss 3659.8813989297255
INFO:root:current train perplexity4.226099967956543
INFO:root:current mean train loss 3657.9277218114353
INFO:root:current train perplexity4.228174209594727
INFO:root:current mean train loss 3656.0778114030068
INFO:root:current train perplexity4.22413969039917
INFO:root:current mean train loss 3656.9976016305086
INFO:root:current train perplexity4.229542255401611

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.34s/it]
INFO:root:final mean train loss: 3656.9999238906366
INFO:root:final train perplexity: 4.232497692108154
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 3991.666074495789
INFO:root:eval perplexity: 5.023427486419678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [9:17:12<18:47:28, 504.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.4679904513887
INFO:root:current train perplexity4.130630970001221
INFO:root:current mean train loss 3635.813722625492
INFO:root:current train perplexity4.1890363693237305
INFO:root:current mean train loss 3650.0709448995044
INFO:root:current train perplexity4.217194080352783
INFO:root:current mean train loss 3651.5020688491495
INFO:root:current train perplexity4.214419841766357
INFO:root:current mean train loss 3653.282017870865
INFO:root:current train perplexity4.211795330047607
INFO:root:current mean train loss 3647.9881005766724
INFO:root:current train perplexity4.20817232131958
INFO:root:current mean train loss 3647.6890372682415
INFO:root:current train perplexity4.2111496925354
INFO:root:current mean train loss 3647.540323837259
INFO:root:current train perplexity4.214663982391357
INFO:root:current mean train loss 3648.2920196422497
INFO:root:current train perplexity4.216678619384766
INFO:root:current mean train loss 3651.406324532683
INFO:root:current train perplexity4.21912956237793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.72s/it]
INFO:root:final mean train loss: 3649.979189534341
INFO:root:final train perplexity: 4.220790386199951
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.58s/it]
INFO:root:eval mean loss: 3988.8259260028813
INFO:root:eval perplexity: 5.0176615715026855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [9:25:13<18:22:48, 497.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3616.414306640625
INFO:root:current train perplexity4.165827751159668
INFO:root:current mean train loss 3617.0265498408567
INFO:root:current train perplexity4.1777119636535645
INFO:root:current mean train loss 3625.951516788564
INFO:root:current train perplexity4.18586540222168
INFO:root:current mean train loss 3635.5402941347947
INFO:root:current train perplexity4.192742347717285
INFO:root:current mean train loss 3634.7476859958692
INFO:root:current train perplexity4.192171096801758
INFO:root:current mean train loss 3641.9968302789134
INFO:root:current train perplexity4.197834014892578
INFO:root:current mean train loss 3642.614273960384
INFO:root:current train perplexity4.195915699005127
INFO:root:current mean train loss 3644.1913879809736
INFO:root:current train perplexity4.20169734954834
INFO:root:current mean train loss 3645.4215083504864
INFO:root:current train perplexity4.205047130584717
INFO:root:current mean train loss 3647.5106502757353
INFO:root:current train perplexity4.207834720611572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.80s/it]
INFO:root:final mean train loss: 3642.7109936744937
INFO:root:final train perplexity: 4.208704948425293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 3991.4400660738033
INFO:root:eval perplexity: 5.022968292236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [9:33:12<18:02:44, 492.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3628.0864768804504
INFO:root:current train perplexity4.174558162689209
INFO:root:current mean train loss 3642.6657322170017
INFO:root:current train perplexity4.195207595825195
INFO:root:current mean train loss 3642.2651738924255
INFO:root:current train perplexity4.1964802742004395
INFO:root:current mean train loss 3640.176735035532
INFO:root:current train perplexity4.191414833068848
INFO:root:current mean train loss 3633.929494612373
INFO:root:current train perplexity4.186432838439941
INFO:root:current mean train loss 3636.973107213254
INFO:root:current train perplexity4.19039249420166
INFO:root:current mean train loss 3640.0691908959466
INFO:root:current train perplexity4.192618370056152
INFO:root:current mean train loss 3641.133200562016
INFO:root:current train perplexity4.19609260559082
INFO:root:current mean train loss 3643.3047454218563
INFO:root:current train perplexity4.200211048126221
INFO:root:current mean train loss 3639.7957682119068
INFO:root:current train perplexity4.197124004364014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.90s/it]
INFO:root:final mean train loss: 3636.1750491972894
INFO:root:final train perplexity: 4.1978654861450195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 3993.1331951601287
INFO:root:eval perplexity: 5.026409149169922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [9:41:14<17:47:24, 488.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.9213819316788
INFO:root:current train perplexity4.180353164672852
INFO:root:current mean train loss 3613.6941710213164
INFO:root:current train perplexity4.174521446228027
INFO:root:current mean train loss 3616.690368409176
INFO:root:current train perplexity4.169167995452881
INFO:root:current mean train loss 3626.4800041176995
INFO:root:current train perplexity4.181662559509277
INFO:root:current mean train loss 3618.6501822122714
INFO:root:current train perplexity4.177969455718994
INFO:root:current mean train loss 3619.59173971685
INFO:root:current train perplexity4.180915355682373
INFO:root:current mean train loss 3623.0143139160905
INFO:root:current train perplexity4.181344032287598
INFO:root:current mean train loss 3625.173969863099
INFO:root:current train perplexity4.183778762817383
INFO:root:current mean train loss 3628.6134981363834
INFO:root:current train perplexity4.184150218963623
INFO:root:current mean train loss 3631.642633063059
INFO:root:current train perplexity4.186024188995361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.89s/it]
INFO:root:final mean train loss: 3629.5500276011803
INFO:root:final train perplexity: 4.18690824508667
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 3993.310891442265
INFO:root:eval perplexity: 5.026770114898682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [9:49:11<17:31:59, 485.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3588.9454283633477
INFO:root:current train perplexity4.166769027709961
INFO:root:current mean train loss 3597.909428434552
INFO:root:current train perplexity4.160338878631592
INFO:root:current mean train loss 3610.7907318940033
INFO:root:current train perplexity4.163999557495117
INFO:root:current mean train loss 3609.873885385837
INFO:root:current train perplexity4.164463043212891
INFO:root:current mean train loss 3611.847297219669
INFO:root:current train perplexity4.1602783203125
INFO:root:current mean train loss 3612.331139416089
INFO:root:current train perplexity4.161154747009277
INFO:root:current mean train loss 3614.395474840549
INFO:root:current train perplexity4.163158893585205
INFO:root:current mean train loss 3615.546383823802
INFO:root:current train perplexity4.1668219566345215
INFO:root:current mean train loss 3618.234679678405
INFO:root:current train perplexity4.169135570526123
INFO:root:current mean train loss 3623.7644681960373
INFO:root:current train perplexity4.172131061553955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.10s/it]
INFO:root:final mean train loss: 3622.062149909235
INFO:root:final train perplexity: 4.174558162689209
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it]
INFO:root:eval mean loss: 3992.1519264599956
INFO:root:eval perplexity: 5.024414539337158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [9:57:12<17:20:43, 484.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.055405346315
INFO:root:current train perplexity4.110442638397217
INFO:root:current mean train loss 3595.0215910951533
INFO:root:current train perplexity4.123775005340576
INFO:root:current mean train loss 3595.5834211142324
INFO:root:current train perplexity4.134766578674316
INFO:root:current mean train loss 3608.0660949208104
INFO:root:current train perplexity4.146420478820801
INFO:root:current mean train loss 3608.7766881775296
INFO:root:current train perplexity4.1470046043396
INFO:root:current mean train loss 3604.8255492518188
INFO:root:current train perplexity4.149156093597412
INFO:root:current mean train loss 3610.781983153931
INFO:root:current train perplexity4.152612209320068
INFO:root:current mean train loss 3613.4816630337355
INFO:root:current train perplexity4.157582759857178
INFO:root:current mean train loss 3613.0317515160937
INFO:root:current train perplexity4.1586737632751465
INFO:root:current mean train loss 3619.2751714791234
INFO:root:current train perplexity4.1659255027771

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.46s/it]
INFO:root:final mean train loss: 3616.7184480236424
INFO:root:final train perplexity: 4.165765762329102
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 3995.4014208638077
INFO:root:eval perplexity: 5.031022071838379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [10:05:13<17:11:00, 483.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3630.370859375
INFO:root:current train perplexity4.145133972167969
INFO:root:current mean train loss 3605.9343247767856
INFO:root:current train perplexity4.131976127624512
INFO:root:current mean train loss 3609.288321200284
INFO:root:current train perplexity4.137329578399658
INFO:root:current mean train loss 3606.011750651042
INFO:root:current train perplexity4.143900394439697
INFO:root:current mean train loss 3609.115396792763
INFO:root:current train perplexity4.149238109588623
INFO:root:current mean train loss 3609.776151494565
INFO:root:current train perplexity4.148180961608887
INFO:root:current mean train loss 3609.2253682002315
INFO:root:current train perplexity4.1480889320373535
INFO:root:current mean train loss 3610.7130730216736
INFO:root:current train perplexity4.151927471160889
INFO:root:current mean train loss 3612.1903094308036
INFO:root:current train perplexity4.152456283569336
INFO:root:current mean train loss 3612.2599228766026
INFO:root:current train perplexity4.153575420379639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it]
INFO:root:final mean train loss: 3609.0121675922023
INFO:root:final train perplexity: 4.1531195640563965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it]
INFO:root:eval mean loss: 3994.631035987367
INFO:root:eval perplexity: 5.029455184936523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [10:13:12<17:00:01, 481.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3569.4438711878765
INFO:root:current train perplexity4.105912685394287
INFO:root:current mean train loss 3587.189870698856
INFO:root:current train perplexity4.121985912322998
INFO:root:current mean train loss 3598.369078511484
INFO:root:current train perplexity4.134998321533203
INFO:root:current mean train loss 3597.827465884057
INFO:root:current train perplexity4.131252288818359
INFO:root:current mean train loss 3600.634551306936
INFO:root:current train perplexity4.139068126678467
INFO:root:current mean train loss 3600.856813826651
INFO:root:current train perplexity4.142023086547852
INFO:root:current mean train loss 3602.9404711520865
INFO:root:current train perplexity4.142650127410889
INFO:root:current mean train loss 3602.5212134194403
INFO:root:current train perplexity4.140606880187988
INFO:root:current mean train loss 3604.346653144465
INFO:root:current train perplexity4.141294002532959
INFO:root:current mean train loss 3604.8623173540022
INFO:root:current train perplexity4.142627716064453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.06s/it]
INFO:root:final mean train loss: 3602.892451686244
INFO:root:final train perplexity: 4.143104076385498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 3994.5439072196364
INFO:root:eval perplexity: 5.029277324676514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [10:21:11<16:50:10, 481.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.514881846669
INFO:root:current train perplexity4.128913879394531
INFO:root:current mean train loss 3588.8800822153144
INFO:root:current train perplexity4.11236047744751
INFO:root:current mean train loss 3595.9870546740763
INFO:root:current train perplexity4.120880126953125
INFO:root:current mean train loss 3591.6116553109014
INFO:root:current train perplexity4.120425701141357
INFO:root:current mean train loss 3591.5872163792005
INFO:root:current train perplexity4.120608806610107
INFO:root:current mean train loss 3593.580527161987
INFO:root:current train perplexity4.1193952560424805
INFO:root:current mean train loss 3594.7205126882463
INFO:root:current train perplexity4.125072002410889
INFO:root:current mean train loss 3595.5299373197495
INFO:root:current train perplexity4.128259658813477
INFO:root:current mean train loss 3596.873095922331
INFO:root:current train perplexity4.130601406097412
INFO:root:current mean train loss 3600.155657755739
INFO:root:current train perplexity4.1340718269348145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.55s/it]
INFO:root:final mean train loss: 3597.3633881230508
INFO:root:final train perplexity: 4.134076118469238
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 3994.3919253518397
INFO:root:eval perplexity: 5.028968334197998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [10:29:11<16:41:22, 480.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.4384371054293
INFO:root:current train perplexity4.1054768562316895
INFO:root:current mean train loss 3590.281064747566
INFO:root:current train perplexity4.1086015701293945
INFO:root:current mean train loss 3586.72629386366
INFO:root:current train perplexity4.110509872436523
INFO:root:current mean train loss 3586.3165800242796
INFO:root:current train perplexity4.112701892852783
INFO:root:current mean train loss 3589.811575788295
INFO:root:current train perplexity4.114309310913086
INFO:root:current mean train loss 3589.529258970028
INFO:root:current train perplexity4.111043930053711
INFO:root:current mean train loss 3593.4996664459272
INFO:root:current train perplexity4.119815349578857
INFO:root:current mean train loss 3591.1630697429405
INFO:root:current train perplexity4.1191558837890625
INFO:root:current mean train loss 3591.9167521204117
INFO:root:current train perplexity4.121805667877197

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.56s/it]
INFO:root:final mean train loss: 3589.9342741197156
INFO:root:final train perplexity: 4.12197732925415
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 3994.3228526013963
INFO:root:eval perplexity: 5.0288286209106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [10:37:09<16:31:43, 479.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.882149832589
INFO:root:current train perplexity4.106552600860596
INFO:root:current mean train loss 3583.436245071554
INFO:root:current train perplexity4.113536357879639
INFO:root:current mean train loss 3575.964809546724
INFO:root:current train perplexity4.1003618240356445
INFO:root:current mean train loss 3574.969938893272
INFO:root:current train perplexity4.093833923339844
INFO:root:current mean train loss 3579.9223968730803
INFO:root:current train perplexity4.100138187408447
INFO:root:current mean train loss 3579.272646811822
INFO:root:current train perplexity4.099675178527832
INFO:root:current mean train loss 3584.402874263154
INFO:root:current train perplexity4.105544090270996
INFO:root:current mean train loss 3585.922314591253
INFO:root:current train perplexity4.1093363761901855
INFO:root:current mean train loss 3585.7093247197377
INFO:root:current train perplexity4.109033584594727
INFO:root:current mean train loss 3584.6409035948695
INFO:root:current train perplexity4.108602523803711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.73s/it]
INFO:root:final mean train loss: 3583.616583301175
INFO:root:final train perplexity: 4.111715793609619
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it]
INFO:root:eval mean loss: 3995.3827241938166
INFO:root:eval perplexity: 5.030983924865723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [10:45:03<16:20:10, 478.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3536.594547526042
INFO:root:current train perplexity4.031854629516602
INFO:root:current mean train loss 3568.479054857337
INFO:root:current train perplexity4.070982933044434
INFO:root:current mean train loss 3575.216106468023
INFO:root:current train perplexity4.080432891845703
INFO:root:current mean train loss 3570.1611397879465
INFO:root:current train perplexity4.079484462738037
INFO:root:current mean train loss 3576.085691594503
INFO:root:current train perplexity4.091335773468018
INFO:root:current mean train loss 3576.966164953732
INFO:root:current train perplexity4.093973636627197
INFO:root:current mean train loss 3572.540337191946
INFO:root:current train perplexity4.089321613311768
INFO:root:current mean train loss 3575.9390133304196
INFO:root:current train perplexity4.094385147094727
INFO:root:current mean train loss 3577.1623813746164
INFO:root:current train perplexity4.097219944000244
INFO:root:current mean train loss 3578.2004383858434
INFO:root:current train perplexity4.09814977645874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.98s/it]
INFO:root:final mean train loss: 3577.1977267726775
INFO:root:final train perplexity: 4.101315975189209
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 3995.167615525266
INFO:root:eval perplexity: 5.030545711517334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [10:53:04<16:14:05, 479.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3581.2010869565215
INFO:root:current train perplexity4.108035564422607
INFO:root:current mean train loss 3564.7384896627286
INFO:root:current train perplexity4.088404655456543
INFO:root:current mean train loss 3562.1349199919423
INFO:root:current train perplexity4.088469505310059
INFO:root:current mean train loss 3566.9181365494387
INFO:root:current train perplexity4.086464881896973
INFO:root:current mean train loss 3565.8929007600104
INFO:root:current train perplexity4.084939956665039
INFO:root:current mean train loss 3564.6094440875954
INFO:root:current train perplexity4.086077690124512
INFO:root:current mean train loss 3569.719726170621
INFO:root:current train perplexity4.08873987197876
INFO:root:current mean train loss 3570.0646631602267
INFO:root:current train perplexity4.087730884552002
INFO:root:current mean train loss 3572.3133131099066
INFO:root:current train perplexity4.088546276092529
INFO:root:current mean train loss 3573.553089079852
INFO:root:current train perplexity4.09334135055542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.49s/it]
INFO:root:final mean train loss: 3572.833389651391
INFO:root:final train perplexity: 4.094260215759277
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 3996.5680927249555
INFO:root:eval perplexity: 5.033395767211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [11:01:03<16:06:11, 479.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3551.5208779611894
INFO:root:current train perplexity4.044894695281982
INFO:root:current mean train loss 3565.3416496451573
INFO:root:current train perplexity4.074612617492676
INFO:root:current mean train loss 3568.7350736015287
INFO:root:current train perplexity4.073339939117432
INFO:root:current mean train loss 3572.79810529173
INFO:root:current train perplexity4.075986385345459
INFO:root:current mean train loss 3570.7298547165024
INFO:root:current train perplexity4.080986976623535
INFO:root:current mean train loss 3570.232883489289
INFO:root:current train perplexity4.084139347076416
INFO:root:current mean train loss 3569.73033333127
INFO:root:current train perplexity4.083261489868164
INFO:root:current mean train loss 3568.5804849147144
INFO:root:current train perplexity4.082003116607666
INFO:root:current mean train loss 3572.294529957318
INFO:root:current train perplexity4.087213039398193
INFO:root:current mean train loss 3567.975256832791
INFO:root:current train perplexity4.083973407745361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.29s/it]
INFO:root:final mean train loss: 3565.749643079696
INFO:root:final train perplexity: 4.082833766937256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 3997.846587918329
INFO:root:eval perplexity: 5.035998821258545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [11:09:03<15:58:50, 479.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3520.52786333133
INFO:root:current train perplexity4.071596145629883
INFO:root:current mean train loss 3541.906550345661
INFO:root:current train perplexity4.04960298538208
INFO:root:current mean train loss 3543.1172385754444
INFO:root:current train perplexity4.0474534034729
INFO:root:current mean train loss 3547.6006622764567
INFO:root:current train perplexity4.046210289001465
INFO:root:current mean train loss 3549.8074937268652
INFO:root:current train perplexity4.057421684265137
INFO:root:current mean train loss 3549.8871975192774
INFO:root:current train perplexity4.059191703796387
INFO:root:current mean train loss 3557.080311949824
INFO:root:current train perplexity4.066132068634033
INFO:root:current mean train loss 3559.091456928176
INFO:root:current train perplexity4.070508003234863
INFO:root:current mean train loss 3560.765283377719
INFO:root:current train perplexity4.0722975730896
INFO:root:current mean train loss 3560.5997255952975
INFO:root:current train perplexity4.071655750274658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.54s/it]
INFO:root:final mean train loss: 3559.9065138909123
INFO:root:final train perplexity: 4.073432922363281
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 3998.051089455895
INFO:root:eval perplexity: 5.036414623260498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [11:16:59<15:48:34, 478.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3561.705130069814
INFO:root:current train perplexity4.100412368774414
INFO:root:current mean train loss 3568.7373262781675
INFO:root:current train perplexity4.074130058288574
INFO:root:current mean train loss 3552.273546226594
INFO:root:current train perplexity4.057326316833496
INFO:root:current mean train loss 3551.375895651342
INFO:root:current train perplexity4.055864334106445
INFO:root:current mean train loss 3557.6863710544253
INFO:root:current train perplexity4.057112693786621
INFO:root:current mean train loss 3552.3912516424816
INFO:root:current train perplexity4.057713031768799
INFO:root:current mean train loss 3554.5894230130652
INFO:root:current train perplexity4.060080051422119
INFO:root:current mean train loss 3558.102348521691
INFO:root:current train perplexity4.060935974121094
INFO:root:current mean train loss 3559.99271757628
INFO:root:current train perplexity4.063207626342773
INFO:root:current mean train loss 3557.2031484601866
INFO:root:current train perplexity4.065162181854248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.04s/it]
INFO:root:final mean train loss: 3554.1066687183998
INFO:root:final train perplexity: 4.064122676849365
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.33s/it]
INFO:root:eval mean loss: 3996.505454205452
INFO:root:eval perplexity: 5.033268451690674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [11:24:58<15:40:43, 478.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3556.0734818892047
INFO:root:current train perplexity4.055846214294434
INFO:root:current mean train loss 3544.8870243195565
INFO:root:current train perplexity4.046034336090088
INFO:root:current mean train loss 3540.4705355775122
INFO:root:current train perplexity4.042967796325684
INFO:root:current mean train loss 3545.7583042198503
INFO:root:current train perplexity4.052701473236084
INFO:root:current mean train loss 3542.466606391655
INFO:root:current train perplexity4.055400371551514
INFO:root:current mean train loss 3545.483521607545
INFO:root:current train perplexity4.056044101715088
INFO:root:current mean train loss 3546.018014596255
INFO:root:current train perplexity4.054504871368408
INFO:root:current mean train loss 3549.044769893419
INFO:root:current train perplexity4.055463790893555
INFO:root:current mean train loss 3550.2631102087903
INFO:root:current train perplexity4.054934024810791
INFO:root:current mean train loss 3552.9197592850132
INFO:root:current train perplexity4.056638240814209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.54s/it]
INFO:root:final mean train loss: 3548.267353673135
INFO:root:final train perplexity: 4.0547709465026855
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 3998.8065800227173
INFO:root:eval perplexity: 5.037954330444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [11:32:54<15:31:29, 477.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.6068289620534
INFO:root:current train perplexity4.011233806610107
INFO:root:current mean train loss 3543.315288894747
INFO:root:current train perplexity4.032947063446045
INFO:root:current mean train loss 3532.6309772680015
INFO:root:current train perplexity4.036805629730225
INFO:root:current mean train loss 3532.5424085044338
INFO:root:current train perplexity4.038086414337158
INFO:root:current mean train loss 3536.9155341986702
INFO:root:current train perplexity4.038007736206055
INFO:root:current mean train loss 3538.269114953375
INFO:root:current train perplexity4.040042400360107
INFO:root:current mean train loss 3543.073632886147
INFO:root:current train perplexity4.044633865356445
INFO:root:current mean train loss 3545.4987335405062
INFO:root:current train perplexity4.047027587890625
INFO:root:current mean train loss 3544.1441201997936
INFO:root:current train perplexity4.044294834136963
INFO:root:current mean train loss 3544.256865852966
INFO:root:current train perplexity4.044747829437256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.50s/it]
INFO:root:final mean train loss: 3542.0256478094284
INFO:root:final train perplexity: 4.044797420501709
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 4000.650281540891
INFO:root:eval perplexity: 5.04171085357666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [11:40:53<15:24:23, 478.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3513.3163993727994
INFO:root:current train perplexity4.017967700958252
INFO:root:current mean train loss 3525.030456186038
INFO:root:current train perplexity4.018712997436523
INFO:root:current mean train loss 3521.373600921068
INFO:root:current train perplexity4.017812728881836
INFO:root:current mean train loss 3524.0627948113206
INFO:root:current train perplexity4.023780822753906
INFO:root:current mean train loss 3526.8198231820593
INFO:root:current train perplexity4.023667335510254
INFO:root:current mean train loss 3531.9185767499453
INFO:root:current train perplexity4.02687406539917
INFO:root:current mean train loss 3536.5010788032087
INFO:root:current train perplexity4.031793594360352
INFO:root:current mean train loss 3540.4932549423434
INFO:root:current train perplexity4.033865928649902
INFO:root:current mean train loss 3541.23358651828
INFO:root:current train perplexity4.036555767059326
INFO:root:current mean train loss 3540.4667448285436
INFO:root:current train perplexity4.037987232208252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.96s/it]
INFO:root:final mean train loss: 3537.410807517267
INFO:root:final train perplexity: 4.037440776824951
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 3999.14320319426
INFO:root:eval perplexity: 5.038639545440674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [11:48:55<15:18:34, 479.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3484.6431374851663
INFO:root:current train perplexity4.0167694091796875
INFO:root:current mean train loss 3513.557859964211
INFO:root:current train perplexity4.017150402069092
INFO:root:current mean train loss 3528.52487609207
INFO:root:current train perplexity4.022340297698975
INFO:root:current mean train loss 3533.042504303059
INFO:root:current train perplexity4.021862983703613
INFO:root:current mean train loss 3532.7064104498304
INFO:root:current train perplexity4.02308464050293
INFO:root:current mean train loss 3531.098426621195
INFO:root:current train perplexity4.024491310119629
INFO:root:current mean train loss 3529.4579653845267
INFO:root:current train perplexity4.024960517883301
INFO:root:current mean train loss 3532.0666196771704
INFO:root:current train perplexity4.026151180267334
INFO:root:current mean train loss 3533.831298272629
INFO:root:current train perplexity4.026602745056152
INFO:root:current mean train loss 3534.449254660368
INFO:root:current train perplexity4.026921272277832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.75s/it]
INFO:root:final mean train loss: 3531.337519737982
INFO:root:final train perplexity: 4.027778148651123
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 3999.536664381095
INFO:root:eval perplexity: 5.039441108703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [11:56:54<15:10:41, 479.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.35511797324
INFO:root:current train perplexity3.9880099296569824
INFO:root:current mean train loss 3503.615713517296
INFO:root:current train perplexity3.99454927444458
INFO:root:current mean train loss 3508.4051773124456
INFO:root:current train perplexity4.011205196380615
INFO:root:current mean train loss 3513.779299398417
INFO:root:current train perplexity4.01205587387085
INFO:root:current mean train loss 3516.5051770846703
INFO:root:current train perplexity4.010714054107666
INFO:root:current mean train loss 3523.060574741136
INFO:root:current train perplexity4.015207290649414
INFO:root:current mean train loss 3523.2286378729987
INFO:root:current train perplexity4.014349460601807
INFO:root:current mean train loss 3526.2144137895093
INFO:root:current train perplexity4.0184431076049805
INFO:root:current mean train loss 3527.672744492936
INFO:root:current train perplexity4.019211292266846
INFO:root:current mean train loss 3529.116832543772
INFO:root:current train perplexity4.019750118255615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.78s/it]
INFO:root:final mean train loss: 3526.422469723609
INFO:root:final train perplexity: 4.019975185394287
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 4000.828824523493
INFO:root:eval perplexity: 5.042075157165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [12:04:55<15:03:15, 479.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3517.7068410773027
INFO:root:current train perplexity3.9890525341033936
INFO:root:current mean train loss 3531.5099296374196
INFO:root:current train perplexity4.004022598266602
INFO:root:current mean train loss 3528.6059934454447
INFO:root:current train perplexity4.008452415466309
INFO:root:current mean train loss 3518.2538073575947
INFO:root:current train perplexity4.001438617706299
INFO:root:current mean train loss 3517.892541133996
INFO:root:current train perplexity4.001123428344727
INFO:root:current mean train loss 3518.9603515625
INFO:root:current train perplexity3.998227596282959
INFO:root:current mean train loss 3518.1257134526754
INFO:root:current train perplexity4.000251770019531
INFO:root:current mean train loss 3519.9342150034395
INFO:root:current train perplexity4.004894733428955
INFO:root:current mean train loss 3522.53223720103
INFO:root:current train perplexity4.009547710418701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.67s/it]
INFO:root:final mean train loss: 3520.7011749513686
INFO:root:final train perplexity: 4.010911464691162
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 4002.6102892287236
INFO:root:eval perplexity: 5.045707702636719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [12:12:54<14:55:06, 479.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.6620279947915
INFO:root:current train perplexity4.110381603240967
INFO:root:current mean train loss 3527.8190941671724
INFO:root:current train perplexity4.001348495483398
INFO:root:current mean train loss 3515.3506845558804
INFO:root:current train perplexity3.9910969734191895
INFO:root:current mean train loss 3508.898228812139
INFO:root:current train perplexity3.983074426651001
INFO:root:current mean train loss 3515.049487244107
INFO:root:current train perplexity3.9949259757995605
INFO:root:current mean train loss 3515.683973308586
INFO:root:current train perplexity3.998666524887085
INFO:root:current mean train loss 3515.990929953099
INFO:root:current train perplexity3.9968178272247314
INFO:root:current mean train loss 3512.8901301203546
INFO:root:current train perplexity3.996384382247925
INFO:root:current mean train loss 3515.573401806215
INFO:root:current train perplexity3.99741792678833
INFO:root:current mean train loss 3516.2411541606107
INFO:root:current train perplexity4.001741409301758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.08s/it]
INFO:root:final mean train loss: 3515.413023671796
INFO:root:final train perplexity: 4.002552032470703
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it]
INFO:root:eval mean loss: 4004.288406263852
INFO:root:eval perplexity: 5.04913330078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [12:20:49<14:44:33, 478.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.831365411932
INFO:root:current train perplexity3.9249839782714844
INFO:root:current mean train loss 3497.0699363914696
INFO:root:current train perplexity3.973440647125244
INFO:root:current mean train loss 3497.081860004443
INFO:root:current train perplexity3.9764797687530518
INFO:root:current mean train loss 3495.9445580976185
INFO:root:current train perplexity3.978213310241699
INFO:root:current mean train loss 3495.228221587021
INFO:root:current train perplexity3.9731643199920654
INFO:root:current mean train loss 3497.8142194953216
INFO:root:current train perplexity3.975351333618164
INFO:root:current mean train loss 3499.9353830490486
INFO:root:current train perplexity3.981776475906372
INFO:root:current mean train loss 3506.1623679374343
INFO:root:current train perplexity3.9836602210998535
INFO:root:current mean train loss 3506.3465782381895
INFO:root:current train perplexity3.9856510162353516
INFO:root:current mean train loss 3509.1689265530667
INFO:root:current train perplexity3.989575147628784

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.74s/it]
INFO:root:final mean train loss: 3509.1996798976775
INFO:root:final train perplexity: 3.9927520751953125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 4005.479322501108
INFO:root:eval perplexity: 5.051565170288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [12:28:47<14:36:28, 478.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3456.0967567845396
INFO:root:current train perplexity4.003737926483154
INFO:root:current mean train loss 3496.064475692621
INFO:root:current train perplexity3.9555530548095703
INFO:root:current mean train loss 3510.9876279787386
INFO:root:current train perplexity3.9652867317199707
INFO:root:current mean train loss 3507.902525898805
INFO:root:current train perplexity3.9722232818603516
INFO:root:current mean train loss 3509.7056788624327
INFO:root:current train perplexity3.973142623901367
INFO:root:current mean train loss 3508.8009600042146
INFO:root:current train perplexity3.9756057262420654
INFO:root:current mean train loss 3506.281528060001
INFO:root:current train perplexity3.9777472019195557
INFO:root:current mean train loss 3503.001498799331
INFO:root:current train perplexity3.9809377193450928
INFO:root:current mean train loss 3503.7930945465123
INFO:root:current train perplexity3.9815361499786377
INFO:root:current mean train loss 3507.8856877274043
INFO:root:current train perplexity3.9853081703186035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.64s/it]
INFO:root:final mean train loss: 3504.004628519858
INFO:root:final train perplexity: 3.984576940536499
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it]
INFO:root:eval mean loss: 4006.988350509752
INFO:root:eval perplexity: 5.054649353027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [12:36:45<14:28:30, 478.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.420563874421
INFO:root:current train perplexity3.999938488006592
INFO:root:current mean train loss 3496.3812496155265
INFO:root:current train perplexity3.9723706245422363
INFO:root:current mean train loss 3493.5178502288686
INFO:root:current train perplexity3.9722533226013184
INFO:root:current mean train loss 3496.5262641556765
INFO:root:current train perplexity3.973496913909912
INFO:root:current mean train loss 3490.9176805840166
INFO:root:current train perplexity3.9710147380828857
INFO:root:current mean train loss 3496.4306686951495
INFO:root:current train perplexity3.9751737117767334
INFO:root:current mean train loss 3498.27401027649
INFO:root:current train perplexity3.973698139190674
INFO:root:current mean train loss 3500.841798889916
INFO:root:current train perplexity3.976121425628662
INFO:root:current mean train loss 3501.149231621259
INFO:root:current train perplexity3.9774715900421143
INFO:root:current mean train loss 3501.2922832073386
INFO:root:current train perplexity3.9773640632629395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.60s/it]
INFO:root:final mean train loss: 3499.421195737777
INFO:root:final train perplexity: 3.9773781299591064
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 4007.3809459496897
INFO:root:eval perplexity: 5.055451393127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [12:44:44<14:21:16, 478.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3480.712730189732
INFO:root:current train perplexity3.952805280685425
INFO:root:current mean train loss 3490.7681731047455
INFO:root:current train perplexity3.9598119258880615
INFO:root:current mean train loss 3495.8516622340426
INFO:root:current train perplexity3.967427968978882
INFO:root:current mean train loss 3497.1319066289648
INFO:root:current train perplexity3.9664297103881836
INFO:root:current mean train loss 3500.962833939476
INFO:root:current train perplexity3.971313953399658
INFO:root:current mean train loss 3501.3565698926695
INFO:root:current train perplexity3.9724223613739014
INFO:root:current mean train loss 3497.5685162401574
INFO:root:current train perplexity3.967714309692383
INFO:root:current mean train loss 3493.851600366709
INFO:root:current train perplexity3.9653191566467285
INFO:root:current mean train loss 3495.687568125468
INFO:root:current train perplexity3.967463493347168
INFO:root:current mean train loss 3494.3259872681315
INFO:root:current train perplexity3.965350866317749

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.15s/it]
INFO:root:final mean train loss: 3494.439238148351
INFO:root:final train perplexity: 3.9695682525634766
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 4006.1926511940383
INFO:root:eval perplexity: 5.053022384643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [12:52:38<14:10:45, 477.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3443.6575501907705
INFO:root:current train perplexity3.9300029277801514
INFO:root:current mean train loss 3487.4789612243226
INFO:root:current train perplexity3.9338338375091553
INFO:root:current mean train loss 3481.2047696839636
INFO:root:current train perplexity3.949111223220825
INFO:root:current mean train loss 3483.681498980731
INFO:root:current train perplexity3.951739549636841
INFO:root:current mean train loss 3482.8579288939054
INFO:root:current train perplexity3.9517245292663574
INFO:root:current mean train loss 3483.1494253028604
INFO:root:current train perplexity3.9519577026367188
INFO:root:current mean train loss 3485.2582271214037
INFO:root:current train perplexity3.9566805362701416
INFO:root:current mean train loss 3490.1006749847534
INFO:root:current train perplexity3.9581005573272705
INFO:root:current mean train loss 3490.264503922468
INFO:root:current train perplexity3.9587905406951904
INFO:root:current mean train loss 3490.6621277567438
INFO:root:current train perplexity3.9593496322631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.79s/it]
INFO:root:final mean train loss: 3488.2947563663606
INFO:root:final train perplexity: 3.959956645965576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it]
INFO:root:eval mean loss: 4010.406821392952
INFO:root:eval perplexity: 5.061641693115234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [13:00:31<14:00:46, 475.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.2474054074755
INFO:root:current train perplexity3.9670658111572266
INFO:root:current mean train loss 3486.793927527421
INFO:root:current train perplexity3.949892520904541
INFO:root:current mean train loss 3488.192710602901
INFO:root:current train perplexity3.953350067138672
INFO:root:current mean train loss 3487.2757968304845
INFO:root:current train perplexity3.942955732345581
INFO:root:current mean train loss 3484.482260558135
INFO:root:current train perplexity3.943678617477417
INFO:root:current mean train loss 3486.813563407441
INFO:root:current train perplexity3.949556589126587
INFO:root:current mean train loss 3486.5102280295937
INFO:root:current train perplexity3.9527859687805176
INFO:root:current mean train loss 3486.462733607794
INFO:root:current train perplexity3.9514386653900146
INFO:root:current mean train loss 3486.512085965041
INFO:root:current train perplexity3.953160047531128
INFO:root:current mean train loss 3487.2657972590528
INFO:root:current train perplexity3.9553422927856445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.32s/it]
INFO:root:final mean train loss: 3483.5280682963707
INFO:root:final train perplexity: 3.952517032623291
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.11s/it]
INFO:root:eval mean loss: 4010.1816371620125
INFO:root:eval perplexity: 5.061180591583252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [13:08:25<13:51:38, 475.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.738430217161
INFO:root:current train perplexity3.904252767562866
INFO:root:current mean train loss 3460.8371136743317
INFO:root:current train perplexity3.9049997329711914
INFO:root:current mean train loss 3465.2521416505792
INFO:root:current train perplexity3.9152956008911133
INFO:root:current mean train loss 3472.983441961177
INFO:root:current train perplexity3.9245917797088623
INFO:root:current mean train loss 3474.390117038569
INFO:root:current train perplexity3.928720474243164
INFO:root:current mean train loss 3477.7896521061607
INFO:root:current train perplexity3.9313619136810303
INFO:root:current mean train loss 3477.5641578593277
INFO:root:current train perplexity3.9346272945404053
INFO:root:current mean train loss 3480.4484059128995
INFO:root:current train perplexity3.938648223876953
INFO:root:current mean train loss 3482.7672467303914
INFO:root:current train perplexity3.942565441131592
INFO:root:current mean train loss 3482.5721403724583
INFO:root:current train perplexity3.943537950515747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.79s/it]
INFO:root:final mean train loss: 3477.979283978862
INFO:root:final train perplexity: 3.9438741207122803
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it]
INFO:root:eval mean loss: 4008.021027260638
INFO:root:eval perplexity: 5.056760311126709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [13:16:25<13:46:08, 476.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3482.3282853311566
INFO:root:current train perplexity3.968993902206421
INFO:root:current mean train loss 3475.582260771426
INFO:root:current train perplexity3.9379725456237793
INFO:root:current mean train loss 3482.6275282727647
INFO:root:current train perplexity3.9418461322784424
INFO:root:current mean train loss 3479.3878050759963
INFO:root:current train perplexity3.934828042984009
INFO:root:current mean train loss 3477.523415543027
INFO:root:current train perplexity3.9351730346679688
INFO:root:current mean train loss 3475.127037088707
INFO:root:current train perplexity3.9350883960723877
INFO:root:current mean train loss 3476.7521947034297
INFO:root:current train perplexity3.93601655960083
INFO:root:current mean train loss 3474.386277896329
INFO:root:current train perplexity3.937575578689575
INFO:root:current mean train loss 3478.079023279808
INFO:root:current train perplexity3.9397432804107666
INFO:root:current mean train loss 3477.3377949380333
INFO:root:current train perplexity3.939450263977051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.40s/it]
INFO:root:final mean train loss: 3474.7681482991866
INFO:root:final train perplexity: 3.938880681991577
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 4012.114252618019
INFO:root:eval perplexity: 5.065136909484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [13:24:25<13:39:55, 477.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.565423177083
INFO:root:current train perplexity3.9411492347717285
INFO:root:current mean train loss 3463.2410477120534
INFO:root:current train perplexity3.9277374744415283
INFO:root:current mean train loss 3473.039003018466
INFO:root:current train perplexity3.9233152866363525
INFO:root:current mean train loss 3474.857283203125
INFO:root:current train perplexity3.92158579826355
INFO:root:current mean train loss 3472.2145903577302
INFO:root:current train perplexity3.9246251583099365
INFO:root:current mean train loss 3467.656052564538
INFO:root:current train perplexity3.9255127906799316
INFO:root:current mean train loss 3471.990634765625
INFO:root:current train perplexity3.9270877838134766
INFO:root:current mean train loss 3470.8043526335687
INFO:root:current train perplexity3.9273507595062256
INFO:root:current mean train loss 3471.8644171316964
INFO:root:current train perplexity3.927982807159424
INFO:root:current mean train loss 3471.013561698718
INFO:root:current train perplexity3.9301340579986572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.79s/it]
INFO:root:final mean train loss: 3469.133027907341
INFO:root:final train perplexity: 3.9301328659057617
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 4013.1138820783467
INFO:root:eval perplexity: 5.0671844482421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [13:32:24<13:33:04, 478.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3450.3816123870483
INFO:root:current train perplexity3.902768611907959
INFO:root:current mean train loss 3455.0585737384736
INFO:root:current train perplexity3.916977643966675
INFO:root:current mean train loss 3469.483596855676
INFO:root:current train perplexity3.9188928604125977
INFO:root:current mean train loss 3469.56786663165
INFO:root:current train perplexity3.915472984313965
INFO:root:current mean train loss 3469.3228084967004
INFO:root:current train perplexity3.9182398319244385
INFO:root:current mean train loss 3467.637732582681
INFO:root:current train perplexity3.9181456565856934
INFO:root:current mean train loss 3468.7016011764504
INFO:root:current train perplexity3.921138286590576
INFO:root:current mean train loss 3465.6636356436584
INFO:root:current train perplexity3.9195399284362793
INFO:root:current mean train loss 3466.688736739542
INFO:root:current train perplexity3.919961452484131
INFO:root:current mean train loss 3467.248287538546
INFO:root:current train perplexity3.922565221786499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.18s/it]
INFO:root:final mean train loss: 3464.5226617013254
INFO:root:final train perplexity: 3.9229907989501953
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 4012.532984956782
INFO:root:eval perplexity: 5.065994739532471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [13:40:23<13:25:02, 478.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.064697265625
INFO:root:current train perplexity3.86936354637146
INFO:root:current mean train loss 3445.136562806774
INFO:root:current train perplexity3.880002975463867
INFO:root:current mean train loss 3449.651316849227
INFO:root:current train perplexity3.892414093017578
INFO:root:current mean train loss 3455.9304573859094
INFO:root:current train perplexity3.901679754257202
INFO:root:current mean train loss 3457.3034304989815
INFO:root:current train perplexity3.904780149459839
INFO:root:current mean train loss 3458.171580048382
INFO:root:current train perplexity3.905444383621216
INFO:root:current mean train loss 3459.0741547999955
INFO:root:current train perplexity3.907205104827881
INFO:root:current mean train loss 3459.9628829087983
INFO:root:current train perplexity3.909592866897583
INFO:root:current mean train loss 3458.6397051570393
INFO:root:current train perplexity3.9108524322509766
INFO:root:current mean train loss 3462.171666581263
INFO:root:current train perplexity3.9151957035064697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.26s/it]
INFO:root:final mean train loss: 3459.4101636948126
INFO:root:final train perplexity: 3.915086507797241
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 4013.222950603945
INFO:root:eval perplexity: 5.067408561706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [13:48:21<13:17:21, 478.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3434.893209438131
INFO:root:current train perplexity3.8740146160125732
INFO:root:current mean train loss 3440.9275748861496
INFO:root:current train perplexity3.895063877105713
INFO:root:current mean train loss 3443.6622555327654
INFO:root:current train perplexity3.8959221839904785
INFO:root:current mean train loss 3441.8434489544175
INFO:root:current train perplexity3.8930065631866455
INFO:root:current mean train loss 3448.161797716527
INFO:root:current train perplexity3.896763801574707
INFO:root:current mean train loss 3450.8018376982473
INFO:root:current train perplexity3.9010159969329834
INFO:root:current mean train loss 3456.5099818239228
INFO:root:current train perplexity3.906256914138794
INFO:root:current mean train loss 3459.318969268226
INFO:root:current train perplexity3.9078454971313477
INFO:root:current mean train loss 3458.567593821694
INFO:root:current train perplexity3.9086837768554688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.29s/it]
INFO:root:final mean train loss: 3455.2346124956684
INFO:root:final train perplexity: 3.9086427688598633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 4014.932203360483
INFO:root:eval perplexity: 5.0709123611450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [13:56:22<13:10:24, 479.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.914236886161
INFO:root:current train perplexity3.8633460998535156
INFO:root:current mean train loss 3474.5562664281542
INFO:root:current train perplexity3.903221845626831
INFO:root:current mean train loss 3457.6837140511775
INFO:root:current train perplexity3.8901619911193848
INFO:root:current mean train loss 3450.6070226613397
INFO:root:current train perplexity3.897825002670288
INFO:root:current mean train loss 3455.995766829507
INFO:root:current train perplexity3.9003872871398926
INFO:root:current mean train loss 3454.4939412675667
INFO:root:current train perplexity3.9013328552246094
INFO:root:current mean train loss 3452.4190450602346
INFO:root:current train perplexity3.8973867893218994
INFO:root:current mean train loss 3451.068844893697
INFO:root:current train perplexity3.897515058517456
INFO:root:current mean train loss 3452.367494264057
INFO:root:current train perplexity3.899779796600342
INFO:root:current mean train loss 3451.6543636300994
INFO:root:current train perplexity3.900787353515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.77s/it]
INFO:root:final mean train loss: 3450.2069548945274
INFO:root:final train perplexity: 3.9008960723876953
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 4019.338834289118
INFO:root:eval perplexity: 5.079957008361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [14:04:21<13:02:38, 479.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3423.151953125
INFO:root:current train perplexity3.8351359367370605
INFO:root:current mean train loss 3428.6995711616846
INFO:root:current train perplexity3.8499269485473633
INFO:root:current mean train loss 3430.9172647165697
INFO:root:current train perplexity3.8656375408172607
INFO:root:current mean train loss 3447.085833643353
INFO:root:current train perplexity3.8823297023773193
INFO:root:current mean train loss 3452.5357845444278
INFO:root:current train perplexity3.8874666690826416
INFO:root:current mean train loss 3447.743799776244
INFO:root:current train perplexity3.8843841552734375
INFO:root:current mean train loss 3448.2586382113823
INFO:root:current train perplexity3.8859431743621826
INFO:root:current mean train loss 3445.9596717247596
INFO:root:current train perplexity3.88763427734375
INFO:root:current mean train loss 3446.0278958373274
INFO:root:current train perplexity3.890216112136841
INFO:root:current mean train loss 3446.8635739519295
INFO:root:current train perplexity3.892315149307251

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.10s/it]
INFO:root:final mean train loss: 3446.269451510522
INFO:root:final train perplexity: 3.894841432571411
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 4016.4428001025044
INFO:root:eval perplexity: 5.074010848999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [14:12:20<12:54:23, 479.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3392.15626061481
INFO:root:current train perplexity3.852863073348999
INFO:root:current mean train loss 3430.9508920064786
INFO:root:current train perplexity3.855090856552124
INFO:root:current mean train loss 3435.2536894794002
INFO:root:current train perplexity3.8670454025268555
INFO:root:current mean train loss 3432.8779909116197
INFO:root:current train perplexity3.8688912391662598
INFO:root:current mean train loss 3431.767653156398
INFO:root:current train perplexity3.8709728717803955
INFO:root:current mean train loss 3435.9528220415573
INFO:root:current train perplexity3.878943920135498
INFO:root:current mean train loss 3439.5409380329556
INFO:root:current train perplexity3.8835697174072266
INFO:root:current mean train loss 3441.5543981106284
INFO:root:current train perplexity3.8873066902160645
INFO:root:current mean train loss 3442.136569536471
INFO:root:current train perplexity3.8870439529418945
INFO:root:current mean train loss 3442.5554244185064
INFO:root:current train perplexity3.885286331176758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.69s/it]
INFO:root:final mean train loss: 3441.7903973979332
INFO:root:final train perplexity: 3.887965202331543
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 4018.163766414561
INFO:root:eval perplexity: 5.077542304992676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [14:20:16<12:45:05, 478.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3386.555372668851
INFO:root:current train perplexity3.8309569358825684
INFO:root:current mean train loss 3412.0762166030536
INFO:root:current train perplexity3.851034164428711
INFO:root:current mean train loss 3410.321532146239
INFO:root:current train perplexity3.860551118850708
INFO:root:current mean train loss 3420.316725624292
INFO:root:current train perplexity3.8702831268310547
INFO:root:current mean train loss 3420.6877718967517
INFO:root:current train perplexity3.8684232234954834
INFO:root:current mean train loss 3425.7178382658017
INFO:root:current train perplexity3.8711869716644287
INFO:root:current mean train loss 3432.361440329091
INFO:root:current train perplexity3.87615704536438
INFO:root:current mean train loss 3434.5782405576692
INFO:root:current train perplexity3.87809419631958
INFO:root:current mean train loss 3440.3308951587883
INFO:root:current train perplexity3.883530378341675
INFO:root:current mean train loss 3440.2589485012754
INFO:root:current train perplexity3.881880760192871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.36s/it]
INFO:root:final mean train loss: 3439.265517265566
INFO:root:final train perplexity: 3.884094476699829
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 4017.4259059175533
INFO:root:eval perplexity: 5.076027870178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [14:28:15<12:37:27, 478.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3420.292048527644
INFO:root:current train perplexity3.8728084564208984
INFO:root:current mean train loss 3437.9942705991457
INFO:root:current train perplexity3.87246036529541
INFO:root:current mean train loss 3431.5793038212605
INFO:root:current train perplexity3.8718645572662354
INFO:root:current mean train loss 3441.22357735873
INFO:root:current train perplexity3.8740224838256836
INFO:root:current mean train loss 3437.5353297622437
INFO:root:current train perplexity3.8709824085235596
INFO:root:current mean train loss 3436.40428419237
INFO:root:current train perplexity3.870832920074463
INFO:root:current mean train loss 3439.3880769971393
INFO:root:current train perplexity3.8726816177368164
INFO:root:current mean train loss 3440.2464630994164
INFO:root:current train perplexity3.8743114471435547
INFO:root:current mean train loss 3437.674022215342
INFO:root:current train perplexity3.873495578765869
INFO:root:current mean train loss 3436.863650710946
INFO:root:current train perplexity3.8746731281280518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.36s/it]
INFO:root:final mean train loss: 3433.7140462936895
INFO:root:final train perplexity: 3.875596046447754
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 4019.9651536873894
INFO:root:eval perplexity: 5.081242561340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [14:36:14<12:29:51, 478.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.533436876662
INFO:root:current train perplexity3.8243305683135986
INFO:root:current mean train loss 3409.105281077275
INFO:root:current train perplexity3.852895975112915
INFO:root:current mean train loss 3409.9956113992916
INFO:root:current train perplexity3.8479058742523193
INFO:root:current mean train loss 3415.5582975448037
INFO:root:current train perplexity3.8564705848693848
INFO:root:current mean train loss 3420.6631738718193
INFO:root:current train perplexity3.854139566421509
INFO:root:current mean train loss 3426.906934664934
INFO:root:current train perplexity3.858959436416626
INFO:root:current mean train loss 3428.892909809095
INFO:root:current train perplexity3.8609137535095215
INFO:root:current mean train loss 3427.4867039773676
INFO:root:current train perplexity3.861222982406616
INFO:root:current mean train loss 3430.9551349085928
INFO:root:current train perplexity3.8671658039093018
INFO:root:current mean train loss 3430.6182140765245
INFO:root:current train perplexity3.867723226547241

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.86s/it]
INFO:root:final mean train loss: 3429.45195130379
INFO:root:final train perplexity: 3.8690850734710693
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 4022.7939747478945
INFO:root:eval perplexity: 5.0870585441589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [14:44:12<12:21:35, 478.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3403.07021484375
INFO:root:current train perplexity3.8319668769836426
INFO:root:current mean train loss 3414.545240045363
INFO:root:current train perplexity3.839207649230957
INFO:root:current mean train loss 3409.0375114889707
INFO:root:current train perplexity3.8429315090179443
INFO:root:current mean train loss 3420.0232456261006
INFO:root:current train perplexity3.8509905338287354
INFO:root:current mean train loss 3424.0220069969096
INFO:root:current train perplexity3.8505465984344482
INFO:root:current mean train loss 3422.7942162865993
INFO:root:current train perplexity3.854555368423462
INFO:root:current mean train loss 3423.2419810054867
INFO:root:current train perplexity3.8575892448425293
INFO:root:current mean train loss 3426.421055592922
INFO:root:current train perplexity3.857438564300537
INFO:root:current mean train loss 3425.5902109603435
INFO:root:current train perplexity3.857227325439453
INFO:root:current mean train loss 3428.435684156168
INFO:root:current train perplexity3.862220525741577

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.78s/it]
INFO:root:final mean train loss: 3424.6542725101594
INFO:root:final train perplexity: 3.861768960952759
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it]
INFO:root:eval mean loss: 4023.4599990303636
INFO:root:eval perplexity: 5.088428974151611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [14:52:14<12:14:59, 479.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3371.6304602244545
INFO:root:current train perplexity3.839385509490967
INFO:root:current mean train loss 3395.885706240414
INFO:root:current train perplexity3.851641893386841
INFO:root:current mean train loss 3403.737480134565
INFO:root:current train perplexity3.8470118045806885
INFO:root:current mean train loss 3409.2929472279616
INFO:root:current train perplexity3.849696159362793
INFO:root:current mean train loss 3414.094116474588
INFO:root:current train perplexity3.8451316356658936
INFO:root:current mean train loss 3418.239871850022
INFO:root:current train perplexity3.8493900299072266
INFO:root:current mean train loss 3420.8376781526913
INFO:root:current train perplexity3.850202798843384
INFO:root:current mean train loss 3421.743754095675
INFO:root:current train perplexity3.8511641025543213
INFO:root:current mean train loss 3421.541651013
INFO:root:current train perplexity3.853217124938965
INFO:root:current mean train loss 3423.7284344983127
INFO:root:current train perplexity3.8568384647369385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.42s/it]
INFO:root:final mean train loss: 3421.3374770379837
INFO:root:final train perplexity: 3.856718063354492
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 4023.394505277593
INFO:root:eval perplexity: 5.08829402923584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [15:00:12<12:06:39, 479.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3394.35498046875
INFO:root:current train perplexity3.812063455581665
INFO:root:current mean train loss 3395.2710803294044
INFO:root:current train perplexity3.829164743423462
INFO:root:current mean train loss 3399.826277278886
INFO:root:current train perplexity3.834489107131958
INFO:root:current mean train loss 3404.922526480374
INFO:root:current train perplexity3.830913543701172
INFO:root:current mean train loss 3408.4119585365247
INFO:root:current train perplexity3.8387951850891113
INFO:root:current mean train loss 3412.593036391063
INFO:root:current train perplexity3.8456523418426514
INFO:root:current mean train loss 3414.2698499790426
INFO:root:current train perplexity3.8473548889160156
INFO:root:current mean train loss 3415.9574191517713
INFO:root:current train perplexity3.8478939533233643
INFO:root:current mean train loss 3416.631647015822
INFO:root:current train perplexity3.8478920459747314
INFO:root:current mean train loss 3419.0498952030766
INFO:root:current train perplexity3.8508903980255127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.08s/it]
INFO:root:final mean train loss: 3417.2765350341797
INFO:root:final train perplexity: 3.850543737411499
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 4024.214381441157
INFO:root:eval perplexity: 5.089982032775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [15:08:13<11:59:10, 479.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.351862267603
INFO:root:current train perplexity3.818389415740967
INFO:root:current mean train loss 3407.796246235597
INFO:root:current train perplexity3.8199939727783203
INFO:root:current mean train loss 3414.43413453461
INFO:root:current train perplexity3.8329617977142334
INFO:root:current mean train loss 3417.121701202795
INFO:root:current train perplexity3.838923931121826
INFO:root:current mean train loss 3418.9132954193306
INFO:root:current train perplexity3.836660146713257
INFO:root:current mean train loss 3415.219307011685
INFO:root:current train perplexity3.83324933052063
INFO:root:current mean train loss 3416.081859021194
INFO:root:current train perplexity3.8349924087524414
INFO:root:current mean train loss 3413.222088991295
INFO:root:current train perplexity3.8368823528289795
INFO:root:current mean train loss 3412.977005230553
INFO:root:current train perplexity3.840485095977783
INFO:root:current mean train loss 3414.783346267716
INFO:root:current train perplexity3.8432815074920654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.90s/it]
INFO:root:final mean train loss: 3412.2610991693314
INFO:root:final train perplexity: 3.8429324626922607
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 4024.8552003684617
INFO:root:eval perplexity: 5.091300964355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [15:16:16<11:52:53, 480.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3419.169043529993
INFO:root:current train perplexity3.827314853668213
INFO:root:current mean train loss 3412.4636021578376
INFO:root:current train perplexity3.8266806602478027
INFO:root:current mean train loss 3409.6970946414963
INFO:root:current train perplexity3.830183267593384
INFO:root:current mean train loss 3406.0289618913516
INFO:root:current train perplexity3.824894666671753
INFO:root:current mean train loss 3405.5021721998523
INFO:root:current train perplexity3.8288590908050537
INFO:root:current mean train loss 3405.460418857139
INFO:root:current train perplexity3.8315744400024414
INFO:root:current mean train loss 3409.505698036072
INFO:root:current train perplexity3.835369110107422
INFO:root:current mean train loss 3407.3643555307935
INFO:root:current train perplexity3.8354666233062744
INFO:root:current mean train loss 3409.922631368024
INFO:root:current train perplexity3.8371362686157227
INFO:root:current mean train loss 3410.9608964388613
INFO:root:current train perplexity3.83664870262146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.55s/it]
INFO:root:final mean train loss: 3408.020574692757
INFO:root:final train perplexity: 3.836507797241211
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it]
INFO:root:eval mean loss: 4026.096317805297
INFO:root:eval perplexity: 5.093855857849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [15:24:14<11:43:51, 479.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3392.3382478412827
INFO:root:current train perplexity3.813300132751465
INFO:root:current mean train loss 3378.353515625
INFO:root:current train perplexity3.8146884441375732
INFO:root:current mean train loss 3386.406340207892
INFO:root:current train perplexity3.815340042114258
INFO:root:current mean train loss 3395.1708873121042
INFO:root:current train perplexity3.8223161697387695
INFO:root:current mean train loss 3396.255386876578
INFO:root:current train perplexity3.8229598999023438
INFO:root:current mean train loss 3395.143526375394
INFO:root:current train perplexity3.8217179775238037
INFO:root:current mean train loss 3399.3461376601845
INFO:root:current train perplexity3.8256635665893555
INFO:root:current mean train loss 3403.0855183151534
INFO:root:current train perplexity3.8288965225219727
INFO:root:current mean train loss 3404.680145502357
INFO:root:current train perplexity3.831118106842041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.46s/it]
INFO:root:final mean train loss: 3403.982508813181
INFO:root:final train perplexity: 3.8304011821746826
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 4028.5250651041665
INFO:root:eval perplexity: 5.0988616943359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [15:32:38<11:46:14, 487.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.8346354166665
INFO:root:current train perplexity3.8456318378448486
INFO:root:current mean train loss 3379.4096442657765
INFO:root:current train perplexity3.798313617706299
INFO:root:current mean train loss 3397.0608006369303
INFO:root:current train perplexity3.8184609413146973
INFO:root:current mean train loss 3394.292385390883
INFO:root:current train perplexity3.8165879249572754
INFO:root:current mean train loss 3393.5808965716114
INFO:root:current train perplexity3.8172590732574463
INFO:root:current mean train loss 3398.7014368864934
INFO:root:current train perplexity3.8219387531280518
INFO:root:current mean train loss 3399.4840332841004
INFO:root:current train perplexity3.821805000305176
INFO:root:current mean train loss 3400.6677808693767
INFO:root:current train perplexity3.823319673538208
INFO:root:current mean train loss 3404.4806253283587
INFO:root:current train perplexity3.827171564102173
INFO:root:current mean train loss 3403.0724786735186
INFO:root:current train perplexity3.824230909347534

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.35s/it]
INFO:root:final mean train loss: 3400.6235773640296
INFO:root:final train perplexity: 3.825328826904297
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 4027.1869995982934
INFO:root:eval perplexity: 5.096102237701416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [15:41:09<11:48:27, 494.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3366.911532315341
INFO:root:current train perplexity3.809412717819214
INFO:root:current mean train loss 3395.5314853427644
INFO:root:current train perplexity3.8362174034118652
INFO:root:current mean train loss 3389.057921495483
INFO:root:current train perplexity3.8255703449249268
INFO:root:current mean train loss 3396.4670355204985
INFO:root:current train perplexity3.8226213455200195
INFO:root:current mean train loss 3397.6493570369526
INFO:root:current train perplexity3.8218250274658203
INFO:root:current mean train loss 3395.608804542258
INFO:root:current train perplexity3.8200817108154297
INFO:root:current mean train loss 3401.445558238927
INFO:root:current train perplexity3.8196988105773926
INFO:root:current mean train loss 3399.6230163144996
INFO:root:current train perplexity3.8192079067230225
INFO:root:current mean train loss 3397.6583765220407
INFO:root:current train perplexity3.8178770542144775
INFO:root:current mean train loss 3399.2122696877573
INFO:root:current train perplexity3.8192338943481445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.89s/it]
INFO:root:final mean train loss: 3398.335280818324
INFO:root:final train perplexity: 3.8218772411346436
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 4028.959405127992
INFO:root:eval perplexity: 5.099756717681885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [15:49:50<11:51:34, 502.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.7712916324012
INFO:root:current train perplexity3.764691114425659
INFO:root:current mean train loss 3356.310509946166
INFO:root:current train perplexity3.7864863872528076
INFO:root:current mean train loss 3376.778412840682
INFO:root:current train perplexity3.796725034713745
INFO:root:current mean train loss 3384.372720843946
INFO:root:current train perplexity3.8019001483917236
INFO:root:current mean train loss 3384.523487610009
INFO:root:current train perplexity3.798896312713623
INFO:root:current mean train loss 3387.7028446381264
INFO:root:current train perplexity3.7998266220092773
INFO:root:current mean train loss 3389.5671765353645
INFO:root:current train perplexity3.8038458824157715
INFO:root:current mean train loss 3394.139519745849
INFO:root:current train perplexity3.807528257369995
INFO:root:current mean train loss 3394.92878099006
INFO:root:current train perplexity3.8090317249298096
INFO:root:current mean train loss 3392.9802070758806
INFO:root:current train perplexity3.8108222484588623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.36s/it]
INFO:root:final mean train loss: 3392.3657625875167
INFO:root:final train perplexity: 3.8128864765167236
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 4030.9772966533687
INFO:root:eval perplexity: 5.1039204597473145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [15:58:05<11:40:00, 500.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3396.9967628761574
INFO:root:current train perplexity3.8121771812438965
INFO:root:current mean train loss 3397.0798089936025
INFO:root:current train perplexity3.8039863109588623
INFO:root:current mean train loss 3393.626403539716
INFO:root:current train perplexity3.7979540824890137
INFO:root:current mean train loss 3389.2472524847094
INFO:root:current train perplexity3.799562692642212
INFO:root:current mean train loss 3392.084991812427
INFO:root:current train perplexity3.80359148979187
INFO:root:current mean train loss 3391.343032402603
INFO:root:current train perplexity3.802096366882324
INFO:root:current mean train loss 3391.4479739053777
INFO:root:current train perplexity3.8019566535949707
INFO:root:current mean train loss 3391.5349389749185
INFO:root:current train perplexity3.803900718688965
INFO:root:current mean train loss 3390.9213952799087
INFO:root:current train perplexity3.8040080070495605
INFO:root:current mean train loss 3391.425529208384
INFO:root:current train perplexity3.8073418140411377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.82s/it]
INFO:root:final mean train loss: 3388.307131674982
INFO:root:final train perplexity: 3.806785821914673
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it]
INFO:root:eval mean loss: 4032.136112727172
INFO:root:eval perplexity: 5.106312274932861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [16:06:33<11:35:15, 502.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.8383231026787
INFO:root:current train perplexity3.7732672691345215
INFO:root:current mean train loss 3380.2861237702546
INFO:root:current train perplexity3.777526378631592
INFO:root:current mean train loss 3376.674830659907
INFO:root:current train perplexity3.7838990688323975
INFO:root:current mean train loss 3383.934905550373
INFO:root:current train perplexity3.790908098220825
INFO:root:current mean train loss 3386.5655896417024
INFO:root:current train perplexity3.7926290035247803
INFO:root:current mean train loss 3387.1112199729846
INFO:root:current train perplexity3.7948760986328125
INFO:root:current mean train loss 3386.8675938884103
INFO:root:current train perplexity3.798588991165161
INFO:root:current mean train loss 3388.3026759141158
INFO:root:current train perplexity3.7987184524536133
INFO:root:current mean train loss 3387.7872622918226
INFO:root:current train perplexity3.799792766571045
INFO:root:current mean train loss 3387.91417686748
INFO:root:current train perplexity3.8021090030670166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it]
INFO:root:final mean train loss: 3384.974097344183
INFO:root:final train perplexity: 3.8017830848693848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 4032.2011857269504
INFO:root:eval perplexity: 5.106446743011475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [16:15:06<11:30:48, 505.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.461675599564
INFO:root:current train perplexity3.7732443809509277
INFO:root:current mean train loss 3366.63790701486
INFO:root:current train perplexity3.7683827877044678
INFO:root:current mean train loss 3368.5729498215665
INFO:root:current train perplexity3.777273654937744
INFO:root:current mean train loss 3373.0740308400145
INFO:root:current train perplexity3.780228614807129
INFO:root:current mean train loss 3379.9633469420146
INFO:root:current train perplexity3.783168077468872
INFO:root:current mean train loss 3380.5479603691874
INFO:root:current train perplexity3.7845370769500732
INFO:root:current mean train loss 3382.154201193138
INFO:root:current train perplexity3.788463592529297
INFO:root:current mean train loss 3382.2265431133287
INFO:root:current train perplexity3.7897298336029053
INFO:root:current mean train loss 3380.6773515115287
INFO:root:current train perplexity3.793292284011841
INFO:root:current mean train loss 3382.242803417865
INFO:root:current train perplexity3.7941315174102783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.78s/it]
INFO:root:final mean train loss: 3380.414011493806
INFO:root:final train perplexity: 3.794950008392334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 4034.3323567708335
INFO:root:eval perplexity: 5.110848426818848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [16:23:41<11:26:30, 508.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3378.515510110294
INFO:root:current train perplexity3.7815515995025635
INFO:root:current mean train loss 3366.0901929842717
INFO:root:current train perplexity3.77085542678833
INFO:root:current mean train loss 3366.028023647597
INFO:root:current train perplexity3.7783846855163574
INFO:root:current mean train loss 3362.4215919081644
INFO:root:current train perplexity3.7793779373168945
INFO:root:current mean train loss 3364.2955297905696
INFO:root:current train perplexity3.779338836669922
INFO:root:current mean train loss 3368.4220500191414
INFO:root:current train perplexity3.7800750732421875
INFO:root:current mean train loss 3373.155574581773
INFO:root:current train perplexity3.783801794052124
INFO:root:current mean train loss 3377.753644554656
INFO:root:current train perplexity3.78816556930542
INFO:root:current mean train loss 3377.627859400246
INFO:root:current train perplexity3.789267063140869
INFO:root:current mean train loss 3379.9458634209054
INFO:root:current train perplexity3.7909247875213623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.49s/it]
INFO:root:final mean train loss: 3377.7602751331947
INFO:root:final train perplexity: 3.790978193283081
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 4038.117989181627
INFO:root:eval perplexity: 5.118678569793701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [16:32:09<11:17:39, 508.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.534163135593
INFO:root:current train perplexity3.771371364593506
INFO:root:current mean train loss 3364.372285279088
INFO:root:current train perplexity3.7706010341644287
INFO:root:current mean train loss 3364.263574784327
INFO:root:current train perplexity3.765997886657715
INFO:root:current mean train loss 3369.894122535472
INFO:root:current train perplexity3.775817394256592
INFO:root:current mean train loss 3371.170601639093
INFO:root:current train perplexity3.7791085243225098
INFO:root:current mean train loss 3368.5187293856216
INFO:root:current train perplexity3.780897855758667
INFO:root:current mean train loss 3373.908745124597
INFO:root:current train perplexity3.7846474647521973
INFO:root:current mean train loss 3375.3849914309535
INFO:root:current train perplexity3.785792827606201
INFO:root:current mean train loss 3377.310639244852
INFO:root:current train perplexity3.786571741104126
INFO:root:current mean train loss 3377.2896849440335
INFO:root:current train perplexity3.7867095470428467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.60s/it]
INFO:root:final mean train loss: 3375.1366588838637
INFO:root:final train perplexity: 3.7870566844940186
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it]
INFO:root:eval mean loss: 4037.2895854111257
INFO:root:eval perplexity: 5.116965293884277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [16:40:27<11:05:08, 505.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.8565582730876
INFO:root:current train perplexity3.780273675918579
INFO:root:current mean train loss 3368.997690166542
INFO:root:current train perplexity3.776562213897705
INFO:root:current mean train loss 3362.260254820634
INFO:root:current train perplexity3.7657370567321777
INFO:root:current mean train loss 3363.2083943130533
INFO:root:current train perplexity3.770681858062744
INFO:root:current mean train loss 3366.6423935818725
INFO:root:current train perplexity3.7690720558166504
INFO:root:current mean train loss 3366.889797419257
INFO:root:current train perplexity3.770890951156616
INFO:root:current mean train loss 3370.7955386320514
INFO:root:current train perplexity3.7743079662323
INFO:root:current mean train loss 3370.2192408276974
INFO:root:current train perplexity3.7747628688812256
INFO:root:current mean train loss 3372.0296885700513
INFO:root:current train perplexity3.7763760089874268
INFO:root:current mean train loss 3374.5422802582893
INFO:root:current train perplexity3.7811760902404785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it]
INFO:root:final mean train loss: 3372.228003101964
INFO:root:final train perplexity: 3.7827134132385254
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 4035.3404203374334
INFO:root:eval perplexity: 5.11293363571167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [16:49:02<11:00:39, 508.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.680393880208
INFO:root:current train perplexity3.775283098220825
INFO:root:current mean train loss 3357.618197544643
INFO:root:current train perplexity3.778209924697876
INFO:root:current mean train loss 3365.3267365056818
INFO:root:current train perplexity3.7788634300231934
INFO:root:current mean train loss 3367.090371744792
INFO:root:current train perplexity3.776698350906372
INFO:root:current mean train loss 3369.9586960320726
INFO:root:current train perplexity3.778052806854248
INFO:root:current mean train loss 3371.0806950577444
INFO:root:current train perplexity3.77597713470459
INFO:root:current mean train loss 3371.483916377315
INFO:root:current train perplexity3.775942802429199
INFO:root:current mean train loss 3372.039133064516
INFO:root:current train perplexity3.7767395973205566
INFO:root:current mean train loss 3370.9979313616072
INFO:root:current train perplexity3.776515007019043
INFO:root:current mean train loss 3370.7383173076923
INFO:root:current train perplexity3.776787757873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.83s/it]
INFO:root:final mean train loss: 3368.2660649207332
INFO:root:final train perplexity: 3.7768049240112305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it]
INFO:root:eval mean loss: 4039.0064602033467
INFO:root:eval perplexity: 5.120518684387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [16:57:31<10:52:37, 508.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.387936511672
INFO:root:current train perplexity3.757676124572754
INFO:root:current mean train loss 3338.98093435152
INFO:root:current train perplexity3.7544267177581787
INFO:root:current mean train loss 3346.932234154152
INFO:root:current train perplexity3.7557504177093506
INFO:root:current mean train loss 3357.4950547180974
INFO:root:current train perplexity3.7661566734313965
INFO:root:current mean train loss 3360.6506165688083
INFO:root:current train perplexity3.7719924449920654
INFO:root:current mean train loss 3369.4245111324776
INFO:root:current train perplexity3.773524761199951
INFO:root:current mean train loss 3371.124083132206
INFO:root:current train perplexity3.7741522789001465
INFO:root:current mean train loss 3368.707664207176
INFO:root:current train perplexity3.770228862762451
INFO:root:current mean train loss 3368.3657558350437
INFO:root:current train perplexity3.771679401397705
INFO:root:current mean train loss 3367.9482384620583
INFO:root:current train perplexity3.7722504138946533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.44s/it]
INFO:root:final mean train loss: 3365.1739225079937
INFO:root:final train perplexity: 3.772200584411621
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 4039.721882272274
INFO:root:eval perplexity: 5.122000217437744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [17:06:04<10:45:47, 509.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3331.6526147192653
INFO:root:current train perplexity3.710573434829712
INFO:root:current mean train loss 3355.124002985929
INFO:root:current train perplexity3.747745990753174
INFO:root:current mean train loss 3359.212645645404
INFO:root:current train perplexity3.7529916763305664
INFO:root:current mean train loss 3359.8807482316975
INFO:root:current train perplexity3.751493453979492
INFO:root:current mean train loss 3359.234124892598
INFO:root:current train perplexity3.753326177597046
INFO:root:current mean train loss 3361.683271120849
INFO:root:current train perplexity3.7591118812561035
INFO:root:current mean train loss 3363.5011062290837
INFO:root:current train perplexity3.7611379623413086
INFO:root:current mean train loss 3366.0825559517225
INFO:root:current train perplexity3.76216721534729
INFO:root:current mean train loss 3364.216996900428
INFO:root:current train perplexity3.7647993564605713
INFO:root:current mean train loss 3363.769158017864
INFO:root:current train perplexity3.7661280632019043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.89s/it]
INFO:root:final mean train loss: 3361.0583726821405
INFO:root:final train perplexity: 3.766080379486084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 4039.5685221354165
INFO:root:eval perplexity: 5.1216816902160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [17:14:05<10:26:34, 501.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3361.3684254655936
INFO:root:current train perplexity3.7551610469818115
INFO:root:current mean train loss 3351.1267028501884
INFO:root:current train perplexity3.7553505897521973
INFO:root:current mean train loss 3354.0347977960387
INFO:root:current train perplexity3.7559401988983154
INFO:root:current mean train loss 3353.427277911576
INFO:root:current train perplexity3.7543201446533203
INFO:root:current mean train loss 3353.982702220848
INFO:root:current train perplexity3.753196954727173
INFO:root:current mean train loss 3355.7906113053004
INFO:root:current train perplexity3.7527706623077393
INFO:root:current mean train loss 3355.367050585658
INFO:root:current train perplexity3.754467725753784
INFO:root:current mean train loss 3358.50622390537
INFO:root:current train perplexity3.7569310665130615
INFO:root:current mean train loss 3360.449263287333
INFO:root:current train perplexity3.7612111568450928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.41s/it]
INFO:root:final mean train loss: 3357.438380825904
INFO:root:final train perplexity: 3.7607054710388184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it]
INFO:root:eval mean loss: 4043.1808735732493
INFO:root:eval perplexity: 5.129168510437012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [17:22:29<10:18:53, 501.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3355.9130859375
INFO:root:current train perplexity3.8001537322998047
INFO:root:current mean train loss 3345.7837028146905
INFO:root:current train perplexity3.7433345317840576
INFO:root:current mean train loss 3349.901767012002
INFO:root:current train perplexity3.7435202598571777
INFO:root:current mean train loss 3350.595219615228
INFO:root:current train perplexity3.7464189529418945
INFO:root:current mean train loss 3344.5502665751687
INFO:root:current train perplexity3.7477080821990967
INFO:root:current mean train loss 3349.0657653206667
INFO:root:current train perplexity3.750898838043213
INFO:root:current mean train loss 3350.951020242355
INFO:root:current train perplexity3.749967098236084
INFO:root:current mean train loss 3355.2296396387687
INFO:root:current train perplexity3.7546279430389404
INFO:root:current mean train loss 3356.4959430907297
INFO:root:current train perplexity3.7557520866394043
INFO:root:current mean train loss 3356.797726127515
INFO:root:current train perplexity3.754659414291382

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.49s/it]
INFO:root:final mean train loss: 3354.6051489922306
INFO:root:final train perplexity: 3.7565038204193115
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it]
INFO:root:eval mean loss: 4042.6173866217864
INFO:root:eval perplexity: 5.127999782562256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [17:30:58<10:13:12, 504.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.087255859375
INFO:root:current train perplexity3.7605879306793213
INFO:root:current mean train loss 3332.2032502547554
INFO:root:current train perplexity3.7572312355041504
INFO:root:current mean train loss 3340.4578102289242
INFO:root:current train perplexity3.7578744888305664
INFO:root:current mean train loss 3345.4317824590776
INFO:root:current train perplexity3.7495720386505127
INFO:root:current mean train loss 3347.1610357445406
INFO:root:current train perplexity3.746835231781006
INFO:root:current mean train loss 3346.424306451001
INFO:root:current train perplexity3.7476494312286377
INFO:root:current mean train loss 3347.8159187627034
INFO:root:current train perplexity3.7455387115478516
INFO:root:current mean train loss 3349.4429673841782
INFO:root:current train perplexity3.7474186420440674
INFO:root:current mean train loss 3349.499213357937
INFO:root:current train perplexity3.7468061447143555
INFO:root:current mean train loss 3352.3304273928447
INFO:root:current train perplexity3.7507388591766357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.16s/it]
INFO:root:final mean train loss: 3351.5522628907233
INFO:root:final train perplexity: 3.7519824504852295
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 4042.733744736259
INFO:root:eval perplexity: 5.128241062164307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [17:39:03<9:58:01, 498.35s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.7567085597825
INFO:root:current train perplexity3.7410500049591064
INFO:root:current mean train loss 3356.0289832634653
INFO:root:current train perplexity3.747739791870117
INFO:root:current mean train loss 3354.6772997389994
INFO:root:current train perplexity3.7484447956085205
INFO:root:current mean train loss 3355.272536522833
INFO:root:current train perplexity3.7560713291168213
INFO:root:current mean train loss 3351.6161768847887
INFO:root:current train perplexity3.747602939605713
INFO:root:current mean train loss 3349.3176778352054
INFO:root:current train perplexity3.7481696605682373
INFO:root:current mean train loss 3350.8777055327046
INFO:root:current train perplexity3.7497198581695557
INFO:root:current mean train loss 3351.9297979204484
INFO:root:current train perplexity3.750439167022705
INFO:root:current mean train loss 3350.067372726496
INFO:root:current train perplexity3.7481799125671387
INFO:root:current mean train loss 3350.554804147904
INFO:root:current train perplexity3.747415065765381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.79s/it]
INFO:root:final mean train loss: 3349.2784116191247
INFO:root:final train perplexity: 3.7486181259155273
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 4042.668160945811
INFO:root:eval perplexity: 5.128106117248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [17:46:59<9:41:59, 491.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.8633836315526
INFO:root:current train perplexity3.7227723598480225
INFO:root:current mean train loss 3340.222290970897
INFO:root:current train perplexity3.7343380451202393
INFO:root:current mean train loss 3352.8040427996484
INFO:root:current train perplexity3.746673583984375
INFO:root:current mean train loss 3351.3716919314106
INFO:root:current train perplexity3.7451794147491455
INFO:root:current mean train loss 3348.418957207983
INFO:root:current train perplexity3.746305465698242
INFO:root:current mean train loss 3349.6499818848574
INFO:root:current train perplexity3.7484054565429688
INFO:root:current mean train loss 3350.0026429867025
INFO:root:current train perplexity3.746321201324463
INFO:root:current mean train loss 3350.5769958078617
INFO:root:current train perplexity3.7452516555786133
INFO:root:current mean train loss 3346.9537560638537
INFO:root:current train perplexity3.742177963256836
INFO:root:current mean train loss 3346.7129032122716
INFO:root:current train perplexity3.7414772510528564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.41s/it]
INFO:root:final mean train loss: 3345.511663313835
INFO:root:final train perplexity: 3.743051290512085
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 4046.836787663453
INFO:root:eval perplexity: 5.1367573738098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [17:55:00<9:29:45, 488.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.733943058894
INFO:root:current train perplexity3.7433924674987793
INFO:root:current mean train loss 3348.6755265709307
INFO:root:current train perplexity3.7444686889648438
INFO:root:current mean train loss 3345.91510341756
INFO:root:current train perplexity3.736759662628174
INFO:root:current mean train loss 3346.7860687165835
INFO:root:current train perplexity3.7379958629608154
INFO:root:current mean train loss 3345.7309008622224
INFO:root:current train perplexity3.7391066551208496
INFO:root:current mean train loss 3339.6877663352275
INFO:root:current train perplexity3.736602306365967
INFO:root:current mean train loss 3339.8075621698945
INFO:root:current train perplexity3.7372283935546875
INFO:root:current mean train loss 3340.4703502938937
INFO:root:current train perplexity3.735639810562134
INFO:root:current mean train loss 3344.8631401198413
INFO:root:current train perplexity3.738919496536255
INFO:root:current mean train loss 3345.230893331087
INFO:root:current train perplexity3.7400896549224854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.05s/it]
INFO:root:final mean train loss: 3343.330602645874
INFO:root:final train perplexity: 3.7398314476013184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 4045.726747769836
INFO:root:eval perplexity: 5.1344523429870605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [18:03:03<9:20:00, 486.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.330020985705
INFO:root:current train perplexity3.7235915660858154
INFO:root:current mean train loss 3335.3594945790815
INFO:root:current train perplexity3.720921277999878
INFO:root:current mean train loss 3337.3264842168524
INFO:root:current train perplexity3.733379364013672
INFO:root:current mean train loss 3334.6866324916696
INFO:root:current train perplexity3.7241756916046143
INFO:root:current mean train loss 3337.810718920407
INFO:root:current train perplexity3.726482391357422
INFO:root:current mean train loss 3338.2583083688014
INFO:root:current train perplexity3.7270240783691406
INFO:root:current mean train loss 3339.2643593931125
INFO:root:current train perplexity3.730721950531006
INFO:root:current mean train loss 3340.35968875502
INFO:root:current train perplexity3.7325525283813477
INFO:root:current mean train loss 3339.6212566064974
INFO:root:current train perplexity3.7318735122680664
INFO:root:current mean train loss 3340.4618668843223
INFO:root:current train perplexity3.7318997383117676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.35s/it]
INFO:root:final mean train loss: 3338.8666699317196
INFO:root:final train perplexity: 3.7332515716552734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 4045.899743046321
INFO:root:eval perplexity: 5.134810447692871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [18:11:43<9:23:03, 496.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.568399325284
INFO:root:current train perplexity3.716514825820923
INFO:root:current mean train loss 3316.1506883190523
INFO:root:current train perplexity3.7213971614837646
INFO:root:current mean train loss 3318.44536707261
INFO:root:current train perplexity3.7247419357299805
INFO:root:current mean train loss 3320.221963028169
INFO:root:current train perplexity3.7190937995910645
INFO:root:current mean train loss 3325.4127022879466
INFO:root:current train perplexity3.7197797298431396
INFO:root:current mean train loss 3328.4078696860925
INFO:root:current train perplexity3.721137285232544
INFO:root:current mean train loss 3330.299058847209
INFO:root:current train perplexity3.724400520324707
INFO:root:current mean train loss 3331.9644928989032
INFO:root:current train perplexity3.7249581813812256
INFO:root:current mean train loss 3334.7902526498538
INFO:root:current train perplexity3.7258529663085938
INFO:root:current mean train loss 3336.8309544748035
INFO:root:current train perplexity3.728383779525757

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.05s/it]
INFO:root:final mean train loss: 3336.613571905321
INFO:root:final train perplexity: 3.7299344539642334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 4048.460921916556
INFO:root:eval perplexity: 5.14013147354126
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [18:20:15<9:19:40, 501.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3321.6393926711307
INFO:root:current train perplexity3.721662998199463
INFO:root:current mean train loss 3318.8609701519363
INFO:root:current train perplexity3.713486909866333
INFO:root:current mean train loss 3326.3195995722435
INFO:root:current train perplexity3.721822738647461
INFO:root:current mean train loss 3328.6742693267906
INFO:root:current train perplexity3.7227110862731934
INFO:root:current mean train loss 3331.755908941347
INFO:root:current train perplexity3.722928524017334
INFO:root:current mean train loss 3339.2734188533805
INFO:root:current train perplexity3.7263314723968506
INFO:root:current mean train loss 3335.7496947321597
INFO:root:current train perplexity3.722200632095337
INFO:root:current mean train loss 3333.8912006343176
INFO:root:current train perplexity3.7210423946380615
INFO:root:current mean train loss 3333.9807629634993
INFO:root:current train perplexity3.7221434116363525
INFO:root:current mean train loss 3336.256407233661
INFO:root:current train perplexity3.725092649459839

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it]
INFO:root:final mean train loss: 3333.4881311232043
INFO:root:final train perplexity: 3.7253377437591553
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 4048.2708645002217
INFO:root:eval perplexity: 5.139736652374268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [18:28:30<9:09:29, 499.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3333.27968543684
INFO:root:current train perplexity3.7227048873901367
INFO:root:current mean train loss 3311.0637478298613
INFO:root:current train perplexity3.6928064823150635
INFO:root:current mean train loss 3313.015825898005
INFO:root:current train perplexity3.696833848953247
INFO:root:current mean train loss 3317.7921363028554
INFO:root:current train perplexity3.7027056217193604
INFO:root:current mean train loss 3322.4647634064822
INFO:root:current train perplexity3.7077784538269043
INFO:root:current mean train loss 3329.7725836491627
INFO:root:current train perplexity3.712470293045044
INFO:root:current mean train loss 3334.2932347213814
INFO:root:current train perplexity3.719864845275879
INFO:root:current mean train loss 3332.163185050361
INFO:root:current train perplexity3.718442916870117
INFO:root:current mean train loss 3332.9710251888096
INFO:root:current train perplexity3.7200262546539307
INFO:root:current mean train loss 3331.3967662304485
INFO:root:current train perplexity3.718449592590332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.16s/it]
INFO:root:final mean train loss: 3329.6152341288903
INFO:root:final train perplexity: 3.7196497917175293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 4050.6234312666224
INFO:root:eval perplexity: 5.144628524780273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [18:37:12<9:08:12, 506.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3332.2034587618673
INFO:root:current train perplexity3.7093098163604736
INFO:root:current mean train loss 3326.04132114176
INFO:root:current train perplexity3.723813056945801
INFO:root:current mean train loss 3325.743478207605
INFO:root:current train perplexity3.718261241912842
INFO:root:current mean train loss 3330.718851134771
INFO:root:current train perplexity3.720472812652588
INFO:root:current mean train loss 3332.7798498866455
INFO:root:current train perplexity3.7208404541015625
INFO:root:current mean train loss 3334.0002142028284
INFO:root:current train perplexity3.720393419265747
INFO:root:current mean train loss 3336.749767365266
INFO:root:current train perplexity3.720702648162842
INFO:root:current mean train loss 3336.0583047928035
INFO:root:current train perplexity3.718615770339966
INFO:root:current mean train loss 3334.968297270513
INFO:root:current train perplexity3.7191386222839355
INFO:root:current mean train loss 3331.4616557073546
INFO:root:current train perplexity3.717984676361084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.52s/it]
INFO:root:final mean train loss: 3328.890744978382
INFO:root:final train perplexity: 3.7185866832733154
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 4051.130414381095
INFO:root:eval perplexity: 5.145683288574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [18:45:59<9:06:29, 512.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3304.721185793822
INFO:root:current train perplexity3.6987783908843994
INFO:root:current mean train loss 3320.8692320145387
INFO:root:current train perplexity3.707420825958252
INFO:root:current mean train loss 3318.902218702363
INFO:root:current train perplexity3.70353364944458
INFO:root:current mean train loss 3326.5013115461484
INFO:root:current train perplexity3.708935499191284
INFO:root:current mean train loss 3330.685068620059
INFO:root:current train perplexity3.7121074199676514
INFO:root:current mean train loss 3328.934274598728
INFO:root:current train perplexity3.7088208198547363
INFO:root:current mean train loss 3328.7677636292306
INFO:root:current train perplexity3.709632635116577
INFO:root:current mean train loss 3325.4710189257066
INFO:root:current train perplexity3.707411289215088
INFO:root:current mean train loss 3325.7596081859497
INFO:root:current train perplexity3.7087554931640625
INFO:root:current mean train loss 3326.4446025875445
INFO:root:current train perplexity3.7114272117614746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.55s/it]
INFO:root:final mean train loss: 3324.126793461461
INFO:root:final train perplexity: 3.711604595184326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 4050.8584278728945
INFO:root:eval perplexity: 5.14511775970459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [18:54:43<9:01:47, 516.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3305.507894736842
INFO:root:current train perplexity3.690929412841797
INFO:root:current mean train loss 3320.241516426282
INFO:root:current train perplexity3.699552297592163
INFO:root:current mean train loss 3321.798000529661
INFO:root:current train perplexity3.704127550125122
INFO:root:current mean train loss 3320.27309199466
INFO:root:current train perplexity3.7052135467529297
INFO:root:current mean train loss 3318.8824356849746
INFO:root:current train perplexity3.7056381702423096
INFO:root:current mean train loss 3321.508348788734
INFO:root:current train perplexity3.708150625228882
INFO:root:current mean train loss 3319.798542533161
INFO:root:current train perplexity3.7065906524658203
INFO:root:current mean train loss 3323.629306394949
INFO:root:current train perplexity3.710050582885742
INFO:root:current mean train loss 3323.5931575157124
INFO:root:current train perplexity3.7086174488067627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.33s/it]
INFO:root:final mean train loss: 3322.0666790008545
INFO:root:final train perplexity: 3.7085888385772705
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.38s/it]
INFO:root:eval mean loss: 4053.3315672096633
INFO:root:eval perplexity: 5.150266647338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [19:03:32<8:57:21, 520.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3376.6883138020835
INFO:root:current train perplexity3.562230110168457
INFO:root:current mean train loss 3290.3447218219053
INFO:root:current train perplexity3.66200590133667
INFO:root:current mean train loss 3296.9339846155326
INFO:root:current train perplexity3.6731643676757812
INFO:root:current mean train loss 3305.65407448948
INFO:root:current train perplexity3.6867525577545166
INFO:root:current mean train loss 3311.9799883442543
INFO:root:current train perplexity3.687077522277832
INFO:root:current mean train loss 3314.2653167906624
INFO:root:current train perplexity3.689300298690796
INFO:root:current mean train loss 3316.0368741416614
INFO:root:current train perplexity3.691594123840332
INFO:root:current mean train loss 3316.9620943028763
INFO:root:current train perplexity3.6951076984405518
INFO:root:current mean train loss 3319.434273573708
INFO:root:current train perplexity3.6981496810913086
INFO:root:current mean train loss 3319.8885799505124
INFO:root:current train perplexity3.700664758682251

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.75s/it]
INFO:root:final mean train loss: 3318.710038954212
INFO:root:final train perplexity: 3.7036807537078857
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 4053.893849041445
INFO:root:eval perplexity: 5.151437282562256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [19:12:21<8:51:14, 522.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.4406960227275
INFO:root:current train perplexity3.6423068046569824
INFO:root:current mean train loss 3314.523701435811
INFO:root:current train perplexity3.6969361305236816
INFO:root:current mean train loss 3313.3471066443276
INFO:root:current train perplexity3.690730571746826
INFO:root:current mean train loss 3302.406723365906
INFO:root:current train perplexity3.6786937713623047
INFO:root:current mean train loss 3307.013692071548
INFO:root:current train perplexity3.683657646179199
INFO:root:current mean train loss 3307.915634364298
INFO:root:current train perplexity3.6900744438171387
INFO:root:current mean train loss 3310.2939369214146
INFO:root:current train perplexity3.690502166748047
INFO:root:current mean train loss 3313.0074450872453
INFO:root:current train perplexity3.6911637783050537
INFO:root:current mean train loss 3315.3193010172627
INFO:root:current train perplexity3.6960866451263428
INFO:root:current mean train loss 3317.5031633764406
INFO:root:current train perplexity3.6971240043640137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.30s/it]
INFO:root:final mean train loss: 3315.0239819557437
INFO:root:final train perplexity: 3.6982991695404053
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 4055.2475551307625
INFO:root:eval perplexity: 5.154256820678711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [19:20:51<8:38:49, 518.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3290.9020739103617
INFO:root:current train perplexity3.6686816215515137
INFO:root:current mean train loss 3292.1871778985033
INFO:root:current train perplexity3.6760036945343018
INFO:root:current mean train loss 3291.489700387058
INFO:root:current train perplexity3.6850688457489014
INFO:root:current mean train loss 3300.0128682773316
INFO:root:current train perplexity3.686739921569824
INFO:root:current mean train loss 3304.294537309815
INFO:root:current train perplexity3.6887013912200928
INFO:root:current mean train loss 3308.1998171062137
INFO:root:current train perplexity3.6914942264556885
INFO:root:current mean train loss 3306.2151971425687
INFO:root:current train perplexity3.689434051513672
INFO:root:current mean train loss 3309.490450672049
INFO:root:current train perplexity3.6911497116088867
INFO:root:current mean train loss 3311.0260100684905
INFO:root:current train perplexity3.691734552383423
INFO:root:current mean train loss 3313.0687421896255
INFO:root:current train perplexity3.6923916339874268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.86s/it]
INFO:root:final mean train loss: 3313.410534151139
INFO:root:final train perplexity: 3.6959452629089355
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it]
INFO:root:eval mean loss: 4053.903883047983
INFO:root:eval perplexity: 5.151458263397217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [19:28:50<8:18:33, 507.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.836009837963
INFO:root:current train perplexity3.7050352096557617
INFO:root:current mean train loss 3305.843540461983
INFO:root:current train perplexity3.6924097537994385
INFO:root:current mean train loss 3305.8077935710353
INFO:root:current train perplexity3.6908910274505615
INFO:root:current mean train loss 3306.7741691752676
INFO:root:current train perplexity3.69402813911438
INFO:root:current mean train loss 3311.1777126481998
INFO:root:current train perplexity3.693561553955078
INFO:root:current mean train loss 3310.472628917368
INFO:root:current train perplexity3.690207004547119
INFO:root:current mean train loss 3311.1072548314146
INFO:root:current train perplexity3.69169282913208
INFO:root:current mean train loss 3311.4627808120918
INFO:root:current train perplexity3.6922786235809326
INFO:root:current mean train loss 3311.8940792798708
INFO:root:current train perplexity3.693089008331299
INFO:root:current mean train loss 3311.6693861878034
INFO:root:current train perplexity3.6908962726593018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.20s/it]
INFO:root:final mean train loss: 3310.0498451109856
INFO:root:final train perplexity: 3.6910476684570312
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 4057.9148763020835
INFO:root:eval perplexity: 5.159820079803467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [19:36:52<8:02:36, 499.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.8392368861605
INFO:root:current train perplexity3.695438861846924
INFO:root:current mean train loss 3335.0085720486113
INFO:root:current train perplexity3.677568197250366
INFO:root:current mean train loss 3322.4022637549865
INFO:root:current train perplexity3.67750883102417
INFO:root:current mean train loss 3320.3167174381997
INFO:root:current train perplexity3.6795685291290283
INFO:root:current mean train loss 3313.974975305316
INFO:root:current train perplexity3.6824331283569336
INFO:root:current mean train loss 3317.6030533549942
INFO:root:current train perplexity3.6858294010162354
INFO:root:current mean train loss 3313.5448953463338
INFO:root:current train perplexity3.682013988494873
INFO:root:current mean train loss 3310.839016993516
INFO:root:current train perplexity3.6829802989959717
INFO:root:current mean train loss 3309.24983626497
INFO:root:current train perplexity3.6853175163269043
INFO:root:current mean train loss 3309.0987900025066
INFO:root:current train perplexity3.6867165565490723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.02s/it]
INFO:root:final mean train loss: 3307.769489780549
INFO:root:final train perplexity: 3.6877293586730957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 4056.6871952570923
INFO:root:eval perplexity: 5.1572585105896
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [19:45:21<7:57:03, 502.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.611322447311
INFO:root:current train perplexity3.661543607711792
INFO:root:current mean train loss 3292.905881228147
INFO:root:current train perplexity3.659684658050537
INFO:root:current mean train loss 3291.818408605003
INFO:root:current train perplexity3.663400173187256
INFO:root:current mean train loss 3297.3910983338646
INFO:root:current train perplexity3.6655240058898926
INFO:root:current mean train loss 3299.128586056539
INFO:root:current train perplexity3.6698293685913086
INFO:root:current mean train loss 3302.12474821593
INFO:root:current train perplexity3.674497604370117
INFO:root:current mean train loss 3305.1937895636906
INFO:root:current train perplexity3.677917003631592
INFO:root:current mean train loss 3302.754695846126
INFO:root:current train perplexity3.6789321899414062
INFO:root:current mean train loss 3304.81044203644
INFO:root:current train perplexity3.6813204288482666
INFO:root:current mean train loss 3306.0242118633187
INFO:root:current train perplexity3.6843464374542236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.86s/it]
INFO:root:final mean train loss: 3306.011646270752
INFO:root:final train perplexity: 3.6851720809936523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 4059.1883969137853
INFO:root:eval perplexity: 5.162478446960449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [19:54:08<7:55:45, 509.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3301.472708907782
INFO:root:current train perplexity3.6509735584259033
INFO:root:current mean train loss 3297.6761838395073
INFO:root:current train perplexity3.6673521995544434
INFO:root:current mean train loss 3296.883606200199
INFO:root:current train perplexity3.6642560958862305
INFO:root:current mean train loss 3293.354252915776
INFO:root:current train perplexity3.665893316268921
INFO:root:current mean train loss 3297.4549768959605
INFO:root:current train perplexity3.6682889461517334
INFO:root:current mean train loss 3298.9826642432795
INFO:root:current train perplexity3.6727712154388428
INFO:root:current mean train loss 3303.2888149841588
INFO:root:current train perplexity3.6759397983551025
INFO:root:current mean train loss 3305.0751312702855
INFO:root:current train perplexity3.6784002780914307
INFO:root:current mean train loss 3304.7720016318117
INFO:root:current train perplexity3.6788949966430664
INFO:root:current mean train loss 3303.219937586258
INFO:root:current train perplexity3.6788339614868164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.04s/it]
INFO:root:final mean train loss: 3302.3845363739997
INFO:root:final train perplexity: 3.6799025535583496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it]
INFO:root:eval mean loss: 4058.744294727948
INFO:root:eval perplexity: 5.161550521850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [20:02:18<7:41:55, 503.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3307.793295650159
INFO:root:current train perplexity3.6661524772644043
INFO:root:current mean train loss 3297.0780236586083
INFO:root:current train perplexity3.6622402667999268
INFO:root:current mean train loss 3293.195710288972
INFO:root:current train perplexity3.6663036346435547
INFO:root:current mean train loss 3294.834196552925
INFO:root:current train perplexity3.670063018798828
INFO:root:current mean train loss 3298.2638250612745
INFO:root:current train perplexity3.672244071960449
INFO:root:current mean train loss 3299.7567865852807
INFO:root:current train perplexity3.6741909980773926
INFO:root:current mean train loss 3303.752069082535
INFO:root:current train perplexity3.675422430038452
INFO:root:current mean train loss 3303.620639243145
INFO:root:current train perplexity3.6773862838745117
INFO:root:current mean train loss 3304.167984666036
INFO:root:current train perplexity3.678102970123291
INFO:root:current mean train loss 3303.2766518060807
INFO:root:current train perplexity3.678001642227173

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.97s/it]
INFO:root:final mean train loss: 3301.5167508894397
INFO:root:final train perplexity: 3.678642749786377
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 4061.2472902122117
INFO:root:eval perplexity: 5.166777610778809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [20:10:17<7:26:44, 496.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.501082235308
INFO:root:current train perplexity3.6649913787841797
INFO:root:current mean train loss 3310.5696224738026
INFO:root:current train perplexity3.6643126010894775
INFO:root:current mean train loss 3305.085716218984
INFO:root:current train perplexity3.667630434036255
INFO:root:current mean train loss 3306.1722721442866
INFO:root:current train perplexity3.6654679775238037
INFO:root:current mean train loss 3301.2897823750336
INFO:root:current train perplexity3.6646816730499268
INFO:root:current mean train loss 3298.3804554880403
INFO:root:current train perplexity3.66628360748291
INFO:root:current mean train loss 3300.4634067243724
INFO:root:current train perplexity3.6688477993011475
INFO:root:current mean train loss 3299.4931083589677
INFO:root:current train perplexity3.6675992012023926
INFO:root:current mean train loss 3300.4492212843315
INFO:root:current train perplexity3.6710762977600098
INFO:root:current mean train loss 3300.9089774572617
INFO:root:current train perplexity3.672632932662964

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:20<00:00, 440.65s/it]
INFO:root:final mean train loss: 3297.8445560086157
INFO:root:final train perplexity: 3.6733171939849854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 4060.6140431072695
INFO:root:eval perplexity: 5.165454387664795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [20:18:56<7:24:21, 503.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3273.149873046875
INFO:root:current train perplexity3.6428542137145996
INFO:root:current mean train loss 3292.980249720982
INFO:root:current train perplexity3.6660916805267334
INFO:root:current mean train loss 3298.3470339133523
INFO:root:current train perplexity3.6715152263641357
INFO:root:current mean train loss 3293.5387102864584
INFO:root:current train perplexity3.6669602394104004
INFO:root:current mean train loss 3292.7143971011515
INFO:root:current train perplexity3.6636385917663574
INFO:root:current mean train loss 3294.2305201256795
INFO:root:current train perplexity3.663910150527954
INFO:root:current mean train loss 3296.267298900463
INFO:root:current train perplexity3.6646480560302734
INFO:root:current mean train loss 3297.087664755544
INFO:root:current train perplexity3.6644766330718994
INFO:root:current mean train loss 3300.8348125
INFO:root:current train perplexity3.6694724559783936
INFO:root:current mean train loss 3299.023958333333
INFO:root:current train perplexity3.670226573944092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.42s/it]
INFO:root:final mean train loss: 3296.1180874609176
INFO:root:final train perplexity: 3.670815944671631
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it]
INFO:root:eval mean loss: 4061.5354609929077
INFO:root:eval perplexity: 5.167379379272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [20:28:05<7:27:53, 516.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.7263418910015
INFO:root:current train perplexity3.668869972229004
INFO:root:current mean train loss 3287.630413785007
INFO:root:current train perplexity3.662050485610962
INFO:root:current mean train loss 3289.1136228743376
INFO:root:current train perplexity3.6591973304748535
INFO:root:current mean train loss 3292.5522384444353
INFO:root:current train perplexity3.660240411758423
INFO:root:current mean train loss 3293.5464443420033
INFO:root:current train perplexity3.6604561805725098
INFO:root:current mean train loss 3291.6887131653357
INFO:root:current train perplexity3.662053108215332
INFO:root:current mean train loss 3292.25976776972
INFO:root:current train perplexity3.66215181350708
INFO:root:current mean train loss 3291.677617761215
INFO:root:current train perplexity3.6615145206451416
INFO:root:current mean train loss 3292.804004016846
INFO:root:current train perplexity3.6633219718933105
INFO:root:current mean train loss 3294.6263863611075
INFO:root:current train perplexity3.6648406982421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.81s/it]
INFO:root:final mean train loss: 3292.5251725719822
INFO:root:final train perplexity: 3.665616273880005
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 4062.2165129100176
INFO:root:eval perplexity: 5.168802738189697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [20:36:45<7:20:11, 517.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.5774864783652
INFO:root:current train perplexity3.650264263153076
INFO:root:current mean train loss 3283.120559452716
INFO:root:current train perplexity3.6477835178375244
INFO:root:current mean train loss 3284.779780961394
INFO:root:current train perplexity3.651766777038574
INFO:root:current mean train loss 3285.424960163243
INFO:root:current train perplexity3.650972366333008
INFO:root:current mean train loss 3284.659163278863
INFO:root:current train perplexity3.6510088443756104
INFO:root:current mean train loss 3284.0214455438345
INFO:root:current train perplexity3.6518542766571045
INFO:root:current mean train loss 3288.205677700457
INFO:root:current train perplexity3.655287027359009
INFO:root:current mean train loss 3288.8781154936396
INFO:root:current train perplexity3.659416437149048
INFO:root:current mean train loss 3289.9553293898184
INFO:root:current train perplexity3.659295082092285
INFO:root:current mean train loss 3292.1521126663406
INFO:root:current train perplexity3.6614058017730713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.81s/it]
INFO:root:final mean train loss: 3289.5927975562313
INFO:root:final train perplexity: 3.6613781452178955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 4063.6458748891846
INFO:root:eval perplexity: 5.17179012298584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [20:45:05<7:07:06, 512.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.0493435329863
INFO:root:current train perplexity3.666168212890625
INFO:root:current mean train loss 3282.134753356627
INFO:root:current train perplexity3.647409439086914
INFO:root:current mean train loss 3282.8729570573787
INFO:root:current train perplexity3.648117780685425
INFO:root:current mean train loss 3279.764925007832
INFO:root:current train perplexity3.644801616668701
INFO:root:current mean train loss 3281.9963892629007
INFO:root:current train perplexity3.6463332176208496
INFO:root:current mean train loss 3284.0588978049354
INFO:root:current train perplexity3.651648759841919
INFO:root:current mean train loss 3283.6710755180393
INFO:root:current train perplexity3.653996229171753
INFO:root:current mean train loss 3282.00932714966
INFO:root:current train perplexity3.6537134647369385
INFO:root:current mean train loss 3286.495467240076
INFO:root:current train perplexity3.6555585861206055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.62s/it]
INFO:root:final mean train loss: 3287.0212789966213
INFO:root:final train perplexity: 3.6576647758483887
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 4063.754574606605
INFO:root:eval perplexity: 5.1720194816589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [20:53:40<6:59:02, 513.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.840750558036
INFO:root:current train perplexity3.6644487380981445
INFO:root:current mean train loss 3288.08376989632
INFO:root:current train perplexity3.6554322242736816
INFO:root:current mean train loss 3285.6086661665913
INFO:root:current train perplexity3.6566965579986572
INFO:root:current mean train loss 3282.8092283565757
INFO:root:current train perplexity3.658465623855591
INFO:root:current mean train loss 3282.6006933113867
INFO:root:current train perplexity3.656512975692749
INFO:root:current mean train loss 3284.7231999083147
INFO:root:current train perplexity3.6539998054504395
INFO:root:current mean train loss 3283.7638987206547
INFO:root:current train perplexity3.6534740924835205
INFO:root:current mean train loss 3288.5583768895863
INFO:root:current train perplexity3.654043674468994
INFO:root:current mean train loss 3289.9219736243417
INFO:root:current train perplexity3.655989646911621
INFO:root:current mean train loss 3292.4745383131203
INFO:root:current train perplexity3.658034324645996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.23s/it]
INFO:root:final mean train loss: 3286.723692494054
INFO:root:final train perplexity: 3.657235860824585
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 4066.425123282358
INFO:root:eval perplexity: 5.177606582641602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [21:02:15<6:51:08, 513.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.7607584635416
INFO:root:current train perplexity3.645634174346924
INFO:root:current mean train loss 3284.1198985224187
INFO:root:current train perplexity3.64749813079834
INFO:root:current mean train loss 3283.2421693313954
INFO:root:current train perplexity3.6500184535980225
INFO:root:current mean train loss 3276.3641578311012
INFO:root:current train perplexity3.645007610321045
INFO:root:current mean train loss 3281.696149637613
INFO:root:current train perplexity3.646812677383423
INFO:root:current mean train loss 3285.077895555218
INFO:root:current train perplexity3.651498556137085
INFO:root:current mean train loss 3285.9987130017785
INFO:root:current train perplexity3.6486597061157227
INFO:root:current mean train loss 3287.759671041849
INFO:root:current train perplexity3.6515002250671387
INFO:root:current mean train loss 3286.144147514858
INFO:root:current train perplexity3.652482509613037
INFO:root:current mean train loss 3286.118173934853
INFO:root:current train perplexity3.653062105178833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.49s/it]
INFO:root:final mean train loss: 3284.023026927825
INFO:root:final train perplexity: 3.653341054916382
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 4065.217789020944
INFO:root:eval perplexity: 5.175078868865967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [21:10:13<6:34:09, 503.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.9877080502715
INFO:root:current train perplexity3.608593702316284
INFO:root:current mean train loss 3273.0041841336383
INFO:root:current train perplexity3.6380996704101562
INFO:root:current mean train loss 3274.517702932315
INFO:root:current train perplexity3.635446786880493
INFO:root:current mean train loss 3274.5163959703946
INFO:root:current train perplexity3.634641170501709
INFO:root:current mean train loss 3276.0397943447106
INFO:root:current train perplexity3.638864755630493
INFO:root:current mean train loss 3278.6837505975145
INFO:root:current train perplexity3.6403250694274902
INFO:root:current mean train loss 3278.704986033432
INFO:root:current train perplexity3.643545389175415
INFO:root:current mean train loss 3281.8898567843403
INFO:root:current train perplexity3.6468191146850586
INFO:root:current mean train loss 3284.2541462375643
INFO:root:current train perplexity3.6471822261810303
INFO:root:current mean train loss 3284.881921638001
INFO:root:current train perplexity3.6493349075317383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.06s/it]
INFO:root:final mean train loss: 3282.153864029915
INFO:root:final train perplexity: 3.6506476402282715
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 4066.926582931627
INFO:root:eval perplexity: 5.178656578063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [21:18:14<6:20:31, 496.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.894822643649
INFO:root:current train perplexity3.6699421405792236
INFO:root:current mean train loss 3278.2804877594226
INFO:root:current train perplexity3.6496176719665527
INFO:root:current mean train loss 3274.738074100379
INFO:root:current train perplexity3.637554168701172
INFO:root:current mean train loss 3277.8957858820336
INFO:root:current train perplexity3.6432971954345703
INFO:root:current mean train loss 3275.250802095418
INFO:root:current train perplexity3.646726608276367
INFO:root:current mean train loss 3274.3831573313914
INFO:root:current train perplexity3.6456410884857178
INFO:root:current mean train loss 3278.8701438843354
INFO:root:current train perplexity3.6495285034179688
INFO:root:current mean train loss 3281.811744199406
INFO:root:current train perplexity3.6522374153137207
INFO:root:current mean train loss 3284.1823010679905
INFO:root:current train perplexity3.6493096351623535
INFO:root:current mean train loss 3282.3697065277593
INFO:root:current train perplexity3.6483652591705322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.03s/it]
INFO:root:final mean train loss: 3280.4576761799476
INFO:root:final train perplexity: 3.6482057571411133
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 4068.762104873116
INFO:root:eval perplexity: 5.182501792907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [21:27:00<6:18:58, 505.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3321.051770332532
INFO:root:current train perplexity3.6511011123657227
INFO:root:current mean train loss 3278.543669556542
INFO:root:current train perplexity3.6319961547851562
INFO:root:current mean train loss 3281.412891850811
INFO:root:current train perplexity3.6391971111297607
INFO:root:current mean train loss 3278.8916779014567
INFO:root:current train perplexity3.6429011821746826
INFO:root:current mean train loss 3275.3907540219247
INFO:root:current train perplexity3.645996570587158
INFO:root:current mean train loss 3276.7436768031075
INFO:root:current train perplexity3.6434028148651123
INFO:root:current mean train loss 3277.3217234723443
INFO:root:current train perplexity3.642526388168335
INFO:root:current mean train loss 3278.9229539760236
INFO:root:current train perplexity3.642235517501831
INFO:root:current mean train loss 3278.717170797173
INFO:root:current train perplexity3.6399333477020264
INFO:root:current mean train loss 3279.990403115432
INFO:root:current train perplexity3.6437768936157227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.27s/it]
INFO:root:final mean train loss: 3277.2288418431435
INFO:root:final train perplexity: 3.643561363220215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it]
INFO:root:eval mean loss: 4067.475670780696
INFO:root:eval perplexity: 5.179806709289551
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [21:35:58<6:17:42, 515.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3267.8057783410904
INFO:root:current train perplexity3.591536283493042
INFO:root:current mean train loss 3280.8437649473854
INFO:root:current train perplexity3.6239094734191895
INFO:root:current mean train loss 3270.0035988502655
INFO:root:current train perplexity3.6234018802642822
INFO:root:current mean train loss 3273.3231704228206
INFO:root:current train perplexity3.628798484802246
INFO:root:current mean train loss 3275.673765314772
INFO:root:current train perplexity3.633939504623413
INFO:root:current mean train loss 3270.991709930587
INFO:root:current train perplexity3.63289737701416
INFO:root:current mean train loss 3271.50020036889
INFO:root:current train perplexity3.634990930557251
INFO:root:current mean train loss 3275.1575837856635
INFO:root:current train perplexity3.637979030609131
INFO:root:current mean train loss 3278.3379182961926
INFO:root:current train perplexity3.640026569366455
INFO:root:current mean train loss 3279.188194266846
INFO:root:current train perplexity3.6414172649383545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.49s/it]
INFO:root:final mean train loss: 3276.694455300608
INFO:root:final train perplexity: 3.6427931785583496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.49s/it]
INFO:root:eval mean loss: 4069.477066364694
INFO:root:eval perplexity: 5.1840009689331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [21:45:14<6:18:00, 527.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.5338600852274
INFO:root:current train perplexity3.6592371463775635
INFO:root:current mean train loss 3250.8355941280242
INFO:root:current train perplexity3.633929967880249
INFO:root:current mean train loss 3264.035623468137
INFO:root:current train perplexity3.6365933418273926
INFO:root:current mean train loss 3269.322880446743
INFO:root:current train perplexity3.6400105953216553
INFO:root:current mean train loss 3271.19585819454
INFO:root:current train perplexity3.6402878761291504
INFO:root:current mean train loss 3273.889380542652
INFO:root:current train perplexity3.638791084289551
INFO:root:current mean train loss 3277.5015382723045
INFO:root:current train perplexity3.6415677070617676
INFO:root:current mean train loss 3277.629652576573
INFO:root:current train perplexity3.641195058822632
INFO:root:current mean train loss 3279.21909522341
INFO:root:current train perplexity3.642808675765991
INFO:root:current mean train loss 3278.1011744314465
INFO:root:current train perplexity3.640796422958374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.05s/it]
INFO:root:final mean train loss: 3275.1518938618324
INFO:root:final train perplexity: 3.6405768394470215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 4068.8296954648713
INFO:root:eval perplexity: 5.182643890380859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [21:55:06<6:22:49, 546.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3287.810980902778
INFO:root:current train perplexity3.6324217319488525
INFO:root:current mean train loss 3281.8138030818636
INFO:root:current train perplexity3.6277525424957275
INFO:root:current mean train loss 3277.5651976146623
INFO:root:current train perplexity3.627513885498047
INFO:root:current mean train loss 3269.3362300652116
INFO:root:current train perplexity3.6292760372161865
INFO:root:current mean train loss 3273.040378644708
INFO:root:current train perplexity3.636871099472046
INFO:root:current mean train loss 3273.6929300691054
INFO:root:current train perplexity3.635344982147217
INFO:root:current mean train loss 3271.839313489819
INFO:root:current train perplexity3.637348175048828
INFO:root:current mean train loss 3276.432859408277
INFO:root:current train perplexity3.6378889083862305
INFO:root:current mean train loss 3274.8414466477766
INFO:root:current train perplexity3.6371257305145264
INFO:root:current mean train loss 3274.522610261309
INFO:root:current train perplexity3.6358447074890137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.09s/it]
INFO:root:final mean train loss: 3272.1036885169246
INFO:root:final train perplexity: 3.636201858520508
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 4070.8068033854165
INFO:root:eval perplexity: 5.186788558959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [22:04:31<6:17:15, 552.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.379329197843
INFO:root:current train perplexity3.6448581218719482
INFO:root:current mean train loss 3265.9436320700843
INFO:root:current train perplexity3.624178647994995
INFO:root:current mean train loss 3264.9162327389877
INFO:root:current train perplexity3.6218996047973633
INFO:root:current mean train loss 3261.3895444638647
INFO:root:current train perplexity3.6269404888153076
INFO:root:current mean train loss 3266.1760150237196
INFO:root:current train perplexity3.629023313522339
INFO:root:current mean train loss 3266.1496466588223
INFO:root:current train perplexity3.63067889213562
INFO:root:current mean train loss 3268.0577932889346
INFO:root:current train perplexity3.6282801628112793
INFO:root:current mean train loss 3270.197657009971
INFO:root:current train perplexity3.629520893096924
INFO:root:current mean train loss 3271.7925721265965
INFO:root:current train perplexity3.633518695831299
INFO:root:current mean train loss 3271.968888790551
INFO:root:current train perplexity3.633368968963623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.06s/it]
INFO:root:final mean train loss: 3269.832324920162
INFO:root:final train perplexity: 3.632944107055664
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 4070.4628611896055
INFO:root:eval perplexity: 5.186067581176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [22:14:08<6:13:08, 559.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.557400860364
INFO:root:current train perplexity3.6099038124084473
INFO:root:current mean train loss 3258.5465476606146
INFO:root:current train perplexity3.625579595565796
INFO:root:current mean train loss 3264.5620992243503
INFO:root:current train perplexity3.627906084060669
INFO:root:current mean train loss 3271.678700630772
INFO:root:current train perplexity3.6283230781555176
INFO:root:current mean train loss 3270.1368278232644
INFO:root:current train perplexity3.6277902126312256
INFO:root:current mean train loss 3272.406478960897
INFO:root:current train perplexity3.6290037631988525
INFO:root:current mean train loss 3268.285163800741
INFO:root:current train perplexity3.6294705867767334
INFO:root:current mean train loss 3269.960929664935
INFO:root:current train perplexity3.6305594444274902
INFO:root:current mean train loss 3268.4473183971486
INFO:root:current train perplexity3.6308891773223877
INFO:root:current mean train loss 3270.5868327654175
INFO:root:current train perplexity3.6315550804138184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.86s/it]
INFO:root:final mean train loss: 3268.7422562876054
INFO:root:final train perplexity: 3.631382703781128
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 4072.7890486480496
INFO:root:eval perplexity: 5.190947532653809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [22:23:07<5:59:42, 553.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3262.0352151804955
INFO:root:current train perplexity3.606379508972168
INFO:root:current mean train loss 3259.067164783172
INFO:root:current train perplexity3.610987663269043
INFO:root:current mean train loss 3265.5700930286366
INFO:root:current train perplexity3.6153311729431152
INFO:root:current mean train loss 3269.080091372941
INFO:root:current train perplexity3.62152099609375
INFO:root:current mean train loss 3266.3326644114154
INFO:root:current train perplexity3.62153959274292
INFO:root:current mean train loss 3267.5446253294026
INFO:root:current train perplexity3.621173858642578
INFO:root:current mean train loss 3266.57180968261
INFO:root:current train perplexity3.621828317642212
INFO:root:current mean train loss 3266.8414882092798
INFO:root:current train perplexity3.6228599548339844
INFO:root:current mean train loss 3267.2606854874225
INFO:root:current train perplexity3.6251375675201416
INFO:root:current mean train loss 3270.0178197920623
INFO:root:current train perplexity3.6296637058258057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.12s/it]
INFO:root:final mean train loss: 3267.2751858003676
INFO:root:final train perplexity: 3.6292808055877686
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it]
INFO:root:eval mean loss: 4073.3954939605496
INFO:root:eval perplexity: 5.192220687866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [22:31:52<5:45:02, 544.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.0806563527963
INFO:root:current train perplexity3.6238598823547363
INFO:root:current mean train loss 3269.8174516726763
INFO:root:current train perplexity3.6317505836486816
INFO:root:current mean train loss 3266.1023594743115
INFO:root:current train perplexity3.621981620788574
INFO:root:current mean train loss 3270.5268258010283
INFO:root:current train perplexity3.621007204055786
INFO:root:current mean train loss 3272.407417929293
INFO:root:current train perplexity3.624596118927002
INFO:root:current mean train loss 3271.061539850315
INFO:root:current train perplexity3.6236045360565186
INFO:root:current mean train loss 3269.4748591361285
INFO:root:current train perplexity3.621530532836914
INFO:root:current mean train loss 3267.0062951429836
INFO:root:current train perplexity3.6222643852233887
INFO:root:current mean train loss 3267.8814916855795
INFO:root:current train perplexity3.6244194507598877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.69s/it]
INFO:root:final mean train loss: 3264.867731525052
INFO:root:final train perplexity: 3.625835418701172
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 4073.2870643561614
INFO:root:eval perplexity: 5.191993713378906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [22:40:41<5:33:04, 540.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.5653483072915
INFO:root:current train perplexity3.629030227661133
INFO:root:current mean train loss 3232.8826963554307
INFO:root:current train perplexity3.613607168197632
INFO:root:current mean train loss 3258.147697862146
INFO:root:current train perplexity3.6278886795043945
INFO:root:current mean train loss 3257.0569621171103
INFO:root:current train perplexity3.625495433807373
INFO:root:current mean train loss 3256.605422708592
INFO:root:current train perplexity3.6269469261169434
INFO:root:current mean train loss 3259.0050201719373
INFO:root:current train perplexity3.6261985301971436
INFO:root:current mean train loss 3261.1533300295396
INFO:root:current train perplexity3.6232991218566895
INFO:root:current mean train loss 3260.455626833659
INFO:root:current train perplexity3.6200780868530273
INFO:root:current mean train loss 3260.5673627461474
INFO:root:current train perplexity3.6204090118408203
INFO:root:current mean train loss 3264.5549424552705
INFO:root:current train perplexity3.6217479705810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.61s/it]
INFO:root:final mean train loss: 3262.5063135700843
INFO:root:final train perplexity: 3.6224591732025146
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 4073.9264998199246
INFO:root:eval perplexity: 5.193336009979248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [22:50:33<5:33:23, 555.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.450750177557
INFO:root:current train perplexity3.5958924293518066
INFO:root:current mean train loss 3259.9572929863457
INFO:root:current train perplexity3.6008541584014893
INFO:root:current mean train loss 3263.8416487707345
INFO:root:current train perplexity3.609938859939575
INFO:root:current mean train loss 3263.413520052502
INFO:root:current train perplexity3.6170356273651123
INFO:root:current mean train loss 3268.9217270899862
INFO:root:current train perplexity3.62455677986145
INFO:root:current mean train loss 3266.712101826229
INFO:root:current train perplexity3.6265289783477783
INFO:root:current mean train loss 3264.3387712893823
INFO:root:current train perplexity3.62351393699646
INFO:root:current mean train loss 3262.693328127747
INFO:root:current train perplexity3.621647834777832
INFO:root:current mean train loss 3263.436970777782
INFO:root:current train perplexity3.6205954551696777
INFO:root:current mean train loss 3263.5934313576254
INFO:root:current train perplexity3.6205854415893555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.34s/it]
INFO:root:final mean train loss: 3260.3493005691034
INFO:root:final train perplexity: 3.619378089904785
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it]
INFO:root:eval mean loss: 4073.738128878546
INFO:root:eval perplexity: 5.192940711975098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [23:00:36<5:32:25, 569.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.786017166941
INFO:root:current train perplexity3.6320555210113525
INFO:root:current mean train loss 3258.9699953223476
INFO:root:current train perplexity3.614905595779419
INFO:root:current mean train loss 3265.881839281892
INFO:root:current train perplexity3.6262123584747314
INFO:root:current mean train loss 3265.894274098746
INFO:root:current train perplexity3.62180757522583
INFO:root:current mean train loss 3263.2070930134996
INFO:root:current train perplexity3.621919870376587
INFO:root:current mean train loss 3260.574635059158
INFO:root:current train perplexity3.620534658432007
INFO:root:current mean train loss 3262.9530871365105
INFO:root:current train perplexity3.62090802192688
INFO:root:current mean train loss 3264.673819296549
INFO:root:current train perplexity3.6201889514923096
INFO:root:current mean train loss 3264.838367876698
INFO:root:current train perplexity3.6218602657318115
INFO:root:current mean train loss 3262.859131922011
INFO:root:current train perplexity3.618605852127075

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.47s/it]
INFO:root:final mean train loss: 3260.048959609001
INFO:root:final train perplexity: 3.6189486980438232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it]
INFO:root:eval mean loss: 4076.5611823332224
INFO:root:eval perplexity: 5.198872089385986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [23:11:09<5:33:46, 589.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.687843605324
INFO:root:current train perplexity3.6275155544281006
INFO:root:current mean train loss 3256.6336583415355
INFO:root:current train perplexity3.606105089187622
INFO:root:current mean train loss 3262.348124096572
INFO:root:current train perplexity3.61631178855896
INFO:root:current mean train loss 3258.118298451835
INFO:root:current train perplexity3.61411714553833
INFO:root:current mean train loss 3259.658041889271
INFO:root:current train perplexity3.6118814945220947
INFO:root:current mean train loss 3263.45959542146
INFO:root:current train perplexity3.61263370513916
INFO:root:current mean train loss 3262.8109012098785
INFO:root:current train perplexity3.6137332916259766
INFO:root:current mean train loss 3264.132801082144
INFO:root:current train perplexity3.6160106658935547
INFO:root:current mean train loss 3261.192983274448
INFO:root:current train perplexity3.616406202316284
INFO:root:current mean train loss 3261.9560294043285
INFO:root:current train perplexity3.6178605556488037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.93s/it]
INFO:root:final mean train loss: 3258.9840872979935
INFO:root:final train perplexity: 3.617428779602051
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 4076.9986148049647
INFO:root:eval perplexity: 5.19979190826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [23:21:05<5:24:57, 590.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.1228515625
INFO:root:current train perplexity3.617943286895752
INFO:root:current mean train loss 3257.7705946180554
INFO:root:current train perplexity3.61207914352417
INFO:root:current mean train loss 3247.7224754820477
INFO:root:current train perplexity3.605792760848999
INFO:root:current mean train loss 3255.314744636194
INFO:root:current train perplexity3.6089696884155273
INFO:root:current mean train loss 3257.365454943427
INFO:root:current train perplexity3.6107637882232666
INFO:root:current mean train loss 3261.0152174905083
INFO:root:current train perplexity3.6121320724487305
INFO:root:current mean train loss 3260.1679095410927
INFO:root:current train perplexity3.613865613937378
INFO:root:current mean train loss 3261.036268335459
INFO:root:current train perplexity3.6127636432647705
INFO:root:current mean train loss 3260.6532907817177
INFO:root:current train perplexity3.6124846935272217
INFO:root:current mean train loss 3259.8474408318016
INFO:root:current train perplexity3.6137754917144775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.13s/it]
INFO:root:final mean train loss: 3257.2522021262876
INFO:root:final train perplexity: 3.6149582862854004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 4075.915835549645
INFO:root:eval perplexity: 5.197515487670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [23:31:44<5:22:57, 605.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.5072674418607
INFO:root:current train perplexity3.5941340923309326
INFO:root:current mean train loss 3276.4420089188156
INFO:root:current train perplexity3.6237895488739014
INFO:root:current mean train loss 3259.006298426247
INFO:root:current train perplexity3.6164896488189697
INFO:root:current mean train loss 3253.2894717736426
INFO:root:current train perplexity3.609050750732422
INFO:root:current mean train loss 3255.058173254973
INFO:root:current train perplexity3.610687255859375
INFO:root:current mean train loss 3252.828869561464
INFO:root:current train perplexity3.6059117317199707
INFO:root:current mean train loss 3258.030407847735
INFO:root:current train perplexity3.607858180999756
INFO:root:current mean train loss 3259.556795061196
INFO:root:current train perplexity3.6126327514648438
INFO:root:current mean train loss 3261.0637354731984
INFO:root:current train perplexity3.6139323711395264
INFO:root:current mean train loss 3259.0685341310145
INFO:root:current train perplexity3.6131181716918945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.12s/it]
INFO:root:final mean train loss: 3255.590488433838
INFO:root:final train perplexity: 3.612588405609131
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 4077.4837741716533
INFO:root:eval perplexity: 5.200811386108398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [23:43:10<5:25:14, 629.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.405125038297
INFO:root:current train perplexity3.5988407135009766
INFO:root:current mean train loss 3249.0961897894244
INFO:root:current train perplexity3.5964574813842773
INFO:root:current mean train loss 3253.0940583369647
INFO:root:current train perplexity3.6098244190216064
INFO:root:current mean train loss 3251.387161124466
INFO:root:current train perplexity3.606397867202759
INFO:root:current mean train loss 3245.766663815653
INFO:root:current train perplexity3.6012585163116455
INFO:root:current mean train loss 3246.045695947
INFO:root:current train perplexity3.6023221015930176
INFO:root:current mean train loss 3250.226311608943
INFO:root:current train perplexity3.6048505306243896
INFO:root:current mean train loss 3253.0255274867886
INFO:root:current train perplexity3.6077821254730225
INFO:root:current mean train loss 3254.5791554972093
INFO:root:current train perplexity3.6073107719421387
INFO:root:current mean train loss 3255.4331832548796
INFO:root:current train perplexity3.608628511428833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.67s/it]
INFO:root:final mean train loss: 3253.7513614777595
INFO:root:final train perplexity: 3.609968900680542
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.96s/it]
INFO:root:eval mean loss: 4077.951339829898
INFO:root:eval perplexity: 5.2017951011657715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [23:51:49<4:58:07, 596.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.989729541843
INFO:root:current train perplexity3.603790283203125
INFO:root:current mean train loss 3238.0225300339034
INFO:root:current train perplexity3.58935809135437
INFO:root:current mean train loss 3235.450708102075
INFO:root:current train perplexity3.5946667194366455
INFO:root:current mean train loss 3245.767957597058
INFO:root:current train perplexity3.6054999828338623
INFO:root:current mean train loss 3245.5754633884803
INFO:root:current train perplexity3.6038975715637207
INFO:root:current mean train loss 3248.2288506086484
INFO:root:current train perplexity3.607107400894165
INFO:root:current mean train loss 3252.1102185632826
INFO:root:current train perplexity3.6091856956481934
INFO:root:current mean train loss 3254.6772206825385
INFO:root:current train perplexity3.6104013919830322
INFO:root:current mean train loss 3255.4289576360593
INFO:root:current train perplexity3.6109256744384766
INFO:root:current mean train loss 3254.9743912013655
INFO:root:current train perplexity3.6094188690185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.73s/it]
INFO:root:final mean train loss: 3253.4050711970176
INFO:root:final train perplexity: 3.6094753742218018
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 4077.6693279726287
INFO:root:eval perplexity: 5.201202869415283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [24:00:19<4:35:42, 570.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.6837686567164
INFO:root:current train perplexity3.59525203704834
INFO:root:current mean train loss 3266.5739015133795
INFO:root:current train perplexity3.611624002456665
INFO:root:current mean train loss 3256.9079727001404
INFO:root:current train perplexity3.6135096549987793
INFO:root:current mean train loss 3254.1653424088895
INFO:root:current train perplexity3.610774040222168
INFO:root:current mean train loss 3247.152394982936
INFO:root:current train perplexity3.606448173522949
INFO:root:current mean train loss 3245.9303376805005
INFO:root:current train perplexity3.602809429168701
INFO:root:current mean train loss 3245.594755112678
INFO:root:current train perplexity3.6021413803100586
INFO:root:current mean train loss 3248.571952093689
INFO:root:current train perplexity3.6034915447235107
INFO:root:current mean train loss 3251.8727233253135
INFO:root:current train perplexity3.60455584526062
INFO:root:current mean train loss 3251.831128661857
INFO:root:current train perplexity3.6042416095733643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.45s/it]
INFO:root:final mean train loss: 3249.6466297641878
INFO:root:final train perplexity: 3.6041269302368164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 4079.2233228751106
INFO:root:eval perplexity: 5.204472064971924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [24:10:07<4:28:41, 575.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.2123404947915
INFO:root:current train perplexity3.6136364936828613
INFO:root:current mean train loss 3243.2241573660713
INFO:root:current train perplexity3.6000759601593018
INFO:root:current mean train loss 3256.730213955966
INFO:root:current train perplexity3.6089258193969727
INFO:root:current mean train loss 3250.9831256510415
INFO:root:current train perplexity3.603172540664673
INFO:root:current mean train loss 3251.9439895148025
INFO:root:current train perplexity3.6046319007873535
INFO:root:current mean train loss 3252.7789087975543
INFO:root:current train perplexity3.6039247512817383
INFO:root:current mean train loss 3250.2421903935187
INFO:root:current train perplexity3.6038880348205566
INFO:root:current mean train loss 3251.5643079007054
INFO:root:current train perplexity3.6043083667755127
INFO:root:current mean train loss 3254.0339400111607
INFO:root:current train perplexity3.6056323051452637
INFO:root:current mean train loss 3252.868098958333
INFO:root:current train perplexity3.604401111602783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.41s/it]
INFO:root:final mean train loss: 3249.7430303635138
INFO:root:final train perplexity: 3.6042640209198
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 4080.0869521553636
INFO:root:eval perplexity: 5.206289291381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [24:20:16<4:23:33, 585.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.4569253576806
INFO:root:current train perplexity3.6185708045959473
INFO:root:current mean train loss 3253.494599556011
INFO:root:current train perplexity3.6006245613098145
INFO:root:current mean train loss 3250.1048907492273
INFO:root:current train perplexity3.6016063690185547
INFO:root:current mean train loss 3249.3760396693456
INFO:root:current train perplexity3.595008134841919
INFO:root:current mean train loss 3256.5653260667377
INFO:root:current train perplexity3.599668264389038
INFO:root:current mean train loss 3250.3323867824024
INFO:root:current train perplexity3.597930431365967
INFO:root:current mean train loss 3249.1950318991353
INFO:root:current train perplexity3.597904682159424
INFO:root:current mean train loss 3250.0028835408684
INFO:root:current train perplexity3.5988826751708984
INFO:root:current mean train loss 3251.59836129937
INFO:root:current train perplexity3.600999355316162
INFO:root:current mean train loss 3249.3205000139083
INFO:root:current train perplexity3.5999746322631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.62s/it]
INFO:root:final mean train loss: 3246.8321626724737
INFO:root:final train perplexity: 3.6001274585723877
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 4080.6936814328456
INFO:root:eval perplexity: 5.207566738128662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [24:28:39<4:03:02, 560.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3225.488831237122
INFO:root:current train perplexity3.5839312076568604
INFO:root:current mean train loss 3230.4020088555303
INFO:root:current train perplexity3.5836312770843506
INFO:root:current mean train loss 3240.7040084366945
INFO:root:current train perplexity3.5917418003082275
INFO:root:current mean train loss 3245.78601355199
INFO:root:current train perplexity3.5954062938690186
INFO:root:current mean train loss 3241.080922921175
INFO:root:current train perplexity3.589144229888916
INFO:root:current mean train loss 3243.3954078429038
INFO:root:current train perplexity3.590475559234619
INFO:root:current mean train loss 3245.8581567700794
INFO:root:current train perplexity3.5932815074920654
INFO:root:current mean train loss 3246.3554909726613
INFO:root:current train perplexity3.5945072174072266
INFO:root:current mean train loss 3249.5731777957526
INFO:root:current train perplexity3.598679780960083
INFO:root:current mean train loss 3250.2051648429615
INFO:root:current train perplexity3.6013238430023193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.52s/it]
INFO:root:final mean train loss: 3247.6301068336734
INFO:root:final train perplexity: 3.6012611389160156
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 4079.7100665586213
INFO:root:eval perplexity: 5.205495834350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [24:38:40<3:58:46, 573.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.8693058514837
INFO:root:current train perplexity3.5993053913116455
INFO:root:current mean train loss 3243.0981825632066
INFO:root:current train perplexity3.5934150218963623
INFO:root:current mean train loss 3243.2665533875943
INFO:root:current train perplexity3.593203544616699
INFO:root:current mean train loss 3244.683740601504
INFO:root:current train perplexity3.594510316848755
INFO:root:current mean train loss 3246.006795818199
INFO:root:current train perplexity3.596066951751709
INFO:root:current mean train loss 3248.023886653537
INFO:root:current train perplexity3.6004085540771484
INFO:root:current mean train loss 3248.614368531496
INFO:root:current train perplexity3.598278284072876
INFO:root:current mean train loss 3246.485225672716
INFO:root:current train perplexity3.5966482162475586
INFO:root:current mean train loss 3247.25495559302
INFO:root:current train perplexity3.597972869873047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.12s/it]
INFO:root:final mean train loss: 3247.35601868168
INFO:root:final train perplexity: 3.6008713245391846
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 4080.8865456006206
INFO:root:eval perplexity: 5.207973003387451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [24:47:13<3:41:57, 554.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.337820870536
INFO:root:current train perplexity3.502490282058716
INFO:root:current mean train loss 3254.420220776139
INFO:root:current train perplexity3.5878536701202393
INFO:root:current mean train loss 3246.96012133907
INFO:root:current train perplexity3.5847604274749756
INFO:root:current mean train loss 3243.9854143869607
INFO:root:current train perplexity3.5869786739349365
INFO:root:current mean train loss 3245.1622941300675
INFO:root:current train perplexity3.5853145122528076
INFO:root:current mean train loss 3243.013714250493
INFO:root:current train perplexity3.586663007736206
INFO:root:current mean train loss 3242.1632753777544
INFO:root:current train perplexity3.5889461040496826
INFO:root:current mean train loss 3244.306508022454
INFO:root:current train perplexity3.5938944816589355
INFO:root:current mean train loss 3245.2354265896065
INFO:root:current train perplexity3.5948598384857178
INFO:root:current mean train loss 3248.1026230447214
INFO:root:current train perplexity3.5989363193511963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.84s/it]
INFO:root:final mean train loss: 3244.874803296981
INFO:root:final train perplexity: 3.59734845161438
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 4080.7862315076463
INFO:root:eval perplexity: 5.207761764526367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [24:58:05<3:43:56, 584.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.815738932292
INFO:root:current train perplexity3.551514148712158
INFO:root:current mean train loss 3231.781022843071
INFO:root:current train perplexity3.560877561569214
INFO:root:current mean train loss 3238.7667491824127
INFO:root:current train perplexity3.5904388427734375
INFO:root:current mean train loss 3237.6703628782243
INFO:root:current train perplexity3.593087911605835
INFO:root:current mean train loss 3240.421317300452
INFO:root:current train perplexity3.5898914337158203
INFO:root:current mean train loss 3239.132637572057
INFO:root:current train perplexity3.586937189102173
INFO:root:current mean train loss 3242.6765855246445
INFO:root:current train perplexity3.588968515396118
INFO:root:current mean train loss 3245.295158845061
INFO:root:current train perplexity3.591672420501709
INFO:root:current mean train loss 3245.71091233704
INFO:root:current train perplexity3.592236042022705
INFO:root:current mean train loss 3244.796658608692
INFO:root:current train perplexity3.594064712524414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.48s/it]
INFO:root:final mean train loss: 3242.9308256333875
INFO:root:final train perplexity: 3.594590425491333
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 4081.846584455341
INFO:root:eval perplexity: 5.209995269775391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [25:08:29<3:38:34, 596.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.5321416440215
INFO:root:current train perplexity3.5964462757110596
INFO:root:current mean train loss 3259.2811785442073
INFO:root:current train perplexity3.5902974605560303
INFO:root:current mean train loss 3251.76073123949
INFO:root:current train perplexity3.5840654373168945
INFO:root:current mean train loss 3252.1256968967687
INFO:root:current train perplexity3.587423086166382
INFO:root:current mean train loss 3254.270273483673
INFO:root:current train perplexity3.5909264087677
INFO:root:current mean train loss 3248.7539071836163
INFO:root:current train perplexity3.5912930965423584
INFO:root:current mean train loss 3247.7174160438403
INFO:root:current train perplexity3.591210126876831
INFO:root:current mean train loss 3244.9537223509897
INFO:root:current train perplexity3.5924932956695557
INFO:root:current mean train loss 3242.854817906098
INFO:root:current train perplexity3.590282440185547
INFO:root:current mean train loss 3243.5232052622223
INFO:root:current train perplexity3.5935497283935547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.95s/it]
INFO:root:final mean train loss: 3242.199434034286
INFO:root:final train perplexity: 3.5935535430908203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 4082.076653230275
INFO:root:eval perplexity: 5.2104811668396
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [25:19:31<3:35:34, 615.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.753189579133
INFO:root:current train perplexity3.5943078994750977
INFO:root:current mean train loss 3235.323670831345
INFO:root:current train perplexity3.5872883796691895
INFO:root:current mean train loss 3232.8555194805194
INFO:root:current train perplexity3.592230796813965
INFO:root:current mean train loss 3231.937524340304
INFO:root:current train perplexity3.5894081592559814
INFO:root:current mean train loss 3236.0252977269433
INFO:root:current train perplexity3.5902047157287598
INFO:root:current mean train loss 3238.1950821526307
INFO:root:current train perplexity3.5877647399902344
INFO:root:current mean train loss 3240.056054068443
INFO:root:current train perplexity3.590566396713257
INFO:root:current mean train loss 3242.8845578883806
INFO:root:current train perplexity3.593007802963257
INFO:root:current mean train loss 3243.212941157115
INFO:root:current train perplexity3.5914204120635986
INFO:root:current mean train loss 3241.689669993203
INFO:root:current train perplexity3.589815616607666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.99s/it]
INFO:root:final mean train loss: 3240.9919721541864
INFO:root:final train perplexity: 3.591841697692871
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 4082.334950548537
INFO:root:eval perplexity: 5.211024761199951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [25:30:38<3:30:21, 631.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.901842948718
INFO:root:current train perplexity3.6242616176605225
INFO:root:current mean train loss 3238.1497952029003
INFO:root:current train perplexity3.594374418258667
INFO:root:current mean train loss 3235.080005597869
INFO:root:current train perplexity3.5890018939971924
INFO:root:current mean train loss 3240.1405004090616
INFO:root:current train perplexity3.587282180786133
INFO:root:current mean train loss 3239.220666420487
INFO:root:current train perplexity3.588691234588623
INFO:root:current mean train loss 3238.5754290352506
INFO:root:current train perplexity3.5868735313415527
INFO:root:current mean train loss 3237.7904516945423
INFO:root:current train perplexity3.5856597423553467
INFO:root:current mean train loss 3240.6444625338295
INFO:root:current train perplexity3.5877158641815186
INFO:root:current mean train loss 3242.437567509684
INFO:root:current train perplexity3.5907528400421143
INFO:root:current mean train loss 3242.420301215971
INFO:root:current train perplexity3.5897228717803955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.76s/it]
INFO:root:final mean train loss: 3240.1508381136
INFO:root:final train perplexity: 3.5906505584716797
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 4083.491827349291
INFO:root:eval perplexity: 5.2134623527526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [25:40:55<3:18:34, 627.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.0419194647607
INFO:root:current train perplexity3.5731699466705322
INFO:root:current mean train loss 3239.916681614052
INFO:root:current train perplexity3.593947649002075
INFO:root:current mean train loss 3242.016355445028
INFO:root:current train perplexity3.5896503925323486
INFO:root:current mean train loss 3247.603659154359
INFO:root:current train perplexity3.5933868885040283
INFO:root:current mean train loss 3244.233903104027
INFO:root:current train perplexity3.58982253074646
INFO:root:current mean train loss 3241.7868179237603
INFO:root:current train perplexity3.5898122787475586
INFO:root:current mean train loss 3243.7611614150646
INFO:root:current train perplexity3.589576005935669
INFO:root:current mean train loss 3242.474979017633
INFO:root:current train perplexity3.589771032333374
INFO:root:current mean train loss 3242.517172280844
INFO:root:current train perplexity3.5899088382720947
INFO:root:current mean train loss 3242.6126800504885
INFO:root:current train perplexity3.590291976928711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.30s/it]
INFO:root:final mean train loss: 3238.9078769068565
INFO:root:final train perplexity: 3.5888895988464355
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it]
INFO:root:eval mean loss: 4083.7000481355276
INFO:root:eval perplexity: 5.213901996612549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [25:49:40<2:58:51, 596.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.0511940696024
INFO:root:current train perplexity3.5968823432922363
INFO:root:current mean train loss 3224.991146358367
INFO:root:current train perplexity3.588977813720703
INFO:root:current mean train loss 3225.9386287913603
INFO:root:current train perplexity3.5771939754486084
INFO:root:current mean train loss 3231.893155122139
INFO:root:current train perplexity3.5783233642578125
INFO:root:current mean train loss 3233.6889498197115
INFO:root:current train perplexity3.576205253601074
INFO:root:current mean train loss 3232.683961500563
INFO:root:current train perplexity3.5807011127471924
INFO:root:current mean train loss 3234.460703795921
INFO:root:current train perplexity3.5796051025390625
INFO:root:current mean train loss 3236.5123758278146
INFO:root:current train perplexity3.5836052894592285
INFO:root:current mean train loss 3238.770206562957
INFO:root:current train perplexity3.584867000579834
INFO:root:current mean train loss 3239.429952092196
INFO:root:current train perplexity3.584944248199463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.53s/it]
INFO:root:final mean train loss: 3236.1468612301733
INFO:root:final train perplexity: 3.584982395172119
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 4083.5175486896055
INFO:root:eval perplexity: 5.213516712188721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [25:59:01<2:45:57, 585.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.3391927083335
INFO:root:current train perplexity3.5920064449310303
INFO:root:current mean train loss 3245.4704155483128
INFO:root:current train perplexity3.5863335132598877
INFO:root:current mean train loss 3238.1648923924668
INFO:root:current train perplexity3.585026741027832
INFO:root:current mean train loss 3238.347348888387
INFO:root:current train perplexity3.587287425994873
INFO:root:current mean train loss 3238.0055345572355
INFO:root:current train perplexity3.586329698562622
INFO:root:current mean train loss 3236.738651146897
INFO:root:current train perplexity3.585634231567383
INFO:root:current mean train loss 3239.1783526436416
INFO:root:current train perplexity3.586527109146118
INFO:root:current mean train loss 3240.4117046071224
INFO:root:current train perplexity3.5852181911468506
INFO:root:current mean train loss 3237.745062588264
INFO:root:current train perplexity3.5845580101013184
INFO:root:current mean train loss 3237.737072462357
INFO:root:current train perplexity3.5852413177490234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.77s/it]
INFO:root:final mean train loss: 3236.6162306877873
INFO:root:final train perplexity: 3.585646152496338
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 4084.03983820922
INFO:root:eval perplexity: 5.21461820602417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [26:09:05<2:37:37, 591.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.641034193442
INFO:root:current train perplexity3.5819814205169678
INFO:root:current mean train loss 3244.3750799524855
INFO:root:current train perplexity3.579676628112793
INFO:root:current mean train loss 3241.169762417839
INFO:root:current train perplexity3.5778634548187256
INFO:root:current mean train loss 3238.5764712927476
INFO:root:current train perplexity3.5777828693389893
INFO:root:current mean train loss 3237.693785973162
INFO:root:current train perplexity3.5777642726898193
INFO:root:current mean train loss 3236.9688290998524
INFO:root:current train perplexity3.5778934955596924
INFO:root:current mean train loss 3237.3045725246834
INFO:root:current train perplexity3.5806710720062256
INFO:root:current mean train loss 3236.529281358929
INFO:root:current train perplexity3.5820982456207275
INFO:root:current mean train loss 3240.313052189473
INFO:root:current train perplexity3.5838098526000977
INFO:root:current mean train loss 3239.367294358667
INFO:root:current train perplexity3.585113525390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.55s/it]
INFO:root:final mean train loss: 3235.784259180869
INFO:root:final train perplexity: 3.5844695568084717
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 4084.2847562749334
INFO:root:eval perplexity: 5.215134143829346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [26:17:52<2:22:59, 571.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.2431578817245
INFO:root:current train perplexity3.568142890930176
INFO:root:current mean train loss 3222.191137558921
INFO:root:current train perplexity3.5763168334960938
INFO:root:current mean train loss 3225.765577746976
INFO:root:current train perplexity3.5845272541046143
INFO:root:current mean train loss 3231.6419487704075
INFO:root:current train perplexity3.582975149154663
INFO:root:current mean train loss 3234.6543529406968
INFO:root:current train perplexity3.5836565494537354
INFO:root:current mean train loss 3236.9383837974956
INFO:root:current train perplexity3.582732915878296
INFO:root:current mean train loss 3239.068383465459
INFO:root:current train perplexity3.5852153301239014
INFO:root:current mean train loss 3239.015549156571
INFO:root:current train perplexity3.5859649181365967
INFO:root:current mean train loss 3240.1529906254445
INFO:root:current train perplexity3.585944414138794
INFO:root:current mean train loss 3239.084434750862
INFO:root:current train perplexity3.5849485397338867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.51s/it]
INFO:root:final mean train loss: 3235.8723847173874
INFO:root:final train perplexity: 3.584594249725342
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 4083.670636981937
INFO:root:eval perplexity: 5.213840484619141
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [26:28:28<2:17:58, 591.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.4230367726295
INFO:root:current train perplexity3.601040840148926
INFO:root:current mean train loss 3239.276760162517
INFO:root:current train perplexity3.5926673412323
INFO:root:current mean train loss 3240.968604536422
INFO:root:current train perplexity3.5842392444610596
INFO:root:current mean train loss 3240.2436302638484
INFO:root:current train perplexity3.5808703899383545
INFO:root:current mean train loss 3241.217966443949
INFO:root:current train perplexity3.5808897018432617
INFO:root:current mean train loss 3239.5658697229023
INFO:root:current train perplexity3.5824532508850098
INFO:root:current mean train loss 3241.3768660588385
INFO:root:current train perplexity3.58417010307312
INFO:root:current mean train loss 3239.6679889140923
INFO:root:current train perplexity3.5842208862304688
INFO:root:current mean train loss 3238.0879319114642
INFO:root:current train perplexity3.583435535430908
INFO:root:current mean train loss 3237.6207749077857
INFO:root:current train perplexity3.583496570587158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.54s/it]
INFO:root:final mean train loss: 3234.6604537963867
INFO:root:final train perplexity: 3.5828802585601807
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 4085.071952224623
INFO:root:eval perplexity: 5.216794967651367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [26:39:02<2:10:52, 604.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.859634560033
INFO:root:current train perplexity3.573552370071411
INFO:root:current mean train loss 3238.5326923076923
INFO:root:current train perplexity3.5815510749816895
INFO:root:current mean train loss 3235.729939088983
INFO:root:current train perplexity3.579976797103882
INFO:root:current mean train loss 3233.8166757318036
INFO:root:current train perplexity3.5793490409851074
INFO:root:current mean train loss 3232.415379379735
INFO:root:current train perplexity3.5780131816864014
INFO:root:current mean train loss 3235.9502662979253
INFO:root:current train perplexity3.5827226638793945
INFO:root:current mean train loss 3239.7908224201888
INFO:root:current train perplexity3.5857670307159424
INFO:root:current mean train loss 3238.9925277613993
INFO:root:current train perplexity3.5846383571624756
INFO:root:current mean train loss 3237.879827437587
INFO:root:current train perplexity3.5844662189483643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.32s/it]
INFO:root:final mean train loss: 3234.409017685921
INFO:root:final train perplexity: 3.5825257301330566
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 4084.3765427609706
INFO:root:eval perplexity: 5.215327739715576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [26:47:27<1:54:50, 574.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.1122233072915
INFO:root:current train perplexity3.5186259746551514
INFO:root:current mean train loss 3229.0022565230583
INFO:root:current train perplexity3.5567266941070557
INFO:root:current mean train loss 3228.0650171740303
INFO:root:current train perplexity3.567159652709961
INFO:root:current mean train loss 3233.3460238113653
INFO:root:current train perplexity3.576145648956299
INFO:root:current mean train loss 3230.0196475651364
INFO:root:current train perplexity3.575364112854004
INFO:root:current mean train loss 3231.348024645098
INFO:root:current train perplexity3.5786638259887695
INFO:root:current mean train loss 3227.641954614946
INFO:root:current train perplexity3.577183246612549
INFO:root:current mean train loss 3230.1947558038096
INFO:root:current train perplexity3.57533860206604
INFO:root:current mean train loss 3230.3105414023585
INFO:root:current train perplexity3.5754473209381104
INFO:root:current mean train loss 3235.4421667899537
INFO:root:current train perplexity3.5785651206970215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.09s/it]
INFO:root:final mean train loss: 3232.276064349759
INFO:root:final train perplexity: 3.579511880874634
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 4084.5462222268397
INFO:root:eval perplexity: 5.215685844421387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [26:56:57<1:45:04, 573.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.8260609019885
INFO:root:current train perplexity3.578803300857544
INFO:root:current mean train loss 3218.725775091498
INFO:root:current train perplexity3.5689728260040283
INFO:root:current mean train loss 3234.111466972749
INFO:root:current train perplexity3.5768418312072754
INFO:root:current mean train loss 3235.3324685050743
INFO:root:current train perplexity3.5784778594970703
INFO:root:current mean train loss 3230.6340640919634
INFO:root:current train perplexity3.578721046447754
INFO:root:current mean train loss 3229.3255029965753
INFO:root:current train perplexity3.5775210857391357
INFO:root:current mean train loss 3227.4117257825287
INFO:root:current train perplexity3.57486891746521
INFO:root:current mean train loss 3229.6246336173745
INFO:root:current train perplexity3.5770115852355957
INFO:root:current mean train loss 3229.559703972719
INFO:root:current train perplexity3.5754494667053223
INFO:root:current mean train loss 3233.256875064318
INFO:root:current train perplexity3.578092575073242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.39s/it]
INFO:root:final mean train loss: 3231.487864278978
INFO:root:final train perplexity: 3.578399181365967
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 4084.7086952155364
INFO:root:eval perplexity: 5.216029167175293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [27:05:51<1:33:32, 561.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.1474095394738
INFO:root:current train perplexity3.5805423259735107
INFO:root:current mean train loss 3249.8200437401524
INFO:root:current train perplexity3.584679365158081
INFO:root:current mean train loss 3243.522405197631
INFO:root:current train perplexity3.5778720378875732
INFO:root:current mean train loss 3244.56932216154
INFO:root:current train perplexity3.5810108184814453
INFO:root:current mean train loss 3235.6351053242465
INFO:root:current train perplexity3.5774378776550293
INFO:root:current mean train loss 3236.132368436898
INFO:root:current train perplexity3.577338218688965
INFO:root:current mean train loss 3233.4688067952343
INFO:root:current train perplexity3.576927423477173
INFO:root:current mean train loss 3232.967082780989
INFO:root:current train perplexity3.576650381088257
INFO:root:current mean train loss 3230.9859781602945
INFO:root:current train perplexity3.576392889022827
INFO:root:current mean train loss 3232.208577119746
INFO:root:current train perplexity3.5767879486083984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.90s/it]
INFO:root:final mean train loss: 3231.064854160432
INFO:root:final train perplexity: 3.5778017044067383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 4085.738818013076
INFO:root:eval perplexity: 5.218202114105225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [27:15:53<1:26:02, 573.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.9916630497687
INFO:root:current train perplexity3.594714641571045
INFO:root:current mean train loss 3250.5664850670523
INFO:root:current train perplexity3.5762362480163574
INFO:root:current mean train loss 3241.7633363160794
INFO:root:current train perplexity3.5777769088745117
INFO:root:current mean train loss 3239.744946214402
INFO:root:current train perplexity3.5762171745300293
INFO:root:current mean train loss 3237.239816419972
INFO:root:current train perplexity3.5773134231567383
INFO:root:current mean train loss 3239.651332442629
INFO:root:current train perplexity3.5774614810943604
INFO:root:current mean train loss 3235.372131055622
INFO:root:current train perplexity3.5764172077178955
INFO:root:current mean train loss 3233.5458974300423
INFO:root:current train perplexity3.5758039951324463
INFO:root:current mean train loss 3231.4417126804337
INFO:root:current train perplexity3.5751395225524902
INFO:root:current mean train loss 3231.97790909225
INFO:root:current train perplexity3.5759623050689697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.50s/it]
INFO:root:final mean train loss: 3230.513700362175
INFO:root:final train perplexity: 3.57702374458313
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 4085.6901232130986
INFO:root:eval perplexity: 5.2180986404418945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [27:26:28<1:18:54, 591.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.886446707589
INFO:root:current train perplexity3.579690456390381
INFO:root:current mean train loss 3230.7562952112266
INFO:root:current train perplexity3.573669910430908
INFO:root:current mean train loss 3226.4761220079786
INFO:root:current train perplexity3.57401967048645
INFO:root:current mean train loss 3230.7264874358675
INFO:root:current train perplexity3.577988862991333
INFO:root:current mean train loss 3235.009753277658
INFO:root:current train perplexity3.5780367851257324
INFO:root:current mean train loss 3229.9051785192755
INFO:root:current train perplexity3.573699474334717
INFO:root:current mean train loss 3232.2989123246803
INFO:root:current train perplexity3.577176570892334
INFO:root:current mean train loss 3231.226439267113
INFO:root:current train perplexity3.577747106552124
INFO:root:current mean train loss 3231.1484965615646
INFO:root:current train perplexity3.576450824737549
INFO:root:current mean train loss 3232.1503021077037
INFO:root:current train perplexity3.5770246982574463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.42s/it]
INFO:root:final mean train loss: 3231.4088183987524
INFO:root:final train perplexity: 3.578287124633789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 4085.4260859929077
INFO:root:eval perplexity: 5.21754264831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [27:35:00<1:06:15, 567.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3233.8241619731107
INFO:root:current train perplexity3.598729133605957
INFO:root:current mean train loss 3236.921526715472
INFO:root:current train perplexity3.5956830978393555
INFO:root:current mean train loss 3235.5758614245756
INFO:root:current train perplexity3.5841259956359863
INFO:root:current mean train loss 3231.887382840971
INFO:root:current train perplexity3.585193395614624
INFO:root:current mean train loss 3236.383042862937
INFO:root:current train perplexity3.5827505588531494
INFO:root:current mean train loss 3235.2221630229915
INFO:root:current train perplexity3.5791821479797363
INFO:root:current mean train loss 3234.0702278291456
INFO:root:current train perplexity3.579162836074829
INFO:root:current mean train loss 3233.2566414136104
INFO:root:current train perplexity3.5776593685150146
INFO:root:current mean train loss 3235.4700402093526
INFO:root:current train perplexity3.578413486480713
INFO:root:current mean train loss 3234.914555700308
INFO:root:current train perplexity3.5776801109313965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.42s/it]
INFO:root:final mean train loss: 3231.180740787137
INFO:root:final train perplexity: 3.577965021133423
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 4085.4218455646055
INFO:root:eval perplexity: 5.217533111572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [27:43:51<55:41, 556.86s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.476864085478
INFO:root:current train perplexity3.541776418685913
INFO:root:current mean train loss 3216.891713123448
INFO:root:current train perplexity3.5591490268707275
INFO:root:current mean train loss 3221.7930533724475
INFO:root:current train perplexity3.5693373680114746
INFO:root:current mean train loss 3222.310190749644
INFO:root:current train perplexity3.5692286491394043
INFO:root:current mean train loss 3225.1873072858925
INFO:root:current train perplexity3.5701088905334473
INFO:root:current mean train loss 3227.5480992478165
INFO:root:current train perplexity3.572956085205078
INFO:root:current mean train loss 3230.6982380622358
INFO:root:current train perplexity3.5750646591186523
INFO:root:current mean train loss 3228.0346949510026
INFO:root:current train perplexity3.5727427005767822
INFO:root:current mean train loss 3228.9175653872285
INFO:root:current train perplexity3.573183059692383
INFO:root:current mean train loss 3229.606642216663
INFO:root:current train perplexity3.5734219551086426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.02s/it]
INFO:root:final mean train loss: 3227.136966889904
INFO:root:final train perplexity: 3.5722618103027344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 4085.4751253601507
INFO:root:eval perplexity: 5.217645168304443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [27:52:42<45:46, 549.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.905732752913
INFO:root:current train perplexity3.5934653282165527
INFO:root:current mean train loss 3244.686300793534
INFO:root:current train perplexity3.587496042251587
INFO:root:current mean train loss 3244.070386024976
INFO:root:current train perplexity3.582268714904785
INFO:root:current mean train loss 3239.6205415433496
INFO:root:current train perplexity3.5782487392425537
INFO:root:current mean train loss 3235.992015697338
INFO:root:current train perplexity3.576831102371216
INFO:root:current mean train loss 3231.454954962824
INFO:root:current train perplexity3.576108932495117
INFO:root:current mean train loss 3229.3547533698074
INFO:root:current train perplexity3.575040340423584
INFO:root:current mean train loss 3230.2668013139205
INFO:root:current train perplexity3.575723886489868
INFO:root:current mean train loss 3231.08675205999
INFO:root:current train perplexity3.574000597000122
INFO:root:current mean train loss 3231.1415020223703
INFO:root:current train perplexity3.574436902999878

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.20s/it]
INFO:root:final mean train loss: 3228.544171917823
INFO:root:final train perplexity: 3.5742454528808594
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 4085.598127216312
INFO:root:eval perplexity: 5.217905044555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [28:00:48<35:20, 530.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.0906599813434
INFO:root:current train perplexity3.584192991256714
INFO:root:current mean train loss 3234.624074604697
INFO:root:current train perplexity3.5820369720458984
INFO:root:current mean train loss 3235.3662621430244
INFO:root:current train perplexity3.5766942501068115
INFO:root:current mean train loss 3234.522938575017
INFO:root:current train perplexity3.574367046356201
INFO:root:current mean train loss 3236.303456341174
INFO:root:current train perplexity3.57680344581604
INFO:root:current mean train loss 3234.5800587487597
INFO:root:current train perplexity3.57568097114563
INFO:root:current mean train loss 3230.9545294491427
INFO:root:current train perplexity3.5729329586029053
INFO:root:current mean train loss 3231.810410958381
INFO:root:current train perplexity3.5750138759613037
INFO:root:current mean train loss 3230.4490382492613
INFO:root:current train perplexity3.5738749504089355
INFO:root:current mean train loss 3229.0378324554035
INFO:root:current train perplexity3.572252035140991

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.01s/it]
INFO:root:final mean train loss: 3226.4281263659077
INFO:root:final train perplexity: 3.571262836456299
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 4085.949809189384
INFO:root:eval perplexity: 5.218647480010986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [28:10:13<27:01, 540.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.4636393229166
INFO:root:current train perplexity3.56339693069458
INFO:root:current mean train loss 3226.3395842633927
INFO:root:current train perplexity3.564441680908203
INFO:root:current mean train loss 3227.606173650568
INFO:root:current train perplexity3.571101665496826
INFO:root:current mean train loss 3223.757634765625
INFO:root:current train perplexity3.568584442138672
INFO:root:current mean train loss 3227.3452477384867
INFO:root:current train perplexity3.5677783489227295
INFO:root:current mean train loss 3228.925915845788
INFO:root:current train perplexity3.567945957183838
INFO:root:current mean train loss 3230.558463179977
INFO:root:current train perplexity3.5705316066741943
INFO:root:current mean train loss 3228.4237745715727
INFO:root:current train perplexity3.5697813034057617
INFO:root:current mean train loss 3230.0571110491073
INFO:root:current train perplexity3.570183038711548
INFO:root:current mean train loss 3228.908709685497
INFO:root:current train perplexity3.57148814201355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.46s/it]
INFO:root:final mean train loss: 3226.5037674442415
INFO:root:final train perplexity: 3.5713694095611572
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4085.8677381150264
INFO:root:eval perplexity: 5.218473434448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [28:20:01<18:29, 554.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.832934276167
INFO:root:current train perplexity3.578012466430664
INFO:root:current mean train loss 3237.435784345116
INFO:root:current train perplexity3.5793519020080566
INFO:root:current mean train loss 3239.952445202076
INFO:root:current train perplexity3.585930347442627
INFO:root:current mean train loss 3235.121691671426
INFO:root:current train perplexity3.5811409950256348
INFO:root:current mean train loss 3227.426166415955
INFO:root:current train perplexity3.578071355819702
INFO:root:current mean train loss 3230.874009199453
INFO:root:current train perplexity3.580629825592041
INFO:root:current mean train loss 3231.139245230143
INFO:root:current train perplexity3.576188564300537
INFO:root:current mean train loss 3230.358478570502
INFO:root:current train perplexity3.5730578899383545
INFO:root:current mean train loss 3231.110159954965
INFO:root:current train perplexity3.572214126586914
INFO:root:current mean train loss 3230.6390568373286
INFO:root:current train perplexity3.573030948638916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.05s/it]
INFO:root:final mean train loss: 3227.571336130942
INFO:root:final train perplexity: 3.57287335395813
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 4085.92573103668
INFO:root:eval perplexity: 5.2185959815979
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [28:29:56<09:27, 567.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.828358409169
INFO:root:current train perplexity3.5770137310028076
INFO:root:current mean train loss 3223.7329293295975
INFO:root:current train perplexity3.5643184185028076
INFO:root:current mean train loss 3220.1514989059815
INFO:root:current train perplexity3.565209150314331
INFO:root:current mean train loss 3223.9873365319295
INFO:root:current train perplexity3.5660877227783203
INFO:root:current mean train loss 3225.74749196474
INFO:root:current train perplexity3.567594289779663
INFO:root:current mean train loss 3226.756560401465
INFO:root:current train perplexity3.5719106197357178
INFO:root:current mean train loss 3225.7168311465493
INFO:root:current train perplexity3.570211172103882
INFO:root:current mean train loss 3227.382408479674
INFO:root:current train perplexity3.569992780685425
INFO:root:current mean train loss 3228.806487180836
INFO:root:current train perplexity3.571380376815796
INFO:root:current mean train loss 3228.989854244844
INFO:root:current train perplexity3.571265935897827

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.96s/it]
INFO:root:final mean train loss: 3226.391792235836
INFO:root:final train perplexity: 3.571211814880371
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 4085.969406236148
INFO:root:eval perplexity: 5.218688488006592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1100/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [28:38:48<00:00, 556.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [28:38:48<00:00, 515.64s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.89s/it]
INFO:root:eval mean loss: 4085.969406236148
INFO:root:eval perplexity: 5.218688488006592
INFO:root:evalaution complete
INFO:root:save model final: small_val_1100/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14b120c63f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14b120c5b8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14b120b80e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b120c64a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14b120b7e948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b120c64a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14b120b39b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14b12059e46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14b21cdbaa27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14b21cdbabe0]
python(+0x24a989) [0x55fee3b49989]
python(+0x24a9bd) [0x55fee3b499bd]
python(+0x24aa14) [0x55fee3b49a14]
python(+0x108f75) [0x55fee3a07f75]
python(Py_RunMain+0x313) [0x55fee3b4c983]
python(Py_BytesMain+0x39) [0x55fee3b4cbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14b21cd980b3]
python(+0x1d6e13) [0x55fee3ad5e13]
/opt/slurm/data/slurmd/job26146353/slurm_script: line 140: 932234 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_1100_final  --output small_val_1100 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
